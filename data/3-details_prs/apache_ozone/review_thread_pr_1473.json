{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk3NDYzMTc5", "number": 1473, "reviewThreads": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzoxMjozM1rOEqL6zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoxNzozMlrOEtJRFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjcwOTI2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzoxMjozM1rOHcQAiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzo0ODozNVrOHdmwYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NDQ1Nw==", "bodyText": "Why not add setFileName here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499384457", "createdAt": "2020-10-05T07:12:33Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -413,7 +461,8 @@ public KeyInfo getProtobuf(boolean ignorePipeline) {\n         .addAllMetadata(KeyValueUtil.toProtobuf(metadata))\n         .addAllAcls(OzoneAclUtil.toProtobuf(acls))\n         .setObjectID(objectID)\n-        .setUpdateID(updateID);\n+        .setUpdateID(updateID)\n+        .setParentID(parentObjectID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ3MDA3OQ==", "bodyText": "I am not persisting fileName, which is already the last name in the path component(keyName). I have added logic to prepare filename from Keyname. Hope this is fine?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500470079", "createdAt": "2020-10-06T17:24:04Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -413,7 +461,8 @@ public KeyInfo getProtobuf(boolean ignorePipeline) {\n         .addAllMetadata(KeyValueUtil.toProtobuf(metadata))\n         .addAllAcls(OzoneAclUtil.toProtobuf(acls))\n         .setObjectID(objectID)\n-        .setUpdateID(updateID);\n+        .setUpdateID(updateID)\n+        .setParentID(parentObjectID);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NDQ1Nw=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwNTczMA==", "bodyText": "Yes, makes sense to me.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500805730", "createdAt": "2020-10-07T07:48:35Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -413,7 +461,8 @@ public KeyInfo getProtobuf(boolean ignorePipeline) {\n         .addAllMetadata(KeyValueUtil.toProtobuf(metadata))\n         .addAllAcls(OzoneAclUtil.toProtobuf(acls))\n         .setObjectID(objectID)\n-        .setUpdateID(updateID);\n+        .setUpdateID(updateID)\n+        .setParentID(parentObjectID);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NDQ1Nw=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjcxOTQ4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/interface-storage/src/main/java/org/apache/hadoop/ozone/om/OMMetadataManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzoxNjowNFrOHcQGiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzowMVrOHdtHLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NTk5NQ==", "bodyText": "Not the change of current PR but was introduced in last PR of HDDS-2949.\n/**\n   * Given a volume, bucket and a key, return the corresponding DB prefixKey\n   * key.\n   *\n   * @param parentObjectId - parent object Id\n   * @param pathComponentName   - path component name\n   * @return DB directory key as String.\n   */\n  String getOzonePathKey(long parentObjectId, String pathComponentName);\nCan we update above comment? It's not correct.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499385995", "createdAt": "2020-10-05T07:16:04Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-storage/src/main/java/org/apache/hadoop/ozone/om/OMMetadataManager.java", "diffHunk": "@@ -399,4 +399,15 @@ String getMultipartKey(String volume, String bucket, String key, String\n    * @return DB directory key as String.\n    */\n   String getOzonePathKey(long parentObjectId, String pathComponentName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkwOTg3MA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500909870", "createdAt": "2020-10-07T10:37:01Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/interface-storage/src/main/java/org/apache/hadoop/ozone/om/OMMetadataManager.java", "diffHunk": "@@ -399,4 +399,15 @@ String getMultipartKey(String volume, String bucket, String key, String\n    * @return DB directory key as String.\n    */\n   String getOzonePathKey(long parentObjectId, String pathComponentName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NTk5NQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjczMDM5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzoxOTo1NlrOHcQM7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzoxMVrOHdtHhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NzYzMQ==", "bodyText": "Can we add openFileTable structure as well here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499387631", "createdAt": "2020-10-05T07:19:56Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,8 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName -> FileInfo                   |\n+   * |----------------------------------------------------------------------|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkwOTk1Ng==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500909956", "createdAt": "2020-10-07T10:37:11Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,8 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName -> FileInfo                   |\n+   * |----------------------------------------------------------------------|", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM4NzYzMQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNjgxMzgzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQwNzo0NjoxMlrOHcQ_SQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzoyMFrOHdtH1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQwMDUyMQ==", "bodyText": "We could use  OmDirectoryInfo#getPath to simplified for this, there is already one method doing this.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499400521", "createdAt": "2020-10-05T07:46:12Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDAzOA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910038", "createdAt": "2020-10-07T10:37:20Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTQwMDUyMQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzkwOTU4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo0NDoxM1rOHcbTnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzoyNVrOHdtIAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU2OTU2NQ==", "bodyText": "Nit: Remove this empty line.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499569565", "createdAt": "2020-10-05T12:44:13Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -346,6 +369,7 @@ protected static DBStoreBuilder addOMTablesAndCodecs(DBStoreBuilder builder) {\n         .addCodec(S3SecretValue.class, new S3SecretValueCodec())\n         .addCodec(OmPrefixInfo.class, new OmPrefixInfoCodec())\n         .addCodec(OmDirectoryInfo.class, new OmDirectoryInfoCodec())\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDA4MQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910081", "createdAt": "2020-10-07T10:37:25Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -346,6 +369,7 @@ protected static DBStoreBuilder addOMTablesAndCodecs(DBStoreBuilder builder) {\n         .addCodec(S3SecretValue.class, new S3SecretValueCodec())\n         .addCodec(OmPrefixInfo.class, new OmPrefixInfoCodec())\n         .addCodec(OmDirectoryInfo.class, new OmDirectoryInfoCodec())\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU2OTU2NQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzk1MzYxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMjo1NToyNFrOHcbu0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzozMFrOHdtIKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjUyOA==", "bodyText": "Can we rename method #getAllParentDirInfo to #getAllMissingParentDirInfo to make this more readable?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499576528", "createdAt": "2020-10-05T12:55:24Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDEyMA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910120", "createdAt": "2020-10-07T10:37:30Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU3NjUyOA=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyNzk5ODYzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzowNjoyNlrOHccKRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzozN1rOHdtIWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU4MzU1OQ==", "bodyText": "Can we use omMetadataManager.getOzonePathKey to construct db key name instead of?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499583559", "createdAt": "2020-10-05T13:06:26Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {\n+    case SUCCESS:\n+      // As when we commit the key, then it is visible in ozone, so we should\n+      // increment here.\n+      // As key also can have multiple versions, we need to increment keys\n+      // only if version is 0. Currently we have not complete support of\n+      // versioning of keys. So, this can be revisited later.\n+      if (omKeyInfo.getKeyLocationVersions().size() == 1) {\n+        omMetrics.incNumKeys();\n+      }\n+      LOG.debug(\"Key committed. Volume:{}, Bucket:{}, Key:{}\", volumeName,\n+              bucketName, keyName);\n+      break;\n+    case FAILURE:\n+      LOG.error(\"Key commit failed. Volume:{}, Bucket:{}, Key:{}. Exception:{}\",\n+              volumeName, bucketName, keyName, exception);\n+      omMetrics.incNumKeyCommitFails();\n+      break;\n+    default:\n+      LOG.error(\"Unrecognized Result for OMKeyCommitRequest: {}\",\n+              commitKeyRequest);\n+    }\n+\n+    return omClientResponse;\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                                        String keyName,\n+                                        OMMetadataManager omMetadataManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+    boolean parentFound = true; // default bucketID as parent\n+    OmDirectoryInfo omDirectoryInfo = null;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      // Reached last component, which would be a file. Returns its parentID.\n+      if (!pathComponents.hasNext()) {\n+        return lastKnownParentId;\n+      }\n+      String dbNodeName = lastKnownParentId + \"/\" + nodeName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDE2OA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910168", "createdAt": "2020-10-07T10:37:37Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {\n+    case SUCCESS:\n+      // As when we commit the key, then it is visible in ozone, so we should\n+      // increment here.\n+      // As key also can have multiple versions, we need to increment keys\n+      // only if version is 0. Currently we have not complete support of\n+      // versioning of keys. So, this can be revisited later.\n+      if (omKeyInfo.getKeyLocationVersions().size() == 1) {\n+        omMetrics.incNumKeys();\n+      }\n+      LOG.debug(\"Key committed. Volume:{}, Bucket:{}, Key:{}\", volumeName,\n+              bucketName, keyName);\n+      break;\n+    case FAILURE:\n+      LOG.error(\"Key commit failed. Volume:{}, Bucket:{}, Key:{}. Exception:{}\",\n+              volumeName, bucketName, keyName, exception);\n+      omMetrics.incNumKeyCommitFails();\n+      break;\n+    default:\n+      LOG.error(\"Unrecognized Result for OMKeyCommitRequest: {}\",\n+              commitKeyRequest);\n+    }\n+\n+    return omClientResponse;\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                                        String keyName,\n+                                        OMMetadataManager omMetadataManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+    boolean parentFound = true; // default bucketID as parent\n+    OmDirectoryInfo omDirectoryInfo = null;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      // Reached last component, which would be a file. Returns its parentID.\n+      if (!pathComponents.hasNext()) {\n+        return lastKnownParentId;\n+      }\n+      String dbNodeName = lastKnownParentId + \"/\" + nodeName;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU4MzU1OQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 241}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODA1Njc5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoyMDoxN1rOHcctcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzo0M1rOHdtIlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MjU2Mg==", "bodyText": "For the cleanuptable annotation of OMKeyCommitResponseV1, we should remove OPEN_KEY_TABLE, KEY_TABLE I think. When OMKeyCommitResponseV1 is used, we should only use OPEN_FILE_TABLE, FILE_TABLE tables.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499592562", "createdAt": "2020-10-05T13:20:17Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_KEY_TABLE, KEY_TABLE,\n+        OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDIzMQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910231", "createdAt": "2020-10-07T10:37:43Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_KEY_TABLE, KEY_TABLE,\n+        OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5MjU2Mg=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODA4MjY1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoyNjowN1rOHcc9FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzo1M1rOHdtI7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5NjU2NQ==", "bodyText": "Seems we lack of below logic compared with original OMFileCreateResponse logic.\n    // update volume usedBytes.\n    omMetadataManager.getVolumeTable().putWithBatch(batchOperation,\n        omMetadataManager.getVolumeKey(omVolumeArgs.getVolume()),\n        omVolumeArgs);\n    // update bucket usedBytes.\n    omMetadataManager.getBucketTable().putWithBatch(batchOperation,\n        omMetadataManager.getBucketKey(omVolumeArgs.getVolume(),\n            omBucketInfo.getBucketName()), omBucketInfo);", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499596565", "createdAt": "2020-10-05T13:26:07Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"putWithBatch adding parent : key {} info : {}\", parentKey,\n+                  parentKeyInfo);\n+        }\n+        omMetadataMgr.getDirectoryTable().putWithBatch(batchOp, parentKey,\n+                parentKeyInfo);\n+      }\n+    }\n+\n+    String openKey = omMetadataMgr.getOpenFileName(\n+            getOmKeyInfo().getParentObjectID(), getOmKeyInfo().getFileName(),\n+            getOpenKeySessionID());\n+    omMetadataMgr.getOpenKeyTable().putWithBatch(batchOp, openKey,\n+            getOmKeyInfo());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDMxOA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910318", "createdAt": "2020-10-07T10:37:53Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {\n+\n+  private List<OmDirectoryInfo> parentDirInfos;\n+\n+  public OMFileCreateResponseV1(@Nonnull OMResponse omResponse,\n+                                @Nonnull OmKeyInfo omKeyInfo,\n+                                @Nonnull List<OmDirectoryInfo> parentDirInfos,\n+                                long openKeySessionID,\n+                                @Nonnull OmVolumeArgs omVolumeArgs,\n+                                @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, new ArrayList<>(), openKeySessionID,\n+        omVolumeArgs, omBucketInfo);\n+    this.parentDirInfos = parentDirInfos;\n+  }\n+\n+  @Override\n+  protected void addToDBBatch(OMMetadataManager omMetadataMgr,\n+                              BatchOperation batchOp) throws IOException {\n+\n+    /**\n+     * Create parent directory entries during Key Create - do not wait\n+     * for Key Commit request.\n+     * XXX handle stale directory entries.\n+     */\n+    if (parentDirInfos != null) {\n+      for (OmDirectoryInfo parentKeyInfo : parentDirInfos) {\n+        String parentKey = omMetadataMgr.getOzonePathKey(\n+                parentKeyInfo.getParentObjectID(), parentKeyInfo.getName());\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"putWithBatch adding parent : key {} info : {}\", parentKey,\n+                  parentKeyInfo);\n+        }\n+        omMetadataMgr.getDirectoryTable().putWithBatch(batchOp, parentKey,\n+                parentKeyInfo);\n+      }\n+    }\n+\n+    String openKey = omMetadataMgr.getOpenFileName(\n+            getOmKeyInfo().getParentObjectID(), getOmKeyInfo().getFileName(),\n+            getOpenKeySessionID());\n+    omMetadataMgr.getOpenKeyTable().putWithBatch(batchOp, openKey,\n+            getOmKeyInfo());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5NjU2NQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODEyMjcyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzozNToyMFrOHcdWOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozNzo1OVrOHdtJIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwMzAwMw==", "bodyText": "We should add annotation for cleanup table.\n@CleanupTableInfo(cleanupTables = OPEN_FILE_TABLE)", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499603003", "createdAt": "2020-10-05T13:35:20Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDM3MQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910371", "createdAt": "2020-10-07T10:37:59Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/file/OMFileCreateResponseV1.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.file;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Response for create file request layout version1.\n+ */\n+public class OMFileCreateResponseV1 extends OMFileCreateResponse {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwMzAwMw=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODE2MjE0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzo0NDozOVrOHcdvOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozODowNVrOHdtJWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwOTQwMw==", "bodyText": "Wrong log instance name used.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499609403", "createdAt": "2020-10-05T13:44:39Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDQyNA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910424", "createdAt": "2020-10-07T10:38:05Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYwOTQwMw=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODE3ODYzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzo0ODoyNlrOHcd5hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozODoxNFrOHdtJuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjAzOQ==", "bodyText": "Remove this unused line.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499612039", "createdAt": "2020-10-05T13:48:26Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmKeyInfo>> keysItr =\n+            omMgr.getOpenKeyTable().iterator();\n+    keysItr.seekToFirst();\n+\n+    // Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDUyMA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910520", "createdAt": "2020-10-07T10:38:14Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmKeyInfo>> keysItr =\n+            omMgr.getOpenKeyTable().iterator();\n+    keysItr.seekToFirst();\n+\n+    // Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjAzOQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODE4MTEyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzo0ODo1OVrOHcd7Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozODoxOVrOHdtJ5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjQzOQ==", "bodyText": "The comment should be 'verify entries in open key table'", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499612439", "createdAt": "2020-10-05T13:48:59Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDU2NQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910565", "createdAt": "2020-10-07T10:38:19Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileOps.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.\u2002\u2002See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.\u2002\u2002The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ *  with the License.\u2002\u2002You may obtain a copy of the License at\n+ *\n+ * \u2002\u2002\u2002\u2002 http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.ozone;\n+\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.fs.CommonConfigurationKeysPublic;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.TestDataUtil;\n+import org.apache.hadoop.ozone.client.OzoneBucket;\n+import org.apache.hadoop.ozone.om.OMConfigKeys;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.util.StringUtils;\n+import org.junit.*;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.concurrent.TimeoutException;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_FS_ITERATE_BATCH_SIZE;\n+\n+/**\n+ * Test verifies the entries and operations in file table, open file table etc.\n+ */\n+public class TestOzoneFileOps {\n+\n+  @Rule\n+  public Timeout timeout = new Timeout(300000);\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(TestOzoneDirectory.class);\n+\n+  private MiniOzoneCluster cluster;\n+  private FileSystem fs;\n+  private String volumeName;\n+  private String bucketName;\n+\n+  @Before\n+  public void setupOzoneFileSystem()\n+          throws IOException, TimeoutException, InterruptedException {\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(FS_TRASH_INTERVAL_KEY, 1);\n+    conf.set(OMConfigKeys.OZONE_OM_LAYOUT_VERSION, \"V1\");\n+    conf.setBoolean(OMConfigKeys.OZONE_OM_ENABLE_FILESYSTEM_PATHS, true);\n+    cluster = MiniOzoneCluster.newBuilder(conf)\n+            .setNumDatanodes(3)\n+            .build();\n+    cluster.waitForClusterToBeReady();\n+    // create a volume and a bucket to be used by OzoneFileSystem\n+    OzoneBucket bucket = TestDataUtil.createVolumeAndBucket(cluster);\n+    volumeName = bucket.getVolumeName();\n+    bucketName = bucket.getName();\n+\n+    String rootPath = String.format(\"%s://%s.%s/\",\n+            OzoneConsts.OZONE_URI_SCHEME, bucket.getName(),\n+            bucket.getVolumeName());\n+\n+    // Set the fs.defaultFS and start the filesystem\n+    conf.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, rootPath);\n+    // Set the number of keys to be processed during batch operate.\n+    conf.setInt(OZONE_FS_ITERATE_BATCH_SIZE, 5);\n+    fs = FileSystem.get(conf);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    IOUtils.closeQuietly(fs);\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 300_000)\n+  public void testCreateFile() throws Exception {\n+    // Op 1. create dir -> /d1/d2/d3/d4/\n+    Path parent = new Path(\"/d1/d2/\");\n+    Path file = new Path(parent, \"file1\");\n+    fs.create(file);\n+    ArrayList<String> openFileKeys = new ArrayList<>();\n+\n+    OMMetadataManager omMgr = cluster.getOzoneManager().getMetadataManager();\n+    OmBucketInfo omBucketInfo = omMgr.getBucketTable().get(\n+            omMgr.getBucketKey(volumeName, bucketName));\n+    Assert.assertNotNull(\"Failed to find bucketInfo\", omBucketInfo);\n+\n+    ArrayList<String> dirKeys = new ArrayList<>();\n+    long d1ObjectID = verifyDirKey(omBucketInfo.getObjectID(), \"d1\", \"/d1\",\n+            dirKeys, omMgr);\n+    long d2ObjectID = verifyDirKey(d1ObjectID, \"d2\", \"/d1/d2\", dirKeys,\n+            omMgr);\n+    openFileKeys.add(d2ObjectID + OzoneConsts.OM_KEY_PREFIX + file.getName());\n+\n+    // verify entries in directory table\n+    TableIterator<String, ? extends\n+            Table.KeyValue<String, OmDirectoryInfo>> iterator =\n+            omMgr.getDirectoryTable().iterator();\n+    iterator.seekToFirst();\n+    int count = dirKeys.size();\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 2, count);\n+    while (iterator.hasNext()) {\n+      count--;\n+      Table.KeyValue<String, OmDirectoryInfo> value = iterator.next();\n+      verifyKeyFormat(value.getKey(), dirKeys);\n+    }\n+    Assert.assertEquals(\"Unexpected directory table entries!\", 0, count);\n+\n+    // verify entries in directory table", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYxMjQzOQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODI2NDAzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNDowNzoxNFrOHcetcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozODo1N1rOHdtLPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyNTMyOQ==", "bodyText": "Suppose here logic is same with TestOMFileCreateRequest.\nCan we fully reused the existed unit tests in TestOMFileCreateRequest?\nMaybe that we can extend TestOMFileCreateRequest and override ozone configuration we set for V1 version .", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499625329", "createdAt": "2020-10-05T14:07:14Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.request.key.TestOMKeyRequestV1;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CreateFileRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.StringUtils;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.VOLUME_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.BUCKET_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.FILE_ALREADY_EXISTS;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.DIRECTORY_NOT_FOUND;\n+\n+/**\n+ * Tests OMFileCreateRequest V1 layout version.\n+ */\n+public class TestOMFileCreateRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDkxMA==", "bodyText": "Great idea. Done in the latest commit.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910910", "createdAt": "2020-10-07T10:38:57Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.request.key.TestOMKeyRequestV1;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CreateFileRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.StringUtils;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.VOLUME_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.BUCKET_NOT_FOUND;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.FILE_ALREADY_EXISTS;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Status.DIRECTORY_NOT_FOUND;\n+\n+/**\n+ * Tests OMFileCreateRequest V1 layout version.\n+ */\n+public class TestOMFileCreateRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyNTMyOQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyODI4MTAwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxNDoxMTowMVrOHce36w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozOTowNVrOHdtLfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyODAxMQ==", "bodyText": "Similar comment above. Can we try to reuse the common logics here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499628011", "createdAt": "2020-10-05T14:11:01Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Class tests OMKeyCommitRequestV1 class.\n+ */\n+public class TestOMKeyCommitRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMDk3NQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500910975", "createdAt": "2020-10-07T10:39:05Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.ozone.OzoneConsts;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.request.TestOMRequestUtils;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.util.Time;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Class tests OMKeyCommitRequestV1 class.\n+ */\n+public class TestOMKeyCommitRequestV1 extends TestOMKeyRequestV1 {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyODAxMQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDQ5MjY1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMjo0ODowN1rOHc0IUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozOTo0MFrOHdtMwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjI3Mg==", "bodyText": "Can we also add a getPath method like that in OmDirectoryInfo? This can be conveniently used in other places.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499976272", "createdAt": "2020-10-06T02:48:07Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -126,6 +144,23 @@ public void setDataSize(long size) {\n     this.dataSize = size;\n   }\n \n+  public void setFileName(String fileName) {\n+    this.fileName = fileName;\n+  }\n+\n+  public String getFileName() {\n+    return fileName;\n+  }\n+\n+  public void setParentObjectID(long parentObjectID) {\n+    this.parentObjectID = parentObjectID;\n+  }\n+\n+  public long getParentObjectID() {\n+    return parentObjectID;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMTI5Nw==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500911297", "createdAt": "2020-10-07T10:39:40Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/helpers/OmKeyInfo.java", "diffHunk": "@@ -126,6 +144,23 @@ public void setDataSize(long size) {\n     this.dataSize = size;\n   }\n \n+  public void setFileName(String fileName) {\n+    this.fileName = fileName;\n+  }\n+\n+  public String getFileName() {\n+    return fileName;\n+  }\n+\n+  public void setParentObjectID(long parentObjectID) {\n+    this.parentObjectID = parentObjectID;\n+  }\n+\n+  public long getParentObjectID() {\n+    return parentObjectID;\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3NjI3Mg=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDUxNDc5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQwMzowMjozMFrOHc0V5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDozOTo1OFrOHdtNdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3OTc1MQ==", "bodyText": "We should additionally increase dir created metric since we created missing parent dirs.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r499979751", "createdAt": "2020-10-06T03:02:30Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMTQ3OQ==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500911479", "createdAt": "2020-10-07T10:39:58Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos = OMDirectoryCreateRequestV1.getAllParentDirInfo(\n+              ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTk3OTc1MQ=="}, "originalCommit": {"oid": "c3ed678081f61b757c6f4181c16ad3fd45b3bb44"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDcxODYxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMjo1Nzo0OVrOHdcx6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNzo1Nzo0NFrOHd_HcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjI4Mg==", "bodyText": "Why do we need to refresh here?\nBecause if override key, we add new blocks as the latest version, and use the latest blocks only.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500642282", "createdAt": "2020-10-06T22:57:49Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxMzcxNQ==", "bodyText": "It makes sense to skip this refresh. FYI, I've followed existing code path. Reference:", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500913715", "createdAt": "2020-10-07T10:44:12Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjI4Mg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTA0MzIwMg==", "bodyText": "Yes, checked that but we are writing new requests, if we can make it better that would be nice.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501043202", "createdAt": "2020-10-07T14:08:55Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjI4Mg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIwNDg0OA==", "bodyText": "OK, got it. I will remove it in the next commit.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501204848", "createdAt": "2020-10-07T17:57:44Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjI4Mg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDcyMDU5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMjo1ODo0NFrOHdczFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQyMjozNzozOFrOHfaL8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjU4Mw==", "bodyText": "Can we skip quota implementation, as it is incorrect. (I am fine with leaving if it needs rework, we can open another Jira to fix the issue for new classes also)\nFor more info refer this\nhttps://issues.apache.org/jira/browse/HDDS-4308", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500642583", "createdAt": "2020-10-06T22:58:44Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIwNzkwMA==", "bodyText": "I've raised HDDS-4321 jira to track the changes and update to the branch.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501207900", "createdAt": "2020-10-07T18:02:51Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjU4Mw=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5Njk0Nw==", "bodyText": "Thanks.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502696947", "createdAt": "2020-10-09T22:37:38Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0MjU4Mw=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDc2MzcyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "isResolved": true, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMzoyMDoxNVrOHddM8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNjo0NDoxNlrOHfdvEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg==", "bodyText": "For file create requests even enableFSPaths is disabled still should create entries in openfileTable only right?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500649202", "createdAt": "2020-10-06T23:20:15Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxNDc1MA==", "bodyText": "The idea here is, will use the tables only if enableFSPaths is true and with V1 version.\nThis new tables will contain only the metadata in new format keys <id/fileName> for better debugging/maintenance.  All the keys with old format will go to existing tables itself.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500914750", "createdAt": "2020-10-07T10:46:02Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjM1MDU5NA==", "bodyText": "Good catch @bharatviswa504. Please feel free to add if anything else needed. Thanks again!\nBased on our offline discussions, below is the expected behavior for diff requests:\nV1 feature version : Following ops shouldn't depend on enableFSPaths flag\n\nFileCreate  -----> Look into dirTable for parents. Then create entries in openFileTable and on close add it to fileTable.\nDirCreate  -----> Create entries in dirTable\nFile/DirDelete -> Look into fileTable and dirTable for the keys.\nFile/DirRename-> Look into fileTable and dirTable for the keys.\n\nV1 feature version & enableFSPaths=true\n\nKeyCreate ---> Look into dirTable for parents. Create entries in openFileTable and on close add it to fileTable.\nKeyDelete ---> Look into fileTable and dirTable for the keys.\nKeyRename -> supported only in ozone shell. It should look into fileTable and dirTable for the keys.\n\nV1 feature version & enableFSPaths=false\n\nKeyCreate ---> Create entries in openFileTable and on close add it to fileTable, but the parentId is the bucketId and the key \"dir1/dir2/dir3/file1\" will be stored into fileTable like \"512/dir1/dir2/dir3/file1\". Assume bucketId is 512.\nKeyDelete ---> Look into fileTable for the keys.\nKeyRename -> supported only in ozone shell. It should look into fileTable for the keys.\n\nIn this PR, will handle only FileCreate request and not provided checks for enableFSPaths in KeyCommit. Will do this changes in latest commit.\nLater, I will raise subsequent jiras for handling KeyCreate/KeyCommit and other ops.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502350594", "createdAt": "2020-10-09T10:59:30Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjM5MzA5NQ==", "bodyText": "@rakeshadr , the V1 feature is a new key format and is not compatible with old format. enableFSPaths flag\nis not behaves as a switch of this feature here? If not, what is enableFSPaths used for? Maybe I am missing something, : ).", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502393095", "createdAt": "2020-10-09T12:29:55Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjUyNTE0OA==", "bodyText": "Thanks @linyiqun for the comment. It seems the above comment was not clear. I had done few corrections to the above comment.\nYes, V1 represents new key format.\nAdding background about  ozone.om.enable.filesystem.paths -> this is the config to enable/disable enableFSPaths feature. Basically here the idea is to provide s3/fs inter-op. Please refer jira https://issues.apache.org/jira/browse/HDDS-4097 for more details. If the flag is enabled, then the user given key will be normalized and stored in FS semantics format by OM and it will be 100% FS semantics. If it is false, the key won't be normalized and it will be 100% S3 semantics.\nFor example, user created a key \"/dir1/dir2/dir3/file1\" from S3 API. Now,  if the flag is enabled the key will be normalized and create intermediate directories for the file1.\nMore Details:-\nThe cases I mentioned above - V1 feature version & enableFSPaths=true is 100% FS semantics and V1 feature version & enableFSPaths=false is 100% S3 semantics\nAssume the key is /dir1/dir2/dir3/file-1. Again assume V1 feature version enabled and bucketId is 512.\nNow,\nenableFSPaths=true, which is 100% FS semantics.\nIt stores as \"512/dir1:1025\", \"1025/dir2:1026\" and \"1026/dir3:1027\" into dirTable and \"1027:file1\" into openFiletable and on close move it to fileTable\nenableFSPaths=false, which is 100% S3 semantics.\nIt stores as \"512/dir1/dir2/dir3/file1:1025\" into openFileTable and on close move it to fileTable. Here still maintains the parentID/Key format, but the key will be the fullpath and not a normalized path. Here the key can be anything like /dir1////dir2////dir3///file1.\nPlease let me know if any more details needed.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502525148", "createdAt": "2020-10-09T15:54:44Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU0NjA4OA==", "bodyText": "Just to add one more point here\nthis is FS API, so the usage of the flag is of no effect, as this is FS API (File create) not an Object Store API.\nBut KeyCommitRequest is common for both FS/Object Store we need special handling over there.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502546088", "createdAt": "2020-10-09T16:32:52Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2NTk5Mw==", "bodyText": "Sure, I will add special handling in KeyCommit code while implementing KeyCreate request. Hope that make sense to you.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502565993", "createdAt": "2020-10-09T17:11:08Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5NzE1OA==", "bodyText": "Fine with me.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502697158", "createdAt": "2020-10-09T22:37:58Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1NTA5MQ==", "bodyText": "Get it, Thanks @rakeshadr and @bharatviswa504 for the very clear explanation!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502755091", "createdAt": "2020-10-10T06:44:16Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -227,6 +247,9 @@ protected OmMetadataManagerImpl() {\n \n   @Override\n   public Table<String, OmKeyInfo> getOpenKeyTable() {\n+    if (enableFSPaths && OzoneManagerRatisUtils.isOmLayoutVersionV1()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY0OTIwMg=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDc4NDc5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "isResolved": false, "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNlQyMzozMTozMlrOHddZyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMjoxODoxMVrOHgTC2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA==", "bodyText": "Looks like in new version we don't need to store full keyName in OmKeyInfo, but we still store it, as OMKeyInfoCodec has still set Keyname and convert to proto.\n\n public KeyInfo getProtobuf(boolean ignorePipeline) {\n    long latestVersion = keyLocationVersions.size() == 0 ? -1 :\n        keyLocationVersions.get(keyLocationVersions.size() - 1).getVersion();\n\n    List<KeyLocationList> keyLocations = new ArrayList<>();\n    for (OmKeyLocationInfoGroup locationInfoGroup : keyLocationVersions) {\n      keyLocations.add(locationInfoGroup.getProtobuf(ignorePipeline));\n    }\n\n    KeyInfo.Builder kb = KeyInfo.newBuilder()\n        .setVolumeName(volumeName)\n        .setBucketName(bucketName)\n        .setKeyName(keyName)", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500652488", "createdAt": "2020-10-06T23:31:32Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MzAzMQ==", "bodyText": "Why can't we use keyName as leaf node name for new requests, so that we don't need to store full pathName for OmKeyInfo for new request processing.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500653031", "createdAt": "2020-10-06T23:33:15Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxOTMzNA==", "bodyText": "OMKeyInfo is exposed to Ozone client, so I have kept 'keyName' as it is. Anyway fileName can be extracted from the  keyName so that I thought of reducing the load on DB.\nHope this make sense to you.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500919334", "createdAt": "2020-10-07T10:54:40Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTA0MTc2Mw==", "bodyText": "But now OmKeyInfo has entire keyPath which is not really needed to be persisted to DB in this new V1 Request.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501041763", "createdAt": "2020-10-07T14:07:04Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIxNTY1OA==", "bodyText": "I completely agree with you that, V1 need only the fileName in DB.\nOn a second thought, do we need to maintain two different OMKeyInfo#keyName semantics in DB. For 100% S3 , 'keyName' stores full path. For 100% FS, 'keyName' stores only the fileName in the value part.\nmessage keyInfo {\n       ....\n       required string keyName = 3;", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501215658", "createdAt": "2020-10-07T18:16:12Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQxNDg3OA==", "bodyText": "Yes. Because if we store the entire keyPath in DB when rename, then if we change the only parentObjectID and then leave keyName then they will diverge.\nAnd also this is FS API not called from S3.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501414878", "createdAt": "2020-10-08T02:38:40Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQzNjU4NQ==", "bodyText": "Fully agreed with you, thanks for pointing out the rename case.\nHow about store fileName in the keyName field in DB. Then, while populating OmKeyInfo logically will prepare fullPath in keyName and will store fileName separately.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501436585", "createdAt": "2020-10-08T04:07:59Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQ0MzM5Nw==", "bodyText": "Yes, you read my mind :)\nIt works perfectly.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501443397", "createdAt": "2020-10-08T04:37:11Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY0NTg5MA==", "bodyText": "Done the changes in new commit", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501645890", "createdAt": "2020-10-08T11:27:12Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5OTgxMQ==", "bodyText": "Added to the cache correctly(With KeyName as leaf node name), but in response class, we passed omKeyInfo this should be also the same thing which we have added to the cache right?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502699811", "createdAt": "2020-10-09T22:41:55Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjczNDUzMw==", "bodyText": "Inside OMFileCreateResponseV1#addToDBBatch() method has the actual call to the DB, it is doing the changes in utility OMFileRequest function. I have done this way to ensure that, only when updating the TableCache and persisting to the Table it makes the DB representation as keyName=leafNodeName. All the other places(any functional checks inside OM, logging inside OM, client response etc..) will have the keyName=fullPath and fileName=leafNodeName.\nOMFileRequest.addToOpenFileTable(omMetadataMgr, batchOp, getOmKeyInfo(),\n         getOpenKeySessionID());\n\nAlso, for better code maintenance, I will be adding these conversion in OMFileRequest utility functions. Hope this is fine for you?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502734533", "createdAt": "2020-10-10T02:25:09Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQ5Njg4Mg==", "bodyText": "With the current approach in PR looks like we do unnecessarily one more time copy object. What we add to the cache, if we pass the same instance to Response class then same can be persisted (Even for this, we can follow current model, same instance is in cache and Response classes, and get always return copy object). With this way cache and Response classes uses the same instance, and anyway in logging in createRequest we use Keyname, I see no issue over there.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r503496882", "createdAt": "2020-10-12T19:43:52Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYyODUwNg==", "bodyText": "Sure, updated patch by addressing this point. Thanks!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r503628506", "createdAt": "2020-10-13T02:18:11Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileCreateRequestV1.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.file;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponse;\n+import org.apache.hadoop.ozone.om.response.file.OMFileCreateResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+import static org.apache.hadoop.ozone.om.request.file.OMFileRequest.OMDirectoryResult.*;\n+\n+/**\n+ * Handles create file request layout version1.\n+ */\n+public class OMFileCreateRequestV1 extends OMFileCreateRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMFileCreateRequestV1.class);\n+  public OMFileCreateRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CreateFileRequest createFileRequest = getOmRequest().getCreateFileRequest();\n+    KeyArgs keyArgs = createFileRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    // if isRecursive is true, file would be created even if parent\n+    // directories does not exist.\n+    boolean isRecursive = createFileRequest.getIsRecursive();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"File create for : \" + volumeName + \"/\" + bucketName + \"/\"\n+          + keyName + \":\" + isRecursive);\n+    }\n+\n+    // if isOverWrite is true, file would be over written.\n+    boolean isOverWrite = createFileRequest.getIsOverwrite();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumCreateFile();\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    boolean acquiredLock = false;\n+\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    final List<OmKeyLocationInfo> locations = new ArrayList<>();\n+    List<OmDirectoryInfo> missingParentInfos;\n+    int numKeysCreated = 0;\n+\n+    OMClientResponse omClientResponse = null;\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    IOException exception = null;\n+    Result result = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      if (keyName.length() == 0) {\n+        // Check if this is the root of the filesystem.\n+        throw new OMException(\"Can not write to directory: \" + keyName,\n+                OMException.ResultCodes.NOT_A_FILE);\n+      }\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.CREATE, OzoneObj.ResourceType.KEY);\n+\n+      // acquire lock\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OmKeyInfo dbFileInfo = null;\n+\n+      OMFileRequest.OMPathInfoV1 pathInfoV1 =\n+              OMFileRequest.verifyDirectoryKeysInPath(omMetadataManager,\n+                      volumeName, bucketName, keyName, Paths.get(keyName));\n+\n+      if (pathInfoV1.getDirectoryResult()\n+              == OMFileRequest.OMDirectoryResult.FILE_EXISTS) {\n+        String dbFileKey = omMetadataManager.getOzonePathKey(\n+                pathInfoV1.getLastKnownParentId(),\n+                pathInfoV1.getLeafNodeName());\n+        dbFileInfo = omMetadataManager.getKeyTable().get(dbFileKey);\n+        if (dbFileInfo != null) {\n+          ozoneManager.getKeyManager().refresh(dbFileInfo);\n+        }\n+      }\n+\n+      // check if the file or directory already existed in OM\n+      checkPathAlreadyExists(keyName, isOverWrite, pathInfoV1);\n+\n+      if (!isRecursive) {\n+        checkAllParentsExist(ozoneManager, keyArgs, pathInfoV1);\n+      }\n+\n+      // add all missing parents to dir table\n+      missingParentInfos =\n+              OMDirectoryCreateRequestV1.getAllMissingParentDirInfo(\n+                      ozoneManager, keyArgs, pathInfoV1, trxnLogIndex);\n+\n+      // total number of keys created.\n+      numKeysCreated = missingParentInfos.size();\n+\n+      // do open key\n+      OmBucketInfo bucketInfo = omMetadataManager.getBucketTable().get(\n+          omMetadataManager.getBucketKey(volumeName, bucketName));\n+\n+      OmKeyInfo omFileInfo = prepareFileInfo(omMetadataManager, keyArgs,\n+              dbFileInfo, keyArgs.getDataSize(), locations,\n+              getFileEncryptionInfo(keyArgs), ozoneManager.getPrefixManager(),\n+              bucketInfo, pathInfoV1, trxnLogIndex,\n+              ozoneManager.isRatisEnabled());\n+\n+      long openVersion = omFileInfo.getLatestVersionLocations().getVersion();\n+      long clientID = createFileRequest.getClientID();\n+      String dbOpenFileName = omMetadataManager.getOpenFileName(\n+              pathInfoV1.getLastKnownParentId(), pathInfoV1.getLeafNodeName(),\n+              clientID);\n+\n+      // Append new blocks\n+      List<OmKeyLocationInfo> newLocationList = keyArgs.getKeyLocationsList()\n+          .stream().map(OmKeyLocationInfo::getFromProtobuf)\n+          .collect(Collectors.toList());\n+      omFileInfo.appendNewBlocks(newLocationList, false);\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+      // check volume quota\n+      long preAllocatedSpace = newLocationList.size()\n+          * ozoneManager.getScmBlockSize()\n+          * omFileInfo.getFactor().getNumber();\n+      checkVolumeQuotaInBytes(omVolumeArgs, preAllocatedSpace);\n+\n+      // Add to cache entry can be done outside of lock for this openKey.\n+      // Even if bucket gets deleted, when commitKey we shall identify if\n+      // bucket gets deleted.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+          new CacheKey<>(dbOpenFileName),\n+          new CacheValue<>(Optional.of(omFileInfo), trxnLogIndex));\n+\n+      // Add cache entries for the prefix directories.\n+      // Skip adding for the file key itself, until Key Commit.\n+      OMFileRequest.addDirectoryTableCacheEntries(omMetadataManager,\n+              Optional.absent(), Optional.of(missingParentInfos),\n+              trxnLogIndex);\n+\n+      // update usedBytes atomically.\n+      omVolumeArgs.getUsedBytes().add(preAllocatedSpace);\n+      omBucketInfo.getUsedBytes().add(preAllocatedSpace);\n+\n+      // Prepare response\n+      omResponse.setCreateFileResponse(CreateFileResponse.newBuilder()\n+          .setKeyInfo(omFileInfo.getProtobuf())\n+          .setID(clientID)\n+          .setOpenVersion(openVersion).build())\n+          .setCmdType(Type.CreateFile);\n+      omClientResponse = new OMFileCreateResponseV1(omResponse.build(),\n+          omFileInfo, missingParentInfos, clientID, omVolumeArgs, omBucketInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY1MjQ4OA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 211}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDkzMjEwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0NjoyMlrOHdevTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNDowNTozN1rOHd1GJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDM4MQ==", "bodyText": "checkDirectoryAlreadyExists check is missing which is added by HDDS-4155", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500674381", "createdAt": "2020-10-07T00:46:22Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxOTYwMA==", "bodyText": "Thanks for pointing out this. Good point. Done in latest commit.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500919600", "createdAt": "2020-10-07T10:55:10Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDM4MQ=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk3NjI1Nw==", "bodyText": "checkDirectoryAlreadyExists check is specific for enabling OzoneFileSystem, do we really need to apply this here?", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500976257", "createdAt": "2020-10-07T12:36:44Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDM4MQ=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTA0MDY3OQ==", "bodyText": "Yes, KeycommitRequest is common for KeyCreate/FileCreate", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501040679", "createdAt": "2020-10-07T14:05:37Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDM4MQ=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 131}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDkzNTcyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo0ODo0MVrOHdexew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NToyNFrOHdttvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDkzOQ==", "bodyText": "acquireLock -> acquireWriteLock. The old method is deprecated.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500674939", "createdAt": "2020-10-07T00:48:41Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxOTc0MQ==", "bodyText": "Good one. Done in latest commit", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500919741", "createdAt": "2020-10-07T10:55:24Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NDkzOQ=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDk0NDIzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1MzozOVrOHde2aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NTozMFrOHdtt9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjIwMA==", "bodyText": "Can we move this to a common method, and call the new method from both old version and this new version.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500676200", "createdAt": "2020-10-07T00:53:39Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxOTc5OQ==", "bodyText": "Sure.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500919799", "createdAt": "2020-10-07T10:55:30Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    switch (result) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjIwMA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDk0Njk1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1NTowNlrOHde35w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NTo0NFrOHdtuaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjU4Mw==", "bodyText": "OMKeyCommitResponse -> OMKeyCommitResponseV1", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500676583", "createdAt": "2020-10-07T00:55:06Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxOTkxNQ==", "bodyText": "Good catch. Done in latest commit", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500919915", "createdAt": "2020-10-07T10:55:44Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.*;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.*;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponse(omResponse.build(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NjU4Mw=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNDk1MTc2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwMDo1ODowMlrOHde6vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NTo1M1rOHdtuxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NzMxMQ==", "bodyText": "These 3 are set, not used anywhere.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500677311", "createdAt": "2020-10-07T00:58:02Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {\n+\n+  private OmKeyInfo omKeyInfo;\n+  private String ozoneKeyName;\n+  private String openKeyName;\n+\n+  public OMKeyCommitResponseV1(@Nonnull OMResponse omResponse,\n+                               @Nonnull OmKeyInfo omKeyInfo,\n+                               String ozoneKeyName, String openKeyName,\n+                               @Nonnull OmVolumeArgs omVolumeArgs,\n+                               @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, ozoneKeyName, openKeyName, omVolumeArgs,\n+            omBucketInfo);\n+    this.omKeyInfo = omKeyInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMDAwNg==", "bodyText": "Sure. Done!", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500920006", "createdAt": "2020-10-07T10:55:53Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyCommitResponseV1.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.*;\n+\n+/**\n+ * Response for CommitKey request layout version V1.\n+ */\n+@CleanupTableInfo(cleanupTables = {OPEN_FILE_TABLE, FILE_TABLE})\n+public class OMKeyCommitResponseV1 extends OMKeyCommitResponse {\n+\n+  private OmKeyInfo omKeyInfo;\n+  private String ozoneKeyName;\n+  private String openKeyName;\n+\n+  public OMKeyCommitResponseV1(@Nonnull OMResponse omResponse,\n+                               @Nonnull OmKeyInfo omKeyInfo,\n+                               String ozoneKeyName, String openKeyName,\n+                               @Nonnull OmVolumeArgs omVolumeArgs,\n+                               @Nonnull OmBucketInfo omBucketInfo) {\n+    super(omResponse, omKeyInfo, ozoneKeyName, openKeyName, omVolumeArgs,\n+            omBucketInfo);\n+    this.omKeyInfo = omKeyInfo;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDY3NzMxMQ=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNTY2NTg0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzowNjowM1rOHdlWdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NjowN1rOHdtvMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc4MjcwOA==", "bodyText": "openFileTable should have additional id after parentId/fileName and fileTable key should be parentId/fileName.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500782708", "createdAt": "2020-10-07T07:06:03Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,10 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName/id -> FileInfo                |\n+   * |----------------------------------------------------------------------|\n+   * |  openFileTable     | parentId/fileName -> FileInfo                   |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMDExMg==", "bodyText": "Thanks again. Done in latest commit", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500920112", "createdAt": "2020-10-07T10:56:07Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmMetadataManagerImpl.java", "diffHunk": "@@ -129,6 +132,10 @@\n    * |----------------------------------------------------------------------|\n    * |  directoryTable    | parentId/directoryName -> DirectoryInfo         |\n    * |----------------------------------------------------------------------|\n+   * |  fileTable         | parentId/fileName/id -> FileInfo                |\n+   * |----------------------------------------------------------------------|\n+   * |  openFileTable     | parentId/fileName -> FileInfo                   |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc4MjcwOA=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNTc0OTgyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QwNzozMTowNlrOHdmJHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMDo1NjoxNlrOHdtvfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NTY3Ng==", "bodyText": "assertNotNull check can be removed as we already check this in verifyPathInOpenKeyTable.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500795676", "createdAt": "2020-10-07T07:31:06Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequest.java", "diffHunk": "@@ -146,7 +141,7 @@ public void testValidateAndUpdateCache() throws Exception {\n \n     // Check open table whether key is added or not.\n \n-    omKeyInfo = omMetadataManager.getOpenKeyTable().get(openKey);\n+    omKeyInfo = verifyPathInOpenKeyTable(keyName, id, true);\n     Assert.assertNotNull(omKeyInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMDE4OQ==", "bodyText": "Done in latest commit", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500920189", "createdAt": "2020-10-07T10:56:16Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequest.java", "diffHunk": "@@ -146,7 +141,7 @@ public void testValidateAndUpdateCache() throws Exception {\n \n     // Check open table whether key is added or not.\n \n-    omKeyInfo = omMetadataManager.getOpenKeyTable().get(openKey);\n+    omKeyInfo = verifyPathInOpenKeyTable(keyName, id, true);\n     Assert.assertNotNull(omKeyInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NTY3Ng=="}, "originalCommit": {"oid": "75b3ba9bfb1846cc215a10385ff4d0d4c0c6166f"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNjkyNzIzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjo0NDowOFrOHdxdAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMzo0MjoyMVrOHdz9uQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk4MDk5Mw==", "bodyText": "Seems we forget to reuse processResult in OMKeyCommitRequest.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r500980993", "createdAt": "2020-10-07T12:44:08Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequest.java", "diffHunk": "@@ -253,4 +253,33 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     return omClientResponse;\n   }\n+\n+  protected void processResult(CommitKeyRequest commitKeyRequest,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64975e250744839bf58a002a53abef4f9034b671"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTAyMjEzNw==", "bodyText": "oops, thanks a lot @linyiqun  for the detailed code reviews. I have fixed this in my latest commit.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501022137", "createdAt": "2020-10-07T13:42:21Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequest.java", "diffHunk": "@@ -253,4 +253,33 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     return omClientResponse;\n   }\n+\n+  protected void processResult(CommitKeyRequest commitKeyRequest,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk4MDk5Mw=="}, "originalCommit": {"oid": "64975e250744839bf58a002a53abef4f9034b671"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTY5NjQ4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMjozOToyMFrOHeL8dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzoyNDoyMlrOHeeZPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQxNTAzMQ==", "bodyText": "protected boolean checkDirectoryAlreadyExists(String volumeName,\n      String bucketName, String keyName, OMMetadataManager omMetadataManager)\n      throws IOException {\n    if (omMetadataManager.getKeyTable().isExist(\n        omMetadataManager.getOzoneDirKey(volumeName, bucketName,\n            keyName))) {\n      return true;\n    }\n    return false;\n  }\nOriginal logic(OMKeyRequest#checkDirectoryAlreadyExists) is to check if there is the same name dir key already stored in key table.\nFor here,  the logic is that we should use new file key to check if that existed in file table, not check the dir table.\ncheckDirectoryAlreadyExists will always throw OMException error once OzoneFileSystem enabled under above logic, because parents dir is already created during File create request.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501415031", "createdAt": "2020-10-08T02:39:20Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request layout version V1.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager, ozoneManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponseV1(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    processResult(commitKeyRequest, volumeName, bucketName, keyName, omMetrics,\n+            exception, omKeyInfo, result);\n+\n+    return omClientResponse;\n+  }\n+\n+\n+  /**\n+   * Check for directory exists with same name, if it exists throw error.\n+   *\n+   * @param keyName                  key name\n+   * @param ozoneManager             Ozone Manager\n+   * @param reachedLastPathComponent true if the path component is a fileName\n+   * @throws IOException if directory exists with same name\n+   */\n+  private void checkDirectoryAlreadyExists(String keyName,\n+                                           OzoneManager ozoneManager,\n+                                           boolean reachedLastPathComponent)\n+          throws IOException {\n+    // Reached last component, which would be a file. Returns its parentID.\n+    if (reachedLastPathComponent && ozoneManager.getEnableFileSystemPaths()) {\n+      throw new OMException(\"Can not create file: \" + keyName +\n+              \" as there is already directory in the given path\", NOT_A_FILE);\n+    }\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                           String keyName, OMMetadataManager omMetadataManager,\n+                           OzoneManager ozoneManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+\n+    // If no sub-dirs then bucketID is the root/parent.\n+    if(!pathComponents.hasNext()){\n+      return bucketId;\n+    }\n+\n+    OmDirectoryInfo omDirectoryInfo;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      boolean reachedLastPathComponent = !pathComponents.hasNext();\n+      String dbNodeName =\n+              omMetadataManager.getOzonePathKey(lastKnownParentId, nodeName);\n+\n+      omDirectoryInfo = omMetadataManager.\n+              getDirectoryTable().get(dbNodeName);\n+      if (omDirectoryInfo != null) {\n+        checkDirectoryAlreadyExists(keyName, ozoneManager,\n+                reachedLastPathComponent);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQyMzc0NA==", "bodyText": "Thanks for the comment. I think the logic is fine, but will discuss for better clarity and happy to fix if we finds any gap.\nYes, the existing logic in OMKeyRequest#checkDirectoryAlreadyExists checks the directory existence for the given committing fileName.\nNew logic also does the directory existence check against DirTable for the given committing fileName. FileTable stores only the file information <parentID/fileName> and will not know about the DirInfo.\nFor example,  committing fileName is /dir1/dir2/dir3/file1.\nExisting Logic:\nstep-1) It will add trailing slash - /dir1/dir2/dir3/file1/ as the directory key entries represented by trailing slash.\nstep-2) Then check /dir1/dir2/dir3/file1/ in the KeyTable.\nNew Logic:\nstep-1) Traverse till the leaf node. I have used a flag boolean reachedLastPathComponent = !pathComponents.hasNext(); to mark that the traversal reached till end.\nstep-2) Once it reached the last path element, if it finds an OmDirectoryInfo from DirTable corresponding to the 'file1' then it throws OMException.\n\n    omDirectoryInfo = omMetadataManager.\n              getDirectoryTable().get(dbNodeName);\n      if (omDirectoryInfo != null) {\n        checkDirectoryAlreadyExists(keyName, ozoneManager,\n                reachedLastPathComponent);\n        lastKnownParentId = omDirectoryInfo.getObjectID();\n      }", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501423744", "createdAt": "2020-10-08T03:13:44Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request layout version V1.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager, ozoneManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponseV1(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    processResult(commitKeyRequest, volumeName, bucketName, keyName, omMetrics,\n+            exception, omKeyInfo, result);\n+\n+    return omClientResponse;\n+  }\n+\n+\n+  /**\n+   * Check for directory exists with same name, if it exists throw error.\n+   *\n+   * @param keyName                  key name\n+   * @param ozoneManager             Ozone Manager\n+   * @param reachedLastPathComponent true if the path component is a fileName\n+   * @throws IOException if directory exists with same name\n+   */\n+  private void checkDirectoryAlreadyExists(String keyName,\n+                                           OzoneManager ozoneManager,\n+                                           boolean reachedLastPathComponent)\n+          throws IOException {\n+    // Reached last component, which would be a file. Returns its parentID.\n+    if (reachedLastPathComponent && ozoneManager.getEnableFileSystemPaths()) {\n+      throw new OMException(\"Can not create file: \" + keyName +\n+              \" as there is already directory in the given path\", NOT_A_FILE);\n+    }\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                           String keyName, OMMetadataManager omMetadataManager,\n+                           OzoneManager ozoneManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+\n+    // If no sub-dirs then bucketID is the root/parent.\n+    if(!pathComponents.hasNext()){\n+      return bucketId;\n+    }\n+\n+    OmDirectoryInfo omDirectoryInfo;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      boolean reachedLastPathComponent = !pathComponents.hasNext();\n+      String dbNodeName =\n+              omMetadataManager.getOzonePathKey(lastKnownParentId, nodeName);\n+\n+      omDirectoryInfo = omMetadataManager.\n+              getDirectoryTable().get(dbNodeName);\n+      if (omDirectoryInfo != null) {\n+        checkDirectoryAlreadyExists(keyName, ozoneManager,\n+                reachedLastPathComponent);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQxNTAzMQ=="}, "originalCommit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTcxNzMwOQ==", "bodyText": "Thanks for the detailed explanation, I missed that fileName can also be passed during directory key entries check.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r501717309", "createdAt": "2020-10-08T13:24:22Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyCommitRequestV1.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmDirectoryInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyLocationInfo;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFSUtils;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyCommitResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.CommitKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyArgs;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.KeyLocation;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.NOT_A_FILE;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles CommitKey request layout version V1.\n+ */\n+public class OMKeyCommitRequestV1 extends OMKeyCommitRequest {\n+\n+  private static final Logger LOG =\n+          LoggerFactory.getLogger(OMKeyCommitRequestV1.class);\n+\n+  public OMKeyCommitRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+\n+    CommitKeyRequest commitKeyRequest = getOmRequest().getCommitKeyRequest();\n+\n+    KeyArgs commitKeyArgs = commitKeyRequest.getKeyArgs();\n+\n+    String volumeName = commitKeyArgs.getVolumeName();\n+    String bucketName = commitKeyArgs.getBucketName();\n+    String keyName = commitKeyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyCommits();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(commitKeyArgs);\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+            getOmRequest());\n+\n+    IOException exception = null;\n+    OmKeyInfo omKeyInfo = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    OMClientResponse omClientResponse = null;\n+    boolean bucketLockAcquired = false;\n+    Result result;\n+\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+\n+    try {\n+      commitKeyArgs = resolveBucketLink(ozoneManager, commitKeyArgs, auditMap);\n+      volumeName = commitKeyArgs.getVolumeName();\n+      bucketName = commitKeyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAclsInOpenKeyTable(ozoneManager, volumeName, bucketName,\n+              keyName, IAccessAuthorizer.ACLType.WRITE,\n+              commitKeyRequest.getClientID());\n+\n+\n+      String bucketKey = omMetadataManager.getBucketKey(volumeName, bucketName);\n+      Iterator<Path> pathComponents = Paths.get(keyName).iterator();\n+      String dbOpenFileKey = null;\n+\n+      List<OmKeyLocationInfo> locationInfoList = new ArrayList<>();\n+      for (KeyLocation keyLocation : commitKeyArgs.getKeyLocationsList()) {\n+        locationInfoList.add(OmKeyLocationInfo.getFromProtobuf(keyLocation));\n+      }\n+\n+      bucketLockAcquired =\n+              omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+                      volumeName, bucketName);\n+\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      String fileName = OzoneFSUtils.getFileName(keyName);\n+      omBucketInfo = omMetadataManager.getBucketTable().get(bucketKey);\n+      long bucketId = omBucketInfo.getObjectID();\n+      long parentID = getParentID(bucketId, pathComponents, keyName,\n+              omMetadataManager, ozoneManager);\n+      String dbFileKey = omMetadataManager.getOzonePathKey(parentID, fileName);\n+      dbOpenFileKey = omMetadataManager.getOpenFileName(parentID, fileName,\n+              commitKeyRequest.getClientID());\n+\n+      omKeyInfo = omMetadataManager.getOpenKeyTable().get(dbOpenFileKey);\n+      if (omKeyInfo == null) {\n+        throw new OMException(\"Failed to commit key, as \" + dbOpenFileKey +\n+                \"entry is not found in the OpenKey table\", KEY_NOT_FOUND);\n+      }\n+      omKeyInfo.setDataSize(commitKeyArgs.getDataSize());\n+\n+      omKeyInfo.setModificationTime(commitKeyArgs.getModificationTime());\n+\n+      // Update the block length for each block\n+      omKeyInfo.updateLocationInfoList(locationInfoList);\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      // Add to cache of open key table and key table.\n+      omMetadataManager.getOpenKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.absent(), trxnLogIndex));\n+\n+      omMetadataManager.getKeyTable().addCacheEntry(\n+              new CacheKey<>(dbFileKey),\n+              new CacheValue<>(Optional.of(omKeyInfo), trxnLogIndex));\n+\n+      long scmBlockSize = ozoneManager.getScmBlockSize();\n+      int factor = omKeyInfo.getFactor().getNumber();\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      // update usedBytes atomically.\n+      // Block was pre-requested and UsedBytes updated when createKey and\n+      // AllocatedBlock. The space occupied by the Key shall be based on\n+      // the actual Key size, and the total Block size applied before should\n+      // be subtracted.\n+      long correctedSpace = omKeyInfo.getDataSize() * factor -\n+              locationInfoList.size() * scmBlockSize * factor;\n+      omVolumeArgs.getUsedBytes().add(correctedSpace);\n+      omBucketInfo.getUsedBytes().add(correctedSpace);\n+\n+      omClientResponse = new OMKeyCommitResponseV1(omResponse.build(),\n+              omKeyInfo, dbFileKey, dbOpenFileKey, omVolumeArgs, omBucketInfo);\n+\n+      result = Result.SUCCESS;\n+    } catch (IOException ex) {\n+      result = Result.FAILURE;\n+      exception = ex;\n+      omClientResponse = new OMKeyCommitResponseV1(createErrorOMResponse(\n+              omResponse, exception));\n+    } finally {\n+      addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n+              omDoubleBufferHelper);\n+\n+      if(bucketLockAcquired) {\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n+                bucketName);\n+      }\n+    }\n+\n+    auditLog(auditLogger, buildAuditMessage(OMAction.COMMIT_KEY, auditMap,\n+            exception, getOmRequest().getUserInfo()));\n+\n+    processResult(commitKeyRequest, volumeName, bucketName, keyName, omMetrics,\n+            exception, omKeyInfo, result);\n+\n+    return omClientResponse;\n+  }\n+\n+\n+  /**\n+   * Check for directory exists with same name, if it exists throw error.\n+   *\n+   * @param keyName                  key name\n+   * @param ozoneManager             Ozone Manager\n+   * @param reachedLastPathComponent true if the path component is a fileName\n+   * @throws IOException if directory exists with same name\n+   */\n+  private void checkDirectoryAlreadyExists(String keyName,\n+                                           OzoneManager ozoneManager,\n+                                           boolean reachedLastPathComponent)\n+          throws IOException {\n+    // Reached last component, which would be a file. Returns its parentID.\n+    if (reachedLastPathComponent && ozoneManager.getEnableFileSystemPaths()) {\n+      throw new OMException(\"Can not create file: \" + keyName +\n+              \" as there is already directory in the given path\", NOT_A_FILE);\n+    }\n+  }\n+\n+  /**\n+   * Get parent id for the user given path.\n+   *\n+   * @param bucketId          bucket id\n+   * @param pathComponents    fie path elements\n+   * @param keyName           user given key name\n+   * @param omMetadataManager metadata manager\n+   * @return lastKnownParentID\n+   * @throws IOException DB failure or parent not exists in DirectoryTable\n+   */\n+  private long getParentID(long bucketId, Iterator<Path> pathComponents,\n+                           String keyName, OMMetadataManager omMetadataManager,\n+                           OzoneManager ozoneManager)\n+          throws IOException {\n+\n+    long lastKnownParentId = bucketId;\n+\n+    // If no sub-dirs then bucketID is the root/parent.\n+    if(!pathComponents.hasNext()){\n+      return bucketId;\n+    }\n+\n+    OmDirectoryInfo omDirectoryInfo;\n+    while (pathComponents.hasNext()) {\n+      String nodeName = pathComponents.next().toString();\n+      boolean reachedLastPathComponent = !pathComponents.hasNext();\n+      String dbNodeName =\n+              omMetadataManager.getOzonePathKey(lastKnownParentId, nodeName);\n+\n+      omDirectoryInfo = omMetadataManager.\n+              getDirectoryTable().get(dbNodeName);\n+      if (omDirectoryInfo != null) {\n+        checkDirectoryAlreadyExists(keyName, ozoneManager,\n+                reachedLastPathComponent);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQxNTAzMQ=="}, "originalCommit": {"oid": "3d7d11ae794666030920067ea7e7f32eb0ba968d"}, "originalPosition": 259}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0NzkyMDYxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQyMjoxNDo1OFrOHfZyMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwMjoyNjozOFrOHfcfVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5MDM1NQ==", "bodyText": "Looks for every key commit now we do 2 times copy once to get from the table and here.\nI understand the reason.\nNothing needs to be done here, just mentioning the difference between the original request and V1.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502690355", "createdAt": "2020-10-09T22:14:58Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -453,4 +456,145 @@ public static void addDirectoryTableCacheEntries(\n     }\n   }\n \n+  /**\n+   * Adding Key info to the openFile Table cache.\n+   *\n+   * @param omMetadataManager OM Metadata Manager\n+   * @param dbOpenFileName    open file name key\n+   * @param omFileInfo        key info\n+   * @param fileName          file name\n+   * @param trxnLogIndex      transaction log index\n+   */\n+  public static void addOpenFileTableCacheEntry(\n+          OMMetadataManager omMetadataManager, String dbOpenFileName,\n+          @Nullable OmKeyInfo omFileInfo, String fileName, long trxnLogIndex) {\n+\n+    Optional<OmKeyInfo> keyInfoOptional = Optional.absent();\n+    if (omFileInfo != null) {\n+      // New key format for the openFileTable.\n+      // For example, the user given key path is '/a/b/c/d/e/file1', then in DB\n+      // keyName field stores only the leaf node name, which is 'file1'.\n+      OmKeyInfo dbOmFileInfo = omFileInfo.copyObject();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjczNDY3Nw==", "bodyText": "OK:-)", "url": "https://github.com/apache/ozone/pull/1473#discussion_r502734677", "createdAt": "2020-10-10T02:26:38Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -453,4 +456,145 @@ public static void addDirectoryTableCacheEntries(\n     }\n   }\n \n+  /**\n+   * Adding Key info to the openFile Table cache.\n+   *\n+   * @param omMetadataManager OM Metadata Manager\n+   * @param dbOpenFileName    open file name key\n+   * @param omFileInfo        key info\n+   * @param fileName          file name\n+   * @param trxnLogIndex      transaction log index\n+   */\n+  public static void addOpenFileTableCacheEntry(\n+          OMMetadataManager omMetadataManager, String dbOpenFileName,\n+          @Nullable OmKeyInfo omFileInfo, String fileName, long trxnLogIndex) {\n+\n+    Optional<OmKeyInfo> keyInfoOptional = Optional.absent();\n+    if (omFileInfo != null) {\n+      // New key format for the openFileTable.\n+      // For example, the user given key path is '/a/b/c/d/e/file1', then in DB\n+      // keyName field stores only the leaf node name, which is 'file1'.\n+      OmKeyInfo dbOmFileInfo = omFileInfo.copyObject();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjY5MDM1NQ=="}, "originalCommit": {"oid": "a190b3de213d1665129ae2fc0f7c6907b7e9d325"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NzczMjA3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoxNzozM1rOHgxelA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoyODoyMFrOHgx3Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEyNzEyNA==", "bodyText": "Minor: There is no return from this method.\nCan be fixed in further jiras.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r504127124", "createdAt": "2020-10-13T17:17:33Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -466,27 +465,22 @@ public static void addDirectoryTableCacheEntries(\n    * @param trxnLogIndex      transaction log index\n    * @return dbOmFileInfo, which keeps leaf node name in keyName field", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzMzQ1OQ==", "bodyText": "Noted. Will take care in next PR.", "url": "https://github.com/apache/ozone/pull/1473#discussion_r504133459", "createdAt": "2020-10-13T17:28:20Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -466,27 +465,22 @@ public static void addDirectoryTableCacheEntries(\n    * @param trxnLogIndex      transaction log index\n    * @return dbOmFileInfo, which keeps leaf node name in keyName field", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEyNzEyNA=="}, "originalCommit": {"oid": "1f22f1d491381af3e9bc9ffa84a8218b9f06a5fb"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4756, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}