{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4NDYyMjMy", "number": 681, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzoyODozN1rODoFQVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNzozOToyMVrODob8EA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU1NzM0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodesCount.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzoyODozN1rOF2cFPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzoyODozN1rOF2cFPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNzUxNg==", "bodyText": "IMO this class is redundant. We can just capture the num datanodes (healthy and total) as 2 longs in the response.", "url": "https://github.com/apache/ozone/pull/681#discussion_r392627516", "createdAt": "2020-03-14T23:28:37Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodesCount.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+import javax.xml.bind.annotation.XmlAccessType;\n+import javax.xml.bind.annotation.XmlAccessorType;\n+import javax.xml.bind.annotation.XmlElement;\n+\n+/**\n+ * Metadata object that contains datanode counts based on its state.\n+ */\n+@XmlAccessorType(XmlAccessType.FIELD)\n+public class DatanodesCount {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU1NzczOnYy", "diffSide": "LEFT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzoyOTo1NFrOF2cFcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzoyOTo1NFrOF2cFcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNzU2OA==", "bodyText": "Why was this changed from using the constructor? Setting the class field directly is non standard.", "url": "https://github.com/apache/ozone/pull/681#discussion_r392627568", "createdAt": "2020-03-14T23:29:54Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "diffHunk": "@@ -167,9 +149,19 @@ public PipelineMetadata build() {\n       Preconditions.checkNotNull(datanodes);\n       Preconditions.checkNotNull(replicationType);\n \n-      return new PipelineMetadata(pipelineId, status, leaderNode, datanodes,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU2NTE1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo0OTozOFrOF2cJVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo0OTozOFrOF2cJVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODU2Ng==", "bodyText": "We can use SCMNodeManager#getNodeCount(NodeState)  to get the number of nodes in a specific state.", "url": "https://github.com/apache/ozone/pull/681#discussion_r392628566", "createdAt": "2020-03-14T23:49:38Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodesCount;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    AtomicInteger healthyDatanodes = new AtomicInteger();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    long volumes;\n+    long buckets;\n+    long keys;\n+    AtomicLong capacity = new AtomicLong(0L);\n+    AtomicLong used = new AtomicLong(0L);\n+    AtomicLong remaining = new AtomicLong(0L);\n+    datanodeDetails.forEach(datanode -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU2NTk1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1MToyNFrOF2cJtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1MToyNFrOF2cJtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODY2MQ==", "bodyText": "Nit. We can directly use builder.set(omm.getTable(). getEstimatedKeyCount()). We don't need local variables. (Same for keys, volumes, pipelines, containers etc)", "url": "https://github.com/apache/ozone/pull/681#discussion_r392628661", "createdAt": "2020-03-14T23:51:24Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodesCount;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    AtomicInteger healthyDatanodes = new AtomicInteger();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    long volumes;\n+    long buckets;\n+    long keys;\n+    AtomicLong capacity = new AtomicLong(0L);\n+    AtomicLong used = new AtomicLong(0L);\n+    AtomicLong remaining = new AtomicLong(0L);\n+    datanodeDetails.forEach(datanode -> {\n+      NodeState nodeState = nodeManager.getNodeState(datanode);\n+      SCMNodeStat nodeStat = nodeManager.getNodeStat(datanode).get();\n+      if (nodeState.equals(NodeState.HEALTHY)) {\n+        healthyDatanodes.getAndIncrement();\n+      }\n+      capacity.getAndAdd(nodeStat.getCapacity().get());\n+      used.getAndAdd(nodeStat.getScmUsed().get());\n+      remaining.getAndAdd(nodeStat.getRemaining().get());\n+    });\n+    DatanodeStorageReport storageReport =\n+        new DatanodeStorageReport(capacity.get(), used.get(), remaining.get());\n+    DatanodesCount datanodesCount = new DatanodesCount(datanodeDetails.size(),\n+        healthyDatanodes.get());\n+    ClusterStateResponse.Builder builder = ClusterStateResponse.newBuilder();\n+    try {\n+      volumes = omMetadataManager.getVolumeTable().getEstimatedKeyCount();\n+      builder.setVolumes(volumes);\n+    } catch (Exception ex) {\n+      LOG.error(\"Unable to get Volumes count in ClusterStateResponse.\", ex);\n+    }\n+    try {\n+      buckets = omMetadataManager.getBucketTable().getEstimatedKeyCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU2NjI5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1Mjo0NFrOF2cJ7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1Mjo0NFrOF2cJ7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODcxOA==", "bodyText": "Why AtomicLong? Simple long may be enough.", "url": "https://github.com/apache/ozone/pull/681#discussion_r392628718", "createdAt": "2020-03-14T23:52:44Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodesCount;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    AtomicInteger healthyDatanodes = new AtomicInteger();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    long volumes;\n+    long buckets;\n+    long keys;\n+    AtomicLong capacity = new AtomicLong(0L);\n+    AtomicLong used = new AtomicLong(0L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzU2NzA4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1NTozMVrOF2cKZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQyMzo1NTozMVrOF2cKZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODgzNw==", "bodyText": "Can we use SCMNodeManager#getStats here? It is supposed to give the aggregate stats from all nodes.", "url": "https://github.com/apache/ozone/pull/681#discussion_r392628837", "createdAt": "2020-03-14T23:55:31Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodesCount;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    AtomicInteger healthyDatanodes = new AtomicInteger();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    long volumes;\n+    long buckets;\n+    long keys;\n+    AtomicLong capacity = new AtomicLong(0L);\n+    AtomicLong used = new AtomicLong(0L);\n+    AtomicLong remaining = new AtomicLong(0L);\n+    datanodeDetails.forEach(datanode -> {\n+      NodeState nodeState = nodeManager.getNodeState(datanode);\n+      SCMNodeStat nodeStat = nodeManager.getNodeStat(datanode).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "56a5eacd8641a0931348efae2ccee3fceea30c26"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzE5ODU4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNzoxODo1MFrOF2-R9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNzo1NDoxOFrOF2_j5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4NzgyOQ==", "bodyText": "Unused variable.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393187829", "createdAt": "2020-03-16T17:18:50Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    int healthyDatanodes = nodeManager.getNodeCount(NodeState.HEALTHY);\n+    SCMNodeStat stats = nodeManager.getStats();\n+    DatanodeStorageReport storageReport =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIwNTg1OA==", "bodyText": "storageReport is used in setStorageReport of ClusterStateResponse.Builder in L102.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393205858", "createdAt": "2020-03-16T17:49:15Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    int healthyDatanodes = nodeManager.getNodeCount(NodeState.HEALTHY);\n+    SCMNodeStat stats = nodeManager.getStats();\n+    DatanodeStorageReport storageReport =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4NzgyOQ=="}, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIwODgwNQ==", "bodyText": "Sorry, I referenced the wrong storageReport. There is an unused one in TestEndpoints#testGetClusterState.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393208805", "createdAt": "2020-03-16T17:54:18Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/ClusterStateEndpoint.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeState;\n+import org.apache.hadoop.hdds.scm.container.placement.metrics.SCMNodeStat;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.ClusterStateResponse;\n+import org.apache.hadoop.ozone.recon.api.types.DatanodeStorageReport;\n+import org.apache.hadoop.ozone.recon.recovery.ReconOMMetadataManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconContainerManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconNodeManager;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.util.List;\n+\n+/**\n+ * Endpoint to fetch current state of ozone cluster.\n+ */\n+@Path(\"/clusterState\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class ClusterStateEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(ClusterStateEndpoint.class);\n+\n+  private ReconNodeManager nodeManager;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+  private ReconOMMetadataManager omMetadataManager;\n+\n+  @Inject\n+  ClusterStateEndpoint(OzoneStorageContainerManager reconSCM,\n+                       ReconOMMetadataManager omMetadataManager) {\n+    this.nodeManager =\n+        (ReconNodeManager) reconSCM.getScmNodeManager();\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+    this.containerManager =\n+        (ReconContainerManager) reconSCM.getContainerManager();\n+    this.omMetadataManager = omMetadataManager;\n+  }\n+\n+  /**\n+   * Return a summary report on current cluster state.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getClusterState() {\n+    List<DatanodeDetails> datanodeDetails = nodeManager.getAllNodes();\n+    int containers = this.containerManager.getContainerIDs().size();\n+    int pipelines = this.pipelineManager.getPipelines().size();\n+    int healthyDatanodes = nodeManager.getNodeCount(NodeState.HEALTHY);\n+    SCMNodeStat stats = nodeManager.getStats();\n+    DatanodeStorageReport storageReport =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4NzgyOQ=="}, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzI3Mzc2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxNzozOToyMVrOF2_BJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo1MToyNlrOF3Boyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE5OTkwOQ==", "bodyText": "Line 440 - 454 has some some repetitive elements in all 3 tests. Only the condition is different. Maybe we can use a helper function to do this and remove duplicate code.\n private void waitAndCheckConditionAfterHeartbeat(Callable<Boolean> check) throws Exception { // if container report is processed first, and pipeline does not exist // then container is not added until the next container report is processed SCMHeartbeatRequestProto heartbeatRequestProto = SCMHeartbeatRequestProto.newBuilder() .setContainerReport(containerReportsProto) .setDatanodeDetails(datanodeDetailsProto) .build(); reconScm.getDatanodeProtocolServer() .sendHeartbeat(heartbeatRequestProto); LambdaTestUtils.await(30000, 2000, check); }\nIt can be invoked by\n    waitAndCheckConditionAfterHeartbeat(() -> { Response response1 = clusterStateEndpoint.getClusterState(); ClusterStateResponse clusterStateResponse1 = (ClusterStateResponse) response1.getEntity(); return (clusterStateResponse1.getContainers() == 1); });\nI am OK to do this in the next JIRA if needed.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393199909", "createdAt": "2020-03-16T17:39:21Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java", "diffHunk": "@@ -305,4 +419,39 @@ public void testGetPipelines() throws Exception {\n       return (pipelineMetadata1.getContainers() == 1);\n     });\n   }\n+\n+  @Test\n+  public void testGetClusterState() throws Exception {\n+    Response response = clusterStateEndpoint.getClusterState();\n+    ClusterStateResponse clusterStateResponse =\n+        (ClusterStateResponse) response.getEntity();\n+\n+    Assert.assertEquals(1, clusterStateResponse.getPipelines());\n+    Assert.assertEquals(2, clusterStateResponse.getVolumes());\n+    Assert.assertEquals(2, clusterStateResponse.getBuckets());\n+    Assert.assertEquals(3, clusterStateResponse.getKeys());\n+    Assert.assertEquals(2, clusterStateResponse.getTotalDatanodes());\n+    Assert.assertEquals(2, clusterStateResponse.getHealthyDatanodes());\n+\n+    DatanodeStorageReport storageReport =\n+        clusterStateResponse.getStorageReport();\n+\n+\n+    // if container report is processed first, and pipeline does not exist\n+    // then container is not added until the next container report is processed\n+    SCMHeartbeatRequestProto heartbeatRequestProto =\n+        SCMHeartbeatRequestProto.newBuilder()\n+            .setContainerReport(containerReportsProto)\n+            .setDatanodeDetails(datanodeDetailsProto)\n+            .build();\n+    reconScm.getDatanodeProtocolServer()\n+        .sendHeartbeat(heartbeatRequestProto);\n+\n+    LambdaTestUtils.await(30000, 2000, () -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIwNjUxNQ==", "bodyText": "Agreed. I can take care of this refactor in another JIRA.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393206515", "createdAt": "2020-03-16T17:50:25Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java", "diffHunk": "@@ -305,4 +419,39 @@ public void testGetPipelines() throws Exception {\n       return (pipelineMetadata1.getContainers() == 1);\n     });\n   }\n+\n+  @Test\n+  public void testGetClusterState() throws Exception {\n+    Response response = clusterStateEndpoint.getClusterState();\n+    ClusterStateResponse clusterStateResponse =\n+        (ClusterStateResponse) response.getEntity();\n+\n+    Assert.assertEquals(1, clusterStateResponse.getPipelines());\n+    Assert.assertEquals(2, clusterStateResponse.getVolumes());\n+    Assert.assertEquals(2, clusterStateResponse.getBuckets());\n+    Assert.assertEquals(3, clusterStateResponse.getKeys());\n+    Assert.assertEquals(2, clusterStateResponse.getTotalDatanodes());\n+    Assert.assertEquals(2, clusterStateResponse.getHealthyDatanodes());\n+\n+    DatanodeStorageReport storageReport =\n+        clusterStateResponse.getStorageReport();\n+\n+\n+    // if container report is processed first, and pipeline does not exist\n+    // then container is not added until the next container report is processed\n+    SCMHeartbeatRequestProto heartbeatRequestProto =\n+        SCMHeartbeatRequestProto.newBuilder()\n+            .setContainerReport(containerReportsProto)\n+            .setDatanodeDetails(datanodeDetailsProto)\n+            .build();\n+    reconScm.getDatanodeProtocolServer()\n+        .sendHeartbeat(heartbeatRequestProto);\n+\n+    LambdaTestUtils.await(30000, 2000, () -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE5OTkwOQ=="}, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIwODIyMQ==", "bodyText": "Thanks!", "url": "https://github.com/apache/ozone/pull/681#discussion_r393208221", "createdAt": "2020-03-16T17:53:17Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java", "diffHunk": "@@ -305,4 +419,39 @@ public void testGetPipelines() throws Exception {\n       return (pipelineMetadata1.getContainers() == 1);\n     });\n   }\n+\n+  @Test\n+  public void testGetClusterState() throws Exception {\n+    Response response = clusterStateEndpoint.getClusterState();\n+    ClusterStateResponse clusterStateResponse =\n+        (ClusterStateResponse) response.getEntity();\n+\n+    Assert.assertEquals(1, clusterStateResponse.getPipelines());\n+    Assert.assertEquals(2, clusterStateResponse.getVolumes());\n+    Assert.assertEquals(2, clusterStateResponse.getBuckets());\n+    Assert.assertEquals(3, clusterStateResponse.getKeys());\n+    Assert.assertEquals(2, clusterStateResponse.getTotalDatanodes());\n+    Assert.assertEquals(2, clusterStateResponse.getHealthyDatanodes());\n+\n+    DatanodeStorageReport storageReport =\n+        clusterStateResponse.getStorageReport();\n+\n+\n+    // if container report is processed first, and pipeline does not exist\n+    // then container is not added until the next container report is processed\n+    SCMHeartbeatRequestProto heartbeatRequestProto =\n+        SCMHeartbeatRequestProto.newBuilder()\n+            .setContainerReport(containerReportsProto)\n+            .setDatanodeDetails(datanodeDetailsProto)\n+            .build();\n+    reconScm.getDatanodeProtocolServer()\n+        .sendHeartbeat(heartbeatRequestProto);\n+\n+    LambdaTestUtils.await(30000, 2000, () -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE5OTkwOQ=="}, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MjgyNw==", "bodyText": "Refactored as per the suggestion in the latest commit.", "url": "https://github.com/apache/ozone/pull/681#discussion_r393242827", "createdAt": "2020-03-16T18:51:26Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java", "diffHunk": "@@ -305,4 +419,39 @@ public void testGetPipelines() throws Exception {\n       return (pipelineMetadata1.getContainers() == 1);\n     });\n   }\n+\n+  @Test\n+  public void testGetClusterState() throws Exception {\n+    Response response = clusterStateEndpoint.getClusterState();\n+    ClusterStateResponse clusterStateResponse =\n+        (ClusterStateResponse) response.getEntity();\n+\n+    Assert.assertEquals(1, clusterStateResponse.getPipelines());\n+    Assert.assertEquals(2, clusterStateResponse.getVolumes());\n+    Assert.assertEquals(2, clusterStateResponse.getBuckets());\n+    Assert.assertEquals(3, clusterStateResponse.getKeys());\n+    Assert.assertEquals(2, clusterStateResponse.getTotalDatanodes());\n+    Assert.assertEquals(2, clusterStateResponse.getHealthyDatanodes());\n+\n+    DatanodeStorageReport storageReport =\n+        clusterStateResponse.getStorageReport();\n+\n+\n+    // if container report is processed first, and pipeline does not exist\n+    // then container is not added until the next container report is processed\n+    SCMHeartbeatRequestProto heartbeatRequestProto =\n+        SCMHeartbeatRequestProto.newBuilder()\n+            .setContainerReport(containerReportsProto)\n+            .setDatanodeDetails(datanodeDetailsProto)\n+            .build();\n+    reconScm.getDatanodeProtocolServer()\n+        .sendHeartbeat(heartbeatRequestProto);\n+\n+    LambdaTestUtils.await(30000, 2000, () -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE5OTkwOQ=="}, "originalCommit": {"oid": "b3813218d0544b3d0af6a329ee5520f72728d2c7"}, "originalPosition": 459}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4835, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}