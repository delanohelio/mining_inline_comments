{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIyMTA0MjE5", "number": 959, "title": "HDDS-3186. Introduce generic SCMRatisRequest and SCMRatisResponse.", "bodyText": "What changes were proposed in this pull request?\nThis PR will introduce generic SCMRatisRequest and SCMRatisResponse which will be used by all the Ratis operations inside SCM. We also have a generic StateMachine which will dispatch the request to registered handlers.\nWhat is the link to the Apache JIRA\nHDDS-3186\nHow was this patch tested?\nThis patch is not tested properly.\nThe following jiras are created for adding unit tests to test the changes introduced in this PR\nHDDS-3650, HDDS-3651 and HDDS-3652", "createdAt": "2020-05-22T19:18:20Z", "url": "https://github.com/apache/ozone/pull/959", "merged": true, "mergeCommit": {"oid": "1ea9555d5e4426902995f7b9c5cd9fde167e3c1c"}, "closed": true, "closedAt": "2020-05-26T07:56:17Z", "author": {"login": "nandakumar131"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcj3QCwAH2gAyNDIyMTA0MjE5OmJhZTQ4YzIyZTg4OTc1ZmYwN2ExYWI0NDA4OGRjNWQyNjZhNTY5NWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABck7SRpgFqTQxNzkzNDkyNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b", "author": {"user": {"login": "nandakumar131", "name": "Nandakumar"}}, "url": "https://github.com/apache/ozone/commit/bae48c22e88975ff07a1ab44088dc5d266a5695b", "committedDate": "2020-05-22T19:15:44Z", "message": "HDDS-3186. Initial version."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3MTM5MjEy", "url": "https://github.com/apache/ozone/pull/959#pullrequestreview-417139212", "createdAt": "2020-05-22T19:19:44Z", "commit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3NTU0MjA1", "url": "https://github.com/apache/ozone/pull/959#pullrequestreview-417554205", "createdAt": "2020-05-25T08:41:13Z", "commit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwODo0MToxM1rOGZ5gIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwODo0MzozNlrOGZ5kyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ==", "bodyText": "can we put this into SCMHAUtils?", "url": "https://github.com/apache/ozone/pull/959#discussion_r429809699", "createdAt": "2020-05-25T08:41:13Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA==", "bodyText": "I've merged SCMRatisServer and SCMStateMachine into one between /ha and /ratis in timmylicheng#1. We can use /ha as your did here, but we need to combine all methods into one.", "url": "https://github.com/apache/ozone/pull/959#discussion_r429810890", "createdAt": "2020-05-25T08:43:36Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "author": {"user": {"login": "nandakumar131", "name": "Nandakumar"}}, "url": "https://github.com/apache/ozone/commit/ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "committedDate": "2020-05-25T18:24:57Z", "message": "HDDS-3186. Additional changes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE3OTM0OTI2", "url": "https://github.com/apache/ozone/pull/959#pullrequestreview-417934926", "createdAt": "2020-05-26T02:31:43Z", "commit": {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwMjozMTo0M1rOGaM3WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwMjozMTo0M1rOGaM3WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjkzNw==", "bodyText": "Do we need to addContainerToDB here?", "url": "https://github.com/apache/ozone/pull/959#discussion_r430126937", "createdAt": "2020-05-26T02:31:43Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ContainerManagerImpl.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.container;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ContainerInfoProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleEvent;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * TODO: Add javadoc.\n+ */\n+public class ContainerManagerImpl implements ContainerManagerV2 {\n+\n+  /**\n+   *\n+   */\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ContainerManagerImpl.class);\n+\n+  /**\n+   *\n+   */\n+  private final ReadWriteLock lock;\n+\n+  /**\n+   *\n+   */\n+  private final PipelineManager pipelineManager;\n+\n+  /**\n+   *\n+   */\n+  private final ContainerStateManagerV2 containerStateManager;\n+\n+  /**\n+   *\n+   */\n+  public ContainerManagerImpl(\n+      // Introduce builder for this class?\n+      final Configuration conf, final PipelineManager pipelineManager,\n+      final SCMHAManager scmhaManager,\n+      final Table<ContainerID, ContainerInfo> containerStore)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineManager = pipelineManager;\n+    this.containerStateManager =  ContainerStateManagerImpl.newBuilder()\n+        .setConfiguration(conf)\n+        .setPipelineManager(pipelineManager)\n+        .setRatisServer(scmhaManager.getRatisServer())\n+        .setContainerStore(containerStore)\n+        .build();\n+  }\n+\n+  @Override\n+  public Set<ContainerID> getContainerIDs() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs();\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs().stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo getContainer(final ContainerID containerID)\n+      throws ContainerNotFoundException {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainer(containerID);\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers(final LifeCycleState state) {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs(state).stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public boolean exists(final ContainerID containerID) {\n+    lock.readLock().lock();\n+    try {\n+      return (containerStateManager.getContainer(containerID) != null);\n+    } catch (ContainerNotFoundException ex) {\n+      return false;\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public List<ContainerInfo> listContainers(final ContainerID startID,\n+                                            final int count) {\n+    lock.readLock().lock();\n+    try {\n+      final long startId = startID == null ? 0 : startID.getId();\n+      final List<ContainerID> containersIds =\n+          new ArrayList<>(containerStateManager.getContainerIDs());\n+      Collections.sort(containersIds);\n+      return containersIds.stream()\n+          .filter(id -> id.getId() > startId)\n+          .limit(count)\n+          .map(id -> {\n+            try {\n+              return containerStateManager.getContainer(id);\n+            } catch (ContainerNotFoundException ex) {\n+              // This can never happen, as we hold lock no one else can remove\n+              // the container after we got the container ids.\n+              LOG.warn(\"Container Missing.\", ex);\n+              return null;\n+            }\n+          }).collect(Collectors.toList());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo allocateContainer(final ReplicationType type,\n+      final ReplicationFactor replicationFactor, final String owner)\n+      throws IOException {\n+    lock.writeLock().lock();\n+    try {\n+      final List<Pipeline> pipelines = pipelineManager\n+          .getPipelines(type, replicationFactor, Pipeline.PipelineState.OPEN);\n+\n+      if (pipelines.isEmpty()) {\n+        throw new IOException(\"Could not allocate container. Cannot get any\" +\n+            \" matching pipeline for Type:\" + type + \", Factor:\" +\n+            replicationFactor + \", State:PipelineState.OPEN\");\n+      }\n+\n+      final ContainerID containerID = containerStateManager\n+          .getNextContainerID();\n+      final Pipeline pipeline = pipelines.get(\n+          (int) containerID.getId() % pipelines.size());\n+\n+      final ContainerInfoProto containerInfo = ContainerInfoProto.newBuilder()\n+          .setState(LifeCycleState.OPEN)\n+          .setPipelineID(pipeline.getId().getProtobuf())\n+          .setUsedBytes(0)\n+          .setNumberOfKeys(0)\n+          .setStateEnterTime(Time.now())\n+          .setOwner(owner)\n+          .setContainerID(containerID.getId())\n+          .setDeleteTransactionId(0)\n+          .setReplicationFactor(pipeline.getFactor())\n+          .setReplicationType(pipeline.getType())\n+          .build();\n+      containerStateManager.addContainer(containerInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3"}, "originalPosition": 216}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3299, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}