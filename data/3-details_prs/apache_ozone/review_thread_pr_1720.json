{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxNDI3ODU3", "number": 1720, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNDowOFrOFH46Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjoyNTozOVrOFMAm_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODE2NzE1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/DataNodeStorageConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNDowOFrOIJhruQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOToyMTowMVrOIJjQlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg1OTk2MQ==", "bodyText": "The StorageInfo class generates a new \"clusterId\" for every Version file that it writes down. There is no clusterId with respect to DN now. Can we confirm the implications of adding a clusterId for the DN persistent state even when we need only the layout version?", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546859961", "createdAt": "2020-12-21T18:24:08Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/DataNodeStorageConfig.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.container.common;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.DATANODE_STORAGE_DIR;\n+import static org.apache.hadoop.ozone.OzoneConsts.DATANODE_UUID;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Properties;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeType;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.hadoop.ozone.common.Storage;\n+\n+/**\n+ * DataNodeStorageConfig is responsible for management of the\n+ * StorageDirectories used by the DataNode.\n+ */\n+public class DataNodeStorageConfig extends Storage {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4NTc4Mg==", "bodyText": "It will remain a \"don't care bit\". storage config is used only for layout information.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546885782", "createdAt": "2020-12-21T19:21:01Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/DataNodeStorageConfig.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.container.common;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.DATANODE_STORAGE_DIR;\n+import static org.apache.hadoop.ozone.OzoneConsts.DATANODE_UUID;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Properties;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.NodeType;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.hadoop.ozone.common.Storage;\n+\n+/**\n+ * DataNodeStorageConfig is responsible for management of the\n+ * StorageDirectories used by the DataNode.\n+ */\n+public class DataNodeStorageConfig extends Storage {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg1OTk2MQ=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODE3Mzc3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/Storage.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNjowN1rOIJhvbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxODowMToxMlrOIN7bAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDkwOA==", "bodyText": "Can we add a unit test for the Datanode layout version startup validation like in TestScmStartupSlvLessThanMlv, TestOmStartupSlvLessThanMlv?", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546860908", "createdAt": "2020-12-21T18:26:07Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/Storage.java", "diffHunk": "@@ -145,7 +145,7 @@ protected StorageInfo getStorageInfo() {\n   abstract protected Properties getNodeProperties();\n \n   /**\n-   * Sets the Node properties specific to OM/SCM.\n+   * Sets the Node properties specific to OM/SCM/DataNode.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ3NTk2OQ==", "bodyText": "yes", "url": "https://github.com/apache/ozone/pull/1720#discussion_r551475969", "createdAt": "2021-01-04T18:01:12Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/Storage.java", "diffHunk": "@@ -145,7 +145,7 @@ protected StorageInfo getStorageInfo() {\n   abstract protected Properties getNodeProperties();\n \n   /**\n-   * Sets the Node properties specific to OM/SCM.\n+   * Sets the Node properties specific to OM/SCM/DataNode.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDkwOA=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODE3NjMwOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/upgrade/BasicUpgradeFinalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyNjo1MlrOIJhw2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOToyMjowNFrOIJjSWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MTI3Mg==", "bodyText": "Can you please explain how this can happen, and how can a user recover from this?", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546861272", "createdAt": "2020-12-21T18:26:52Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/upgrade/BasicUpgradeFinalizer.java", "diffHunk": "@@ -71,6 +69,11 @@ public synchronized StatusAndMessages preFinalize(String upgradeClientID,\n       return FINALIZATION_IN_PROGRESS_MSG;\n     case FINALIZATION_DONE:\n     case ALREADY_FINALIZED:\n+      if (versionManager.needsFinalization()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4NjIzNA==", "bodyText": "it cant happen. just trying to catch if any future modification messes this up.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546886234", "createdAt": "2020-12-21T19:22:04Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/upgrade/BasicUpgradeFinalizer.java", "diffHunk": "@@ -71,6 +69,11 @@ public synchronized StatusAndMessages preFinalize(String upgradeClientID,\n       return FINALIZATION_IN_PROGRESS_MSG;\n     case FINALIZATION_DONE:\n     case ALREADY_FINALIZED:\n+      if (versionManager.needsFinalization()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MTI3Mg=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODE5MTg1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeFinalizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODozMjoxM1rOIJh6KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwNzoxNjo0NlrOIO0RcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MzY1Nw==", "bodyText": "We currently have a common layout feature hierarchy for SCM and Datanode. It is likely that a feature can either be part of the SCM or the DN. If we call on the onFinalize action in both the SCM and DN for every unfinalized HDDS layout feature, then we may be left with unintended consequences of trying to call on finalize action on an SCM feature on the DN. We should either have a marker on every layout feature to say if it belongs to SCM or DN, or not support finalization actions for DN for the V1 upgrade implementation.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546863657", "createdAt": "2020-12-21T18:32:13Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeFinalizer.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.container.upgrade;\n+\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_DONE;\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_IN_PROGRESS;\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_REQUIRED;\n+\n+import java.io.IOException;\n+import java.util.concurrent.Callable;\n+\n+import org.apache.hadoop.hdds.upgrade.HDDSLayoutFeatureCatalog.HDDSLayoutFeature;\n+import org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine;\n+import org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer;\n+\n+/**\n+ * UpgradeFinalizer for the DataNode.\n+ */\n+public class DataNodeUpgradeFinalizer extends\n+    BasicUpgradeFinalizer<DatanodeStateMachine, DataNodeLayoutVersionManager> {\n+\n+  public DataNodeUpgradeFinalizer(DataNodeLayoutVersionManager versionManager) {\n+    super(versionManager);\n+  }\n+\n+  @Override\n+  public StatusAndMessages finalize(String upgradeClientID,\n+                                    DatanodeStateMachine dsm)\n+      throws IOException {\n+    StatusAndMessages response = preFinalize(upgradeClientID, dsm);\n+    if (response.status() != FINALIZATION_REQUIRED) {\n+      return response;\n+    }\n+    new Worker(dsm).call();\n+    return STARTING_MSG;\n+  }\n+\n+  private class Worker implements Callable<Void> {\n+    private DatanodeStateMachine datanodeStateMachine;\n+\n+    /**\n+     * Initiates the Worker, for the specified DataNode instance.\n+     * @param dsm the DataNodeStateMachine instance on which to finalize the\n+     *           new LayoutFeatures.\n+     */\n+    Worker(DatanodeStateMachine dsm) {\n+      datanodeStateMachine = dsm;\n+    }\n+\n+    @Override\n+    public Void call() throws IOException {\n+      if(!datanodeStateMachine.preFinalizeUpgrade()) {\n+      // datanode is not yet ready to finalize.\n+      // Reset the Finalization state.\n+        versionManager.setUpgradeState(FINALIZATION_REQUIRED);\n+        return null;\n+      }\n+      try {\n+        emitStartingMsg();\n+        versionManager.setUpgradeState(FINALIZATION_IN_PROGRESS);\n+        /*\n+         * Before we can call finalize the feature, we need to make sure that\n+         * all existing pipelines are closed and pipeline Manger would freeze\n+         * all new pipeline creation.\n+         */\n+\n+        for (HDDSLayoutFeature f : versionManager.unfinalizedFeatures()) {\n+          finalizeFeature(f, datanodeStateMachine.getDataNodeStorageConfig());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQwNzQwOQ==", "bodyText": "yes. I added separate SCM and datanode actions. Please take a look.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r552407409", "createdAt": "2021-01-06T07:16:46Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeFinalizer.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.container.upgrade;\n+\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_DONE;\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_IN_PROGRESS;\n+import static org.apache.hadoop.ozone.upgrade.UpgradeFinalizer.Status.FINALIZATION_REQUIRED;\n+\n+import java.io.IOException;\n+import java.util.concurrent.Callable;\n+\n+import org.apache.hadoop.hdds.upgrade.HDDSLayoutFeatureCatalog.HDDSLayoutFeature;\n+import org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine;\n+import org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer;\n+\n+/**\n+ * UpgradeFinalizer for the DataNode.\n+ */\n+public class DataNodeUpgradeFinalizer extends\n+    BasicUpgradeFinalizer<DatanodeStateMachine, DataNodeLayoutVersionManager> {\n+\n+  public DataNodeUpgradeFinalizer(DataNodeLayoutVersionManager versionManager) {\n+    super(versionManager);\n+  }\n+\n+  @Override\n+  public StatusAndMessages finalize(String upgradeClientID,\n+                                    DatanodeStateMachine dsm)\n+      throws IOException {\n+    StatusAndMessages response = preFinalize(upgradeClientID, dsm);\n+    if (response.status() != FINALIZATION_REQUIRED) {\n+      return response;\n+    }\n+    new Worker(dsm).call();\n+    return STARTING_MSG;\n+  }\n+\n+  private class Worker implements Callable<Void> {\n+    private DatanodeStateMachine datanodeStateMachine;\n+\n+    /**\n+     * Initiates the Worker, for the specified DataNode instance.\n+     * @param dsm the DataNodeStateMachine instance on which to finalize the\n+     *           new LayoutFeatures.\n+     */\n+    Worker(DatanodeStateMachine dsm) {\n+      datanodeStateMachine = dsm;\n+    }\n+\n+    @Override\n+    public Void call() throws IOException {\n+      if(!datanodeStateMachine.preFinalizeUpgrade()) {\n+      // datanode is not yet ready to finalize.\n+      // Reset the Finalization state.\n+        versionManager.setUpgradeState(FINALIZATION_REQUIRED);\n+        return null;\n+      }\n+      try {\n+        emitStartingMsg();\n+        versionManager.setUpgradeState(FINALIZATION_IN_PROGRESS);\n+        /*\n+         * Before we can call finalize the feature, we need to make sure that\n+         * all existing pipelines are closed and pipeline Manger would freeze\n+         * all new pipeline creation.\n+         */\n+\n+        for (HDDSLayoutFeature f : versionManager.unfinalizedFeatures()) {\n+          finalizeFeature(f, datanodeStateMachine.getDataNodeStorageConfig());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MzY1Nw=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODIxMzQyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeLayoutVersionManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODo0MDowMlrOIJiG-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxNzo1OToxNlrOIN7XCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2NjkzNw==", "bodyText": "With these changes, I believe that HDDSLayoutFeature#FIRST_UPGRADE_VERSION can be removed.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546866937", "createdAt": "2020-12-21T18:40:02Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeLayoutVersionManager.java", "diffHunk": "@@ -69,41 +58,15 @@ public static synchronized LayoutVersionManager getInstance() {\n   /**\n    * Initialize DataNode version manager from version file stored on the\n    * DataNode.\n-   * @param conf - Ozone Configuration\n+   * @param dataNodeStorage - DataNode storage config\n    * @return version manager instance.\n    */\n+\n   public static synchronized DataNodeLayoutVersionManager initialize(\n-      ConfigurationSource conf)\n-      throws IOException {\n+      Storage dataNodeStorage) throws IOException {\n     if (dataNodeLayoutVersionManager == null) {\n       dataNodeLayoutVersionManager = new DataNodeLayoutVersionManager();\n-      int layoutVersion = 0;\n-      Collection<String> rawLocations = getDatanodeStorageDirs(conf);\n-      for (String locationString : rawLocations) {\n-        StorageLocation location = StorageLocation.parse(locationString);\n-        File hddsRootDir = new File(location.getUri().getPath(),\n-            HDDS_VOLUME_DIR);\n-        // Read the version from VersionFile Stored on the data node.\n-        File versionFile = HddsVolumeUtil.getVersionFile(hddsRootDir);\n-        if (!versionFile.exists()) {\n-          // Volume Root is non empty but VERSION file does not exist.\n-          LOG.warn(\"VERSION file does not exist in volume {},\"\n-                  + \" current volume state: {}.\",\n-              hddsRootDir.getPath(), HddsVolume.VolumeState.INCONSISTENT);\n-          continue;\n-        } else {\n-          LOG.debug(\"Reading version file {} from disk.\", versionFile);\n-        }\n-        Properties props = DatanodeVersionFile.readFrom(versionFile);\n-        if (props.isEmpty()) {\n-          continue;\n-        }\n-        int storedVersion = HddsVolumeUtil.getLayOutVersion(props, versionFile);\n-        if (storedVersion > layoutVersion) {\n-          layoutVersion = storedVersion;\n-        }\n-      }\n-      dataNodeLayoutVersionManager.init(layoutVersion,\n+      dataNodeLayoutVersionManager.init(dataNodeStorage.getLayoutVersion(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ3NDk1NA==", "bodyText": "As discussed in the last call. Let us keep it as it can be used to test the upgrade feature itself when we role out this feature. It would be a self validating upgrade.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r551474954", "createdAt": "2021-01-04T17:59:16Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeLayoutVersionManager.java", "diffHunk": "@@ -69,41 +58,15 @@ public static synchronized LayoutVersionManager getInstance() {\n   /**\n    * Initialize DataNode version manager from version file stored on the\n    * DataNode.\n-   * @param conf - Ozone Configuration\n+   * @param dataNodeStorage - DataNode storage config\n    * @return version manager instance.\n    */\n+\n   public static synchronized DataNodeLayoutVersionManager initialize(\n-      ConfigurationSource conf)\n-      throws IOException {\n+      Storage dataNodeStorage) throws IOException {\n     if (dataNodeLayoutVersionManager == null) {\n       dataNodeLayoutVersionManager = new DataNodeLayoutVersionManager();\n-      int layoutVersion = 0;\n-      Collection<String> rawLocations = getDatanodeStorageDirs(conf);\n-      for (String locationString : rawLocations) {\n-        StorageLocation location = StorageLocation.parse(locationString);\n-        File hddsRootDir = new File(location.getUri().getPath(),\n-            HDDS_VOLUME_DIR);\n-        // Read the version from VersionFile Stored on the data node.\n-        File versionFile = HddsVolumeUtil.getVersionFile(hddsRootDir);\n-        if (!versionFile.exists()) {\n-          // Volume Root is non empty but VERSION file does not exist.\n-          LOG.warn(\"VERSION file does not exist in volume {},\"\n-                  + \" current volume state: {}.\",\n-              hddsRootDir.getPath(), HddsVolume.VolumeState.INCONSISTENT);\n-          continue;\n-        } else {\n-          LOG.debug(\"Reading version file {} from disk.\", versionFile);\n-        }\n-        Properties props = DatanodeVersionFile.readFrom(versionFile);\n-        if (props.isEmpty()) {\n-          continue;\n-        }\n-        int storedVersion = HddsVolumeUtil.getLayOutVersion(props, versionFile);\n-        if (storedVersion > layoutVersion) {\n-          layoutVersion = storedVersion;\n-        }\n-      }\n-      dataNodeLayoutVersionManager.init(layoutVersion,\n+      dataNodeLayoutVersionManager.init(dataNodeStorage.getLayoutVersion(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2NjkzNw=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODIyNTU1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/OzoneConsts.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODo0NDoxNlrOIJiOMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxODowMDoxMlrOIN7ZFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2ODc4Ng==", "bodyText": "There is also a \"datanode.id\" file being created in the Datanode that looks like a metadata yaml file. Can we look into whether we can add our layout version into that file? Reference -> org.apache.hadoop.hdds.utils.HddsServerUtil#getDatanodeIdFilePath", "url": "https://github.com/apache/ozone/pull/1720#discussion_r546868786", "createdAt": "2020-12-21T18:44:16Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/OzoneConsts.java", "diffHunk": "@@ -42,6 +42,7 @@\n \n   public static final String STORAGE_ID = \"storageID\";\n   public static final String DATANODE_UUID = \"datanodeUuid\";\n+  public static final String DATANODE_STORAGE_DIR = \"datanodeStorageConfig\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ3NTQ3OA==", "bodyText": "yup, storage config is used just for the upgrade and nothing else. We will continue to use datanode.id file as it is.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r551475478", "createdAt": "2021-01-04T18:00:12Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/OzoneConsts.java", "diffHunk": "@@ -42,6 +42,7 @@\n \n   public static final String STORAGE_ID = \"storageID\";\n   public static final String DATANODE_UUID = \"datanodeUuid\";\n+  public static final String DATANODE_STORAGE_DIR = \"datanodeStorageConfig\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2ODc4Ng=="}, "originalCommit": {"oid": "084dd9ea6dcb14f90e0cfdc24bef716e6fdfcb0c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4MTMyNTkyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeAction.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjowMjowN1rOIPgGFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wOFQwNjoyMTo1NlrOIQHB-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEyNTM5Nw==", "bodyText": "Can we have DataNodeUpgradeAction and SCMUpgradeAction as an interface or abstract class?", "url": "https://github.com/apache/ozone/pull/1720#discussion_r553125397", "createdAt": "2021-01-07T06:02:07Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeAction.java", "diffHunk": "@@ -0,0 +1,31 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.container.upgrade;\n+\n+import org.apache.hadoop.hdds.upgrade.HDDSUpgradeAction;\n+import org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine;\n+\n+/**\n+ * Upgrade Action for DataNode which takes in a 'DataNodeStateMachine' instance.\n+ */\n+public class DataNodeUpgradeAction extends", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mzc2MzMyMQ==", "bodyText": "Yes, will do", "url": "https://github.com/apache/ozone/pull/1720#discussion_r553763321", "createdAt": "2021-01-08T06:21:56Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/upgrade/DataNodeUpgradeAction.java", "diffHunk": "@@ -0,0 +1,31 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.container.upgrade;\n+\n+import org.apache.hadoop.hdds.upgrade.HDDSUpgradeAction;\n+import org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine;\n+\n+/**\n+ * Upgrade Action for DataNode which takes in a 'DataNodeStateMachine' instance.\n+ */\n+public class DataNodeUpgradeAction extends", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEyNTM5Nw=="}, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4MTM3MjE1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjoyNTozOVrOIPggkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNTowMjoyMFrOIRB1Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzMjE3Ng==", "bodyText": "I am wondering whether the organization of modules will cause a problem here. The DatanodeStateMachine class is in container-service module, while this class (HDDSLayoutFeatureCatalog) is in hdds-common. The common module is usually shared across the more specific modules. Where does one create an upgrade action for the Datanode? If the action is in container-service, then it cannot be accessed in hdds-common, if the action is in common, then it cannot access the DatanodeStateMachine class.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r553132176", "createdAt": "2021-01-07T06:25:39Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "diffHunk": "@@ -39,7 +40,11 @@\n \n     private int layoutVersion;\n     private String description;\n-    private Optional< ? extends HDDSUpgradeAction> hddsUpgradeAction =\n+\n+    private Optional<? extends HDDSUpgradeAction> scmUpgradeAction =\n+        Optional.empty();\n+\n+    private Optional<? extends HDDSUpgradeAction> datanodeUpgradeAction =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mzc2MzU5Mw==", "bodyText": "Yes. I have updated the PR to add datanode action and scm action. There is an integration test for this, thats working but thats in a separate PR for integration test.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r553763593", "createdAt": "2021-01-08T06:23:03Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "diffHunk": "@@ -39,7 +40,11 @@\n \n     private int layoutVersion;\n     private String description;\n-    private Optional< ? extends HDDSUpgradeAction> hddsUpgradeAction =\n+\n+    private Optional<? extends HDDSUpgradeAction> scmUpgradeAction =\n+        Optional.empty();\n+\n+    private Optional<? extends HDDSUpgradeAction> datanodeUpgradeAction =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzMjE3Ng=="}, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mzc4MjM0OQ==", "bodyText": "New approach looks good to me. Can we fix the CI issues? Also, do we need to include the sample SCM and DN action that you have added in the latest commit?", "url": "https://github.com/apache/ozone/pull/1720#discussion_r553782349", "createdAt": "2021-01-08T07:27:30Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "diffHunk": "@@ -39,7 +40,11 @@\n \n     private int layoutVersion;\n     private String description;\n-    private Optional< ? extends HDDSUpgradeAction> hddsUpgradeAction =\n+\n+    private Optional<? extends HDDSUpgradeAction> scmUpgradeAction =\n+        Optional.empty();\n+\n+    private Optional<? extends HDDSUpgradeAction> datanodeUpgradeAction =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzMjE3Ng=="}, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4OTg2Nw==", "bodyText": "Yes, uploaded the new changes to address CI failures. We can leave sample SCM and DN actions to be used as an example in future upgrades. This also makes it a self validating release.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r554289867", "createdAt": "2021-01-09T04:35:42Z", "author": {"login": "prashantpogde"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "diffHunk": "@@ -39,7 +40,11 @@\n \n     private int layoutVersion;\n     private String description;\n-    private Optional< ? extends HDDSUpgradeAction> hddsUpgradeAction =\n+\n+    private Optional<? extends HDDSUpgradeAction> scmUpgradeAction =\n+        Optional.empty();\n+\n+    private Optional<? extends HDDSUpgradeAction> datanodeUpgradeAction =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzMjE3Ng=="}, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcyNjcyNw==", "bodyText": "@prashantpogde I am ok with that. If we are going to add these No-Op actions for the first upgrade release, I would suggest renaming the action to something more intuitive rather than \"DatanodeAction1\" and \"SCMAction1\". I am OK with doing these changes in a follow up JIRA.", "url": "https://github.com/apache/ozone/pull/1720#discussion_r554726727", "createdAt": "2021-01-11T05:02:20Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/upgrade/HDDSLayoutFeatureCatalog.java", "diffHunk": "@@ -39,7 +40,11 @@\n \n     private int layoutVersion;\n     private String description;\n-    private Optional< ? extends HDDSUpgradeAction> hddsUpgradeAction =\n+\n+    private Optional<? extends HDDSUpgradeAction> scmUpgradeAction =\n+        Optional.empty();\n+\n+    private Optional<? extends HDDSUpgradeAction> datanodeUpgradeAction =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzMjE3Ng=="}, "originalCommit": {"oid": "180492562773544ca9685d502a26cb0b6c9614f5"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4463, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}