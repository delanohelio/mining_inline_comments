{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4MTA3Nzc3", "number": 678, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwOToyMTowMlrODoGmEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDowOTowOVrODrqaWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzMzc3NjgxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNVQwOToyMTowMlrOF2dzSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo1MDoyOVrOF7XgyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NTY4OQ==", "bodyText": "I also meet this issue in my testing cluster.\nI would like to log the exception in debug level log here. Then we could know the fallback happened.\nAlso can we log the debug log for final pick node when returned is null?\nif (pick != null) {\nresults.add(pick);\n...\n} else {\nLOG.debug(\"Pick node is null, exclude {}, anchor {}.\",\nexclude, anchor);\n}", "url": "https://github.com/apache/ozone/pull/678#discussion_r392655689", "createdAt": "2020-03-15T09:21:02Z", "author": {"login": "linyiqun"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,15 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8dd24acaed89d4501cb8aaf00e77c4cf5431f4e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY3NzY2Mw==", "bodyText": "Debug log makes sense.\nMy thought was: fall back will happen every time when there is only one node on the rack. Under all other scenarios, this fallback logic shouldn't take effects. As a known case, I was reluctant to add logs for it regardless of its log level. But I guess it can be valuable if fallback logic takes effect in other cases.", "url": "https://github.com/apache/ozone/pull/678#discussion_r392677663", "createdAt": "2020-03-15T14:13:04Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,15 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NTY4OQ=="}, "originalCommit": {"oid": "d8dd24acaed89d4501cb8aaf00e77c4cf5431f4e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMjMyMA==", "bodyText": "Could we avoid the exception block here, especially if we think the exception block will be the \"normal code path\" if the rack only has one node?\nEg, if we change chooseNodeFromNetworkTopology() to return null or the picked node, and then refactor this code block to look like this:\n      DatanodeDetails pick = null;\n      if (rackAwareness) {\n        pick = chooseNodeFromNetworkTopology(\n            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude);\n      }\n      if (pick == null) {\n        pick = fallBackPickNodes(healthyNodes, exclude);\n        if (rackAwareness) {\n          LOG.debug(\"Failed to choose node based on topology. Fallback \" +\n              \"picks node as: {}\", pick);\n        }\n      }\n\nI think that is easier to read and avoid the expensive exception handler. What do you think?", "url": "https://github.com/apache/ozone/pull/678#discussion_r394322320", "createdAt": "2020-03-18T12:52:23Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,15 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NTY4OQ=="}, "originalCommit": {"oid": "d8dd24acaed89d4501cb8aaf00e77c4cf5431f4e"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NTUyOQ==", "bodyText": "This is clean. I will make updates. Thanks for the suggestion.", "url": "https://github.com/apache/ozone/pull/678#discussion_r397795529", "createdAt": "2020-03-25T11:50:29Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,15 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NTY4OQ=="}, "originalCommit": {"oid": "d8dd24acaed89d4501cb8aaf00e77c4cf5431f4e"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODIzMzE1OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjo1ODozOVrOF3Ifnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQwMzoyMToxMVrOF31F5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw==", "bodyText": "I don't think we need to wrap the debug logs in if (LOG.isDebugEnabled()) if we use the SLF4J style logs with {} placeholders rather than string interpolation. The log message will only be evaluated if the debug level is set.\nFor this log, I would suggest using the {} placeholders and let the full stack trace be logged rather than just e.getMessage(), eg:\nLOG.debug(\"Pipeline not found in pipeline state manager during\" +\n              \" pipeline creation. PipelineID: {}\", pid, e);", "url": "https://github.com/apache/ozone/pull/678#discussion_r393355167", "createdAt": "2020-03-16T22:58:39Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQxMTA2Nw==", "bodyText": "Thanks for the info. How about the logs without \"{}\" ? Shall we check if debug is enabled? @sodonnel", "url": "https://github.com/apache/ozone/pull/678#discussion_r393411067", "createdAt": "2020-03-17T02:29:51Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzUzNjU1NA==", "bodyText": "If you don't use the {} syntax, then it makes sense to wrap the log in the if statement to avoid needing to construct the string. Ideally you should use the {} syntax for the logs, as they are easier to write, generally easier to read and more efficient.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393536554", "createdAt": "2020-03-17T09:14:29Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzYyMjI5NA==", "bodyText": "I added {} and removed isDebugEnabled check", "url": "https://github.com/apache/ozone/pull/678#discussion_r393622294", "createdAt": "2020-03-17T11:50:01Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzY2MTMwMQ==", "bodyText": "The other logs have been changed, but this one is still using interpolation and is wrapped in the if statement. Could you change it too please?\nWith SLF4J, if you pass an exception object as the last parameter it will print the full stack into the log automatically, eg:\nLOG.debug(\"Pipeline not found in pipeline state manager during\" +\n              \" pipeline creation. PipelineID: {}\", pid, e);\n\nI don't think the full stack will get printed using string concatenation as that will call toString on the exception which will just return the message part and not the stack trace.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393661301", "createdAt": "2020-03-17T13:02:05Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA4NTg2Mg==", "bodyText": "Yea just updated. Thanks.", "url": "https://github.com/apache/ozone/pull/678#discussion_r394085862", "createdAt": "2020-03-18T03:21:11Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTE2Nw=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODIzNDczOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjo1OToyMVrOF3Ighg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxMTo0OToyMlrOF3Yx2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTM5OA==", "bodyText": "I think we can remove this if statement safely.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393355398", "createdAt": "2020-03-16T22:59:21Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,19 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {\n+        pick = fallBackPickNodes(healthyNodes, exclude);\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzYyMTk3OA==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393621978", "createdAt": "2020-03-17T11:49:22Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -292,10 +294,19 @@ DatanodeDetails fallBackPickNodes(\n     int nodesToFind = nodesRequired - results.size();\n     for (int x = 0; x < nodesToFind; x++) {\n       // Pick remaining nodes based on the existence of rack awareness.\n-      DatanodeDetails pick = rackAwareness\n-          ? chooseNodeFromNetworkTopology(\n-              nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n-          : fallBackPickNodes(healthyNodes, exclude);\n+      DatanodeDetails pick;\n+      try {\n+        pick = rackAwareness\n+            ? chooseNodeFromNetworkTopology(\n+            nodeManager.getClusterNetworkTopologyMap(), anchor, exclude)\n+            : fallBackPickNodes(healthyNodes, exclude);\n+      } catch (SCMException e) {\n+        pick = fallBackPickNodes(healthyNodes, exclude);\n+        if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTM5OA=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODIzODA3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMzowMDozNFrOF3IirQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxMTo0OToxNVrOF3Yxpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTk0OQ==", "bodyText": "Again, I don't think we need the if (LOG.isDebugEnabled()) { wrapping the debug log.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393355949", "createdAt": "2020-03-16T23:00:34Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -414,6 +425,14 @@ protected DatanodeDetails chooseNodeFromNetworkTopology(\n     Node pick = networkTopology.chooseRandom(\n         anchor.getNetworkLocation(), excluded);\n     DatanodeDetails pickedNode = (DatanodeDetails) pick;\n+    if (pickedNode == null) {\n+      if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzYyMTkyNw==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/678#discussion_r393621927", "createdAt": "2020-03-17T11:49:15Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -414,6 +425,14 @@ protected DatanodeDetails chooseNodeFromNetworkTopology(\n     Node pick = networkTopology.chooseRandom(\n         anchor.getNetworkLocation(), excluded);\n     DatanodeDetails pickedNode = (DatanodeDetails) pick;\n+    if (pickedNode == null) {\n+      if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM1NTk0OQ=="}, "originalCommit": {"oid": "b007fae14fc28a49c16e8241710713728ed10098"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NDA1MTc4OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxMjoxMDoyMVrOF4CHrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo1MTowNlrOF7Xh4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI5OTMxMQ==", "bodyText": "This line still is not correct. The way SLF4J works, is it substitutes the {} for each parameter in turn. If the last parameter is a Throwable, it prints the stack trace after the log message. So I think it should be:\nLOG.debug(\"Pipeline not found in pipeline state manager during\" +\n            \" pipeline creation. PipelineID: {}\", pid, e);", "url": "https://github.com/apache/ozone/pull/678#discussion_r394299311", "createdAt": "2020-03-18T12:10:21Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,8 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        LOG.debug(\"Pipeline not found in pipeline state manager during\" +\n+            \" pipeline creation. PipelineID: {}\" + pid + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NTgwOQ==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/678#discussion_r397795809", "createdAt": "2020-03-25T11:51:06Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -99,9 +99,8 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n       try {\n         pipeline = stateManager.getPipeline(pid);\n       } catch (PipelineNotFoundException e) {\n-        LOG.error(\"Pipeline not found in pipeline state manager during\" +\n-            \" pipeline creation. PipelineID: \" + pid +\n-            \" exception: \" + e.getMessage());\n+        LOG.debug(\"Pipeline not found in pipeline state manager during\" +\n+            \" pipeline creation. PipelineID: {}\" + pid + e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI5OTMxMQ=="}, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NDE5OTgzOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxMjo1NDowN1rOF4DllA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMTo1MToyMVrOF7XiVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMzM0OA==", "bodyText": "As I mentioned above, I feel it would be simpler if this just returns null rather than throwing an exception.", "url": "https://github.com/apache/ozone/pull/678#discussion_r394323348", "createdAt": "2020-03-18T12:54:07Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -414,6 +416,12 @@ protected DatanodeDetails chooseNodeFromNetworkTopology(\n     Node pick = networkTopology.chooseRandom(\n         anchor.getNetworkLocation(), excluded);\n     DatanodeDetails pickedNode = (DatanodeDetails) pick;\n+    if (pickedNode == null) {\n+      LOG.debug(\"Pick node is null, excluded nodes {}, anchor {}.\",\n+          excluded, anchor);\n+      throw new SCMException(\"Unable to find node based on Topology.\",\n+          SCMException.ResultCodes.FAILED_TO_FIND_SUITABLE_NODE);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NTkyNg==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/678#discussion_r397795926", "createdAt": "2020-03-25T11:51:21Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -414,6 +416,12 @@ protected DatanodeDetails chooseNodeFromNetworkTopology(\n     Node pick = networkTopology.chooseRandom(\n         anchor.getNetworkLocation(), excluded);\n     DatanodeDetails pickedNode = (DatanodeDetails) pick;\n+    if (pickedNode == null) {\n+      LOG.debug(\"Pick node is null, excluded nodes {}, anchor {}.\",\n+          excluded, anchor);\n+      throw new SCMException(\"Unable to find node based on Topology.\",\n+          SCMException.ResultCodes.FAILED_TO_FIND_SUITABLE_NODE);\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMzM0OA=="}, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NDM5Nzk3OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOFQxMzo0NToxNFrOF4FlhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxMjo1NTo0N1rOF7Zq7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1NjEwMQ==", "bodyText": "There are a lot of changes in this test file, but do we have a test that reproduces the problem reported? The problem is that if the anchor node is on a rack with only a single node, then only 2 nodes would be allocated rather than 3? It should be possible to reproduce this easily with a 3 node and 3 rack cluster, one rack per node.\nI think we should add a test that reproduces the problem so we know the changes correct it and we have no regressions in the future. We should also test this via the public API of PipelinePlacementPolicy if possible. Right now, most of the tests in TestPipelinePolicy seem to call \"@VisibleForTesting\" methods rather than chooseDatanodes or getResultSet, which are the public methods.", "url": "https://github.com/apache/ozone/pull/678#discussion_r394356101", "createdAt": "2020-03-18T13:45:14Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.hdds.conf.OzoneConfiguration;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzgzMDg5Mg==", "bodyText": "I just added a test for this case. Please see the updates.", "url": "https://github.com/apache/ozone/pull/678#discussion_r397830892", "createdAt": "2020-03-25T12:55:47Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.hdds.conf.OzoneConfiguration;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1NjEwMQ=="}, "originalCommit": {"oid": "c4576bc435569ba74a7b650890532669f5e958f3"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3MDk4NzkxOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxMzo0NTowOVrOF8HjsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDozNTo1NVrOF8J9Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4MjcwNA==", "bodyText": "You can remove the throws SCMException in the method definition now, as it is no longer used.", "url": "https://github.com/apache/ozone/pull/678#discussion_r398582704", "createdAt": "2020-03-26T13:45:09Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -403,7 +408,7 @@ private boolean checkAllNodesAreEqual(NetworkTopology topology) {\n   @VisibleForTesting\n   protected DatanodeDetails chooseNodeFromNetworkTopology(\n       NetworkTopology networkTopology, DatanodeDetails anchor,\n-      List<DatanodeDetails> excludedNodes) {\n+      List<DatanodeDetails> excludedNodes) throws SCMException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7e6aff83aa28d312989c0af16560f40fac2efe6"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYyMjAyMw==", "bodyText": "Updated.", "url": "https://github.com/apache/ozone/pull/678#discussion_r398622023", "createdAt": "2020-03-26T14:35:55Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -403,7 +408,7 @@ private boolean checkAllNodesAreEqual(NetworkTopology topology) {\n   @VisibleForTesting\n   protected DatanodeDetails chooseNodeFromNetworkTopology(\n       NetworkTopology networkTopology, DatanodeDetails anchor,\n-      List<DatanodeDetails> excludedNodes) {\n+      List<DatanodeDetails> excludedNodes) throws SCMException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4MjcwNA=="}, "originalCommit": {"oid": "b7e6aff83aa28d312989c0af16560f40fac2efe6"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3MTEwMjMyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDowOTowOVrOF8Irzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxNDozNTo0OFrOF8J88A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYwMTE2Ng==", "bodyText": "This test doesn't reproduce the error if the fix in this PR is removed. I commented out the fix in PipelinePlacement policy and added back in the old logic and ran this and it still passed. The reason, is that PipelinePlacementPolicy did not believe networkTopology was present. Changing this line as follows makes the test reproduce the problem:\n    MockNodeManager localNodeManager = new MockNodeManager(initTopology(), datanodes,\n        false, datanodes.size());\n\nNote I added initTopology() when constructing the NodeManager.\nWith that, the test fails without the fix, and passes with the fix in this PR, so that is good.", "url": "https://github.com/apache/ozone/pull/678#discussion_r398601166", "createdAt": "2020-03-26T14:09:09Z", "author": {"login": "sodonnel"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "diffHunk": "@@ -43,36 +47,98 @@\n   private MockNodeManager nodeManager;\n   private OzoneConfiguration conf;\n   private PipelinePlacementPolicy placementPolicy;\n+  private NetworkTopologyImpl cluster;\n   private static final int PIPELINE_PLACEMENT_MAX_NODES_COUNT = 10;\n \n+  private List<DatanodeDetails> nodesWithOutRackAwareness = new ArrayList<>();\n+  private List<DatanodeDetails> nodesWithRackAwareness = new ArrayList<>();\n+\n   @Before\n   public void init() throws Exception {\n-    nodeManager = new MockNodeManager(true,\n-        PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n+    cluster = initTopology();\n+    // start with nodes with rack awareness.\n+    nodeManager = new MockNodeManager(cluster, getNodesWithRackAwareness(),\n+        false, PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n     conf = new OzoneConfiguration();\n     conf.setInt(OZONE_DATANODE_PIPELINE_LIMIT, 5);\n     placementPolicy = new PipelinePlacementPolicy(\n         nodeManager, new PipelineStateManager(), conf);\n   }\n \n+  private NetworkTopologyImpl initTopology() {\n+    NodeSchema[] schemas = new NodeSchema[]\n+        {ROOT_SCHEMA, RACK_SCHEMA, LEAF_SCHEMA};\n+    NodeSchemaManager.getInstance().init(schemas, true);\n+    NetworkTopologyImpl topology =\n+        new NetworkTopologyImpl(NodeSchemaManager.getInstance());\n+    return topology;\n+  }\n+\n+  private List<DatanodeDetails> getNodesWithRackAwareness() {\n+    List<DatanodeDetails> datanodes = new ArrayList<>();\n+    for (Node node : NODES) {\n+      DatanodeDetails datanode = overwriteLocationInNode(\n+          getNodesWithoutRackAwareness(), node);\n+      nodesWithRackAwareness.add(datanode);\n+      datanodes.add(datanode);\n+    }\n+    return datanodes;\n+  }\n+\n+  private DatanodeDetails getNodesWithoutRackAwareness() {\n+    DatanodeDetails node = MockDatanodeDetails.randomDatanodeDetails();\n+    nodesWithOutRackAwareness.add(node);\n+    return node;\n+  }\n+\n   @Test\n-  public void testChooseNodeBasedOnNetworkTopology() {\n-    List<DatanodeDetails> healthyNodes =\n-        nodeManager.getNodes(HddsProtos.NodeState.HEALTHY);\n-    DatanodeDetails anchor = placementPolicy.chooseNode(healthyNodes);\n+  public void testChooseNodeBasedOnNetworkTopology() throws SCMException {\n+    DatanodeDetails anchor = placementPolicy.chooseNode(nodesWithRackAwareness);\n     // anchor should be removed from healthyNodes after being chosen.\n-    Assert.assertFalse(healthyNodes.contains(anchor));\n+    Assert.assertFalse(nodesWithRackAwareness.contains(anchor));\n \n     List<DatanodeDetails> excludedNodes =\n         new ArrayList<>(PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n     excludedNodes.add(anchor);\n     DatanodeDetails nextNode = placementPolicy.chooseNodeFromNetworkTopology(\n         nodeManager.getClusterNetworkTopologyMap(), anchor, excludedNodes);\n     Assert.assertFalse(excludedNodes.contains(nextNode));\n-    // nextNode should not be the same as anchor.\n+    // next node should not be the same as anchor.\n     Assert.assertTrue(anchor.getUuid() != nextNode.getUuid());\n+    // next node should be on the same rack based on topology.\n+    Assert.assertEquals(anchor.getNetworkLocation(),\n+        nextNode.getNetworkLocation());\n   }\n \n+  @Test\n+  public void testChooseNodeWithSingleNodeRack() throws SCMException {\n+    // There is only one node on 3 racks altogether.\n+    List<DatanodeDetails> datanodes = new ArrayList<>();\n+    for (Node node : SINGLE_NODE_RACK) {\n+      DatanodeDetails datanode = overwriteLocationInNode(\n+          MockDatanodeDetails.randomDatanodeDetails(), node);\n+      datanodes.add(datanode);\n+    }\n+    MockNodeManager localNodeManager = new MockNodeManager(null, datanodes,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7e6aff83aa28d312989c0af16560f40fac2efe6"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYyMTkzNg==", "bodyText": "You are right. I updated this part. Thanks!", "url": "https://github.com/apache/ozone/pull/678#discussion_r398621936", "createdAt": "2020-03-26T14:35:48Z", "author": {"login": "timmylicheng"}, "path": "hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java", "diffHunk": "@@ -43,36 +47,98 @@\n   private MockNodeManager nodeManager;\n   private OzoneConfiguration conf;\n   private PipelinePlacementPolicy placementPolicy;\n+  private NetworkTopologyImpl cluster;\n   private static final int PIPELINE_PLACEMENT_MAX_NODES_COUNT = 10;\n \n+  private List<DatanodeDetails> nodesWithOutRackAwareness = new ArrayList<>();\n+  private List<DatanodeDetails> nodesWithRackAwareness = new ArrayList<>();\n+\n   @Before\n   public void init() throws Exception {\n-    nodeManager = new MockNodeManager(true,\n-        PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n+    cluster = initTopology();\n+    // start with nodes with rack awareness.\n+    nodeManager = new MockNodeManager(cluster, getNodesWithRackAwareness(),\n+        false, PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n     conf = new OzoneConfiguration();\n     conf.setInt(OZONE_DATANODE_PIPELINE_LIMIT, 5);\n     placementPolicy = new PipelinePlacementPolicy(\n         nodeManager, new PipelineStateManager(), conf);\n   }\n \n+  private NetworkTopologyImpl initTopology() {\n+    NodeSchema[] schemas = new NodeSchema[]\n+        {ROOT_SCHEMA, RACK_SCHEMA, LEAF_SCHEMA};\n+    NodeSchemaManager.getInstance().init(schemas, true);\n+    NetworkTopologyImpl topology =\n+        new NetworkTopologyImpl(NodeSchemaManager.getInstance());\n+    return topology;\n+  }\n+\n+  private List<DatanodeDetails> getNodesWithRackAwareness() {\n+    List<DatanodeDetails> datanodes = new ArrayList<>();\n+    for (Node node : NODES) {\n+      DatanodeDetails datanode = overwriteLocationInNode(\n+          getNodesWithoutRackAwareness(), node);\n+      nodesWithRackAwareness.add(datanode);\n+      datanodes.add(datanode);\n+    }\n+    return datanodes;\n+  }\n+\n+  private DatanodeDetails getNodesWithoutRackAwareness() {\n+    DatanodeDetails node = MockDatanodeDetails.randomDatanodeDetails();\n+    nodesWithOutRackAwareness.add(node);\n+    return node;\n+  }\n+\n   @Test\n-  public void testChooseNodeBasedOnNetworkTopology() {\n-    List<DatanodeDetails> healthyNodes =\n-        nodeManager.getNodes(HddsProtos.NodeState.HEALTHY);\n-    DatanodeDetails anchor = placementPolicy.chooseNode(healthyNodes);\n+  public void testChooseNodeBasedOnNetworkTopology() throws SCMException {\n+    DatanodeDetails anchor = placementPolicy.chooseNode(nodesWithRackAwareness);\n     // anchor should be removed from healthyNodes after being chosen.\n-    Assert.assertFalse(healthyNodes.contains(anchor));\n+    Assert.assertFalse(nodesWithRackAwareness.contains(anchor));\n \n     List<DatanodeDetails> excludedNodes =\n         new ArrayList<>(PIPELINE_PLACEMENT_MAX_NODES_COUNT);\n     excludedNodes.add(anchor);\n     DatanodeDetails nextNode = placementPolicy.chooseNodeFromNetworkTopology(\n         nodeManager.getClusterNetworkTopologyMap(), anchor, excludedNodes);\n     Assert.assertFalse(excludedNodes.contains(nextNode));\n-    // nextNode should not be the same as anchor.\n+    // next node should not be the same as anchor.\n     Assert.assertTrue(anchor.getUuid() != nextNode.getUuid());\n+    // next node should be on the same rack based on topology.\n+    Assert.assertEquals(anchor.getNetworkLocation(),\n+        nextNode.getNetworkLocation());\n   }\n \n+  @Test\n+  public void testChooseNodeWithSingleNodeRack() throws SCMException {\n+    // There is only one node on 3 racks altogether.\n+    List<DatanodeDetails> datanodes = new ArrayList<>();\n+    for (Node node : SINGLE_NODE_RACK) {\n+      DatanodeDetails datanode = overwriteLocationInNode(\n+          MockDatanodeDetails.randomDatanodeDetails(), node);\n+      datanodes.add(datanode);\n+    }\n+    MockNodeManager localNodeManager = new MockNodeManager(null, datanodes,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODYwMTE2Ng=="}, "originalCommit": {"oid": "b7e6aff83aa28d312989c0af16560f40fac2efe6"}, "originalPosition": 102}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4829, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}