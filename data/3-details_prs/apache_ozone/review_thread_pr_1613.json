{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI2MDYyNTM4", "number": 1613, "reviewThreads": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDo1MTo1N1rOE8wgRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMjo1OTo1M1rOFBA8cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMTQ0NzA5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNDo1MTo1N1rOH5EeRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxOTozNDozMlrOH6BYdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTYwNDE2Nw==", "bodyText": "Transaction entry added in double buffer is async flushed to db. Shall we pass transactionLogIndex to double check and make sure previous txns be applied.  I mean we would better to double check and ensure that snapshot index equals current prepare transactionLogIndex.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r529604167", "createdAt": "2020-11-24T14:51:57Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.hdds.ratis.RatisUpgradeUtils;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final long DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS = 5 * 60;\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final long DOUBLE_BUFFER_FLUSH_CHECK_SECONDS = 1;\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareForUpgradeResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      OzoneManagerStateMachine omStateMachine =\n+          omRatisServer.getOmStateMachine();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      RatisUpgradeUtils.waitForAllTxnsApplied(omStateMachine, serverImpl,\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS,\n+          DOUBLE_BUFFER_FLUSH_CHECK_SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYwMjEwMw==", "bodyText": "Yes Yiqun, you are right. This was an early draft of the feature. Please see the new code and let me know if this resolves your concern.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530602103", "createdAt": "2020-11-25T19:34:32Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.hdds.ratis.RatisUpgradeUtils;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final long DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS = 5 * 60;\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final long DOUBLE_BUFFER_FLUSH_CHECK_SECONDS = 1;\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareForUpgradeResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      OzoneManagerStateMachine omStateMachine =\n+          omRatisServer.getOmStateMachine();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      RatisUpgradeUtils.waitForAllTxnsApplied(omStateMachine, serverImpl,\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS,\n+          DOUBLE_BUFFER_FLUSH_CHECK_SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTYwNDE2Nw=="}, "originalCommit": {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODA0NzgyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0ODozNlrOH6Davw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo0ODozNlrOH6Davw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzNTQ1NQ==", "bodyText": "We need to have the RPC server running even in \"Prepared\" state. This if condition can be removed.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530635455", "createdAt": "2020-11-25T20:48:36Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1239,7 +1208,7 @@ public void start() throws IOException {\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n \n-    if (!prepareForUpgrade) {\n+    if (!isPrepared) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODA2NzUxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo1NjoxMVrOH6Dmgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMzo0NDoxNlrOH6HH_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzODQ2Ng==", "bodyText": "3 second timeout maybe a bit aggressive. Can we increase it to 30seconds?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530638466", "createdAt": "2020-11-25T20:56:11Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Submit prepare request via Ratis.\n+    OzoneManager leaderOM = cluster.getOMLeader();\n+    long prepareIndex =\n+        leaderOM.getOmRatisServer().submitRequest(buildPrepareRequest())\n+            .getPrepareResponse()\n+            .getTxnID();\n+\n+    // Check that the two live OMs are prepared.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      if (om == leaderOM) {\n+        // Leader should have been prepared after we got the response.\n+        checkPrepared(om, prepareIndex);\n+      } else if (om != downedOM) {\n+        // Follower may still be applying transactions.\n+        waitAndCheckPrepared(om, prepareIndex);\n+      }\n+    }\n+\n+    // Restart the downed OM and wait for it to catch up.\n+    // Since prepare was the last Ratis transaction, it should have all data\n+    // it missed once it receives the prepare transaction.\n+    cluster.restartOzoneManager(downedOM, true);\n+    // Wait for other OMs to catch this one up on transactions.\n+    LambdaTestUtils.await(3000, 1000,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY5NjE4OQ==", "bodyText": "Sure, done.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530696189", "createdAt": "2020-11-25T23:44:16Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Submit prepare request via Ratis.\n+    OzoneManager leaderOM = cluster.getOMLeader();\n+    long prepareIndex =\n+        leaderOM.getOmRatisServer().submitRequest(buildPrepareRequest())\n+            .getPrepareResponse()\n+            .getTxnID();\n+\n+    // Check that the two live OMs are prepared.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      if (om == leaderOM) {\n+        // Leader should have been prepared after we got the response.\n+        checkPrepared(om, prepareIndex);\n+      } else if (om != downedOM) {\n+        // Follower may still be applying transactions.\n+        waitAndCheckPrepared(om, prepareIndex);\n+      }\n+    }\n+\n+    // Restart the downed OM and wait for it to catch up.\n+    // Since prepare was the last Ratis transaction, it should have all data\n+    // it missed once it receives the prepare transaction.\n+    cluster.restartOzoneManager(downedOM, true);\n+    // Wait for other OMs to catch this one up on transactions.\n+    LambdaTestUtils.await(3000, 1000,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzODQ2Ng=="}, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODA3NDYzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo1ODo0OFrOH6DqnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMzo0NTowMVrOH6HIww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTUxNg==", "bodyText": "Let's add a logFilesPresentInRatisPeer 'true' assert here so that we start from an 'expected' state and also to make sure that there are no bugs in that method itself :).", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530639516", "createdAt": "2020-11-25T20:58:48Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY5NjM4Nw==", "bodyText": "Added this check on all OMs in both the tests that have transactions (even though one is commented out and does not run).", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530696387", "createdAt": "2020-11-25T23:45:01Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTUxNg=="}, "originalCommit": {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668"}, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNzA1NzQ4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwOTo0NjowNFrOH7XfLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjozNDo1NlrOH8VzsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMjg0NQ==", "bodyText": "Can we rename to PrepareUpgrade which can be more readable? In the design doc, it also called PrepareUpgrade request.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532012845", "createdAt": "2020-11-28T09:46:04Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -74,6 +74,7 @@ enum Type {\n   DBUpdates = 53;\n   FinalizeUpgrade = 54;\n   FinalizeUpgradeProgress = 55;\n+  Prepare = 56;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMzkwNA==", "bodyText": "Ignored this, see below comments about this.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533033904", "createdAt": "2020-12-01T02:34:56Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -74,6 +74,7 @@ enum Type {\n   DBUpdates = 53;\n   FinalizeUpgrade = 54;\n   FinalizeUpgradeProgress = 55;\n+  Prepare = 56;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMjg0NQ=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNzA1ODk5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQwOTo0Nzo1NFrOH7Xf2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjoyODowNVrOH8VrnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMzAxNw==", "bodyText": "Can we rename to PrepareUpgradeRequest/PrepareUpgradeResponse?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532013017", "createdAt": "2020-11-28T09:47:54Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -145,6 +146,7 @@ message OMRequest {\n   optional DBUpdatesRequest                  dbUpdatesRequest              = 53;\n   optional FinalizeUpgradeRequest           finalizeUpgradeRequest         = 54;\n   optional FinalizeUpgradeProgressRequest   finalizeUpgradeProgressRequest = 55;\n+  optional PrepareRequest                   prepareRequest                 = 56;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjY5MDYwNg==", "bodyText": "The design doc and flow diagram are a bit inconsistent with usage of PrepareRequest or PrepareUpgradeRequest. We were initially planning on calling it PrepareUpgradeRequest during the design phase, but later decided that the command is not actually specific to upgrades. It will also be used for downgrades, and it is really a more general operation to clear out the OM logs, without any upgrade/downgrade specific actions in it. We opted to keep the name generic to reflect this.\n@avijayanhwx let me know if I missed anything here, and your current thoughts on the prepare vs. prepareUpgrade naming.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532690606", "createdAt": "2020-11-30T15:39:47Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -145,6 +146,7 @@ message OMRequest {\n   optional DBUpdatesRequest                  dbUpdatesRequest              = 53;\n   optional FinalizeUpgradeRequest           finalizeUpgradeRequest         = 54;\n   optional FinalizeUpgradeProgressRequest   finalizeUpgradeProgressRequest = 55;\n+  optional PrepareRequest                   prepareRequest                 = 56;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMzAxNw=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4MjgzMw==", "bodyText": "+1 to @errose28's comment. We can keep it \"prepare\" as a generic operation that can be used during upgrade, downgrade as well as creating checkpoint for supporting \"rollbacks\" in the future.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532782833", "createdAt": "2020-11-30T17:45:40Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -145,6 +146,7 @@ message OMRequest {\n   optional DBUpdatesRequest                  dbUpdatesRequest              = 53;\n   optional FinalizeUpgradeRequest           finalizeUpgradeRequest         = 54;\n   optional FinalizeUpgradeProgressRequest   finalizeUpgradeProgressRequest = 55;\n+  optional PrepareRequest                   prepareRequest                 = 56;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMzAxNw=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMTgzNg==", "bodyText": "Okay, get it.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533031836", "createdAt": "2020-12-01T02:28:05Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/interface-client/src/main/proto/OmClientProtocol.proto", "diffHunk": "@@ -145,6 +146,7 @@ message OMRequest {\n   optional DBUpdatesRequest                  dbUpdatesRequest              = 53;\n   optional FinalizeUpgradeRequest           finalizeUpgradeRequest         = 54;\n   optional FinalizeUpgradeProgressRequest   finalizeUpgradeProgressRequest = 55;\n+  optional PrepareRequest                   prepareRequest                 = 56;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjAxMzAxNw=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzODE5MDAxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOVQwNTo0MzowM1rOH7gbzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjozMDoyOFrOH8Vuqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg==", "bodyText": "Not a comment for this PR, another TODO thing I am thinking: After this prepare request be executed, OM should  reject subsequent requests immediately, how do we implement this? Exit OM and use upgrade flag to restart OM?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532159436", "createdAt": "2020-11-29T05:43:03Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjY4MjUyOA==", "bodyText": "Subsequent requests will be rejected by the leader using a gate in the preAppend step. This will will be done in another Jira. See HDDS-4470 for the design document and flow diagram of the overall prepare approach. This also documents how the upgrade startup flag or cancel prepare request (to be implemented in following Jiras) can be used to take the OM out of prepare mode.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532682528", "createdAt": "2020-11-30T15:29:22Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMjYxOA==", "bodyText": "Okay, will have a look for this. Thanks, @errose28 .", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533032618", "createdAt": "2020-12-01T02:30:28Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg=="}, "originalCommit": {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NzkzMDQ1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyNjoxOFrOH86JEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMDo0MToyNFrOH8-7-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw==", "bodyText": "Minor nit: Why isn't this externally configurable? Since we throw an IOException after waiting. For non-rolling upgrades probably unnecessary hence a minor nit.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533629203", "createdAt": "2020-12-01T18:26:18Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5MzYxMA==", "bodyText": "I can make this an external config if we think it is necessary. @avijayanhwx any thoughts here?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533693610", "createdAt": "2020-12-01T20:15:27Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNTM3OQ==", "bodyText": "We can add this as a passed in client side param, rather than an OM config. Something like\nozone admin om --prepare --wait-for-flush=2m\nThis will be added in subsequent JIRAs.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533705379", "createdAt": "2020-12-01T20:36:58Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNzc3MQ==", "bodyText": "Actually @avijayanhwx suggested offline we should probably make this a client side param later. Something like ozone om prepare --waitFor=1m.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533707771", "createdAt": "2020-12-01T20:41:24Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Nzk0NDAxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoyOTo1M1rOH86Rwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDo1Njo0NFrOH9F-qQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg==", "bodyText": "Minor nit: unused local references", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533631426", "createdAt": "2020-12-01T18:29:53Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NTYwNA==", "bodyText": "Which reference is unused, omRatisServer? It is used in the following two lines to construct the RaftServerImpl.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533695604", "createdAt": "2020-12-01T20:19:14Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NzMyOQ==", "bodyText": "server and serverImpl do not seem to be used, only a code readability comment, it makes the method more concise, can be inline with usage", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533697329", "createdAt": "2020-12-01T20:22:14Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNjA4MA==", "bodyText": "server is used to obtain serverImpl, which is passed to takeSnapshotAndPurgeLogs. I could collapse it, not sure if its more readable. It would look like this:\ntakeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n          .getImpl(omRatisServer.getRaftGroup().getGroupId()));", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533706080", "createdAt": "2020-12-01T20:38:19Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyMzE0NQ==", "bodyText": "Since typecasting is involved, lets leave this the way it is. It is more of a personal choice. Since the reference is utilized only once, I think it make sense to eliminate the reference, probably an interesting discussion for some other time :) Marking this as resolved.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533823145", "createdAt": "2020-12-02T00:56:44Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Nzk2NDQzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODozNToyNFrOH86ekQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMDoxOTo1MlrOH8-N2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDcwNQ==", "bodyText": "Can we add a comment here: What is the recovery step from this? If the snapshot index does not match will subsequent prepare ever succeed? cc: @avijayanhwx", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533634705", "createdAt": "2020-12-01T18:35:24Z", "author": {"login": "swagle"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NTk2MQ==", "bodyText": "If this fails, prepare will fail and an error response will be sent back to the client. I will add a comment to address this.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533695961", "createdAt": "2020-12-01T20:19:52Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDcwNQ=="}, "originalCommit": {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODg0MzE2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMjo0NjoxM1rOH9C6iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QyMjo1NzoyMlrOH-4_7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg==", "bodyText": "I believe there is a chance of snapshotIndex != lastAppliedTermIndex.\nBecause once doubleBuffer flush completes, it calls updateLastAppliedIndex from DoubleBuffer flush thread, to update lastAppliedIndex, but if doubleBuffer flush thread has not completed updateLastAppliedIndex updating, then this might not be equal.\nThere is very little chance to happen, as there is takeSnapshot which flush to DB, as updateLastAppliedIndex is inmemory map update.\nSo, to be safer side check lastAppliedTermIndex is the same as the TransactionInfo table lastAppliedIndex in the waitForDoubleBufferFlush method.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533772936", "createdAt": "2020-12-01T22:46:13Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2NzkyMA==", "bodyText": "The comment I put above this check is actually incorrect. This check is redundant since it is checking Ratis's in memory snapshot index against itself. It does not touch the transaction info table in the DB. I will remove this check.\n\ncheck lastAppliedTermIndex is the same as the TransactionInfo table lastAppliedIndex in the waitForDoubleBufferFlush method\n\nI believe the check we have in the waitForDoubleBufferFlush method provides the same guarantee. Let me know if there is any added benefit to putting this check there as well.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534467920", "createdAt": "2020-12-02T20:42:30Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzYzMA==", "bodyText": "I understand the issue now, sorry for the confusion about the original code. It looks like this did surface on the most recent CI integration test run. If I understand correctly, we should be waiting for both the lastAppliedIndex (Ratis's view) and the transaction index in the DB to update to the prepare request's index. There is no guarantee whether one or the other is updated first.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r535707630", "createdAt": "2020-12-03T22:57:22Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODg4NzE4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzowMTowM1rOH9DWCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo0Mjo0MFrOH9tVrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3OTk3OA==", "bodyText": "Minor: We can pass the serverImpl which we got in L106 to takeSnapshotAndPurgeLogs", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533779978", "createdAt": "2020-12-01T23:01:03Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2ODAxNA==", "bodyText": "Will do", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534468014", "createdAt": "2020-12-02T20:42:40Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3OTk3OA=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODg5NzYyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzowNTowM1rOH9DcxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo0NToyOVrOH9tcAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MTcwMA==", "bodyText": "Why we need to return success in this case, because when PrepareRequest is added to double-buffer that mean double-buffer will flush the transaction of PrepareRequest to DB, even if there is no request to OM at all.\nAnd also not understood the reason for the null pointer exception part", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533781700", "createdAt": "2020-12-01T23:05:03Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2OTYzNQ==", "bodyText": "This left over from an earlier implementation where the prepare request was not part of the snapshot and the passed txnLogIndex could be 0 if prepare was the first request. Now that we add the response to the double buffer before calling this method, this logic is more of an extra step for completeness so passing 0 as txnLogIndex does not yield incorrect behavior, even though we are not doing that right now. I will tweak this to be more apparent.\nEven if we add the response to the double buffer before calling this method, it may not (and usually does not) make it to the DB by the first check, meaning a get on the TRANSACTION_INFO_KEY will return null and should be handled anyways.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534469635", "createdAt": "2020-12-02T20:45:29Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MTcwMA=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODkyODU2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzoxNTo1MVrOH9DwBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo1ODoyN1rOH9t4YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjYyOQ==", "bodyText": "Question: According to design flow, in preAppend we set the prepare flag to true so that no new transactions will be accepted. In which scenario will we have logs more than snapshotIndex and if we purge them those requests will not receive any response from OM leader and timed out?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786629", "createdAt": "2020-12-01T23:15:51Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +\n+          \"Index\");\n+    }\n+\n+    RaftLog raftLog = impl.getState().getLog();\n+    // In order to get rid of all logs, make sure we also account for\n+    // intermediate Ratis entries that do not pertain to OM.\n+    long lastIndex = Math.max(snapshotIndex,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3Njg5Ng==", "bodyText": "This was originally done defensively against meta transactions that Ratis may put in the log, which are not related to OM activities. @avijayanhwx and I are unable to reproduce earlier errors we thought we saw related to this, so we will remove this max statement and just use snapshotIndex. If an error surfaces later under more robust prepare and upgrade testing, we will re-address this issue, but for now we can remove it to avoid unintended side effects this might cause.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534476896", "createdAt": "2020-12-02T20:58:27Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +\n+          \"Index\");\n+    }\n+\n+    RaftLog raftLog = impl.getState().getLog();\n+    // In order to get rid of all logs, make sure we also account for\n+    // intermediate Ratis entries that do not pertain to OM.\n+    long lastIndex = Math.max(snapshotIndex,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjYyOQ=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODkyOTY5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/upgrade/OMPrepareResponse.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzoxNjoyMlrOH9DwwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo0NjoyNFrOH9td_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjgxNg==", "bodyText": "Why cleanupAll is true in this case, as this has not touched any DB, so it can be false right?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786816", "createdAt": "2020-12-01T23:16:22Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/upgrade/OMPrepareResponse.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.upgrade;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Response for prepare request.\n+ */\n+@CleanupTableInfo(cleanupAll = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3MDE0MQ==", "bodyText": "Yes, we can actually just set this to false.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534470141", "createdAt": "2020-12-02T20:46:24Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/upgrade/OMPrepareResponse.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.upgrade;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Response for prepare request.\n+ */\n+@CleanupTableInfo(cleanupAll = true)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjgxNg=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0ODk0Mzg1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQyMzoyMTo0MlrOH9D5dA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMTo0NTowMlrOH9HC2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4OTA0NA==", "bodyText": "In design flow, the prepare flag is set in preAppend will that be handled in a seperate Jira?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533789044", "createdAt": "2020-12-01T23:21:42Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg0MDYwMQ==", "bodyText": "Yes, in follow up JIRAs, the 'Prepared' OM state maintenance and the gate for stopping other requests will be added.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533840601", "createdAt": "2020-12-02T01:45:02Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4OTA0NA=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTEwNTE3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDoyNzowOVrOH9FVwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMDo1MDowOVrOH9tlxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjY3Mg==", "bodyText": "Is this failing test that needs more changes?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533812672", "createdAt": "2020-12-02T00:27:09Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,326 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OMRatisHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.Message;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+  private final int timeoutMillis = 30000;\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Make sure all OMs have logs from writing data, so we can check that\n+    // they are purged after prepare.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      LambdaTestUtils.await(timeoutMillis, 1000,\n+          () -> logFilesPresentInRatisPeer(om));\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3MjEzMg==", "bodyText": "I could not get this test to work without client side changes. Once those are implemented by @avijayanhwx, we will use them to implement more robust integration tests with failures. This is left here for reference to come back to.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534472132", "createdAt": "2020-12-02T20:50:09Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,326 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OMRatisHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.Message;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+  private final int timeoutMillis = 30000;\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Make sure all OMs have logs from writing data, so we can check that\n+    // they are purged after prepare.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      LambdaTestUtils.await(timeoutMillis, 1000,\n+          () -> logFilesPresentInRatisPeer(om));\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjY3Mg=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTExMTcwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMDoyOTo0NlrOH9FZeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMTo0NjoxMlrOH9HEgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMzYyNA==", "bodyText": "Offline discussion with @avijayanhwx this part of logic will be revisited in next jiras, if another PrepareUpgrade request is let in, we cleanup logIndexes greater than snapshotIndex and also syncWithSnapshot does not close when end logIndex is greater than snapshotIndex, so that might be left out.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533813624", "createdAt": "2020-12-02T00:29:46Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg0MTAyNQ==", "bodyText": "Yes, +1.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533841025", "createdAt": "2020-12-02T01:46:12Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMzYyNA=="}, "originalCommit": {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjA3NzgxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMjo1NzozMVrOH_lRJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzoyOTo0NFrOH_l63A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ==", "bodyText": "Right now adding this logic might have issue, as there is no safeguard logic to not allow further requests after PUR.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536432935", "createdAt": "2020-12-04T22:57:31Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MjM3MQ==", "bodyText": "@bharatviswa504 That will be the next work item in the prepare OM feature.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536442371", "createdAt": "2020-12-04T23:25:37Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}, "originalCommit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MjUwMw==", "bodyText": "Right. The gate to stop further write transactions will be added in a later Jira. This is added in anticipation of that feature. Current testing acknowledges that the gate does not exist by not submitting requests after prepare.  Basically this whole pull request will have issues under a real use case without the gate, which is why this is part of a larger feature off of the master branch.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536442503", "createdAt": "2020-12-04T23:26:03Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}, "originalCommit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MzYxMg==", "bodyText": "Makes sense, thanks for the clear explanation.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536443612", "createdAt": "2020-12-04T23:29:44Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}, "originalCommit": {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjA4MzY4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMjo1OTo1M1rOH_lUQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzo1MDozOFrOH_mSeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ==", "bodyText": "When PUR is flushed, in DB of transactionInfo table still it is null means something wrong right?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536433729", "createdAt": "2020-12-04T22:59:53Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MDI0NA==", "bodyText": "Yes, when it is flushed. But this is the method that is waiting for the flush. The flush has not necessarily completed by the first run of this loop. It is possible that when prepare is the first transaction to the DB, this method call happens before its flush completes, and on the first (few) iterations of the loop, the transaction info table is empty and dbTxnInfo will be null. Once the flush completes, dbTxnInfo will no longer be null on later loop iterations.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536440244", "createdAt": "2020-12-04T23:18:38Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MzQ0NQ==", "bodyText": "Ohh misread the condition indexToWaitFor==0, indexTowaitFor will never be zero, so in case when doubleBuffer flush fails to flush this condition is not met. Is my understanding correct?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536443445", "createdAt": "2020-12-04T23:29:14Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NDI1NQ==", "bodyText": "Or simply here, we can have if dbTxnInfo success=false right?", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536444255", "createdAt": "2020-12-04T23:31:37Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTY1OA==", "bodyText": "Right, the condition should never be met. Because of that, we could just set success = false when the dbTxnInfo is null, but since we have to do the null check anyways, I figured it was better to add a line to handle the case correctly, even if it should never arise.", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536449658", "createdAt": "2020-12-04T23:50:38Z", "author": {"login": "errose28"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, "originalCommit": {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4509, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}