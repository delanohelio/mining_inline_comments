{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzODc5NzM5", "number": 633, "title": "HDDS-3123. Create REST API to serve Pipeline information and integrate with UI in Recon", "bodyText": "What changes were proposed in this pull request?\n\nAdd REST endpoint in Recon Server to get Pipeline information\nIntegrate Pipelines page in Recon UI with REST endpoint\nAdd unit tests and acceptance tests\nShow more information about pipelines in Datanodes page in Recon UI\n\nWhat is the link to the Apache JIRA\nhttps://issues.apache.org/jira/browse/HDDS-3123\nHow was this patch tested?\nPatch was tested with unit, acceptance tests and manually by bringing up ozone using docker-compose with 6 datanodes.\nAttached are screenshots of Pipelines page and Datanodes page in Recon UI with this patch:", "createdAt": "2020-03-04T21:09:15Z", "url": "https://github.com/apache/ozone/pull/633", "merged": true, "mergeCommit": {"oid": "ee29b16245b903bdbc8f2858b7d50b9319f5e364"}, "closed": true, "closedAt": "2020-03-05T19:10:37Z", "author": {"login": "vivekratnavel"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKdassAH2gAyMzgzODc5NzM5OmJlYjlmNmQ0YTY2NTE0NzllODY1ZDE3N2EwOGNhNDlmZGI1OGU5ZTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcKwZV_gFqTM2OTgzMzU3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "author": {"user": {"login": "vivekratnavel", "name": "Vivek Ratnavel Subramanian"}}, "url": "https://github.com/apache/ozone/commit/beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "committedDate": "2020-03-04T21:01:44Z", "message": "Create REST API to serve Pipeline information and integrate with UI in Recon"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTQ1OTIy", "url": "https://github.com/apache/ozone/pull/633#pullrequestreview-369145922", "createdAt": "2020-03-04T21:45:01Z", "commit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0NTowMVrOFx-v8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMjowNToxM1rOFx_XXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MjYyNg==", "bodyText": "Can we make sure this is not flaky? Since the pipelines are created by SCM, onto Datanodes and then reaches Recon through heartbeats, there will be a lag between Recon container starting up, and having the pipelines available.  (Same may be true for Datanodes test above this)", "url": "https://github.com/apache/ozone/pull/633#discussion_r387952626", "createdAt": "2020-03-04T21:45:01Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/dist/src/main/smoketest/recon/recon-api.robot", "diffHunk": "@@ -34,6 +34,13 @@ Recon REST API\n                         Should contain      ${result}       ozone_datanode_1.ozone_default\n                         Should contain      ${result}       ozone_datanode_2.ozone_default\n                         Should contain      ${result}       ozone_datanode_3.ozone_default\n+    ${result} =         Execute                             curl --negotiate -u : -v ${API_ENDPOINT_URL}/pipelines\n+                        Should contain      ${result}       pipelines\n+                        Should contain      ${result}       RATIS\n+                        Should contain      ${result}       OPEN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MzkyMw==", "bodyText": "Nit: Can use something like lambda forEach.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387953923", "createdAt": "2020-03-04T21:47:39Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDIyNQ==", "bodyText": "Log the exception message here if not already logged further down the stack.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954225", "createdAt": "2020-03-04T21:48:10Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDczMg==", "bodyText": "Nit: Lambda.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954732", "createdAt": "2020-03-04T21:49:14Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NzQ0Nw==", "bodyText": "Seems like a lot of duplicated code between the 2 endpoint Test classes. Can we move this Test into the other class? We don't necessarily need a unit test for every endpoint class.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387957447", "createdAt": "2020-03-04T21:54:31Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import com.google.inject.AbstractModule;\n+import com.google.inject.Guice;\n+import com.google.inject.Injector;\n+import com.google.inject.Singleton;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.PipelineID;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.NodeReportProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReport;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.SCMHeartbeatRequestProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.GuiceInjectorUtilsForTestsImpl;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.persistence.AbstractSqlDatabaseTest;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.hadoop.ozone.recon.schema.ReconTaskSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.ReconTaskStatusDao;\n+import org.jooq.Configuration;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import javax.ws.rs.core.Response;\n+\n+import static org.apache.hadoop.hdds.protocol.MockDatanodeDetails.randomDatanodeDetails;\n+import static org.apache.hadoop.hdds.recon.ReconConfigKeys.OZONE_RECON_DATANODE_ADDRESS_KEY;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/**\n+ * Test for Pipeline Endpoint.\n+ */\n+public class TestPipelineEndpoint extends AbstractSqlDatabaseTest {\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private PipelineEndpoint pipelineEndpoint;\n+  private ReconStorageContainerManagerFacade reconScm;\n+  private boolean isSetupDone = false;\n+  private String pipelineId;\n+  private DatanodeDetails datanodeDetails;\n+  private GuiceInjectorUtilsForTestsImpl guiceInjectorTest =\n+      new GuiceInjectorUtilsForTestsImpl();\n+  private DatanodeDetailsProto datanodeDetailsProto;\n+  private ContainerReportsProto containerReportsProto;\n+  private long containerId = 1L;\n+  private Pipeline pipeline;\n+  private void initializeInjector() {\n+\n+    Injector injector = Guice.createInjector(new AbstractModule() {\n+      @Override\n+      protected void configure() {\n+        try {\n+          datanodeDetails = randomDatanodeDetails();\n+          pipeline = getRandomPipeline(datanodeDetails);\n+          pipelineId = pipeline.getId().getId().toString();\n+\n+          Configuration sqlConfiguration =\n+              getInjector().getInstance((Configuration.class));\n+\n+          ContainerInfo containerInfo = new ContainerInfo.Builder()\n+              .setContainerID(containerId)\n+              .setReplicationFactor(ReplicationFactor.ONE)\n+              .setState(LifeCycleState.OPEN)\n+              .setOwner(\"test\")\n+              .setPipelineID(pipeline.getId())\n+              .setReplicationType(ReplicationType.RATIS)\n+              .build();\n+          ContainerWithPipeline containerWithPipeline =\n+              new ContainerWithPipeline(containerInfo, pipeline);\n+\n+          ReconTaskSchemaDefinition taskSchemaDefinition = getInjector()\n+              .getInstance(ReconTaskSchemaDefinition.class);\n+          taskSchemaDefinition.initializeSchema();\n+\n+          ReconTaskStatusDao reconTaskStatusDao =\n+              new ReconTaskStatusDao(sqlConfiguration);\n+          MissingContainersDao missingContainersDao =\n+              new MissingContainersDao(sqlConfiguration);\n+\n+          bind(ReconTaskStatusDao.class).toInstance(reconTaskStatusDao);\n+          bind(MissingContainersDao.class).toInstance(missingContainersDao);\n+\n+          StorageContainerLocationProtocol mockScmClient = mock(\n+              StorageContainerLocationProtocol.class);\n+          StorageContainerServiceProvider mockScmServiceProvider = mock(\n+              StorageContainerServiceProviderImpl.class);\n+          when(mockScmServiceProvider.getPipeline(\n+              pipeline.getId().getProtobuf())).thenReturn(pipeline);\n+          when(mockScmServiceProvider.getContainerWithPipeline(containerId))\n+              .thenReturn(containerWithPipeline);\n+\n+          OzoneConfiguration testOzoneConfiguration =\n+              guiceInjectorTest.getTestOzoneConfiguration(temporaryFolder);\n+          testOzoneConfiguration.set(OZONE_RECON_DATANODE_ADDRESS_KEY,\n+              \"0.0.0.0:0\");\n+          bind(OzoneConfiguration.class).toInstance(testOzoneConfiguration);\n+          bind(StorageContainerLocationProtocol.class)\n+              .toInstance(mockScmClient);\n+          bind(StorageContainerServiceProvider.class)\n+              .toInstance(mockScmServiceProvider);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1OTUyMw==", "bodyText": "Shouldn't this just be IOException? From\npublic DatanodeDetails getLeaderNode() throws IOException {.\nWhy do we need to set leaderNode to \"\" on exception? It can be null, and handled in the UI maybe.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387959523", "createdAt": "2020-03-04T21:58:46Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MDI4NA==", "bodyText": "PipelineMetadata constructor looks like it is taking in a lot of parameters. A Builder may be better.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387960284", "createdAt": "2020-03-04T22:00:13Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {\n+        datanodes.add(datanode.getHostName());\n+      }\n+\n+      PipelineMetadata pipelineMetadata = new PipelineMetadata(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MjcxOA==", "bodyText": "Can we keep the type of 'pipelineID' as UUID? Since the Pipeline endpoint uses UUID.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387962718", "createdAt": "2020-03-04T22:05:13Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+/**\n+ * Metadata object that contains pipeline information of a Datanode.\n+ */\n+public class DatanodePipeline {\n+  private String pipelineID;\n+  private String replicationType;\n+  private int replicationFactor;\n+\n+  public DatanodePipeline(String pipelineID, String replicationType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 28}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "382791a35985e75cac0d3dddd735a10f753ef215", "author": {"user": {"login": "vivekratnavel", "name": "Vivek Ratnavel Subramanian"}}, "url": "https://github.com/apache/ozone/commit/382791a35985e75cac0d3dddd735a10f753ef215", "committedDate": "2020-03-05T01:00:32Z", "message": "Address Review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5ODMzNTc2", "url": "https://github.com/apache/ozone/pull/633#pullrequestreview-369833576", "createdAt": "2020-03-05T19:02:36Z", "commit": {"oid": "382791a35985e75cac0d3dddd735a10f753ef215"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMjozNlrOFygDvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMjozNlrOFygDvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5ODM2Nw==", "bodyText": "minor nit. To be consistent with terminology, we can keep it as \"state\" instead of \"status\".", "url": "https://github.com/apache/ozone/pull/633#discussion_r388498367", "createdAt": "2020-03-05T19:02:36Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState;\n+\n+import javax.xml.bind.annotation.XmlAccessType;\n+import javax.xml.bind.annotation.XmlAccessorType;\n+import javax.xml.bind.annotation.XmlElement;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Metadata object that represents a Pipeline.\n+ */\n+@XmlAccessorType(XmlAccessType.FIELD)\n+public class PipelineMetadata {\n+\n+  @XmlElement(name = \"pipelineId\")\n+  private UUID pipelineId;\n+\n+  @XmlElement(name = \"status\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "382791a35985e75cac0d3dddd735a10f753ef215"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3681, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}