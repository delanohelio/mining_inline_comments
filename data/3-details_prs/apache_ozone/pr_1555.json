{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE2NTQyMjM0", "number": 1555, "title": "HDDS-4347.Make Ozone specific Trash remover multi threaded", "bodyText": "What changes were proposed in this pull request?\nThis change makes the Trash Emptier multithreaded. i.e the main emptier thread starts a thread pool executor and executes tasks (checkpointing and deletion) present in the task queue. the parallelism is obtained at the  bucket level as fs.trashRoots for a root OFS URI returns a list of bucket level trashroots.\nWhat is the link to the Apache JIRA\nhttps://issues.apache.org/jira/browse/HDDS-4347\nHow was this patch tested?\nAdded unit tests and tested manually", "createdAt": "2020-11-06T06:42:55Z", "url": "https://github.com/apache/ozone/pull/1555", "merged": true, "mergeCommit": {"oid": "e6712119a03f4e00094f9b46a0b7edc27a964035"}, "closed": true, "closedAt": "2021-01-04T13:26:13Z", "author": {"login": "sadanand48"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbX1H_AFqTUyNzg4OTQ3NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdsyncDAH2gAyNTE2NTQyMjM0OmYxZmM1ZDgwM2Y3OGI3MWE5MTUxMjBmOGY1OTk5MDg1MzhlNTg0OWE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3ODg5NDc1", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-527889475", "createdAt": "2020-11-11T06:19:02Z", "commit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoxOTowMlrOHw_nOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoxOTowMlrOHw_nOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNTkyOQ==", "bodyText": "Please remove the * imports", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521135929", "createdAt": "2020-11-11T06:19:02Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3ODg5ODE2", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-527889816", "createdAt": "2020-11-11T06:20:00Z", "commit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoyMDowMVrOHw_oYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwNjoyMDowMVrOHw_oYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg==", "bodyText": "Why do we need to copy these functions? Is it doing anything special with respect to ozone\n/", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521136226", "createdAt": "2020-11-11T06:20:01Z", "author": {"login": "bshashikant"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "49dec78ee794e898a0c083927238ec036131d1e8"}, "originalPosition": 207}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTk0MjA0", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-532994204", "createdAt": "2020-11-18T02:10:42Z", "commit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxMDo0M1rOH1TD9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMjoxNjozMFrOH1TSuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0ODg4Nw==", "bodyText": "why are these tests commented out ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525648887", "createdAt": "2020-11-18T02:10:43Z", "author": {"login": "prashantpogde"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,19 +210,19 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)\n   public void testFileSystem() throws Exception {\n     setupOzoneFileSystem();\n \n     testOzoneFsServiceLoader();\n     o3fs = (OzoneFileSystem) fs;\n \n-    testCreateFileShouldCheckExistenceOfDirWithSameName();\n+  /*  testCreateFileShouldCheckExistenceOfDirWithSameName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MjY2Nw==", "bodyText": "this check should be inside run method in TrashPolicyOzone. I also do not see a problem if it was run on all OM nodes.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525652667", "createdAt": "2020-11-18T02:16:30Z", "author": {"login": "prashantpogde"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1228,17 +1238,61 @@ public void restart() throws IOException {\n       // Allow OM to start as Http Server failure is not fatal.\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n-\n     omRpcServer.start();\n+\n     isOmRpcServerRunning = true;\n \n+    if (isLeader()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNDE4MTcy", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-533418172", "createdAt": "2020-11-18T12:58:06Z", "commit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMjo1ODowNlrOH1sg6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMjo1ODowNlrOH1sg6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2NTg5Ng==", "bodyText": "Can we try to catch Exception rather than IOException to avoid uncaught exception that may be swallowed here?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526065896", "createdAt": "2020-11-18T12:58:06Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 177}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzNDQ1MjIw", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-533445220", "createdAt": "2020-11-18T13:29:38Z", "commit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMzoyOTozOFrOH1t1_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxMzoyOTozOFrOH1t1_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA4NzY3OA==", "bodyText": "Can we shutdown executor pool in the finally block?\n        try {\n             while (true) {\n                 ....\n             }\n         } finally {\n            shutdown executor pool.\n         }", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526087678", "createdAt": "2020-11-18T13:29:38Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0"}, "originalPosition": 198}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d455115f71f3634442048527ad6fdadefbd5d5a0", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/d455115f71f3634442048527ad6fdadefbd5d5a0", "committedDate": "2020-11-12T18:53:19Z", "message": "added more tests"}, "afterCommit": {"oid": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "committedDate": "2020-11-18T13:41:51Z", "message": "Rebase changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1MjczMTQw", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-535273140", "createdAt": "2020-11-20T09:45:03Z", "commit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTo0NTowM1rOH3IXbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMjo1NTowM1rOH3Okxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3MDc5Ng==", "bodyText": "why do we need to increase the timeout ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527570796", "createdAt": "2020-11-20T09:45:03Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,7 +209,7 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTM5MA==", "bodyText": "This should be outside the runnable function.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671390", "createdAt": "2020-11-20T12:52:46Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n-              try {\n-                TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n-                trash.deleteCheckpoint(trashRoot.getPath(), false);\n-                trash.createCheckpoint(trashRoot.getPath(), new Date(now));\n-              } catch (IOException e) {\n-                LOG.warn(\"Trash caught: \"+e+\". Skipping \" +\n-                    trashRoot.getPath() + \".\");\n-              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTYxMg==", "bodyText": "Same as above.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671612", "createdAt": "2020-11-20T12:53:13Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTc0NA==", "bodyText": "Please change the LOG.info to LOG.debug", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671744", "createdAt": "2020-11-20T12:53:29Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjE5OA==", "bodyText": "We also need to do executor.awaitTermination as well here.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672198", "createdAt": "2020-11-20T12:54:27Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -139,9 +159,12 @@ public void run() {\n         fs.close();\n       } catch(IOException e) {\n         LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      } finally {\n+        executor.shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjUxOA==", "bodyText": "Please change this to great from a config.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672518", "createdAt": "2020-11-20T12:55:03Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -49,6 +53,8 @@\n \n   private static final Path CURRENT = new Path(\"Current\");\n \n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62383d005e00ab9b355e21bd9942c067b135606a"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4Nzg0NzQz", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-538784743", "createdAt": "2020-11-25T19:13:41Z", "commit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxMTU0MTE4", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-541154118", "createdAt": "2020-11-30T17:54:10Z", "commit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1NDoxMFrOH8G0zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1NTo1MFrOH8G5KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODQyOA==", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_CHECKPOINT_INTERVAL_KEY here", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788428", "createdAt": "2020-11-30T17:54:10Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.checkpoint.interval\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODY4Mg==", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_INTERVAL_KEY here", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788682", "createdAt": "2020-11-30T17:54:32Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ==", "bodyText": "I think this is intentional. @elek @bharatviswa504 can you please confirm this line ?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532789545", "createdAt": "2020-11-30T17:55:50Z", "author": {"login": "mukul1987"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1275,7 +1275,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new Configuration();\n+    Configuration fsconf = new OzoneConfiguration();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa19ae01045398828a93de9388839abb127adfe7"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NTA4OTc2", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-545508976", "createdAt": "2020-12-05T08:34:34Z", "commit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNDozNFrOH_tC9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwODozNzo1OVrOH_tMrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2MDM3NQ==", "bodyText": "Can you please use Java, annotation based configuration?", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536560375", "createdAt": "2020-12-05T08:34:34Z", "author": {"login": "elek"}, "path": "hadoop-hdds/common/src/main/resources/ozone-default.xml", "diffHunk": "@@ -1907,6 +1907,15 @@\n     </description>\n   </property>\n \n+  <property>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2Mjg2MA==", "bodyText": "I know it's committed in the previous commit, but can you please help me to understand why do we need FileSystem in OM side? As far as I understood the design doc has more cons against this approach.", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536562860", "createdAt": "2020-12-05T08:37:59Z", "author": {"login": "elek"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +128,23 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d28ee25d6adc25a9802badce75bca1705f41f055"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "committedDate": "2020-12-14T16:19:52Z", "message": "resolve conflicts"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "423afa2411fe5b9db6a02642a8a08f41b3638dc1", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/423afa2411fe5b9db6a02642a8a08f41b3638dc1", "committedDate": "2020-12-14T15:06:04Z", "message": "resolved conflicts"}, "afterCommit": {"oid": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "committedDate": "2020-12-14T16:19:52Z", "message": "resolve conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8aecec9de30ad4b1b01aeac1a458c87f89c92310", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/8aecec9de30ad4b1b01aeac1a458c87f89c92310", "committedDate": "2020-12-14T16:33:23Z", "message": "remove * import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwNTcwMzMy", "url": "https://github.com/apache/ozone/pull/1555#pullrequestreview-560570332", "createdAt": "2021-01-01T04:59:48Z", "commit": {"oid": "8aecec9de30ad4b1b01aeac1a458c87f89c92310"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cea401d8cb7de66cacadbd20b4fc5b54e91726d", "author": {"user": {"login": "mukul1987", "name": "Mukul Kumar Singh"}}, "url": "https://github.com/apache/ozone/commit/5cea401d8cb7de66cacadbd20b4fc5b54e91726d", "committedDate": "2021-01-01T05:01:39Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "723af8a4e49a0deeebed14ebe3c691ad96a330fb", "author": {"user": {"login": "mukul1987", "name": "Mukul Kumar Singh"}}, "url": "https://github.com/apache/ozone/commit/723af8a4e49a0deeebed14ebe3c691ad96a330fb", "committedDate": "2021-01-01T05:02:23Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bcd1fd1d08c55394727672be000bf28bd80cf6d7", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/bcd1fd1d08c55394727672be000bf28bd80cf6d7", "committedDate": "2021-01-02T06:19:15Z", "message": "resolve test failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e3c1a99240a0976fe7d39892a55b3d1d5a0d324", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/2e3c1a99240a0976fe7d39892a55b3d1d5a0d324", "committedDate": "2021-01-02T07:37:15Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca071209c860ab45ef7e393d2857cce47238b99e", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/ca071209c860ab45ef7e393d2857cce47238b99e", "committedDate": "2021-01-04T06:55:06Z", "message": "trigger new CI check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1fc5d803f78b71a915120f8f599908538e5849a", "author": {"user": {"login": "sadanand48", "name": "Sadanand Shenoy"}}, "url": "https://github.com/apache/ozone/commit/f1fc5d803f78b71a915120f8f599908538e5849a", "committedDate": "2021-01-04T09:08:14Z", "message": "trigger new CI check"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2240, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}