{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0Njc4ODcy", "number": 1607, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxNToxODo1NVrOE7lZ-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOToxNjozNFrOFAs_sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwOTE0Mjk3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxNToxODo1NVrOH3T_0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjoxNTo1OVrOH6Jgyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MTM2MQ==", "bodyText": "HI @rakeshadr , current PR change hasn't implemented recursively delete, right?\nFrom a quick review of this, it implements the delete semantic for deleting a single dir or a file.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r527761361", "createdAt": "2020-11-20T15:18:55Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODQ1MTExNg==", "bodyText": "Thanks a lot @linyiqun for the reviews.\nThis patch is removing the given keyPath from the DirTable(if its a dir) or from the KeyTable(if its a file). Presently, it is not checking whether the dir is empty or not then handle it based on recursive flag.\nNeed to implement: Point-1: I've to pass the 'recursive' flag to the OM then throw OMException(\"Directory is not empty\") if recursive==true && keyPath#isNotEmptyDir(). This I will do in current PR on next commit.\nNeed to implement: Point-2: Like I mentioned in the description, once the given keyPath is removed it requires cleanup of sub-dirs/files for a non-empty parent. Since the parent doesn't exists the traversal logic will not be able to find its children. For example: '/a/b/c/d/e/file1'. Now user deletes '/b' , then the key entry '/b=' will be removed on the user call path. Assume parentID=1023 and objectID=1024. Deletion of '1023/b=1024' key hides all its children and become orphan. '1024/c'. Now, these garbage has to cleaned up async way and can be done via HDDS-4495.\nNeed to implement: Point-3: Also, for the above point-2, it has to modify the existing KeyDeletingService to delete all the file-blocks. I will analyse these flow during HDDS-4495 implementation then will handle it based on the complexity.\nIMHO, Point-2 & Point-3 can be done separately as its not affecting the functionality of recursive or non-recursive deletion. Does this make sense to you?", "url": "https://github.com/apache/ozone/pull/1607#discussion_r528451116", "createdAt": "2020-11-23T02:58:31Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MTM2MQ=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODcyMjkyMg==", "bodyText": "@rakeshadr , sounds good to me. Please go ahead for this, : ).", "url": "https://github.com/apache/ozone/pull/1607#discussion_r528722922", "createdAt": "2020-11-23T14:01:13Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MTM2MQ=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk2NzM3Ng==", "bodyText": "I think here\nif recursive==false, and directory is not empty we should throw OMException(\"Directory is not empty\")\nif recursive==true, directory is empty or not, we should delete directory.\nCurrent Code in BasicOzoneFileSystem.java:\nif (getStatus().isDirectory()\n          && !this.recursive\n          && listStatus(f).length != 0) {\n        throw new PathIsNotEmptyDirectoryException(f.toString());\n      }\n\nJavadoc:\n   * @param recursive if path is a directory and set to\n   * true, the directory is deleted else throws an exception. In\n   * case of a file the recursive can be set to either true or false.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r529967376", "createdAt": "2020-11-24T22:52:23Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MTM2MQ=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczNTMwNg==", "bodyText": "Yes, agreed. I will make this way:-)", "url": "https://github.com/apache/ozone/pull/1607#discussion_r530735306", "createdAt": "2020-11-26T02:15:59Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MTM2MQ=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzc1NTUzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMjo1NzoxMlrOH5a8ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjoxNjozNVrOH6Jhbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3MjMzMA==", "bodyText": "Minor: Can we add KeyName also as part of the exception message.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r529972330", "createdAt": "2020-11-24T22:57:12Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczNTQ3MA==", "bodyText": "Sure, will add it", "url": "https://github.com/apache/ozone/pull/1607#discussion_r530735470", "createdAt": "2020-11-26T02:16:35Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3MjMzMA=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzc2ODI1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMjo1OToyM1rOH5bE5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwNTo0MDowNFrOH96i8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3NDUwMw==", "bodyText": "In case of directory OmKeyInfo will not have any blocks,\nWe need to get the bytesUsed from all the keys in the directory, but if we do that it will be an expensive operation.\nJust some thought: Might be also update byteUsed at directory level also, so we can sum up all byteUsed at directory level. Need to think more here.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r529974503", "createdAt": "2020-11-24T22:59:23Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);\n+      }\n+\n+      OmKeyInfo omKeyInfo = keyStatus.getKeyInfo();\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      String ozonePathKey = omMetadataManager.getOzonePathKey(\n+              omKeyInfo.getParentObjectID(), omKeyInfo.getFileName());\n+\n+      if (keyStatus.isDirectory()) {\n+        // Update dir cache.\n+        omMetadataManager.getDirectoryTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      } else {\n+        // Update table cache.\n+        omMetadataManager.getKeyTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      }\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+\n+      long quotaReleased = sumBlockLengths(omKeyInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MTE1NQ==", "bodyText": "There is a discussion going on to remove bytesUsed from VolumeArgs once HDDS-4308, we might need to revisit once after that went in.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r529981155", "createdAt": "2020-11-24T23:05:56Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);\n+      }\n+\n+      OmKeyInfo omKeyInfo = keyStatus.getKeyInfo();\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      String ozonePathKey = omMetadataManager.getOzonePathKey(\n+              omKeyInfo.getParentObjectID(), omKeyInfo.getFileName());\n+\n+      if (keyStatus.isDirectory()) {\n+        // Update dir cache.\n+        omMetadataManager.getDirectoryTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      } else {\n+        // Update table cache.\n+        omMetadataManager.getKeyTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      }\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+\n+      long quotaReleased = sumBlockLengths(omKeyInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3NDUwMw=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MDAwMg==", "bodyText": "HDDS-4308 was resolved , volume used bytes is not used. Please have a look for this RP fix #1489\nCurrent new implementation way:\n\nFor now we no longer need to check the Quota of Volume. Because we have ensured that all bucket quota and do not exceed volume quota when we set bucket and volume quota. Therefore, to write a key under a bucket, we simply check bucket quota. Volume's quota will naturally not exceed as long as the bucket's quota checks pass.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r530740002", "createdAt": "2020-11-26T02:34:02Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);\n+      }\n+\n+      OmKeyInfo omKeyInfo = keyStatus.getKeyInfo();\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      String ozonePathKey = omMetadataManager.getOzonePathKey(\n+              omKeyInfo.getParentObjectID(), omKeyInfo.getFileName());\n+\n+      if (keyStatus.isDirectory()) {\n+        // Update dir cache.\n+        omMetadataManager.getDirectoryTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      } else {\n+        // Update table cache.\n+        omMetadataManager.getKeyTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      }\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+\n+      long quotaReleased = sumBlockLengths(omKeyInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3NDUwMw=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDY4NDQwMw==", "bodyText": "Thanks for pointing out this. It requires more wider changes. I've raised HDDS-4321 to revisit and correct all the places in the branch.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r534684403", "createdAt": "2020-12-03T05:40:04Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequestV1.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.key;\n+\n+import com.google.common.base.Optional;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheKey;\n+import org.apache.hadoop.hdds.utils.db.cache.CacheValue;\n+import org.apache.hadoop.ozone.audit.AuditLogger;\n+import org.apache.hadoop.ozone.audit.OMAction;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.OMMetrics;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.helpers.OzoneFileStatus;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.file.OMFileRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.key.OMKeyDeleteResponseV1;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.DeleteKeyResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.security.acl.IAccessAuthorizer;\n+import org.apache.hadoop.ozone.security.acl.OzoneObj;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import static org.apache.hadoop.ozone.om.exceptions.OMException.ResultCodes.KEY_NOT_FOUND;\n+import static org.apache.hadoop.ozone.om.lock.OzoneManagerLock.Resource.BUCKET_LOCK;\n+\n+/**\n+ * Handles DeleteKey request layout version V1.\n+ */\n+public class OMKeyDeleteRequestV1 extends OMKeyDeleteRequest {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMKeyDeleteRequestV1.class);\n+\n+  public OMKeyDeleteRequestV1(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"methodlength\")\n+  public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n+      long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n+    DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n+\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n+        deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n+\n+    String volumeName = keyArgs.getVolumeName();\n+    String bucketName = keyArgs.getBucketName();\n+    String keyName = keyArgs.getKeyName();\n+\n+    OMMetrics omMetrics = ozoneManager.getMetrics();\n+    omMetrics.incNumKeyDeletes();\n+\n+    AuditLogger auditLogger = ozoneManager.getAuditLogger();\n+    OzoneManagerProtocolProtos.UserInfo userInfo = getOmRequest().getUserInfo();\n+\n+    OMResponse.Builder omResponse = OmResponseUtil.getOMResponseBuilder(\n+        getOmRequest());\n+    OMMetadataManager omMetadataManager = ozoneManager.getMetadataManager();\n+    IOException exception = null;\n+    boolean acquiredLock = false;\n+    OMClientResponse omClientResponse = null;\n+    Result result = null;\n+    OmVolumeArgs omVolumeArgs = null;\n+    OmBucketInfo omBucketInfo = null;\n+    try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n+\n+      // check Acl\n+      checkKeyAcls(ozoneManager, volumeName, bucketName, keyName,\n+          IAccessAuthorizer.ACLType.DELETE, OzoneObj.ResourceType.KEY);\n+\n+      acquiredLock = omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n+          volumeName, bucketName);\n+\n+      // Validate bucket and volume exists or not.\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n+\n+      OzoneFileStatus keyStatus =\n+              OMFileRequest.getOMKeyInfoIfExists(omMetadataManager, volumeName,\n+                      bucketName, keyName, 0);\n+\n+      if (keyStatus == null) {\n+        throw new OMException(\"Key not found\", KEY_NOT_FOUND);\n+      }\n+\n+      OmKeyInfo omKeyInfo = keyStatus.getKeyInfo();\n+\n+      // Set the UpdateID to current transactionLogIndex\n+      omKeyInfo.setUpdateID(trxnLogIndex, ozoneManager.isRatisEnabled());\n+\n+      String ozonePathKey = omMetadataManager.getOzonePathKey(\n+              omKeyInfo.getParentObjectID(), omKeyInfo.getFileName());\n+\n+      if (keyStatus.isDirectory()) {\n+        // Update dir cache.\n+        omMetadataManager.getDirectoryTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      } else {\n+        // Update table cache.\n+        omMetadataManager.getKeyTable().addCacheEntry(\n+                new CacheKey<>(ozonePathKey),\n+                new CacheValue<>(Optional.absent(), trxnLogIndex));\n+      }\n+\n+      omVolumeArgs = getVolumeInfo(omMetadataManager, volumeName);\n+      omBucketInfo = getBucketInfo(omMetadataManager, volumeName, bucketName);\n+\n+      long quotaReleased = sumBlockLengths(omKeyInfo);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk3NDUwMw=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 142}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzgxMDQwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyDeleteResponseV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMzowNjoxN1rOH5bgOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoyMToxMVrOH-Y-Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MTQ5OA==", "bodyText": "KEY_TABLE  -> FILE_TABLE", "url": "https://github.com/apache/ozone/pull/1607#discussion_r529981498", "createdAt": "2020-11-24T23:06:17Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyDeleteResponseV1.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.DELETED_TABLE;\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.KEY_TABLE;\n+\n+/**\n+ * Response for DeleteKey request.\n+ */\n+@CleanupTableInfo(cleanupTables = {KEY_TABLE, DELETED_TABLE})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MjkyMg==", "bodyText": "Done in latest commit.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535182922", "createdAt": "2020-12-03T12:21:11Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/key/OMKeyDeleteResponseV1.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.key;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.helpers.OmVolumeArgs;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.DELETED_TABLE;\n+import static org.apache.hadoop.ozone.om.OmMetadataManagerImpl.KEY_TABLE;\n+\n+/**\n+ * Response for DeleteKey request.\n+ */\n+@CleanupTableInfo(cleanupTables = {KEY_TABLE, DELETED_TABLE})", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MTQ5OA=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzk0MjkyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMzoyOToxMlrOH5c2Jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoyMToyMFrOH-Y-ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwMzQ5NA==", "bodyText": "Can we rename tableCleanup to deleteRootDir or something meaningful?\nAnd also update Javadoc now delete is supported for V1 with this patch.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r530003494", "createdAt": "2020-11-24T23:29:12Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "diffHunk": "@@ -475,6 +475,15 @@ public void testFileSystem() throws Exception {\n \n     testSeekOnFileLength();\n     tableCleanup();\n+\n+    testFileDelete();\n+    tableCleanup();\n+\n+    testDeleteRoot();\n+    tableCleanup();\n+\n+    testRecursiveDelete();\n+    tableCleanup();\n   }\n \n   /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MzAxMQ==", "bodyText": "Done in latest commit.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535183011", "createdAt": "2020-12-03T12:21:20Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "diffHunk": "@@ -475,6 +475,15 @@ public void testFileSystem() throws Exception {\n \n     testSeekOnFileLength();\n     tableCleanup();\n+\n+    testFileDelete();\n+    tableCleanup();\n+\n+    testDeleteRoot();\n+    tableCleanup();\n+\n+    testRecursiveDelete();\n+    tableCleanup();\n   }\n \n   /**", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwMzQ5NA=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyMzk2OTkwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMzozMzo1OFrOH5dHxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjoyMToyNVrOH-Y-yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwODAwNw==", "bodyText": "For V1, we missed the root check delete at the client end.\nFor old buckets, this check is there.\n      if (f.isRoot()) {\n        LOG.warn(\"Cannot delete root directory.\");\n        return false;\n      }", "url": "https://github.com/apache/ozone/pull/1607#discussion_r530008007", "createdAt": "2020-11-24T23:33:58Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE4MzA1MA==", "bodyText": "Done in latest commit.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535183050", "createdAt": "2020-12-03T12:21:25Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java", "diffHunk": "@@ -498,6 +498,14 @@ public boolean delete(Path f, boolean recursive) throws IOException {\n     incrementCounter(Statistic.INVOCATION_DELETE, 1);\n     statistics.incrementWriteOps(1);\n     LOG.debug(\"Delete path {} - recursive {}\", f, recursive);\n+\n+    String layOutVersion = adapter.getBucketLayoutVersion();\n+    if (layOutVersion != null &&\n+            OMConfigKeys.OZONE_OM_LAYOUT_VERSION_V1.equals(layOutVersion)) {\n+      String key = pathToKey(f);\n+      return adapter.deleteObject(key);\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwODAwNw=="}, "originalCommit": {"oid": "215c834192dd32bb25e05b3f0687af792a38e5a0"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2Mjc0NzU3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOTowMDoyNVrOH_HKyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMjozMTowNVrOH_O3vA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkzOTc4Ng==", "bodyText": "Here should use 'if (iterator.hasNext())' not 'while (iterator.hasNext())'. We just check if the next path is immediate child.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535939786", "createdAt": "2020-12-04T09:00:25Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -759,4 +762,93 @@ public static long getToKeyNameParentId(String volumeName,\n     }\n     return toKeyParentDirStatus.getKeyInfo().getObjectID();\n   }\n+\n+  /**\n+   * Check if there are any sub path exist for the given user key path.\n+   *\n+   * @param omKeyInfo om key path\n+   * @param metaMgr   OMMetadataManager\n+   * @return true if there are any sub path, false otherwise\n+   * @throws IOException DB exception\n+   */\n+  public static boolean hasChildren(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    return checkSubDirectoryExists(omKeyInfo, metaMgr) ||\n+            checkSubFileExists(omKeyInfo, metaMgr);\n+  }\n+\n+  private static boolean checkSubDirectoryExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all dirTable cache for any sub paths.\n+    Table dirTable = metaMgr.getDirectoryTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>>>\n+            cacheIter = dirTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>> entry =\n+              cacheIter.next();\n+      OmDirectoryInfo cacheOmDirInfo = entry.getValue().getCacheValue();\n+      if (cacheOmDirInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmDirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path directory\n+      }\n+    }\n+\n+    // Check dirTable entries for any sub paths.\n+    String seekDirInDB = metaMgr.getOzonePathKey(omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmDirectoryInfo>>\n+            iterator = dirTable.iterator();\n+\n+    iterator.seek(seekDirInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmDirectoryInfo dirInfo = iterator.value().getValue();\n+      return isImmediateChild(dirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjA2NTk4MA==", "bodyText": "Thanks again @linyiqun for the review help. I will change it.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r536065980", "createdAt": "2020-12-04T12:31:05Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -759,4 +762,93 @@ public static long getToKeyNameParentId(String volumeName,\n     }\n     return toKeyParentDirStatus.getKeyInfo().getObjectID();\n   }\n+\n+  /**\n+   * Check if there are any sub path exist for the given user key path.\n+   *\n+   * @param omKeyInfo om key path\n+   * @param metaMgr   OMMetadataManager\n+   * @return true if there are any sub path, false otherwise\n+   * @throws IOException DB exception\n+   */\n+  public static boolean hasChildren(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    return checkSubDirectoryExists(omKeyInfo, metaMgr) ||\n+            checkSubFileExists(omKeyInfo, metaMgr);\n+  }\n+\n+  private static boolean checkSubDirectoryExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all dirTable cache for any sub paths.\n+    Table dirTable = metaMgr.getDirectoryTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>>>\n+            cacheIter = dirTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>> entry =\n+              cacheIter.next();\n+      OmDirectoryInfo cacheOmDirInfo = entry.getValue().getCacheValue();\n+      if (cacheOmDirInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmDirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path directory\n+      }\n+    }\n+\n+    // Check dirTable entries for any sub paths.\n+    String seekDirInDB = metaMgr.getOzonePathKey(omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmDirectoryInfo>>\n+            iterator = dirTable.iterator();\n+\n+    iterator.seek(seekDirInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmDirectoryInfo dirInfo = iterator.value().getValue();\n+      return isImmediateChild(dirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkzOTc4Ng=="}, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2Mjc0OTc4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOTowMDo1OVrOH_HMAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQxNzo0MjowNVrOH_9eRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDA5OQ==", "bodyText": "The same comment for above place.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535940099", "createdAt": "2020-12-04T09:00:59Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -759,4 +762,93 @@ public static long getToKeyNameParentId(String volumeName,\n     }\n     return toKeyParentDirStatus.getKeyInfo().getObjectID();\n   }\n+\n+  /**\n+   * Check if there are any sub path exist for the given user key path.\n+   *\n+   * @param omKeyInfo om key path\n+   * @param metaMgr   OMMetadataManager\n+   * @return true if there are any sub path, false otherwise\n+   * @throws IOException DB exception\n+   */\n+  public static boolean hasChildren(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    return checkSubDirectoryExists(omKeyInfo, metaMgr) ||\n+            checkSubFileExists(omKeyInfo, metaMgr);\n+  }\n+\n+  private static boolean checkSubDirectoryExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all dirTable cache for any sub paths.\n+    Table dirTable = metaMgr.getDirectoryTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>>>\n+            cacheIter = dirTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>> entry =\n+              cacheIter.next();\n+      OmDirectoryInfo cacheOmDirInfo = entry.getValue().getCacheValue();\n+      if (cacheOmDirInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmDirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path directory\n+      }\n+    }\n+\n+    // Check dirTable entries for any sub paths.\n+    String seekDirInDB = metaMgr.getOzonePathKey(omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmDirectoryInfo>>\n+            iterator = dirTable.iterator();\n+\n+    iterator.seek(seekDirInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmDirectoryInfo dirInfo = iterator.value().getValue();\n+      return isImmediateChild(dirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID());\n+    }\n+    return false; // no sub paths found\n+  }\n+\n+  private static boolean checkSubFileExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all fileTable cache for any sub paths.\n+    Table fileTable = metaMgr.getKeyTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmKeyInfo>>>\n+            cacheIter = fileTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmKeyInfo>> entry =\n+              cacheIter.next();\n+      OmKeyInfo cacheOmFileInfo = entry.getValue().getCacheValue();\n+      if (cacheOmFileInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmFileInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path file\n+      }\n+    }\n+\n+    // Check fileTable entries for any sub paths.\n+    String seekFileInDB = metaMgr.getOzonePathKey(\n+            omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmKeyInfo>>\n+            iterator = fileTable.iterator();\n+\n+    iterator.seek(seekFileInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmKeyInfo fileInfo = iterator.value().getValue();\n+      return isImmediateChild(fileInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID()); // found a sub path file\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjgyOTUwOA==", "bodyText": "Done!", "url": "https://github.com/apache/ozone/pull/1607#discussion_r536829508", "createdAt": "2020-12-05T17:42:05Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMFileRequest.java", "diffHunk": "@@ -759,4 +762,93 @@ public static long getToKeyNameParentId(String volumeName,\n     }\n     return toKeyParentDirStatus.getKeyInfo().getObjectID();\n   }\n+\n+  /**\n+   * Check if there are any sub path exist for the given user key path.\n+   *\n+   * @param omKeyInfo om key path\n+   * @param metaMgr   OMMetadataManager\n+   * @return true if there are any sub path, false otherwise\n+   * @throws IOException DB exception\n+   */\n+  public static boolean hasChildren(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    return checkSubDirectoryExists(omKeyInfo, metaMgr) ||\n+            checkSubFileExists(omKeyInfo, metaMgr);\n+  }\n+\n+  private static boolean checkSubDirectoryExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all dirTable cache for any sub paths.\n+    Table dirTable = metaMgr.getDirectoryTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>>>\n+            cacheIter = dirTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmDirectoryInfo>> entry =\n+              cacheIter.next();\n+      OmDirectoryInfo cacheOmDirInfo = entry.getValue().getCacheValue();\n+      if (cacheOmDirInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmDirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path directory\n+      }\n+    }\n+\n+    // Check dirTable entries for any sub paths.\n+    String seekDirInDB = metaMgr.getOzonePathKey(omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmDirectoryInfo>>\n+            iterator = dirTable.iterator();\n+\n+    iterator.seek(seekDirInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmDirectoryInfo dirInfo = iterator.value().getValue();\n+      return isImmediateChild(dirInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID());\n+    }\n+    return false; // no sub paths found\n+  }\n+\n+  private static boolean checkSubFileExists(OmKeyInfo omKeyInfo,\n+      OMMetadataManager metaMgr) throws IOException {\n+    // Check all fileTable cache for any sub paths.\n+    Table fileTable = metaMgr.getKeyTable();\n+    Iterator<Map.Entry<CacheKey<String>, CacheValue<OmKeyInfo>>>\n+            cacheIter = fileTable.cacheIterator();\n+\n+    while (cacheIter.hasNext()) {\n+      Map.Entry<CacheKey<String>, CacheValue<OmKeyInfo>> entry =\n+              cacheIter.next();\n+      OmKeyInfo cacheOmFileInfo = entry.getValue().getCacheValue();\n+      if (cacheOmFileInfo == null) {\n+        continue;\n+      }\n+      if (isImmediateChild(cacheOmFileInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID())) {\n+        return true; // found a sub path file\n+      }\n+    }\n+\n+    // Check fileTable entries for any sub paths.\n+    String seekFileInDB = metaMgr.getOzonePathKey(\n+            omKeyInfo.getObjectID(), \"\");\n+    TableIterator<String, ? extends Table.KeyValue<String, OmKeyInfo>>\n+            iterator = fileTable.iterator();\n+\n+    iterator.seek(seekFileInDB);\n+\n+    while (iterator.hasNext()) {\n+      OmKeyInfo fileInfo = iterator.value().getValue();\n+      return isImmediateChild(fileInfo.getParentObjectID(),\n+              omKeyInfo.getObjectID()); // found a sub path file\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDA5OQ=="}, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MjgxNTIwOnYy", "diffSide": "LEFT", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwOToxNjozNFrOH_Hx6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxMzo0Mzo1NlrOH_RehQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0OTgwMA==", "bodyText": "As I see we catch the OMException.ResultCodes.KEY_ALREADY_EXISTS error case, can we just make a minor change to adapt this? These test cases can be kept here.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r535949800", "createdAt": "2020-12-04T09:16:34Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "diffHunk": "@@ -308,78 +300,6 @@ protected void testRenameDirToItsOwnSubDir() throws Exception {\n     }\n   }\n \n-  /**\n-   * Case-5) If new destin '/dst/source' exists then throws exception.\n-   * If destination is a directory then rename source as sub-path of it.\n-   * <p>\n-   * For example: rename /a to /b will lead to /b/a. This new path should\n-   * not exist.\n-   */\n-  protected void testRenameToNewSubDirShouldNotExist() throws Exception {\n-    // Case-5.a) Rename directory from /a to /b.\n-    // created /a\n-    final Path aSourcePath = new Path(fs.getUri().toString() + \"/a\");\n-    fs.mkdirs(aSourcePath);\n-\n-    // created /b\n-    final Path bDestinPath = new Path(fs.getUri().toString() + \"/b\");\n-    fs.mkdirs(bDestinPath);\n-\n-    // Add a sub-directory '/b/a' to '/b'. This is to verify that rename\n-    // throws exception as new destin /b/a already exists.\n-    final Path baPath = new Path(fs.getUri().toString() + \"/b/a\");\n-    fs.mkdirs(baPath);\n-\n-    try {\n-      fs.rename(aSourcePath, bDestinPath);\n-      Assert.fail(\"Should fail as new destination dir exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-\n-    // Case-5.b) Rename file from /a/b/c/file1 to /a.\n-    // Should be failed since /a/file1 exists.\n-    final Path abcPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcPath);\n-    Path abcFile1 = new Path(abcPath, \"/file1\");\n-    ContractTestUtils.touch(fs, abcFile1);\n-\n-    final Path aFile1 = new Path(fs.getUri().toString() + \"/a/file1\");\n-    ContractTestUtils.touch(fs, aFile1);\n-\n-    final Path aDestinPath = new Path(fs.getUri().toString() + \"/a\");\n-\n-    try {\n-      fs.rename(abcFile1, aDestinPath);\n-      Assert.fail(\"Should fail as new destination file exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-  }\n-\n-  /**\n-   * Case-6) Rename directory to an existed file, should be failed.\n-   */\n-  protected void testRenameDirToFile() throws Exception {\n-    final String root = \"/root\";\n-    Path rootPath = new Path(fs.getUri().toString() + root);\n-    fs.mkdirs(rootPath);\n-\n-    Path file1Destin = new Path(fs.getUri().toString() + root + \"/file1\");\n-    ContractTestUtils.touch(fs, file1Destin);\n-    Path abcRootPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcRootPath);\n-    try {\n-      fs.rename(abcRootPath, file1Destin);\n-      Assert.fail(\"key already exists /root_dir/file1\");\n-    } catch (OMException ome) {\n-      // expected\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjA2ODgwNw==", "bodyText": "IIUC, you are suggesting to retain this test. Actually,  I haven't removed this test instead I avoided overriding  #testRenameDirToFile in TestOzoneFileSystemV1. Since TestOzoneFileSystemV1 extends TestOzoneFileSystem, it will run from the parent class. Does this fine for you?", "url": "https://github.com/apache/ozone/pull/1607#discussion_r536068807", "createdAt": "2020-12-04T12:36:02Z", "author": {"login": "rakeshadr"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "diffHunk": "@@ -308,78 +300,6 @@ protected void testRenameDirToItsOwnSubDir() throws Exception {\n     }\n   }\n \n-  /**\n-   * Case-5) If new destin '/dst/source' exists then throws exception.\n-   * If destination is a directory then rename source as sub-path of it.\n-   * <p>\n-   * For example: rename /a to /b will lead to /b/a. This new path should\n-   * not exist.\n-   */\n-  protected void testRenameToNewSubDirShouldNotExist() throws Exception {\n-    // Case-5.a) Rename directory from /a to /b.\n-    // created /a\n-    final Path aSourcePath = new Path(fs.getUri().toString() + \"/a\");\n-    fs.mkdirs(aSourcePath);\n-\n-    // created /b\n-    final Path bDestinPath = new Path(fs.getUri().toString() + \"/b\");\n-    fs.mkdirs(bDestinPath);\n-\n-    // Add a sub-directory '/b/a' to '/b'. This is to verify that rename\n-    // throws exception as new destin /b/a already exists.\n-    final Path baPath = new Path(fs.getUri().toString() + \"/b/a\");\n-    fs.mkdirs(baPath);\n-\n-    try {\n-      fs.rename(aSourcePath, bDestinPath);\n-      Assert.fail(\"Should fail as new destination dir exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-\n-    // Case-5.b) Rename file from /a/b/c/file1 to /a.\n-    // Should be failed since /a/file1 exists.\n-    final Path abcPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcPath);\n-    Path abcFile1 = new Path(abcPath, \"/file1\");\n-    ContractTestUtils.touch(fs, abcFile1);\n-\n-    final Path aFile1 = new Path(fs.getUri().toString() + \"/a/file1\");\n-    ContractTestUtils.touch(fs, aFile1);\n-\n-    final Path aDestinPath = new Path(fs.getUri().toString() + \"/a\");\n-\n-    try {\n-      fs.rename(abcFile1, aDestinPath);\n-      Assert.fail(\"Should fail as new destination file exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-  }\n-\n-  /**\n-   * Case-6) Rename directory to an existed file, should be failed.\n-   */\n-  protected void testRenameDirToFile() throws Exception {\n-    final String root = \"/root\";\n-    Path rootPath = new Path(fs.getUri().toString() + root);\n-    fs.mkdirs(rootPath);\n-\n-    Path file1Destin = new Path(fs.getUri().toString() + root + \"/file1\");\n-    ContractTestUtils.touch(fs, file1Destin);\n-    Path abcRootPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcRootPath);\n-    try {\n-      fs.rename(abcRootPath, file1Destin);\n-      Assert.fail(\"key already exists /root_dir/file1\");\n-    } catch (OMException ome) {\n-      // expected\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0OTgwMA=="}, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjEwODY3Nw==", "bodyText": "Okay, have seen that test cases.", "url": "https://github.com/apache/ozone/pull/1607#discussion_r536108677", "createdAt": "2020-12-04T13:43:56Z", "author": {"login": "linyiqun"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemV1.java", "diffHunk": "@@ -308,78 +300,6 @@ protected void testRenameDirToItsOwnSubDir() throws Exception {\n     }\n   }\n \n-  /**\n-   * Case-5) If new destin '/dst/source' exists then throws exception.\n-   * If destination is a directory then rename source as sub-path of it.\n-   * <p>\n-   * For example: rename /a to /b will lead to /b/a. This new path should\n-   * not exist.\n-   */\n-  protected void testRenameToNewSubDirShouldNotExist() throws Exception {\n-    // Case-5.a) Rename directory from /a to /b.\n-    // created /a\n-    final Path aSourcePath = new Path(fs.getUri().toString() + \"/a\");\n-    fs.mkdirs(aSourcePath);\n-\n-    // created /b\n-    final Path bDestinPath = new Path(fs.getUri().toString() + \"/b\");\n-    fs.mkdirs(bDestinPath);\n-\n-    // Add a sub-directory '/b/a' to '/b'. This is to verify that rename\n-    // throws exception as new destin /b/a already exists.\n-    final Path baPath = new Path(fs.getUri().toString() + \"/b/a\");\n-    fs.mkdirs(baPath);\n-\n-    try {\n-      fs.rename(aSourcePath, bDestinPath);\n-      Assert.fail(\"Should fail as new destination dir exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-\n-    // Case-5.b) Rename file from /a/b/c/file1 to /a.\n-    // Should be failed since /a/file1 exists.\n-    final Path abcPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcPath);\n-    Path abcFile1 = new Path(abcPath, \"/file1\");\n-    ContractTestUtils.touch(fs, abcFile1);\n-\n-    final Path aFile1 = new Path(fs.getUri().toString() + \"/a/file1\");\n-    ContractTestUtils.touch(fs, aFile1);\n-\n-    final Path aDestinPath = new Path(fs.getUri().toString() + \"/a\");\n-\n-    try {\n-      fs.rename(abcFile1, aDestinPath);\n-      Assert.fail(\"Should fail as new destination file exists!\");\n-    } catch (OMException ome) {\n-      // expected as new sub-path /b/a already exists.\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);\n-    }\n-  }\n-\n-  /**\n-   * Case-6) Rename directory to an existed file, should be failed.\n-   */\n-  protected void testRenameDirToFile() throws Exception {\n-    final String root = \"/root\";\n-    Path rootPath = new Path(fs.getUri().toString() + root);\n-    fs.mkdirs(rootPath);\n-\n-    Path file1Destin = new Path(fs.getUri().toString() + root + \"/file1\");\n-    ContractTestUtils.touch(fs, file1Destin);\n-    Path abcRootPath = new Path(fs.getUri().toString() + \"/a/b/c\");\n-    fs.mkdirs(abcRootPath);\n-    try {\n-      fs.rename(abcRootPath, file1Destin);\n-      Assert.fail(\"key already exists /root_dir/file1\");\n-    } catch (OMException ome) {\n-      // expected\n-      assertEquals(ome.getResult(), OMException.ResultCodes.KEY_ALREADY_EXISTS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0OTgwMA=="}, "originalCommit": {"oid": "7a1bcf4b28e85f3cf0dc65f523316b9bb7999ba4"}, "originalPosition": 111}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4497, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}