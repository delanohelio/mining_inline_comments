{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3NTcyNDcx", "number": 1104, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjowMTo1MVrOEJ2Ksg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzowNDoyMVrOEOxgRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NzYwMTE0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjowMTo1MVrOGqjwww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMzoxNjowMFrOGqqGww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3OTI5OQ==", "bodyText": "Old write code is not being used anymore.\nThis logic needs to be added to new Class OMBucketCreateRequest.java", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447279299", "createdAt": "2020-06-29T22:01:51Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM4MzIzNQ==", "bodyText": "Thanks, I missed that.  Will update the patch.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447383235", "createdAt": "2020-06-30T03:16:00Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3OTI5OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NzY4MzI4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjoyMTo1NVrOGqkhyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMzoxODo1N1rOGu8XOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ==", "bodyText": "Question: No, where we checked source volume/bucket exists or not.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447291849", "createdAt": "2020-06-29T22:21:55Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxODcxMg==", "bodyText": "Reading more understood that if we create link for /vol1/buck1 -> /vol2/buck2 (source)\nWe create in DB /vol1/buck1 and they have sourceVolume as vol2 and sourceBucket as buck2.\nNow, when someone calls lookupKey on unresolved bucket, during actual request of lookupKey, this will result in Bucket_NOT_FOUND.  Do you think, we need to make sure that source volume/source bucket exists during link creation to avoid such scenarios?\nMy reason was this looks strange, the user thinks he created a link bucket with some source volume/source bucket that has passed without any issues, but now when creating key it is saying bucket does not exist.\nFollowing ln -s   looks confusing in our scenario.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447318712", "createdAt": "2020-06-29T23:36:20Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3MzQ5Mg==", "bodyText": "Source bucket can be deleted any time after the link is created.  We would have to perform a reverse lookup to check if it leaves any dangling link.  Since this is not done, checking upon creation would be inconsistent.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447373492", "createdAt": "2020-06-30T02:39:16Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0OTgzNw==", "bodyText": "This is the same as the behavior of sym links:\nmkdir source\nln -s source dest\nrm r source\n\nNow you have a wrong pointer. You can list the content of the directory, but when you try to create a fie it will fail.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r449449837", "createdAt": "2020-07-03T08:26:55Z", "author": {"login": "elek"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg3NjY2NQ==", "bodyText": "Okay error seems to be confusing because the link bucket is happening through create bucket, with parameters sourcevolume/sourceBucket.\nI am not sure if someone will use our direct API's OzoneBucket/RpcClient.\nBut the explanation makes sense to me.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r451876665", "createdAt": "2020-07-08T23:18:57Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NzY4NTU0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjoyMjo1MFrOGqkjOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjoyMjo1MFrOGqkjOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MjIxOQ==", "bodyText": "Same, for all, write requests old code is not used anymore.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447292219", "createdAt": "2020-06-29T22:22:50Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2020,60 +2026,72 @@ public OmBucketInfo getBucketInfo(String volume, String bucket)\n    */\n   @Override\n   public OpenKeySession openKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);\n+\n     if (isAclEnabled) {\n       try {\n         checkAcls(ResourceType.KEY, StoreType.OZONE, ACLType.WRITE,\n-            args.getVolumeName(), args.getBucketName(), args.getKeyName());\n+            bucket.realVolume(), bucket.realBucket(), args.getKeyName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4Nzc0NTcxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjo0NTozNVrOGqlIVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNTo0MDowOFrOGv8KIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg==", "bodyText": "Now for each operation if it is link bucket where if it has sourceVolume/SourceBucket we do checkAcls twice. One with READ permission on sourceBucket/SourceVolume in resoleBucketLink and one in actual request with required ACL type. It is not clear why do we need the first check acl.\nIf it requires, do you think we need to have an API where we can check all required ACLS with a single checkAcl call?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447301716", "createdAt": "2020-06-29T22:45:35Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMTY1Nw==", "bodyText": "Okay, I see is in resolveBucketLink we check Acls for read on provided bucket, and in actual request check acls on sourceBucket/sourceVolume which it is resolved to. Let me know if i am missing something here. Why do we need this?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447311657", "createdAt": "2020-06-29T23:15:15Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3NDk3Nw==", "bodyText": "Read permission on the link is required to follow it.  Do you propose to completely skip ACL on link and allow anyone to use it?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447374977", "createdAt": "2020-06-30T02:44:36Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYwNTk0MQ==", "bodyText": "I am not sure what is the expected behavior, how is  this semantics derived?\nBecause with this approach for all mounted buckets, we do 2 checkAcls, we might put pressure on Ranger.\nCan we rely on underlying bucket acls, as anyway we verify already. Any downside/security issue?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r450605941", "createdAt": "2020-07-07T04:36:21Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg3NzMxNg==", "bodyText": "Any info on this question?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r451877316", "createdAt": "2020-07-08T23:20:48Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjAyMDc5Mg==", "bodyText": "I am not sure what is the expected behavior, how is this semantics derived?\nCan we rely on underlying bucket acls, as anyway we verify already. Any downside/security issue?\n\nThis matches unix symlinks permissions: if you have read access on the link, you see where it points to and can follow it.  ACL was discussed in design doc update (#1009) and the current behavior was approved.  Please check with @arp7 if we need any changes.  Also pinging @ChenSammi for input.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r452020792", "createdAt": "2020-07-09T07:33:57Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMTg4OQ==", "bodyText": "This matches unix symlinks permissions: if you have read access on the link, you see where it points to and can follow it.\n\n+1", "url": "https://github.com/apache/ozone/pull/1104#discussion_r452921889", "createdAt": "2020-07-10T15:40:08Z", "author": {"login": "arp7"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4Nzc1MDU0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMjo0NzozM1rOGqlK-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwNDozNjozM1rOGtuzrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA==", "bodyText": "The same comment for all write requests:\nCan we remove the changes from old write code path, which is not required? It is unnecessary now.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447302394", "createdAt": "2020-06-29T22:47:33Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2197,20 +2234,25 @@ public void renameKey(OmKeyArgs args, String toKeyName) throws IOException {\n    */\n   @Override\n   public void deleteKey(OmKeyArgs args) throws IOException {\n+    Map<String, String> auditMap = args.toAuditMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3NjkzOQ==", "bodyText": "I would have preferred removing old write code path before implementing links to avoid duplicate work.  However, now that these changes are in place, I prefer keeping them, and removing old write code path completely in a separate step.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447376939", "createdAt": "2020-06-30T02:51:44Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2197,20 +2234,25 @@ public void renameKey(OmKeyArgs args, String toKeyName) throws IOException {\n    */\n   @Override\n   public void deleteKey(OmKeyArgs args) throws IOException {\n+    Map<String, String> auditMap = args.toAuditMap();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYwNTk5OQ==", "bodyText": "Makes sense to me.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r450605999", "createdAt": "2020-07-07T04:36:33Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2197,20 +2234,25 @@ public void renameKey(OmKeyArgs args, String toKeyName) throws IOException {\n    */\n   @Override\n   public void deleteKey(OmKeyArgs args) throws IOException {\n+    Map<String, String> auditMap = args.toAuditMap();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NzgxODk0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzoxODoyMlrOGqlzCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwNzowMDowMFrOGquavQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMjY0OQ==", "bodyText": "Looks like this logic is needed for all KeyRequests. Can we move this to a common method, instead of duplicating it.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447312649", "createdAt": "2020-06-29T23:18:22Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "diffHunk": "@@ -174,6 +175,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     Result result = null;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ1Mzg4NQ==", "bodyText": "Thanks, extracted to a method.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447453885", "createdAt": "2020-06-30T07:00:00Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "diffHunk": "@@ -174,6 +175,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     Result result = null;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMjY0OQ=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4NzgyMTk1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzoxOTo1MlrOGql02Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwMjo1OTowMFrOGqp1jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMzExMw==", "bodyText": "And also do you think it would be useful to log the actual bucket/volume request which it resolved also?\nThis might help during debug purposes.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447313113", "createdAt": "2020-06-29T23:19:52Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java", "diffHunk": "@@ -149,6 +150,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     List<OmKeyInfo> missingParentInfos;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3ODgzMQ==", "bodyText": "Audit log includes both.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447378831", "createdAt": "2020-06-30T02:59:00Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java", "diffHunk": "@@ -149,6 +150,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     List<OmKeyInfo> missingParentInfos;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMzExMw=="}, "originalCommit": {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDgwNjA0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNzowMjozNVrOGxc4Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNDoyMDozMFrOGxtqRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNjU3MA==", "bodyText": "Can we change the error code here, the reason for this is in HA when error code is INTERNAL_ERROR we terminate OM. (This is done to avoid DB divergence)", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454506570", "createdAt": "2020-07-14T17:02:35Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -3314,4 +3396,59 @@ private void startJVMPauseMonitor() {\n     jvmPauseMonitor.init(configuration);\n     jvmPauseMonitor.start();\n   }\n+\n+  public ResolvedBucket resolveBucketLink(KeyArgs args) throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(OmKeyArgs args)\n+      throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(Pair<String, String> requested)\n+      throws IOException {\n+    Pair<String, String> resolved =\n+        resolveBucketLink(requested, new HashSet<>());\n+    return new ResolvedBucket(requested, resolved);\n+  }\n+\n+  /**\n+   * Resolves bucket symlinks. Read permission is required for following links.\n+   *\n+   * @param volumeAndBucket the bucket to be resolved (if it is a link)\n+   * @param visited collects link buckets visited during the resolution to\n+   *   avoid infinite loops\n+   * @return bucket location possibly updated with its actual volume and bucket\n+   *   after following bucket links\n+   * @throws IOException (most likely OMException) if ACL check fails, bucket is\n+   *   not found, loop is detected in the links, etc.\n+   */\n+  private Pair<String, String> resolveBucketLink(\n+      Pair<String, String> volumeAndBucket,\n+      Set<Pair<String, String>> visited) throws IOException {\n+\n+    String volumeName = volumeAndBucket.getLeft();\n+    String bucketName = volumeAndBucket.getRight();\n+    OmBucketInfo info = bucketManager.getBucketInfo(volumeName, bucketName);\n+    if (!info.isLink()) {\n+      return volumeAndBucket;\n+    }\n+\n+    if (!visited.add(volumeAndBucket)) {\n+      throw new OMException(\"Detected loop in bucket links\", INTERNAL_ERROR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc40b72206b47dab6da47d2b069910017a205f96"}, "originalPosition": 688}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MTUwOA==", "bodyText": "Sure.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454781508", "createdAt": "2020-07-15T04:20:30Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -3314,4 +3396,59 @@ private void startJVMPauseMonitor() {\n     jvmPauseMonitor.init(configuration);\n     jvmPauseMonitor.start();\n   }\n+\n+  public ResolvedBucket resolveBucketLink(KeyArgs args) throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(OmKeyArgs args)\n+      throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(Pair<String, String> requested)\n+      throws IOException {\n+    Pair<String, String> resolved =\n+        resolveBucketLink(requested, new HashSet<>());\n+    return new ResolvedBucket(requested, resolved);\n+  }\n+\n+  /**\n+   * Resolves bucket symlinks. Read permission is required for following links.\n+   *\n+   * @param volumeAndBucket the bucket to be resolved (if it is a link)\n+   * @param visited collects link buckets visited during the resolution to\n+   *   avoid infinite loops\n+   * @return bucket location possibly updated with its actual volume and bucket\n+   *   after following bucket links\n+   * @throws IOException (most likely OMException) if ACL check fails, bucket is\n+   *   not found, loop is detected in the links, etc.\n+   */\n+  private Pair<String, String> resolveBucketLink(\n+      Pair<String, String> volumeAndBucket,\n+      Set<Pair<String, String>> visited) throws IOException {\n+\n+    String volumeName = volumeAndBucket.getLeft();\n+    String bucketName = volumeAndBucket.getRight();\n+    OmBucketInfo info = bucketManager.getBucketInfo(volumeName, bucketName);\n+    if (!info.isLink()) {\n+      return volumeAndBucket;\n+    }\n+\n+    if (!visited.add(volumeAndBucket)) {\n+      throw new OMException(\"Detected loop in bucket links\", INTERNAL_ERROR);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNjU3MA=="}, "originalCommit": {"oid": "fc40b72206b47dab6da47d2b069910017a205f96"}, "originalPosition": 688}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTA3NDY4OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODoxMTozNFrOGxfdNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwODoxNzozNVrOGygGzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ==", "bodyText": "Now with this approach, we validate bucket exist twice. Once is resolvedBucketLink, and again in ValidateVolumeAndBucket. If this is link, can we skip 2nd-time check?\n(Now bucket/volume is in the full cache, but I think it will be better to avoid still)\nMight be in non-HA, this might create a problem as we release lock and then re-acquire some other thread might delete the bucket. But once HA becomes the default, we can optimize this, as in HA there is only a single thread executor. If you also think the same open the Jira for improvement", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454548791", "createdAt": "2020-07-14T18:11:34Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgxMDMwNQ==", "bodyText": "But once HA becomes the default, we can optimize this, as in HA there is only a single thread executor.\n\nDoes that mean we can completely get rid of the locks?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454810305", "createdAt": "2020-07-15T05:59:21Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE0NzIwMg==", "bodyText": "we cannot completely get rid of locks, as there are readers. But there will ne no parallel writers to have a situation like in non-HA, where other writer thread can acquire a lock in between", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455147202", "createdAt": "2020-07-15T15:37:42Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ2MDU4NA==", "bodyText": "OK, I'll check if I can update the patch to address this.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455460584", "createdAt": "2020-07-16T01:44:48Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTYwODAxMg==", "bodyText": "Opened https://issues.apache.org/jira/browse/HDDS-3971 for the improvement.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455608012", "createdAt": "2020-07-16T08:17:35Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTA5ODk2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODoxNzo1M1rOGxfsMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNDoxOTo1MFrOGxtppA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ==", "bodyText": "Minor: We can skip getting from original Args, as anyway final Volume/Bucket we get is from resolvedBucket returned keyArgs.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454552625", "createdAt": "2020-07-14T18:17:53Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -88,21 +88,20 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n     DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n \n-    OzoneManagerProtocolProtos.KeyArgs deleteKeyArgs =\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n         deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n \n-    String volumeName = deleteKeyArgs.getVolumeName();\n-    String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = deleteKeyArgs.getKeyName();\n+    String volumeName = keyArgs.getVolumeName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjkxMw==", "bodyText": "The same comment applies for all requests", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454552913", "createdAt": "2020-07-14T18:18:24Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -88,21 +88,20 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n     DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n \n-    OzoneManagerProtocolProtos.KeyArgs deleteKeyArgs =\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n         deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n \n-    String volumeName = deleteKeyArgs.getVolumeName();\n-    String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = deleteKeyArgs.getKeyName();\n+    String volumeName = keyArgs.getVolumeName();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MTM0OA==", "bodyText": "We can skip getting from original Args, as anyway final Volume/Bucket we get is from resolvedBucket returned keyArgs.\n\nUnfortunately not, because volumeName and bucketName are used later to log result.  If resolveBucketLink throws exception (eg. due to lack of permission), then we exit from try earlier than getting resolvedBucket and we need the original values from request.\nhttps://github.com/apache/hadoop-ozone/blob/fbf04a33ecad2d23e8bd57ecceca4842a9cf5281/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java#L173-L183", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454781348", "createdAt": "2020-07-15T04:19:50Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -88,21 +88,20 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n     DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n \n-    OzoneManagerProtocolProtos.KeyArgs deleteKeyArgs =\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n         deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n \n-    String volumeName = deleteKeyArgs.getVolumeName();\n-    String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = deleteKeyArgs.getKeyName();\n+    String volumeName = keyArgs.getVolumeName();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ=="}, "originalCommit": {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTExNjAzOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeysDeleteRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODoyMjozNFrOGxf26A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNDoyMjo1N1rOGxttVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1NTM2OA==", "bodyText": "Minor: We can skip this, as anyway bucket.audit has already taken care of this.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454555368", "createdAt": "2020-07-14T18:22:34Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeysDeleteRequest.java", "diffHunk": "@@ -85,10 +87,11 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     OMMetrics omMetrics = ozoneManager.getMetrics();\n     omMetrics.incNumKeyDeletes();\n-    Map<String, String> auditMap = null;\n     String volumeName = deleteKeyArgs.getVolumeName();\n     String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = \"\";\n+    Map<String, String> auditMap = new LinkedHashMap<>();\n+    auditMap.put(VOLUME, volumeName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MjI5NQ==", "bodyText": "Similar to volumeName and bucketName variables, this is also required for the case when we encounter exception before reaching bucket.audit().", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454782295", "createdAt": "2020-07-15T04:22:57Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeysDeleteRequest.java", "diffHunk": "@@ -85,10 +87,11 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     OMMetrics omMetrics = ozoneManager.getMetrics();\n     omMetrics.incNumKeyDeletes();\n-    Map<String, String> auditMap = null;\n     String volumeName = deleteKeyArgs.getVolumeName();\n     String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = \"\";\n+    Map<String, String> auditMap = new LinkedHashMap<>();\n+    auditMap.put(VOLUME, volumeName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1NTM2OA=="}, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTE0OTY0OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODozMTozNFrOGxgLeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODozMTozNFrOGxgLeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MDYzNA==", "bodyText": "Minor: Can we assign to volumeName and bucketName, similar to Key requests and use that, instead of getting multiple times.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454560634", "createdAt": "2020-07-14T18:31:34Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java", "diffHunk": "@@ -114,12 +117,15 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n         getOmRequest());\n     OMClientResponse omClientResponse = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+\n       // TODO to support S3 ACL later.\n       acquiredBucketLock =\n-          omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK, volumeName,\n-              bucketName);\n+          omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTE1OTkyOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxODozNDoyNlrOGxgR8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNTo0OTo0NFrOGxvOdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MjI4OA==", "bodyText": "I see for all key requests we logged resolvedVolume/resolvedBucket. For MPU we log requested volume/bucket any reason for this?. Can we follow one approach for all requests?", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454562288", "createdAt": "2020-07-14T18:34:26Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java", "diffHunk": "@@ -152,27 +158,29 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n           omDoubleBufferHelper);\n       if (acquiredLock) {\n-        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n-            bucketName);\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK,\n+            keyArgs.getVolumeName(), keyArgs.getBucketName());\n       }\n     }\n \n     // audit log\n     auditLog(ozoneManager.getAuditLogger(), buildAuditMessage(\n-        OMAction.ABORT_MULTIPART_UPLOAD, buildKeyArgsAuditMap(keyArgs),\n+        OMAction.ABORT_MULTIPART_UPLOAD, auditMap,\n         exception, getOmRequest().getUserInfo()));\n \n     switch (result) {\n     case SUCCESS:\n       LOG.debug(\"Abort Multipart request is successfully completed for \" +\n-              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, volumeName,\n-          bucketName);\n+              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, requestedVolume,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgwNzE1Nw==", "bodyText": "Updated, thanks.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454807157", "createdAt": "2020-07-15T05:49:44Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java", "diffHunk": "@@ -152,27 +158,29 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n           omDoubleBufferHelper);\n       if (acquiredLock) {\n-        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n-            bucketName);\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK,\n+            keyArgs.getVolumeName(), keyArgs.getBucketName());\n       }\n     }\n \n     // audit log\n     auditLog(ozoneManager.getAuditLogger(), buildAuditMessage(\n-        OMAction.ABORT_MULTIPART_UPLOAD, buildKeyArgsAuditMap(keyArgs),\n+        OMAction.ABORT_MULTIPART_UPLOAD, auditMap,\n         exception, getOmRequest().getUserInfo()));\n \n     switch (result) {\n     case SUCCESS:\n       LOG.debug(\"Abort Multipart request is successfully completed for \" +\n-              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, volumeName,\n-          bucketName);\n+              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, requestedVolume,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MjI4OA=="}, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTY4NjY3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/smoketest/basic/links.robot", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQyMTowNTo0NlrOGxlU0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNDoyNDo1MVrOGxtvEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY0NDk0Nw==", "bodyText": "This needs to be updated, once error code is modified.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454644947", "createdAt": "2020-07-14T21:05:46Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/dist/src/main/smoketest/basic/links.robot", "diffHunk": "@@ -0,0 +1,152 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test bucket links via Ozone CLI\n+Library             OperatingSystem\n+Resource            ../commonlib.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Setup          Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Kinit test user     testuser     testuser.keytab\n+Test Timeout        2 minute\n+Suite Setup         Create volumes\n+\n+*** Variables ***\n+${prefix}    generated\n+\n+*** Keywords ***\n+Create volumes\n+    ${random} =         Generate Random String  5  [NUMBERS]\n+    Set Suite Variable  ${source}  ${random}-source\n+    Set Suite Variable  ${target}  ${random}-target\n+    Execute             ozone sh volume create ${source}\n+    Execute             ozone sh volume create ${target}\n+    Run Keyword if      '${SECURITY_ENABLED}' == 'true'    Setup ACL tests\n+\n+Setup ACL tests\n+    Execute             ozone sh bucket create ${source}/readable-bucket\n+    Execute             ozone sh key put ${source}/readable-bucket/key-in-readable-bucket /etc/passwd\n+    Execute             ozone sh bucket create ${source}/unreadable-bucket\n+    Execute             ozone sh bucket link ${source}/readable-bucket ${target}/readable-link\n+    Execute             ozone sh bucket link ${source}/readable-bucket ${target}/unreadable-link\n+    Execute             ozone sh bucket link ${source}/unreadable-bucket ${target}/link-to-unreadable-bucket\n+    Execute             ozone sh volume addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}\n+    Execute             ozone sh volume addacl --acl user:testuser2/scm@EXAMPLE.COM:rl ${source}\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:rl ${source}/readable-bucket\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}/readable-link\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}/link-to-unreadable-bucket\n+\n+Can follow link with read access\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/readable-link\n+                        Should Contain              ${result}         key-in-readable-bucket\n+\n+Cannot follow link without read access\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/unreadable-link\n+                        Should Contain              ${result}         PERMISSION_DENIED\n+\n+ACL verified on source bucket\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute                     ozone sh bucket info ${target}/link-to-unreadable-bucket\n+                        Should Contain              ${result}         link-to-unreadable-bucket\n+                        Should Not Contain          ${result}         PERMISSION_DENIED\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/link-to-unreadable-bucket\n+                        Should Contain              ${result}         PERMISSION_DENIED\n+\n+*** Test Cases ***\n+Link to non-existent bucket\n+                        Execute                     ozone sh bucket link ${source}/no-such-bucket ${target}/dangling-link\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/dangling-link\n+                        Should Contain              ${result}         BUCKET_NOT_FOUND\n+\n+Key create passthrough\n+                        Execute                     ozone sh bucket link ${source}/bucket1 ${target}/link1\n+                        Execute                     ozone sh bucket create ${source}/bucket1\n+                        Execute                     ozone sh key put ${target}/link1/key1 /etc/passwd\n+                        Key Should Match Local File     ${target}/link1/key1    /etc/passwd\n+\n+Key read passthrough\n+                        Execute                     ozone sh key put ${source}/bucket1/key2 /opt/hadoop/NOTICE.txt\n+                        Key Should Match Local File     ${source}/bucket1/key2    /opt/hadoop/NOTICE.txt\n+\n+Key list passthrough\n+    ${target_list} =    Execute                     ozone sh key list ${target}/link1 | jq -r '.name'\n+    ${source_list} =    Execute                     ozone sh key list ${source}/bucket1 | jq -r '.name'\n+                        Should Be Equal             ${target_list}    ${source_list}\n+                        Should Contain              ${source_list}    key1\n+                        Should Contain              ${source_list}    key2\n+\n+Key delete passthrough\n+                        Execute                     ozone sh key delete ${target}/link1/key2\n+    ${source_list} =    Execute                     ozone sh key list ${source}/bucket1 | jq -r '.name'\n+                        Should Not Contain          ${source_list}    key2\n+\n+Bucket list contains links\n+    ${result} =         Execute                     ozone sh bucket list ${target}\n+                        Should Contain              ${result}         link1\n+                        Should Contain              ${result}         dangling-link\n+\n+Bucket info shows source\n+    ${result} =         Execute                     ozone sh bucket info ${target}/link1 | jq -r '.sourceVolume, .sourceBucket' | xargs\n+                        Should Be Equal             ${result}    ${source} bucket1\n+\n+Source and target have separate ACLs\n+    Execute       ozone sh bucket addacl --acl user:user1:rwxy ${target}/link1\n+    Verify ACL    bucket    ${target}/link1      USER    user1    READ WRITE READ_ACL WRITE_ACL\n+    Verify ACL    bucket    ${source}/bucket1    USER    user1    ${EMPTY}\n+\n+    Execute       ozone sh bucket addacl --acl group:group2:r ${source}/bucket1\n+    Verify ACL    bucket    ${target}/link1      GROUP   group2    ${EMPTY}\n+    Verify ACL    bucket    ${source}/bucket1    GROUP   group2    READ\n+\n+Buckets and links share namespace\n+                        Execute                     ozone sh bucket link ${source}/bucket2 ${target}/link2\n+    ${result} =         Execute And Ignore Error    ozone sh bucket create ${target}/link2\n+                        Should Contain              ${result}    BUCKET_ALREADY_EXISTS\n+\n+                        Execute                     ozone sh bucket create ${target}/bucket3\n+    ${result} =         Execute And Ignore Error    ozone sh bucket link ${source}/bucket1 ${target}/bucket3\n+                        Should Contain              ${result}    BUCKET_ALREADY_EXISTS\n+\n+Can follow link with read access\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Can follow link with read access\n+\n+Cannot follow link without read access\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Cannot follow link without read access\n+\n+ACL verified on source bucket\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    ACL verified on source bucket\n+\n+Loop in link chain is detected\n+                        Execute                     ozone sh bucket link ${target}/loop1 ${target}/loop2\n+                        Execute                     ozone sh bucket link ${target}/loop2 ${target}/loop3\n+                        Execute                     ozone sh bucket link ${target}/loop3 ${target}/loop1\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/loop2\n+                        Should Contain              ${result}    INTERNAL_ERROR", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MjczOA==", "bodyText": "Done.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454782738", "createdAt": "2020-07-15T04:24:51Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/smoketest/basic/links.robot", "diffHunk": "@@ -0,0 +1,152 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+*** Settings ***\n+Documentation       Test bucket links via Ozone CLI\n+Library             OperatingSystem\n+Resource            ../commonlib.robot\n+Resource            ../ozone-lib/shell.robot\n+Test Setup          Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Kinit test user     testuser     testuser.keytab\n+Test Timeout        2 minute\n+Suite Setup         Create volumes\n+\n+*** Variables ***\n+${prefix}    generated\n+\n+*** Keywords ***\n+Create volumes\n+    ${random} =         Generate Random String  5  [NUMBERS]\n+    Set Suite Variable  ${source}  ${random}-source\n+    Set Suite Variable  ${target}  ${random}-target\n+    Execute             ozone sh volume create ${source}\n+    Execute             ozone sh volume create ${target}\n+    Run Keyword if      '${SECURITY_ENABLED}' == 'true'    Setup ACL tests\n+\n+Setup ACL tests\n+    Execute             ozone sh bucket create ${source}/readable-bucket\n+    Execute             ozone sh key put ${source}/readable-bucket/key-in-readable-bucket /etc/passwd\n+    Execute             ozone sh bucket create ${source}/unreadable-bucket\n+    Execute             ozone sh bucket link ${source}/readable-bucket ${target}/readable-link\n+    Execute             ozone sh bucket link ${source}/readable-bucket ${target}/unreadable-link\n+    Execute             ozone sh bucket link ${source}/unreadable-bucket ${target}/link-to-unreadable-bucket\n+    Execute             ozone sh volume addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}\n+    Execute             ozone sh volume addacl --acl user:testuser2/scm@EXAMPLE.COM:rl ${source}\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:rl ${source}/readable-bucket\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}/readable-link\n+    Execute             ozone sh bucket addacl --acl user:testuser2/scm@EXAMPLE.COM:r ${target}/link-to-unreadable-bucket\n+\n+Can follow link with read access\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/readable-link\n+                        Should Contain              ${result}         key-in-readable-bucket\n+\n+Cannot follow link without read access\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/unreadable-link\n+                        Should Contain              ${result}         PERMISSION_DENIED\n+\n+ACL verified on source bucket\n+    Execute             kdestroy\n+    Run Keyword         Kinit test user             testuser2         testuser2.keytab\n+    ${result} =         Execute                     ozone sh bucket info ${target}/link-to-unreadable-bucket\n+                        Should Contain              ${result}         link-to-unreadable-bucket\n+                        Should Not Contain          ${result}         PERMISSION_DENIED\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/link-to-unreadable-bucket\n+                        Should Contain              ${result}         PERMISSION_DENIED\n+\n+*** Test Cases ***\n+Link to non-existent bucket\n+                        Execute                     ozone sh bucket link ${source}/no-such-bucket ${target}/dangling-link\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/dangling-link\n+                        Should Contain              ${result}         BUCKET_NOT_FOUND\n+\n+Key create passthrough\n+                        Execute                     ozone sh bucket link ${source}/bucket1 ${target}/link1\n+                        Execute                     ozone sh bucket create ${source}/bucket1\n+                        Execute                     ozone sh key put ${target}/link1/key1 /etc/passwd\n+                        Key Should Match Local File     ${target}/link1/key1    /etc/passwd\n+\n+Key read passthrough\n+                        Execute                     ozone sh key put ${source}/bucket1/key2 /opt/hadoop/NOTICE.txt\n+                        Key Should Match Local File     ${source}/bucket1/key2    /opt/hadoop/NOTICE.txt\n+\n+Key list passthrough\n+    ${target_list} =    Execute                     ozone sh key list ${target}/link1 | jq -r '.name'\n+    ${source_list} =    Execute                     ozone sh key list ${source}/bucket1 | jq -r '.name'\n+                        Should Be Equal             ${target_list}    ${source_list}\n+                        Should Contain              ${source_list}    key1\n+                        Should Contain              ${source_list}    key2\n+\n+Key delete passthrough\n+                        Execute                     ozone sh key delete ${target}/link1/key2\n+    ${source_list} =    Execute                     ozone sh key list ${source}/bucket1 | jq -r '.name'\n+                        Should Not Contain          ${source_list}    key2\n+\n+Bucket list contains links\n+    ${result} =         Execute                     ozone sh bucket list ${target}\n+                        Should Contain              ${result}         link1\n+                        Should Contain              ${result}         dangling-link\n+\n+Bucket info shows source\n+    ${result} =         Execute                     ozone sh bucket info ${target}/link1 | jq -r '.sourceVolume, .sourceBucket' | xargs\n+                        Should Be Equal             ${result}    ${source} bucket1\n+\n+Source and target have separate ACLs\n+    Execute       ozone sh bucket addacl --acl user:user1:rwxy ${target}/link1\n+    Verify ACL    bucket    ${target}/link1      USER    user1    READ WRITE READ_ACL WRITE_ACL\n+    Verify ACL    bucket    ${source}/bucket1    USER    user1    ${EMPTY}\n+\n+    Execute       ozone sh bucket addacl --acl group:group2:r ${source}/bucket1\n+    Verify ACL    bucket    ${target}/link1      GROUP   group2    ${EMPTY}\n+    Verify ACL    bucket    ${source}/bucket1    GROUP   group2    READ\n+\n+Buckets and links share namespace\n+                        Execute                     ozone sh bucket link ${source}/bucket2 ${target}/link2\n+    ${result} =         Execute And Ignore Error    ozone sh bucket create ${target}/link2\n+                        Should Contain              ${result}    BUCKET_ALREADY_EXISTS\n+\n+                        Execute                     ozone sh bucket create ${target}/bucket3\n+    ${result} =         Execute And Ignore Error    ozone sh bucket link ${source}/bucket1 ${target}/bucket3\n+                        Should Contain              ${result}    BUCKET_ALREADY_EXISTS\n+\n+Can follow link with read access\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Can follow link with read access\n+\n+Cannot follow link without read access\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    Cannot follow link without read access\n+\n+ACL verified on source bucket\n+    Run Keyword if    '${SECURITY_ENABLED}' == 'true'    ACL verified on source bucket\n+\n+Loop in link chain is detected\n+                        Execute                     ozone sh bucket link ${target}/loop1 ${target}/loop2\n+                        Execute                     ozone sh bucket link ${target}/loop2 ${target}/loop3\n+                        Execute                     ozone sh bucket link ${target}/loop3 ${target}/loop1\n+    ${result} =         Execute And Ignore Error    ozone sh key list ${target}/loop2\n+                        Should Contain              ${result}    INTERNAL_ERROR", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY0NDk0Nw=="}, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNTg0MjI1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/compose/ozone/test.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQyMTo1NzoyOVrOGxm01g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwNTo0OToyNFrOGxvOEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY2OTUyNg==", "bodyText": "S3 tests not using this bucket right?\nFor example\nDelete existing bucket\nBucket already is created in Test Setup.\n${bucket} =                Create bucket\nExecute AWSS3APICli        delete-bucket --bucket ${bucket}\n\nAnd bucket is returned from\nDelete existing bucket\nBucket already is created in Test Setup.\n${bucket} =                Create bucket\nExecute AWSS3APICli        delete-bucket --bucket ${bucket}", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454669526", "createdAt": "2020-07-14T21:57:29Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/dist/src/main/compose/ozone/test.sh", "diffHunk": "@@ -26,24 +26,24 @@ source \"$COMPOSE_DIR/../testlib.sh\"\n \n start_docker_env\n \n-#Due to the limitation of the current auditparser test, it should be the\n-#first test in a clean cluster.\n-\n-#Disabling for now, audit parser tool during parse getting exception.\n-#execute_robot_test om auditparser\n-\n execute_robot_test scm lib\n+execute_robot_test scm ozone-lib\n \n execute_robot_test scm basic\n \n execute_robot_test scm gdpr\n \n-execute_robot_test scm -v SCHEME:ofs ozonefs/ozonefs.robot\n-execute_robot_test scm -v SCHEME:o3fs ozonefs/ozonefs.robot\n+for scheme in ofs o3fs; do\n+  for bucket in link bucket; do\n+    execute_robot_test scm -v SCHEME:${scheme} -v BUCKET_TYPE:${bucket} ozonefs/ozonefs.robot\n+  done\n+done\n \n execute_robot_test scm security/ozone-secure-token.robot\n \n-execute_robot_test scm s3\n+for bucket in link generated; do\n+  execute_robot_test scm -v BUCKET:${bucket} s3", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgwNzA1OA==", "bodyText": "S3 tests not using this bucket right?\n\nOther tests do use bucket or link created by setup.  Thanks for spotting this instance, fixed.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454807058", "createdAt": "2020-07-15T05:49:24Z", "author": {"login": "adoroszlai"}, "path": "hadoop-ozone/dist/src/main/compose/ozone/test.sh", "diffHunk": "@@ -26,24 +26,24 @@ source \"$COMPOSE_DIR/../testlib.sh\"\n \n start_docker_env\n \n-#Due to the limitation of the current auditparser test, it should be the\n-#first test in a clean cluster.\n-\n-#Disabling for now, audit parser tool during parse getting exception.\n-#execute_robot_test om auditparser\n-\n execute_robot_test scm lib\n+execute_robot_test scm ozone-lib\n \n execute_robot_test scm basic\n \n execute_robot_test scm gdpr\n \n-execute_robot_test scm -v SCHEME:ofs ozonefs/ozonefs.robot\n-execute_robot_test scm -v SCHEME:o3fs ozonefs/ozonefs.robot\n+for scheme in ofs o3fs; do\n+  for bucket in link bucket; do\n+    execute_robot_test scm -v SCHEME:${scheme} -v BUCKET_TYPE:${bucket} ozonefs/ozonefs.robot\n+  done\n+done\n \n execute_robot_test scm security/ozone-secure-token.robot\n \n-execute_robot_test scm s3\n+for bucket in link generated; do\n+  execute_robot_test scm -v BUCKET:${bucket} s3", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY2OTUyNg=="}, "originalCommit": {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTI2NTk3OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzowNDoyMVrOGyHLvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzowNDoyMVrOGyHLvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE5OTY3OQ==", "bodyText": "openKeyName should be generated from resolveBucketLink.", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455199679", "createdAt": "2020-07-15T17:04:21Z", "author": {"login": "bharatviswa504"}, "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "diffHunk": "@@ -172,6 +172,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     IOException exception = null;\n \n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "272a6f4865e4db97bc4d9fe37fd799fe69f59c8d"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4091, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}