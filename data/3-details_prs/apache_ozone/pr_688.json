{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5MjY4MDgy", "number": 688, "title": "HDDS-2995. Add integration test for Recon's Passive SCM state.", "bodyText": "What changes were proposed in this pull request?\n\nVerify Recon gets pipeline, node and container report from Datanode.\nVerify SCM metadata state == Recon metadata state (Create pipeline , Close pipeline, create container)\nFix issue in DN StateContext.\n\nWhat is the link to the Apache JIRA\nhttps://issues.apache.org/jira/browse/HDDS-2995\nHow was this patch tested?\nManually tested.", "createdAt": "2020-03-16T14:15:34Z", "url": "https://github.com/apache/ozone/pull/688", "merged": true, "mergeCommit": {"oid": "f0a06bc6537953abfc8d1badc36bcc1a61d7d1e9"}, "closed": true, "closedAt": "2020-03-19T15:18:07Z", "author": {"login": "avijayanhwx"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcOOxWoAH2gAyMzg5MjY4MDgyOmQ2ZmM0NTkxMDg1NGE5NTBkODk4ZjZiMzRjNTY5Nzc2M2VhODU3ZmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPNfNWAFqTM3NzgyMTgwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d6fc45910854a950d898f6b34c5697763ea857fb", "author": {"user": {"login": "avijayanhwx", "name": null}}, "url": "https://github.com/apache/ozone/commit/d6fc45910854a950d898f6b34c5697763ea857fb", "committedDate": "2020-03-16T14:13:36Z", "message": "HDDS-2995. Add integration test for Recon's Passive SCM state."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a4a3b0bc1fad57ca260361be877b87177ec0f09", "author": {"user": {"login": "avijayanhwx", "name": null}}, "url": "https://github.com/apache/ozone/commit/5a4a3b0bc1fad57ca260361be877b87177ec0f09", "committedDate": "2020-03-16T14:46:59Z", "message": "HDDS-2995. Fix compilation issue."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9226f3285d5fdcb9c3de79e882fc80c66860bbe6", "author": {"user": {"login": "avijayanhwx", "name": null}}, "url": "https://github.com/apache/ozone/commit/9226f3285d5fdcb9c3de79e882fc80c66860bbe6", "committedDate": "2020-03-16T14:54:46Z", "message": "HDDS-2995. Fix checkstyle issue."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDg4NDcz", "url": "https://github.com/apache/ozone/pull/688#pullrequestreview-375488473", "createdAt": "2020-03-16T18:39:22Z", "commit": {"oid": "9226f3285d5fdcb9c3de79e882fc80c66860bbe6"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODozOToyMlrOF3BPlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo0OTowMFrOF3BjEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzNjM3Mw==", "bodyText": "Nit: Fix typo", "url": "https://github.com/apache/ozone/pull/688#discussion_r393236373", "createdAt": "2020-03-16T18:39:22Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/recon/TestReconAsPassiveScm.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon;\n+\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_CONTAINER_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.RATIS;\n+import static org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer.runTestOzoneContainerViaDataNode;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.Optional;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.scm.XceiverClientGrpc;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.ContainerManager;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.hdds.scm.server.StorageContainerManager;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Recon's passive SCM integration tests.\n+ */\n+public class TestReconAsPassiveScm {\n+\n+  private MiniOzoneCluster cluster = null;\n+  private OzoneConfiguration conf;\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(HDDS_CONTAINER_REPORT_INTERVAL, \"5s\");\n+    conf.set(HDDS_PIPELINE_REPORT_INTERVAL, \"5s\");\n+    cluster =  MiniOzoneCluster.newBuilder(conf).setNumDatanodes(3)\n+        .includeRecon(true).build();\n+    cluster.waitForClusterToBeReady();\n+  }\n+\n+  @After\n+  public void shutdown() {\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 120000)\n+  public void testDatanodeRegistrationAndReports() throws Exception {\n+    ReconStorageContainerManagerFacade reconScm =\n+        (ReconStorageContainerManagerFacade)\n+        cluster.getReconServer().getReconStorageContainerManager();\n+    StorageContainerManager scm = cluster.getStorageContainerManager();\n+    PipelineManager reconPipelineManager = reconScm.getPipelineManager();\n+    PipelineManager scmPipelineManager = scm.getPipelineManager();\n+\n+    LambdaTestUtils.await(60000, 5000,\n+        () -> (reconPipelineManager.getPipelines().size() == 4));\n+\n+    // Verify if Recon has all the pipelines from SCM.\n+    scmPipelineManager.getPipelines().forEach(p -> {\n+      try {\n+        assertNotNull(reconPipelineManager.getPipeline(p.getId()));\n+      } catch (PipelineNotFoundException e) {\n+        Assert.fail();\n+      }\n+    });\n+\n+    // Verify we can never create a pipeline in Recon.\n+    LambdaTestUtils.intercept(UnsupportedOperationException.class,\n+        \"Trying to create pipeline in Recon, which is prohibited!\",\n+        () -> reconPipelineManager.createPipeline(RATIS, ONE));\n+\n+    ContainerManager scmContainerManager = scm.getContainerManager();\n+    assertTrue(scmContainerManager.getContainerIDs().isEmpty());\n+\n+    // Verify if Recon regix  stered all the nodes.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f3285d5fdcb9c3de79e882fc80c66860bbe6"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzNzk0Mg==", "bodyText": "Can we reduce the interval to 2s instead of 5s? This will help reduce overall runtime of the test.", "url": "https://github.com/apache/ozone/pull/688#discussion_r393237942", "createdAt": "2020-03-16T18:42:24Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/recon/TestReconAsPassiveScm.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon;\n+\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_CONTAINER_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.RATIS;\n+import static org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer.runTestOzoneContainerViaDataNode;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.Optional;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.scm.XceiverClientGrpc;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.ContainerManager;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.hdds.scm.server.StorageContainerManager;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Recon's passive SCM integration tests.\n+ */\n+public class TestReconAsPassiveScm {\n+\n+  private MiniOzoneCluster cluster = null;\n+  private OzoneConfiguration conf;\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(HDDS_CONTAINER_REPORT_INTERVAL, \"5s\");\n+    conf.set(HDDS_PIPELINE_REPORT_INTERVAL, \"5s\");\n+    cluster =  MiniOzoneCluster.newBuilder(conf).setNumDatanodes(3)\n+        .includeRecon(true).build();\n+    cluster.waitForClusterToBeReady();\n+  }\n+\n+  @After\n+  public void shutdown() {\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 120000)\n+  public void testDatanodeRegistrationAndReports() throws Exception {\n+    ReconStorageContainerManagerFacade reconScm =\n+        (ReconStorageContainerManagerFacade)\n+        cluster.getReconServer().getReconStorageContainerManager();\n+    StorageContainerManager scm = cluster.getStorageContainerManager();\n+    PipelineManager reconPipelineManager = reconScm.getPipelineManager();\n+    PipelineManager scmPipelineManager = scm.getPipelineManager();\n+\n+    LambdaTestUtils.await(60000, 5000,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f3285d5fdcb9c3de79e882fc80c66860bbe6"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTM2MQ==", "bodyText": "Can we reduce the interval from 30s to 5s?", "url": "https://github.com/apache/ozone/pull/688#discussion_r393241361", "createdAt": "2020-03-16T18:49:00Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/recon/TestReconAsPassiveScm.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon;\n+\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_CONTAINER_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.RATIS;\n+import static org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer.runTestOzoneContainerViaDataNode;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.util.Optional;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.scm.XceiverClientGrpc;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.ContainerManager;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.hdds.scm.server.StorageContainerManager;\n+import org.apache.hadoop.ozone.MiniOzoneCluster;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Recon's passive SCM integration tests.\n+ */\n+public class TestReconAsPassiveScm {\n+\n+  private MiniOzoneCluster cluster = null;\n+  private OzoneConfiguration conf;\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void init() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(HDDS_CONTAINER_REPORT_INTERVAL, \"5s\");\n+    conf.set(HDDS_PIPELINE_REPORT_INTERVAL, \"5s\");\n+    cluster =  MiniOzoneCluster.newBuilder(conf).setNumDatanodes(3)\n+        .includeRecon(true).build();\n+    cluster.waitForClusterToBeReady();\n+  }\n+\n+  @After\n+  public void shutdown() {\n+    if (cluster != null) {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 120000)\n+  public void testDatanodeRegistrationAndReports() throws Exception {\n+    ReconStorageContainerManagerFacade reconScm =\n+        (ReconStorageContainerManagerFacade)\n+        cluster.getReconServer().getReconStorageContainerManager();\n+    StorageContainerManager scm = cluster.getStorageContainerManager();\n+    PipelineManager reconPipelineManager = reconScm.getPipelineManager();\n+    PipelineManager scmPipelineManager = scm.getPipelineManager();\n+\n+    LambdaTestUtils.await(60000, 5000,\n+        () -> (reconPipelineManager.getPipelines().size() == 4));\n+\n+    // Verify if Recon has all the pipelines from SCM.\n+    scmPipelineManager.getPipelines().forEach(p -> {\n+      try {\n+        assertNotNull(reconPipelineManager.getPipeline(p.getId()));\n+      } catch (PipelineNotFoundException e) {\n+        Assert.fail();\n+      }\n+    });\n+\n+    // Verify we can never create a pipeline in Recon.\n+    LambdaTestUtils.intercept(UnsupportedOperationException.class,\n+        \"Trying to create pipeline in Recon, which is prohibited!\",\n+        () -> reconPipelineManager.createPipeline(RATIS, ONE));\n+\n+    ContainerManager scmContainerManager = scm.getContainerManager();\n+    assertTrue(scmContainerManager.getContainerIDs().isEmpty());\n+\n+    // Verify if Recon regix  stered all the nodes.\n+    NodeManager reconNodeManager = reconScm.getScmNodeManager();\n+    NodeManager scmNodeManager = scm.getScmNodeManager();\n+    assertEquals(scmNodeManager.getAllNodes().size(),\n+        reconNodeManager.getAllNodes().size());\n+\n+    // Create container\n+    ContainerManager reconContainerManager = reconScm.getContainerManager();\n+    ContainerInfo containerInfo =\n+        scmContainerManager.allocateContainer(RATIS, ONE, \"test\");\n+    long containerID = containerInfo.getContainerID();\n+    Pipeline pipeline =\n+        scmPipelineManager.getPipeline(containerInfo.getPipelineID());\n+    XceiverClientGrpc client = new XceiverClientGrpc(pipeline, conf);\n+    runTestOzoneContainerViaDataNode(containerID, client);\n+\n+    // Verify Recon picked up the new container that was created.\n+    assertEquals(scmContainerManager.getContainerIDs(),\n+        reconContainerManager.getContainerIDs());\n+  }\n+\n+  @Test(timeout = 120000)\n+  public void testReconRestart() throws Exception {\n+    final OzoneStorageContainerManager reconScm =\n+            cluster.getReconServer().getReconStorageContainerManager();\n+    StorageContainerManager scm = cluster.getStorageContainerManager();\n+\n+    // Stop Recon\n+    ContainerManager scmContainerManager = scm.getContainerManager();\n+    assertTrue(scmContainerManager.getContainerIDs().isEmpty());\n+    ContainerManager reconContainerManager = reconScm.getContainerManager();\n+    assertTrue(reconContainerManager.getContainerIDs().isEmpty());\n+\n+    LambdaTestUtils.await(60000, 5000,\n+        () -> (reconScm.getScmNodeManager().getAllNodes().size() == 3));\n+\n+    cluster.stopRecon();\n+\n+    // Create container in SCM.\n+    ContainerInfo containerInfo =\n+        scmContainerManager.allocateContainer(RATIS, ONE, \"test\");\n+    long containerID = containerInfo.getContainerID();\n+    PipelineManager scmPipelineManager = scm.getPipelineManager();\n+    Pipeline pipeline =\n+        scmPipelineManager.getPipeline(containerInfo.getPipelineID());\n+    XceiverClientGrpc client = new XceiverClientGrpc(pipeline, conf);\n+    runTestOzoneContainerViaDataNode(containerID, client);\n+    assertFalse(scmContainerManager.getContainerIDs().isEmpty());\n+\n+    // Close a pipeline\n+    Optional<Pipeline> pipelineToClose = scmPipelineManager\n+        .getPipelines(RATIS, ONE)\n+        .stream()\n+        .filter(p -> !p.getId().equals(containerInfo.getPipelineID()))\n+        .findFirst();\n+    assertTrue(pipelineToClose.isPresent());\n+    scmPipelineManager.finalizeAndDestroyPipeline(pipelineToClose.get(), false);\n+\n+    // Start Recon\n+    cluster.startRecon();\n+\n+    // Verify if Recon has all the nodes on restart (even if heartbeats are\n+    // not yet received).\n+    NodeManager reconNodeManager = reconScm.getScmNodeManager();\n+    NodeManager scmNodeManager = scm.getScmNodeManager();\n+    assertEquals(scmNodeManager.getAllNodes().size(),\n+        reconNodeManager.getAllNodes().size());\n+\n+    // Verify Recon picks up new container, close pipeline SCM actions.\n+    OzoneStorageContainerManager newReconScm =\n+        cluster.getReconServer().getReconStorageContainerManager();\n+    PipelineManager reconPipelineManager = newReconScm.getPipelineManager();\n+    assertFalse(\n+        reconPipelineManager.containsPipeline(pipelineToClose.get().getId()));\n+\n+    LambdaTestUtils.await(300000, 30000,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f3285d5fdcb9c3de79e882fc80c66860bbe6"}, "originalPosition": 185}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b274531e1645af6b632249ed3a247038621fe9ea", "author": {"user": {"login": "avijayanhwx", "name": null}}, "url": "https://github.com/apache/ozone/commit/b274531e1645af6b632249ed3a247038621fe9ea", "committedDate": "2020-03-16T19:16:07Z", "message": "HDDS-2995. Reduce interval time for checking condition."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NTYwMDI4", "url": "https://github.com/apache/ozone/pull/688#pullrequestreview-375560028", "createdAt": "2020-03-16T20:30:16Z", "commit": {"oid": "b274531e1645af6b632249ed3a247038621fe9ea"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d94f38c7aa481933a39b20d95c2db0664b18799d", "author": {"user": {"login": "avijayanhwx", "name": null}}, "url": "https://github.com/apache/ozone/commit/d94f38c7aa481933a39b20d95c2db0664b18799d", "committedDate": "2020-03-16T21:21:28Z", "message": "Merge remote-tracking branch 'upstream/master' into HDDS-2995-master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3ODIxODAx", "url": "https://github.com/apache/ozone/pull/688#pullrequestreview-377821801", "createdAt": "2020-03-19T15:17:48Z", "commit": {"oid": "d94f38c7aa481933a39b20d95c2db0664b18799d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3483, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}