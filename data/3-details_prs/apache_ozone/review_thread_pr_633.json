{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzODc5NzM5", "number": 633, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0NTowMVrODlNrgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMjozNlrODli4rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzQ4MDM1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/dist/src/main/smoketest/recon/recon-api.robot", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0NTowMVrOFx-v8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQwNToyMDoyOFrOFyGt9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MjYyNg==", "bodyText": "Can we make sure this is not flaky? Since the pipelines are created by SCM, onto Datanodes and then reaches Recon through heartbeats, there will be a lag between Recon container starting up, and having the pipelines available.  (Same may be true for Datanodes test above this)", "url": "https://github.com/apache/ozone/pull/633#discussion_r387952626", "createdAt": "2020-03-04T21:45:01Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/dist/src/main/smoketest/recon/recon-api.robot", "diffHunk": "@@ -34,6 +34,13 @@ Recon REST API\n                         Should contain      ${result}       ozone_datanode_1.ozone_default\n                         Should contain      ${result}       ozone_datanode_2.ozone_default\n                         Should contain      ${result}       ozone_datanode_3.ozone_default\n+    ${result} =         Execute                             curl --negotiate -u : -v ${API_ENDPOINT_URL}/pipelines\n+                        Should contain      ${result}       pipelines\n+                        Should contain      ${result}       RATIS\n+                        Should contain      ${result}       OPEN", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAyNDk4Nw==", "bodyText": "Added a 2s delay before executing CURL calls. I don't think this will be flaky since recon tests will run after several other tests in both ozone and ozone-secure docker-compose. That should give recon a lot of time to get heartbeats. I have also run this test locally with recon tests running first after docker setup is up and haven't faced any flakiness issues. I am positive that this will not be flaky.", "url": "https://github.com/apache/ozone/pull/633#discussion_r388024987", "createdAt": "2020-03-05T01:05:26Z", "author": {"login": "vivekratnavel"}, "path": "hadoop-ozone/dist/src/main/smoketest/recon/recon-api.robot", "diffHunk": "@@ -34,6 +34,13 @@ Recon REST API\n                         Should contain      ${result}       ozone_datanode_1.ozone_default\n                         Should contain      ${result}       ozone_datanode_2.ozone_default\n                         Should contain      ${result}       ozone_datanode_3.ozone_default\n+    ${result} =         Execute                             curl --negotiate -u : -v ${API_ENDPOINT_URL}/pipelines\n+                        Should contain      ${result}       pipelines\n+                        Should contain      ${result}       RATIS\n+                        Should contain      ${result}       OPEN", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MjYyNg=="}, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODA4MzE5MA==", "bodyText": "Makes sense. I am ok with this.", "url": "https://github.com/apache/ozone/pull/633#discussion_r388083190", "createdAt": "2020-03-05T05:20:28Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/dist/src/main/smoketest/recon/recon-api.robot", "diffHunk": "@@ -34,6 +34,13 @@ Recon REST API\n                         Should contain      ${result}       ozone_datanode_1.ozone_default\n                         Should contain      ${result}       ozone_datanode_2.ozone_default\n                         Should contain      ${result}       ozone_datanode_3.ozone_default\n+    ${result} =         Execute                             curl --negotiate -u : -v ${API_ENDPOINT_URL}/pipelines\n+                        Should contain      ${result}       pipelines\n+                        Should contain      ${result}       RATIS\n+                        Should contain      ${result}       OPEN", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MjYyNg=="}, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzQ4ODY2OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0NzozOVrOFx-1Aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0NzozOVrOFx-1Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MzkyMw==", "bodyText": "Nit: Can use something like lambda forEach.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387953923", "createdAt": "2020-03-04T21:47:39Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzQ5MDU5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0ODoxMFrOFx-2MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0ODoxMFrOFx-2MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDIyNQ==", "bodyText": "Log the exception message here if not already logged further down the stack.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954225", "createdAt": "2020-03-04T21:48:10Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzQ5Mzc5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0OToxNFrOFx-4LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo0OToxNFrOFx-4LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDczMg==", "bodyText": "Nit: Lambda.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954732", "createdAt": "2020-03-04T21:49:14Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzUxMTM1OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo1NDozMVrOFx_Cxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo1NDozMVrOFx_Cxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NzQ0Nw==", "bodyText": "Seems like a lot of duplicated code between the 2 endpoint Test classes. Can we move this Test into the other class? We don't necessarily need a unit test for every endpoint class.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387957447", "createdAt": "2020-03-04T21:54:31Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import com.google.inject.AbstractModule;\n+import com.google.inject.Guice;\n+import com.google.inject.Injector;\n+import com.google.inject.Singleton;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.PipelineID;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.NodeReportProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReport;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.SCMHeartbeatRequestProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.GuiceInjectorUtilsForTestsImpl;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.persistence.AbstractSqlDatabaseTest;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.hadoop.ozone.recon.schema.ReconTaskSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.ReconTaskStatusDao;\n+import org.jooq.Configuration;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import javax.ws.rs.core.Response;\n+\n+import static org.apache.hadoop.hdds.protocol.MockDatanodeDetails.randomDatanodeDetails;\n+import static org.apache.hadoop.hdds.recon.ReconConfigKeys.OZONE_RECON_DATANODE_ADDRESS_KEY;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/**\n+ * Test for Pipeline Endpoint.\n+ */\n+public class TestPipelineEndpoint extends AbstractSqlDatabaseTest {\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private PipelineEndpoint pipelineEndpoint;\n+  private ReconStorageContainerManagerFacade reconScm;\n+  private boolean isSetupDone = false;\n+  private String pipelineId;\n+  private DatanodeDetails datanodeDetails;\n+  private GuiceInjectorUtilsForTestsImpl guiceInjectorTest =\n+      new GuiceInjectorUtilsForTestsImpl();\n+  private DatanodeDetailsProto datanodeDetailsProto;\n+  private ContainerReportsProto containerReportsProto;\n+  private long containerId = 1L;\n+  private Pipeline pipeline;\n+  private void initializeInjector() {\n+\n+    Injector injector = Guice.createInjector(new AbstractModule() {\n+      @Override\n+      protected void configure() {\n+        try {\n+          datanodeDetails = randomDatanodeDetails();\n+          pipeline = getRandomPipeline(datanodeDetails);\n+          pipelineId = pipeline.getId().getId().toString();\n+\n+          Configuration sqlConfiguration =\n+              getInjector().getInstance((Configuration.class));\n+\n+          ContainerInfo containerInfo = new ContainerInfo.Builder()\n+              .setContainerID(containerId)\n+              .setReplicationFactor(ReplicationFactor.ONE)\n+              .setState(LifeCycleState.OPEN)\n+              .setOwner(\"test\")\n+              .setPipelineID(pipeline.getId())\n+              .setReplicationType(ReplicationType.RATIS)\n+              .build();\n+          ContainerWithPipeline containerWithPipeline =\n+              new ContainerWithPipeline(containerInfo, pipeline);\n+\n+          ReconTaskSchemaDefinition taskSchemaDefinition = getInjector()\n+              .getInstance(ReconTaskSchemaDefinition.class);\n+          taskSchemaDefinition.initializeSchema();\n+\n+          ReconTaskStatusDao reconTaskStatusDao =\n+              new ReconTaskStatusDao(sqlConfiguration);\n+          MissingContainersDao missingContainersDao =\n+              new MissingContainersDao(sqlConfiguration);\n+\n+          bind(ReconTaskStatusDao.class).toInstance(reconTaskStatusDao);\n+          bind(MissingContainersDao.class).toInstance(missingContainersDao);\n+\n+          StorageContainerLocationProtocol mockScmClient = mock(\n+              StorageContainerLocationProtocol.class);\n+          StorageContainerServiceProvider mockScmServiceProvider = mock(\n+              StorageContainerServiceProviderImpl.class);\n+          when(mockScmServiceProvider.getPipeline(\n+              pipeline.getId().getProtobuf())).thenReturn(pipeline);\n+          when(mockScmServiceProvider.getContainerWithPipeline(containerId))\n+              .thenReturn(containerWithPipeline);\n+\n+          OzoneConfiguration testOzoneConfiguration =\n+              guiceInjectorTest.getTestOzoneConfiguration(temporaryFolder);\n+          testOzoneConfiguration.set(OZONE_RECON_DATANODE_ADDRESS_KEY,\n+              \"0.0.0.0:0\");\n+          bind(OzoneConfiguration.class).toInstance(testOzoneConfiguration);\n+          bind(StorageContainerLocationProtocol.class)\n+              .toInstance(mockScmClient);\n+          bind(StorageContainerServiceProvider.class)\n+              .toInstance(mockScmServiceProvider);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzUyNDQwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo1ODo0NlrOFx_K4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTo1ODo0NlrOFx_K4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1OTUyMw==", "bodyText": "Shouldn't this just be IOException? From\npublic DatanodeDetails getLeaderNode() throws IOException {.\nWhy do we need to set leaderNode to \"\" on exception? It can be null, and handled in the UI maybe.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387959523", "createdAt": "2020-03-04T21:58:46Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzUyOTAxOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMjowMDoxM1rOFx_N3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMjowMDoxM1rOFx_N3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MDI4NA==", "bodyText": "PipelineMetadata constructor looks like it is taking in a lot of parameters. A Builder may be better.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387960284", "createdAt": "2020-03-04T22:00:13Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {\n+        datanodes.add(datanode.getHostName());\n+      }\n+\n+      PipelineMetadata pipelineMetadata = new PipelineMetadata(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMzU0NDE5OnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMjowNToxM1rOFx_XXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMjowNToxM1rOFx_XXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MjcxOA==", "bodyText": "Can we keep the type of 'pipelineID' as UUID? Since the Pipeline endpoint uses UUID.", "url": "https://github.com/apache/ozone/pull/633#discussion_r387962718", "createdAt": "2020-03-04T22:05:13Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+/**\n+ * Metadata object that contains pipeline information of a Datanode.\n+ */\n+public class DatanodePipeline {\n+  private String pipelineID;\n+  private String replicationType;\n+  private int replicationFactor;\n+\n+  public DatanodePipeline(String pipelineID, String replicationType,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwNjk1NDcwOnYy", "diffSide": "RIGHT", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMjozNlrOFygDvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMjozNlrOFygDvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5ODM2Nw==", "bodyText": "minor nit. To be consistent with terminology, we can keep it as \"state\" instead of \"status\".", "url": "https://github.com/apache/ozone/pull/633#discussion_r388498367", "createdAt": "2020-03-05T19:02:36Z", "author": {"login": "avijayanhwx"}, "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState;\n+\n+import javax.xml.bind.annotation.XmlAccessType;\n+import javax.xml.bind.annotation.XmlAccessorType;\n+import javax.xml.bind.annotation.XmlElement;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Metadata object that represents a Pipeline.\n+ */\n+@XmlAccessorType(XmlAccessType.FIELD)\n+public class PipelineMetadata {\n+\n+  @XmlElement(name = \"pipelineId\")\n+  private UUID pipelineId;\n+\n+  @XmlElement(name = \"status\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "382791a35985e75cac0d3dddd735a10f753ef215"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4954, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}