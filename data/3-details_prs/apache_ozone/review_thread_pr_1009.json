{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI2NTU5MDkx", "number": 1009, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyNjoyMlrOEB0uiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjozMDoxNFrOEB00YQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzQ3OTEyOnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyNjoyMlrOGd58dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxMjowNjo1MlrOGgarMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMTI1NA==", "bodyText": "You can remove my name, I really cannot claim any authorship credit for this idea. \ud83d\ude42", "url": "https://github.com/apache/ozone/pull/1009#discussion_r434011254", "createdAt": "2020-06-02T16:26:22Z", "author": {"login": "arp7"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -4,7 +4,7 @@ summary: A simplified version of mapping between S3 buckets and Ozone volume/buc\n date: 2020-04-02\n jira: HDDS-3331\n status: accepted\n-author: Marton Elek, Arpit Agarwall, Sunjay Radia\n+author: Marton Elek, Arpit Agarwal, Sanjay Radia", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY0NDY1OQ==", "bodyText": "@arp7 You wrote additional section to this document about the volume ownership problems.", "url": "https://github.com/apache/ozone/pull/1009#discussion_r436644659", "createdAt": "2020-06-08T12:06:52Z", "author": {"login": "elek"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -4,7 +4,7 @@ summary: A simplified version of mapping between S3 buckets and Ozone volume/buc\n date: 2020-04-02\n jira: HDDS-3331\n status: accepted\n-author: Marton Elek, Arpit Agarwall, Sunjay Radia\n+author: Marton Elek, Arpit Agarwal, Sanjay Radia", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMTI1NA=="}, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzQ4NTQ5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyODowNlrOGd6Afg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyODowNlrOGd6Afg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMjI4Ng==", "bodyText": "Yeah this should work a lot like symlinks, so we shouldn't perform reverse checks on changes to the target bucket.", "url": "https://github.com/apache/ozone/pull/1009#discussion_r434012286", "createdAt": "2020-06-02T16:28:06Z", "author": {"login": "arp7"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -106,19 +106,27 @@ This is an easy an fast method, but with this approach not all the volumes are a\n \n The first approach required a secondary cache table and it violates the naming hierarchy. The s3 bucket name is a global unique name, therefore it's more than just a single attribute on a specific object. It's more like an element in the hierachy. For this reason the second option is proposed:\n \n-For example if the default s3 volume is `s3`\n+For example if the default s3 volume is `s3v`\n \n- 1. Every new buckets created via s3 interface will be placed under the `/s3` volume\n- 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3/s3bucketname`\n+ 1. Every new buckets created via s3 interface will be placed under the `/s3v` volume\n+ 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3v/s3bucketname`\n \n **Lock contention problem**\n \n-One possible problem with using just one volume is using the locks of the same volume for all the D3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n+One possible problem with using just one volume is using the locks of the same volume for all the S3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n \n  1. We hold only a READ lock. Most of the time it can acquired without any contention (writing lock is required only to change owner / set quota)\n  2. For symbolic link / bind mounts the read lock is only required for the first read. After that the lock of the referenced volume will be used. In case of any performance problem multiple volumes + bind mounts can be used.\n \n-Note: Sunjay is added to the authors as the original proposal of this approach.\n+Note: Sanjay is added to the authors as the original proposal of this approach.\n+\n+#### Implementation details\n+\n+ * Let bucket mount operation create a link bucket.  Links are like regular buckets, stored in DB the same way, but with two new, optional pieces of information: source volume and bucket.\n+ * Existing bucket operations (info, delete, ACL) work on the link object in the same way as they do on regular buckets.  No new link-specific RPC is required.\n+ * Links are followed for key operations (list, get, put, etc.).  Checks for existence of the source bucket, as well as ACL, are performed at this time (similar to symlinks).  This avoids the need for reverse checks for each bucket delete or ACL change.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzQ4ODI0OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyODo0N1rOGd6CLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjoyODo0N1rOGd6CLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMjcxNg==", "bodyText": "We should probably try to match the behavior of Unix symlinks wrt permissions.", "url": "https://github.com/apache/ozone/pull/1009#discussion_r434012716", "createdAt": "2020-06-02T16:28:47Z", "author": {"login": "arp7"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -106,19 +106,27 @@ This is an easy an fast method, but with this approach not all the volumes are a\n \n The first approach required a secondary cache table and it violates the naming hierarchy. The s3 bucket name is a global unique name, therefore it's more than just a single attribute on a specific object. It's more like an element in the hierachy. For this reason the second option is proposed:\n \n-For example if the default s3 volume is `s3`\n+For example if the default s3 volume is `s3v`\n \n- 1. Every new buckets created via s3 interface will be placed under the `/s3` volume\n- 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3/s3bucketname`\n+ 1. Every new buckets created via s3 interface will be placed under the `/s3v` volume\n+ 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3v/s3bucketname`\n \n **Lock contention problem**\n \n-One possible problem with using just one volume is using the locks of the same volume for all the D3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n+One possible problem with using just one volume is using the locks of the same volume for all the S3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n \n  1. We hold only a READ lock. Most of the time it can acquired without any contention (writing lock is required only to change owner / set quota)\n  2. For symbolic link / bind mounts the read lock is only required for the first read. After that the lock of the referenced volume will be used. In case of any performance problem multiple volumes + bind mounts can be used.\n \n-Note: Sunjay is added to the authors as the original proposal of this approach.\n+Note: Sanjay is added to the authors as the original proposal of this approach.\n+\n+#### Implementation details\n+\n+ * Let bucket mount operation create a link bucket.  Links are like regular buckets, stored in DB the same way, but with two new, optional pieces of information: source volume and bucket.\n+ * Existing bucket operations (info, delete, ACL) work on the link object in the same way as they do on regular buckets.  No new link-specific RPC is required.\n+ * Links are followed for key operations (list, get, put, etc.).  Checks for existence of the source bucket, as well as ACL, are performed at this time (similar to symlinks).  This avoids the need for reverse checks for each bucket delete or ACL change.\n+ * The same permission is required on both the link and the source bucket to be able to perform the operation via the link.  This allows finer-grained access control.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMzQ5NDA5OnYy", "diffSide": "RIGHT", "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjozMDoxNFrOGd6F9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxNjo1NjozMVrOGd7Gog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMzY4NA==", "bodyText": "Let bucket mount operation create a link bucket\n\nDidn't understand this sentence. Does it mean that when you try to mount a bucket in a new volume it silently creates a link under the covers? Is the link reused next time we try to mount again?\nAlso how do we handle name collisions? Can the user choose any name for the link/mount point?", "url": "https://github.com/apache/ozone/pull/1009#discussion_r434013684", "createdAt": "2020-06-02T16:30:14Z", "author": {"login": "arp7"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -106,19 +106,27 @@ This is an easy an fast method, but with this approach not all the volumes are a\n \n The first approach required a secondary cache table and it violates the naming hierarchy. The s3 bucket name is a global unique name, therefore it's more than just a single attribute on a specific object. It's more like an element in the hierachy. For this reason the second option is proposed:\n \n-For example if the default s3 volume is `s3`\n+For example if the default s3 volume is `s3v`\n \n- 1. Every new buckets created via s3 interface will be placed under the `/s3` volume\n- 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3/s3bucketname`\n+ 1. Every new buckets created via s3 interface will be placed under the `/s3v` volume\n+ 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3v/s3bucketname`\n \n **Lock contention problem**\n \n-One possible problem with using just one volume is using the locks of the same volume for all the D3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n+One possible problem with using just one volume is using the locks of the same volume for all the S3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n \n  1. We hold only a READ lock. Most of the time it can acquired without any contention (writing lock is required only to change owner / set quota)\n  2. For symbolic link / bind mounts the read lock is only required for the first read. After that the lock of the referenced volume will be used. In case of any performance problem multiple volumes + bind mounts can be used.\n \n-Note: Sunjay is added to the authors as the original proposal of this approach.\n+Note: Sanjay is added to the authors as the original proposal of this approach.\n+\n+#### Implementation details\n+\n+ * Let bucket mount operation create a link bucket.  Links are like regular buckets, stored in DB the same way, but with two new, optional pieces of information: source volume and bucket.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAzMDI0Mg==", "bodyText": "Let bucket mount operation create a link bucket\n\nDidn't understand this sentence. Does it mean that when you try to mount a bucket in a new volume it silently creates a link under the covers?\n\nMount and link are the same.  (Even the high-level parts of the doc refer to it as \"link\" in some places and \"mount\" in others.  Maybe we should not mix terminology.  Since proposed behavior is closer to symlinks, I suggest using \"link\" instead of \"mount\".)\n\nIs the link reused next time we try to mount again?\n\nThe mount is \"active\" until the link is deleted via regular DeleteBucket request.  Until then, another attempt to mount (or create a bucket with same name) will result in a \"bucket already exists\" error.\n\nAlso how do we handle name collisions? Can the user choose any name for the link/mount point?\n\nName collision is handled the same as if trying to create a regular bucket.\nBasically, the extra link info does not change behavior until client starts working with keys in the \"bucket\".  Then it is redirected.", "url": "https://github.com/apache/ozone/pull/1009#discussion_r434030242", "createdAt": "2020-06-02T16:56:31Z", "author": {"login": "adoroszlai"}, "path": "hadoop-hdds/docs/content/design/ozone-volume-management.md", "diffHunk": "@@ -106,19 +106,27 @@ This is an easy an fast method, but with this approach not all the volumes are a\n \n The first approach required a secondary cache table and it violates the naming hierarchy. The s3 bucket name is a global unique name, therefore it's more than just a single attribute on a specific object. It's more like an element in the hierachy. For this reason the second option is proposed:\n \n-For example if the default s3 volume is `s3`\n+For example if the default s3 volume is `s3v`\n \n- 1. Every new buckets created via s3 interface will be placed under the `/s3` volume\n- 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3/s3bucketname`\n+ 1. Every new buckets created via s3 interface will be placed under the `/s3v` volume\n+ 2. Any existing **Ozone** buckets can be exposed with mounting it to s3: `ozone sh mount /vol1/bucket1 /s3v/s3bucketname`\n \n **Lock contention problem**\n \n-One possible problem with using just one volume is using the locks of the same volume for all the D3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n+One possible problem with using just one volume is using the locks of the same volume for all the S3 buckets (thanks Xiaoyu). But this shouldn't be a big problem.\n \n  1. We hold only a READ lock. Most of the time it can acquired without any contention (writing lock is required only to change owner / set quota)\n  2. For symbolic link / bind mounts the read lock is only required for the first read. After that the lock of the referenced volume will be used. In case of any performance problem multiple volumes + bind mounts can be used.\n \n-Note: Sunjay is added to the authors as the original proposal of this approach.\n+Note: Sanjay is added to the authors as the original proposal of this approach.\n+\n+#### Implementation details\n+\n+ * Let bucket mount operation create a link bucket.  Links are like regular buckets, stored in DB the same way, but with two new, optional pieces of information: source volume and bucket.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDAxMzY4NA=="}, "originalCommit": {"oid": "8c8dd0218bb9d1b04e166ccdcbef50b300307182"}, "originalPosition": 52}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4215, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}