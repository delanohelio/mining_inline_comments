{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MjQxMDQ5", "number": 174, "title": "Issue 173 struct evolution", "bodyText": "Addresses #173", "createdAt": "2020-03-10T16:35:10Z", "url": "https://github.com/ExpediaGroup/circus-train/pull/174", "merged": true, "mergeCommit": {"oid": "f6f5389ac7f365df542b73bd5acdd0deaab68223"}, "closed": true, "closedAt": "2020-03-16T19:25:24Z", "author": {"login": "max-jacobs"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKuS9aAH2gAyMzg2MjQxMDQ5OjI1NTYwZjdmNjM2NDE0NjI1ODJlNTFkZDA2ODM4ODVmMDQ0YTg3NzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOShW-gH2gAyMzg2MjQxMDQ5Ojk3MWU2NjkxMmY0MzQzYThjMjgyZGY5OTNlODA0YzcxODUzMjk1NDI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "25560f7f63641462582e51dd0683885f044a8770", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/25560f7f63641462582e51dd0683885f044a8770", "committedDate": "2020-03-05T16:41:40Z", "message": "Initial commit with flakey test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0000ac52659bc5f568298aade29a6bbf34c0469f", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/0000ac52659bc5f568298aade29a6bbf34c0469f", "committedDate": "2020-03-06T10:38:51Z", "message": "Updates to test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42dc731e5d0c2ef13062160472ca6970ad3c417e", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/42dc731e5d0c2ef13062160472ca6970ad3c417e", "committedDate": "2020-03-06T10:59:10Z", "message": "Updates to test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d0d1003a2e13d146672676d3e7734fdc83c2209", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/2d0d1003a2e13d146672676d3e7734fdc83c2209", "committedDate": "2020-03-06T11:56:59Z", "message": "Adding column in between two columns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56ab02c2016946200ef75378abb5eba7e9160d53", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/56ab02c2016946200ef75378abb5eba7e9160d53", "committedDate": "2020-03-06T15:22:25Z", "message": "Some changes to use Parquet"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85b74ba8cd7433ef729e7821612b5bb66e9efd15", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/85b74ba8cd7433ef729e7821612b5bb66e9efd15", "committedDate": "2020-03-09T17:33:36Z", "message": "Test now failing successfully"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a548c9558a3bdba13050e8c6fb94eece4451f056", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/a548c9558a3bdba13050e8c6fb94eece4451f056", "committedDate": "2020-03-10T15:12:32Z", "message": "Creating AlterTableService and operations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f6ff366016d268c2e93976d46fc50e46b8dde2e", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/0f6ff366016d268c2e93976d46fc50e46b8dde2e", "committedDate": "2020-03-10T15:50:07Z", "message": "Fixing integration test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c304abc4f55f8828e0e6777d2bf607e6942d5a35", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/c304abc4f55f8828e0e6777d2bf607e6942d5a35", "committedDate": "2020-03-10T16:01:35Z", "message": "Fixing integration test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8638af1b9b822b534bfd864a7c2f702d6810c6ae", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/8638af1b9b822b534bfd864a7c2f702d6810c6ae", "committedDate": "2020-03-10T16:15:11Z", "message": "Fixing unit tests and copyright"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyMTM0NTAx", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372134501", "createdAt": "2020-03-10T16:46:40Z", "commit": {"oid": "8638af1b9b822b534bfd864a7c2f702d6810c6ae"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNjo0Njo0MFrOF0Xr0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNjo0Njo0MFrOF0Xr0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDQ1ODMyMQ==", "bodyText": "Why you have to refresh the tables?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390458321", "createdAt": "2020-03-10T16:46:40Z", "author": {"login": "patduin"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private final static Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    from = client.getTable(from.getDbName(), from.getTableName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8638af1b9b822b534bfd864a7c2f702d6810c6ae"}, "originalPosition": 40}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/8d5ededfcc255059e1dfccca72b31d0d23daf55f", "committedDate": "2020-03-10T17:15:49Z", "message": "Some fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNjU0MDAy", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372654002", "createdAt": "2020-03-11T10:55:06Z", "commit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMDo1NTowNlrOF0yBjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMDo1NToxOFrOF0yB7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTg2OQ==", "bodyText": "This was for debugging ?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390889869", "createdAt": "2020-03-11T10:55:06Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,115 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+\n+    Table replicaTable = replicaHelper.createParquetPartitionedTableWithStruct(\n+        toUri(replicaWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schema,\n+        \"struct<name:string, city:string>\",\n+        structData,\n+        1);\n+    LOG.info(\">>>> Table {} \", replicaCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTk2Nw==", "bodyText": "this one too.", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390889967", "createdAt": "2020-03-11T10:55:18Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,115 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+\n+    Table replicaTable = replicaHelper.createParquetPartitionedTableWithStruct(\n+        toUri(replicaWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schema,\n+        \"struct<name:string, city:string>\",\n+        structData,\n+        1);\n+    LOG.info(\">>>> Table {} \", replicaCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));\n+\n+    replicaTable.getParameters().put(\"com.hotels.bdp.circustrain.replication.event\", \"event_id\");\n+    replicaCatalog.client().alter_table(DATABASE, PARTITIONED_TABLE, replicaTable);\n+\n+    // Create the source partition with the original struct.\n+    helper.createData(toUri(sourceWarehouseUri, DATABASE, PARTITIONED_TABLE), schema, \"1\", 1, structData);\n+\n+    // Create the source table with an additional column in the struct.\n+    Schema schemaV2 = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .optionalString(\"dob\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+    structData.put(\"dob\", \"22/09/1992\");\n+\n+    Table table = helper.createParquetPartitionedTableWithStruct(\n+        toUri(sourceWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schemaV2,\n+        \"struct<name:string, city:string, dob:string>\",\n+        structData,\n+        2);\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "originalPosition": 96}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNjkzMjU0", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372693254", "createdAt": "2020-03-11T11:57:25Z", "commit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMTo1NzoyNVrOF0z7ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMTo1NzoyNVrOF0z7ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA==", "bodyText": "Does this copy all the table properties?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390921118", "createdAt": "2020-03-11T11:57:25Z", "author": {"login": "patduin"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableService.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.bdp.circustrain.core.replica.Replica;\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class AlterTableService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(Replica.class);\n+\n+  private CopyPartitionsOperation copyPartitionsOperation;\n+  private RenameTableOperation renameTableOperation;\n+\n+  public AlterTableService(\n+      CopyPartitionsOperation copyPartitionsOperation,\n+      RenameTableOperation renameTableOperation) {\n+    this.copyPartitionsOperation = copyPartitionsOperation;\n+    this.renameTableOperation = renameTableOperation;\n+  }\n+\n+  public void alterTable(CloseableMetaStoreClient client, Table oldTable, Table newTable) throws TException {\n+    List<FieldSchema> oldColumns = oldTable.getSd().getCols();\n+    List<FieldSchema> newColumns = newTable.getSd().getCols();\n+    if (hasAnyChangedColumns(oldColumns, newColumns)) {\n+      LOG\n+          .info(\"Found columns that have changed type, attempting to recreate target table with the new columns.\"\n+              + \"Old columns: {}, new columns: {}\", oldColumns, newColumns);\n+      Table tempTable = new Table(newTable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyNjk3MDcw", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372697070", "createdAt": "2020-03-11T12:03:40Z", "commit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMjowMzo0MFrOF00HGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMjowMzo0MFrOF00HGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyNDA1Nw==", "bodyText": "We need to double check beekeeper props and we don't accidentally delete folders when we drop this table.", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390924057", "createdAt": "2020-03-11T12:03:40Z", "author": {"login": "patduin"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private final static Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    from = client.getTable(from.getDbName(), from.getTableName());\n+    to = client.getTable(to.getDbName(), to.getTableName());\n+    String fromTableName = from.getTableName();\n+    String toTableName = to.getTableName();\n+    String toTableNameTemp = toTableName + \"_original\";\n+    try {\n+      from.setTableName(toTableName);\n+      to.setTableName(toTableNameTemp);\n+      client.alter_table(to.getDbName(), toTableName, to);\n+      client.alter_table(from.getDbName(), fromTableName, from);\n+    } finally {\n+      client.dropTable(to.getDbName(), toTableNameTemp, false, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "originalPosition": 51}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12aa8157e72b1efc4679aca55943e1f25be3cbf0", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/12aa8157e72b1efc4679aca55943e1f25be3cbf0", "committedDate": "2020-03-11T14:40:15Z", "message": "Adding DropTableService which removes custom table parameters before dropping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1b2eac5e822353acd52855a6f607262166f1116", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/e1b2eac5e822353acd52855a6f607262166f1116", "committedDate": "2020-03-11T14:45:15Z", "message": "Adding changelog and other bits"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/4ce2b900d03183a48b66efd01c2322bf3999bd20", "committedDate": "2020-03-11T15:15:18Z", "message": "Added catch for non existent table"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyOTIyMDc2", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372922076", "createdAt": "2020-03-11T16:25:38Z", "commit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjoyNTozOFrOF0-wjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjoyNTo1NVrOF0-xVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODUwOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static final Logger LOG = LoggerFactory.getLogger(AlterTableService.class);\n          \n          \n            \n              private static final Logger log = LoggerFactory.getLogger(AlterTableService.class);\n          \n      \n    \n    \n  \n\n(it's not a constant)", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391098508", "createdAt": "2020-03-11T16:25:38Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class AlterTableService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(AlterTableService.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODcwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  ReplicaTableFactoryProvider replicaTableFactoryPicker,\n          \n          \n            \n                  ReplicaTableFactoryProvider replicaTableFactoryProvider,", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391098709", "createdAt": "2020-03-11T16:25:55Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/ReplicaFactory.java", "diffHunk": "@@ -49,19 +55,24 @@ public ReplicaFactory(\n       Supplier<CloseableMetaStoreClient> replicaMetaStoreClientSupplier,\n       HousekeepingListener housekeepingListener,\n       ReplicaCatalogListener replicaCatalogListener,\n-      ReplicaTableFactoryProvider replicaTableFactoryPicker) {\n+      ReplicaTableFactoryProvider replicaTableFactoryPicker,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyOTQwMzgy", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-372940382", "createdAt": "2020-03-11T16:47:03Z", "commit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjo0NzowNFrOF0_pyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjo0NzowNFrOF0_pyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTExMzE2MQ==", "bodyText": "to be deleted?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391113161", "createdAt": "2020-03-11T16:47:04Z", "author": {"login": "max-jacobs"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+  private static final String TEMP_SUFFIX = \"_original\";\n+\n+  private DropTableService dropTableService;\n+\n+  public RenameTableOperation(DropTableService dropTableService) {\n+    this.dropTableService = dropTableService;\n+  }\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    Table fromTable = client.getTable(from.getDbName(), from.getTableName());\n+    Table toTable = client.getTable(to.getDbName(), to.getTableName());\n+    String fromTableName = fromTable.getTableName();\n+    String toTableName = toTable.getTableName();\n+    try {\n+      fromTable.setTableName(toTableName);\n+      toTable.setTableName(toTableName + TEMP_SUFFIX);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20"}, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ee9d232ad75ca78653032f00a649d832a906da0", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/7ee9d232ad75ca78653032f00a649d832a906da0", "committedDate": "2020-03-12T11:54:34Z", "message": "Fixing some bits, renaming, adding external key to table when dropping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "committedDate": "2020-03-12T12:06:46Z", "message": "Undoing unnecessary changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczNzQ0Mjkx", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-373744291", "createdAt": "2020-03-12T17:08:30Z", "commit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNzowODozMVrOF1nixg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNzoxMzozOFrOF1nu2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NjcyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private StorageDescriptor getSd(List<FieldSchema> columns) {\n          \n          \n            \n              private StorageDescriptor createStorageDescriptor(List<FieldSchema> columns) {", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391766726", "createdAt": "2020-03-12T17:08:31Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableServiceTest.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.fail;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.verifyZeroInteractions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class AlterTableServiceTest {\n+\n+  private static final String OLD_TABLE_NAME = \"old_table\";\n+  private static final String NEW_TABLE_NAME = \"new_table\";\n+  private static final String NEW_TABLE_NAME_TEMP = NEW_TABLE_NAME + \"_temp\";\n+  private static final String OLD_DB_NAME = \"old_db\";\n+  private static final String NEW_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Mock DropTableService dropTableService;\n+  private @Mock CopyPartitionsOperation copyPartitionsOperation;\n+  private @Mock RenameTableOperation renameTableOperation;\n+\n+  private AlterTableService service;\n+  private Table oldTable = new Table();\n+  private Table newTable = new Table();\n+\n+  @Before\n+  public void setUp() {\n+    service = new AlterTableService(dropTableService, copyPartitionsOperation, renameTableOperation);\n+    oldTable.setTableName(OLD_TABLE_NAME);\n+    newTable.setTableName(NEW_TABLE_NAME);\n+    oldTable.setDbName(OLD_DB_NAME);\n+    newTable.setDbName(NEW_DB_NAME);\n+  }\n+\n+  @Test\n+  public void typicalAlterTable() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+\n+    service.alterTable(client, oldTable, newTable);\n+\n+    verify(client).alter_table(NEW_DB_NAME, NEW_TABLE_NAME, newTable);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void alterTableColumnChange() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+\n+    service.alterTable(client, oldTable, newTable);\n+\n+    verify(client).createTable(tempTable);\n+    verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+    verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+    verify(renameTableOperation).execute(client, tempTable, newTable);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void alterTableCopyPartitionsFails() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+    TException toBeThrown = new TException(\"error\");\n+    doThrow(toBeThrown).when(copyPartitionsOperation).execute(client, newTable, tempTable);\n+\n+    try {\n+      service.alterTable(client, oldTable, newTable);\n+      fail(\"Should have thrown exception.\");\n+    } catch (Exception e) {\n+      verify(client).createTable(tempTable);\n+      verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+      verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+      verifyZeroInteractions(renameTableOperation);\n+      verifyNoMoreInteractions(client);\n+      assertThat(e, is(toBeThrown));\n+    }\n+  }\n+\n+  @Test\n+  public void alterTableRenameTableFails() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+    TException toBeThrown = new TException(\"error\");\n+    doThrow(toBeThrown).when(renameTableOperation).execute(client, tempTable, newTable);\n+\n+    try {\n+      service.alterTable(client, oldTable, newTable);\n+      fail(\"Should have thrown exception.\");\n+    } catch (Exception e) {\n+      verify(client).createTable(tempTable);\n+      verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+      verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+      verify(renameTableOperation).execute(client, tempTable, newTable);\n+      verifyNoMoreInteractions(client);\n+      assertThat(e, is(toBeThrown));\n+    }\n+  }\n+\n+  private StorageDescriptor getSd(List<FieldSchema> columns) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzA2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                ArrayList<Partition> partitions = new ArrayList<>();\n          \n          \n            \n                List<Partition> partitions = new ArrayList<>();", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767061", "createdAt": "2020-03-12T17:09:04Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/CopyPartitionsOperationTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Partition;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class CopyPartitionsOperationTest {\n+\n+  private static final short BATCH_SIZE = 2;\n+  private static final String OLD_TABLE_NAME = \"old_table\";\n+  private static final String NEW_TABLE_NAME = \"new_table\";\n+  private static final String OLD_DB_NAME = \"old_db\";\n+  private static final String NEW_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<List<Partition>> partitionCaptor;\n+  private Table oldTable = new Table();\n+  private Table newTable = new Table();\n+  private CopyPartitionsOperation operation;\n+\n+  @Before\n+  public void setUp() {\n+    operation = new CopyPartitionsOperation(BATCH_SIZE);\n+    oldTable.setTableName(OLD_TABLE_NAME);\n+    newTable.setTableName(NEW_TABLE_NAME);\n+    oldTable.setDbName(OLD_DB_NAME);\n+    newTable.setDbName(NEW_DB_NAME);\n+    StorageDescriptor sd = new StorageDescriptor();\n+    sd.setCols(Arrays.asList(new FieldSchema(\"id\", \"bigint\", \"\")));\n+    newTable.setSd(sd);\n+  }\n+\n+  @Test\n+  public void typicalCopyPartitions() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\")))\n+        .thenReturn(createPartitions(1));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(1)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(1));\n+    assertThat(captured.get(0).size(), is(1));\n+  }\n+\n+  @Test\n+  public void singleBatch() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\", \"part2\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\", \"part2\")))\n+        .thenReturn(createPartitions(2));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(1)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(1));\n+    assertThat(captured.get(0).size(), is(2));\n+  }\n+\n+  @Test\n+  public void multipleBatches() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\", \"part2\", \"part3\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\", \"part2\")))\n+        .thenReturn(createPartitions(2));\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part3\")))\n+        .thenReturn(createPartitions(1));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(2)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(2));\n+    assertThat(captured.get(0).size(), is(2));\n+    assertThat(captured.get(1).size(), is(1));\n+  }\n+\n+  @Test\n+  public void noPartitions() throws Exception {\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(Collections.emptyList());\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Collections.emptyList()))\n+        .thenReturn(Collections.emptyList());\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client).listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1);\n+    verify(client).getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Collections.emptyList());\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  private List<Partition> createPartitions(int count) {\n+    ArrayList<Partition> partitions = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzM1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> params = new HashMap<>();\n          \n          \n            \n                Map<String, String> params = new HashMap<>();", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767359", "createdAt": "2020-03-12T17:09:35Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/DropTableServiceTest.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class DropTableServiceTest {\n+\n+  private static final String TABLE_NAME = \"table\";\n+  private static final String DB_NAME = \"db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<Table> tableCaptor;\n+\n+  private DropTableService service;\n+  private Table table = new Table();\n+\n+  @Before\n+  public void setUp() throws TException {\n+    service = new DropTableService();\n+    table.setTableName(TABLE_NAME);\n+    table.setDbName(DB_NAME);\n+    when(client.getTable(DB_NAME, TABLE_NAME)).thenReturn(table);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropNullParams() throws TException {\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropEmptyParams() throws TException {\n+    table.setParameters(Collections.emptyMap());\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDrop() throws TException {\n+    HashMap<String, String> params = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzQ1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> params = new HashMap<>();\n          \n          \n            \n                Map<String, String> params = new HashMap<>();", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767451", "createdAt": "2020-03-12T17:09:44Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/DropTableServiceTest.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class DropTableServiceTest {\n+\n+  private static final String TABLE_NAME = \"table\";\n+  private static final String DB_NAME = \"db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<Table> tableCaptor;\n+\n+  private DropTableService service;\n+  private Table table = new Table();\n+\n+  @Before\n+  public void setUp() throws TException {\n+    service = new DropTableService();\n+    table.setTableName(TABLE_NAME);\n+    table.setDbName(DB_NAME);\n+    when(client.getTable(DB_NAME, TABLE_NAME)).thenReturn(table);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropNullParams() throws TException {\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropEmptyParams() throws TException {\n+    table.setParameters(Collections.emptyMap());\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDrop() throws TException {\n+    HashMap<String, String> params = new HashMap<>();\n+    params.put(\"key1\", \"value\");\n+    params.put(\"key2\", \"value\");\n+    params.put(\"EXTERNAL\", \"true\");\n+    table.setParameters(params);\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).alter_table(eq(DB_NAME), eq(TABLE_NAME), tableCaptor.capture());\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+    List<Table> capturedTables = tableCaptor.getAllValues();\n+    assertThat(capturedTables.size(), is(1));\n+    Map<String, String> parameters = capturedTables.get(0).getParameters();\n+    assertThat(parameters.size(), is(1));\n+    assertThat(parameters.get(\"EXTERNAL\"), is(\"true\"));\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropCaseInsensitiveExternalTable() throws TException {\n+    HashMap<String, String> params = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2ODQ0OQ==", "bodyText": "Why did you move this down here? Ideally the dependencies should be alpha sorted by groupId and then artifactId in two sections - one for normal scope and another for test scope.", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391768449", "createdAt": "2020-03-12T17:11:23Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/pom.xml", "diffHunk": "@@ -172,6 +165,28 @@\n       <artifactId>protobuf-java</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.parquet</groupId>\n+      <artifactId>parquet-avro</artifactId>\n+      <version>1.10.1</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.apache.avro</groupId>\n+      <artifactId>avro</artifactId>\n+      <version>1.9.0</version>\n+    </dependency>\n+    <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2ODg3MA==", "bodyText": "I'd be wary of setting these to version numbers other than what the Hive/Hadoop dependencies are using. I guess this works but I just know how fragile things can get as the newer versions aren't backwards compatible and the only reason we're not seeing an issue now is we haven't hit certain code paths that would trigger problems.", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391768870", "createdAt": "2020-03-12T17:12:06Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/pom.xml", "diffHunk": "@@ -172,6 +165,28 @@\n       <artifactId>protobuf-java</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2OTEyMA==", "bodyText": "Line break", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391769120", "createdAt": "2020-03-12T17:12:32Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest/partitioned-single-table-one-partition.yml", "diffHunk": "@@ -0,0 +1,15 @@\n+table-replications:\n+  - source-table:\n+      database-name: ${circus-train-runner.database-name}\n+      table-name: ct_table_p\n+      partition-filter: (hour='1') OR (hour='2') OR (hour='3') OR (hour='4')\n+      partition-limit: 100\n+    replica-table:\n+      table-location: ${circus-train-runner.replica-warehouse-uri}/${circus-train-runner.database-name}/ct_table_p\n+    orphaned-data-strategy: NONE\n+copier-options:\n+  file-attribute: replication, blocksize, user, group, permission, checksumtype\n+  preserve-raw-xattrs: false\n+metrics-reporter:\n+  period: 1\n+  time-unit: SECONDS", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2OTI5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> structData = new HashMap<>();\n          \n          \n            \n                Map<String, String> structData = new HashMap<>();", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391769298", "createdAt": "2020-03-12T17:12:49Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,119 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2OTgxNw==", "bodyText": "Don't we want to throw this and fail the test if this happens?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391769817", "createdAt": "2020-03-12T17:13:38Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/IntegrationTestHelper.java", "diffHunk": "@@ -74,6 +87,60 @@ void createPartitionedTable(URI sourceTableUri) throws Exception {\n                         newTablePartition(hiveTable, Arrays.asList(\"Asia\", \"China\"), partitionChina))));\n   }\n \n+  Table createParquetPartitionedTableWithStruct(\n+      URI tableUri,\n+      Schema schema,\n+      String structType,\n+      Map<String, String> structData,\n+      int version) throws Exception {\n+    List<FieldSchema> columns = Arrays.asList(\n+        new FieldSchema(\"id\", \"string\", \"\"),\n+        new FieldSchema(\"details\", structType, \"\")\n+    );\n+    List<FieldSchema> partitionKeys = Arrays.asList(new FieldSchema(\"hour\", \"string\", \"\"));\n+    Table table = TestUtils\n+        .createPartitionedTable(metaStoreClient, DATABASE, PARTITIONED_TABLE, tableUri, columns, partitionKeys,\n+            \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\", ParquetInputFormat.class.getName(),\n+            ParquetOutputFormat.class.getName());\n+    URI partition = createData(tableUri, schema, Integer.toString(version), version, structData);\n+    metaStoreClient.add_partitions(Arrays.asList(newTablePartition(table,\n+        Arrays.asList(Integer.toString(version)), partition)));\n+    return metaStoreClient.getTable(DATABASE, PARTITIONED_TABLE);\n+  }\n+\n+  URI createData(\n+      URI tableUri,\n+      Schema schema,\n+      String hour,\n+      int id,\n+      Map<String, String> detailsStruct) throws IOException {\n+    GenericData.Record record = new GenericData.Record(schema);\n+    Schema detailsSchema = schema.getField(\"details\").schema();\n+    GenericData.Record details = new GenericData.Record(detailsSchema);\n+    detailsStruct.forEach(details::put);\n+    record.put(\"id\", id);\n+    record.put(\"details\", details);\n+\n+    URI partition = URI.create(tableUri + \"/hour=\" + hour);\n+    String path = partition.getPath();\n+    File parentFolder = new File(path);\n+    parentFolder.mkdirs();\n+    File partitionFile = new File(parentFolder, \"parquet0000\");\n+    Path filePath = new Path(partitionFile.toURI());\n+    ParquetWriter<GenericData.Record> writer = AvroParquetWriter.<GenericData.Record>builder(filePath)\n+        .withSchema(schema)\n+        .withConf(new Configuration())\n+        .build();\n+\n+    try {\n+      writer.write(record);\n+    } catch (IOException e) {\n+      e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "890ea8d1a8319bab6dbb82258cdd21d2a26bc6de", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/890ea8d1a8319bab6dbb82258cdd21d2a26bc6de", "committedDate": "2020-03-13T11:12:32Z", "message": "Fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b933684b80afe94031fb06103e198f6d7571af3", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/2b933684b80afe94031fb06103e198f6d7571af3", "committedDate": "2020-03-13T11:18:53Z", "message": "Fixing pom"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0MjU0MzMx", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-374254331", "createdAt": "2020-03-13T12:17:30Z", "commit": {"oid": "2b933684b80afe94031fb06103e198f6d7571af3"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxMjoxNzozMFrOF2Bj-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QxMjoyMzo1MFrOF2BuGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE5MzAxNw==", "bodyText": "OK, let's go with that for now and keep an eye on it when this is in use.", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392193017", "createdAt": "2020-03-13T12:17:30Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableService.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.bdp.circustrain.core.replica.Replica;\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class AlterTableService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(Replica.class);\n+\n+  private CopyPartitionsOperation copyPartitionsOperation;\n+  private RenameTableOperation renameTableOperation;\n+\n+  public AlterTableService(\n+      CopyPartitionsOperation copyPartitionsOperation,\n+      RenameTableOperation renameTableOperation) {\n+    this.copyPartitionsOperation = copyPartitionsOperation;\n+    this.renameTableOperation = renameTableOperation;\n+  }\n+\n+  public void alterTable(CloseableMetaStoreClient client, Table oldTable, Table newTable) throws TException {\n+    List<FieldSchema> oldColumns = oldTable.getSd().getCols();\n+    List<FieldSchema> newColumns = newTable.getSd().getCols();\n+    if (hasAnyChangedColumns(oldColumns, newColumns)) {\n+      LOG\n+          .info(\"Found columns that have changed type, attempting to recreate target table with the new columns.\"\n+              + \"Old columns: {}, new columns: {}\", oldColumns, newColumns);\n+      Table tempTable = new Table(newTable);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}, "originalCommit": {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE5NTYxMA==", "bodyText": "NABD but would be nice to replace \"1\" and \"2\" in this and the next method with something more descriptive as to what the difference is. From what I can see it's about where the exception is thrown, when altering the to or the from table? So maybe something like renameToTableException and renameFromTableException?", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392195610", "createdAt": "2020-03-13T12:23:50Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperationTest.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.fail;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class RenameTableOperationTest {\n+\n+  private static final String FROM_TABLE_NAME = \"old_table\";\n+  private static final String TO_TABLE_NAME = \"new_table\";\n+  private static final String TO_TABLE_NAME_TEMP = TO_TABLE_NAME + \"_delete_me\";\n+  private static final String FROM_DB_NAME = \"old_db\";\n+  private static final String TO_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Mock DropTableService dropTableService;\n+  private Table fromTable = new Table();\n+  private Table toTable = new Table();\n+  private RenameTableOperation operation;\n+\n+  @Before\n+  public void setUp() throws TException {\n+    operation = new RenameTableOperation(dropTableService);\n+    fromTable.setTableName(FROM_TABLE_NAME);\n+    toTable.setTableName(TO_TABLE_NAME);\n+    fromTable.setDbName(FROM_DB_NAME);\n+    toTable.setDbName(TO_DB_NAME);\n+    when(client.getTable(FROM_DB_NAME, FROM_TABLE_NAME)).thenReturn(fromTable);\n+    when(client.getTable(TO_DB_NAME, TO_TABLE_NAME)).thenReturn(toTable);\n+  }\n+\n+  @Test\n+  public void typicalRenameTable() throws Exception {\n+    Table toTableTemp = new Table(toTable);\n+    toTableTemp.setTableName(TO_TABLE_NAME_TEMP);\n+\n+    operation.execute(client, fromTable, toTable);\n+\n+    fromTable.setTableName(TO_TABLE_NAME);\n+    verify(client).alter_table(TO_DB_NAME, TO_TABLE_NAME, toTableTemp);\n+    verify(client).alter_table(FROM_DB_NAME, FROM_TABLE_NAME, fromTable);\n+    verify(dropTableService).removeTableParamsAndDrop(client, TO_DB_NAME, TO_TABLE_NAME_TEMP);\n+  }\n+\n+  @Test\n+  public void renameTableExceptionThrown1() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b933684b80afe94031fb06103e198f6d7571af3"}, "originalPosition": 76}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b2664f8eb5a3757b1a531868387eb50516a9f66", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/2b2664f8eb5a3757b1a531868387eb50516a9f66", "committedDate": "2020-03-13T12:54:20Z", "message": "Fixing pom and test names"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0Mzk1OTM3", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#pullrequestreview-374395937", "createdAt": "2020-03-13T15:30:31Z", "commit": {"oid": "2b2664f8eb5a3757b1a531868387eb50516a9f66"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8cd3a80e502048fa97999d52bbad460f07ded75", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/e8cd3a80e502048fa97999d52bbad460f07ded75", "committedDate": "2020-03-16T18:17:11Z", "message": "Minor change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e40d296706864874e46b430285b4ef390f71373", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/4e40d296706864874e46b430285b4ef390f71373", "committedDate": "2020-03-16T18:20:30Z", "message": "Merge branch 'master' into issue-173-struct-evolution"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "971e66912f4343a8c282df993e804c7185329542", "author": {"user": null}, "url": "https://github.com/ExpediaGroup/circus-train/commit/971e66912f4343a8c282df993e804c7185329542", "committedDate": "2020-03-16T18:35:45Z", "message": "Fixing tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3787, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}