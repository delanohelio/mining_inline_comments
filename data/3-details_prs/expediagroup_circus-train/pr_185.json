{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2ODM2NTgy", "number": 185, "title": "Full overwrite replication", "bodyText": "\ud83d\udcdd Description\nAdded a replication mode FULL_OVERWRITE which will overwrite an existing table with the source. The expected use for this mode would be early during the development cycle when the schema could be subject to incompatible changes.\n\ud83d\udd17 Related Issues\n#183", "createdAt": "2020-05-12T16:29:54Z", "url": "https://github.com/ExpediaGroup/circus-train/pull/185", "merged": true, "mergeCommit": {"oid": "940f9ccfb4e2654607a5544c6582d4cf586e5b2b"}, "closed": true, "closedAt": "2020-06-10T15:20:48Z", "author": {"login": "JayGreeeen"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABceWG3KgH2gAyNDE2ODM2NTgyOjY0MjkzMmNhMGMxMTJkNDdhNTlkYjg4ZmZlOGRhOTZlNmNhMThhYzg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcp4w3TAFqTQyNzk5ODI5MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "642932ca0c112d47a59db88ffe8da96e6ca18ac8", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/642932ca0c112d47a59db88ffe8da96e6ca18ac8", "committedDate": "2020-05-05T15:49:13Z", "message": "Added new replication mode to overwrite tables"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "068a9d5254716512e9b991ac851ba6e856a131c0", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/068a9d5254716512e9b991ac851ba6e856a131c0", "committedDate": "2020-05-05T15:53:21Z", "message": "Updating changelog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb4d269b0148cd47c47c1846820f04555da75bc6", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/eb4d269b0148cd47c47c1846820f04555da75bc6", "committedDate": "2020-05-12T14:16:22Z", "message": "Added integration tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/77c6564f7ff0b36066f3796103817d1a9756d258", "committedDate": "2020-05-12T14:42:06Z", "message": "Added more tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMjMwMTM0", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-410230134", "createdAt": "2020-05-12T16:44:15Z", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjo0NDoxNVrOGUPoBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNjo1NjozOVrOGUQIgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4MDcwOA==", "bodyText": "I think this and the added case in the other switch statement needs some tests", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423880708", "createdAt": "2020-05-12T16:44:15Z", "author": {"login": "max-jacobs"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImpl.java", "diffHunk": "@@ -107,6 +107,7 @@ private Replication createPartitionedTableReplication(\n       replication = new PartitionedTableMetadataMirrorReplication(sourceDatabaseName, sourceTableName,\n           partitionPredicate, source, replica, eventIdFactory, replicaDatabaseName, replicaTableName);\n       break;\n+    case FULL_OVERWRITE:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng==", "bodyText": "Would recommend moving this method to the DropTableService. Also, on a full overwrite I imagine we will want to delete the current data (right?), but if we're using Beekeeper drop table events will be ignored (unless we add the param to allow drop table events). But even if we do this, we won't want to schedule the table path because then Beekeeper will delete any new data that is added after the delete - Beekeeper doesn't yet go to the Metastore to only schedule the current partitions for deletion on a table drop.\nWe probably want to do an alter all the individual partitions to make sure they're deleted and not the new data? Not sure, is that possible?", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887176", "createdAt": "2020-05-12T16:53:57Z", "author": {"login": "max-jacobs"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4Nzk5NQ==", "bodyText": "think you need a fail here to make sure this throws an exception", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887995", "createdAt": "2020-05-12T16:55:05Z", "author": {"login": "max-jacobs"}, "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java", "diffHunk": "@@ -323,6 +327,60 @@ public void validateReplicaTableMetadataMirrorOnExistingMetadataUpdateTableFails\n     }\n   }\n \n+  @Test\n+  public void validateReplicaTableMetadataMirrorOnExistingFullOverwriteReplicationTableFails()\n+    throws TException, IOException {\n+    try {\n+      existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+      existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL_OVERWRITE.name());\n+      tableReplication.setReplicationMode(METADATA_MIRROR);\n+      replica = newReplica(tableReplication);\n+      replica.validateReplicaTable(DB_NAME, TABLE_NAME);\n+      fail(\"Should have thrown InvalidReplicationModeException\");\n+    } catch (InvalidReplicationModeException e) {\n+      // Check that nothing was written to the metastore\n+      verify(mockMetaStoreClient).getTable(DB_NAME, TABLE_NAME);\n+      verify(mockMetaStoreClient).close();\n+      verifyNoMoreInteractions(mockMetaStoreClient);\n+    }\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationOnExistingTableSucceeds() throws TException {\n+    existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+    existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL.name());\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+    verify(alterTableService).alterTable(eq(mockMetaStoreClient), eq(existingReplicaTable), any(Table.class));\n+    verify(mockMetaStoreClient).updateTableColumnStatistics(columnStatistics);\n+    verify(mockReplicaLocationManager, never()).addCleanUpLocation(anyString(), any(Path.class));\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationWithoutExistingTableFails() throws MetaException, TException {\n+    try {\n+    when(mockMetaStoreClient.tableExists(DB_NAME, TABLE_NAME)).thenReturn(false);\n+\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA==", "bodyText": "I think at some point we should think about removing all these duplicated yaml files and building them programmatically, just an idea", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423889024", "createdAt": "2020-05-12T16:56:39Z", "author": {"login": "max-jacobs"}, "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest/partitioned-single-table-full-overwrite.yml", "diffHunk": "@@ -0,0 +1,9 @@\n+table-replications:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMjgxMDQ5", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-410281049", "createdAt": "2020-05-12T17:47:41Z", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNzo0Nzo0MVrOGUSDxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNzo1MDozOVrOGUSKuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMDU4MA==", "bodyText": "If the old replica is dropped, and then later the new replica is recreated, and all new data and partitions are put in a new ctp-... folder, won't Beekeeper eventually find and delete all the old ctp paths from the old (dropped) version of the table?  Or what am I missing?", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423920580", "createdAt": "2020-05-12T17:47:41Z", "author": {"login": "barnharts4"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng=="}, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMjM2Mw==", "bodyText": "Is throwing a No replica table exception necessary here?  What does it buy us?  If a warning were logged here instead, then wouldn't the FULL_OVERWRITE proceed just as a normal FULL operation, and the end result would be just what the user wanted?", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423922363", "createdAt": "2020-05-12T17:50:39Z", "author": {"login": "barnharts4"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+        client.dropTable(replicaDatabaseName, replicaTableName);\n+      } else {\n+        throw new MetaStoreClientException(\"No replica table '\"\n+            + replicaDatabaseName\n+            + \".\"\n+            + replicaTableName\n+            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+            + FULL.name()\n+            + \".\");\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 114}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExMDM5NTI5", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-411039529", "createdAt": "2020-05-13T15:24:40Z", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxNToyNDo0MFrOGU3BEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxNTozNDozN1rOGU3e0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNjA5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private void setupRelicaParameters(Table replicaTable) {\n          \n          \n            \n              private void setupReplicaParameters(Table replicaTable) {", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424526096", "createdAt": "2020-05-13T15:24:40Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzg5Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                setupRelicaParameters(replicaTable);\n          \n          \n            \n                setupReplicaParameters(replicaTable);", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424527893", "createdAt": "2020-05-13T15:27:08Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMDM4OQ==", "bodyText": "This function is not just setting params but also adding two new columns to the table. Splitting this function up would be better.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424530389", "createdAt": "2020-05-13T15:30:06Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMzcxNQ==", "bodyText": "same comments here. Typo and splitting up.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424533715", "createdAt": "2020-05-13T15:34:37Z", "author": {"login": "abhimanyugupta07"}, "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java", "diffHunk": "@@ -273,4 +282,139 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+    TestUtils.createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+\n+    // setting up parameters, additional columns and partitions\n+    setupReplicaTable(replicaTable, true, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_TABLE, (short) -1);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    final URI sourceTableLocation = toUri(\"s3a://source/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(sourceCatalog.client(), DATABASE, UNPARTITIONED_TABLE, sourceTableLocation);\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final File dataFile = temporaryFolder.newFile();\n+    FileUtils.writeStringToFile(dataFile, \"1\\trob\\tbristol\\n2\\tsam\\ttoronto\\n\");\n+    String fileKey = String.format(\"%s/%s/%s\", DATABASE, UNPARTITIONED_TABLE, PART_00000);\n+    s3Client.putObject(\"source\", fileKey, dataFile);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+        String eventId = hiveTable.getParameters().get(REPLICATION_EVENT.parameterName());\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_UNPARTITIONED_TABLE + \"/\" + eventId);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(eventId, startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        // Assert files copied from source\n+        List<S3ObjectSummary> replicaFiles = TestUtils.listObjects(s3Client, \"replica\");\n+        assertThat(replicaFiles.size(), is(1));\n+        assertThat(replicaFiles.get(0).getSize(), is(dataFile.length()));\n+        String fileKey = String\n+            .format(\"%s/%s/%s/%s\", DATABASE, TARGET_UNPARTITIONED_TABLE, eventId, PART_00000);\n+        assertThat(replicaFiles.get(0).getKey(), is(fileKey));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 168}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNjgxMDE1", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-411681015", "createdAt": "2020-05-14T10:41:44Z", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMDo0MTo0NFrOGVWe1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMDo1Mjo0MVrOGVW1Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MTYyMw==", "bodyText": "Let's go with 16.2.0 as the version number as this is a new feature.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425041623", "createdAt": "2020-05-14T10:41:44Z", "author": {"login": "massdosage"}, "path": "CHANGELOG.md", "diffHunk": "@@ -2,6 +2,9 @@\n ### Changed\n * Changed version of `hive.version` to `2.3.7` (was `2.3.2`). This allows Circus Train to be used on JDK>=9.\n \n+### Added\n+* Replication mode `FULL_OVERWRITE` to overwrite a previously replicated table. Useful for incompatible schema changes. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjAwNg==", "bodyText": "Good spot ;)", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042006", "createdAt": "2020-05-14T10:42:29Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -346,12 +351,12 @@ public void validateReplicaTable(String replicaDatabaseName, String replicaTable\n       Optional<Table> oldReplicaTable = getTable(client, replicaDatabaseName, replicaTableName);\n       if (oldReplicaTable.isPresent()) {\n         LOG.debug(\"Existing table found, checking that it is a valid replica.\");\n-        determinValidityOfReplica(replicationMode, oldReplicaTable.get());\n+        determineValidityOfReplica(replicationMode, oldReplicaTable.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjQwNA==", "bodyText": "Move this up to below FULL - they feel more \"related\" and I don't think we use the ordering of this enum for anything.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042404", "createdAt": "2020-05-14T10:43:12Z", "author": {"login": "massdosage"}, "path": "circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java", "diffHunk": "@@ -19,6 +19,8 @@\n \n   FULL,\n   METADATA_MIRROR,\n-  METADATA_UPDATE;\n+  METADATA_UPDATE,\n+  FULL_OVERWRITE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0NDU3NQ==", "bodyText": "The intention initially was for the integration tests to read in the yaml to ensure the yaml conversion code etc. is working. I don't think we envisioned there being this many integration tests, ideally we should only add them to test things that can't be tested in any other way.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425044575", "createdAt": "2020-05-14T10:47:19Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest/partitioned-single-table-full-overwrite.yml", "diffHunk": "@@ -0,0 +1,9 @@\n+table-replications:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA=="}, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0NzM0Nw==", "bodyText": "Having looked through the above I'm not sure we need to add these tests to all combinations of HDFS and S3 as they probably don't really test anything new in each of them right? Perhaps create a new CircusTrainReplicationModeIntegrationTest and then put the two tests into that and have it use S3 to S3 for the location on each side (as that's becoming the most used file system on both sides now).\nAt some point we should review the other integration tests and see if there is other overlap that isn't needed that can be refactored out to reduce the number of these.", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425047347", "createdAt": "2020-05-14T10:52:41Z", "author": {"login": "massdosage"}, "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest/unpartitioned-single-table-full-overwrite-replication.yml", "diffHunk": "@@ -0,0 +1,10 @@\n+table-replications:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNzk3NjM2", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-411797636", "createdAt": "2020-05-14T13:22:35Z", "commit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMzoyMjozNVrOGVb-pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMzoyMjozNVrOGVb-pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEzMTY4NA==", "bodyText": "This call is a \"new\" addition of the hive API I'm not sure if we use it anywhere else but if we do it is ok but if we don't better to avoid using it as it's not always there on old client.\nBetter to just do the\nTry\ndropTable() \nCatch(NoSuchObjectException e) {\n//nothing to drop table doesn't exist etc.....\n}", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425131684", "createdAt": "2020-05-14T13:22:35Z", "author": {"login": "patduin"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258"}, "originalPosition": 104}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/7f25cff5174805a209500a7cffcb7faf4fe121ff", "committedDate": "2020-05-28T11:58:55Z", "message": "Created integration test for new replication mode."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb0d8dc12554a6194e6031889b5b78681826737f", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/bb0d8dc12554a6194e6031889b5b78681826737f", "committedDate": "2020-05-28T12:02:24Z", "message": "Cleaning up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b623630151a38a8a703747896485d295add8b627", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/b623630151a38a8a703747896485d295add8b627", "committedDate": "2020-05-28T12:09:43Z", "message": "Added tests for switch case, and removed comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzNDEzMDM3", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-423413037", "createdAt": "2020-06-03T10:15:58Z", "commit": {"oid": "b623630151a38a8a703747896485d295add8b627"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxMDoxNTo1OFrOGeVZSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxMDoxNTo1OFrOGeVZSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg==", "bodyText": "I think the TException could be thrown for other reasons too, like network problems etc. So perhaps it would be better to have a try/catch for TException that retrhrows a MetaStoreClientException like in some of the blocks below, and then introduce a \"does table exist\" check in the code (maybe in the service?) and if it doesn't then it just silently continues without throwing an exception (as this is fine, there's no need to drop the replica if it doesn't exist).", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434461002", "createdAt": "2020-06-03T10:15:58Z", "author": {"login": "massdosage"}, "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -302,6 +304,16 @@ public void updateMetadata(\n     LOG.info(\"Updating replica table metadata.\");\n     TableAndStatistics replicaTable = tableFactory\n         .newReplicaTable(eventId, sourceTable, replicaDatabaseName, replicaTableName, tableLocation, replicationMode);\n+\n+    if (replicationMode == FULL_OVERWRITE) {\n+      LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table and its data.\");\n+      DropTableService dropTableService = new DropTableService();\n+      try {\n+        dropTableService.removeTableParamsAndDrop(client, replicaDatabaseName, replicaTableName);\n+      } catch (TException e) {\n+        LOG.info(\"No replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' found. Nothing to delete.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b623630151a38a8a703747896485d295add8b627"}, "originalPosition": 52}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "committedDate": "2020-06-03T10:43:20Z", "message": "Changing log messages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c985f96cb80fc03446388ef88e8e364b9c577d8a", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/c985f96cb80fc03446388ef88e8e364b9c577d8a", "committedDate": "2020-06-03T11:28:03Z", "message": "Removing log to throw metastore client exception instead"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzNDk3MTIy", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-423497122", "createdAt": "2020-06-03T12:23:14Z", "commit": {"oid": "c985f96cb80fc03446388ef88e8e364b9c577d8a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI3OTk4Mjkw", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#pullrequestreview-427998290", "createdAt": "2020-06-10T12:25:02Z", "commit": {"oid": "c985f96cb80fc03446388ef88e8e364b9c577d8a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3806, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}