{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQwNjcxNzk2", "number": 190, "title": "Add developers md", "bodyText": "\ud83d\udcdd Description\nAdded a DEVELOPERS.md file based on the notes I have taken while working on CT.\n\ud83d\udd17 Related Issues", "createdAt": "2020-06-26T16:16:28Z", "url": "https://github.com/ExpediaGroup/circus-train/pull/190", "merged": true, "mergeCommit": {"oid": "a2c254c4dc4b14f5537e7926cc78ec27078b418b"}, "closed": true, "closedAt": "2020-07-23T13:51:38Z", "author": {"login": "JayGreeeen"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcvEvrMgH2gAyNDQwNjcxNzk2OmU3MjJmYzM0NDM5ODI3Mzc0NThkNjM1NWQ1MDhmMTRlODI3YjFmYjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3vv0QgFqTQ1NDE0OTAyMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e722fc3443982737458d6355d508f14e827b1fb1", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/e722fc3443982737458d6355d508f14e827b1fb1", "committedDate": "2020-06-26T15:12:13Z", "message": "Added DEVELOPERS.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a47180d0a8a5db4992608cae6b1d5f87d72eae1f", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/a47180d0a8a5db4992608cae6b1d5f87d72eae1f", "committedDate": "2020-06-26T15:42:06Z", "message": "Changed some formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3dd2f3403de2d055b3ac1d73bd477330838e8c8e", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/3dd2f3403de2d055b3ac1d73bd477330838e8c8e", "committedDate": "2020-06-26T16:04:45Z", "message": "Changed some formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/d73e9c31dc267956e1c0f96030d80635f0e18a36", "committedDate": "2020-06-26T16:14:20Z", "message": "Refining wording"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NDMxNDQ5", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#pullrequestreview-438431449", "createdAt": "2020-06-26T16:25:45Z", "commit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjoyNTo0NVrOGpnEXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjozNDoxMVrOGpnVFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4NDg5Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * S3 \u2192 S3,  uses `S3S3Copier`\n          \n          \n            \n               * S3 \u2192 S3,  uses `S3S3Copier`\n          \n          \n            \n                  * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n          \n      \n    \n    \n  \n\nI suggest to add a note on cross-account/assume-role requirements.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446284893", "createdAt": "2020-06-26T16:25:45Z", "author": {"login": "barnharts4"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,122 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4NTc4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This replication mode behaves in the same was as `FULL` however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n          \n          \n            \n            This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446285788", "createdAt": "2020-06-26T16:27:37Z", "author": {"login": "barnharts4"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,122 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL` however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4ODAzNw==", "bodyText": "Is this true?  When you added assume-role to the S3S3Copier, were you able to test assuming a role into the target account?  @KenFigueiredo and I were unable to get it to work - the role being assumed also needed S3 READ permissions on the source account in order for us to use S3S3Copier cross-account.  If we were doing something wrong, please let us know, since this is a use-case we are very interested in.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446288037", "createdAt": "2020-06-26T16:31:58Z", "author": {"login": "barnharts4"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,122 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL` however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients with the necessary permissions to perform actions on S3 buckets", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4OTE3Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and wont be used by the other copiers. \n          \n          \n            \n            The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and won't be used by the other copiers.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446289173", "createdAt": "2020-06-26T16:34:11Z", "author": {"login": "barnharts4"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,122 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL` however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients with the necessary permissions to perform actions on S3 buckets\n+\n+One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials required. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers which will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.\n+\n+The replication is handled by a `TransferManager` which uses the target S3 client and the `S3S3CopierOptions`. The `TransferManager` will be given the the source client to replicate from. \n+\n+The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and wont be used by the other copiers. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "originalPosition": 108}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/bc17a3f5ff68015d837b175cf9617b2b11695b1d", "committedDate": "2020-06-26T16:41:37Z", "message": "Apply suggestions from code review\n\nCo-authored-by: Scott Barnhart <github@barnharts4.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NDc0MDky", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#pullrequestreview-438474092", "createdAt": "2020-06-26T17:31:29Z", "commit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzozMToyOVrOGppEyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzo1NDoxOVrOGppvOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMxNzc3MA==", "bodyText": "Suggested change", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446317770", "createdAt": "2020-06-26T17:31:29Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMxODEzNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n          \n          \n            \n            These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446318134", "createdAt": "2020-06-26T17:32:15Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyMDM3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n          \n          \n            \n            This replication mode behaves in the same way as `FULL`; however, corresponding existing replica table if any and its underlying data will first be deleted before being replaced with the source table and data.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446320379", "createdAt": "2020-06-26T17:37:01Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyMDc2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n          \n          \n            \n            This mode is useful in the early stages of development lifecycle when incompatible schema changes are being made constantly.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446320763", "createdAt": "2020-06-26T17:37:44Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyMTU4OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n          \n          \n            \n            A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446321589", "createdAt": "2020-06-26T17:39:37Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyMjgzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The copiers are the classes which do the actual copying of the data. \n          \n          \n            \n            The copiers are the classes which performs the actual copying of the data.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446322838", "createdAt": "2020-06-26T17:42:07Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyMzQ1MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. \n          \n          \n            \n            There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implements `CopierFactory` and pass these onto the constructor for the `DefaultCopierFactoryManager`.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446323450", "createdAt": "2020-06-26T17:43:24Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyNTA4Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * and then falls down to `DistCpCopier` if the above factories don't support the replication.\n          \n          \n            \n            * and then falls back to `DistCpCopier` if the above factories don't support the replication.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446325082", "createdAt": "2020-06-26T17:46:50Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,123 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL`; however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc17a3f5ff68015d837b175cf9617b2b11695b1d"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMyODYzMg==", "bodyText": "I think I did investigate this in the past and you are right. The role does require read permissions on source account. iirc, it was because the S3 class that was copying only uses one client and that was target client. There is no data handover which was possible between two clients.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r446328632", "createdAt": "2020-06-26T17:54:19Z", "author": {"login": "abhimanyugupta07"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,122 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+\n+\n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but it not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same was as `FULL` however, any existing replica table and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of lifecycle when incompatible schema changes are made. \n+\n+A `DataManipulator` is used to handle the deleting of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will give a suitable `DataManipulatorFactory` that will return a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which do the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which are implementations of the `CopierFactory` and pass these into the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients with the necessary permissions to perform actions on S3 buckets", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4ODAzNw=="}, "originalCommit": {"oid": "d73e9c31dc267956e1c0f96030d80635f0e18a36"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0bb40810285094e73043641886379a21fd39320", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/a0bb40810285094e73043641886379a21fd39320", "committedDate": "2020-06-29T15:11:15Z", "message": "Addressing PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38f083fa6204999e339f6e30d678679ac45315eb", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/38f083fa6204999e339f6e30d678679ac45315eb", "committedDate": "2020-07-22T13:58:23Z", "message": "Addressing PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1226c64f3995abf00e86556573f9897f16ed66ee", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/1226c64f3995abf00e86556573f9897f16ed66ee", "committedDate": "2020-07-22T13:58:26Z", "message": "Merge branch 'master' into Add-developers-md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/7b82fcb2ac5cef64bcf04057d739dad67680f508", "committedDate": "2020-07-22T14:00:17Z", "message": "Merged in master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNjM3ODc1", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#pullrequestreview-453637875", "createdAt": "2020-07-22T19:55:54Z", "commit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0MDE3Mjg2", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#pullrequestreview-454017286", "createdAt": "2020-07-23T10:45:01Z", "commit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMDo0NTowMVrOG2FREg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMDo1NjoyM1rOG2FlYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2MjU3OA==", "bodyText": "This isn't really part of the release so I don't think you need to update the CHANGELOG.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459362578", "createdAt": "2020-07-23T10:45:01Z", "author": {"login": "massdosage"}, "path": "CHANGELOG.md", "diffHunk": "@@ -1,3 +1,7 @@\n+## [16.2.1] - TBD\n+### Added\n+* A `DEVELOPERS.md` file with some notes on the inner workings of the project. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Mjg3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n          \n          \n            \n            These notes are meant as a helpful developer's guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459362879", "createdAt": "2020-07-23T10:45:42Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Mjk4NA==", "bodyText": "link to the README directly", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459362984", "createdAt": "2020-07-23T10:45:56Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Mzc5MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n          \n          \n            \n            If the source table has partitions containing data then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459363790", "createdAt": "2020-07-23T10:47:39Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Mzk0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n          \n          \n            \n            Otherwise, if the source table is partitioned but has no partitions containing data only the metadata of the table will be updated.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459363944", "createdAt": "2020-07-23T10:48:00Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NDQ5MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n          \n          \n            \n            This mode is useful in the early stages of the development lifecycle if incompatible schema changes are being made frequently so one doesn't have to manually remove data that is no longer valid.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459364490", "createdAt": "2020-07-23T10:49:11Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NTEyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n          \n          \n            \n            Only metadata will be copied (mirrored) from the source to the replica. Unlike the replication modes above, locations in the replica metadata will not be modified so your source and replica will have the same data locations.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459365122", "createdAt": "2020-07-23T10:50:36Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NTQ1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n          \n          \n            \n            Example use case:  this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n          \n      \n    \n    \n  \n\n(to be consistent with what you've done below)", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459365451", "createdAt": "2020-07-23T10:51:19Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NjAwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n          \n          \n            \n            There is an optional copier option available to specify which `CopierFactory` to use, if this value is set then this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459366002", "createdAt": "2020-07-23T10:52:30Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NjMzMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n          \n          \n            \n            The following is the order of precedence which the `CopierFactories` will be checked in to see if the replication is supported:", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459366330", "createdAt": "2020-07-23T10:53:14Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NjYxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * and then falls down to `DistCpCopier` if the above factories don't support the replication.\n          \n          \n            \n            * `DistCpCopier` (i.e. this is used if all the above factories don't support the replication).", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459366617", "createdAt": "2020-07-23T10:53:50Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Njc2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n          \n          \n            \n            The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed (e.g. if data is being transferred across S3 accounts).", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459366765", "createdAt": "2020-07-23T10:54:10Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NzExOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials required. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers which will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.\n          \n          \n            \n            One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers that will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459367118", "createdAt": "2020-07-23T10:54:56Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients to perform actions on S3 buckets. \n+\n+One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials required. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers which will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NzM0OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and won't be used by the other copiers. \n          \n          \n            \n            The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific S3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and won't be used by the other copiers.", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459367349", "createdAt": "2020-07-23T10:55:26Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients to perform actions on S3 buckets. \n+\n+One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials required. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers which will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.\n+\n+The replication is handled by a `TransferManager` which uses the target S3 client and the `S3S3CopierOptions`. The `TransferManager` will be given the the source client to replicate from. \n+\n+The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and won't be used by the other copiers. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2Nzc3Ng==", "bodyText": "I think we can remove this line, IMHO it's clear that if you can't read from the source then you can't do much!", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#discussion_r459367776", "createdAt": "2020-07-23T10:56:23Z", "author": {"login": "massdosage"}, "path": "DEVELOPERS.md", "diffHunk": "@@ -0,0 +1,134 @@\n+![Circus Train.](circus-train.png \"Moving Hive data between sites.\")\n+\n+# Developer's Guide\n+\n+## Overview\n+\n+This document is a collection of notes on Circus Train which have been put together to outline what some of the main classes do and how they link together. The project is pretty large and if you haven't worked on it for a while its easy to get lost! \n+These notes are meant as a helpful developers guide into Circus Train's code and how it works, but they are not completely exhaustive of all the inner workings of the project. Do feel free to add more information or detail. \n+\n+## README.md\n+\n+First and foremost, its worth having a read through the [README.md](https://github.com/HotelsDotCom/circus-train) file. It is a pretty extensive guide containing a lot of info on the project, including how to run it and all the different configurations which can be used. \n+\n+## Classes\n+**Locomotive**\n+\n+* This is where it all begins.\n+* A new `Replication` object is created using the `ReplicationFactory` and *replicate* is called on it.\n+\n+**ReplicationFactory**\n+\n+* Returns a `Replication` object. The type depends on whether the source table is partitioned or not, and the replication mode specified in the configuration file.\n+\n+**Replication**\n+\n+* Either partitioned or unpartitioned.\n+* There are 4 replication modes:\n+   * `FULL` \u2190 default\n+   * `FULL_OVERWRITE`\n+   * `METADATA_MIRROR`\n+   * `METADATA_UPDATE`\n+* Uses a copier based on where the data is coming from and going to:\n+   * HDFS or S3 \u2192 HDFS, uses `DistCpCopier`\n+   * HDFS \u2192 S3, uses `S3MapreduceCpCopier`\n+   * S3 \u2192 S3,  uses `S3S3Copier`\n+      * Note: If you are replicating S3 \u2192 S3 cross account, *and* you want to assume a role in the target account (see `copier-options.assume-role` in `README.md`), then you must use `S3MapreduceCpCopier`.\n+* The data is copied over first (if the mode is `FULL` or `FULL_OVERWRITE`).\n+* Then the metadata of the table is updated.\n+\n+## Types of replication\n+There are four types of replication which Circus Train can handle:\n+\n+* `FULL` \u2190 default\n+* `FULL_OVERWRITE`\n+* `METADATA_MIRROR`\n+* `METADATA_UPDATE`\n+\n+\n+### Full Replication\n+**Partitioned**\n+\n+If the source table has partitions then these and the corresponding data will be copied over to the replica table. After this, the metadata of the table will be updated. \n+\n+Otherwise, if the source table has no partitions only the metadata of the table will be updated. \n+\n+**Unpartitioned** \n+\n+All data from the source is copied over to the replica table, then the metadata is updated.\n+\n+\n+### Full Overwrite Replication\n+This replication mode behaves in the same way as `FULL`; however, the corresponding existing replica table, if any, and its underlying data will first be deleted before being replaced with the source table and data. \n+\n+This mode is useful in the early stages of the development lifecycle when incompatible schema changes are being made constantly. \n+\n+A `DataManipulator` is used to handle the deletion of data. Determining which manipulator to use is handled in the same manner as the [Copier](#copiers), in that there is a `DataManipulatorFactoryManager` which will generate a suitable `DataManipulatorFactory` that returns a `DataManipulator` object. \n+\n+### Metadata Mirror Replication \n+Only metadata will be copied (mirrored) from the source to the replica. Replica metadata will not be modified so your source and replica will have the same data location.\n+\n+*NOTE:* The replica table will be marked as `EXTERNAL`. This is done to prevent accidental data loss when dropping the replica. \n+\n+For example, this can be used for copying someone else's metadata into your Hive Metastore without copying the data or to replicate a view. You still need to have access to the data in order to query it.\n+\n+### Metadata Update Replication\n+This will update the metadata only for a table that was previously fully replicated.\n+\n+No data will be copied but any metadata from the source will be copied and table/partition locations will keep pointing to previously replicated data.\n+\n+Example use case: Update the metadata of a Hive Table (for instance to change the Serde used) without having the overhead of re-replicating all the data.\n+\n+## Copiers\n+The copiers are the classes which perform the actual copying of the data. \n+\n+There is a `CopierFactoryManager` which determines which type of copier will be used. The `DefaultCopierFactoryManager` is an implementation of this, and has a list of `CopierFactories` auto-wired into it. Spring will find all beans which implement `CopierFactory` and pass these on to the constructor for the `DefaultCopierFactoryManager`. \n+\n+There is an optional copier option available to set which `CopierFactory` to use, if this value is set this copier factory class will be used. If this value is not set the `DefaultCopierFactoryManager` will check all `CopierFactories` in the list and return the first which supports replication between the SourceLocation and ReplicaLocation provided. \n+\n+There is an order of precedence, which means the `CopierFactories` will be checked in the following order to see if the replication is supported:\n+* `S3S3Copier`,\n+* `S3MapreduceCpCopier`, \n+* and then falls down to `DistCpCopier` if the above factories don't support the replication.\n+\n+The copiers which use S3 will create clients that allow access and give permissions to perform actions on S3 buckets. In some cases an IAM role is needed, if data is being transferred across S3 accounts. \n+\n+### Types of copier\n+**S3S3Copier**\n+\n+*Replication: S3 \u2192 S3* \n+\n+This copier uses two `AwsS3Clients` - a source client and a replica client. There is an `AwsS3ClientFactory` which will create clients to perform actions on S3 buckets. \n+\n+One of these client factories is `JceksAmazonS3ClientFactory`, which creates a client with the necessary credentials required. It does this using a credential provider chain, which will create (as the name states) a chain of credential providers which will be tried in order, until one is successful. One of the credentials in this chain is the `AssumeRoleCredentialProvider` which uses a role provided in the copier options to be able to replicate across S3 accounts.\n+\n+The replication is handled by a `TransferManager` which uses the target S3 client and the `S3S3CopierOptions`. The `TransferManager` will be given the the source client to replicate from. \n+\n+The `S3S3CopierOptions` will take the `CopierOptions` provided and change them into more specific s3 options. For example it will have the options `s3-server-side-encryption` and `assume-role`, which are specific to S3 clients and won't be used by the other copiers. \n+\n+*Cross-account Replication*\n+\n+As mentioned above, if you want to replicate from one S3 account to another S3 account you will need to make use of `roles`. \n+In the config file for the replication an `assume-role` will need to be included which will be used by Circus Train to perform the replication. In order for this to work this role will need to have the following permissions:\n+* Read access to the source account, \n+* Read and write access to the target account. \n+\n+Its important that the role has read access to the source so the data can be read before it is replicated to the target. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b82fcb2ac5cef64bcf04057d739dad67680f508"}, "originalPosition": 116}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a8723f8020e1211844ef359c1854ca2833f9f33", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/5a8723f8020e1211844ef359c1854ca2833f9f33", "committedDate": "2020-07-23T11:59:27Z", "message": "Apply suggestions from code review\n\nCo-authored-by: Adrian Woodhead <awoodhead@expediagroup.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3cba6c77b54fe29041b03ad22928ff241b5e7b2", "author": {"user": {"login": "JayGreeeen", "name": "Jay Green-Stevens"}}, "url": "https://github.com/ExpediaGroup/circus-train/commit/d3cba6c77b54fe29041b03ad22928ff241b5e7b2", "committedDate": "2020-07-23T12:01:00Z", "message": "Addressing PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0MTQ5MDIx", "url": "https://github.com/ExpediaGroup/circus-train/pull/190#pullrequestreview-454149021", "createdAt": "2020-07-23T13:49:41Z", "commit": {"oid": "d3cba6c77b54fe29041b03ad22928ff241b5e7b2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3824, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}