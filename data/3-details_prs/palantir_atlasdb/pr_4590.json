{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc3Njk2Njk0", "number": 4590, "title": "[LW] Fix corner case in registering lock watches", "bodyText": "Goals (and why):\nPrimary goal of this PR is to prevent the following race condition:\n\nIn-flight lock request checks if lock descriptor A is being watched, and it is not. Enter GC.\nA request to start watching A is received and an inspection of open locks determines A is not locked.\nThe lock request from 1. is processed. Since A was filtered out as it was not being watched at the time, it will not be logged in the lock event.\nSevere data corruption (TM)\n\nAdditionally, two smaller fixes:\n\ndo not log anything on locks/unlocks if all lock descriptors are filtered out (oops)\nexit early if ranges being registered are already fully covered by existing ranges (in a follow up PR this will be made a noop, but requires some additional changes first)\n\nImplementation Description (bullets):\nUse fair read/write locks to force registration of new lock watches to wait for all in-flight lock/unlock requests to complete before the change is made and, consequently, guaranteed to be reflected in all subsequent lock/unlock events. See concerns for further comments.\nTesting (What was existing testing like?  What have you done to improve it?):\nI spent a couple of hours trying to write a test that would catch the above bug, but have failed and moved on.\nConcerns (what feedback would you like?):\nThe issue here is that, due to the fair locking mechanism, lock and unlock requests may end up blocking waiting for an update that is waiting on in-flight lock/unlock requests. I think this is fine given that:\n\nregistering lock watches is going to be extremely infrequent\nthe write lock is only acquired if there is an actual change to ranges being watched\nthe work done holding the write lock is tiny\nHowever, if there is an in-flight lock/unlock with a huge number of lock descriptors, and a waiting lock watch registration, it is possible many incoming locks/unlocks will have to block until the huge request is processed.\n\nThe difficult part is that we must ensure that, once we start iterating through heldLocksCollection any change that could happen to the set of open locks is reflected in the log. This PR seems like the least intrusive way of doing this.\nWhere should we start reviewing?:\nPR is tiny\nPriority (whenever / two weeks / yesterday):\nToday please, let's pair when you have a moment to discuss", "createdAt": "2020-02-20T11:16:57Z", "url": "https://github.com/palantir/atlasdb/pull/4590", "merged": true, "mergeCommit": {"oid": "8f4c903dd1597cc0fca68efc7931ad67cb4217c0"}, "closed": true, "closedAt": "2020-02-24T10:43:38Z", "author": {"login": "gmaretic"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcGIxlvAH2gAyMzc3Njk2Njk0Ojg3NDBhYjliMGViOGU4ZGFmNGQyZDgxNTIyMzE3MzhkMDdkNDI0OGU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcGkaT-gFqTM2Mjg0MzY5OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "8740ab9b0eb8e8daf4d2d8152231738d07d4248e", "author": {"user": {"login": "gmaretic", "name": null}}, "url": "https://github.com/palantir/atlasdb/commit/8740ab9b0eb8e8daf4d2d8152231738d07d4248e", "committedDate": "2020-02-20T10:43:02Z", "message": "Be better, one day at a time. Also fix nasty concurrency issue."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYxODkzMzEw", "url": "https://github.com/palantir/atlasdb/pull/4590#pullrequestreview-361893310", "createdAt": "2020-02-20T13:20:59Z", "commit": {"oid": "8740ab9b0eb8e8daf4d2d8152231738d07d4248e"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYyODQzNjk5", "url": "https://github.com/palantir/atlasdb/pull/4590#pullrequestreview-362843699", "createdAt": "2020-02-21T18:54:20Z", "commit": {"oid": "8740ab9b0eb8e8daf4d2d8152231738d07d4248e"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMVQxODo1NDoyMVrOFtBI4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMVQxODo1NDoyMVrOFtBI4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc0ODg5Ng==", "bodyText": "nit: unnecessary this", "url": "https://github.com/palantir/atlasdb/pull/4590#discussion_r382748896", "createdAt": "2020-02-21T18:54:21Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/lock/watch/LockWatchingServiceImpl.java", "diffHunk": "@@ -59,19 +75,38 @@ public LockWatchStateUpdate getWatchStateUpdate(OptionalLong lastKnownVersion) {\n \n     @Override\n     public void registerLock(Set<LockDescriptor> locksTakenOut, LockToken token) {\n-        lockEventLog.logLock(locksTakenOut.stream().filter(this::hasLockWatch).collect(Collectors.toSet()), token);\n+        watchesLock.readLock().lock();\n+        try {\n+            lockEventLog.logLock(locksTakenOut.stream().filter(this::hasLockWatch).collect(Collectors.toSet()), token);\n+        } finally {\n+            watchesLock.readLock().unlock();\n+        }\n     }\n \n     @Override\n     public void registerUnlock(Set<LockDescriptor> unlocked) {\n+        watchesLock.readLock().lock();\n+        try {\n         lockEventLog.logUnlock(unlocked.stream().filter(this::hasLockWatch).collect(Collectors.toSet()));\n+        } finally {\n+            watchesLock.readLock().unlock();\n+        }\n     }\n \n     private synchronized void addToWatches(LockWatchRequest request) {\n         RangeSet<LockDescriptor> oldRanges = ranges.get();\n+        List<Range<LockDescriptor>> requestAsRanges = toRanges(request);\n+        if (oldRanges.enclosesAll(requestAsRanges)) {\n+            return;\n+        }\n         RangeSet<LockDescriptor> newRanges = TreeRangeSet.create(oldRanges);\n-        newRanges.addAll(toRanges(request));\n-        ranges.set(newRanges);\n+        newRanges.addAll(requestAsRanges);\n+        watchesLock.writeLock().lock();\n+        try {\n+            this.ranges.set(newRanges);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8740ab9b0eb8e8daf4d2d8152231738d07d4248e"}, "originalPosition": 69}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2274, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}