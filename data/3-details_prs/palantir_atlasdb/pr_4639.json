{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0NTAzOTYy", "number": 4639, "title": "[Timelock Partitioning] Part 53: Latest sequence cache concurrent", "bodyText": "Goals (and why):\nBatchingPaxosLatestSequenceCache is stateful, I correctly identified it as not thread-safe but gave an incorrect justification as to why. i.e. the claim was that it\u2019s in an Autobatcher so it\u2019s fine. But it\u2019s actually launched in PaxosQuorumChecker from an Autobatcher, so it\u2019s not fine. i.e. with B and C as followers, if C is slow, Autobatcher will have returned a result from itself and B, and is free to send another PaxosQuorumChecker call => two concurrent threads to a class that\u2019s explicitly not thread safe.\nImplementation Description (bullets):\nA separate approach that I considered:\n\nActually have another Autobatcher that we call instead of calling the cache directly. This would allow us to use BatchingPaxosLatestSequenceCache as is without any changes because then it would serialise calls into the cache (autobatcher has only one thread). I did not go with this approach because I want to try getting rid of threads generated in PaxosQuorumChecker that leverages async retrofit.\n\nCurrent approach:\n\nEach cache key is timestamped (it's timestamped internally, just not exposed over the wire). This is a break, but this is fine, this hasn't gone out anywhere.\n\nMultiple threads can come in and make requests, if they get back differing cache keys because updates have occurred in between, which do we pick? The timestamp is what orders them all.\nSimilarly still process all sequences returned, but merge them with what already exists in the map.\n\n\nUse concurrent collections for safe access\nMake it easier to expose the timestamp from the server side, see AcceptorCacheImpl\n\nTesting (What was existing testing like?  What have you done to improve it?):\nExisting tests pass, not sure how to go about the concurrent pieces since there aren't that many levers I can pull to force certain orderings.\nConcerns (what feedback would you like?):\nAm I missing anything?\nWhere should we start reviewing?:\n\nBatchingPaxosLatestSequenceCache\nAcceptorCacheImpl\n\nPriority (whenever / two weeks / yesterday):\nASAP please.", "createdAt": "2020-03-05T21:15:16Z", "url": "https://github.com/palantir/atlasdb/pull/4639", "merged": true, "mergeCommit": {"oid": "63d932b4756959bed5e298aaf7a7b04e87260815"}, "closed": true, "closedAt": "2020-03-19T12:26:24Z", "author": {"login": "felixdesouza"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKumjUAH2gAyMzg0NTAzOTYyOjExZDcyM2JjMWQ5MTE2MDA2NmNiZjY1MWQ5NThhN2U1N2Q1MDIxYWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPK0XwAH2gAyMzg0NTAzOTYyOjRhNjEzNTNkODBlZjQ1MTgyOGQyN2ZjNWFhMzFiNzdiNTYyNGM1Mjg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "11d723bc1d91160066cbf651d958a7e57d5021ab", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/11d723bc1d91160066cbf651d958a7e57d5021ab", "committedDate": "2020-03-05T17:03:04Z", "message": "Concurrent cache."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9c540e1173c2e30b0eb19bb25bf8a5cdc0e7d4b", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/c9c540e1173c2e30b0eb19bb25bf8a5cdc0e7d4b", "committedDate": "2020-03-05T17:06:53Z", "message": "Fix up comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d93303b9dca0055f18880e00250fd982403a10ec", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/d93303b9dca0055f18880e00250fd982403a10ec", "committedDate": "2020-03-05T17:09:57Z", "message": "More clarifying details around the CAS."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1ad8bfc46dbac3ae2c8933d6020e71c73868edb", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/f1ad8bfc46dbac3ae2c8933d6020e71c73868edb", "committedDate": "2020-03-05T17:43:54Z", "message": "Fix compile error."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5OTE5NjU5", "url": "https://github.com/palantir/atlasdb/pull/4639#pullrequestreview-369919659", "createdAt": "2020-03-05T21:16:02Z", "commit": {"oid": "f1ad8bfc46dbac3ae2c8933d6020e71c73868edb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMToxNjowM1rOFykbVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMToxNjowM1rOFykbVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU2OTk0MQ==", "bodyText": "should I have passed in the cache key that generated this request? I think it's probably fine, but might make sense", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r388569941", "createdAt": "2020-03-05T21:16:03Z", "author": {"login": "felixdesouza"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,159 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n+import org.immutables.value.Value;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<TimestampedAcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =\n+            Caffeine.newBuilder()\n+                    .expireAfterAccess(Duration.ofMinutes(1))\n+                    .build($ -> Maps.newConcurrentMap());\n \n     BatchingPaxosLatestSequenceCache(BatchPaxosAcceptor delegate) {\n         this.delegate = delegate;\n     }\n \n     @Override\n-    public Map<Client, PaxosLong> apply(Set<Client> clients) {\n-        try {\n-            return unsafeGetLatest(clients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.info(\"Cache key is invalid, invalidating cache - using deprecated detection method\");\n-            return handleCacheMiss(clients);\n-        }\n-    }\n+    public Map<Client, PaxosLong> apply(Set<Client> requestedClients) {\n+        // always add requested clients so we can easily query with everything we've ever seen when our cache is invalid\n+        clientsSeenSoFar.addAll(requestedClients);\n \n-    private Map<Client, PaxosLong> handleCacheMiss(Set<Client> requestedClients) {\n-        cacheKey = null;\n-        Set<Client> allClients = ImmutableSet.<Client>builder()\n-                .addAll(requestedClients)\n-                .addAll(cachedEntries.keySet())\n-                .build();\n-        cachedEntries.clear();\n-        try {\n-            return unsafeGetLatest(allClients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.warn(\"Empty cache key is still invalid indicates product bug, failing request.\");\n-            throw new RuntimeException(e);\n+        int attempt = 0;\n+        while (attempt < 3) {\n+            TimestampedAcceptorCacheKey timestampedCacheKey = cacheKey.get();\n+            try {\n+                if (timestampedCacheKey == null) {\n+                    return populateNewCache(requestedClients);\n+                } else {\n+                    return populateExistingCache(\n+                            timestampedCacheKey,\n+                            cacheKeysToCaches.get(timestampedCacheKey),\n+                            requestedClients);\n+                }\n+            } catch (InvalidAcceptorCacheKeyException e) {\n+                log.info(\"Cache key is invalid, invalidating cache and retrying\",\n+                        SafeArg.of(\"attempt\", attempt),\n+                        e);\n+                cacheKey.compareAndSet(timestampedCacheKey, null);\n+                attempt++;\n+            }\n         }\n+\n+        throw new SafeIllegalStateException(\"could not request complete request due to contention in the cache\");\n     }\n \n-    private Map<Client, PaxosLong> unsafeGetLatest(Set<Client> clients) throws InvalidAcceptorCacheKeyException {\n-        if (cacheKey == null) {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clients));\n-            return getResponseMap(clients);\n-        }\n+    private Map<Client, PaxosLong> populateNewCache(Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        AcceptorCacheDigest digest = delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clientsSeenSoFar);\n+        ConcurrentMap<Client, PaxosLong> newEntriesToCache =\n+                cacheKeysToCaches.get(TimestampedAcceptorCacheKey.of(digest));\n+        processDigest(newEntriesToCache, digest);\n+        return getResponseMap(newEntriesToCache, requestedClients);\n+    }\n \n-        Set<Client> newClients = Sets.difference(clients, cachedEntries.keySet());\n+    private Map<Client, PaxosLong> populateExistingCache(\n+            TimestampedAcceptorCacheKey timestampedCacheKey,\n+            ConcurrentMap<Client, PaxosLong> currentCachedEntries,\n+            Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        Set<Client> newClients = ImmutableSet.copyOf(Sets.difference(requestedClients, currentCachedEntries.keySet()));\n         if (newClients.isEmpty()) {\n-            delegate.latestSequencesPreparedOrAcceptedCached(cacheKey).ifPresent(this::processDigest);\n-            return getResponseMap(clients);\n+            delegate.latestSequencesPreparedOrAcceptedCached(timestampedCacheKey.cacheKey())\n+                    .ifPresent(digest -> processDigest(currentCachedEntries, digest));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         } else {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.of(cacheKey), newClients));\n-            return getResponseMap(clients);\n+            processDigest(currentCachedEntries, delegate.latestSequencesPreparedOrAccepted(\n+                    Optional.of(timestampedCacheKey.cacheKey()),\n+                    newClients));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n+        }\n+    }\n+\n+    private void processDigest(ConcurrentMap<Client, PaxosLong> currentCachedEntries, AcceptorCacheDigest digest) {\n+        TimestampedAcceptorCacheKey newCacheKey = TimestampedAcceptorCacheKey.of(digest);\n+        // this shares the same map with \"previous\" cache keys, if it's too confusing we can always copy it potentially\n+        ConcurrentMap<Client, PaxosLong> newCachedEntries =\n+                cacheKeysToCaches.get(newCacheKey, $ -> currentCachedEntries);\n+        KeyedStream.stream(digest.updates())\n+                .map(PaxosLong::of)\n+                .forEach((client, paxosLong) ->\n+                        newCachedEntries.merge(client, paxosLong, BatchingPaxosLatestSequenceCache::max));\n+\n+        // for a *new* mapping, setting the cache key must happen *after* we've setup the mapping, so that concurrent\n+        // clients will not reference an in-progress populating map which can be empty.\n+        maybeSetNewCacheKey(newCacheKey);\n+    }\n+\n+    private void maybeSetNewCacheKey(TimestampedAcceptorCacheKey newCacheKey) {\n+        while (true) {\n+            TimestampedAcceptorCacheKey current = cacheKey.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1ad8bfc46dbac3ae2c8933d6020e71c73868edb"}, "originalPosition": 165}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/7daa4c3499227e18bc8d885fc1e210e5686156dc", "committedDate": "2020-03-05T21:16:42Z", "message": "Fix server side runtime errors and pass the timestamp around."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee3931053e3285b59cb5f735bff5bbc4c322bf08", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/ee3931053e3285b59cb5f735bff5bbc4c322bf08", "committedDate": "2020-03-06T14:21:20Z", "message": "clarifying rename"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwMjk0MTM2", "url": "https://github.com/palantir/atlasdb/pull/4639#pullrequestreview-370294136", "createdAt": "2020-03-06T12:43:33Z", "commit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxMjo0MzozM1rOFy3dgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxMjo0NjozM1rOFy3iqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODg4MTc5NA==", "bodyText": "The new and old cache key are never the same at this point", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r388881794", "createdAt": "2020-03-06T12:43:33Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,145 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<AcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =\n+            Caffeine.newBuilder()\n+                    .expireAfterAccess(Duration.ofMinutes(1))\n+                    .build($ -> Maps.newConcurrentMap());\n \n     BatchingPaxosLatestSequenceCache(BatchPaxosAcceptor delegate) {\n         this.delegate = delegate;\n     }\n \n     @Override\n-    public Map<Client, PaxosLong> apply(Set<Client> clients) {\n-        try {\n-            return unsafeGetLatest(clients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.info(\"Cache key is invalid, invalidating cache - using deprecated detection method\");\n-            return handleCacheMiss(clients);\n-        }\n-    }\n+    public Map<Client, PaxosLong> apply(Set<Client> requestedClients) {\n+        // always add requested clients so we can easily query with everything we've ever seen when our cache is invalid\n+        clientsSeenSoFar.addAll(requestedClients);\n \n-    private Map<Client, PaxosLong> handleCacheMiss(Set<Client> requestedClients) {\n-        cacheKey = null;\n-        Set<Client> allClients = ImmutableSet.<Client>builder()\n-                .addAll(requestedClients)\n-                .addAll(cachedEntries.keySet())\n-                .build();\n-        cachedEntries.clear();\n-        try {\n-            return unsafeGetLatest(allClients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.warn(\"Empty cache key is still invalid indicates product bug, failing request.\");\n-            throw new RuntimeException(e);\n+        int attempt = 0;\n+        while (attempt < 3) {\n+            TimestampedAcceptorCacheKey timestampedCacheKey = cacheKey.get();\n+            try {\n+                if (timestampedCacheKey == null) {\n+                    return populateNewCache(requestedClients);\n+                } else {\n+                    return populateExistingCache(\n+                            timestampedCacheKey,\n+                            cacheKeysToCaches.get(timestampedCacheKey.cacheKey()),\n+                            requestedClients);\n+                }\n+            } catch (InvalidAcceptorCacheKeyException e) {\n+                log.info(\"Cache key is invalid, invalidating cache and retrying\",\n+                        SafeArg.of(\"attempt\", attempt),\n+                        e);\n+                cacheKey.compareAndSet(timestampedCacheKey, null);\n+                attempt++;\n+            }\n         }\n+\n+        throw new SafeIllegalStateException(\"could not request complete request due to contention in the cache\");\n     }\n \n-    private Map<Client, PaxosLong> unsafeGetLatest(Set<Client> clients) throws InvalidAcceptorCacheKeyException {\n-        if (cacheKey == null) {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clients));\n-            return getResponseMap(clients);\n-        }\n+    private Map<Client, PaxosLong> populateNewCache(Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        AcceptorCacheDigest digest = delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clientsSeenSoFar);\n+        ConcurrentMap<Client, PaxosLong> newEntriesToCache =\n+                cacheKeysToCaches.get(digest.newCacheKey());\n+        processDigest(newEntriesToCache, digest);\n+        return getResponseMap(newEntriesToCache, requestedClients);\n+    }\n \n-        Set<Client> newClients = Sets.difference(clients, cachedEntries.keySet());\n+    private Map<Client, PaxosLong> populateExistingCache(\n+            TimestampedAcceptorCacheKey timestampedCacheKey,\n+            ConcurrentMap<Client, PaxosLong> currentCachedEntries,\n+            Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        Set<Client> newClients = ImmutableSet.copyOf(Sets.difference(requestedClients, currentCachedEntries.keySet()));\n         if (newClients.isEmpty()) {\n-            delegate.latestSequencesPreparedOrAcceptedCached(cacheKey).ifPresent(this::processDigest);\n-            return getResponseMap(clients);\n+            delegate.latestSequencesPreparedOrAcceptedCached(timestampedCacheKey.cacheKey())\n+                    .ifPresent(digest -> processDigest(currentCachedEntries, digest));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         } else {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.of(cacheKey), newClients));\n-            return getResponseMap(clients);\n+            processDigest(currentCachedEntries, delegate.latestSequencesPreparedOrAccepted(\n+                    Optional.of(timestampedCacheKey.cacheKey()),\n+                    newClients));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         }\n     }\n \n-    private Map<Client, PaxosLong> getResponseMap(Set<Client> clientsInRequest) {\n-        return Maps.toMap(clientsInRequest, client -> cachedEntries.getOrDefault(client, DEFAULT_VALUE));\n+    private void processDigest(ConcurrentMap<Client, PaxosLong> currentCachedEntries, AcceptorCacheDigest digest) {\n+        TimestampedAcceptorCacheKey newCacheKey = TimestampedAcceptorCacheKey.of(digest);\n+        // this shares the same map with \"previous\" cache keys, if it's too confusing we can always copy it potentially\n+        ConcurrentMap<Client, PaxosLong> newCachedEntries =\n+                cacheKeysToCaches.get(newCacheKey.cacheKey(), $ -> currentCachedEntries);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODg4MzExNQ==", "bodyText": "so this map stores the largest known version of the updates from the reference point indicated by the cache key", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r388883115", "createdAt": "2020-03-06T12:46:33Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,145 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<AcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwNTA0MDg0", "url": "https://github.com/palantir/atlasdb/pull/4639#pullrequestreview-370504084", "createdAt": "2020-03-06T17:36:51Z", "commit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxNzozNjo1MVrOFzBYaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQxODowNToxNFrOFzCPXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA0NDMyOA==", "bodyText": "nit: double request in message\nI think this is safe even with 3 attempts, that usually indicates leader churn or getting strangely far behind.", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r389044328", "createdAt": "2020-03-06T17:36:51Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,145 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<AcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =\n+            Caffeine.newBuilder()\n+                    .expireAfterAccess(Duration.ofMinutes(1))\n+                    .build($ -> Maps.newConcurrentMap());\n \n     BatchingPaxosLatestSequenceCache(BatchPaxosAcceptor delegate) {\n         this.delegate = delegate;\n     }\n \n     @Override\n-    public Map<Client, PaxosLong> apply(Set<Client> clients) {\n-        try {\n-            return unsafeGetLatest(clients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.info(\"Cache key is invalid, invalidating cache - using deprecated detection method\");\n-            return handleCacheMiss(clients);\n-        }\n-    }\n+    public Map<Client, PaxosLong> apply(Set<Client> requestedClients) {\n+        // always add requested clients so we can easily query with everything we've ever seen when our cache is invalid\n+        clientsSeenSoFar.addAll(requestedClients);\n \n-    private Map<Client, PaxosLong> handleCacheMiss(Set<Client> requestedClients) {\n-        cacheKey = null;\n-        Set<Client> allClients = ImmutableSet.<Client>builder()\n-                .addAll(requestedClients)\n-                .addAll(cachedEntries.keySet())\n-                .build();\n-        cachedEntries.clear();\n-        try {\n-            return unsafeGetLatest(allClients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.warn(\"Empty cache key is still invalid indicates product bug, failing request.\");\n-            throw new RuntimeException(e);\n+        int attempt = 0;\n+        while (attempt < 3) {\n+            TimestampedAcceptorCacheKey timestampedCacheKey = cacheKey.get();\n+            try {\n+                if (timestampedCacheKey == null) {\n+                    return populateNewCache(requestedClients);\n+                } else {\n+                    return populateExistingCache(\n+                            timestampedCacheKey,\n+                            cacheKeysToCaches.get(timestampedCacheKey.cacheKey()),\n+                            requestedClients);\n+                }\n+            } catch (InvalidAcceptorCacheKeyException e) {\n+                log.info(\"Cache key is invalid, invalidating cache and retrying\",\n+                        SafeArg.of(\"attempt\", attempt),\n+                        e);\n+                cacheKey.compareAndSet(timestampedCacheKey, null);\n+                attempt++;\n+            }\n         }\n+\n+        throw new SafeIllegalStateException(\"could not request complete request due to contention in the cache\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA0NzE2MQ==", "bodyText": "I think this is fine, as written we have a standard CAS algorithm and it makes the most current role of cacheKey more obvious", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r389047161", "createdAt": "2020-03-06T17:41:36Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,159 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n+import org.immutables.value.Value;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<TimestampedAcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =\n+            Caffeine.newBuilder()\n+                    .expireAfterAccess(Duration.ofMinutes(1))\n+                    .build($ -> Maps.newConcurrentMap());\n \n     BatchingPaxosLatestSequenceCache(BatchPaxosAcceptor delegate) {\n         this.delegate = delegate;\n     }\n \n     @Override\n-    public Map<Client, PaxosLong> apply(Set<Client> clients) {\n-        try {\n-            return unsafeGetLatest(clients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.info(\"Cache key is invalid, invalidating cache - using deprecated detection method\");\n-            return handleCacheMiss(clients);\n-        }\n-    }\n+    public Map<Client, PaxosLong> apply(Set<Client> requestedClients) {\n+        // always add requested clients so we can easily query with everything we've ever seen when our cache is invalid\n+        clientsSeenSoFar.addAll(requestedClients);\n \n-    private Map<Client, PaxosLong> handleCacheMiss(Set<Client> requestedClients) {\n-        cacheKey = null;\n-        Set<Client> allClients = ImmutableSet.<Client>builder()\n-                .addAll(requestedClients)\n-                .addAll(cachedEntries.keySet())\n-                .build();\n-        cachedEntries.clear();\n-        try {\n-            return unsafeGetLatest(allClients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.warn(\"Empty cache key is still invalid indicates product bug, failing request.\");\n-            throw new RuntimeException(e);\n+        int attempt = 0;\n+        while (attempt < 3) {\n+            TimestampedAcceptorCacheKey timestampedCacheKey = cacheKey.get();\n+            try {\n+                if (timestampedCacheKey == null) {\n+                    return populateNewCache(requestedClients);\n+                } else {\n+                    return populateExistingCache(\n+                            timestampedCacheKey,\n+                            cacheKeysToCaches.get(timestampedCacheKey),\n+                            requestedClients);\n+                }\n+            } catch (InvalidAcceptorCacheKeyException e) {\n+                log.info(\"Cache key is invalid, invalidating cache and retrying\",\n+                        SafeArg.of(\"attempt\", attempt),\n+                        e);\n+                cacheKey.compareAndSet(timestampedCacheKey, null);\n+                attempt++;\n+            }\n         }\n+\n+        throw new SafeIllegalStateException(\"could not request complete request due to contention in the cache\");\n     }\n \n-    private Map<Client, PaxosLong> unsafeGetLatest(Set<Client> clients) throws InvalidAcceptorCacheKeyException {\n-        if (cacheKey == null) {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clients));\n-            return getResponseMap(clients);\n-        }\n+    private Map<Client, PaxosLong> populateNewCache(Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        AcceptorCacheDigest digest = delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clientsSeenSoFar);\n+        ConcurrentMap<Client, PaxosLong> newEntriesToCache =\n+                cacheKeysToCaches.get(TimestampedAcceptorCacheKey.of(digest));\n+        processDigest(newEntriesToCache, digest);\n+        return getResponseMap(newEntriesToCache, requestedClients);\n+    }\n \n-        Set<Client> newClients = Sets.difference(clients, cachedEntries.keySet());\n+    private Map<Client, PaxosLong> populateExistingCache(\n+            TimestampedAcceptorCacheKey timestampedCacheKey,\n+            ConcurrentMap<Client, PaxosLong> currentCachedEntries,\n+            Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        Set<Client> newClients = ImmutableSet.copyOf(Sets.difference(requestedClients, currentCachedEntries.keySet()));\n         if (newClients.isEmpty()) {\n-            delegate.latestSequencesPreparedOrAcceptedCached(cacheKey).ifPresent(this::processDigest);\n-            return getResponseMap(clients);\n+            delegate.latestSequencesPreparedOrAcceptedCached(timestampedCacheKey.cacheKey())\n+                    .ifPresent(digest -> processDigest(currentCachedEntries, digest));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         } else {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.of(cacheKey), newClients));\n-            return getResponseMap(clients);\n+            processDigest(currentCachedEntries, delegate.latestSequencesPreparedOrAccepted(\n+                    Optional.of(timestampedCacheKey.cacheKey()),\n+                    newClients));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n+        }\n+    }\n+\n+    private void processDigest(ConcurrentMap<Client, PaxosLong> currentCachedEntries, AcceptorCacheDigest digest) {\n+        TimestampedAcceptorCacheKey newCacheKey = TimestampedAcceptorCacheKey.of(digest);\n+        // this shares the same map with \"previous\" cache keys, if it's too confusing we can always copy it potentially\n+        ConcurrentMap<Client, PaxosLong> newCachedEntries =\n+                cacheKeysToCaches.get(newCacheKey, $ -> currentCachedEntries);\n+        KeyedStream.stream(digest.updates())\n+                .map(PaxosLong::of)\n+                .forEach((client, paxosLong) ->\n+                        newCachedEntries.merge(client, paxosLong, BatchingPaxosLatestSequenceCache::max));\n+\n+        // for a *new* mapping, setting the cache key must happen *after* we've setup the mapping, so that concurrent\n+        // clients will not reference an in-progress populating map which can be empty.\n+        maybeSetNewCacheKey(newCacheKey);\n+    }\n+\n+    private void maybeSetNewCacheKey(TimestampedAcceptorCacheKey newCacheKey) {\n+        while (true) {\n+            TimestampedAcceptorCacheKey current = cacheKey.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU2OTk0MQ=="}, "originalCommit": {"oid": "f1ad8bfc46dbac3ae2c8933d6020e71c73868edb"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA1ODM5Nw==", "bodyText": "nit: accumulateLatestCacheKey?", "url": "https://github.com/palantir/atlasdb/pull/4639#discussion_r389058397", "createdAt": "2020-03-06T18:05:14Z", "author": {"login": "jeremyk-91"}, "path": "timelock-impl/src/main/java/com/palantir/atlasdb/timelock/paxos/BatchingPaxosLatestSequenceCache.java", "diffHunk": "@@ -16,92 +16,145 @@\n \n package com.palantir.atlasdb.timelock.paxos;\n \n+import java.time.Duration;\n+import java.util.Comparator;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Stream;\n \n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.NotThreadSafe;\n+import javax.annotation.concurrent.ThreadSafe;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import com.github.benmanes.caffeine.cache.LoadingCache;\n import com.google.common.collect.ImmutableSet;\n import com.google.common.collect.Maps;\n import com.google.common.collect.Sets;\n import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n import com.palantir.paxos.PaxosLong;\n \n-/*\n-    This is not thread safe, but it is okay because it is run within an autobatcher, which is configured to not process\n-    multiple batches in parallel.\n- */\n-@NotThreadSafe\n+@ThreadSafe\n final class BatchingPaxosLatestSequenceCache implements CoalescingRequestFunction<Client, PaxosLong> {\n \n     private static final Logger log = LoggerFactory.getLogger(BatchingPaxosLatestSequenceCache.class);\n     private static final PaxosLong DEFAULT_VALUE = PaxosLong.of(BatchPaxosAcceptor.NO_LOG_ENTRY);\n \n-    @Nullable\n-    private AcceptorCacheKey cacheKey = null;\n-    private Map<Client, PaxosLong> cachedEntries = Maps.newHashMap();\n-    private BatchPaxosAcceptor delegate;\n+    private final BatchPaxosAcceptor delegate;\n+\n+    private final Set<Client> clientsSeenSoFar = Sets.newConcurrentHashSet();\n+\n+    private final AtomicReference<TimestampedAcceptorCacheKey> cacheKey = new AtomicReference<>();\n+    private final LoadingCache<AcceptorCacheKey, ConcurrentMap<Client, PaxosLong>> cacheKeysToCaches =\n+            Caffeine.newBuilder()\n+                    .expireAfterAccess(Duration.ofMinutes(1))\n+                    .build($ -> Maps.newConcurrentMap());\n \n     BatchingPaxosLatestSequenceCache(BatchPaxosAcceptor delegate) {\n         this.delegate = delegate;\n     }\n \n     @Override\n-    public Map<Client, PaxosLong> apply(Set<Client> clients) {\n-        try {\n-            return unsafeGetLatest(clients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.info(\"Cache key is invalid, invalidating cache - using deprecated detection method\");\n-            return handleCacheMiss(clients);\n-        }\n-    }\n+    public Map<Client, PaxosLong> apply(Set<Client> requestedClients) {\n+        // always add requested clients so we can easily query with everything we've ever seen when our cache is invalid\n+        clientsSeenSoFar.addAll(requestedClients);\n \n-    private Map<Client, PaxosLong> handleCacheMiss(Set<Client> requestedClients) {\n-        cacheKey = null;\n-        Set<Client> allClients = ImmutableSet.<Client>builder()\n-                .addAll(requestedClients)\n-                .addAll(cachedEntries.keySet())\n-                .build();\n-        cachedEntries.clear();\n-        try {\n-            return unsafeGetLatest(allClients);\n-        } catch (InvalidAcceptorCacheKeyException e) {\n-            log.warn(\"Empty cache key is still invalid indicates product bug, failing request.\");\n-            throw new RuntimeException(e);\n+        int attempt = 0;\n+        while (attempt < 3) {\n+            TimestampedAcceptorCacheKey timestampedCacheKey = cacheKey.get();\n+            try {\n+                if (timestampedCacheKey == null) {\n+                    return populateNewCache(requestedClients);\n+                } else {\n+                    return populateExistingCache(\n+                            timestampedCacheKey,\n+                            cacheKeysToCaches.get(timestampedCacheKey.cacheKey()),\n+                            requestedClients);\n+                }\n+            } catch (InvalidAcceptorCacheKeyException e) {\n+                log.info(\"Cache key is invalid, invalidating cache and retrying\",\n+                        SafeArg.of(\"attempt\", attempt),\n+                        e);\n+                cacheKey.compareAndSet(timestampedCacheKey, null);\n+                attempt++;\n+            }\n         }\n+\n+        throw new SafeIllegalStateException(\"could not request complete request due to contention in the cache\");\n     }\n \n-    private Map<Client, PaxosLong> unsafeGetLatest(Set<Client> clients) throws InvalidAcceptorCacheKeyException {\n-        if (cacheKey == null) {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clients));\n-            return getResponseMap(clients);\n-        }\n+    private Map<Client, PaxosLong> populateNewCache(Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        AcceptorCacheDigest digest = delegate.latestSequencesPreparedOrAccepted(Optional.empty(), clientsSeenSoFar);\n+        ConcurrentMap<Client, PaxosLong> newEntriesToCache =\n+                cacheKeysToCaches.get(digest.newCacheKey());\n+        processDigest(newEntriesToCache, digest);\n+        return getResponseMap(newEntriesToCache, requestedClients);\n+    }\n \n-        Set<Client> newClients = Sets.difference(clients, cachedEntries.keySet());\n+    private Map<Client, PaxosLong> populateExistingCache(\n+            TimestampedAcceptorCacheKey timestampedCacheKey,\n+            ConcurrentMap<Client, PaxosLong> currentCachedEntries,\n+            Set<Client> requestedClients)\n+            throws InvalidAcceptorCacheKeyException {\n+        Set<Client> newClients = ImmutableSet.copyOf(Sets.difference(requestedClients, currentCachedEntries.keySet()));\n         if (newClients.isEmpty()) {\n-            delegate.latestSequencesPreparedOrAcceptedCached(cacheKey).ifPresent(this::processDigest);\n-            return getResponseMap(clients);\n+            delegate.latestSequencesPreparedOrAcceptedCached(timestampedCacheKey.cacheKey())\n+                    .ifPresent(digest -> processDigest(currentCachedEntries, digest));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         } else {\n-            processDigest(delegate.latestSequencesPreparedOrAccepted(Optional.of(cacheKey), newClients));\n-            return getResponseMap(clients);\n+            processDigest(currentCachedEntries, delegate.latestSequencesPreparedOrAccepted(\n+                    Optional.of(timestampedCacheKey.cacheKey()),\n+                    newClients));\n+            return getResponseMap(currentCachedEntries, requestedClients);\n         }\n     }\n \n-    private Map<Client, PaxosLong> getResponseMap(Set<Client> clientsInRequest) {\n-        return Maps.toMap(clientsInRequest, client -> cachedEntries.getOrDefault(client, DEFAULT_VALUE));\n+    private void processDigest(ConcurrentMap<Client, PaxosLong> currentCachedEntries, AcceptorCacheDigest digest) {\n+        TimestampedAcceptorCacheKey newCacheKey = TimestampedAcceptorCacheKey.of(digest);\n+        // this shares the same map with \"previous\" cache keys, if it's too confusing we can always copy it potentially\n+        ConcurrentMap<Client, PaxosLong> newCachedEntries =\n+                cacheKeysToCaches.get(newCacheKey.cacheKey(), $ -> currentCachedEntries);\n+        KeyedStream.stream(digest.updates())\n+                .map(PaxosLong::of)\n+                .forEach((client, paxosLong) ->\n+                        newCachedEntries.merge(client, paxosLong, BatchingPaxosLatestSequenceCache::max));\n+\n+        // for a *new* mapping, setting the cache key must happen *after* we've setup the mapping, so that concurrent\n+        // clients will not reference an in-progress populating map which can be empty.\n+        maybeSetNewCacheKey(newCacheKey);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7daa4c3499227e18bc8d885fc1e210e5686156dc"}, "originalPosition": 161}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "110f30d2dd22a4e94db7da0414166bf8dcbed1f8", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/110f30d2dd22a4e94db7da0414166bf8dcbed1f8", "committedDate": "2020-03-19T11:48:13Z", "message": "Add clarifying comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3NjU3ODE0", "url": "https://github.com/palantir/atlasdb/pull/4639#pullrequestreview-377657814", "createdAt": "2020-03-19T12:07:18Z", "commit": {"oid": "110f30d2dd22a4e94db7da0414166bf8dcbed1f8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a61353d80ef451828d27fc5aa31b77b5624c528", "author": {"user": {"login": "felixdesouza", "name": "Felix de Souza"}}, "url": "https://github.com/palantir/atlasdb/commit/4a61353d80ef451828d27fc5aa31b77b5624c528", "committedDate": "2020-03-19T12:11:12Z", "message": "fix up comments again."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3132, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}