{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MjY1ODc0", "number": 4348, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNDoyOTo0MVrOEHmM3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMzoyNzozNlrOEH9_hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDAxMzczOnYy", "diffSide": "RIGHT", "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNDoyOTo0MVrOGnDPIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzozMDozN1rOGnzd6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMDY3NQ==", "bodyText": "Is it possible it would still would work by falling back to the system truststore, or is it required to provide the truststore from the SSLContext?", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443600675", "createdAt": "2020-06-22T14:29:41Z", "author": {"login": "bbende"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -385,31 +401,50 @@ protected PropertyDescriptor getSupportedDynamicPropertyDescriptor(String proper\n     protected Collection<ValidationResult> customValidate(ValidationContext context) {\n         final Collection<ValidationResult> results = new ArrayList<>();\n \n-        final boolean isSSLContextServiceSet = context.getProperty(KAFKA_SSL_CONTEXT_SERVICE).isSet();\n+        final SSLContextService sslContextService = context.getProperty(SSL_CONTEXT_SERVICE).asControllerService(SSLContextService.class);\n         final ValidationResult.Builder invalidSSLService = new ValidationResult.Builder()\n-                .subject(KAFKA_SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n+                .subject(SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n \n+        AtomicBoolean isAtlasApiSecure = new AtomicBoolean(false);\n         String atlasUrls = context.getProperty(ATLAS_URLS).evaluateAttributeExpressions().getValue();\n         if (!StringUtils.isEmpty(atlasUrls)) {\n             Arrays.stream(atlasUrls.split(ATLAS_URL_DELIMITER))\n                 .map(String::trim)\n                 .forEach(input -> {\n-                    final ValidationResult.Builder builder = new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input);\n                     try {\n-                        new URL(input);\n-                        results.add(builder.explanation(\"Valid URI\").valid(true).build());\n+                        final URL url = new URL(input);\n+                        if (\"https\".equalsIgnoreCase(url.getProtocol())) {\n+                            isAtlasApiSecure.set(true);\n+                        }\n                     } catch (Exception e) {\n-                        results.add(builder.explanation(\"Contains invalid URI: \" + e).valid(false).build());\n+                        results.add(new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input)\n+                                .explanation(\"contains invalid URI: \" + e).valid(false).build());\n                     }\n                 });\n         }\n \n+        if (isAtlasApiSecure.get()) {\n+            if (sslContextService == null) {\n+                results.add(invalidSSLService.explanation(\"required for connecting to Atlas via HTTPS.\").build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzczOTAyNg==", "bodyText": "I'll remove these checks from customValidate().\nThere are also runtime checks with warning messages and fallback to system truststore in setAtlasSSLConfig(). These were used only when the Atlas URL was configured in the Atlas property file (not on the reporting task) and customValidate() did not check the SSL config.\nHowever, it is more consistent if there is only one check (with system truststore fallback) for all cases, regardless where the Atlas url has been configured.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443739026", "createdAt": "2020-06-22T18:09:45Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -385,31 +401,50 @@ protected PropertyDescriptor getSupportedDynamicPropertyDescriptor(String proper\n     protected Collection<ValidationResult> customValidate(ValidationContext context) {\n         final Collection<ValidationResult> results = new ArrayList<>();\n \n-        final boolean isSSLContextServiceSet = context.getProperty(KAFKA_SSL_CONTEXT_SERVICE).isSet();\n+        final SSLContextService sslContextService = context.getProperty(SSL_CONTEXT_SERVICE).asControllerService(SSLContextService.class);\n         final ValidationResult.Builder invalidSSLService = new ValidationResult.Builder()\n-                .subject(KAFKA_SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n+                .subject(SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n \n+        AtomicBoolean isAtlasApiSecure = new AtomicBoolean(false);\n         String atlasUrls = context.getProperty(ATLAS_URLS).evaluateAttributeExpressions().getValue();\n         if (!StringUtils.isEmpty(atlasUrls)) {\n             Arrays.stream(atlasUrls.split(ATLAS_URL_DELIMITER))\n                 .map(String::trim)\n                 .forEach(input -> {\n-                    final ValidationResult.Builder builder = new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input);\n                     try {\n-                        new URL(input);\n-                        results.add(builder.explanation(\"Valid URI\").valid(true).build());\n+                        final URL url = new URL(input);\n+                        if (\"https\".equalsIgnoreCase(url.getProtocol())) {\n+                            isAtlasApiSecure.set(true);\n+                        }\n                     } catch (Exception e) {\n-                        results.add(builder.explanation(\"Contains invalid URI: \" + e).valid(false).build());\n+                        results.add(new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input)\n+                                .explanation(\"contains invalid URI: \" + e).valid(false).build());\n                     }\n                 });\n         }\n \n+        if (isAtlasApiSecure.get()) {\n+            if (sslContextService == null) {\n+                results.add(invalidSSLService.explanation(\"required for connecting to Atlas via HTTPS.\").build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMDY3NQ=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5MDg4OA==", "bodyText": "Removed the checks from customValidate(). Tested the fallback mechanism to the system truststore with -Djavax.net.ssl.trustStore* system properties and also with a custom jssecacerts.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444390888", "createdAt": "2020-06-23T17:30:37Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -385,31 +401,50 @@ protected PropertyDescriptor getSupportedDynamicPropertyDescriptor(String proper\n     protected Collection<ValidationResult> customValidate(ValidationContext context) {\n         final Collection<ValidationResult> results = new ArrayList<>();\n \n-        final boolean isSSLContextServiceSet = context.getProperty(KAFKA_SSL_CONTEXT_SERVICE).isSet();\n+        final SSLContextService sslContextService = context.getProperty(SSL_CONTEXT_SERVICE).asControllerService(SSLContextService.class);\n         final ValidationResult.Builder invalidSSLService = new ValidationResult.Builder()\n-                .subject(KAFKA_SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n+                .subject(SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n \n+        AtomicBoolean isAtlasApiSecure = new AtomicBoolean(false);\n         String atlasUrls = context.getProperty(ATLAS_URLS).evaluateAttributeExpressions().getValue();\n         if (!StringUtils.isEmpty(atlasUrls)) {\n             Arrays.stream(atlasUrls.split(ATLAS_URL_DELIMITER))\n                 .map(String::trim)\n                 .forEach(input -> {\n-                    final ValidationResult.Builder builder = new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input);\n                     try {\n-                        new URL(input);\n-                        results.add(builder.explanation(\"Valid URI\").valid(true).build());\n+                        final URL url = new URL(input);\n+                        if (\"https\".equalsIgnoreCase(url.getProtocol())) {\n+                            isAtlasApiSecure.set(true);\n+                        }\n                     } catch (Exception e) {\n-                        results.add(builder.explanation(\"Contains invalid URI: \" + e).valid(false).build());\n+                        results.add(new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input)\n+                                .explanation(\"contains invalid URI: \" + e).valid(false).build());\n                     }\n                 });\n         }\n \n+        if (isAtlasApiSecure.get()) {\n+            if (sslContextService == null) {\n+                results.add(invalidSSLService.explanation(\"required for connecting to Atlas via HTTPS.\").build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMDY3NQ=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDI0MjY0OnYy", "diffSide": "RIGHT", "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNToxOTozMVrOGnFedg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzoyNzo0OVrOGnzXkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzNzM2Ng==", "bodyText": "Could we use the Atlas constants instead?", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443637366", "createdAt": "2020-06-22T15:19:31Z", "author": {"login": "tpalfy"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -322,9 +328,19 @@\n     private static final String ATLAS_PROPERTY_CLUSTER_NAME = \"atlas.cluster.name\";\n     private static final String ATLAS_PROPERTY_REST_ADDRESS = \"atlas.rest.address\";\n     private static final String ATLAS_PROPERTY_ENABLE_TLS = \"atlas.enableTLS\";\n+    private static final String ATLAS_PROPERTY_TRUSTSTORE_FILE = \"truststore.file\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4OTI2Nw==", "bodyText": "Replaced the literals with the Atlas constants but keeping the local constants because the Atlas names are not really straightforward.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444389267", "createdAt": "2020-06-23T17:27:49Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -322,9 +328,19 @@\n     private static final String ATLAS_PROPERTY_CLUSTER_NAME = \"atlas.cluster.name\";\n     private static final String ATLAS_PROPERTY_REST_ADDRESS = \"atlas.rest.address\";\n     private static final String ATLAS_PROPERTY_ENABLE_TLS = \"atlas.enableTLS\";\n+    private static final String ATLAS_PROPERTY_TRUSTSTORE_FILE = \"truststore.file\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzNzM2Ng=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDQ3ODY3OnYy", "diffSide": "RIGHT", "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/security/Kerberos.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNjoxNjoxMFrOGnHyZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzozNTo1OFrOGnzpQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3NTIzOA==", "bodyText": "This looks very similar to the added validation in ReportLineageToAtlas. Would it make sense to extract?", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443675238", "createdAt": "2020-06-22T16:16:10Z", "author": {"login": "simonbence"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/security/Kerberos.java", "diffHunk": "@@ -49,22 +49,24 @@\n \n         final KerberosCredentialsService credentialsService = context.getProperty(ReportLineageToAtlas.KERBEROS_CREDENTIALS_SERVICE).asControllerService(KerberosCredentialsService.class);\n \n-        final String resolvedPrincipal;\n-        final String resolvedKeytab;\n-        if (credentialsService == null) {\n-            resolvedPrincipal = explicitPrincipal;\n-            resolvedKeytab = explicitKeytab;\n-        } else {\n-            resolvedPrincipal = credentialsService.getPrincipal();\n-            resolvedKeytab = credentialsService.getKeytab();\n-        }\n-\n-        if (resolvedPrincipal == null || resolvedKeytab == null) {\n-            problems.add(new ValidationResult.Builder()\n-                .subject(\"Kerberos Credentials\")\n-                .valid(false)\n-                .explanation(\"Both the Principal and the Keytab must be specified when using Kerberos authentication, either via the explicit properties or the Kerberos Credentials Service.\")\n-                .build());\n+        if (credentialsService == null || context.getControllerServiceLookup().isControllerServiceEnabled(credentialsService)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5Mzc5NA==", "bodyText": "Yes, that would make sense. However, I just wanted to fix the ControllerServiceDisabledException stacktraces in the log for now. Leaving as it was.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444393794", "createdAt": "2020-06-23T17:35:58Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/security/Kerberos.java", "diffHunk": "@@ -49,22 +49,24 @@\n \n         final KerberosCredentialsService credentialsService = context.getProperty(ReportLineageToAtlas.KERBEROS_CREDENTIALS_SERVICE).asControllerService(KerberosCredentialsService.class);\n \n-        final String resolvedPrincipal;\n-        final String resolvedKeytab;\n-        if (credentialsService == null) {\n-            resolvedPrincipal = explicitPrincipal;\n-            resolvedKeytab = explicitKeytab;\n-        } else {\n-            resolvedPrincipal = credentialsService.getPrincipal();\n-            resolvedKeytab = credentialsService.getKeytab();\n-        }\n-\n-        if (resolvedPrincipal == null || resolvedKeytab == null) {\n-            problems.add(new ValidationResult.Builder()\n-                .subject(\"Kerberos Credentials\")\n-                .valid(false)\n-                .explanation(\"Both the Principal and the Keytab must be specified when using Kerberos authentication, either via the explicit properties or the Kerberos Credentials Service.\")\n-                .build());\n+        if (credentialsService == null || context.getControllerServiceLookup().isControllerServiceEnabled(credentialsService)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3NTIzOA=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDQ5NTMxOnYy", "diffSide": "RIGHT", "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNjoyMDoyM1rOGnH84Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzo0MDozOFrOGnzzxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3NzkyMQ==", "bodyText": "Is not that necessary to use allMatch? (I am not 100% sure though)", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443677921", "createdAt": "2020-06-22T16:20:23Z", "author": {"login": "simonbence"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -632,10 +667,37 @@ private void setValue(Consumer<String> setter, Runnable emptyHandler, PropertyVa\n         }\n     }\n \n-    private void checkAtlasUrls(List<String> urlStrings, ConfigurationContext context) {\n-        if (urlStrings.isEmpty()) {\n-            throw new ProcessException(\"No Atlas URL has been specified! Set either the '\" + ATLAS_URLS.getDisplayName() + \"' \" +\n-                \"property on the processor or the 'atlas.rest.address' porperty in the atlas configuration file.\");\n+    private void setAtlasSSLConfig(Properties atlasProperties, ConfigurationContext context, List<String> urls, File confDir) throws IOException {\n+        boolean isAtlasApiSecure = urls.stream().anyMatch(url -> url.toLowerCase().startsWith(\"https\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 245}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5NjQ4NQ==", "bodyText": "It is a preexisting line relocated between methods. It is supposed here that all the URLs have the same scheme so it is enough to check if there is one https:// (and in this case all the others are https://).\nBut it was not checked anywhere. Added the check to customValidate().", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444396485", "createdAt": "2020-06-23T17:40:38Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -632,10 +667,37 @@ private void setValue(Consumer<String> setter, Runnable emptyHandler, PropertyVa\n         }\n     }\n \n-    private void checkAtlasUrls(List<String> urlStrings, ConfigurationContext context) {\n-        if (urlStrings.isEmpty()) {\n-            throw new ProcessException(\"No Atlas URL has been specified! Set either the '\" + ATLAS_URLS.getDisplayName() + \"' \" +\n-                \"property on the processor or the 'atlas.rest.address' porperty in the atlas configuration file.\");\n+    private void setAtlasSSLConfig(Properties atlasProperties, ConfigurationContext context, List<String> urls, File confDir) throws IOException {\n+        boolean isAtlasApiSecure = urls.stream().anyMatch(url -> url.toLowerCase().startsWith(\"https\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3NzkyMQ=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 245}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDc1MTczOnYy", "diffSide": "RIGHT", "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNzozNDoyNFrOGnKgtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzozMToxOFrOGnzfXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxOTg2Mw==", "bodyText": "Could use the Hadoop constants.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443719863", "createdAt": "2020-06-22T17:34:24Z", "author": {"login": "tpalfy"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {\n+\n+    private static final String CRED_STORE_PASSWORD_ENVVAR = \"HADOOP_CREDSTORE_PASSWORD\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5MTI2Mg==", "bodyText": "Class has been removed (see comments below).", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444391262", "createdAt": "2020-06-23T17:31:18Z", "author": {"login": "turcsanyip"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {\n+\n+    private static final String CRED_STORE_PASSWORD_ENVVAR = \"HADOOP_CREDSTORE_PASSWORD\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcxOTg2Mw=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NDc3NjgxOnYy", "diffSide": "RIGHT", "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQxNzo0MjoxNlrOGnKxJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzozMzo1N1rOGnzk3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcyNDA3MQ==", "bodyText": "We could initialize a collection in @OnScheduled instread.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r443724071", "createdAt": "2020-06-22T17:42:16Z", "author": {"login": "tpalfy"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -385,31 +401,50 @@ protected PropertyDescriptor getSupportedDynamicPropertyDescriptor(String proper\n     protected Collection<ValidationResult> customValidate(ValidationContext context) {\n         final Collection<ValidationResult> results = new ArrayList<>();\n \n-        final boolean isSSLContextServiceSet = context.getProperty(KAFKA_SSL_CONTEXT_SERVICE).isSet();\n+        final SSLContextService sslContextService = context.getProperty(SSL_CONTEXT_SERVICE).asControllerService(SSLContextService.class);\n         final ValidationResult.Builder invalidSSLService = new ValidationResult.Builder()\n-                .subject(KAFKA_SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n+                .subject(SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n \n+        AtomicBoolean isAtlasApiSecure = new AtomicBoolean(false);\n         String atlasUrls = context.getProperty(ATLAS_URLS).evaluateAttributeExpressions().getValue();\n         if (!StringUtils.isEmpty(atlasUrls)) {\n             Arrays.stream(atlasUrls.split(ATLAS_URL_DELIMITER))\n                 .map(String::trim)\n                 .forEach(input -> {\n-                    final ValidationResult.Builder builder = new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input);\n                     try {\n-                        new URL(input);\n-                        results.add(builder.explanation(\"Valid URI\").valid(true).build());\n+                        final URL url = new URL(input);\n+                        if (\"https\".equalsIgnoreCase(url.getProtocol())) {\n+                            isAtlasApiSecure.set(true);\n+                        }\n                     } catch (Exception e) {\n-                        results.add(builder.explanation(\"Contains invalid URI: \" + e).valid(false).build());\n+                        results.add(new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input)\n+                                .explanation(\"contains invalid URI: \" + e).valid(false).build());\n                     }\n                 });\n         }\n \n+        if (isAtlasApiSecure.get()) {\n+            if (sslContextService == null) {\n+                results.add(invalidSSLService.explanation(\"required for connecting to Atlas via HTTPS.\").build());\n+            } else if (context.getControllerServiceLookup().isControllerServiceEnabled(sslContextService)) {\n+                if (!sslContextService.isTrustStoreConfigured()) {\n+                    results.add(invalidSSLService.explanation(\"no truststore configured which is required for connecting to Atlas via HTTPS.\").build());\n+                } else if (!KEYSTORE_TYPE_JKS.equalsIgnoreCase(sslContextService.getTrustStoreType())) {\n+                    results.add(invalidSSLService.explanation(\"truststore type is not JKS. Atlas client supports JKS truststores only.\").build());\n+                }\n+            }\n+        }\n+\n         final String atlasAuthNMethod = context.getProperty(ATLAS_AUTHN_METHOD).getValue();\n         final AtlasAuthN atlasAuthN = getAtlasAuthN(atlasAuthNMethod);\n         results.addAll(atlasAuthN.validate(context));\n \n-\n-        namespaceResolverLoader.forEach(resolver -> results.addAll(resolver.validate(context)));\n+        synchronized (namespaceResolverLoader) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5MjY3MQ==", "bodyText": "customValidate() runs before @OnScheduled gets called so that point is too late.\nI tried init() but ran into classloader issues with NamespaceResolver interface and its implementations.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444392671", "createdAt": "2020-06-23T17:33:57Z", "author": {"login": "turcsanyip"}, "path": "nifi-nar-bundles/nifi-atlas-bundle/nifi-atlas-reporting-task/src/main/java/org/apache/nifi/atlas/reporting/ReportLineageToAtlas.java", "diffHunk": "@@ -385,31 +401,50 @@ protected PropertyDescriptor getSupportedDynamicPropertyDescriptor(String proper\n     protected Collection<ValidationResult> customValidate(ValidationContext context) {\n         final Collection<ValidationResult> results = new ArrayList<>();\n \n-        final boolean isSSLContextServiceSet = context.getProperty(KAFKA_SSL_CONTEXT_SERVICE).isSet();\n+        final SSLContextService sslContextService = context.getProperty(SSL_CONTEXT_SERVICE).asControllerService(SSLContextService.class);\n         final ValidationResult.Builder invalidSSLService = new ValidationResult.Builder()\n-                .subject(KAFKA_SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n+                .subject(SSL_CONTEXT_SERVICE.getDisplayName()).valid(false);\n \n+        AtomicBoolean isAtlasApiSecure = new AtomicBoolean(false);\n         String atlasUrls = context.getProperty(ATLAS_URLS).evaluateAttributeExpressions().getValue();\n         if (!StringUtils.isEmpty(atlasUrls)) {\n             Arrays.stream(atlasUrls.split(ATLAS_URL_DELIMITER))\n                 .map(String::trim)\n                 .forEach(input -> {\n-                    final ValidationResult.Builder builder = new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input);\n                     try {\n-                        new URL(input);\n-                        results.add(builder.explanation(\"Valid URI\").valid(true).build());\n+                        final URL url = new URL(input);\n+                        if (\"https\".equalsIgnoreCase(url.getProtocol())) {\n+                            isAtlasApiSecure.set(true);\n+                        }\n                     } catch (Exception e) {\n-                        results.add(builder.explanation(\"Contains invalid URI: \" + e).valid(false).build());\n+                        results.add(new ValidationResult.Builder().subject(ATLAS_URLS.getDisplayName()).input(input)\n+                                .explanation(\"contains invalid URI: \" + e).valid(false).build());\n                     }\n                 });\n         }\n \n+        if (isAtlasApiSecure.get()) {\n+            if (sslContextService == null) {\n+                results.add(invalidSSLService.explanation(\"required for connecting to Atlas via HTTPS.\").build());\n+            } else if (context.getControllerServiceLookup().isControllerServiceEnabled(sslContextService)) {\n+                if (!sslContextService.isTrustStoreConfigured()) {\n+                    results.add(invalidSSLService.explanation(\"no truststore configured which is required for connecting to Atlas via HTTPS.\").build());\n+                } else if (!KEYSTORE_TYPE_JKS.equalsIgnoreCase(sslContextService.getTrustStoreType())) {\n+                    results.add(invalidSSLService.explanation(\"truststore type is not JKS. Atlas client supports JKS truststores only.\").build());\n+                }\n+            }\n+        }\n+\n         final String atlasAuthNMethod = context.getProperty(ATLAS_AUTHN_METHOD).getValue();\n         final AtlasAuthN atlasAuthN = getAtlasAuthN(atlasAuthNMethod);\n         results.addAll(atlasAuthN.validate(context));\n \n-\n-        namespaceResolverLoader.forEach(resolver -> results.addAll(resolver.validate(context)));\n+        synchronized (namespaceResolverLoader) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcyNDA3MQ=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 130}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzkxMTc1OnYy", "diffSide": "RIGHT", "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMzoyNzozNlrOGnpMmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxNzo0MTozNVrOGnz2nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIyMjYxOA==", "bodyText": "Taking a closer look, I think we would be better off using the hadoop library for this.\nThis module already depends on hadoop-commons and the API between NiFi and Atlas solidifies this dependency - although not explicitly through code, but through the constraints of how to create the keystore.\nI don't think it's worth having our own version but @bbende, I'd give you the final word on this one.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444222618", "createdAt": "2020-06-23T13:27:36Z", "author": {"login": "tpalfy"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzMDQ5NQ==", "bodyText": "I didn't realize the Atlas bundle already had hadoop-common so originally I thought it was better to not add that dependency and just have our own version of this class, but if it is already there then I'm indifferent.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444230495", "createdAt": "2020-06-23T13:38:30Z", "author": {"login": "bbende"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIyMjYxOA=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzNzQ3MQ==", "bodyText": "I had troubles with running the tests on Windows. I managed to fix them but some other problems may occur later. So now I would also vote for not maintaining our custom solution but using the one from hadoop-common.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444237471", "createdAt": "2020-06-23T13:48:00Z", "author": {"login": "turcsanyip"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIyMjYxOA=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5NzIxNQ==", "bodyText": "Refactored to use LocalJavaKeyStoreProvider from hadoop-common.", "url": "https://github.com/apache/nifi/pull/4348#discussion_r444397215", "createdAt": "2020-06-23T17:41:35Z", "author": {"login": "turcsanyip"}, "path": "nifi-commons/nifi-security-utils/src/main/java/org/apache/nifi/security/credstore/HadoopCredentialStore.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.nifi.security.credstore;\n+\n+import org.apache.nifi.processor.exception.ProcessException;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.security.KeyStore;\n+import java.util.Map;\n+\n+public class HadoopCredentialStore {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIyMjYxOA=="}, "originalCommit": {"oid": "9c9a61190d43ea616f3b49219b5ec6dfa28dc10a"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 167, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}