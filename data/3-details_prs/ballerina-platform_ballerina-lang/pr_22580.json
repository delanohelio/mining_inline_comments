{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAxODYxMTMz", "number": 22580, "title": "Fix API docs in module Kafka", "bodyText": "Purpose\n\n$title\n\nCheck List\n\n Read the Contributing Guide\n Updated Change Log\n Checked Tooling Support (#)\n Added necessary tests\n\n Unit Tests\n Spec Conformance Tests\n Integration Tests\n Ballerina By Example Tests\n\n\n Increased Test Coverage\n Added necessary documentation\n\n API documentation\n Module documentation in Module.md files\n Ballerina By Examples", "createdAt": "2020-04-10T10:50:05Z", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580", "merged": true, "mergeCommit": {"oid": "e0410cc4015b1fe2ed9007f5324995599fcd8ab4"}, "closed": true, "closedAt": "2020-04-15T15:29:37Z", "author": {"login": "aashikam"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcWO1ILgH2gAyNDAxODYxMTMzOmIwNmZhZmYyZTI2ZGYyYjdmNDU5ZTUwYWRjOTc3YjhmZWQ3YzcyZTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcX5tAIgFqTM5Mzg4MDAzNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "author": {"user": {"login": "aashikam", "name": "Arshika Mohottige"}}, "url": "https://github.com/ballerina-platform/ballerina-lang/commit/b06faff2e26df2b7f459e50adc977b8fed7c72e5", "committedDate": "2020-04-10T10:49:07Z", "message": "Fix API docs in module Kafka"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNDM3NDAz", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-391437403", "createdAt": "2020-04-10T13:19:03Z", "commit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "state": "COMMENTED", "comments": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTowNFrOGD6RTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNzowNFrOGD7tcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzYxMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">`kafka:ConsumerError</span>` if an error is encountered while starting the server<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753612", "createdAt": "2020-04-10T13:19:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzgxMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753812", "createdAt": "2020-04-10T13:19:37Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzkyOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753929", "createdAt": "2020-04-10T13:19:57Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDE5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while attaching the service or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754196", "createdAt": "2020-04-10T13:20:39Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDMzOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while detaching a service or nil\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while detaching a service or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754339", "createdAt": "2020-04-10T13:21:03Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n     public function __attach(service s, string? name = ()) returns error? {\n         return register(self, s, name);\n     }\n \n     # Detaches a consumer service from the listener.\n     #\n     # + s - The service to be detached\n-    # + return - An `error` if an error occurred during detaching a service or `nil`\n+    # + return - An `error` if an error is encountered while detaching a service or nil", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDQ2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754468", "createdAt": "2020-04-10T13:21:24Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDYxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754614", "createdAt": "2020-04-10T13:21:47Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTIwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755204", "createdAt": "2020-04-10T13:23:32Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function close(public int duration = -1) returns ConsumerError? {\n         return consumerClose(self, duration);\n     }\n \n-    # Commits current consumed offsets for consumer.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Commits current consumed offsets for consumer.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->commit();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTI5OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise.</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755299", "createdAt": "2020-04-10T13:23:44Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTM2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755361", "createdAt": "2020-04-10T13:23:53Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTUzMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully<span class=\"x x-first x-last\">, </span>`kafka:ConsumerError`<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully<span class=\"x x-first x-last\">  or else </span>`kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755530", "createdAt": "2020-04-10T13:24:17Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTkyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #            `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n            #            `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755926", "createdAt": "2020-04-10T13:25:25Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 339}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA0NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756045", "createdAt": "2020-04-10T13:25:42Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 324}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA5Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756092", "createdAt": "2020-04-10T13:25:51Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 309}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjE3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756179", "createdAt": "2020-04-10T13:26:07Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 294}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjI0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756241", "createdAt": "2020-04-10T13:26:18Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 280}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjMzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n          \n          \n            \n                #            the operation fails\n          \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756333", "createdAt": "2020-04-10T13:26:35Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 353}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjQxOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n          \n          \n            \n            #            the operation fails\n          \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756419", "createdAt": "2020-04-10T13:26:47Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 368}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjUwMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756501", "createdAt": "2020-04-10T13:26:58Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 386}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1OTc2NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406759764", "createdAt": "2020-04-10T13:34:49Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 386}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzQwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773405", "createdAt": "2020-04-10T14:08:03Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzUwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n          \n          \n            \n            #            fails\n          \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773509", "createdAt": "2020-04-10T14:08:19Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 414}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3Mzc3NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773775", "createdAt": "2020-04-10T14:08:53Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 425}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzgyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773826", "createdAt": "2020-04-10T14:09:02Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 436}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDA1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offset - The `PartitionOffset` to seek\n          \n          \n            \n                # + offset - The `<span class=\"x x-first x-last\">kafka:</span>PartitionOffset` to seek", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774058", "createdAt": "2020-04-10T14:09:37Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 435}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDM3OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774378", "createdAt": "2020-04-10T14:10:19Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 447}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDQzNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774435", "createdAt": "2020-04-10T14:10:28Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 458}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDUyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774522", "createdAt": "2020-04-10T14:10:42Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 473}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDY0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774646", "createdAt": "2020-04-10T14:11:00Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 488}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDg4MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774880", "createdAt": "2020-04-10T14:11:33Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 505}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDk0OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774948", "createdAt": "2020-04-10T14:11:43Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeWithPartitionRebalance(string[] topics,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsRevoked,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsAssigned)\n     returns ConsumerError? {\n         return consumerSubscribeWithPartitionRebalance(self, topics, onPartitionsRevoked, onPartitionsAssigned);\n     }\n \n-    # Unsubscribe the consumer from all the topic subscriptions.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Unsubscribes from all the topic subscriptions.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->unsubscribe();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 521}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjAxMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits <span class=\"x x-first x-last\">consumer </span>consumed <span class=\"x x-first x-last\">offsets to offset topic</span>.\n          \n          \n            \n                # Commits <span class=\"x x-first x-last\">the offsets </span>consumed <span class=\"x x-first x-last\">by the provided consumer</span>.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776010", "createdAt": "2020-04-10T14:14:07Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjEwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776102", "createdAt": "2020-04-10T14:14:21Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjUxNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776515", "createdAt": "2020-04-10T14:15:22Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjgxOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Flushes batch of records.\n          \n          \n            \n            # Flushes <span class=\"x x-first x-last\">the </span>batch of records<span class=\"x x-first x-last\"> already sent to the broker by the producer</span>.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776818", "createdAt": "2020-04-10T14:16:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjkxMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776910", "createdAt": "2020-04-10T14:16:17Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NzIwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves <span class=\"x x-first x-last\">given </span>topic partition information.\n          \n          \n            \n            # Retrieves topic partition information<span class=\"x x-first x-last\"> for the provided topic</span>.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406777202", "createdAt": "2020-04-10T14:17:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 187}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNDc3MDgy", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-391477082", "createdAt": "2020-04-10T14:38:52Z", "commit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "state": "COMMENTED", "comments": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozODo1MlrOGD8Tow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NjozM1rOGD8gjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Njk3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             To do so, download the necessary dependencies and <span class=\"x x-first x-last\">put</span> them inside the `resources\n          \n          \n            \n             To do so, download the necessary dependencies and <span class=\"x x-first x-last\">add</span> them inside the `resources", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406786979", "createdAt": "2020-04-10T14:38:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -89,10 +21,9 @@ cd kafka_avro_sample\n ballerina add producer\n ballerina add consumer\n ```\n-\n- #### Dependencies\n+ ##### Dependencies\n  To use Avro, you need to add the necessary dependencies to the Ballerina project you created. \n-To do so, download the necessary dependencies and put them inside the `resources\n+ To do so, download the necessary dependencies and put them inside the `resources", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzEwMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like follows<span class=\"x x-first x-last\">. (Some</span> of the files are ignored)\n          \n          \n            \n            Now, the directory structure will look like follows<span class=\"x x-first x-last\"> (some</span> of the files are ignored)<span class=\"x x-first x-last\">.</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787100", "createdAt": "2020-04-10T14:39:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +85,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows. (Some of the files are ignored)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzIwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents topic partition position in which consumed record is stored.\n          \n          \n            \n            # Represents <span class=\"x x-first x-last\">the </span>topic partition position in which<span class=\"x x-first x-last\"> the</span> consumed record is stored.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787209", "createdAt": "2020-04-10T14:39:24Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzI3OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + offset - Offset in which record is stored in partition\n          \n          \n            \n            # + offset - Offset in which <span class=\"x x-first x-last\">the </span>record is stored in<span class=\"x x-first x-last\"> the</span> partition", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787278", "createdAt": "2020-04-10T14:39:34Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQxMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStore - Configurations associated with KeyStore\n          \n          \n            \n            # + keyStore - Configurations associated with <span class=\"x x-first x-last\">the </span>KeyStore", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787412", "createdAt": "2020-04-10T14:39:51Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQ1MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStore - Configurations associated with TrustStore\n          \n          \n            \n            # + trustStore - Configurations associated with <span class=\"x x-first x-last\">the </span>TrustStore", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787450", "createdAt": "2020-04-10T14:39:57Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzUwNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + protocol - Configurations related to SSL/TLS protocol and version to be used\n          \n          \n            \n            # + protocol - Configurations related to <span class=\"x x-first x-last\">the </span>SSL/TLS protocol and<span class=\"x x-first x-last\"> the</span> version to be used", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787504", "createdAt": "2020-04-10T14:40:06Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzc4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n          \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for <span class=\"x x-first x-last\">the </span>client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787786", "createdAt": "2020-04-10T14:40:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzk0OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n          \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC<span class=\"x x-first x-last\">,</span> and key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787949", "createdAt": "2020-04-10T14:41:03Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODMzNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network protocol. By default all the available cipher suites are supported\n          \n          \n            \n            #                     or SSL network protocol. By default<span class=\"x x-first x-last\">,</span> all the available cipher suites are supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788335", "createdAt": "2020-04-10T14:42:00Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODQ5OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n          \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate <span class=\"x x-first x-last\">the </span>server hostname using<span class=\"x x-first x-last\"> the</span> server", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788499", "createdAt": "2020-04-10T14:42:24Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODYxMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The <span class=\"x x-first x-last\">`</span>SecureRandom<span class=\"x x-first x-last\">`</span> PRNG implementation to use for SSL cryptography operations", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788613", "createdAt": "2020-04-10T14:42:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                                        certificate\n+# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODY2NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>KeyStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788664", "createdAt": "2020-04-10T14:42:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODg3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStoreType - The file format of KeyStore file. This is optional for client\n          \n          \n            \n            # + keyStoreType - The file format of <span class=\"x x-first x-last\">the </span>KeyStore file. This is optional for<span class=\"x x-first x-last\"> the</span> client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788874", "createdAt": "2020-04-10T14:43:15Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODk0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n          \n          \n            \n            # + location - The location of the KeyStore file. This is optional for <span class=\"x x-first x-last\">the </span>client and can be used for two-way", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788941", "createdAt": "2020-04-10T14:43:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTAxOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              authentication for client\n          \n          \n            \n            #              authentication for <span class=\"x x-first x-last\">the </span>client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789019", "createdAt": "2020-04-10T14:43:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTExMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for client and only needed if\n          \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for <span class=\"x x-first x-last\">the </span>client and<span class=\"x x-first x-last\"> is</span> only needed if", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789111", "createdAt": "2020-04-10T14:43:44Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTE5Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              ssl.keystore.location is configured\n          \n          \n            \n            #              <span class=\"x x-first x-last\">the `</span>ssl.keystore.location<span class=\"x x-first x-last\">`</span> is configured", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789197", "createdAt": "2020-04-10T14:43:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTMxNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. <span class=\"x x-first x-last\">Default</span> value is the key\n          \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by <span class=\"x x-first x-last\">the </span>key manager factory for SSL connections. <span class=\"x x-first x-last\">The default</span> value is the key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789316", "createdAt": "2020-04-10T14:44:09Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTM2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                         manager factory algorithm configured for the JVM\n          \n          \n            \n            #                         manager factory algorithm configured for the JVM", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789363", "createdAt": "2020-04-10T14:44:17Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTQxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to TrustStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>TrustStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789414", "createdAt": "2020-04-10T14:44:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTUzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n      \n    \n    \n  \n\nAdd fullstops for all descriptions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789536", "createdAt": "2020-04-10T14:44:43Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTYyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n          \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set<span class=\"x x-first x-last\">,</span> access to the TrustStore is still", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789620", "createdAt": "2020-04-10T14:44:54Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTY4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              available<span class=\"x x-first x-last\">,</span> but integrity checking is disabled\n          \n          \n            \n            #              available but integrity checking is disabled", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789686", "createdAt": "2020-04-10T14:45:03Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTgwMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. <span class=\"x x-first x-last\">Default</span> value is the trust\n          \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by <span class=\"x x-first x-last\">the </span>trust manager factory for SSL connections. <span class=\"x x-first x-last\">The default</span> value is the trust", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789800", "createdAt": "2020-04-10T14:45:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTg5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to SSL/TLS protocol and the versions to be used.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>SSL/TLS protocol and the versions to be used.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789895", "createdAt": "2020-04-10T14:45:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTk4OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. <span class=\"x x-first x-last\">Default</span> setting is TLS, which is fine for most\n          \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. <span class=\"x x-first x-last\">The default</span> setting is TLS, which is fine for most", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789989", "createdAt": "2020-04-10T14:45:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDIyOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n          \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1<span class=\"x x-first x-last\">,</span> and TLSv1.2. <span class=\"x x-first x-last\">Also, </span>SSL, SSLv2<span class=\"x x-first x-last\">,</span> and SSLv3 may be supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790229", "createdAt": "2020-04-10T14:46:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDI4Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 in older JVMs<span class=\"x x-first x-last\">,</span> but their usage is discouraged due to known security vulnerabilities\n          \n          \n            \n            #                 in older JVMs but their usage is discouraged due to known security vulnerabilities", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790287", "createdAt": "2020-04-10T14:46:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n+#                 in older JVMs, but their usage is discouraged due to known security vulnerabilities", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 113}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNDk2ODA2", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-391496806", "createdAt": "2020-04-10T15:15:52Z", "commit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "state": "COMMENTED", "comments": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNTo1MlrOGD9Tjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMToyMlrOGD9ufw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzM0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be deserialized\n          \n          \n            \n                # + data - Data<span class=\"x x-first x-last\">,</span> which should be deserialized", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803342", "createdAt": "2020-04-10T15:15:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data which should be deserialized", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzQzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Isolation levels\n          \n          \n            \n            // Isolation levels<span class=\"x x-first x-last\">.</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803433", "createdAt": "2020-04-10T15:16:02Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzU0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read all the messages<span class=\"x x-first x-last\">,</span> even the aborted ones.\n          \n          \n            \n            # Configures the consumer to read all the messages even the aborted ones.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803547", "createdAt": "2020-04-10T15:16:17Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjQ1Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer related constants\n          \n          \n            \n            // Producer related constants<span class=\"x x-first x-last\">.</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806457", "createdAt": "2020-04-10T15:22:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n // Producer related constants", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjUxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Compression types\n          \n          \n            \n            // Compression types<span class=\"x x-first x-last\">.</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806514", "createdAt": "2020-04-10T15:22:58Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -86,17 +86,17 @@ public const SER_CUSTOM = \"CUSTOM\";\n public const SER_AVRO = \"AVRO\";\n \n // Compression types", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjcyOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents Kafka Producer configuration.\n          \n          \n            \n            # Represents <span class=\"x x-first x-last\">the </span>Kafka Producer configuration.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806728", "createdAt": "2020-04-10T15:23:29Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjg3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n          \n          \n            \n            # + partitionerClass - Partitioner class to be used to select <span class=\"x x-first x-last\">the </span>partition to which the message is sent", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806879", "createdAt": "2020-04-10T15:23:46Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzE1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keySerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">kafka</span> keys. This should<span class=\"x x-first x-last\"> be</span> implement the `kafka:Serializer`\n          \n          \n            \n            # + keySerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">Kafka</span> keys. This should implement the `kafka:Serializer`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807158", "createdAt": "2020-04-10T15:24:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzI0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">kafka</span> values. This should<span class=\"x x-first x-last\"> be</span> implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">Kafka</span> values. This should implement the", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807244", "createdAt": "2020-04-10T15:24:34Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzUwMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaRegistryUrl - Avro schema registry <span class=\"x x-first x-last\">url</span>. Use this field to specify schema registry <span class=\"x x-first x-last\">url</span> if Avro serializer\n          \n          \n            \n            # + schemaRegistryUrl - Avro schema registry <span class=\"x x-first x-last\">URL</span>. Use this field to specify <span class=\"x x-first x-last\">the </span>schema registry <span class=\"x x-first x-last\">URL</span> if<span class=\"x x-first x-last\"> the</span> Avro serializer", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807500", "createdAt": "2020-04-10T15:25:09Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzgzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time which the <span class=\"x x-first x-last\">send</span> is blocked<span class=\"x x-first x-last\">,</span> when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time <span class=\"x x-first x-last\">during </span>which the <span class=\"x x-first x-last\">sending</span> is blocked when the buffer is full", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807831", "createdAt": "2020-04-10T15:25:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzkxMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + requestTimeoutInMillis - Wait time for response of a request\n          \n          \n            \n            # + requestTimeoutInMillis - Wait time for <span class=\"x x-first x-last\">the </span>response of a request", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807910", "createdAt": "2020-04-10T15:26:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODE3Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to <span class=\"x x-first x-last\">computed</span> over\n          \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to <span class=\"x x-first x-last\">compute</span> over", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808177", "createdAt": "2020-04-10T15:26:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODU1Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaString - The string which defines the Avro schema\n          \n          \n            \n            # + schemaString - The string<span class=\"x x-first x-last\">,</span> which defines the Avro schema", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808556", "createdAt": "2020-04-10T15:27:36Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODYxMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + dataRecord - Records which should be serialized using Avro\n          \n          \n            \n            # + dataRecord - Records<span class=\"x x-first x-last\">,</span> which should be serialized using Avro", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808611", "createdAt": "2020-04-10T15:27:45Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema\n+# + dataRecord - Records which should be serialized using Avro", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODgwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Closes producer connection to the external Kafka broker.\n          \n          \n            \n            # Closes <span class=\"x x-first x-last\">the </span>producer connection to the external Kafka broker.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808802", "createdAt": "2020-04-10T15:28:11Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTA0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer consumed offsets to offset topic.\n          \n          \n            \n                # Commits consumer consumed offsets to <span class=\"x x-first x-last\">the </span>offset topic.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809047", "createdAt": "2020-04-10T15:28:42Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTI2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + consumer - Consumer which needs offsets to be committed\n          \n          \n            \n                # + consumer - Consumer<span class=\"x x-first x-last\">,</span> which needs offsets to be committed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809268", "createdAt": "2020-04-10T15:29:12Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTc2Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic which the partition information is given\n          \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">to </span>which the partition information is given", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809766", "createdAt": "2020-04-10T15:30:18Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTg0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if <span class=\"x x-first x-last\">the </span>operation fails", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809847", "createdAt": "2020-04-10T15:30:29Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTkwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Produces records to Kafka server.\n          \n          \n            \n            # Produces records to <span class=\"x x-first x-last\">the </span>Kafka server.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809905", "createdAt": "2020-04-10T15:30:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTk3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic to which the record will be appended <span class=\"x x-first x-last\">to</span>\n          \n          \n            \n            # + topic - Topic to which the record will be appended", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809972", "createdAt": "2020-04-10T15:30:46Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDA3MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + timestamp - Timestamp of the record<span class=\"x x-first x-last\">,</span> in milliseconds since epoch\n          \n          \n            \n            # + timestamp - Timestamp of the record in milliseconds since epoch", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810070", "createdAt": "2020-04-10T15:30:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDEzNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil <span class=\"x x-first x-last\">otherwise</span>\n          \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810135", "createdAt": "2020-04-10T15:31:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDIzOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be serialized\n          \n          \n            \n                # + data - Data<span class=\"x x-first x-last\">,</span> which should be serialized", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810239", "createdAt": "2020-04-10T15:31:22Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.\n     #\n-    # + data - Data which should be serialized.\n-    # + return - Serialized `byte[]` value.\n+    # + data - Data which should be serialized", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNTA1NDgw", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-391505480", "createdAt": "2020-04-10T15:32:33Z", "commit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMjozM1rOGD9wXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMjozM1rOGD9wXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDcxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n      \n    \n    \n  \n\nPlease replace all occurrences of \"nil\" with \"()\".", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810717", "createdAt": "2020-04-10T15:32:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 141}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6", "author": {"user": {"login": "aashikam", "name": "Arshika Mohottige"}}, "url": "https://github.com/ballerina-platform/ballerina-lang/commit/68e58f2d9f4ec969c01575be4e0b120a2f60e9f6", "committedDate": "2020-04-14T04:53:36Z", "message": "Add changes from code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNzY1NzA2", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-392765706", "createdAt": "2020-04-14T09:41:14Z", "commit": {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwOTo0MToxNVrOGFGkEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwOTo0MToxNVrOGFGkEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAwMzYwMQ==", "bodyText": "Shall we make the module.md structure similar to the other messaging modules. Add code snippets to the usages.\n\nhttps://github.com/daneshk/ballerina/blob/nats-docs-updates/stdlib/messaging/nats/src/main/ballerina/src/nats/Module.md\nhttps://github.com/daneshk/ballerina/blob/rabbitmq-docs-updates/stdlib/messaging/rabbitmq/src/main/ballerina/src/rabbitmq/Module.md", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408003601", "createdAt": "2020-04-14T09:41:15Z", "author": {"login": "daneshk"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,15 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d422b3c0dcdce0b16499e06276f1a335a83dbca", "author": {"user": {"login": "aashikam", "name": "Arshika Mohottige"}}, "url": "https://github.com/ballerina-platform/ballerina-lang/commit/4d422b3c0dcdce0b16499e06276f1a335a83dbca", "committedDate": "2020-04-15T03:49:48Z", "message": "Merge branch 'stdlib-doc-hackathon' of https://github.com/ballerina-platform/ballerina-lang into kafka-docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506", "author": {"user": {"login": "aashikam", "name": "Arshika Mohottige"}}, "url": "https://github.com/ballerina-platform/ballerina-lang/commit/d4730360c31d2d785c78586af3fd7631ca0a3506", "committedDate": "2020-04-15T04:04:43Z", "message": "Add basic usages to Module.md"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNDk0Mjc3", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-393494277", "createdAt": "2020-04-15T06:43:37Z", "commit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 40, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0MzozOFrOGFr1kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1OFrOGFsMVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDI4OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This module supports <span class=\"x x-first x-last\">kafka</span> 1.x.x and 2.0.0 versions.\n          \n          \n            \n            This module supports <span class=\"x x-first x-last\">Kafka</span> 1.x.x and 2.0.0 versions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614289", "createdAt": "2020-04-15T06:43:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDQ0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Producer` to publish messages. \n          \n          \n            \n            2. Use <span class=\"x x-first x-last\">the </span>`kafka:Producer` to publish messages.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614441", "createdAt": "2020-04-15T06:43:56Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Consumer` as a simple record consumer.\n          \n          \n            \n            2. Use <span class=\"x x-first x-last\">the </span>`kafka:Consumer` as a simple record consumer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614542", "createdAt": "2020-04-15T06:44:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU3NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            3. Use `kafka:Consumer` as a listener.\n          \n          \n            \n            3. Use <span class=\"x x-first x-last\">the </span>`kafka:Consumer` as a listener.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614575", "createdAt": "2020-04-15T06:44:14Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDY2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To try this, <span class=\"x x-first x-last\">let's </span>create a new Ballerina project and two modules inside it.\n          \n          \n            \n            To try this, create a new Ballerina project and two modules inside it.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614662", "createdAt": "2020-04-15T06:44:30Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.\n+```ballerina\n+listener kafka:Consumer consumer = new (consumerConfiguration);\n \n-function main () {\n-    string msg = \"Hello World, Ballerina\";\n-    byte[] serializedMsg = msg.toByteArray(\"UTF-8\");\n-    var sendResult = kafkaProducer->send(serializedMsg, \"test-kafka-topic\");\n-    if (sendResult is error) {\n-        log:printError(\"Kafka producer failed to send data\", err = sendResult);\n+service kafkaService on consumer {\n+    // This resource will be executed when a message is published to the\n+    // subscribed topic/topics.\n+    resource function onMessage(kafka:Consumer kafkaConsumer,\n+            kafka:ConsumerRecord[] records) {\n     }\n }\n ```\n \n-### Send Data Using Avro\n+#### Send Data Using Avro\n The Ballerina Kafka module supports Avro serialization and deserialization.\n \n To try this, let's create a new Ballerina project and two modules inside it.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDk5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like <span class=\"x x-first x-last\">follows</span> (some of the files are ignored).\n          \n          \n            \n            Now, the directory structure will look like <span class=\"x x-first x-last\">below</span> (some of the files are ignored).", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614995", "createdAt": "2020-04-15T06:45:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +138,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows (some of the files are ignored).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTE1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.\n          \n          \n            \n            The Consumer will return <span class=\"x x-first x-last\">a </span>`kafka:AvroGenericRecord` with the data received from Avro.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615158", "createdAt": "2020-04-15T06:45:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -225,7 +209,7 @@ public function main() {\n }\n ```\n \n-#### Avro Consumer\n+##### Avro Consumer\n The Kafka implementation of Ballerina currently supports Avro deserialization only for generic records.\n The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTIzOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partition - `kafka:TopicPartition` to which the record is related\n          \n          \n            \n            # + partition - <span class=\"x x-first x-last\">The </span>`kafka:TopicPartition` to which the record is related", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615239", "createdAt": "2020-04-15T06:45:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTQ1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of <span class=\"x x-first x-last\">cipher</span> suites. This is a named combination of authentication, encryption, MAC, and key\n          \n          \n            \n            # + sslCipherSuites - A list of <span class=\"x x-first x-last\">Cipher</span> suites. This is a named combination of<span class=\"x x-first x-last\"> the</span> authentication, encryption, MAC, and key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615451", "createdAt": "2020-04-15T06:46:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTU2OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     exchange <span class=\"x x-first x-last\">algorithm</span> used to negotiate the security settings for a network connection using TLS\n          \n          \n            \n            #                     exchange <span class=\"x x-first x-last\">algorithms</span> used to negotiate the security settings for a network connection using<span class=\"x x-first x-last\"> the</span> TLS", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615569", "createdAt": "2020-04-15T06:46:45Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTY4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network <span class=\"x x-first x-last\">protocol</span>. By default, all the available <span class=\"x x-first x-last\">cipher</span> suites are supported\n          \n          \n            \n            #                     or SSL network <span class=\"x x-first x-last\">protocols</span>. By default, all the available <span class=\"x x-first x-last\">Cipher</span> suites are supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615688", "createdAt": "2020-04-15T06:47:02Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTg0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for <span class=\"x x-first x-last\">the </span>SSL cryptography operations", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615847", "createdAt": "2020-04-15T06:47:23Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported\n+# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate the server hostname using\n+#                                        the server certificate\n+# + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTkwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>KeyStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615905", "createdAt": "2020-04-15T06:47:31Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjU1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n          \n          \n            \n                # Deserializes the provided data. Implement this to deserialize <span class=\"x x-first x-last\">a </span>`byte[]` and return any data type.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616559", "createdAt": "2020-04-15T06:48:56Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjY2Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - <span class=\"x x-first x-last\">Deserialized</span> value\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">The deserialized</span> value", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616667", "createdAt": "2020-04-15T06:49:11Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data, which should be deserialized\n+    # + return - Deserialized value", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjc2Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n          \n          \n            \n            # Configures the consumer to read the committed messages only in <span class=\"x x-first x-last\">the </span>transactional mode when poll() is called.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616767", "createdAt": "2020-04-15T06:49:26Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjg1NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer<span class=\"x x-first x-last\"> </span>related constants.\n          \n          \n            \n            // Producer<span class=\"x x-first x-last\">-</span>related constants.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616854", "createdAt": "2020-04-15T06:49:35Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjk2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Producer acknowledgement type 'all'. This will <span class=\"x x-first x-last\">gurantee</span> that the record will not be lost as long as at least one\n          \n          \n            \n            # Producer acknowledgement type <span class=\"x x-first x-last\">is </span>'all'. This will <span class=\"x x-first x-last\">guarantee</span> that the record will not be lost as long as at least one", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616963", "createdAt": "2020-04-15T06:49:50Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.\n+// Produce Ack types.\n # Producer acknowledgement type 'all'. This will gurantee that the record will not be lost as long as at least one", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzIxMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # local log <span class=\"x x-first x-last\">but </span>will respond without <span class=\"x x-first x-last\">awaiting </span>full acknowledgement from all followers.\n          \n          \n            \n            # <span class=\"x x-first x-last\">A </span>local log will respond without <span class=\"x x-first x-last\">waiting FOR </span>full acknowledgement from all<span class=\"x x-first x-last\"> the</span> followers.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617211", "createdAt": "2020-04-15T06:50:27Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -66,7 +66,7 @@ public const ACKS_NONE = \"0\";\n # local log but will respond without awaiting full acknowledgement from all followers.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzMxMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Apache <span class=\"x x-first x-last\">avro</span> serializer.\n          \n          \n            \n            # Apache <span class=\"x x-first x-last\">Avro</span> serializer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617313", "createdAt": "2020-04-15T06:50:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -85,18 +85,18 @@ public const SER_CUSTOM = \"CUSTOM\";\n # Apache avro serializer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzQ3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Consumer` object functions.\n          \n          \n            \n            # Error type specific to <span class=\"x x-first x-last\">the </span>`kafka:Consumer` object functions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617474", "createdAt": "2020-04-15T06:51:00Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzUzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Producer` object functions.\n          \n          \n            \n            # Error type specific to <span class=\"x x-first x-last\">the </span>`kafka:Producer` object functions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617533", "createdAt": "2020-04-15T06:51:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.\n public type ConsumerError error<CONSUMER_ERROR, Detail>;\n \n-# Defines a Kafka producer related error\n+# Used as the error reason for the `kafka:ProducerError` type.\n public const PRODUCER_ERROR = \"{ballerina/kafka}ProducerError\";\n \n-# Represents a Kafka producer related error\n+# Error type specific to `kafka:Producer` object functions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzgyOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should <span class=\"x x-first x-last\">be </span>implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should implement the", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617828", "createdAt": "2020-04-15T06:51:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODQ4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute metrics\n          \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute <span class=\"x x-first x-last\">the </span>metrics", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618486", "createdAt": "2020-04-15T06:53:16Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODUzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked<span class=\"x x-first x-last\">,</span> when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked when the buffer is full", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618536", "createdAt": "2020-04-15T06:53:21Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODY0MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close idle connections after <span class=\"x x-first x-last\">the</span> number of milliseconds\n          \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close <span class=\"x x-first x-last\">the </span>idle connections after <span class=\"x x-first x-last\">this</span> number of milliseconds", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618640", "createdAt": "2020-04-15T06:53:35Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics\n+# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection\n+# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTA0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else ()\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if closing the producer is failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619044", "createdAt": "2020-04-15T06:54:26Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTE2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">A</span>`kafka:ProducerError` if committing the consumer failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619163", "createdAt": "2020-04-15T06:54:44Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTIyNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer offsets in given transaction.\n          \n          \n            \n                # Commits <span class=\"x x-first x-last\">the </span>consumer offsets in<span class=\"x x-first x-last\"> a</span> given transaction.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619224", "createdAt": "2020-04-15T06:54:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTMyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offsets - Consumer offsets to commit for given transaction\n          \n          \n            \n                # + offsets - Consumer offsets to commit for <span class=\"x x-first x-last\">a </span>given transaction", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619322", "createdAt": "2020-04-15T06:55:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTM1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + groupID - Consumer group <span class=\"x x-first x-last\">id</span>\n          \n          \n            \n                # + groupID - Consumer group <span class=\"x x-first x-last\">ID</span>", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619359", "createdAt": "2020-04-15T06:55:14Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQxOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if committing consumer offsets failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619418", "createdAt": "2020-04-15T06:55:22Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQ5OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if records couldn't be flushed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619498", "createdAt": "2020-04-15T06:55:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTU1Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves topic partition information for the provided topic.\n          \n          \n            \n            # Retrieves <span class=\"x x-first x-last\">the </span>topic partition information for the provided topic.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619553", "createdAt": "2020-04-15T06:55:42Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTYxMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">to</span> which the partition information is given\n          \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">of</span> which the partition information is given", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619611", "createdAt": "2020-04-15T06:55:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTczNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:TopicPartition` array for the given topic or else <span class=\"x x-first x-last\">a </span>`kafka:ProducerError` if<span class=\"x x-first x-last\"> the</span> operation fails", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619735", "createdAt": "2020-04-15T06:56:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTg0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else ()\n          \n          \n            \n            # + return -  <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if send action fails to send data or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619846", "createdAt": "2020-04-15T06:56:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to the Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTk0Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n          \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for <span class=\"x x-first x-last\">the </span>Ballerina Kafka", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619943", "createdAt": "2020-04-15T06:56:37Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDA2NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type<span class=\"x x-first x-last\">,</span> and return the `byte[]` value to use in\n          \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type and return the `byte[]` value to use in", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620064", "createdAt": "2020-04-15T06:56:51Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDExOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Kafka producer.\n          \n          \n            \n                # <span class=\"x x-first x-last\">the </span>Kafka producer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620119", "createdAt": "2020-04-15T06:56:58Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNjg3MzE5", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-393687319", "createdAt": "2020-04-15T11:30:09Z", "commit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20fcdbea0f1975a9de332abd138583bbddbbf5d3", "author": {"user": {"login": "aashikam", "name": "Arshika Mohottige"}}, "url": "https://github.com/ballerina-platform/ballerina-lang/commit/20fcdbea0f1975a9de332abd138583bbddbbf5d3", "committedDate": "2020-04-15T13:37:55Z", "message": "Apply suggestions from code review\n\nCo-Authored-By: praneesha <praneesha@wso2.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzODgwMDM2", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#pullrequestreview-393880036", "createdAt": "2020-04-15T15:20:05Z", "commit": {"oid": "20fcdbea0f1975a9de332abd138583bbddbbf5d3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3962, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}