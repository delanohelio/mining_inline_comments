{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAxODYxMTMz", "number": 22580, "reviewThreads": {"totalCount": 133, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NTo1M1rODx73bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1OFrODx8Dqg==", "hasNextPage": false, "hasPreviousPage": true}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3NjYxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NTo1M1rOGFr5Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NTo1M1rOGFr5Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTIzOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partition - `kafka:TopicPartition` to which the record is related\n          \n          \n            \n            # + partition - The `kafka:TopicPartition` to which the record is related", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615239", "createdAt": "2020-04-15T06:45:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3Nzg5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NjoyNVrOGFr6Gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NjoyNVrOGFr6Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTQ1MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n          \n          \n            \n            # + sslCipherSuites - A list of Cipher suites. This is a named combination of the authentication, encryption, MAC, and key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615451", "createdAt": "2020-04-15T06:46:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3ODYwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0Njo0NVrOGFr6kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0Njo0NVrOGFr6kQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTU2OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n          \n          \n            \n            #                     exchange algorithms used to negotiate the security settings for a network connection using the TLS", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615569", "createdAt": "2020-04-15T06:46:45Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3OTQ0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzowMlrOGFr7CA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzowMlrOGFr7CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTY4OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network protocol. By default, all the available cipher suites are supported\n          \n          \n            \n            #                     or SSL network protocols. By default, all the available Cipher suites are supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615688", "createdAt": "2020-04-15T06:47:02Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4MDQ1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzoyM1rOGFr7pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzoyM1rOGFr7pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTg0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for the SSL cryptography operations", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615847", "createdAt": "2020-04-15T06:47:23Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported\n+# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate the server hostname using\n+#                                        the server certificate\n+# + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4MDgwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzozMVrOGFr74Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NzozMVrOGFr74Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTkwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to the KeyStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615905", "createdAt": "2020-04-15T06:47:31Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4NDg1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0ODo1NlrOGFr-bw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0ODo1NlrOGFr-bw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjU1OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n          \n          \n            \n                # Deserializes the provided data. Implement this to deserialize a `byte[]` and return any data type.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616559", "createdAt": "2020-04-15T06:48:56Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4NTYzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OToxMVrOGFr-2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OToxMVrOGFr-2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjY2Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Deserialized value\n          \n          \n            \n                # + return - The deserialized value", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616667", "createdAt": "2020-04-15T06:49:11Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data, which should be deserialized\n+    # + return - Deserialized value", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4NjE3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OToyNlrOGFr_Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OToyNlrOGFr_Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjc2Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n          \n          \n            \n            # Configures the consumer to read the committed messages only in the transactional mode when poll() is called.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616767", "createdAt": "2020-04-15T06:49:26Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4Njc1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OTozNVrOGFr_lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OTozNVrOGFr_lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjg1NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer related constants.\n          \n          \n            \n            // Producer-related constants.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616854", "createdAt": "2020-04-15T06:49:35Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4NzQ1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OTo1MFrOGFsAAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0OTo1MFrOGFsAAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjk2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Producer acknowledgement type 'all'. This will gurantee that the record will not be lost as long as at least one\n          \n          \n            \n            # Producer acknowledgement type is 'all'. This will guarantee that the record will not be lost as long as at least one", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616963", "createdAt": "2020-04-15T06:49:50Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.\n+// Produce Ack types.\n # Producer acknowledgement type 'all'. This will gurantee that the record will not be lost as long as at least one", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4OTA5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MDoyN1rOGFsA-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MDoyN1rOGFsA-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzIxMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # local log but will respond without awaiting full acknowledgement from all followers.\n          \n          \n            \n            # A local log will respond without waiting FOR full acknowledgement from all the followers.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617211", "createdAt": "2020-04-15T06:50:27Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -66,7 +66,7 @@ public const ACKS_NONE = \"0\";\n # local log but will respond without awaiting full acknowledgement from all followers.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg4OTgyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MDozOVrOGFsBYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MDozOVrOGFsBYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzMxMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Apache avro serializer.\n          \n          \n            \n            # Apache Avro serializer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617313", "createdAt": "2020-04-15T06:50:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -85,18 +85,18 @@ public const SER_CUSTOM = \"CUSTOM\";\n # Apache avro serializer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5MDkwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTowMFrOGFsCAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTowMFrOGFsCAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzQ3NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Consumer` object functions.\n          \n          \n            \n            # Error type specific to the `kafka:Consumer` object functions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617474", "createdAt": "2020-04-15T06:51:00Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5MTMxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTowOFrOGFsCPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTowOFrOGFsCPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzUzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Producer` object functions.\n          \n          \n            \n            # Error type specific to the `kafka:Producer` object functions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617533", "createdAt": "2020-04-15T06:51:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.\n public type ConsumerError error<CONSUMER_ERROR, Detail>;\n \n-# Defines a Kafka producer related error\n+# Used as the error reason for the `kafka:ProducerError` type.\n public const PRODUCER_ERROR = \"{ballerina/kafka}ProducerError\";\n \n-# Represents a Kafka producer related error\n+# Error type specific to `kafka:Producer` object functions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5MzA5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTo1M1rOGFsDZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MTo1M1rOGFsDZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzgyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should implement the", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617828", "createdAt": "2020-04-15T06:51:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5NzM0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzoxNlrOGFsF9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzoxNlrOGFsF9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODQ4Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute metrics\n          \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute the metrics", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618486", "createdAt": "2020-04-15T06:53:16Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5NzYzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzoyMVrOGFsGKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzoyMVrOGFsGKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODUzNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked when the buffer is full", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618536", "createdAt": "2020-04-15T06:53:21Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg5ODI0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzozNVrOGFsGkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1MzozNVrOGFsGkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODY0MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds\n          \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close the idle connections after this number of milliseconds", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618640", "createdAt": "2020-04-15T06:53:35Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics\n+# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection\n+# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMDgzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDoyNlrOGFsIJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDoyNlrOGFsIJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTA0NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else ()\n          \n          \n            \n            # + return - A `kafka:ProducerError` if closing the producer is failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619044", "createdAt": "2020-04-15T06:54:26Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMTczOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDo0NFrOGFsImw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDo0NFrOGFsImw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTE2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n          \n          \n            \n                # + return - A`kafka:ProducerError` if committing the consumer failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619163", "createdAt": "2020-04-15T06:54:44Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMjE1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDo1M1rOGFsI2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NDo1M1rOGFsI2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTIyNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer offsets in given transaction.\n          \n          \n            \n                # Commits the consumer offsets in a given transaction.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619224", "createdAt": "2020-04-15T06:54:53Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMjc3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTowOFrOGFsJOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTowOFrOGFsJOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTMyMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offsets - Consumer offsets to commit for given transaction\n          \n          \n            \n                # + offsets - Consumer offsets to commit for a given transaction", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619322", "createdAt": "2020-04-15T06:55:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 165}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMjk5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NToxNFrOGFsJXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NToxNFrOGFsJXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTM1OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + groupID - Consumer group id\n          \n          \n            \n                # + groupID - Consumer group ID", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619359", "createdAt": "2020-04-15T06:55:14Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMzM0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NToyMlrOGFsJmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NToyMlrOGFsJmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQxOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n          \n          \n            \n                # + return - A `kafka:ProducerError` if committing consumer offsets failed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619418", "createdAt": "2020-04-15T06:55:22Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwMzkxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTozM1rOGFsJ6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTozM1rOGFsJ6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQ5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n          \n          \n            \n            # + return - A `kafka:ProducerError` if records couldn't be flushed or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619498", "createdAt": "2020-04-15T06:55:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNDIzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTo0MlrOGFsKIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTo0MlrOGFsKIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTU1Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves topic partition information for the provided topic.\n          \n          \n            \n            # Retrieves the topic partition information for the provided topic.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619553", "createdAt": "2020-04-15T06:55:42Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNDYzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTo1MlrOGFsKWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NTo1MlrOGFsKWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTYxMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic to which the partition information is given\n          \n          \n            \n            # + topic - Topic of which the partition information is given", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619611", "createdAt": "2020-04-15T06:55:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 194}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNTUwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjowN1rOGFsK1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjowN1rOGFsK1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTczNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - A `kafka:TopicPartition` array for the given topic or else a `kafka:ProducerError` if the operation fails", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619735", "createdAt": "2020-04-15T06:56:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 195}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNjA4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjoyNVrOGFsLRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjoyNVrOGFsLRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTg0Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else ()\n          \n          \n            \n            # + return -  A `kafka:ProducerError` if send action fails to send data or else ()", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619846", "createdAt": "2020-04-15T06:56:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to the Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else ()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 218}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNjY5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjozN1rOGFsLpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1NjozN1rOGFsLpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTk0Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n          \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for the Ballerina Kafka", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619943", "createdAt": "2020-04-15T06:56:37Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNzUxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1MVrOGFsMIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1MVrOGFsMIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDA2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n          \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type and return the `byte[]` value to use in", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620064", "createdAt": "2020-04-15T06:56:51Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjkwNzk0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1OFrOGFsMVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo1Njo1OFrOGFsMVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDExOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Kafka producer.\n          \n          \n            \n                # the Kafka producer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620119", "createdAt": "2020-04-15T06:56:58Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM4ODE5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTowNFrOGD6RTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMzo1NDo0N1rOGE9RVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzYxMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while starting the server or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753612", "createdAt": "2020-04-10T13:19:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MTM1MQ==", "bodyText": "Fixed in all places.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407851351", "createdAt": "2020-04-14T03:54:47Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzYxMg=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM4OTUyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTozN1rOGD6SFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTozN1rOGD6SFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzgxMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753812", "createdAt": "2020-04-10T13:19:37Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 160}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5MDI3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTo1N1rOGD6SiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoxOTo1N1rOGD6SiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzkyOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753929", "createdAt": "2020-04-10T13:19:57Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5MTk5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMDozOVrOGD6TlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMDozOVrOGD6TlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDE5Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while attaching the service or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754196", "createdAt": "2020-04-10T13:20:39Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5MjkzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMTowM1rOGD6UIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMTowM1rOGD6UIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDMzOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while detaching a service or nil\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while detaching a service or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754339", "createdAt": "2020-04-10T13:21:03Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n     public function __attach(service s, string? name = ()) returns error? {\n         return register(self, s, name);\n     }\n \n     # Detaches a consumer service from the listener.\n     #\n     # + s - The service to be detached\n-    # + return - An `error` if an error occurred during detaching a service or `nil`\n+    # + return - An `error` if an error is encountered while detaching a service or nil", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 190}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5MzcyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMToyNFrOGD6UpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMToyNFrOGD6UpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDQ2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754468", "createdAt": "2020-04-10T13:21:24Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5NDcwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMTo0N1rOGD6VNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMzo1ODoyM1rOGE9VFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDYxNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754614", "createdAt": "2020-04-10T13:21:47Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MjMxMA==", "bodyText": "Fixed in all places", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407852310", "createdAt": "2020-04-14T03:58:23Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDYxNA=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5ODYxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzozMlrOGD6XhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzozMlrOGD6XhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTIwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755204", "createdAt": "2020-04-10T13:23:32Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function close(public int duration = -1) returns ConsumerError? {\n         return consumerClose(self, duration);\n     }\n \n-    # Commits current consumed offsets for consumer.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Commits current consumed offsets for consumer.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->commit();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5OTI3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzo0NFrOGD6X4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzo0NFrOGD6X4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTI5OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755299", "createdAt": "2020-04-10T13:23:44Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDM5OTYzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzo1M1rOGD6YIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyMzo1M1rOGD6YIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTM2MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755361", "createdAt": "2020-04-10T13:23:53Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 251}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwMDc0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNDoxN1rOGD6Yyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNDoxN1rOGD6Yyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTUzMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n          \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully  or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755530", "createdAt": "2020-04-10T13:24:17Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwMzQwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNToyNVrOGD6aVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowMDowN1rOGE9W1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTkyNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #            `kafka:ConsumerError` if the operation fails\n          \n          \n            \n            #            `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755926", "createdAt": "2020-04-10T13:25:25Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 339}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1Mjc1OQ==", "bodyText": "Fixed in all places", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407852759", "createdAt": "2020-04-14T04:00:07Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTkyNg=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 339}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNDEzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNTo0MlrOGD6azQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNTo0MlrOGD6azQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA0NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756045", "createdAt": "2020-04-10T13:25:42Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 324}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNDM5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNTo1MVrOGD6a_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNTo1MVrOGD6a_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA5Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError` if the operation fails\n          \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756092", "createdAt": "2020-04-10T13:25:51Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 309}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNDkzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjowN1rOGD6bUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjowN1rOGD6bUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjE3OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756179", "createdAt": "2020-04-10T13:26:07Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 294}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNTI3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjoxOFrOGD6bkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjoxOFrOGD6bkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjI0MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError` if the operation fails\n          \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756241", "createdAt": "2020-04-10T13:26:18Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 280}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNTkyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjozNVrOGD6b7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjozNVrOGD6b7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjMzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n          \n          \n            \n                #            the operation fails\n          \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756333", "createdAt": "2020-04-10T13:26:35Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 353}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNjQ3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjo0N1rOGD6cQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjo0N1rOGD6cQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjQxOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n          \n          \n            \n            #            the operation fails\n          \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756419", "createdAt": "2020-04-10T13:26:47Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 368}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQwNzAxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjo1OFrOGD6clQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzoyNjo1OFrOGD6clQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjUwMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756501", "createdAt": "2020-04-10T13:26:58Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 386}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDQyOTA0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzozNDo0OVrOGD6pVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxMzozNDo0OVrOGD6pVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1OTc2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406759764", "createdAt": "2020-04-10T13:34:49Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 386}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUxNzY0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODowM1rOGD7enQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODowM1rOGD7enQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzQwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773405", "createdAt": "2020-04-10T14:08:03Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 398}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUxODMzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODoxOVrOGD7fBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODoxOVrOGD7fBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzUwOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n          \n          \n            \n            #            fails\n          \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773509", "createdAt": "2020-04-10T14:08:19Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 414}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyMDEwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODo1M1rOGD7gDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowODo1M1rOGD7gDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3Mzc3NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773775", "createdAt": "2020-04-10T14:08:53Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 425}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyMDQzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowOTowMlrOGD7gQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowOTowMlrOGD7gQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzgyNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773826", "createdAt": "2020-04-10T14:09:02Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 436}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyMTg0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowOTozN1rOGD7hKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDowOTozN1rOGD7hKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDA1OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offset - The `PartitionOffset` to seek\n          \n          \n            \n                # + offset - The `kafka:PartitionOffset` to seek", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774058", "createdAt": "2020-04-10T14:09:37Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 435}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNDE4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDoxOVrOGD7iag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDoxOVrOGD7iag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDM3OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774378", "createdAt": "2020-04-10T14:10:19Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 447}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNDQ4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDoyOFrOGD7iow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDoyOFrOGD7iow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDQzNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774435", "createdAt": "2020-04-10T14:10:28Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 458}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNTA3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDo0MlrOGD7i-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMDo0MlrOGD7i-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDUyMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774522", "createdAt": "2020-04-10T14:10:42Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 473}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNTc4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTowMFrOGD7jdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTowMFrOGD7jdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDY0Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774646", "createdAt": "2020-04-10T14:11:00Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 488}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNzMyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTozM1rOGD7kYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTozM1rOGD7kYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDg4MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774880", "createdAt": "2020-04-10T14:11:33Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 505}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUyNzcyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTo0M1rOGD7kpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxMTo0M1rOGD7kpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDk0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774948", "createdAt": "2020-04-10T14:11:43Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeWithPartitionRebalance(string[] topics,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsRevoked,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsAssigned)\n     returns ConsumerError? {\n         return consumerSubscribeWithPartitionRebalance(self, topics, onPartitionsRevoked, onPartitionsAssigned);\n     }\n \n-    # Unsubscribe the consumer from all the topic subscriptions.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Unsubscribes from all the topic subscriptions.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->unsubscribe();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 521}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUzNDQzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNDowN1rOGD7oyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNDoxOFrOGE9a2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjAxMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer consumed offsets to offset topic.\n          \n          \n            \n                # Commits the offsets consumed by the provided consumer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776010", "createdAt": "2020-04-10T14:14:07Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1Mzc4Ng==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407853786", "createdAt": "2020-04-14T04:04:18Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjAxMA=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUzNDk2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNDoyMVrOGD7pJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNTowMlrOGE9baQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjEwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776102", "createdAt": "2020-04-10T14:14:21Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MzkyOQ==", "bodyText": "Fixed in all places", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407853929", "createdAt": "2020-04-14T04:05:02Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjEwMg=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUzNzcwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNToyMlrOGD7qww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNToyMlrOGD7qww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjUxNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776515", "createdAt": "2020-04-10T14:15:22Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 165}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDUzOTU2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNjowNFrOGD7r8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNTo0MlrOGE9b5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjgxOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Flushes batch of records.\n          \n          \n            \n            # Flushes the batch of records already sent to the broker by the producer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776818", "createdAt": "2020-04-10T14:16:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDA1Mg==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854052", "createdAt": "2020-04-14T04:05:42Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjgxOA=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDU0MDEzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNjoxN1rOGD7sTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNjoxN1rOGD7sTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjkxMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776910", "createdAt": "2020-04-10T14:16:17Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDU0MTkxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDoxNzowNFrOGD7tcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNjoxNVrOGE9cUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NzIwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves given topic partition information.\n          \n          \n            \n            # Retrieves topic partition information for the provided topic.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406777202", "createdAt": "2020-04-10T14:17:04Z", "author": {"login": "ThisaruGuruge"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDE2Mw==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854163", "createdAt": "2020-04-14T04:06:15Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NzIwMg=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwNTk5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozODo1MlrOGD8Tow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNjo1OFrOGE9c6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Njk3OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             To do so, download the necessary dependencies and put them inside the `resources\n          \n          \n            \n             To do so, download the necessary dependencies and add them inside the `resources", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406786979", "createdAt": "2020-04-10T14:38:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -89,10 +21,9 @@ cd kafka_avro_sample\n ballerina add producer\n ballerina add consumer\n ```\n-\n- #### Dependencies\n+ ##### Dependencies\n  To use Avro, you need to add the necessary dependencies to the Ballerina project you created. \n-To do so, download the necessary dependencies and put them inside the `resources\n+ To do so, download the necessary dependencies and put them inside the `resources", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDMxNA==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854314", "createdAt": "2020-04-14T04:06:58Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -89,10 +21,9 @@ cd kafka_avro_sample\n ballerina add producer\n ballerina add consumer\n ```\n-\n- #### Dependencies\n+ ##### Dependencies\n  To use Avro, you need to add the necessary dependencies to the Ballerina project you created. \n-To do so, download the necessary dependencies and put them inside the `resources\n+ To do so, download the necessary dependencies and put them inside the `resources", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Njk3OQ=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwNjgxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTowOFrOGD8UHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowNzozNFrOGE9daQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzEwMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like follows. (Some of the files are ignored)\n          \n          \n            \n            Now, the directory structure will look like follows (some of the files are ignored).", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787100", "createdAt": "2020-04-10T14:39:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +85,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows. (Some of the files are ignored)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDQ0MQ==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854441", "createdAt": "2020-04-14T04:07:34Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +85,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows. (Some of the files are ignored)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzEwMA=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwNzUwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOToyNFrOGD8UiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowODoxMFrOGE9d9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzIwOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents topic partition position in which consumed record is stored.\n          \n          \n            \n            # Represents the topic partition position in which the consumed record is stored.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787209", "createdAt": "2020-04-10T14:39:24Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDU4Mw==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854583", "createdAt": "2020-04-14T04:08:10Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzIwOQ=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwNzkyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTozNFrOGD8Uzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDowODo1NFrOGE9epg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzI3OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + offset - Offset in which record is stored in partition\n          \n          \n            \n            # + offset - Offset in which the record is stored in the partition", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787278", "createdAt": "2020-04-10T14:39:34Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDc1OA==", "bodyText": "Fixed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854758", "createdAt": "2020-04-14T04:08:54Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzI3OA=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwODc3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTo1MVrOGD8VVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTo1MVrOGD8VVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQxMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStore - Configurations associated with KeyStore\n          \n          \n            \n            # + keyStore - Configurations associated with the KeyStore", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787412", "createdAt": "2020-04-10T14:39:51Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwOTAwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTo1N1rOGD8Veg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDozOTo1N1rOGD8Veg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQ1MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStore - Configurations associated with TrustStore\n          \n          \n            \n            # + trustStore - Configurations associated with the TrustStore", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787450", "createdAt": "2020-04-10T14:39:57Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYwOTMxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MDowNlrOGD8VsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MDowNlrOGD8VsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzUwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + protocol - Configurations related to SSL/TLS protocol and version to be used\n          \n          \n            \n            # + protocol - Configurations related to the SSL/TLS protocol and the version to be used", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787504", "createdAt": "2020-04-10T14:40:06Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxMTEzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MDozOFrOGD8Wyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MDozOFrOGD8Wyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzc4Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n          \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for the client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787786", "createdAt": "2020-04-10T14:40:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxMjE3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MTowM1rOGD8XbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MTowM1rOGD8XbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzk0OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n          \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787949", "createdAt": "2020-04-10T14:41:03Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNDUxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjowMFrOGD8Y7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjowMFrOGD8Y7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODMzNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network protocol. By default all the available cipher suites are supported\n          \n          \n            \n            #                     or SSL network protocol. By default, all the available cipher suites are supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788335", "createdAt": "2020-04-10T14:42:00Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNTU0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjoyNFrOGD8Zkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjoyNFrOGD8Zkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODQ5OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n          \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate the server hostname using the server", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788499", "createdAt": "2020-04-10T14:42:24Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNjE1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjozOVrOGD8aBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MjozOVrOGD8aBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODYxMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788613", "createdAt": "2020-04-10T14:42:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                                        certificate\n+# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNjM2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mjo0N1rOGD8aOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mjo0N1rOGD8aOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODY2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to the KeyStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788664", "createdAt": "2020-04-10T14:42:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNzYwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzoxNVrOGD8bCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzoxNVrOGD8bCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODg3NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStoreType - The file format of KeyStore file. This is optional for client\n          \n          \n            \n            # + keyStoreType - The file format of the KeyStore file. This is optional for the client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788874", "createdAt": "2020-04-10T14:43:15Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxNzk3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzoyNVrOGD8bTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzoyNVrOGD8bTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODk0MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n          \n          \n            \n            # + location - The location of the KeyStore file. This is optional for the client and can be used for two-way", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788941", "createdAt": "2020-04-10T14:43:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxODUyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzozM1rOGD8bmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0MzozM1rOGD8bmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTAxOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              authentication for client\n          \n          \n            \n            #              authentication for the client", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789019", "createdAt": "2020-04-10T14:43:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxOTA5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mzo0NFrOGD8b9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mzo0NFrOGD8b9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTExMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for client and only needed if\n          \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for the client and is only needed if", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789111", "createdAt": "2020-04-10T14:43:44Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYxOTY2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mzo1NVrOGD8cTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0Mzo1NVrOGD8cTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTE5Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              ssl.keystore.location is configured\n          \n          \n            \n            #              the `ssl.keystore.location` is configured", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789197", "createdAt": "2020-04-10T14:43:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMDU1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDowOVrOGD8cxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDowOVrOGD8cxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTMxNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n          \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by the key manager factory for SSL connections. The default value is the key", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789316", "createdAt": "2020-04-10T14:44:09Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMDgxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDoxN1rOGD8c8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDoxN1rOGD8c8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTM2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                         manager factory algorithm configured for the JVM\n          \n          \n            \n            #                         manager factory algorithm configured for the JVM", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789363", "createdAt": "2020-04-10T14:44:17Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMTEzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDoyNVrOGD8dJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDoyNVrOGD8dJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTQxNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to TrustStore.\n          \n          \n            \n            # Configurations related to the TrustStore.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789414", "createdAt": "2020-04-10T14:44:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMTk0OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDo0M1rOGD8doA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDo0M1rOGD8doA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTUzNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n      \n    \n    \n  \n\nAdd fullstops for all descriptions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789536", "createdAt": "2020-04-10T14:44:43Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMjUzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDo1NFrOGD8d9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NDo1NFrOGD8d9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTYyMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n          \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set, access to the TrustStore is still", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789620", "createdAt": "2020-04-10T14:44:54Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMjkwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTowM1rOGD8eNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTowM1rOGD8eNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTY4Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              available, but integrity checking is disabled\n          \n          \n            \n            #              available but integrity checking is disabled", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789686", "createdAt": "2020-04-10T14:45:03Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyMzU3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NToxOVrOGD8eqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NToxOVrOGD8eqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTgwMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n          \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by the trust manager factory for SSL connections. The default value is the trust", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789800", "createdAt": "2020-04-10T14:45:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyNDE2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTozM1rOGD8fBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTozM1rOGD8fBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTg5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to SSL/TLS protocol and the versions to be used.\n          \n          \n            \n            # Configurations related to the SSL/TLS protocol and the versions to be used.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789895", "createdAt": "2020-04-10T14:45:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyNDcwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTo0N1rOGD8fZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NTo0N1rOGD8fZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTk4OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n          \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. The default setting is TLS, which is fine for most", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789989", "createdAt": "2020-04-10T14:45:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyNjE1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NjoyNVrOGD8gVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NjoyNVrOGD8gVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDIyOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n          \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1, and TLSv1.2. Also, SSL, SSLv2, and SSLv3 may be supported", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790229", "createdAt": "2020-04-10T14:46:25Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDYyNjQ1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NjozM1rOGD8gjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNDo0NjozM1rOGD8gjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDI4Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 in older JVMs, but their usage is discouraged due to known security vulnerabilities\n          \n          \n            \n            #                 in older JVMs but their usage is discouraged due to known security vulnerabilities", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790287", "createdAt": "2020-04-10T14:46:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n+#                 in older JVMs, but their usage is discouraged due to known security vulnerabilities", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDcxMTE1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNTo1MlrOGD9Tjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNTo1MlrOGD9Tjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzM0Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be deserialized\n          \n          \n            \n                # + data - Data, which should be deserialized", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803342", "createdAt": "2020-04-10T15:15:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data which should be deserialized", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDcxMTgxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNjowMlrOGD9T6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNjowMlrOGD9T6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzQzMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Isolation levels\n          \n          \n            \n            // Isolation levels.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803433", "createdAt": "2020-04-10T15:16:02Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDcxMjU1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNjoxN1rOGD9UWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToxNjoxN1rOGD9UWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzU0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read all the messages, even the aborted ones.\n          \n          \n            \n            # Configures the consumer to read all the messages even the aborted ones.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803547", "createdAt": "2020-04-10T15:16:17Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczMTI3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMjo1MlrOGD9fuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMjo1MlrOGD9fuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjQ1Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer related constants\n          \n          \n            \n            // Producer related constants.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806457", "createdAt": "2020-04-10T15:22:52Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n // Producer related constants", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczMTY5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMjo1OFrOGD9f8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMjo1OFrOGD9f8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjUxNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Compression types\n          \n          \n            \n            // Compression types.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806514", "createdAt": "2020-04-10T15:22:58Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -86,17 +86,17 @@ public const SER_CUSTOM = \"CUSTOM\";\n public const SER_AVRO = \"AVRO\";\n \n // Compression types", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczMzA5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMzoyOVrOGD9gyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMzoyOVrOGD9gyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjcyOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents Kafka Producer configuration.\n          \n          \n            \n            # Represents the Kafka Producer configuration.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806728", "createdAt": "2020-04-10T15:23:29Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczNDExOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMzo0NlrOGD9hXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyMzo0NlrOGD9hXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjg3OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n          \n          \n            \n            # + partitionerClass - Partitioner class to be used to select the partition to which the message is sent", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806879", "createdAt": "2020-04-10T15:23:46Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczNTkwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNDoxOVrOGD9idg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNDoxOVrOGD9idg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzE1OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n          \n          \n            \n            # + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807158", "createdAt": "2020-04-10T15:24:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczNjQ5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNDozNFrOGD9izA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNDozNFrOGD9izA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzI0NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should implement the", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807244", "createdAt": "2020-04-10T15:24:34Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDczODIwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNTowOVrOGD9jzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNTowOVrOGD9jzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzUwMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n          \n          \n            \n            # + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro serializer", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807500", "createdAt": "2020-04-10T15:25:09Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0MDMxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNTo1NVrOGD9lFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNTo1NVrOGD9lFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzgzMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked when the buffer is full", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807831", "createdAt": "2020-04-10T15:25:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0MDc5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNjowN1rOGD9lZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNjowN1rOGD9lZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzkxMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + requestTimeoutInMillis - Wait time for response of a request\n          \n          \n            \n            # + requestTimeoutInMillis - Wait time for the response of a request", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807910", "createdAt": "2020-04-10T15:26:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0MjQ4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNjo0N1rOGD9mcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNjo0N1rOGD9mcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODE3Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to computed over\n          \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to compute over", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808177", "createdAt": "2020-04-10T15:26:47Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0NDg5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNzozNlrOGD9n7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNzozNlrOGD9n7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODU1Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaString - The string which defines the Avro schema\n          \n          \n            \n            # + schemaString - The string, which defines the Avro schema", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808556", "createdAt": "2020-04-10T15:27:36Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0NTI3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNzo0NVrOGD9oIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyNzo0NVrOGD9oIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODYxMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + dataRecord - Records which should be serialized using Avro\n          \n          \n            \n            # + dataRecord - Records, which should be serialized using Avro", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808611", "createdAt": "2020-04-10T15:27:45Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema\n+# + dataRecord - Records which should be serialized using Avro", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0NjQwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyODoxMVrOGD9o4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyODoxMVrOGD9o4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODgwMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Closes producer connection to the external Kafka broker.\n          \n          \n            \n            # Closes the producer connection to the external Kafka broker.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808802", "createdAt": "2020-04-10T15:28:11Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0Nzk4OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyODo0MlrOGD9p1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyODo0MlrOGD9p1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTA0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer consumed offsets to offset topic.\n          \n          \n            \n                # Commits consumer consumed offsets to the offset topic.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809047", "createdAt": "2020-04-10T15:28:42Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc0OTQ5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyOToxMlrOGD9qtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNToyOToxMlrOGD9qtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTI2OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + consumer - Consumer which needs offsets to be committed\n          \n          \n            \n                # + consumer - Consumer, which needs offsets to be committed", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809268", "createdAt": "2020-04-10T15:29:12Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1MjcyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDoxOFrOGD9spg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDoxOFrOGD9spg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTc2Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic which the partition information is given\n          \n          \n            \n            # + topic - Topic to which the partition information is given", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809766", "createdAt": "2020-04-10T15:30:18Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 192}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1MzI2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDoyOVrOGD9s9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDoyOVrOGD9s9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTg0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if the operation fails", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809847", "createdAt": "2020-04-10T15:30:29Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1MzYzOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDozOFrOGD9tMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDozOFrOGD9tMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTkwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Produces records to Kafka server.\n          \n          \n            \n            # Produces records to the Kafka server.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809905", "createdAt": "2020-04-10T15:30:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1Mzk5OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDo0NlrOGD9tdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDo0NlrOGD9tdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTk3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic to which the record will be appended to\n          \n          \n            \n            # + topic - Topic to which the record will be appended", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809972", "createdAt": "2020-04-10T15:30:46Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 212}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1NDcwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDo1NVrOGD9t1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMDo1NVrOGD9t1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDA3MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + timestamp - Timestamp of the record, in milliseconds since epoch\n          \n          \n            \n            # + timestamp - Timestamp of the record in milliseconds since epoch", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810070", "createdAt": "2020-04-10T15:30:55Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 215}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1NTA1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMTowN1rOGD9uFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMTowN1rOGD9uFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDEzNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil otherwise\n          \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810135", "createdAt": "2020-04-10T15:31:07Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1NTY2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMToyMlrOGD9ufw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMToyMlrOGD9ufw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDIzOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be serialized\n          \n          \n            \n                # + data - Data, which should be serialized", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810239", "createdAt": "2020-04-10T15:31:22Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.\n     #\n-    # + data - Data which should be serialized.\n-    # + return - Serialized `byte[]` value.\n+    # + data - Data which should be serialized", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNDc1ODY2OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQxNTozMjozM1rOGD9wXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwNDozNDozN1rOGE94ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDcxNw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n      \n    \n    \n  \n\nPlease replace all occurrences of \"nil\" with \"()\".", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810717", "createdAt": "2020-04-10T15:32:33Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg2MTM4Ng==", "bodyText": "Fixed in all places", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407861386", "createdAt": "2020-04-14T04:34:37Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDcxNw=="}, "originalCommit": {"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjk5Mzk3OnYy", "diffSide": "LEFT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwOTo0MToxNVrOGFGkEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNDowNToyMlrOGFpBEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAwMzYwMQ==", "bodyText": "Shall we make the module.md structure similar to the other messaging modules. Add code snippets to the usages.\n\nhttps://github.com/daneshk/ballerina/blob/nats-docs-updates/stdlib/messaging/nats/src/main/ballerina/src/nats/Module.md\nhttps://github.com/daneshk/ballerina/blob/rabbitmq-docs-updates/stdlib/messaging/rabbitmq/src/main/ballerina/src/rabbitmq/Module.md", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408003601", "createdAt": "2020-04-14T09:41:15Z", "author": {"login": "daneshk"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,15 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU2ODA4Mw==", "bodyText": "Fixed in d473036", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408568083", "createdAt": "2020-04-15T04:05:22Z", "author": {"login": "aashikam"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,15 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAwMzYwMQ=="}, "originalCommit": {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg2OTk1OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0MzozOFrOGFr1kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0MzozOFrOGFr1kQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDI4OQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This module supports kafka 1.x.x and 2.0.0 versions.\n          \n          \n            \n            This module supports Kafka 1.x.x and 2.0.0 versions.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614289", "createdAt": "2020-04-15T06:43:38Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3MTEwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0Mzo1NlrOGFr2KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0Mzo1NlrOGFr2KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDQ0MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Producer` to publish messages. \n          \n          \n            \n            2. Use the `kafka:Producer` to publish messages.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614441", "createdAt": "2020-04-15T06:43:56Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3MTgxOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDowOFrOGFr2jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDowOFrOGFr2jg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU0Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Consumer` as a simple record consumer.\n          \n          \n            \n            2. Use the `kafka:Consumer` as a simple record consumer.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614542", "createdAt": "2020-04-15T06:44:08Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3MjAwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDoxNFrOGFr2rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDoxNFrOGFr2rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU3NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            3. Use `kafka:Consumer` as a listener.\n          \n          \n            \n            3. Use the `kafka:Consumer` as a listener.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614575", "createdAt": "2020-04-15T06:44:14Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3MjYwOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDozMFrOGFr3Bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NDozMFrOGFr3Bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDY2Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To try this, let's create a new Ballerina project and two modules inside it.\n          \n          \n            \n            To try this, create a new Ballerina project and two modules inside it.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614662", "createdAt": "2020-04-15T06:44:30Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.\n+```ballerina\n+listener kafka:Consumer consumer = new (consumerConfiguration);\n \n-function main () {\n-    string msg = \"Hello World, Ballerina\";\n-    byte[] serializedMsg = msg.toByteArray(\"UTF-8\");\n-    var sendResult = kafkaProducer->send(serializedMsg, \"test-kafka-topic\");\n-    if (sendResult is error) {\n-        log:printError(\"Kafka producer failed to send data\", err = sendResult);\n+service kafkaService on consumer {\n+    // This resource will be executed when a message is published to the\n+    // subscribed topic/topics.\n+    resource function onMessage(kafka:Consumer kafkaConsumer,\n+            kafka:ConsumerRecord[] records) {\n     }\n }\n ```\n \n-### Send Data Using Avro\n+#### Send Data Using Avro\n The Ballerina Kafka module supports Avro serialization and deserialization.\n \n To try this, let's create a new Ballerina project and two modules inside it.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3NDkyOnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NToxOVrOGFr4Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NToxOVrOGFr4Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDk5NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like follows (some of the files are ignored).\n          \n          \n            \n            Now, the directory structure will look like below (some of the files are ignored).", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614995", "createdAt": "2020-04-15T06:45:19Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +138,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows (some of the files are ignored).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNjg3NjA3OnYy", "diffSide": "RIGHT", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NTozOVrOGFr49g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjo0NTozOVrOGFr49g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTE1OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.\n          \n          \n            \n            The Consumer will return a `kafka:AvroGenericRecord` with the data received from Avro.", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615158", "createdAt": "2020-04-15T06:45:39Z", "author": {"login": "praneesha"}, "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -225,7 +209,7 @@ public function main() {\n }\n ```\n \n-#### Avro Consumer\n+##### Avro Consumer\n The Kafka implementation of Ballerina currently supports Avro deserialization only for generic records.\n The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506"}, "originalPosition": 168}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4281, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}