{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgzODgyMzE3", "number": 10517, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNDozODozMFrOEiJqyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNDozODozMFrOEiJqyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0MjQ1NDQ4OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNDozODozMFrOHP3VKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNDozODozMFrOHP3VKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjM5NzIyNQ==", "bodyText": "lgtm\n@Test annotations are missing on few test cases.", "url": "https://github.com/crate/crate/pull/10517#discussion_r486397225", "createdAt": "2020-09-10T14:38:30Z", "author": {"login": "kovrus"}, "path": "server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java", "diffHunk": "@@ -0,0 +1,3283 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.translog;\n+\n+import static org.elasticsearch.common.util.BigArrays.NON_RECYCLING_INSTANCE;\n+import static org.elasticsearch.index.translog.SnapshotMatchers.containsOperationsInAnyOrder;\n+import static org.elasticsearch.index.translog.TranslogDeletionPolicies.createTranslogDeletionPolicy;\n+import static org.hamcrest.CoreMatchers.hasItem;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.empty;\n+import static org.hamcrest.Matchers.endsWith;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.hasToString;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.isIn;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.nullValue;\n+\n+import java.io.Closeable;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.CopyOption;\n+import java.nio.file.FileAlreadyExistsException;\n+import java.nio.file.Files;\n+import java.nio.file.InvalidPathException;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.BrokenBarrierException;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.Phaser;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.LongConsumer;\n+import java.util.function.LongSupplier;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import java.util.stream.LongStream;\n+import java.util.stream.Stream;\n+\n+import com.carrotsearch.randomizedtesting.generators.RandomPicks;\n+\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.lucene.codecs.CodecUtil;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.NumericDocValuesField;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.IndexFormatTooOldException;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.mockfile.FilterFileChannel;\n+import org.apache.lucene.mockfile.FilterFileSystemProvider;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.store.ByteArrayDataOutput;\n+import org.apache.lucene.store.MockDirectoryWrapper;\n+import org.apache.lucene.util.LineFileDocs;\n+import org.apache.lucene.util.LuceneTestCase;\n+import org.elasticsearch.Assertions;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.Randomness;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.io.FileSystemUtils;\n+import org.elasticsearch.common.io.stream.BytesStreamOutput;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.ConcurrentCollections;\n+import org.elasticsearch.common.util.concurrent.ReleasableLock;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.VersionType;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.engine.Engine.Operation.Origin;\n+import org.elasticsearch.index.mapper.IdFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext.Document;\n+import org.elasticsearch.index.mapper.ParsedDocument;\n+import org.elasticsearch.index.mapper.SeqNoFieldMapper;\n+import org.elasticsearch.index.mapper.Uid;\n+import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n+import org.elasticsearch.index.seqno.LocalCheckpointTrackerTests;\n+import org.elasticsearch.index.seqno.SequenceNumbers;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.translog.Translog.Location;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.test.IndexSettingsModule;\n+import org.elasticsearch.test.VersionUtils;\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import io.crate.common.collections.Tuple;\n+import io.crate.common.io.IOUtils;\n+\n+@LuceneTestCase.SuppressFileSystems(\"ExtrasFS\")\n+public class TranslogTests extends ESTestCase {\n+\n+    protected final ShardId shardId = new ShardId(\"index\", \"_na_\", 1);\n+\n+    protected Translog translog;\n+    private AtomicLong globalCheckpoint;\n+    protected Path translogDir;\n+    // A default primary term is used by translog instances created in this test.\n+    private final AtomicLong primaryTerm = new AtomicLong();\n+    private final AtomicReference<LongConsumer> persistedSeqNoConsumer = new AtomicReference<>();\n+    private boolean expectIntactTranslog;\n+\n+    @Before\n+    public void expectIntactTranslogByDefault() {\n+        expectIntactTranslog = true;\n+    }\n+\n+    @Override\n+    protected void afterIfSuccessful() throws Exception {\n+        super.afterIfSuccessful();\n+\n+        if (translog.isOpen()) {\n+            if (translog.currentFileGeneration() > 1) {\n+                markCurrentGenAsCommitted(translog);\n+                translog.trimUnreferencedReaders();\n+                assertFileDeleted(translog, translog.currentFileGeneration() - 1);\n+            }\n+            translog.close();\n+        }\n+        if (expectIntactTranslog) {\n+            assertFileIsPresent(translog, translog.currentFileGeneration());\n+        }\n+        IOUtils.rm(translog.location()); // delete all the locations\n+\n+    }\n+\n+    private LongConsumer getPersistedSeqNoConsumer() {\n+        return seqNo -> {\n+            final LongConsumer consumer = persistedSeqNoConsumer.get();\n+            if (consumer != null) {\n+                consumer.accept(seqNo);\n+            }\n+        };\n+    }\n+\n+    protected Translog createTranslog(TranslogConfig config) throws IOException {\n+        String translogUUID =\n+            Translog.createEmptyTranslog(config.getTranslogPath(), SequenceNumbers.NO_OPS_PERFORMED, shardId, primaryTerm.get());\n+        return new Translog(config, translogUUID, createTranslogDeletionPolicy(config.getIndexSettings()),\n+            () -> SequenceNumbers.NO_OPS_PERFORMED, primaryTerm::get, getPersistedSeqNoConsumer());\n+    }\n+\n+    protected Translog openTranslog(TranslogConfig config, String translogUUID) throws IOException {\n+        return new Translog(config, translogUUID, createTranslogDeletionPolicy(config.getIndexSettings()),\n+            () -> SequenceNumbers.NO_OPS_PERFORMED, primaryTerm::get, getPersistedSeqNoConsumer());\n+    }\n+\n+\n+    private void markCurrentGenAsCommitted(Translog translog) throws IOException {\n+        long genToCommit = translog.currentFileGeneration();\n+        long genToRetain = randomLongBetween(translog.getDeletionPolicy().getMinTranslogGenerationForRecovery(), genToCommit);\n+        commit(translog, genToRetain, genToCommit);\n+    }\n+\n+    private void rollAndCommit(Translog translog) throws IOException {\n+        translog.rollGeneration();\n+        markCurrentGenAsCommitted(translog);\n+    }\n+\n+    private long commit(Translog translog, long genToRetain, long genToCommit) throws IOException {\n+        final TranslogDeletionPolicy deletionPolicy = translog.getDeletionPolicy();\n+        deletionPolicy.setTranslogGenerationOfLastCommit(genToCommit);\n+        deletionPolicy.setMinTranslogGenerationForRecovery(genToRetain);\n+        long minGenRequired = deletionPolicy.minTranslogGenRequired(translog.getReaders(), translog.getCurrent());\n+        translog.trimUnreferencedReaders();\n+        assertThat(minGenRequired, equalTo(translog.getMinFileGeneration()));\n+        assertFilePresences(translog);\n+        return minGenRequired;\n+    }\n+\n+    @Override\n+    @Before\n+    public void setUp() throws Exception {\n+        super.setUp();\n+        primaryTerm.set(randomLongBetween(1, Integer.MAX_VALUE));\n+        // if a previous test failed we clean up things here\n+        translogDir = createTempDir();\n+        translog = create(translogDir);\n+    }\n+\n+    @Override\n+    @After\n+    public void tearDown() throws Exception {\n+        try {\n+            translog.getDeletionPolicy().assertNoOpenTranslogRefs();\n+            translog.close();\n+        } finally {\n+            super.tearDown();\n+        }\n+    }\n+\n+    private Translog create(Path path) throws IOException {\n+        globalCheckpoint = new AtomicLong(SequenceNumbers.NO_OPS_PERFORMED);\n+        final TranslogConfig translogConfig = getTranslogConfig(path);\n+        final TranslogDeletionPolicy deletionPolicy = createTranslogDeletionPolicy(translogConfig.getIndexSettings());\n+        final String translogUUID = Translog.createEmptyTranslog(path, SequenceNumbers.NO_OPS_PERFORMED, shardId, primaryTerm.get());\n+        return new Translog(translogConfig, translogUUID, deletionPolicy, () -> globalCheckpoint.get(), primaryTerm::get,\n+            getPersistedSeqNoConsumer());\n+    }\n+\n+    private TranslogConfig getTranslogConfig(final Path path) {\n+        final Settings settings = Settings\n+            .builder()\n+            .put(IndexMetadata.SETTING_VERSION_CREATED, org.elasticsearch.Version.CURRENT)\n+            // only randomize between nog age retention and a long one, so failures will have a chance of reproducing\n+            .put(IndexSettings.INDEX_TRANSLOG_RETENTION_AGE_SETTING.getKey(), randomBoolean() ? \"-1ms\" : \"1h\")\n+            .put(IndexSettings.INDEX_TRANSLOG_RETENTION_SIZE_SETTING.getKey(), randomIntBetween(-1, 2048) + \"b\")\n+            .build();\n+        return getTranslogConfig(path, settings);\n+    }\n+\n+    private TranslogConfig getTranslogConfig(final Path path, final Settings settings) {\n+        final ByteSizeValue bufferSize;\n+        if (randomBoolean()) {\n+            bufferSize = TranslogConfig.DEFAULT_BUFFER_SIZE;\n+        } else {\n+            bufferSize = new ByteSizeValue(10 + randomInt(128 * 1024), ByteSizeUnit.BYTES);\n+        }\n+\n+        final IndexSettings indexSettings =\n+            IndexSettingsModule.newIndexSettings(shardId.getIndex(), settings);\n+        return new TranslogConfig(shardId, path, indexSettings, NON_RECYCLING_INSTANCE, bufferSize);\n+    }\n+\n+    private Location addToTranslogAndList(Translog translog, List<Translog.Operation> list, Translog.Operation op) throws IOException {\n+        list.add(op);\n+        return translog.add(op);\n+    }\n+\n+    public void testIdParsingFromFile() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ac0d8cdce86517f8a7be2ea028f117c5d26f29"}, "originalPosition": 281}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 996, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}