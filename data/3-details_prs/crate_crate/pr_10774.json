{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIxNTc1MDMw", "number": 10774, "title": "Backport gateway related patches", "bodyText": "Summary of the changes / Why this improves CrateDB\nSee commits for details.\nFilling in more gaps in our backports.\nMotivated by the currently ignored/flaky testConflictingCommandsInSingleRequest.\nChecklist\n\n Added an entry in CHANGES.txt for user facing changes\n Updated documentation & sql_features table for user facing changes\n Touched code is covered by tests\n CLA is signed\n This does not contain breaking changes, or if it does:\n\nIt is released within a major release\nIt is recorded in CHANGES.txt\nIt was marked as deprecated in an earlier release if possible\nYou've thought about the consequences and other components are adapted\n(E.g. AdminUI)", "createdAt": "2020-11-16T10:41:33Z", "url": "https://github.com/crate/crate/pull/10774", "merged": true, "mergeCommit": {"oid": "4230d1467c02c61091e3ac99d32cef6f1facf088"}, "closed": true, "closedAt": "2020-11-17T08:42:48Z", "author": {"login": "mfussenegger"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddHGhhAH2gAyNTIxNTc1MDMwOjExNDhlMDc0MGFmZGM5ZjdjYjhlNWRhYmNiNTIwY2JkMWQ2MDQ0ZDY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABddVcZqAFqTUzMjEzMTA1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Remove remaining TransportAction.execute calls from gateway code\n\nhttps://github.com/elastic/elasticsearch/commit/61de092679b8c2aed166b8e058df248a33608f06"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74dd6202ebd4cf23f6719581beef10226c7a1571", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/74dd6202ebd4cf23f6719581beef10226c7a1571", "committedDate": "2020-11-16T15:57:30Z", "message": "Regenerate es-backports commit list and include gateway package"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f139aabfaf154149b3c0d220d48789c476fb4454", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/f139aabfaf154149b3c0d220d48789c476fb4454", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Re-fetch shard info of primary when new node joins\n\nhttps://github.com/elastic/elasticsearch/commit/caaf02fda30af18f4cd14a078f3e1521ba8ee55e"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c743d269e86ee0146f20fe9031350c28c096088", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/4c743d269e86ee0146f20fe9031350c28c096088", "committedDate": "2020-11-16T15:57:30Z", "message": "Remove unused dependencies from Gateway"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c73e9a08569e22ef53fc1e9c4bfce061b05d445", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/7c73e9a08569e22ef53fc1e9c4bfce061b05d445", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Reset state recovery after successful recovery\n\nhttps://github.com/elastic/elasticsearch/commit/692245cc447d748b8233d588bb38cc261227d6f5"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e91639cf8561e048c59ba1947d24f323c6239445", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/e91639cf8561e048c59ba1947d24f323c6239445", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Some Cleanup in o.e.gateway Package\n\nhttps://github.com/elastic/elasticsearch/commit/5cadfe7f119838276c91107a09607c3e9fc37a46"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84caa268f4d848f452f6ae556f12951a43a4760a", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/84caa268f4d848f452f6ae556f12951a43a4760a", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Load metadata at start time not construction time\n\nhttps://github.com/elastic/elasticsearch/commit/9e3822a8622cfb50494b92a5e5674624da412211"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "61533b10eba003f4c7122e33c0e33fd3baa81237", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/61533b10eba003f4c7122e33c0e33fd3baa81237", "committedDate": "2020-11-16T15:55:33Z", "message": "bp: Load metadata at start time not construction time\n\nhttps://github.com/elastic/elasticsearch/commit/9e3822a8622cfb50494b92a5e5674624da412211"}, "afterCommit": {"oid": "84caa268f4d848f452f6ae556f12951a43a4760a", "author": {"user": {"login": "mfussenegger", "name": "Mathias Fu\u00dfenegger"}}, "url": "https://github.com/crate/crate/commit/84caa268f4d848f452f6ae556f12951a43a4760a", "committedDate": "2020-11-16T15:57:30Z", "message": "bp: Load metadata at start time not construction time\n\nhttps://github.com/elastic/elasticsearch/commit/9e3822a8622cfb50494b92a5e5674624da412211"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyMDkzNTg5", "url": "https://github.com/crate/crate/pull/10774#pullrequestreview-532093589", "createdAt": "2020-11-17T07:52:48Z", "commit": {"oid": "1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwNzo1Mjo0OFrOH0oDog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwODowMDowOVrOH0oRrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDI5MA==", "bodyText": "Why do we diverge here from elastic/elasticsearch@61de092#diff-4b3484e2c7a2e90b18ee27be05b638f9de273fa7976d1af077cfde3f353019caR54?\nAfaik it will set nodeIds only to the request to avoid streaming each bigger DiscoveryNode. Any reason to change this?", "url": "https://github.com/crate/crate/pull/10774#discussion_r524944290", "createdAt": "2020-11-17T07:52:48Z", "author": {"login": "seut"}, "path": "server/src/main/java/org/elasticsearch/gateway/Gateway.java", "diffHunk": "@@ -41,22 +44,27 @@\n \n     private final ClusterService clusterService;\n \n-    private final TransportNodesListGatewayMetaState listGatewayMetaState;\n+    private final NodeClient client;\n \n     private final IndicesService indicesService;\n \n     public Gateway(final Settings settings, final ClusterService clusterService,\n-                   final TransportNodesListGatewayMetaState listGatewayMetaState,\n+                   final NodeClient client,\n                    final IndicesService indicesService) {\n         this.indicesService = indicesService;\n         this.clusterService = clusterService;\n-        this.listGatewayMetaState = listGatewayMetaState;\n+        this.client = client;\n     }\n \n     public void performStateRecovery(final GatewayStateRecoveredListener listener) throws GatewayException {\n-        DiscoveryNode[] discoveryNodes = clusterService.state().nodes().getMasterNodes().values().toArray(DiscoveryNode.class);\n-        LOGGER.trace(\"performing state recovery from {}\", discoveryNodes);\n-        final TransportNodesListGatewayMetaState.NodesGatewayMetaState nodesState = listGatewayMetaState.list(discoveryNodes, null).actionGet();\n+        final DiscoveryNode[] nodes = clusterService.state().nodes().getMasterNodes().values().toArray(DiscoveryNode.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0Nzg4NQ==", "bodyText": "debug traces? at least the original test does not contain it...", "url": "https://github.com/crate/crate/pull/10774#discussion_r524947885", "createdAt": "2020-11-17T08:00:09Z", "author": {"login": "seut"}, "path": "server/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.gateway;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasItem;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushAction;\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushRequest;\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushResponse;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.seqno.ReplicationTracker;\n+import org.elasticsearch.indices.recovery.PeerRecoveryTargetService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.test.InternalTestCluster;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.transport.TransportService;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import io.crate.integrationtests.SQLTransportIntegrationTest;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class ReplicaShardAllocatorIT extends SQLTransportIntegrationTest {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        var nodePlugins = new ArrayList<>(super.nodePlugins());\n+        nodePlugins.add(MockTransportService.TestPlugin.class);\n+        nodePlugins.add(InternalSettingsPlugin.class);\n+        return nodePlugins;\n+    }\n+\n+    /**\n+     * Ensure that we fetch the latest shard store from the primary when a new node joins so we won't cancel the current recovery\n+     * for the copy on the newly joined node unless we can perform a noop recovery with that node.\n+     */\n+    @Test\n+    @Ignore(\"Fails currently, maybe missing backports\")\n+    public void testRecentPrimaryInformation() throws Exception {\n+        String indexName = \"test\";\n+        String nodeWithPrimary = internalCluster().startNode();\n+\n+        execute(\"\"\"\n+            create table doc.test (x int)\n+            clustered into 1 shards with (\n+                number_of_replicas = 1,\n+                \"recovery.file_based_threshold\" = 1.0,\n+                \"global_checkpoint_sync.interval\" = '100ms',\n+                \"unassigned.node_left.delayed_timeout\" = '1ms'\n+            )\n+        \"\"\");\n+        String nodeWithReplica = internalCluster().startDataOnlyNode();\n+        DiscoveryNode discoNodeWithReplica = internalCluster().getInstance(ClusterService.class, nodeWithReplica).localNode();\n+        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);\n+        ensureGreen(indexName);\n+        execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+            new Object[] { randomIntBetween(10, 100) },\n+            new Object[] { randomIntBetween(10, 100) },\n+        });\n+        assertBusy(() -> {\n+            SyncedFlushResponse syncedFlushResponse = client()\n+                .execute(SyncedFlushAction.INSTANCE, new SyncedFlushRequest(indexName))\n+                .actionGet(5, TimeUnit.SECONDS);\n+            assertThat(syncedFlushResponse.successfulShards(), equalTo(2));\n+        });\n+        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));\n+        if (randomBoolean()) {\n+            execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+                new Object[] { randomIntBetween(10, 100) },\n+                new Object[] { randomIntBetween(10, 100) },\n+            });\n+        }\n+        CountDownLatch blockRecovery = new CountDownLatch(1);\n+        CountDownLatch recoveryStarted = new CountDownLatch(1);\n+        MockTransportService transportServiceOnPrimary\n+            = (MockTransportService) internalCluster().getInstance(TransportService.class, nodeWithPrimary);\n+        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {\n+            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {\n+                recoveryStarted.countDown();\n+                try {\n+                    blockRecovery.await(5, TimeUnit.SECONDS);\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+            }\n+            connection.sendRequest(requestId, action, request, options);\n+        });\n+        try {\n+            String newNode = internalCluster().startDataOnlyNode();\n+            recoveryStarted.await(5, TimeUnit.SECONDS);\n+            // Index more documents and flush to destroy sync_id and remove the retention lease (as file_based_recovery_threshold reached).\n+            execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+                new Object[] { randomIntBetween(10, 100) },\n+                new Object[] { randomIntBetween(10, 100) },\n+            });\n+            execute(\"optimize table doc.test with (flush = true, max_num_segments = 1)\");\n+            assertBusy(() -> {\n+                execute(\"select unnest(retention_leases['leases']['id']) from sys.shards where table_name = 'test'\");\n+                for (var row : response.rows()) {\n+                    assertThat(row[0], not(equalTo((ReplicationTracker.getPeerRecoveryRetentionLeaseId(discoNodeWithReplica.getId())))));\n+                }\n+            });\n+            // AllocationService only calls GatewayAllocator if there are unassigned shards\n+            execute(\"\"\"\n+                create table doc.dummy (x int)\n+                with (\"routing.allocation.require.attr\" = 'not-found')\n+            \"\"\");\n+            internalCluster().startDataOnlyNode(nodeWithReplicaSettings);\n+            // need to wait for events to ensure the reroute has happened since we perform it async when a new node joins.\n+            client().admin().cluster()\n+                .prepareHealth(indexName)\n+                .setWaitForYellowStatus()\n+                .setWaitForEvents(Priority.LANGUID)\n+                .execute()\n+                .get(5, TimeUnit.SECONDS);\n+            blockRecovery.countDown();\n+            ensureGreen(indexName);\n+            assertThat(internalCluster().nodesInclude(indexName), hasItem(newNode));\n+            //for (RecoveryState recovery : client().admin().indices().prepareRecoveries(indexName).get().shardRecoveryStates().get(indexName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f139aabfaf154149b3c0d220d48789c476fb4454"}, "originalPosition": 149}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyMTMxMDUy", "url": "https://github.com/crate/crate/pull/10774#pullrequestreview-532131052", "createdAt": "2020-11-17T08:40:04Z", "commit": {"oid": "84caa268f4d848f452f6ae556f12951a43a4760a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3634, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}