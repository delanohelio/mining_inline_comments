{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk5Mjg0NTEw", "number": 10628, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDozMjo0OVrOEr_jxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNDo1ODo1NlrOEtFSkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0NTY1NTc1OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/io/crate/integrationtests/TableSettingsTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDozMjo0OVrOHfEQ0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxMDozMjo0OVrOHfEQ0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzNzc0Nw==", "bodyText": "Since translog.sync_interval is dynamic now we need to test against a different non dynamic setting.", "url": "https://github.com/crate/crate/pull/10628#discussion_r502337747", "createdAt": "2020-10-09T10:32:49Z", "author": {"login": "mkleen"}, "path": "server/src/test/java/io/crate/integrationtests/TableSettingsTest.java", "diffHunk": "@@ -88,8 +88,8 @@ public void testSelectSettingsColumn() throws Exception {\n \n     @Test\n     public void testSetNonDynamicTableSetting() {\n-        assertThrows(() -> execute(\"alter table settings_table set (\\\"translog.sync_interval\\\"='10s')\"),\n-                     isSQLError(containsString(\"Can't update non dynamic settings [[index.translog.sync_interval]] for open indices\"),\n+        assertThrows(() -> execute(\"alter table settings_table set (\\\"soft_deletes.enabled\\\"='true')\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af97277ec2b7a6e712dcdf0f5dbb8ef8fa953e35"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1Mjc5MzM5OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/index/IndexServiceTests.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNToxMzo1MFrOHgC4Ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNToxMzo1MFrOHgC4Ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM2MzYwMw==", "bodyText": "Last remaining flaky test. The flush operation does not always trigger the translog to be trimmed because the generation is not increased. I hope this is a test setup problem and not a issue in the engine. I was thinking to fix that in a follow up.", "url": "https://github.com/crate/crate/pull/10628#discussion_r503363603", "createdAt": "2020-10-12T15:13:50Z", "author": {"login": "mkleen"}, "path": "server/src/test/java/org/elasticsearch/index/IndexServiceTests.java", "diffHunk": "@@ -0,0 +1,480 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index;\n+\n+import io.crate.common.unit.TimeValue;\n+import io.crate.integrationtests.SQLHttpIntegrationTest;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.TopDocs;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.engine.EngineTestCase;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.junit.Ignore;\n+\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;\n+import static io.crate.testing.Asserts.assertThrows;\n+import static io.crate.testing.SQLErrorMatcher.isSQLError;\n+import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.flushShard;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.getEngine;\n+import static org.elasticsearch.test.InternalSettingsPlugin.TRANSLOG_RETENTION_CHECK_INTERVAL_SETTING;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+@ESIntegTestCase.ClusterScope(numDataNodes = 1, supportsDedicatedMasters = false)\n+public class IndexServiceTests extends SQLHttpIntegrationTest {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        var plugins = new ArrayList<>(super.nodePlugins());\n+        plugins.add(InternalSettingsPlugin.class);\n+        return plugins;\n+    }\n+\n+    public void testBaseAsyncTask() throws Exception {\n+        execute(\"create table test (x int) clustered into 1 shards\");\n+        IndexService indexService = getIndexService(\"test\");\n+\n+        AtomicReference<CountDownLatch> latch = new AtomicReference<>(new CountDownLatch(1));\n+        AtomicReference<CountDownLatch> latch2 = new AtomicReference<>(new CountDownLatch(1));\n+        final AtomicInteger count = new AtomicInteger();\n+        IndexService.BaseAsyncTask task = new IndexService.BaseAsyncTask(indexService, TimeValue.timeValueMillis(1)) {\n+            @Override\n+            protected void runInternal() {\n+                final CountDownLatch l1 = latch.get();\n+                final CountDownLatch l2 = latch2.get();\n+                count.incrementAndGet();\n+                assertTrue(\"generic threadpool is configured\", Thread.currentThread().getName().contains(\"[generic]\"));\n+                l1.countDown();\n+                try {\n+                    l2.await();\n+                } catch (InterruptedException e) {\n+                    fail(\"interrupted\");\n+                }\n+                if (randomBoolean()) { // task can throw exceptions!!\n+                    if (randomBoolean()) {\n+                        throw new RuntimeException(\"foo\");\n+                    } else {\n+                        throw new RuntimeException(\"bar\");\n+                    }\n+                }\n+            }\n+\n+            @Override\n+            protected String getThreadPool() {\n+                return ThreadPool.Names.GENERIC;\n+            }\n+        };\n+\n+        latch.get().await();\n+        latch.set(new CountDownLatch(1));\n+        assertEquals(1, count.get());\n+        // here we need to swap first before we let it go otherwise threads might be very fast and run that task twice due to\n+        // random exception and the schedule interval is 1ms\n+        latch2.getAndSet(new CountDownLatch(1)).countDown();\n+        latch.get().await();\n+        assertEquals(2, count.get());\n+        task.close();\n+        latch2.get().countDown();\n+        assertEquals(2, count.get());\n+\n+        task = new IndexService.BaseAsyncTask(indexService, TimeValue.timeValueMillis(1000000)) {\n+            @Override\n+            protected void runInternal() {\n+\n+            }\n+        };\n+        assertTrue(task.mustReschedule());\n+\n+        // now close the index\n+        execute(\"alter table test close\");\n+        final Index index = indexService.index();\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+        final IndexService closedIndexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(indexService, closedIndexService);\n+        assertFalse(task.mustReschedule());\n+        assertFalse(task.isClosed());\n+        assertEquals(1000000, task.getInterval().millis());\n+\n+        assertNotSame(indexService, closedIndexService);\n+        assertFalse(task.mustReschedule());\n+        assertFalse(task.isClosed());\n+        assertEquals(1000000, task.getInterval().millis());\n+\n+        // now reopen the index\n+        execute(\"alter table test open\");\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+        indexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(closedIndexService, indexService);\n+\n+        task = new IndexService.BaseAsyncTask(indexService, TimeValue.timeValueMillis(100000)) {\n+            @Override\n+            protected void runInternal() {\n+\n+            }\n+        };\n+        assertTrue(task.mustReschedule());\n+        assertFalse(task.isClosed());\n+        assertTrue(task.isScheduled());\n+\n+        indexService.close(\"simon says\", false);\n+        assertFalse(\"no shards left\", task.mustReschedule());\n+        assertTrue(task.isScheduled());\n+        task.close();\n+        assertFalse(task.isScheduled());\n+    }\n+\n+    public void testRefreshTaskIsUpdated() throws Exception {\n+        execute(\"create table test (x int) clustered into 1 shards\");\n+        IndexService indexService = getIndexService(\"test\");\n+        var indexName = indexService.index().getName();\n+        IndexService.AsyncRefreshTask refreshTask = indexService.getRefreshTask();\n+        assertEquals(1000, refreshTask.getInterval().millis());\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+\n+        // now disable\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), -1)).get();\n+        assertNotSame(refreshTask, indexService.getRefreshTask());\n+        assertTrue(refreshTask.isClosed());\n+        assertFalse(refreshTask.isScheduled());\n+\n+        // set it to 100ms\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(),  \"100ms\")).get();\n+        assertNotSame(refreshTask, indexService.getRefreshTask());\n+        assertTrue(refreshTask.isClosed());\n+\n+        refreshTask = indexService.getRefreshTask();\n+        assertTrue(refreshTask.mustReschedule());\n+        assertTrue(refreshTask.isScheduled());\n+        assertEquals(100, refreshTask.getInterval().millis());\n+\n+        // set it to 200ms\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), \"200ms\")).get();\n+        assertNotSame(refreshTask, indexService.getRefreshTask());\n+        assertTrue(refreshTask.isClosed());\n+\n+        refreshTask = indexService.getRefreshTask();\n+        assertTrue(refreshTask.mustReschedule());\n+        assertTrue(refreshTask.isScheduled());\n+        assertEquals(200, refreshTask.getInterval().millis());\n+\n+        // set it to 200ms again\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), \"200ms\")).get();\n+        assertSame(refreshTask, indexService.getRefreshTask());\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+        assertTrue(refreshTask.isScheduled());\n+        assertFalse(refreshTask.isClosed());\n+        assertEquals(200, refreshTask.getInterval().millis());\n+\n+        // now close the index\n+        execute(\"alter table test close\");\n+        final Index index = indexService.index();\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+\n+        final IndexService closedIndexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(indexService, closedIndexService);\n+        assertNotSame(refreshTask, closedIndexService.getRefreshTask());\n+        assertFalse(closedIndexService.getRefreshTask().mustReschedule());\n+        assertFalse(closedIndexService.getRefreshTask().isClosed());\n+        assertEquals(200, closedIndexService.getRefreshTask().getInterval().millis());\n+\n+        // now reopen the index\n+        execute(\"alter table test open\");\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+        indexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(closedIndexService, indexService);\n+        refreshTask = indexService.getRefreshTask();\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+        assertTrue(refreshTask.isScheduled());\n+        assertFalse(refreshTask.isClosed());\n+\n+        indexService.close(\"simon says\", false);\n+        assertFalse(refreshTask.isScheduled());\n+        assertTrue(refreshTask.isClosed());\n+    }\n+\n+    public void testFsyncTaskIsRunning() throws Exception {\n+        execute(\"create table test(x int) clustered into 1 shards with (\\\"translog.durability\\\" = 'ASYNC')\");\n+        IndexService indexService = getIndexService(\"test\");\n+        IndexService.AsyncTranslogFSync fsyncTask = indexService.getFsyncTask();\n+        assertNotNull(fsyncTask);\n+        assertEquals(5000, fsyncTask.getInterval().millis());\n+        assertTrue(fsyncTask.mustReschedule());\n+        assertTrue(fsyncTask.isScheduled());\n+\n+        // now close the index\n+        execute(\"alter table test close\");\n+        final Index index = indexService.index();\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+\n+        final IndexService closedIndexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(indexService, closedIndexService);\n+        assertNotSame(fsyncTask, closedIndexService.getFsyncTask());\n+        assertFalse(closedIndexService.getFsyncTask().mustReschedule());\n+        assertFalse(closedIndexService.getFsyncTask().isClosed());\n+        assertEquals(5000, closedIndexService.getFsyncTask().getInterval().millis());\n+\n+        // now reopen the index\n+        execute(\"alter table test open\");\n+        assertBusy(() -> assertTrue(\"Index not found: \" + index.getName(), getIndicesService().hasIndex(index)));\n+        indexService = getIndicesService().indexServiceSafe(index);\n+        assertNotSame(closedIndexService, indexService);\n+        fsyncTask = indexService.getFsyncTask();\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+        assertTrue(fsyncTask.isScheduled());\n+        assertFalse(fsyncTask.isClosed());\n+\n+        indexService.close(\"simon says\", false);\n+        assertFalse(fsyncTask.isScheduled());\n+        assertTrue(fsyncTask.isClosed());\n+\n+        execute(\"create table test1 (x int, data text)\");\n+        indexService = getIndexService(\"test1\");\n+        assertNull(indexService.getFsyncTask());\n+    }\n+\n+    public void testRefreshActuallyWorks() throws Exception {\n+        execute(\"create table test (x int, data text) clustered into 1 shards\");\n+        var indexService = getIndexService(\"test\");\n+        var indexName = indexService.index().getName();\n+        ensureGreen(indexName);\n+        IndexService.AsyncRefreshTask refreshTask = indexService.getRefreshTask();\n+        assertEquals(1000, refreshTask.getInterval().millis());\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+        IndexShard shard = indexService.getShard(0);\n+        execute(\"insert into test (x, data) values (1, 'foo')\");\n+        // now disable the refresh\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), -1)).get();\n+        // when we update we reschedule the existing task AND fire off an async refresh to make sure we make everything visible\n+        // before that this is why we need to wait for the refresh task to be unscheduled and the first doc to be visible\n+        assertTrue(refreshTask.isClosed());\n+        refreshTask = indexService.getRefreshTask();\n+        assertBusy(() -> {\n+            // this one either becomes visible due to a concurrently running scheduled refresh OR due to the force refresh\n+            // we are running on updateMetadata if the interval changes\n+            try (Engine.Searcher searcher = shard.acquireSearcher(indexName)) {\n+                TopDocs search = searcher.search(new MatchAllDocsQuery(), 10);\n+                assertEquals(1, search.totalHits.value);\n+            }\n+        });\n+        assertFalse(refreshTask.isClosed());\n+        // refresh every millisecond\n+        execute(\"insert into test (x, data) values (2, 'foo')\");\n+        client().admin().indices().prepareUpdateSettings(indexName)\n+            .setSettings(Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), \"1ms\")).get();\n+        assertTrue(refreshTask.isClosed());\n+\n+        assertBusy(() -> {\n+            // this one becomes visible due to the force refresh we are running on updateMetadata if the interval changes\n+            try (Engine.Searcher searcher = shard.acquireSearcher(indexName)) {\n+                TopDocs search = searcher.search(new MatchAllDocsQuery(), 10);\n+                assertEquals(2, search.totalHits.value);\n+            }\n+        });\n+        execute(\"insert into test (x, data) values (3, 'foo')\");\n+\n+        assertBusy(() -> {\n+            // this one becomes visible due to the scheduled refresh\n+            try (Engine.Searcher searcher = shard.acquireSearcher(\"test\")) {\n+                TopDocs search = searcher.search(new MatchAllDocsQuery(), 10);\n+                assertEquals(3, search.totalHits.value);\n+            }\n+        });\n+    }\n+\n+    public void testAsyncFsyncActuallyWorks() throws Exception {\n+        execute(\"create table test(x int, data string) clustered into 1 shards with (\\\"translog.sync_interval\\\" = '100ms', \" +\n+                \"\\\"translog.durability\\\" = 'ASYNC')\");\n+        IndexService indexService = getIndexService(\"test\");\n+        var indexName = indexService.index().getName();\n+        ensureGreen(indexName);\n+        assertTrue(indexService.getRefreshTask().mustReschedule());\n+        execute(\"insert into test (x, data) values (1, 'foo')\");\n+        IndexShard shard = indexService.getShard(0);\n+        assertBusy(() -> assertFalse(shard.isSyncNeeded()));\n+    }\n+\n+    public void testRescheduleAsyncFsync() throws Exception {\n+        execute(\"create table test(x int, data string) clustered into 1 shards with (\\\"translog.sync_interval\\\" = '100ms', \\\"translog.durability\\\" = 'REQUEST')\");\n+        IndexService indexService = getIndexService(\"test\");\n+        var indexName = indexService.index().getName();\n+\n+        ensureGreen(indexName);\n+        assertNull(indexService.getFsyncTask());\n+\n+        execute(\"alter table test set (\\\"translog.durability\\\" = 'ASYNC')\");\n+\n+        assertNotNull(indexService.getFsyncTask());\n+        assertTrue(indexService.getFsyncTask().mustReschedule());\n+        execute(\"insert into test (x, data) values (1, 'foo')\");\n+        assertNotNull(indexService.getFsyncTask());\n+        final IndexShard shard = indexService.getShard(0);\n+        assertBusy(() -> assertFalse(shard.isSyncNeeded()));\n+\n+        execute(\"alter table test set (\\\"translog.durability\\\" = 'REQUEST')\");\n+        assertNull(indexService.getFsyncTask());\n+\n+        execute(\"alter table test set (\\\"translog.durability\\\" = 'ASYNC')\");\n+        assertNotNull(indexService.getFsyncTask());\n+    }\n+\n+    @Ignore(\"Flaky\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ca785d4e7114b7f93573a95b53f1e2dc48cb66"}, "originalPosition": 360}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NTE5MDg1OnYy", "diffSide": "LEFT", "path": "server/src/main/java/org/elasticsearch/index/IndexService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzoyOToxN1rOHgZAjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNzoyOToxN1rOHgZAjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcyNjIyMg==", "bodyText": "Isn't the rescheduleFsyncTask method now unused?", "url": "https://github.com/crate/crate/pull/10628#discussion_r503726222", "createdAt": "2020-10-13T07:29:17Z", "author": {"login": "mfussenegger"}, "path": "server/src/main/java/org/elasticsearch/index/IndexService.java", "diffHunk": "@@ -566,10 +564,23 @@ public boolean isForceExecution() {\n                 });\n                 rescheduleRefreshTasks();\n             }\n-            final Translog.Durability durability = indexSettings.getTranslogDurability();\n-            if (durability != oldTranslogDurability) {\n-                rescheduleFsyncTask(durability);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13ca785d4e7114b7f93573a95b53f1e2dc48cb66"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NzA4MDUxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/elasticsearch/index/IndexServiceTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNDo1ODo1NlrOHgrJIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNToxNDozMFrOHgr5IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAyMzMyOA==", "bodyText": "Any reason to use the SQLHttpIntegrationTest base class instead of SQLTransportIntegrationTest ?", "url": "https://github.com/crate/crate/pull/10628#discussion_r504023328", "createdAt": "2020-10-13T14:58:56Z", "author": {"login": "mfussenegger"}, "path": "server/src/test/java/org/elasticsearch/index/IndexServiceTests.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index;\n+\n+import io.crate.common.unit.TimeValue;\n+import io.crate.integrationtests.SQLHttpIntegrationTest;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.TopDocs;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.engine.EngineTestCase;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;\n+import static io.crate.testing.Asserts.assertThrows;\n+import static io.crate.testing.SQLErrorMatcher.isSQLError;\n+import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.flushShard;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.getEngine;\n+import static org.elasticsearch.test.InternalSettingsPlugin.TRANSLOG_RETENTION_CHECK_INTERVAL_SETTING;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+@ESIntegTestCase.ClusterScope(numDataNodes = 1, supportsDedicatedMasters = false)\n+public class IndexServiceTests extends SQLHttpIntegrationTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ffb7da1ef3dbf84b7183570c255decdc325d7c0b"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAzNTYxNg==", "bodyText": "The original idea was to not have mixed api half http half psql to be as close possible to the original test when everything was quite unstable. But you are right. Lets go with SQLTransportIntegrationTest.", "url": "https://github.com/crate/crate/pull/10628#discussion_r504035616", "createdAt": "2020-10-13T15:14:30Z", "author": {"login": "mkleen"}, "path": "server/src/test/java/org/elasticsearch/index/IndexServiceTests.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index;\n+\n+import io.crate.common.unit.TimeValue;\n+import io.crate.integrationtests.SQLHttpIntegrationTest;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.TopDocs;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.engine.EngineTestCase;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.index.translog.Translog;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;\n+import static io.crate.testing.Asserts.assertThrows;\n+import static io.crate.testing.SQLErrorMatcher.isSQLError;\n+import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.flushShard;\n+import static org.elasticsearch.index.shard.IndexShardTestCase.getEngine;\n+import static org.elasticsearch.test.InternalSettingsPlugin.TRANSLOG_RETENTION_CHECK_INTERVAL_SETTING;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+@ESIntegTestCase.ClusterScope(numDataNodes = 1, supportsDedicatedMasters = false)\n+public class IndexServiceTests extends SQLHttpIntegrationTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDAyMzMyOA=="}, "originalCommit": {"oid": "ffb7da1ef3dbf84b7183570c255decdc325d7c0b"}, "originalPosition": 57}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 954, "cost": 1, "resetAt": "2021-11-12T11:57:46Z"}}}