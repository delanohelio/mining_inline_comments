{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4NDUyNzI0", "number": 6687, "reviewThreads": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoyOTozMVrOEOVepA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjo0MzozOFrOEUU2bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDY3NDI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjoyOTozMVrOGxblhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMDoyODo1MlrOGx4DqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NTM4Mg==", "bodyText": "As this is a special form of a SearchBasedParserFetcher I would suggest to also reflect it in the name: AdvancedSearchBasedParserFetcher (although it gets a bit long).\nMoreover, I think, it's a good idea to replicate the abstract interface and introduce a AdvancedSearchBasedFetcher as well. Finally, these Advanced* classes should probably overwrite the normal performSearch methods and rely them to the performAdvancedSearch methods in order to make implementation easier, or not?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454485382", "createdAt": "2020-07-14T16:29:31Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0NTUyNQ==", "bodyText": "Yeah, I totally agree with the renaming of the interface and method.\nI can see your point regarding the introduction of advanced Fetcher classes, but I think that this might not work that simply, as these advanced fetchers would somehow have to parse the query, as it is a string in the standard performSearch method, into a ComplexQuery.\nI think this is out of the scope of the current PR as it just tries to make the fielded search capabilities of the external library APIs testable.\nBut I really like your idea and I believe it will be in the scope of the thesis, just not in scope of this PR. :)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454945525", "createdAt": "2020-07-15T10:16:45Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NTM4Mg=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1MTg0OA==", "bodyText": "Ok, we can leave it for now. What I was thinking was to simply pass the normal query as the \"default field\" and then call the \"advanced search\" method.\nOtherwise I agree, parsing complex queries should probably happen in the user interface (and should be consistent across fetchers to add even more value for users).", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454951848", "createdAt": "2020-07-15T10:28:52Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NTM4Mg=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDY3Nzc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjozMDoyNFrOGxbnqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMDowMDowOVrOGx3Hag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NTkzMA==", "bodyText": "the Advanced in the name is not really necessary I guess.\nMoreover, I would rename the paramaer to ComplexQuery (or ComplexSearchQuery) since this is not really a configuration.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454485930", "createdAt": "2020-07-14T16:30:24Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {\n+\n+    /**\n+     * This method is used to send queries with advanced URL parameters.\n+     * This method is necessary as the performSearch method does not support certain URL parameters that are used for\n+     * fielded search, such as a title, author, or year parameter.\n+     *\n+     * @param advancedSearchConfig the search config defining all fielded search parameters\n+     */\n+    default List<BibEntry> performAdvancedSearch(AdvancedSearchConfig advancedSearchConfig) throws FetcherException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzNjQyNg==", "bodyText": "Thanks, I modified the names accordingly.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454936426", "createdAt": "2020-07-15T10:00:09Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {\n+\n+    /**\n+     * This method is used to send queries with advanced URL parameters.\n+     * This method is necessary as the performSearch method does not support certain URL parameters that are used for\n+     * fielded search, such as a title, author, or year parameter.\n+     *\n+     * @param advancedSearchConfig the search config defining all fielded search parameters\n+     */\n+    default List<BibEntry> performAdvancedSearch(AdvancedSearchConfig advancedSearchConfig) throws FetcherException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NTkzMA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDY4MjYwOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjozMTo0MVrOGxbq3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMDoxODozM1rOGx3uXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4Njc1MA==", "bodyText": "In line with the other interfaces, I would suggest to change the return value to URL.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454486750", "createdAt": "2020-07-14T16:31:41Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {\n+\n+    /**\n+     * This method is used to send queries with advanced URL parameters.\n+     * This method is necessary as the performSearch method does not support certain URL parameters that are used for\n+     * fielded search, such as a title, author, or year parameter.\n+     *\n+     * @param advancedSearchConfig the search config defining all fielded search parameters\n+     */\n+    default List<BibEntry> performAdvancedSearch(AdvancedSearchConfig advancedSearchConfig) throws FetcherException {\n+        try (InputStream stream = getAdvancedURLDownload(advancedSearchConfig).asInputStream()) {\n+            List<BibEntry> fetchedEntries = getParser().parseEntries(stream);\n+            fetchedEntries.forEach(this::doPostCleanup);\n+            return fetchedEntries;\n+        } catch (IOException e) {\n+            // TODO: Catch HTTP Response 401/403 errors and report that user has no rights to access resource\n+            throw new FetcherException(\"A network error occurred\", e);\n+        } catch (ParseException e) {\n+            throw new FetcherException(\"An internal parser error occurred\", e);\n+        }\n+    }\n+\n+    URLDownload getAdvancedURLDownload(AdvancedSearchConfig advancedSearchConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzNDkzMw==", "bodyText": "Sorry, I do not understand the \"In line with the other interfaces\" as the method is just a modification of the WebFetcher interface that contains a getUrlDownload method that returns an URLDownload?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454934933", "createdAt": "2020-07-15T09:57:49Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {\n+\n+    /**\n+     * This method is used to send queries with advanced URL parameters.\n+     * This method is necessary as the performSearch method does not support certain URL parameters that are used for\n+     * fielded search, such as a title, author, or year parameter.\n+     *\n+     * @param advancedSearchConfig the search config defining all fielded search parameters\n+     */\n+    default List<BibEntry> performAdvancedSearch(AdvancedSearchConfig advancedSearchConfig) throws FetcherException {\n+        try (InputStream stream = getAdvancedURLDownload(advancedSearchConfig).asInputStream()) {\n+            List<BibEntry> fetchedEntries = getParser().parseEntries(stream);\n+            fetchedEntries.forEach(this::doPostCleanup);\n+            return fetchedEntries;\n+        } catch (IOException e) {\n+            // TODO: Catch HTTP Response 401/403 errors and report that user has no rights to access resource\n+            throw new FetcherException(\"A network error occurred\", e);\n+        } catch (ParseException e) {\n+            throw new FetcherException(\"An internal parser error occurred\", e);\n+        }\n+    }\n+\n+    URLDownload getAdvancedURLDownload(AdvancedSearchConfig advancedSearchConfig);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4Njc1MA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0NjM5Ng==", "bodyText": "The analog is\n\n  \n    \n      jabref/src/main/java/org/jabref/logic/importer/SearchBasedParserFetcher.java\n    \n    \n         Line 27\n      in\n      ec71351\n    \n    \n    \n    \n\n        \n          \n           URL getURLForQuery(String query) throws URISyntaxException, MalformedURLException, FetcherException; \n        \n    \n  \n\n\nThe getUrlDownload method converts the url then to a UrlDownload object.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454946396", "createdAt": "2020-07-15T10:18:33Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/AdvancedFetcher.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.jabref.logic.importer;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+\n+import org.jabref.logic.importer.fetcher.AdvancedSearchConfig;\n+import org.jabref.logic.net.URLDownload;\n+import org.jabref.model.entry.BibEntry;\n+\n+/**\n+ * This interface allows SearchBasedParserFetcher fetchers to test their corresponding\n+ * library APIs for their advanced search options, e.g. search in the \"title\" field.\n+ */\n+public interface AdvancedFetcher extends SearchBasedParserFetcher {\n+\n+    /**\n+     * This method is used to send queries with advanced URL parameters.\n+     * This method is necessary as the performSearch method does not support certain URL parameters that are used for\n+     * fielded search, such as a title, author, or year parameter.\n+     *\n+     * @param advancedSearchConfig the search config defining all fielded search parameters\n+     */\n+    default List<BibEntry> performAdvancedSearch(AdvancedSearchConfig advancedSearchConfig) throws FetcherException {\n+        try (InputStream stream = getAdvancedURLDownload(advancedSearchConfig).asInputStream()) {\n+            List<BibEntry> fetchedEntries = getParser().parseEntries(stream);\n+            fetchedEntries.forEach(this::doPostCleanup);\n+            return fetchedEntries;\n+        } catch (IOException e) {\n+            // TODO: Catch HTTP Response 401/403 errors and report that user has no rights to access resource\n+            throw new FetcherException(\"A network error occurred\", e);\n+        } catch (ParseException e) {\n+            throw new FetcherException(\"An internal parser error occurred\", e);\n+        }\n+    }\n+\n+    URLDownload getAdvancedURLDownload(AdvancedSearchConfig advancedSearchConfig);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4Njc1MA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDY4NTM5OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/AdvancedSearchConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjozMjoxOVrOGxbsmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwOTo1MDo1N1rOGx2yKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NzE5NQ==", "bodyText": "What's the purpose of this \"default field\" ?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454487195", "createdAt": "2020-07-14T16:32:19Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/AdvancedSearchConfig.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class AdvancedSearchConfig {\n+    private final String defaultField;\n+    private final String author;\n+    private final String title;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final String journal;\n+\n+    private AdvancedSearchConfig(String defaultField, String author, String title, Integer fromYear, Integer toYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.author = author;\n+        this.title = title;\n+        this.fromYear = fromYear;\n+        this.toYear = toYear;\n+        this.journal = journal;\n+    }\n+\n+    public Optional<String> getDefaultField() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxMTI1OQ==", "bodyText": "The default field is used if no fielded search parameter is used. In most of the API's this results in searching in multiple (all) fields.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454911259", "createdAt": "2020-07-15T09:17:23Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/AdvancedSearchConfig.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class AdvancedSearchConfig {\n+    private final String defaultField;\n+    private final String author;\n+    private final String title;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final String journal;\n+\n+    private AdvancedSearchConfig(String defaultField, String author, String title, Integer fromYear, Integer toYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.author = author;\n+        this.title = title;\n+        this.fromYear = fromYear;\n+        this.toYear = toYear;\n+        this.journal = journal;\n+    }\n+\n+    public Optional<String> getDefaultField() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NzE5NQ=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzMDk4Ng==", "bodyText": "Just add JavaDoc \ud83d\ude05", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454930986", "createdAt": "2020-07-15T09:50:57Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/AdvancedSearchConfig.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class AdvancedSearchConfig {\n+    private final String defaultField;\n+    private final String author;\n+    private final String title;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final String journal;\n+\n+    private AdvancedSearchConfig(String defaultField, String author, String title, Integer fromYear, Integer toYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.author = author;\n+        this.title = title;\n+        this.fromYear = fromYear;\n+        this.toYear = toYear;\n+        this.journal = journal;\n+    }\n+\n+    public Optional<String> getDefaultField() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4NzE5NQ=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDY5Mjk3OnYy", "diffSide": "RIGHT", "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjozNDozMlrOGxbxvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMjowMzo1NlrOGx6-FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA==", "bodyText": "These new tests are fine, but they are not really using the new interface that you introduced. Is there are reason for this?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454488508", "createdAt": "2020-07-14T16:34:32Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzMjgzMA==", "bodyText": "The AdvancedFetcher Interface is only used for fetchers that use URL parameters for fielded search. Since in this case arXiv uses the query string for fielded search, this is not necessary.\nAn example where this Interface will be used is the IEEE fetcher in the future. The IEEE Fetcher Tests that should be using the interface are not implemented yet, due to my IEEE API key not being activated until recently.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454932830", "createdAt": "2020-07-15T09:54:09Z", "author": {"login": "DominikVoigt"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzNDE4NQ==", "bodyText": "This is contained in the JavaDoc from the interface the test implements, isn't it?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454934185", "createdAt": "2020-07-15T09:56:31Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0ODAxNA==", "bodyText": "I thought the end goal was to support more complex search queries with a syntax that is the same across all \"advanced fetchers\" (and parsed to the \"AdvancedSearchQuery\" object). Thus, I think also the arXiv fetcher should implement the AdvancedFetcher interface, and then internally convert it to the correct query using \"au:\" etc.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454948014", "createdAt": "2020-07-15T10:21:36Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk2NTcwMw==", "bodyText": "The thought behind the current state is, that the fetchers that support fielded search as part of the query string do not have to be changed.\nTo get closed to the end goal though, we can integrate the perfromComplexSearchQuery method into the SearchBasedFetcher interface. The problem with this is, that not all APIs and their corresponding fetchers will be able to support all fields that are included in the AdvancedSearchConfig/ComplexQuery.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454965703", "createdAt": "2020-07-15T10:55:39Z", "author": {"login": "DominikVoigt"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk2ODc5Ng==", "bodyText": "End goal: right. Breaking it up in smaller PRs to ease reviewing. Maybe, it was too much to include the search config now? - Howe6, to me, that part was already finished. Thus, I thought it is a good package to review. There will be follow up PRs.\n@DominikVoigt Maybe you can show one implementation this week or do the issues with keys prevent you from that?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454968796", "createdAt": "2020-07-15T11:01:42Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3MjkxNw==", "bodyText": "Solved the key issue yesterday. I'll work on one implementation this week.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454972917", "createdAt": "2020-07-15T11:10:07Z", "author": {"login": "DominikVoigt"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk5OTU3Mg==", "bodyText": "We can leave it like this for the moment, but the tests should get rewritten to use the performComplexSearch method at some point.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454999572", "createdAt": "2020-07-15T12:03:56Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/ArXivTest.java", "diffHunk": "@@ -13,210 +14,296 @@\n import org.jabref.model.entry.types.StandardEntryType;\n import org.jabref.testutils.category.FetcherTest;\n \n+import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Disabled;\n import org.junit.jupiter.api.Test;\n \n import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n import static org.junit.jupiter.api.Assertions.assertThrows;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n-class ArXivTest {\n-    private ArXiv finder;\n+class ArXivTest implements SearchBasedFetcherCapabilityTest {\n+    private ArXiv fetcher;\n     private BibEntry entry;\n     private BibEntry sliceTheoremPaper;\n \n     @BeforeEach\n     void setUp() {\n         ImportFormatPreferences importFormatPreferences = mock(ImportFormatPreferences.class);\n         when(importFormatPreferences.getKeywordSeparator()).thenReturn(',');\n-        finder = new ArXiv(importFormatPreferences);\n+        fetcher = new ArXiv(importFormatPreferences);\n         entry = new BibEntry();\n-\n-        sliceTheoremPaper = new BibEntry();\n-        sliceTheoremPaper.setType(StandardEntryType.Article);\n-        sliceTheoremPaper.setField(StandardField.AUTHOR, \"Tobias Diez\");\n-        sliceTheoremPaper.setField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\");\n-        sliceTheoremPaper.setField(StandardField.DATE, \"2014-05-09\");\n-        sliceTheoremPaper.setField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\");\n-        sliceTheoremPaper.setField(StandardField.EPRINT, \"1405.2249\");\n-        sliceTheoremPaper.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        sliceTheoremPaper.setField(StandardField.EPRINTCLASS, \"math-ph\");\n-        sliceTheoremPaper.setField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n+        sliceTheoremPaper = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Tobias Diez\")\n+                .withField(StandardField.TITLE, \"Slice theorem for Fr\u00e9chet group actions and covariant symplectic field theory\")\n+                .withField(StandardField.DATE, \"2014-05-09\")\n+                .withField(StandardField.ABSTRACT, \"A general slice theorem for the action of a Fr\\\\'echet Lie group on a Fr\\\\'echet manifolds is established. The Nash-Moser theorem provides the fundamental tool to generalize the result of Palais to this infinite-dimensional setting. The presented slice theorem is illustrated by its application to gauge theories: the action of the gauge transformation group admits smooth slices at every point and thus the gauge orbit space is stratified by Fr\\\\'echet manifolds. Furthermore, a covariant and symplectic formulation of classical field theory is proposed and extensively discussed. At the root of this novel framework is the incorporation of field degrees of freedom F and spacetime M into the product manifold F * M. The induced bigrading of differential forms is used in order to carry over the usual symplectic theory to this new setting. The examples of the Klein-Gordon field and general Yang-Mills theory illustrate that the presented approach conveniently handles the occurring symmetries.\")\n+                .withField(StandardField.EPRINT, \"1405.2249\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/1405.2249v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"math-ph\")\n+                .withField(StandardField.KEYWORDS, \"math-ph, math.DG, math.MP, math.SG, 58B99, 58Z05, 58B25, 22E65, 58D19, 53D20, 53D42\");\n     }\n \n     @Test\n     void findFullTextForEmptyEntryResultsEmptyOptional() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextRejectsNullParameter() {\n-        assertThrows(NullPointerException.class, () -> finder.findFullText(null));\n+        assertThrows(NullPointerException.class, () -> fetcher.findFullText(null));\n     }\n \n     @Test\n     void findFullTextByDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/biophysj.104.047340\");\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprint() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithPrefix() throws IOException {\n         entry.setField(StandardField.EPRINT, \"arXiv:1603.06570\");\n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByEprintWithUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n         entry.setField(StandardField.EPRINT, \"1603.06570\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/1603.06570v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitle() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByTitleAndPartOfAuthor() throws IOException {\n         entry.setField(StandardField.TITLE, \"Pause Point Spectra in DNA Constant-Force Unzipping\");\n         entry.setField(StandardField.AUTHOR, \"Weeks and Lucks\");\n \n-        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), finder.findFullText(entry));\n+        assertEquals(Optional.of(new URL(\"http://arxiv.org/pdf/cond-mat/0406246v1\")), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownDOI() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1529/unknown\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void notFindFullTextByUnknownId() throws IOException {\n         entry.setField(StandardField.EPRINT, \"1234.12345\");\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextByDOINotAvailableInCatalog() throws IOException {\n         entry.setField(StandardField.DOI, \"10.1016/0370-2693(77)90015-6\");\n         entry.setField(StandardField.TITLE, \"Superspace formulation of supergravity\");\n \n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextEntityWithoutDoi() throws IOException {\n-        assertEquals(Optional.empty(), finder.findFullText(entry));\n+        assertEquals(Optional.empty(), fetcher.findFullText(entry));\n     }\n \n     @Test\n     void findFullTextTrustLevel() {\n-        assertEquals(TrustLevel.PREPRINT, finder.getTrustLevel());\n+        assertEquals(TrustLevel.PREPRINT, fetcher.getTrustLevel());\n     }\n \n     @Test\n     void searchEntryByPartOfTitle() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Frechet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByPartOfTitleWithAcuteAccent() throws Exception {\n         assertEquals(Collections.singletonList(sliceTheoremPaper),\n-                finder.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n+                fetcher.performSearch(\"ti:\\\"slice theorem for Fr\u00e9chet\\\"\"));\n     }\n \n     @Test\n     void searchEntryByOldId() throws Exception {\n-        BibEntry expected = new BibEntry();\n-        expected.setType(StandardEntryType.Article);\n-        expected.setField(StandardField.AUTHOR, \"H1 Collaboration\");\n-        expected.setField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\");\n-        expected.setField(StandardField.DATE, \"2003-07-07\");\n-        expected.setField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\");\n-        expected.setField(StandardField.EPRINT, \"hep-ex/0307015\");\n-        expected.setField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\");\n-        expected.setField(StandardField.EPRINTTYPE, \"arXiv\");\n-        expected.setField(StandardField.EPRINTCLASS, \"hep-ex\");\n-        expected.setField(StandardField.KEYWORDS, \"hep-ex\");\n-        expected.setField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\");\n-        expected.setField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n-\n-        assertEquals(Optional.of(expected), finder.performSearchById(\"hep-ex/0307015\"));\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"H1 Collaboration\")\n+                .withField(StandardField.TITLE, \"Multi-Electron Production at High Transverse Momenta in ep Collisions at HERA\")\n+                .withField(StandardField.DATE, \"2003-07-07\")\n+                .withField(StandardField.ABSTRACT, \"Multi-electron production is studied at high electron transverse momentum in positron- and electron-proton collisions using the H1 detector at HERA. The data correspond to an integrated luminosity of 115 pb-1. Di-electron and tri-electron event yields are measured. Cross sections are derived in a restricted phase space region dominated by photon-photon collisions. In general good agreement is found with the Standard Model predictions. However, for electron pair invariant masses above 100 GeV, three di-electron events and three tri-electron events are observed, compared to Standard Model expectations of 0.30 \\\\pm 0.04 and 0.23 \\\\pm 0.04, respectively.\")\n+                .withField(StandardField.EPRINT, \"hep-ex/0307015\")\n+                .withField(StandardField.FILE, \":http\\\\://arxiv.org/pdf/hep-ex/0307015v1:PDF\")\n+                .withField(StandardField.EPRINTTYPE, \"arXiv\")\n+                .withField(StandardField.EPRINTCLASS, \"hep-ex\")\n+                .withField(StandardField.KEYWORDS, \"hep-ex\")\n+                .withField(StandardField.DOI, \"10.1140/epjc/s2003-01326-x\")\n+                .withField(StandardField.JOURNALTITLE, \"Eur.Phys.J.C31:17-29,2003\");\n+\n+        assertEquals(Optional.of(expected), fetcher.performSearchById(\"hep-ex/0307015\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndVersion() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249v1\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249v1\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4Digits() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefix() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv:1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv:1405.2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith4DigitsAndPrefixAndNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"arXiv : 1405. 2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"arXiv : 1405. 2249\"));\n     }\n \n     @Test\n     void searchEntryByIdWith5Digits() throws Exception {\n         assertEquals(Optional.of(\n                 \"An Optimal Convergence Theorem for Mean Curvature Flow of Arbitrary Codimension in Hyperbolic Spaces\"),\n-                finder.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n+                fetcher.performSearchById(\"1503.06747\").flatMap(entry -> entry.getField(StandardField.TITLE)));\n     }\n \n     @Test\n     void searchWithMalformedIdThrowsException() throws Exception {\n-        assertThrows(FetcherException.class, () -> finder.performSearchById(\"123412345\"));\n+        assertThrows(FetcherException.class, () -> fetcher.performSearchById(\"123412345\"));\n     }\n \n     @Test\n     void searchIdentifierForSlicePaper() throws Exception {\n         sliceTheoremPaper.clearField(StandardField.EPRINT);\n \n-        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), finder.findIdentifier(sliceTheoremPaper));\n+        assertEquals(ArXivIdentifier.parse(\"1405.2249\"), fetcher.findIdentifier(sliceTheoremPaper));\n     }\n \n     @Test\n     void searchEmptyId() throws Exception {\n-        assertEquals(Optional.empty(), finder.performSearchById(\"\"));\n+        assertEquals(Optional.empty(), fetcher.performSearchById(\"\"));\n     }\n \n     @Test\n     void searchWithHttpUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"http://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrl() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https://arxiv.org/abs/1405.2249\"));\n     }\n \n     @Test\n     void searchWithHttpsUrlNotTrimmed() throws Exception {\n-        assertEquals(Optional.of(sliceTheoremPaper), finder.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+        assertEquals(Optional.of(sliceTheoremPaper), fetcher.performSearchById(\"https : // arxiv . org / abs / 1405 . 2249 \"));\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        List<BibEntry> results = fetcher.performSearch(\"au:\\\"Tobias Diez\\\"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ4ODUwOA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 279}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDcyMzY0OnYy", "diffSide": "RIGHT", "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "isResolved": true, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjo0MjowNlrOGxcEzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxODowNTozNVrOGyJzew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA==", "bodyText": "I don't think it's a good strategy to have a test interface. As you have already noted not every fetcher supports all of these fields, and it is also not possible to make sure that the tests defined by this interface are consistent across the fetchers.\nWhat would make more sense is to have tests (against the interface itself) that checks that all implementing classes perform the same under certain conditions (e.g. empty query results in empty result etc). Personally I would restrict those general tests to simple test situations, although it should be possible to use parameterized tests to also check for more complex scenarios.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454493388", "createdAt": "2020-07-14T16:42:06Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzNjg1NA==", "bodyText": "These tests are more low-level. That was tried to be explained there:\n\nHere, I am systematically evaluating the capabilities of fetchers. This is a) for documentation in code b) to check whether the fetchers change their capability over time. I accept that tests may fail due to changing external services.\n\n\"documentation as code\"\nThe screnario explained by you builds on the \"results\" of these tests. These test ensure that the idea of \"your\" tests can be implemented.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454936854", "createdAt": "2020-07-15T10:00:48Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkzOTM5NA==", "bodyText": "In other words: Instead of documenting the features of a fetcher in markdown, Google Docs, Latex,  PDF or JavaDoc, the documentation is put as code. This ensures that one implementation aspect (query synatx) is checked, changes of the capabilities are detected at the level.of the query and that the list of capabilities (avail/unavail) are noted down as test case.\nWhen documenting in Markdown (or other text), a programmer has to update the documentation in case a capability changes. It is open who enforces this (e.g., do the reviewers know that there is documentation somewhere?) - With the \"documentation as code\" approach, the programmer is forced to update the documentation", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454939394", "createdAt": "2020-07-15T10:05:15Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1MDIyNQ==", "bodyText": "I'm in favor of adding these tests, but I don't see the value of the test interface. The interface methods don't say anything about the actual contract that the fetcher has to satisfy. At most they serve as a reminder to test certain aspects of the fetcher.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454950225", "createdAt": "2020-07-15T10:25:44Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk2OTI5MA==", "bodyText": "Therefore, more tests covering the contract will come in. These tests are one level above the current ones. This here is like testing Java Byte Code, the next tests will tests Java Code", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454969290", "createdAt": "2020-07-15T11:02:46Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3MzA2Mw==", "bodyText": "Will be a \"research\" effort to compare the semantics. E.g. is \"year\" really the same for each fetcher? Submission date versus published date. - Is \"journal\" the same thing for all.\nWe can surely work on that. Then the PR will posaibly be ready in September if all other parts of the Theiss are finished.\nWith that, I surely accept that there might be changes in the future . They definitely need to be discussed.\nThe idea is to have rather small PRs than 10kLOC to review as a whole in September.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454973063", "createdAt": "2020-07-15T11:10:24Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk5ODc0NA==", "bodyText": "As I said above, the idea of the tests is good. I also agree with many small PRs instead of a big one.\nBut can you please explain to me what the advantages of the test interface are? The test interface is never used (only implemented), thus from an abstract object-oriented view it's meaningless, right?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454998744", "createdAt": "2020-07-15T12:02:16Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTA1MjcwMw==", "bodyText": "Implementation-only is also valid from oo perspective. The alternative would be an abstract class. In the concrete case,  the test classes implementing the interface implement also more tests. The interface just documents that the respective tests are implemented for the concrete fetcher. Documentation as code (answering the question for which fetchers a capability test is implemented)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r455052703", "createdAt": "2020-07-15T13:30:49Z", "author": {"login": "koppor"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI0MjYxOQ==", "bodyText": "I strongly prefer that the interface adds real tests and not just serves as a reminder. See for example the StringTest at the end of https://junit.org/junit5/docs/current/user-guide/#writing-tests-test-interfaces-and-default-methods. There the ComparableTest interface really defines how the object under test behaves. The implementing classes then only have to provide the correct input/output variables.\nFor now we can keep the simple interface, but this should be really improved as the project continuous.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r455242619", "createdAt": "2020-07-15T18:05:35Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SearchBasedFetcherCapabilityTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import org.junit.jupiter.api.Test;\n+\n+/**\n+ * Defines the set of capability tests that each tests a given search capability, e.g. author based search.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5MzM4OA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDcyNjg3OnYy", "diffSide": "RIGHT", "path": "src/test/java/org/jabref/logic/importer/fetcher/SpringerFetcherTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjo0Mjo1N1rOGxcGyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjo0Mjo1N1rOGxcGyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5Mzg5Ng==", "bodyText": "remove empty line (here and at a few other instances).", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454493896", "createdAt": "2020-07-14T16:42:57Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SpringerFetcherTest.java", "diffHunk": "@@ -78,4 +82,110 @@ void testSpringerJSONToBibtex() {\n     void searchByEmptyQueryFindsNothing() throws Exception {\n         assertEquals(Collections.emptyList(), fetcher.performSearch(\"\"));\n     }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Steinmacher, Igor and Gerosa, Marco and Conte, Tayana U. and Redmiles, David F.\")\n+                .withField(StandardField.DATE, \"2019-04-15\")\n+                .withField(StandardField.DOI, \"10.1007/s10606-018-9335-z\")\n+                .withField(StandardField.ISSN, \"0925-9724\")\n+                .withField(StandardField.JOURNAL, \"Computer Supported Cooperative Work (CSCW)\")\n+                .withField(StandardField.MONTH, \"#apr#\")\n+                .withField(StandardField.PAGES, \"247--290\")\n+                .withField(StandardField.NUMBER, \"1-2\")\n+                .withField(StandardField.VOLUME, \"28\")\n+                .withField(StandardField.PUBLISHER, \"Springer\")\n+                .withField(StandardField.TITLE, \"Overcoming Social Barriers When Contributing to Open Source Software Projects\")\n+                .withField(StandardField.YEAR, \"2019\")\n+                .withField(StandardField.FILE, \"online:http\\\\://link.springer.com/openurl/pdf?id=doi\\\\:10.1007/s10606-018-9335-z:PDF\")\n+                .withField(StandardField.ABSTRACT, \"An influx of newcomers is critical to the survival, long-term success, and continuity of many Open Source Software (OSS) community-based projects. However, newcomers face many barriers when making their first contribution, leading in many cases to dropouts. Due to the collaborative nature of community-based OSS projects, newcomers may be susceptible to social barriers, such as communication breakdowns and reception issues. In this article, we report a two-phase study aimed at better understanding social barriers faced by newcomers. In the first phase, we qualitatively analyzed the literature and data collected from practitioners to identify barriers that hinder newcomers\u2019 first contribution. We designed a model composed of 58 barriers, including 13 social barriers. In the second phase, based on the barriers model, we developed FLOSScoach, a portal to support newcomers making their first contribution. We evaluated the portal in a diary-based study and found that the portal guided the newcomers and reduced the need for communication. Our results provide insights for communities that want to support newcomers and lay a foundation for building better onboarding tools. The contributions of this paper include identifying and gathering empirical evidence of social barriers faced by newcomers; understanding how social barriers can be reduced or avoided by using a portal that organizes proper information for newcomers (FLOSScoach); presenting guidelines for communities and newcomers on how to reduce or avoid social barriers; and identifying new streams of research.\");\n+\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND name:\\\"Conte, Tayana U.\\\"\");\n+\n+        Assertions.assertEquals(Collections.singletonList(expected), result);\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsYearSearch() throws Exception {\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND year:2014\");\n+\n+        // There are 3 papers published by Igor Steinmacher and Marco Gerosa in 2014.\n+        assertEquals(3, result.size());\n+        long publicationsIn2014 = result.stream()\n+                                        .map(bibEntry -> bibEntry.getField(StandardField.YEAR))\n+                                        .filter(Optional::isPresent)\n+                                        .map(Optional::get)\n+                                        .filter(s -> s.equals(\"2014\"))\n+                                        .count();\n+        assertEquals(3, publicationsIn2014);\n+    }\n+\n+    @Test\n+    @Disabled(\"Is not natively supported by the API, can be emulated by multiple single year searches.\")\n+    @Override\n+    public void supportsYearRangeSearch() throws Exception {\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsJournalSearch() throws Exception {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNDczNTIwOnYy", "diffSide": "RIGHT", "path": "src/test/java/org/jabref/logic/importer/fetcher/SpringerFetcherTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxNjo0NTowN1rOGxcMOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwOTo0NzoxMlrOGx2piA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5NTI5MA==", "bodyText": "I think an assertion is missing here, moreover it seems Assert.equals(Collection.singleton(\"Clinical...\"), result) is what were looking for.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454495290", "createdAt": "2020-07-14T16:45:07Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SpringerFetcherTest.java", "diffHunk": "@@ -78,4 +82,110 @@ void testSpringerJSONToBibtex() {\n     void searchByEmptyQueryFindsNothing() throws Exception {\n         assertEquals(Collections.emptyList(), fetcher.performSearch(\"\"));\n     }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Steinmacher, Igor and Gerosa, Marco and Conte, Tayana U. and Redmiles, David F.\")\n+                .withField(StandardField.DATE, \"2019-04-15\")\n+                .withField(StandardField.DOI, \"10.1007/s10606-018-9335-z\")\n+                .withField(StandardField.ISSN, \"0925-9724\")\n+                .withField(StandardField.JOURNAL, \"Computer Supported Cooperative Work (CSCW)\")\n+                .withField(StandardField.MONTH, \"#apr#\")\n+                .withField(StandardField.PAGES, \"247--290\")\n+                .withField(StandardField.NUMBER, \"1-2\")\n+                .withField(StandardField.VOLUME, \"28\")\n+                .withField(StandardField.PUBLISHER, \"Springer\")\n+                .withField(StandardField.TITLE, \"Overcoming Social Barriers When Contributing to Open Source Software Projects\")\n+                .withField(StandardField.YEAR, \"2019\")\n+                .withField(StandardField.FILE, \"online:http\\\\://link.springer.com/openurl/pdf?id=doi\\\\:10.1007/s10606-018-9335-z:PDF\")\n+                .withField(StandardField.ABSTRACT, \"An influx of newcomers is critical to the survival, long-term success, and continuity of many Open Source Software (OSS) community-based projects. However, newcomers face many barriers when making their first contribution, leading in many cases to dropouts. Due to the collaborative nature of community-based OSS projects, newcomers may be susceptible to social barriers, such as communication breakdowns and reception issues. In this article, we report a two-phase study aimed at better understanding social barriers faced by newcomers. In the first phase, we qualitatively analyzed the literature and data collected from practitioners to identify barriers that hinder newcomers\u2019 first contribution. We designed a model composed of 58 barriers, including 13 social barriers. In the second phase, based on the barriers model, we developed FLOSScoach, a portal to support newcomers making their first contribution. We evaluated the portal in a diary-based study and found that the portal guided the newcomers and reduced the need for communication. Our results provide insights for communities that want to support newcomers and lay a foundation for building better onboarding tools. The contributions of this paper include identifying and gathering empirical evidence of social barriers faced by newcomers; understanding how social barriers can be reduced or avoided by using a portal that organizes proper information for newcomers (FLOSScoach); presenting guidelines for communities and newcomers on how to reduce or avoid social barriers; and identifying new streams of research.\");\n+\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND name:\\\"Conte, Tayana U.\\\"\");\n+\n+        Assertions.assertEquals(Collections.singletonList(expected), result);\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsYearSearch() throws Exception {\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND year:2014\");\n+\n+        // There are 3 papers published by Igor Steinmacher and Marco Gerosa in 2014.\n+        assertEquals(3, result.size());\n+        long publicationsIn2014 = result.stream()\n+                                        .map(bibEntry -> bibEntry.getField(StandardField.YEAR))\n+                                        .filter(Optional::isPresent)\n+                                        .map(Optional::get)\n+                                        .filter(s -> s.equals(\"2014\"))\n+                                        .count();\n+        assertEquals(3, publicationsIn2014);\n+    }\n+\n+    @Test\n+    @Disabled(\"Is not natively supported by the API, can be emulated by multiple single year searches.\")\n+    @Override\n+    public void supportsYearRangeSearch() throws Exception {\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsJournalSearch() throws Exception {\n+\n+        List<BibEntry> result = fetcher.performSearch(\"journalid:392\");\n+        List<String> resultEntriesJournals = result.stream()\n+                                                   .map(bibEntry -> bibEntry.getField(StandardField.JOURNAL))\n+                                                   .filter(Optional::isPresent)\n+                                                   .map(Optional::get)\n+                                                   .collect(Collectors.toList());\n+\n+        // Ensure no entries without a journal field were returned\n+        assertEquals(result.size(), resultEntriesJournals.size());\n+        resultEntriesJournals.forEach(journal -> journal.equals(\"Clinical Research in Cardiology\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyODc3Ng==", "bodyText": "Thanks, I added the missing assert and modified the test.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r454928776", "createdAt": "2020-07-15T09:47:12Z", "author": {"login": "DominikVoigt"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/SpringerFetcherTest.java", "diffHunk": "@@ -78,4 +82,110 @@ void testSpringerJSONToBibtex() {\n     void searchByEmptyQueryFindsNothing() throws Exception {\n         assertEquals(Collections.emptyList(), fetcher.performSearch(\"\"));\n     }\n+\n+    @Test\n+    @Override\n+    public void supportsAuthorSearch() throws Exception {\n+        BibEntry expected = new BibEntry(StandardEntryType.Article)\n+                .withField(StandardField.AUTHOR, \"Steinmacher, Igor and Gerosa, Marco and Conte, Tayana U. and Redmiles, David F.\")\n+                .withField(StandardField.DATE, \"2019-04-15\")\n+                .withField(StandardField.DOI, \"10.1007/s10606-018-9335-z\")\n+                .withField(StandardField.ISSN, \"0925-9724\")\n+                .withField(StandardField.JOURNAL, \"Computer Supported Cooperative Work (CSCW)\")\n+                .withField(StandardField.MONTH, \"#apr#\")\n+                .withField(StandardField.PAGES, \"247--290\")\n+                .withField(StandardField.NUMBER, \"1-2\")\n+                .withField(StandardField.VOLUME, \"28\")\n+                .withField(StandardField.PUBLISHER, \"Springer\")\n+                .withField(StandardField.TITLE, \"Overcoming Social Barriers When Contributing to Open Source Software Projects\")\n+                .withField(StandardField.YEAR, \"2019\")\n+                .withField(StandardField.FILE, \"online:http\\\\://link.springer.com/openurl/pdf?id=doi\\\\:10.1007/s10606-018-9335-z:PDF\")\n+                .withField(StandardField.ABSTRACT, \"An influx of newcomers is critical to the survival, long-term success, and continuity of many Open Source Software (OSS) community-based projects. However, newcomers face many barriers when making their first contribution, leading in many cases to dropouts. Due to the collaborative nature of community-based OSS projects, newcomers may be susceptible to social barriers, such as communication breakdowns and reception issues. In this article, we report a two-phase study aimed at better understanding social barriers faced by newcomers. In the first phase, we qualitatively analyzed the literature and data collected from practitioners to identify barriers that hinder newcomers\u2019 first contribution. We designed a model composed of 58 barriers, including 13 social barriers. In the second phase, based on the barriers model, we developed FLOSScoach, a portal to support newcomers making their first contribution. We evaluated the portal in a diary-based study and found that the portal guided the newcomers and reduced the need for communication. Our results provide insights for communities that want to support newcomers and lay a foundation for building better onboarding tools. The contributions of this paper include identifying and gathering empirical evidence of social barriers faced by newcomers; understanding how social barriers can be reduced or avoided by using a portal that organizes proper information for newcomers (FLOSScoach); presenting guidelines for communities and newcomers on how to reduce or avoid social barriers; and identifying new streams of research.\");\n+\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND name:\\\"Conte, Tayana U.\\\"\");\n+\n+        Assertions.assertEquals(Collections.singletonList(expected), result);\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsYearSearch() throws Exception {\n+        List<BibEntry> result = fetcher.performSearch(\"name:\\\"Steinmacher, Igor\\\" AND name:\\\"Gerosa, Marco\\\" AND year:2014\");\n+\n+        // There are 3 papers published by Igor Steinmacher and Marco Gerosa in 2014.\n+        assertEquals(3, result.size());\n+        long publicationsIn2014 = result.stream()\n+                                        .map(bibEntry -> bibEntry.getField(StandardField.YEAR))\n+                                        .filter(Optional::isPresent)\n+                                        .map(Optional::get)\n+                                        .filter(s -> s.equals(\"2014\"))\n+                                        .count();\n+        assertEquals(3, publicationsIn2014);\n+    }\n+\n+    @Test\n+    @Disabled(\"Is not natively supported by the API, can be emulated by multiple single year searches.\")\n+    @Override\n+    public void supportsYearRangeSearch() throws Exception {\n+    }\n+\n+    @Test\n+    @Override\n+    public void supportsJournalSearch() throws Exception {\n+\n+        List<BibEntry> result = fetcher.performSearch(\"journalid:392\");\n+        List<String> resultEntriesJournals = result.stream()\n+                                                   .map(bibEntry -> bibEntry.getField(StandardField.JOURNAL))\n+                                                   .filter(Optional::isPresent)\n+                                                   .map(Optional::get)\n+                                                   .collect(Collectors.toList());\n+\n+        // Ensure no entries without a journal field were returned\n+        assertEquals(result.size(), resultEntriesJournals.size());\n+        resultEntriesJournals.forEach(journal -> journal.equals(\"Clinical Research in Cardiology\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ5NTI5MA=="}, "originalCommit": {"oid": "7c1327581da2d9ba359b7919c4d8df86d9be1133"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzODAxNjg1OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMjowNjoyNlrOGx7DFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNTo0MzoyMVrOGyEM7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAwMDg1NA==", "bodyText": "Can you please have a look how the other getUrl*** methods handle the exception handling. I think they are allowed to simply throw them and the performSearch method then converts it to a FetcherException.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r455000854", "createdAt": "2020-07-15T12:06:26Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -236,4 +229,24 @@ public String getName() {\n     public Optional<HelpFile> getHelpPage() {\n         return Optional.of(HelpFile.FETCHER_IEEEXPLORE);\n     }\n+\n+    @Override\n+    public URL getComplexQueryURL(ComplexSearchQuery complexSearchQuery) {\n+        try {\n+            URIBuilder uriBuilder = new URIBuilder(\"https://ieeexploreapi.ieee.org/api/v1/search/articles\");\n+            uriBuilder.addParameter(\"apikey\", API_KEY);\n+            complexSearchQuery.getDefaultField().ifPresent(defaultField -> uriBuilder.addParameter(\"querytext\", defaultField));\n+            complexSearchQuery.getAuthor().ifPresent(author -> uriBuilder.addParameter(\"author\", author));\n+            complexSearchQuery.getTitle().ifPresent(articleTitle -> uriBuilder.addParameter(\"article_title\", articleTitle));\n+            complexSearchQuery.getJournal().ifPresent(journalTitle -> uriBuilder.addParameter(\"publication_title\", journalTitle));\n+            complexSearchQuery.getFromYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"start_year\", year));\n+            complexSearchQuery.getToYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"end_year\", year));\n+\n+            URLDownload.bypassSSLVerification();\n+            return uriBuilder.build().toURL();\n+        } catch (URISyntaxException | MalformedURLException ex) {\n+            LOGGER.error(\"Error creating URL.\", ex);\n+            throw new IllegalStateException(\"Error during creation of URL.\", ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db19e60100f253a9a5654254d9be0d12a98e1c82"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTA1MzkwOQ==", "bodyText": "Oh, the comment was missing here. The assumption was that per definition, this exception will never raised. Neverheless +1 for consistency \ud83d\ude05", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r455053909", "createdAt": "2020-07-15T13:32:37Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -236,4 +229,24 @@ public String getName() {\n     public Optional<HelpFile> getHelpPage() {\n         return Optional.of(HelpFile.FETCHER_IEEEXPLORE);\n     }\n+\n+    @Override\n+    public URL getComplexQueryURL(ComplexSearchQuery complexSearchQuery) {\n+        try {\n+            URIBuilder uriBuilder = new URIBuilder(\"https://ieeexploreapi.ieee.org/api/v1/search/articles\");\n+            uriBuilder.addParameter(\"apikey\", API_KEY);\n+            complexSearchQuery.getDefaultField().ifPresent(defaultField -> uriBuilder.addParameter(\"querytext\", defaultField));\n+            complexSearchQuery.getAuthor().ifPresent(author -> uriBuilder.addParameter(\"author\", author));\n+            complexSearchQuery.getTitle().ifPresent(articleTitle -> uriBuilder.addParameter(\"article_title\", articleTitle));\n+            complexSearchQuery.getJournal().ifPresent(journalTitle -> uriBuilder.addParameter(\"publication_title\", journalTitle));\n+            complexSearchQuery.getFromYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"start_year\", year));\n+            complexSearchQuery.getToYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"end_year\", year));\n+\n+            URLDownload.bypassSSLVerification();\n+            return uriBuilder.build().toURL();\n+        } catch (URISyntaxException | MalformedURLException ex) {\n+            LOGGER.error(\"Error creating URL.\", ex);\n+            throw new IllegalStateException(\"Error during creation of URL.\", ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAwMDg1NA=="}, "originalCommit": {"oid": "db19e60100f253a9a5654254d9be0d12a98e1c82"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE1MDgyOQ==", "bodyText": "I changed this to be consistent with the other getURL methods.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r455150829", "createdAt": "2020-07-15T15:43:21Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -236,4 +229,24 @@ public String getName() {\n     public Optional<HelpFile> getHelpPage() {\n         return Optional.of(HelpFile.FETCHER_IEEEXPLORE);\n     }\n+\n+    @Override\n+    public URL getComplexQueryURL(ComplexSearchQuery complexSearchQuery) {\n+        try {\n+            URIBuilder uriBuilder = new URIBuilder(\"https://ieeexploreapi.ieee.org/api/v1/search/articles\");\n+            uriBuilder.addParameter(\"apikey\", API_KEY);\n+            complexSearchQuery.getDefaultField().ifPresent(defaultField -> uriBuilder.addParameter(\"querytext\", defaultField));\n+            complexSearchQuery.getAuthor().ifPresent(author -> uriBuilder.addParameter(\"author\", author));\n+            complexSearchQuery.getTitle().ifPresent(articleTitle -> uriBuilder.addParameter(\"article_title\", articleTitle));\n+            complexSearchQuery.getJournal().ifPresent(journalTitle -> uriBuilder.addParameter(\"publication_title\", journalTitle));\n+            complexSearchQuery.getFromYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"start_year\", year));\n+            complexSearchQuery.getToYear().map(String::valueOf).ifPresent(year -> uriBuilder.addParameter(\"end_year\", year));\n+\n+            URLDownload.bypassSSLVerification();\n+            return uriBuilder.build().toURL();\n+        } catch (URISyntaxException | MalformedURLException ex) {\n+            LOGGER.error(\"Error creating URL.\", ex);\n+            throw new IllegalStateException(\"Error during creation of URL.\", ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAwMDg1NA=="}, "originalCommit": {"oid": "db19e60100f253a9a5654254d9be0d12a98e1c82"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MDY1ODc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxMDowMTowOFrOG2p3yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTozNVrOG6gPHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2MjMxMw==", "bodyText": "If these changes are approved this localized text has to be adapted", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r459962313", "createdAt": "2020-07-24T10:01:08Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "diffHunk": "@@ -520,15 +520,17 @@ private void regenerateCitationKeys(List<ParserResult> loaded) {\n      * @return A parser result containing the entries fetched or null if an error occurred.\n      */\n     private Optional<ParserResult> fetch(String fetchCommand) {\n-        if ((fetchCommand == null) || !fetchCommand.contains(\":\")) {\n-            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>'\"));\n+        if ((fetchCommand == null) || !fetchCommand.contains(\":\") ||\n+                !(fetchCommand.toLowerCase().endsWith(\":bibtex\") || fetchCommand.toLowerCase().endsWith(\":biblatex\"))) {\n+            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>:<bib entry format>'\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f675e132a9eb7e3c1cef3f08aaddff673722fae6"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODc1MA==", "bodyText": "Due to the decision in ADR-0012, this hole change is obsolete? --> git checkout upstream/master -- src/main/java/org/jabref/cli/ArgumentProcessor.java (to revert the changes in this file)\n(If not, there should be a default mode, if possible, the mode of the bibdatabase should be used)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998750", "createdAt": "2020-08-01T20:45:35Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "diffHunk": "@@ -520,15 +520,17 @@ private void regenerateCitationKeys(List<ParserResult> loaded) {\n      * @return A parser result containing the entries fetched or null if an error occurred.\n      */\n     private Optional<ParserResult> fetch(String fetchCommand) {\n-        if ((fetchCommand == null) || !fetchCommand.contains(\":\")) {\n-            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>'\"));\n+        if ((fetchCommand == null) || !fetchCommand.contains(\":\") ||\n+                !(fetchCommand.toLowerCase().endsWith(\":bibtex\") || fetchCommand.toLowerCase().endsWith(\":biblatex\"))) {\n+            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>:<bib entry format>'\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2MjMxMw=="}, "originalCommit": {"oid": "f675e132a9eb7e3c1cef3f08aaddff673722fae6"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxMTMyOnYy", "diffSide": "RIGHT", "path": "docs/adr/0013-how-to-provide-fetchers-with-import-format.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTozOVrOG6gPKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTozOVrOG6gPKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODc2MA==", "bodyText": "I think, this ADR is obsolete, isn't it? (Because of ADR-0012)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998760", "createdAt": "2020-08-01T20:45:39Z", "author": {"login": "koppor"}, "path": "docs/adr/0013-how-to-provide-fetchers-with-import-format.md", "diffHunk": "@@ -0,0 +1,32 @@\n+# How to provide fetchers with import format", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxMTQ4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTo1MVrOG6gPOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTo1MVrOG6gPOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODc3OA==", "bodyText": "This variable is obsolete, isn't it?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998778", "createdAt": "2020-08-01T20:45:51Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "diffHunk": "@@ -520,15 +520,17 @@ private void regenerateCitationKeys(List<ParserResult> loaded) {\n      * @return A parser result containing the entries fetched or null if an error occurred.\n      */\n     private Optional<ParserResult> fetch(String fetchCommand) {\n-        if ((fetchCommand == null) || !fetchCommand.contains(\":\")) {\n-            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>'\"));\n+        if ((fetchCommand == null) || !fetchCommand.contains(\":\") ||\n+                !(fetchCommand.toLowerCase().endsWith(\":bibtex\") || fetchCommand.toLowerCase().endsWith(\":biblatex\"))) {\n+            System.out.println(Localization.lang(\"Expected syntax for --fetch='<name of fetcher>:<query>:<bib entry format>'\"));\n             System.out.println(Localization.lang(\"The following fetchers are available:\"));\n             return Optional.empty();\n         }\n \n         String[] split = fetchCommand.split(\":\");\n         String engine = split[0];\n         String query = split[1];\n+        String bibFormat = split[2].toLowerCase();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxMTUyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTo1OFrOG6gPQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0NTo1OFrOG6gPQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODc4NQ==", "bodyText": "Just keep it in one line", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998785", "createdAt": "2020-08-01T20:45:58Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/cli/ArgumentProcessor.java", "diffHunk": "@@ -545,7 +547,8 @@ private void regenerateCitationKeys(List<ParserResult> loaded) {\n             System.out.println(Localization.lang(\"Running query '%0' with fetcher '%1'.\", query, engine));\n             System.out.print(Localization.lang(\"Please wait...\"));\n             try {\n-                List<BibEntry> matches = selectedFetcher.get().performSearch(query);\n+                List<BibEntry> matches = selectedFetcher.get().performSearch(query", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxMjcyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/EntryBasedParserFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0Nzo1MlrOG6gPxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0Nzo1MlrOG6gPxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODkxOQ==", "bodyText": "I think, the location in the code can be kept --> git checkoupt upstream/master -- src/main/java/org/jabref/logic/importer/EntryBasedParserFetcher.java", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998919", "createdAt": "2020-08-01T20:47:52Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/EntryBasedParserFetcher.java", "diffHunk": "@@ -69,4 +52,21 @@ default void doPostCleanup(BibEntry entry) {\n             throw new FetcherException(\"An internal parser error occurred\", e);\n         }\n     }\n+\n+    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxMjk4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/IdBasedParserFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0ODozMlrOG6gP5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo0ODozMlrOG6gP5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5ODk1MA==", "bodyText": "Pleaes move to the original location (maybe reset to the original format and add the newline at line 76 afterwards)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463998950", "createdAt": "2020-08-01T20:48:32Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/IdBasedParserFetcher.java", "diffHunk": "@@ -87,4 +69,21 @@ default void doPostCleanup(BibEntry entry) {\n             throw new FetcherException(\"An internal parser error occurred\", e);\n         }\n     }\n+\n+    /**", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxNDMzOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/CiteSeer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1MDoxNlrOG6gQeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1MDoxNlrOG6gQeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTA5OA==", "bodyText": "Please use Logger.debug() or remove this line", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463999098", "createdAt": "2020-08-01T20:50:16Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/CiteSeer.java", "diffHunk": "@@ -59,7 +59,7 @@ public Parser getParser() {\n         // So we extract the data string from the <span class=\"Z3988\" title=\"<data>\"></span> tags and pass the content to the COinS parser\n         return inputStream -> {\n             String response = new BufferedReader(new InputStreamReader(inputStream)).lines().collect(Collectors.joining(OS.NEWLINE));\n-\n+            System.out.println(response);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxNjEyOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/CompositeSearchBasedFetcher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1MzoxOVrOG6gRWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjozODo0NFrOG6gv5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTMyMA==", "bodyText": "Can't the cleanup be done right after .limit? If it's not easy, maybe add .forEach after the .collect and initialize the converter before the result variable?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463999320", "createdAt": "2020-08-01T20:53:19Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/CompositeSearchBasedFetcher.java", "diffHunk": "@@ -35,16 +36,19 @@ public CompositeSearchBasedFetcher(Set<SearchBasedFetcher> searchBasedFetchers,\n \n     @Override\n     public List<BibEntry> performSearch(String query) {\n-        return fetchers.stream().flatMap(searchBasedFetcher -> {\n+        List<BibEntry> result = fetchers.parallelStream().flatMap(searchBasedFetcher -> {\n             try {\n                 return searchBasedFetcher.performSearch(query).stream();\n             } catch (FetcherException e) {\n                 LOGGER.warn(String.format(\"%s API request failed\", searchBasedFetcher.getName()), e);\n                 return Stream.empty();\n             }\n-        }).parallel()\n-          .limit(maximumNumberOfReturnedResults)\n-          .collect(Collectors.toList());\n+        }).limit(maximumNumberOfReturnedResults)\n+                                        .collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNzE0Mw==", "bodyText": "Shouldn't this cleanup actually be removed / replaced by the import cleanup process?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464007143", "createdAt": "2020-08-01T22:38:44Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/CompositeSearchBasedFetcher.java", "diffHunk": "@@ -35,16 +36,19 @@ public CompositeSearchBasedFetcher(Set<SearchBasedFetcher> searchBasedFetchers,\n \n     @Override\n     public List<BibEntry> performSearch(String query) {\n-        return fetchers.stream().flatMap(searchBasedFetcher -> {\n+        List<BibEntry> result = fetchers.parallelStream().flatMap(searchBasedFetcher -> {\n             try {\n                 return searchBasedFetcher.performSearch(query).stream();\n             } catch (FetcherException e) {\n                 LOGGER.warn(String.format(\"%s API request failed\", searchBasedFetcher.getName()), e);\n                 return Stream.empty();\n             }\n-        }).parallel()\n-          .limit(maximumNumberOfReturnedResults)\n-          .collect(Collectors.toList());\n+        }).limit(maximumNumberOfReturnedResults)\n+                                        .collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTMyMA=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxNjc0OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/DoiFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1NDoxMlrOG6gRoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1NDoxMlrOG6gRoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTM5Mw==", "bodyText": "This really has to be public?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463999393", "createdAt": "2020-08-01T20:54:12Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/DoiFetcher.java", "diffHunk": "@@ -89,7 +88,7 @@ public String getName() {\n         }\n     }\n \n-    private void doPostCleanup(BibEntry entry) {\n+    public void doPostCleanup(BibEntry entry) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQxODc2OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMDo1Njo1MFrOG6gSjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQyMDowMDoxMVrOG6nfOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTYyOA==", "bodyText": "This needs to be discused -> maybe in a separate PR?\nThe LinkedFile points to a file locally stored. Not to a URL. -- Maybe, just use the URL field of the BibEntry. Or use the URLDownloader to download and store the file. (Needs some investigation how JabRef downloads the file; since JabRef does some rename and folder-sort-magic)", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r463999628", "createdAt": "2020-08-01T20:56:50Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -115,7 +106,11 @@ private static BibEntry parseJsonRespone(JSONObject jsonEntry, Character keyword\n         entry.setField(StandardField.ISBN, jsonEntry.optString(\"isbn\"));\n         entry.setField(StandardField.ISSN, jsonEntry.optString(\"issn\"));\n         entry.setField(StandardField.ISSUE, jsonEntry.optString(\"issue\"));\n-        entry.addFile(new LinkedFile(\"\", Path.of(jsonEntry.optString(\"pdf_url\")), \"PDF\"));\n+        try {\n+            entry.addFile(new LinkedFile(new URL(jsonEntry.optString(\"pdf_url\")), \"PDF\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwMzEzMA==", "bodyText": "Linked files can also contain an online link.\nHowever in this case I would set the URL field with the pdf url.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464003130", "createdAt": "2020-08-01T21:43:43Z", "author": {"login": "Siedlerchr"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -115,7 +106,11 @@ private static BibEntry parseJsonRespone(JSONObject jsonEntry, Character keyword\n         entry.setField(StandardField.ISBN, jsonEntry.optString(\"isbn\"));\n         entry.setField(StandardField.ISSN, jsonEntry.optString(\"issn\"));\n         entry.setField(StandardField.ISSUE, jsonEntry.optString(\"issue\"));\n-        entry.addFile(new LinkedFile(\"\", Path.of(jsonEntry.optString(\"pdf_url\")), \"PDF\"));\n+        try {\n+            entry.addFile(new LinkedFile(new URL(jsonEntry.optString(\"pdf_url\")), \"PDF\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTYyOA=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNzMwMQ==", "bodyText": "I think this is correct: the url for the download of the fulltetx should be added as a linked file.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464007301", "createdAt": "2020-08-01T22:40:41Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -115,7 +106,11 @@ private static BibEntry parseJsonRespone(JSONObject jsonEntry, Character keyword\n         entry.setField(StandardField.ISBN, jsonEntry.optString(\"isbn\"));\n         entry.setField(StandardField.ISSN, jsonEntry.optString(\"issn\"));\n         entry.setField(StandardField.ISSUE, jsonEntry.optString(\"issue\"));\n-        entry.addFile(new LinkedFile(\"\", Path.of(jsonEntry.optString(\"pdf_url\")), \"PDF\"));\n+        try {\n+            entry.addFile(new LinkedFile(new URL(jsonEntry.optString(\"pdf_url\")), \"PDF\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTYyOA=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNzU2Mw==", "bodyText": "Did not know this concept. Seemed to be introduced at 5e1adf8. Thus, OK for me.", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464117563", "createdAt": "2020-08-02T20:00:11Z", "author": {"login": "koppor"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/IEEE.java", "diffHunk": "@@ -115,7 +106,11 @@ private static BibEntry parseJsonRespone(JSONObject jsonEntry, Character keyword\n         entry.setField(StandardField.ISBN, jsonEntry.optString(\"isbn\"));\n         entry.setField(StandardField.ISSN, jsonEntry.optString(\"issn\"));\n         entry.setField(StandardField.ISSUE, jsonEntry.optString(\"issue\"));\n-        entry.addFile(new LinkedFile(\"\", Path.of(jsonEntry.optString(\"pdf_url\")), \"PDF\"));\n+        try {\n+            entry.addFile(new LinkedFile(new URL(jsonEntry.optString(\"pdf_url\")), \"PDF\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk5OTYyOA=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3MTI5OnYy", "diffSide": "RIGHT", "path": "docs/adr/0012-handle-different-bibEntry-formats-of-fetchers.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMDo1MlrOG6gqrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMDo1MlrOG6gqrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNTgwNQ==", "bodyText": "Title should be changed", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464005805", "createdAt": "2020-08-01T22:20:52Z", "author": {"login": "tobiasdiez"}, "path": "docs/adr/0012-handle-different-bibEntry-formats-of-fetchers.md", "diffHunk": "@@ -0,0 +1,56 @@\n+# Where to translate the abstract queries", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3MTk4OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/gui/ClipBoardManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMTo0NVrOG6gq-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMTo0NVrOG6gq-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNTg4MQ==", "bodyText": "targetBibEntryFormat is not used", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464005881", "createdAt": "2020-08-01T22:21:45Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/gui/ClipBoardManager.java", "diffHunk": "@@ -201,7 +201,7 @@ public void setContent(List<BibEntry> entries) throws IOException {\n         }\n     }\n \n-    private List<BibEntry> fetchByDOI(DOI doi) {\n+    private List<BibEntry> fetchByDOI(DOI doi, BibDatabaseMode targetBibEntryFormat) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3MjA1OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/gui/bibtexextractor/BibtexExtractorViewModel.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMTo1OFrOG6grAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMTo1OFrOG6grAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNTg5MA==", "bodyText": "also not used I guess", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464005890", "createdAt": "2020-08-01T22:21:58Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/gui/bibtexextractor/BibtexExtractorViewModel.java", "diffHunk": "@@ -41,6 +43,7 @@ public BibtexExtractorViewModel(BibDatabaseContext bibdatabaseContext,\n         this.dialogService = dialogService;\n         currentCitationfetcher = new GrobidCitationFetcher(jabRefPreferences.getImportFormatPreferences());\n         this.taskExecutor = taskExecutor;\n+        this.bibEntryFormat = bibdatabaseContext.getMode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3Mjk3OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/ImportCleanup.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMzozNVrOG6grbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyMzozNVrOG6grbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNTk5Nw==", "bodyText": "I would move the targetBibEntryFormat into a constructor argument", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464005997", "createdAt": "2020-08-01T22:23:35Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/ImportCleanup.java", "diffHunk": "@@ -0,0 +1,29 @@\n+package org.jabref.logic.importer;\n+\n+import java.util.Collection;\n+\n+import org.jabref.logic.cleanup.ConvertToBiblatexCleanup;\n+import org.jabref.logic.cleanup.ConvertToBibtexCleanup;\n+import org.jabref.model.database.BibDatabaseMode;\n+import org.jabref.model.entry.BibEntry;\n+\n+public class ImportCleanup {\n+\n+    /**\n+     * Performs a format conversion of the given entry into the targeted format.\n+     */\n+    public void doPostCleanup(BibEntry entry, BibDatabaseMode targetBibEntryFormat) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3MzI0OnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/SearchBasedFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyNDoxNFrOG6grjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyNDoxNFrOG6grjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNjAyOQ==", "bodyText": "the addition \"in the requested format\" is obsolete now, right?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464006029", "createdAt": "2020-08-01T22:24:14Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/SearchBasedFetcher.java", "diffHunk": "@@ -14,7 +15,18 @@\n      * Looks for hits which are matched by the given free-text query.\n      *\n      * @param query search string\n-     * @return a list of {@link BibEntry}, which are matched by the query (may be empty)\n+     * @return a list of {@link BibEntry}, which are matched by the query (may be empty) in the requested format", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ3MzUzOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/SearchBasedParserFetcher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyNDo0OFrOG6grrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjoyNDo0OFrOG6grrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNjA2MA==", "bodyText": "the old documentation of query should be kept", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464006060", "createdAt": "2020-08-01T22:24:48Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/SearchBasedParserFetcher.java", "diffHunk": "@@ -22,7 +23,6 @@\n \n     /**\n      * Constructs a URL based on the query.\n-     * @param query the search query\n      */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ4MTUxOnYy", "diffSide": "RIGHT", "path": "src/main/java/org/jabref/logic/importer/fetcher/ComplexSearchQuery.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjozNjowN1rOG6gvQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxNDoxMjoyNVrOG6lXnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNjk3Ng==", "bodyText": "Is it really a problem if the user searches for an empty string, e.g. author = \"\"?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464006976", "createdAt": "2020-08-01T22:36:07Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/ComplexSearchQuery.java", "diffHunk": "@@ -0,0 +1,166 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class ComplexSearchQuery {\n+    // Field for non-fielded search\n+    private final String defaultField;\n+    private final List<String> authors;\n+    private final List<String> titlePhrases;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final Integer singleYear;\n+    private final String journal;\n+\n+    private ComplexSearchQuery(String defaultField, List<String> authors, List<String> titlePhrases, Integer fromYear, Integer toYear, Integer singleYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.authors = authors;\n+        this.titlePhrases = titlePhrases;\n+        this.fromYear = fromYear;\n+        // Some APIs do not support, or not fully support, year based search. In these cases, the non applicable parameters are ignored.\n+        this.toYear = toYear;\n+        this.journal = journal;\n+        this.singleYear = singleYear;\n+    }\n+\n+    public Optional<String> getDefaultField() {\n+        return Optional.ofNullable(defaultField);\n+    }\n+\n+    public Optional<List<String>> getAuthors() {\n+        return Optional.ofNullable(authors);\n+    }\n+\n+    public Optional<List<String>> getTitlePhrases() {\n+        return Optional.ofNullable(titlePhrases);\n+    }\n+\n+    public Optional<Integer> getFromYear() {\n+        return Optional.ofNullable(fromYear);\n+    }\n+\n+    public Optional<Integer> getToYear() {\n+        return Optional.ofNullable(toYear);\n+    }\n+\n+    public Optional<Integer> getSingleYear() {\n+        return Optional.ofNullable(singleYear);\n+    }\n+\n+    public Optional<String> getJournal() {\n+        return Optional.ofNullable(journal);\n+    }\n+\n+    public static ComplexSearchQueryBuilder builder() {\n+        return new ComplexSearchQueryBuilder();\n+    }\n+\n+    public static class ComplexSearchQueryBuilder {\n+        private String defaultField;\n+        private List<String> authors;\n+        private List<String> titlePhrases;\n+        private String journal;\n+        private Integer fromYear;\n+        private Integer toYear;\n+        private Integer singleYear;\n+\n+        public ComplexSearchQueryBuilder() {\n+        }\n+\n+        public ComplexSearchQueryBuilder defaultField(String defaultField) {\n+            if (Objects.requireNonNull(defaultField).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");\n+            }\n+            this.defaultField = defaultField;\n+            return this;\n+        }\n+\n+        /**\n+         * Adds author and wraps it in quotes\n+         */\n+        public ComplexSearchQueryBuilder author(String author) {\n+            if (Objects.requireNonNull(author).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDA3MjcxNw==", "bodyText": "Hey :)\nIMHO allowing empty strings for any query parameter does not really make much sense semantically.\nI do not see the semantics such an empty string should have:\n\nIf the user does not want to specify an author, he should just leave the field null\nOtherwise, he tries to searches for documents without authors?\n\nDid I overlook a use case where giving an empty string for a query parameter is useful?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464072717", "createdAt": "2020-08-02T12:41:52Z", "author": {"login": "DominikVoigt"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/ComplexSearchQuery.java", "diffHunk": "@@ -0,0 +1,166 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class ComplexSearchQuery {\n+    // Field for non-fielded search\n+    private final String defaultField;\n+    private final List<String> authors;\n+    private final List<String> titlePhrases;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final Integer singleYear;\n+    private final String journal;\n+\n+    private ComplexSearchQuery(String defaultField, List<String> authors, List<String> titlePhrases, Integer fromYear, Integer toYear, Integer singleYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.authors = authors;\n+        this.titlePhrases = titlePhrases;\n+        this.fromYear = fromYear;\n+        // Some APIs do not support, or not fully support, year based search. In these cases, the non applicable parameters are ignored.\n+        this.toYear = toYear;\n+        this.journal = journal;\n+        this.singleYear = singleYear;\n+    }\n+\n+    public Optional<String> getDefaultField() {\n+        return Optional.ofNullable(defaultField);\n+    }\n+\n+    public Optional<List<String>> getAuthors() {\n+        return Optional.ofNullable(authors);\n+    }\n+\n+    public Optional<List<String>> getTitlePhrases() {\n+        return Optional.ofNullable(titlePhrases);\n+    }\n+\n+    public Optional<Integer> getFromYear() {\n+        return Optional.ofNullable(fromYear);\n+    }\n+\n+    public Optional<Integer> getToYear() {\n+        return Optional.ofNullable(toYear);\n+    }\n+\n+    public Optional<Integer> getSingleYear() {\n+        return Optional.ofNullable(singleYear);\n+    }\n+\n+    public Optional<String> getJournal() {\n+        return Optional.ofNullable(journal);\n+    }\n+\n+    public static ComplexSearchQueryBuilder builder() {\n+        return new ComplexSearchQueryBuilder();\n+    }\n+\n+    public static class ComplexSearchQueryBuilder {\n+        private String defaultField;\n+        private List<String> authors;\n+        private List<String> titlePhrases;\n+        private String journal;\n+        private Integer fromYear;\n+        private Integer toYear;\n+        private Integer singleYear;\n+\n+        public ComplexSearchQueryBuilder() {\n+        }\n+\n+        public ComplexSearchQueryBuilder defaultField(String defaultField) {\n+            if (Objects.requireNonNull(defaultField).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");\n+            }\n+            this.defaultField = defaultField;\n+            return this;\n+        }\n+\n+        /**\n+         * Adds author and wraps it in quotes\n+         */\n+        public ComplexSearchQueryBuilder author(String author) {\n+            if (Objects.requireNonNull(author).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNjk3Ng=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDA4Mjg0NQ==", "bodyText": "Sounds good! I just wanted to double check.\n(We should keep this in the back of our heads when the user interface is implemented. There you would like to show a helping message instead of an error dialog).", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464082845", "createdAt": "2020-08-02T14:12:25Z", "author": {"login": "tobiasdiez"}, "path": "src/main/java/org/jabref/logic/importer/fetcher/ComplexSearchQuery.java", "diffHunk": "@@ -0,0 +1,166 @@\n+package org.jabref.logic.importer.fetcher;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import org.jabref.model.strings.StringUtil;\n+\n+public class ComplexSearchQuery {\n+    // Field for non-fielded search\n+    private final String defaultField;\n+    private final List<String> authors;\n+    private final List<String> titlePhrases;\n+    private final Integer fromYear;\n+    private final Integer toYear;\n+    private final Integer singleYear;\n+    private final String journal;\n+\n+    private ComplexSearchQuery(String defaultField, List<String> authors, List<String> titlePhrases, Integer fromYear, Integer toYear, Integer singleYear, String journal) {\n+        this.defaultField = defaultField;\n+        this.authors = authors;\n+        this.titlePhrases = titlePhrases;\n+        this.fromYear = fromYear;\n+        // Some APIs do not support, or not fully support, year based search. In these cases, the non applicable parameters are ignored.\n+        this.toYear = toYear;\n+        this.journal = journal;\n+        this.singleYear = singleYear;\n+    }\n+\n+    public Optional<String> getDefaultField() {\n+        return Optional.ofNullable(defaultField);\n+    }\n+\n+    public Optional<List<String>> getAuthors() {\n+        return Optional.ofNullable(authors);\n+    }\n+\n+    public Optional<List<String>> getTitlePhrases() {\n+        return Optional.ofNullable(titlePhrases);\n+    }\n+\n+    public Optional<Integer> getFromYear() {\n+        return Optional.ofNullable(fromYear);\n+    }\n+\n+    public Optional<Integer> getToYear() {\n+        return Optional.ofNullable(toYear);\n+    }\n+\n+    public Optional<Integer> getSingleYear() {\n+        return Optional.ofNullable(singleYear);\n+    }\n+\n+    public Optional<String> getJournal() {\n+        return Optional.ofNullable(journal);\n+    }\n+\n+    public static ComplexSearchQueryBuilder builder() {\n+        return new ComplexSearchQueryBuilder();\n+    }\n+\n+    public static class ComplexSearchQueryBuilder {\n+        private String defaultField;\n+        private List<String> authors;\n+        private List<String> titlePhrases;\n+        private String journal;\n+        private Integer fromYear;\n+        private Integer toYear;\n+        private Integer singleYear;\n+\n+        public ComplexSearchQueryBuilder() {\n+        }\n+\n+        public ComplexSearchQueryBuilder defaultField(String defaultField) {\n+            if (Objects.requireNonNull(defaultField).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");\n+            }\n+            this.defaultField = defaultField;\n+            return this;\n+        }\n+\n+        /**\n+         * Adds author and wraps it in quotes\n+         */\n+        public ComplexSearchQueryBuilder author(String author) {\n+            if (Objects.requireNonNull(author).isBlank()) {\n+                throw new IllegalArgumentException(\"Parameter must not be blank\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNjk3Ng=="}, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5NzQ4NTg5OnYy", "diffSide": "RIGHT", "path": "src/test/java/org/jabref/logic/importer/fetcher/CompositeSearchBasedFetcherTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjo0MzozOFrOG6gxUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQyMjo0MzozOFrOG6gxUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDAwNzUwNA==", "bodyText": "Why did you disabled these tests?", "url": "https://github.com/JabRef/jabref/pull/6687#discussion_r464007504", "createdAt": "2020-08-01T22:43:38Z", "author": {"login": "tobiasdiez"}, "path": "src/test/java/org/jabref/logic/importer/fetcher/CompositeSearchBasedFetcherTest.java", "diffHunk": "@@ -26,6 +28,7 @@\n import static org.mockito.Mockito.when;\n \n @FetcherTest\n+@Disabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6eb086acec5c426a2bde6a68bf50f10c5f26b63"}, "originalPosition": 20}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1781, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}