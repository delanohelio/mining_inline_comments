{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NDQzNzY5", "number": 2663, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyMDowOFrODnXoHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwOToxMDoxOVrODpbF_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjA4MTU5OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/io/strimzi/api/kafka/model/status/Status.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyMDowOFrOF1U0rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNDo1MzozNFrOF1iD1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MDAxNA==", "bodyText": "If we're going to the trouble to size the new list why not pass in the number of things which will be added?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391460014", "createdAt": "2020-03-12T08:20:08Z", "author": {"login": "tombentley"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/status/Status.java", "diffHunk": "@@ -45,13 +45,24 @@ public void setConditions(List<Condition> conditions) {\n         this.conditions = conditions;\n     }\n \n-    public void addCondition(Condition condition) {\n+    private List<Condition> prepareConditionsUpdate() {\n         List<Condition> oldConditions = getConditions();\n         List<Condition> newConditions = oldConditions != null ? new ArrayList<>(oldConditions) : new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY3Njg4Nw==", "bodyText": "As the constructor is using an existing list, rather than a size, this looked a bit fiddly to change so I've left it as-is for now.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391676887", "createdAt": "2020-03-12T14:53:34Z", "author": {"login": "dalelane"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/status/Status.java", "diffHunk": "@@ -45,13 +45,24 @@ public void setConditions(List<Condition> conditions) {\n         this.conditions = conditions;\n     }\n \n-    public void addCondition(Condition condition) {\n+    private List<Condition> prepareConditionsUpdate() {\n         List<Condition> oldConditions = getConditions();\n         List<Condition> newConditions = oldConditions != null ? new ArrayList<>(oldConditions) : new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MDAxNA=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjA4ODY5OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyMjo1N1rOF1U5Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNDo1MjoxMlrOF1h_6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MTE5NA==", "bodyText": "Can we factor out a utility method for creating the timestamp (maybe put it in ModelUtils)? Because I know there are at least a few other places where we do this (grep -F '\"yyyy-MM-dd'T'HH:mm:ssZ\"')", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391461194", "createdAt": "2020-03-12T08:22:57Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY3NTg4MQ==", "bodyText": "Nice idea, thanks", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391675881", "createdAt": "2020-03-12T14:52:12Z", "author": {"login": "dalelane"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MTE5NA=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjA5MTE4OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyMzo0N1rOF1U63w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNDo1MTo1OVrOF1h_Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MTU5OQ==", "bodyText": "Can we put this before the member fields?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391461599", "createdAt": "2020-03-12T08:23:47Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY3NTczNQ==", "bodyText": "sure - done", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391675735", "createdAt": "2020-03-12T14:51:59Z", "author": {"login": "dalelane"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MTU5OQ=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjEwMzUxOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyODowMFrOF1VCsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwOToyMjozOVrOF1WsDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MzYwMA==", "bodyText": "IIRC it's possible to have JBOD storage with ephemeral volumes, so I think you need to cover that case too.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391463600", "createdAt": "2020-03-12T08:28:00Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 &&\n+            kafkaCluster.getStorage() != null && Storage.TYPE_EPHEMERAL.equals(kafkaCluster.getStorage().getType())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ5MDU3NQ==", "bodyText": "Yeah that's right.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391490575", "createdAt": "2020-03-12T09:22:39Z", "author": {"login": "ppatierno"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 &&\n+            kafkaCluster.getStorage() != null && Storage.TYPE_EPHEMERAL.equals(kafkaCluster.getStorage().getType())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MzYwMA=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjEwNDMxOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyODoxNFrOF1VDLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyODoxNFrOF1VDLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2MzcyNA==", "bodyText": "Ditto", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391463724", "createdAt": "2020-03-12T08:28:14Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 &&\n+            kafkaCluster.getStorage() != null && Storage.TYPE_EPHEMERAL.equals(kafkaCluster.getStorage().getType())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 &&\n+            zkCluster.getStorage() != null && Storage.TYPE_EPHEMERAL.equals(zkCluster.getStorage().getType())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjEwODgyOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyOTo1MFrOF1VGGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODoyOTo1MFrOF1VGGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2NDQ3Mg==", "bodyText": "Elsewhere in this class you call this list warnings. It would be good to be consistent.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391464472", "createdAt": "2020-03-12T08:29:50Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjExNTc2OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODozMjowM1rOF1VKYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QyMTowMDozOVrOF3t4Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2NTU3MA==", "bodyText": "I wonder if we should also add warnings from the ValidationVisitor. Potentially that could add quite a few warnings, but it makes them more visible than just in the logs. WDYT @scholzj ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391465570", "createdAt": "2020-03-12T08:32:03Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java", "diffHunk": "@@ -523,6 +525,17 @@ ReconciliationState createReconciliationState(Reconciliation reconciliation, Kaf\n             return initialStatusPromise.future();\n         }\n \n+        /**\n+         * Checks the requested Kafka spec for potential issues, and adds warnings and advice for best\n+         * practice to the status.\n+         */\n+        Future<ReconciliationState> checkKafkaSpec() {\n+            KafkaSpecChecker checker = new KafkaSpecChecker(kafkaAssembly.getSpec(), kafkaCluster, zkCluster);\n+            List<Condition> warnings = checker.run();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk2NzY0Mw==", "bodyText": "Sorry, I missed this earlier. But I think this would be good idea for next PR.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r393967643", "createdAt": "2020-03-17T21:00:39Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java", "diffHunk": "@@ -523,6 +525,17 @@ ReconciliationState createReconciliationState(Reconciliation reconciliation, Kaf\n             return initialStatusPromise.future();\n         }\n \n+        /**\n+         * Checks the requested Kafka spec for potential issues, and adds warnings and advice for best\n+         * practice to the status.\n+         */\n+        Future<ReconciliationState> checkKafkaSpec() {\n+            KafkaSpecChecker checker = new KafkaSpecChecker(kafkaAssembly.getSpec(), kafkaCluster, zkCluster);\n+            List<Condition> warnings = checker.run();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2NTU3MA=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNjEyNTczOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwODozNTo0OFrOF1VQsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNDo1OTo1MlrOF1iVQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2NzE4NA==", "bodyText": "I'm not completely sure about this. Unlike the other checks in this class, I think there are valid use cases where someone want might to stick with the old log.message.format.version (e.g. because they're using older clients and can't upgrade them right now). It would be kind of annoying if they're doing that intentionally and they get this warning which they can't remove. But I'm not sure it's worth an annotation to be able to disable the warning, for example.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391467184", "createdAt": "2020-03-12T08:35:48Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY4MTM0Nw==", "bodyText": "It's a fair point - if the user is aware of the issue and is doing it their way intentionally, the warning is potentially annoying.\nI've come across more people who updated their brokers (albeit not using Strimzi) and either forgot or didn't realise they needed to update the config they'd been using since they started, than I have people who are intentionally using a previous/legacy format. So on balance I think the potential benefit outweighs the cost.\nBut this is absolutely an anecdotal and not-very-scientific or representative view :-)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r391681347", "createdAt": "2020-03-12T14:59:52Z", "author": {"login": "dalelane"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ssZ\").format(new Date());\n+    }\n+\n+\n+    public List<Condition> run() {\n+        List<Condition> notifications = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(notifications);\n+        checkKafkaStorage(notifications);\n+        checkZooKeeperStorage(notifications);\n+        checkZooKeeperReplicas(notifications);\n+        return notifications;\n+    }\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTQ2NzE4NA=="}, "originalCommit": {"oid": "034f6ec1c7034d3319d370408ba4a08763c58e47"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNTYzMTg2OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxMDo1NDowNVrOF2u0yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwOTowNzoyMVrOF4liwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzNDYwMA==", "bodyText": "Date supplier?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r392934600", "createdAt": "2020-03-16T10:54:05Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.JbodStorage;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(new Date());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c816b4ccc49cfb017865fd6b95386ad07128b9a2"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1MjMwOA==", "bodyText": "@dalelane why this was marked as resolved? Isn't it better passing the date supplier as we have it in the KafkaAssemblyOperator?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394852308", "createdAt": "2020-03-19T08:14:27Z", "author": {"login": "ppatierno"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.JbodStorage;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(new Date());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzNDYwMA=="}, "originalCommit": {"oid": "c816b4ccc49cfb017865fd6b95386ad07128b9a2"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg3OTY4MA==", "bodyText": "Added it now", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394879680", "createdAt": "2020-03-19T09:07:21Z", "author": {"login": "dalelane"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.JbodStorage;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(new Date());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzNDYwMA=="}, "originalCommit": {"oid": "c816b4ccc49cfb017865fd6b95386ad07128b9a2"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNTY0MDY2OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxMDo1Njo1NFrOF2u6XQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxMDo1Njo1NFrOF2u6XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzNjAyOQ==", "bodyText": "I think these could be static, and probably ModelUtil is a better place for them (more likely to be reused there).", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r392936029", "createdAt": "2020-03-16T10:56:54Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.api.kafka.model.storage.JbodStorage;\n+import io.strimzi.api.kafka.model.storage.Storage;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(new Date());\n+    }\n+\n+    public List<Condition> run() {\n+        List<Condition> warnings = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(warnings);\n+        checkKafkaStorage(warnings);\n+        checkZooKeeperStorage(warnings);\n+        checkZooKeeperReplicas(warnings);\n+        return warnings;\n+    }\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 && usesEphemeral(kafkaCluster.getStorage())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 && usesEphemeral(zkCluster.getStorage())) {\n+            warnings.add(buildCondition(\"ZooKeeperStorage\",\n+                    \"A ZooKeeper cluster with a single replica and ephemeral storage will be in a defective state after any restart or rolling update. It is recommended that a minimum of three replicas are used.\"));\n+        }\n+    }\n+\n+    private boolean isEphemeral(Storage storage) {\n+        return Storage.TYPE_EPHEMERAL.equals(storage.getType());\n+    }\n+\n+    private boolean usesEphemeral(Storage storage) {\n+        if (storage != null) {\n+            if (isEphemeral(storage)) {\n+                return true;\n+            }\n+            if (Storage.TYPE_JBOD.equals(storage.getType())) {\n+                JbodStorage jbodStorage = (JbodStorage) storage;\n+                return jbodStorage.getVolumes().stream().anyMatch(this::isEphemeral);\n+            }\n+        }\n+        return false;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c816b4ccc49cfb017865fd6b95386ad07128b9a2"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NzQ2NzUxOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecCheckerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwODoyMToxOFrOF4kFRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwODoyMToxOFrOF4kFRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1NTc0OQ==", "bodyText": "could it be assertThat(checker.run(), empty()) ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394855749", "createdAt": "2020-03-19T08:21:18Z", "author": {"login": "ppatierno"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecCheckerTest.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.Kafka;\n+import io.strimzi.api.kafka.model.KafkaBuilder;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.storage.EphemeralStorage;\n+import io.strimzi.api.kafka.model.storage.EphemeralStorageBuilder;\n+import io.strimzi.api.kafka.model.storage.JbodStorageBuilder;\n+import io.strimzi.operator.cluster.KafkaVersionTestUtils;\n+import io.strimzi.operator.cluster.ResourceUtils;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.KafkaVersion;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.StringReader;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Collections.emptyMap;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.emptyOrNullString;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.collection.IsCollectionWithSize.hasSize;\n+\n+public class KafkaSpecCheckerTest {\n+\n+    private static final String NAMESPACE = \"ns\";\n+    private static final String NAME = \"foo\";\n+    private static final String IMAGE = \"image\";\n+    private static final int HEALTH_DELAY = 120;\n+    private static final int HEALTH_TIMEOUT = 30;\n+\n+    private KafkaSpecChecker generateChecker(Kafka kafka) {\n+        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(\n+                new StringReader(KafkaVersionTestUtils.getKafkaVersionYaml()),\n+                KafkaVersionTestUtils.getKafkaImageMap(),\n+                emptyMap(),\n+                emptyMap(),\n+                emptyMap(),\n+                emptyMap()) { };\n+        KafkaCluster kafkaCluster = KafkaCluster.fromCrd(kafka, versions);\n+        ZookeeperCluster zkCluster = ZookeeperCluster.fromCrd(kafka, versions);\n+        return new KafkaSpecChecker(kafka.getSpec(), kafkaCluster, zkCluster);\n+    }\n+\n+    @Test\n+    public void checkEmptyWarnings() {\n+        Kafka kafka = ResourceUtils.createKafkaCluster(NAMESPACE, NAME, 3, IMAGE, HEALTH_DELAY, HEALTH_TIMEOUT);\n+        KafkaSpecChecker checker = generateChecker(kafka);\n+        assertThat(checker.run().isEmpty(), is(true));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b962379595c71e4a8ddbede17d7d332f74cbaaf"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ0NzYyMTA4OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwOToxMDoxOVrOF4lovw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNDo1MTo0OFrOF4yH0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4MTIxNQ==", "bodyText": "I was mostly thinking about passing the date supplier from the outside because it's created in the KafkaAssemblyOperator using the spec checker. I know they are the same (just returning new Date()) but if we do a change for any reason I don't have right now in the KafkaAssemblyOperator, it should be reflected in the spec checker. @tombentley wdyt? You had a related comment about this.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394881215", "createdAt": "2020-03-19T09:10:19Z", "author": {"login": "ppatierno"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.StorageUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(dateSupplier());\n+    }\n+\n+    public List<Condition> run() {\n+        List<Condition> warnings = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(warnings);\n+        checkKafkaStorage(warnings);\n+        checkZooKeeperStorage(warnings);\n+        checkZooKeeperReplicas(warnings);\n+        return warnings;\n+    }\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(kafkaCluster.getStorage())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(zkCluster.getStorage())) {\n+            warnings.add(buildCondition(\"ZooKeeperStorage\",\n+                    \"A ZooKeeper cluster with a single replica and ephemeral storage will be in a defective state after any restart or rolling update. It is recommended that a minimum of three replicas are used.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for an even number of ZooKeeper replicas. As ZooKeeper is dependent on maintaining a quorum,\n+     * this means that users should deploy clusters with an odd number of nodes.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperReplicas(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 2) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with two nodes is not advisable as both replicas will be needed to avoid downtime. It is recommended that a minimum of three replicas are used.\"));\n+        } else if (zkCluster.getReplicas() % 2 == 0) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with an odd number of replicas is recommended.\"));\n+        }\n+    }\n+\n+    private Condition buildCondition(String reason, String message) {\n+        return new ConditionBuilder()\n+                .withLastTransitionTime(timestamp)\n+                .withType(\"Warning\")\n+                .withStatus(\"True\")\n+                .withReason(reason)\n+                .withMessage(message)\n+                .build();\n+    }\n+    private Date dateSupplier() {\n+        return new Date();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e5335294ea54fd5574fa58c59b915f6ebcb56f9a"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4NTYxOA==", "bodyText": "Sorry if my comment wasn't clear. The point I was trying to make is that the KAO already uses a Supplier<Date> to abstract how it obtains the current time (in support of the \"maintenance time\" functionality). I think we should use the same Supplier<Date> instance here. In also makes it easier to write tests which depend on the \"current\" time.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394885618", "createdAt": "2020-03-19T09:18:02Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.StorageUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(dateSupplier());\n+    }\n+\n+    public List<Condition> run() {\n+        List<Condition> warnings = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(warnings);\n+        checkKafkaStorage(warnings);\n+        checkZooKeeperStorage(warnings);\n+        checkZooKeeperReplicas(warnings);\n+        return warnings;\n+    }\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(kafkaCluster.getStorage())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(zkCluster.getStorage())) {\n+            warnings.add(buildCondition(\"ZooKeeperStorage\",\n+                    \"A ZooKeeper cluster with a single replica and ephemeral storage will be in a defective state after any restart or rolling update. It is recommended that a minimum of three replicas are used.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for an even number of ZooKeeper replicas. As ZooKeeper is dependent on maintaining a quorum,\n+     * this means that users should deploy clusters with an odd number of nodes.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperReplicas(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 2) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with two nodes is not advisable as both replicas will be needed to avoid downtime. It is recommended that a minimum of three replicas are used.\"));\n+        } else if (zkCluster.getReplicas() % 2 == 0) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with an odd number of replicas is recommended.\"));\n+        }\n+    }\n+\n+    private Condition buildCondition(String reason, String message) {\n+        return new ConditionBuilder()\n+                .withLastTransitionTime(timestamp)\n+                .withType(\"Warning\")\n+                .withStatus(\"True\")\n+                .withReason(reason)\n+                .withMessage(message)\n+                .build();\n+    }\n+    private Date dateSupplier() {\n+        return new Date();\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4MTIxNQ=="}, "originalCommit": {"oid": "e5335294ea54fd5574fa58c59b915f6ebcb56f9a"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDk3OTI4Mw==", "bodyText": "@tombentley I've tried moving it into ModelUtils alongside the formatter - was that what you had in mind?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r394979283", "createdAt": "2020-03-19T12:09:46Z", "author": {"login": "dalelane"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.StorageUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(dateSupplier());\n+    }\n+\n+    public List<Condition> run() {\n+        List<Condition> warnings = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(warnings);\n+        checkKafkaStorage(warnings);\n+        checkZooKeeperStorage(warnings);\n+        checkZooKeeperReplicas(warnings);\n+        return warnings;\n+    }\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(kafkaCluster.getStorage())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(zkCluster.getStorage())) {\n+            warnings.add(buildCondition(\"ZooKeeperStorage\",\n+                    \"A ZooKeeper cluster with a single replica and ephemeral storage will be in a defective state after any restart or rolling update. It is recommended that a minimum of three replicas are used.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for an even number of ZooKeeper replicas. As ZooKeeper is dependent on maintaining a quorum,\n+     * this means that users should deploy clusters with an odd number of nodes.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperReplicas(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 2) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with two nodes is not advisable as both replicas will be needed to avoid downtime. It is recommended that a minimum of three replicas are used.\"));\n+        } else if (zkCluster.getReplicas() % 2 == 0) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with an odd number of replicas is recommended.\"));\n+        }\n+    }\n+\n+    private Condition buildCondition(String reason, String message) {\n+        return new ConditionBuilder()\n+                .withLastTransitionTime(timestamp)\n+                .withType(\"Warning\")\n+                .withStatus(\"True\")\n+                .withReason(reason)\n+                .withMessage(message)\n+                .build();\n+    }\n+    private Date dateSupplier() {\n+        return new Date();\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4MTIxNQ=="}, "originalCommit": {"oid": "e5335294ea54fd5574fa58c59b915f6ebcb56f9a"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTA4NTc3Nw==", "bodyText": "Almost. Please can we pass a Supplier<Date> to the constructor or run() method from the call site in KAO. Ideally only one place in KAO will depend on the ModelUtils method.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2663#discussion_r395085777", "createdAt": "2020-03-19T14:51:48Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecChecker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.cluster.operator.resource;\n+\n+import io.strimzi.api.kafka.model.KafkaSpec;\n+import io.strimzi.api.kafka.model.status.Condition;\n+import io.strimzi.api.kafka.model.status.ConditionBuilder;\n+import io.strimzi.operator.cluster.model.KafkaCluster;\n+import io.strimzi.operator.cluster.model.KafkaConfiguration;\n+import io.strimzi.operator.cluster.model.ModelUtils;\n+import io.strimzi.operator.cluster.model.StorageUtils;\n+import io.strimzi.operator.cluster.model.ZookeeperCluster;\n+\n+import java.util.ArrayList;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Checks for potential problems in the configuration requested by the user, to provide\n+ * warnings and share best practice. The intent is this class will generate warnings about\n+ * configurations that aren't necessarily illegal or invalid, but that could potentially\n+ * lead to problems.\n+ */\n+public class KafkaSpecChecker {\n+\n+    private KafkaSpec spec;\n+    private KafkaCluster kafkaCluster;\n+    private ZookeeperCluster zkCluster;\n+    private String timestamp;\n+\n+    private final static Pattern VERSION_REGEX = Pattern.compile(\"(\\\\d\\\\.\\\\d+).*\");\n+\n+    /**\n+     * @param spec The spec requested by the user in the CR\n+     * @param kafkaCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     * @param zkCluster The model generated based on the spec. This is requested so that default\n+     *                     values not included in the spec can be taken into account, without needing\n+     *                     this class to include awareness of what defaults are applied.\n+     */\n+    public KafkaSpecChecker(KafkaSpec spec, KafkaCluster kafkaCluster, ZookeeperCluster zkCluster) {\n+        this.spec = spec;\n+        this.kafkaCluster = kafkaCluster;\n+        this.zkCluster = zkCluster;\n+        this.timestamp = ModelUtils.formatTimestamp(dateSupplier());\n+    }\n+\n+    public List<Condition> run() {\n+        List<Condition> warnings = new ArrayList<>();\n+        checkKafkaLogMessageFormatVersion(warnings);\n+        checkKafkaStorage(warnings);\n+        checkZooKeeperStorage(warnings);\n+        checkZooKeeperReplicas(warnings);\n+        return warnings;\n+    }\n+\n+    /**\n+     * Checks if the version of the Kafka brokers matches any custom log.message.format.version config.\n+     *\n+     * Updating this is the final step in upgrading Kafka version, so if this doesn't match it is possibly an\n+     * indication that a user has updated their Kafka cluster and is unaware that they also should update\n+     * their format version to match.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaLogMessageFormatVersion(List<Condition> warnings) {\n+        String logMsgFormatVersion = kafkaCluster.getConfiguration().getConfigOption(KafkaConfiguration.LOG_MESSAGE_FORMAT_VERSION);\n+        String kafkaBrokerVersion = spec.getKafka().getVersion();\n+        if (logMsgFormatVersion != null && kafkaBrokerVersion != null) {\n+            Matcher m = VERSION_REGEX.matcher(logMsgFormatVersion);\n+            if (m.find() && !kafkaBrokerVersion.startsWith(m.group(0))) {\n+                warnings.add(buildCondition(\"KafkaLogMessageFormatVersion\",\n+                                            \"log.message.format.version does not match the Kafka cluster version, which suggests that an upgrade is incomplete.\"));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-broker Kafka cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the broker will result in data loss, as the single broker won't allow for any\n+     * topic replicas.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkKafkaStorage(List<Condition> warnings) {\n+        if (kafkaCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(kafkaCluster.getStorage())) {\n+            warnings.add(buildCondition(\"KafkaStorage\",\n+                    \"A Kafka cluster with a single replica and ephemeral storage will lose topic messages after any restart or rolling update.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for a single-node ZooKeeper cluster using ephemeral storage. This is potentially a problem as it\n+     * means any restarts of the pod will cause the loss of cluster metadata.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperStorage(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 1 && StorageUtils.usesEphemeral(zkCluster.getStorage())) {\n+            warnings.add(buildCondition(\"ZooKeeperStorage\",\n+                    \"A ZooKeeper cluster with a single replica and ephemeral storage will be in a defective state after any restart or rolling update. It is recommended that a minimum of three replicas are used.\"));\n+        }\n+    }\n+\n+    /**\n+     * Checks for an even number of ZooKeeper replicas. As ZooKeeper is dependent on maintaining a quorum,\n+     * this means that users should deploy clusters with an odd number of nodes.\n+     *\n+     * @param warnings List to add a warning to, if appropriate.\n+     */\n+    private void checkZooKeeperReplicas(List<Condition> warnings) {\n+        if (zkCluster.getReplicas() == 2) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with two nodes is not advisable as both replicas will be needed to avoid downtime. It is recommended that a minimum of three replicas are used.\"));\n+        } else if (zkCluster.getReplicas() % 2 == 0) {\n+            warnings.add(buildCondition(\"ZooKeeperReplicas\",\n+                    \"Running ZooKeeper with an odd number of replicas is recommended.\"));\n+        }\n+    }\n+\n+    private Condition buildCondition(String reason, String message) {\n+        return new ConditionBuilder()\n+                .withLastTransitionTime(timestamp)\n+                .withType(\"Warning\")\n+                .withStatus(\"True\")\n+                .withReason(reason)\n+                .withMessage(message)\n+                .build();\n+    }\n+    private Date dateSupplier() {\n+        return new Date();\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4MTIxNQ=="}, "originalCommit": {"oid": "e5335294ea54fd5574fa58c59b915f6ebcb56f9a"}, "originalPosition": 138}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 286, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}