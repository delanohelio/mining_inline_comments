{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc0OTQzMzky", "number": 2548, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo0NjozOFrODg3UkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo0NjozOFrODg3UkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM1Nzg3NDA5OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOFQyMTo0NjozOFrOFrTmXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xOVQwNzo1NjoyN1rOFreFVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1NDIwNA==", "bodyText": "Should you actually check the status or something?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2548#discussion_r380954204", "createdAt": "2020-02-18T21:46:38Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.recovery;\n+\n+import io.fabric8.kubernetes.api.model.PersistentVolume;\n+import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;\n+import io.fabric8.kubernetes.api.model.storage.StorageClass;\n+import io.fabric8.kubernetes.api.model.storage.StorageClassBuilder;\n+import io.strimzi.api.kafka.model.EntityOperatorSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaTopic;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.NamespaceUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+import java.util.Random;\n+\n+import static io.strimzi.systemtest.Constants.RECOVERY;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(RECOVERY)\n+class NamespaceDeletionRecoveryST extends BaseST {\n+\n+    static final String NAMESPACE = \"namespace-recovery-cluster-test\";\n+    static final String CLUSTER_NAME = \"recovery-cluster\";\n+\n+    private static final Logger LOGGER = LogManager.getLogger(NamespaceDeletionRecoveryST.class);\n+\n+    private String storageClassName = \"retain\";\n+\n+    @Test\n+    void testTopicAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<KafkaTopic> kafkaTopicList = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).list().getItems();\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        // Recreate all KafkaTopic resources\n+        for (KafkaTopic kafkaTopic : kafkaTopicList) {\n+            kafkaTopic.getMetadata().setResourceVersion(null);\n+            KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).createOrReplace(kafkaTopic);\n+        }\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+            .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+\n+        String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+\n+        internalKafkaClient.setPodName(defaultKafkaClientsPodName);\n+\n+        LOGGER.info(\"Checking produced and consumed messages to pod:{}\", internalKafkaClient.getPodName());\n+        Integer consumed = internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT, consumerGroup);\n+        assertThat(consumed, is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testTopicNotAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        // Recreate Kafka Cluster\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+                .withNewEntityOperator()\n+                .endEntityOperator()\n+            .endSpec().done();\n+\n+        // Wait some time after kafka is ready before delete topics files\n+        Thread.sleep(60000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d54946a1fd4ef84cb0ae2fba3172dbca4e971ea"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEyNTk3Mg==", "bodyText": "This whould be great, but I am not sure what exactly I can check in that case, because Kafka CR is ready, but when I execute the following command to delete topic data from ZK, I got strange errors as I sent you in offline discussion. Only this way help to solve it. If you have any siggestion what I can check instead of this sleep, I am happy to change it", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2548#discussion_r381125972", "createdAt": "2020-02-19T07:56:27Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.recovery;\n+\n+import io.fabric8.kubernetes.api.model.PersistentVolume;\n+import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;\n+import io.fabric8.kubernetes.api.model.storage.StorageClass;\n+import io.fabric8.kubernetes.api.model.storage.StorageClassBuilder;\n+import io.strimzi.api.kafka.model.EntityOperatorSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaTopic;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.NamespaceUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+import java.util.Random;\n+\n+import static io.strimzi.systemtest.Constants.RECOVERY;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(RECOVERY)\n+class NamespaceDeletionRecoveryST extends BaseST {\n+\n+    static final String NAMESPACE = \"namespace-recovery-cluster-test\";\n+    static final String CLUSTER_NAME = \"recovery-cluster\";\n+\n+    private static final Logger LOGGER = LogManager.getLogger(NamespaceDeletionRecoveryST.class);\n+\n+    private String storageClassName = \"retain\";\n+\n+    @Test\n+    void testTopicAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<KafkaTopic> kafkaTopicList = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).list().getItems();\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        // Recreate all KafkaTopic resources\n+        for (KafkaTopic kafkaTopic : kafkaTopicList) {\n+            kafkaTopic.getMetadata().setResourceVersion(null);\n+            KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).createOrReplace(kafkaTopic);\n+        }\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+            .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+\n+        String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+\n+        internalKafkaClient.setPodName(defaultKafkaClientsPodName);\n+\n+        LOGGER.info(\"Checking produced and consumed messages to pod:{}\", internalKafkaClient.getPodName());\n+        Integer consumed = internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT, consumerGroup);\n+        assertThat(consumed, is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testTopicNotAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        // Recreate Kafka Cluster\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+                .withNewEntityOperator()\n+                .endEntityOperator()\n+            .endSpec().done();\n+\n+        // Wait some time after kafka is ready before delete topics files\n+        Thread.sleep(60000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1NDIwNA=="}, "originalCommit": {"oid": "9d54946a1fd4ef84cb0ae2fba3172dbca4e971ea"}, "originalPosition": 136}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 458, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}