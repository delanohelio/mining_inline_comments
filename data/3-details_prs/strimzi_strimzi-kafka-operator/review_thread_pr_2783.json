{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4MzcwNTg5", "number": 2783, "reviewThreads": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QyMjowNDoxNVrODum5RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxOTowNToyN1rODyNKpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMTk4MzQxOnYy", "diffSide": "RIGHT", "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wM1QyMjowNDoxNVrOGArCnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMToyNjo1MFrOGAxMRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM1ODM2NQ==", "bodyText": "assertDoesNotThrow(() ->  mockDescribeAcls(mockAdminClient, AclBindingFilter.ANY, aclBindings))\n\nis a good alternative aslong as we don't need the return value to this,\nalso means we don't have to add to the list of handled exceptions if they change.\nSimilar suggestion applies to all try{} catch{} in this file", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403358365", "createdAt": "2020-04-03T22:04:15Z", "author": {"login": "samuel-hawker"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "diffHunk": "@@ -62,162 +70,198 @@ public static void after() {\n \n     @Test\n     public void testGetUsersFromAcls(VertxTestContext context)  {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl fooAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal bar = new KafkaPrincipal(\"User\", \"CN=bar\");\n-        Acl barAcl = new Acl(bar, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal baz = new KafkaPrincipal(\"User\", \"baz\");\n-        Acl bazAcl = new Acl(baz, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal all = new KafkaPrincipal(\"User\", \"*\");\n-        Acl allAcl = new Acl(all, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal anonymous = new KafkaPrincipal(\"User\", \"ANONYMOUS\");\n-        Acl anonymousAcl = new Acl(anonymous, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Resource res1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource res2 = new Resource(Group$.MODULE$, \"my-group\", PatternType.LITERAL);\n-        scala.collection.immutable.Set<Acl> set1 = new scala.collection.immutable.Set.Set3<>(fooAcl, barAcl, allAcl);\n-        scala.collection.immutable.Set<Acl> set2 = new scala.collection.immutable.Set.Set2<>(bazAcl, anonymousAcl);\n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map2<>(res1, set1, res2, set2);\n-        when(mockAuthorizer.getAcls()).thenReturn(map);\n-\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n-\n-        assertThat(aclOp.getUsersWithAcls(), is(new HashSet(asList(\"foo\", \"bar\", \"baz\"))));\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n+\n+        ResourcePattern res1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern res2 = new ResourcePattern(ResourceType.GROUP, \"my-group\", PatternType.LITERAL);\n+\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding fooAclBinding = new AclBinding(res1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal bar = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=bar\");\n+        AclBinding barAclBinding = new AclBinding(res1, new AccessControlEntry(bar.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal baz = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"baz\");\n+        AclBinding bazAclBinding = new AclBinding(res2, new AccessControlEntry(baz.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal all = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"*\");\n+        AclBinding allAclBinding = new AclBinding(res1, new AccessControlEntry(all.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal anonymous = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"ANONYMOUS\");\n+        AclBinding anonymousAclBinding = new AclBinding(res2, new AccessControlEntry(anonymous.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+\n+        Collection<AclBinding> aclBindings =\n+                asList(fooAclBinding, barAclBinding, bazAclBinding, allAclBinding, anonymousAclBinding);\n+\n+        try {\n+            mockDescribeAcls(mockAdminClient, AclBindingFilter.ANY, aclBindings);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5f82c6b29321c3813eb97fb9853a42313613ebc"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ1OTE0Mw==", "bodyText": "Good suggestion! Done ;-)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403459143", "createdAt": "2020-04-04T11:26:50Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "diffHunk": "@@ -62,162 +70,198 @@ public static void after() {\n \n     @Test\n     public void testGetUsersFromAcls(VertxTestContext context)  {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl fooAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal bar = new KafkaPrincipal(\"User\", \"CN=bar\");\n-        Acl barAcl = new Acl(bar, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal baz = new KafkaPrincipal(\"User\", \"baz\");\n-        Acl bazAcl = new Acl(baz, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal all = new KafkaPrincipal(\"User\", \"*\");\n-        Acl allAcl = new Acl(all, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal anonymous = new KafkaPrincipal(\"User\", \"ANONYMOUS\");\n-        Acl anonymousAcl = new Acl(anonymous, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Resource res1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource res2 = new Resource(Group$.MODULE$, \"my-group\", PatternType.LITERAL);\n-        scala.collection.immutable.Set<Acl> set1 = new scala.collection.immutable.Set.Set3<>(fooAcl, barAcl, allAcl);\n-        scala.collection.immutable.Set<Acl> set2 = new scala.collection.immutable.Set.Set2<>(bazAcl, anonymousAcl);\n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map2<>(res1, set1, res2, set2);\n-        when(mockAuthorizer.getAcls()).thenReturn(map);\n-\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n-\n-        assertThat(aclOp.getUsersWithAcls(), is(new HashSet(asList(\"foo\", \"bar\", \"baz\"))));\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n+\n+        ResourcePattern res1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern res2 = new ResourcePattern(ResourceType.GROUP, \"my-group\", PatternType.LITERAL);\n+\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding fooAclBinding = new AclBinding(res1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal bar = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=bar\");\n+        AclBinding barAclBinding = new AclBinding(res1, new AccessControlEntry(bar.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal baz = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"baz\");\n+        AclBinding bazAclBinding = new AclBinding(res2, new AccessControlEntry(baz.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal all = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"*\");\n+        AclBinding allAclBinding = new AclBinding(res1, new AccessControlEntry(all.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal anonymous = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"ANONYMOUS\");\n+        AclBinding anonymousAclBinding = new AclBinding(res2, new AccessControlEntry(anonymous.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+\n+        Collection<AclBinding> aclBindings =\n+                asList(fooAclBinding, barAclBinding, bazAclBinding, allAclBinding, anonymousAclBinding);\n+\n+        try {\n+            mockDescribeAcls(mockAdminClient, AclBindingFilter.ANY, aclBindings);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM1ODM2NQ=="}, "originalCommit": {"oid": "b5f82c6b29321c3813eb97fb9853a42313613ebc"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjc4NDE1OnYy", "diffSide": "RIGHT", "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMTo1NDoyMVrOGAxV3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMDo1NjowMFrOGCVyig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2MTU5OQ==", "bodyText": "I know this isn't under the remit of this PR, but I noticed that both of the trys here have no catch, I guess that means if for any reason they throw the error gets propagated up and the user would see this somehow? For instance in the case where keyCertName + \".password\" isn't a valid key in the secret?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403461599", "createdAt": "2020-04-04T11:54:21Z", "author": {"login": "samuel-hawker"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {\n         Admin ac;\n-        PasswordGenerator pg = new PasswordGenerator(12);\n-        String trustStorePassword = pg.generate();\n-        File truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        String trustStorePassword = null;\n+        File truststoreFile = null;\n+        // provided Secret with cluster CA certificate for TLS encryption\n+        if (clusterCaCertSecret != null) {\n+            PasswordGenerator pg = new PasswordGenerator(12);\n+            trustStorePassword = pg.generate();\n+            truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        }\n+\n         try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c88774547c7b3d5b18f1f2c45c22c5a9a809e0e"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE3NjEzNg==", "bodyText": "I would see the reason about the error in the UO log. What's your proposal?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404176136", "createdAt": "2020-04-06T15:20:44Z", "author": {"login": "ppatierno"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {\n         Admin ac;\n-        PasswordGenerator pg = new PasswordGenerator(12);\n-        String trustStorePassword = pg.generate();\n-        File truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        String trustStorePassword = null;\n+        File truststoreFile = null;\n+        // provided Secret with cluster CA certificate for TLS encryption\n+        if (clusterCaCertSecret != null) {\n+            PasswordGenerator pg = new PasswordGenerator(12);\n+            trustStorePassword = pg.generate();\n+            truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        }\n+\n         try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2MTU5OQ=="}, "originalCommit": {"oid": "4c88774547c7b3d5b18f1f2c45c22c5a9a809e0e"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg2Njg1Mg==", "bodyText": "I guess @samuel-hawker is wondering whether it makes sense to wrap the exception using a more meaningful exception type? My opinion on that (whether or not that is what he meant) was that it makes little difference. It's not going to be an exception which would be caught by the operator, so the only place it would appear would be in the logs and in the status as a reason for not being ready. I don't think anyone could reasonably do any automation around the problem in either of those places.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404866852", "createdAt": "2020-04-07T14:45:46Z", "author": {"login": "tombentley"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {\n         Admin ac;\n-        PasswordGenerator pg = new PasswordGenerator(12);\n-        String trustStorePassword = pg.generate();\n-        File truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        String trustStorePassword = null;\n+        File truststoreFile = null;\n+        // provided Secret with cluster CA certificate for TLS encryption\n+        if (clusterCaCertSecret != null) {\n+            PasswordGenerator pg = new PasswordGenerator(12);\n+            trustStorePassword = pg.generate();\n+            truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        }\n+\n         try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2MTU5OQ=="}, "originalCommit": {"oid": "4c88774547c7b3d5b18f1f2c45c22c5a9a809e0e"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwNzMzOA==", "bodyText": "If this is the case, then I agree that catching and re-throwing as a different exception makes a little difference in this case. @samuel-hawker any more comments?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r405107338", "createdAt": "2020-04-07T20:56:00Z", "author": {"login": "ppatierno"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {\n         Admin ac;\n-        PasswordGenerator pg = new PasswordGenerator(12);\n-        String trustStorePassword = pg.generate();\n-        File truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        String trustStorePassword = null;\n+        File truststoreFile = null;\n+        // provided Secret with cluster CA certificate for TLS encryption\n+        if (clusterCaCertSecret != null) {\n+            PasswordGenerator pg = new PasswordGenerator(12);\n+            trustStorePassword = pg.generate();\n+            truststoreFile = Util.createFileTrustStore(getClass().getName(), \"ts\", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());\n+        }\n+\n         try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2MTU5OQ=="}, "originalCommit": {"oid": "4c88774547c7b3d5b18f1f2c45c22c5a9a809e0e"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjgyNzE2OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMjo1MjozNlrOGAxqvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNjozMDozMlrOGBJaUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2Njk0Mg==", "bodyText": "Wouldn't it be better to name the env var STRIMZI_EO_KEY_SECRET_NAME?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403466942", "createdAt": "2020-04-04T12:52:36Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java", "diffHunk": "@@ -56,9 +58,12 @@\n     public static final String ENV_VAR_CLIENTS_CA_NAMESPACE = \"STRIMZI_CA_NAMESPACE\";\n     public static final String ENV_VAR_CLIENTS_CA_VALIDITY = \"STRIMZI_CA_VALIDITY\";\n     public static final String ENV_VAR_CLIENTS_CA_RENEWAL = \"STRIMZI_CA_RENEWAL\";\n+    public static final String ENV_VAR_CLUSTER_CA_CERT_SECRET_NAME = \"STRIMZI_CLUSTER_CA_CERT_NAME\";\n+    public static final String ENV_VAR_EO_KEY_SECRET_NAME = \"STRIMZI_EO_KEY_NAME\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NTk1NA==", "bodyText": "I would agree with that but I would change the others as well.\nFor example, we have STRIMZI_CA_KEY_NAME and STRIMZI_CA_CERT_NAME where SECRET is not there (just in the env var name). I would also change these env vars adding CLIENTS in the env var name (as the env var constant) to distinguish with the new one I added related to CLUSTER. I know it's a little bit of breaking change on people using the UO as standalone, but from an offline discussion, I remember we agree that it should not be a problem.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403855954", "createdAt": "2020-04-06T06:30:32Z", "author": {"login": "ppatierno"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java", "diffHunk": "@@ -56,9 +58,12 @@\n     public static final String ENV_VAR_CLIENTS_CA_NAMESPACE = \"STRIMZI_CA_NAMESPACE\";\n     public static final String ENV_VAR_CLIENTS_CA_VALIDITY = \"STRIMZI_CA_VALIDITY\";\n     public static final String ENV_VAR_CLIENTS_CA_RENEWAL = \"STRIMZI_CA_RENEWAL\";\n+    public static final String ENV_VAR_CLUSTER_CA_CERT_SECRET_NAME = \"STRIMZI_CLUSTER_CA_CERT_NAME\";\n+    public static final String ENV_VAR_EO_KEY_SECRET_NAME = \"STRIMZI_EO_KEY_NAME\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2Njk0Mg=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjgzOTEzOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzowODo0OVrOGAxwcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzowODo0OVrOGAxwcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2ODQwMA==", "bodyText": "Same as before - I think it should be STRIMZI_EO_KEY_SECRET_NAME", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403468400", "createdAt": "2020-04-04T13:08:49Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java", "diffHunk": "@@ -20,51 +20,68 @@\n     public static final String STRIMZI_LABELS = \"STRIMZI_LABELS\";\n     public static final String STRIMZI_CA_CERT_SECRET_NAME = \"STRIMZI_CA_CERT_NAME\";\n     public static final String STRIMZI_CA_KEY_SECRET_NAME = \"STRIMZI_CA_KEY_NAME\";\n+    public static final String STRIMZI_CLUSTER_CA_CERT_SECRET_NAME = \"STRIMZI_CLUSTER_CA_CERT_NAME\";\n+    public static final String STRIMZI_EO_KEY_SECRET_NAME = \"STRIMZI_EO_KEY_NAME\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjg0NTczOnYy", "diffSide": "RIGHT", "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoxNzo0N1rOGAxzhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNjozMjoyNlrOGBJctg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTE5MQ==", "bodyText": "I do not really understand why do we have here (and on the other places) the assertDoesNotThrow when just creating the mocks. Could you explain it please? (just here, not necessarily in the code)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403469191", "createdAt": "2020-04-04T13:17:47Z", "author": {"login": "scholzj"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "diffHunk": "@@ -62,162 +71,187 @@ public static void after() {\n \n     @Test\n     public void testGetUsersFromAcls(VertxTestContext context)  {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl fooAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal bar = new KafkaPrincipal(\"User\", \"CN=bar\");\n-        Acl barAcl = new Acl(bar, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal baz = new KafkaPrincipal(\"User\", \"baz\");\n-        Acl bazAcl = new Acl(baz, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal all = new KafkaPrincipal(\"User\", \"*\");\n-        Acl allAcl = new Acl(all, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal anonymous = new KafkaPrincipal(\"User\", \"ANONYMOUS\");\n-        Acl anonymousAcl = new Acl(anonymous, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Resource res1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource res2 = new Resource(Group$.MODULE$, \"my-group\", PatternType.LITERAL);\n-        scala.collection.immutable.Set<Acl> set1 = new scala.collection.immutable.Set.Set3<>(fooAcl, barAcl, allAcl);\n-        scala.collection.immutable.Set<Acl> set2 = new scala.collection.immutable.Set.Set2<>(bazAcl, anonymousAcl);\n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map2<>(res1, set1, res2, set2);\n-        when(mockAuthorizer.getAcls()).thenReturn(map);\n-\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n-\n-        assertThat(aclOp.getUsersWithAcls(), is(new HashSet(asList(\"foo\", \"bar\", \"baz\"))));\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n+\n+        ResourcePattern res1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern res2 = new ResourcePattern(ResourceType.GROUP, \"my-group\", PatternType.LITERAL);\n+\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding fooAclBinding = new AclBinding(res1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal bar = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=bar\");\n+        AclBinding barAclBinding = new AclBinding(res1, new AccessControlEntry(bar.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal baz = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"baz\");\n+        AclBinding bazAclBinding = new AclBinding(res2, new AccessControlEntry(baz.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal all = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"*\");\n+        AclBinding allAclBinding = new AclBinding(res1, new AccessControlEntry(all.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal anonymous = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"ANONYMOUS\");\n+        AclBinding anonymousAclBinding = new AclBinding(res2, new AccessControlEntry(anonymous.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+\n+        Collection<AclBinding> aclBindings =\n+                asList(fooAclBinding, barAclBinding, bazAclBinding, allAclBinding, anonymousAclBinding);\n+\n+        assertDoesNotThrow(() -> mockDescribeAcls(mockAdminClient, AclBindingFilter.ANY, aclBindings));\n+        assertThat(aclOp.getUsersWithAcls(), is(new HashSet<>(asList(\"foo\", \"bar\", \"baz\"))));\n         context.completeNow();\n     }\n \n     @Test\n     public void testReconcileInternalCreateAddsAclsToAuthorizer(VertxTestContext context) {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.HashMap<Resource, scala.collection.immutable.Set<Acl>>();\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n+        ResourcePattern resource1 = new ResourcePattern(ResourceType.CLUSTER, \"kafka-cluster\", PatternType.LITERAL);\n+        ResourcePattern resource2 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> aclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> resourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        doNothing().when(mockAuthorizer).addAcls(aclCaptor.capture(), resourceCaptor.capture());\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding describeAclBinding = new AclBinding(resource1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.DESCRIBE, AclPermissionType.ALLOW));\n+        AclBinding readAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        AclBinding writeAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.WRITE, AclPermissionType.ALLOW));\n \n-        SimpleAclRuleResource ruleResource1 = new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.CLUSTER, AclResourcePatternType.LITERAL);\n+        SimpleAclRuleResource ruleResource1 = new SimpleAclRuleResource(\"kafka-cluster\", SimpleAclRuleResourceType.CLUSTER, AclResourcePatternType.LITERAL);\n         SimpleAclRuleResource ruleResource2 = new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n         SimpleAclRule resource1DescribeRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource1, \"*\", AclOperation.DESCRIBE);\n         SimpleAclRule resource2ReadRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource2, \"*\", AclOperation.READ);\n         SimpleAclRule resource2WriteRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource2, \"*\", AclOperation.WRITE);\n \n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl readAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Acl writeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Write$.MODULE$);\n-        Acl describeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Describe$.MODULE$);\n-        scala.collection.immutable.Set<Acl> expectedResource1RuleSet = new scala.collection.immutable.Set.Set1<>(describeAcl);\n-        scala.collection.immutable.Set<Acl> expectedResource2RuleSet = new scala.collection.immutable.Set.Set2<>(readAcl, writeAcl);\n-\n-        Resource resource1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource resource2 = new Resource(Cluster$.MODULE$, \"kafka-cluster\", PatternType.LITERAL);\n+        ArgumentCaptor<Collection<AclBinding>> aclBindingsCaptor = ArgumentCaptor.forClass(Collection.class);\n+        assertDoesNotThrow(() -> {\n+            mockDescribeAcls(mockAdminClient, null, emptyList());\n+            mockCreateAcls(mockAdminClient, aclBindingsCaptor);\n+        });\n \n         Checkpoint async = context.checkpoint();\n         aclOp.reconcile(\"CN=foo\", new LinkedHashSet<>(asList(resource2ReadRule, resource2WriteRule, resource1DescribeRule)))\n-            .setHandler(context.succeeding(rr -> context.verify(() -> {\n-                List<scala.collection.immutable.Set<Acl>> capturedAcls = aclCaptor.getAllValues();\n-                List<Resource> capturedResource = resourceCaptor.getAllValues();\n-\n-                assertThat(capturedAcls, hasSize(2));\n-                assertThat(capturedResource, hasSize(2));\n-\n-                assertThat(capturedResource, hasItems(resource1, resource2));\n-                assertThat(capturedAcls, hasItems(expectedResource1RuleSet, expectedResource2RuleSet));\n-\n-                async.flag();\n-            })));\n+                .setHandler(context.succeeding(rr -> context.verify(() -> {\n+                    Collection<AclBinding> capturedAclBindings = aclBindingsCaptor.getValue();\n+                    assertThat(capturedAclBindings, hasSize(3));\n+                    assertThat(capturedAclBindings, hasItems(describeAclBinding, readAclBinding, writeAclBinding));\n+\n+                    Set<ResourcePattern> capturedResourcePatterns =\n+                            capturedAclBindings.stream().map(AclBinding::pattern).collect(Collectors.toSet());\n+                    assertThat(capturedResourcePatterns, hasSize(2));\n+                    assertThat(capturedResourcePatterns, hasItems(resource1, resource2));\n+\n+                    async.flag();\n+                })));\n     }\n \n     @Test\n     public void testReconcileInternalUpdateCreatesNewAclsAndDeletesOldAcls(VertxTestContext context) {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n \n-        SimpleAclRuleResource resource = new SimpleAclRuleResource(\"my-topic2\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n-        SimpleAclRule rule1 = new SimpleAclRule(AclRuleType.ALLOW, resource, \"*\", AclOperation.WRITE);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl readAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        scala.collection.immutable.Set<Acl> readAclSet = new scala.collection.immutable.Set.Set1<>(readAcl);\n-        Acl writeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Write$.MODULE$);\n-        scala.collection.immutable.Set<Acl> writeAclSet = new scala.collection.immutable.Set.Set1<>(writeAcl);\n-\n-        Resource resource1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource resource2 = new Resource(Topic$.MODULE$, \"my-topic2\", PatternType.LITERAL);\n+        ResourcePattern resource1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern resource2 = new ResourcePattern(ResourceType.TOPIC, \"my-topic2\", PatternType.LITERAL);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map1<>(resource1, readAclSet);\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding readAclBinding = new AclBinding(resource1, new AccessControlEntry(foo.toString(), \"*\", org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        AclBinding writeAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\", org.apache.kafka.common.acl.AclOperation.WRITE, AclPermissionType.ALLOW));\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> aclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> resourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        doNothing().when(mockAuthorizer).addAcls(aclCaptor.capture(), resourceCaptor.capture());\n+        SimpleAclRuleResource resource = new SimpleAclRuleResource(\"my-topic2\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n+        SimpleAclRule rule1 = new SimpleAclRule(AclRuleType.ALLOW, resource, \"*\", AclOperation.WRITE);\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> deleteAclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> deleterResourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        when(mockAuthorizer.removeAcls(deleteAclCaptor.capture(), deleterResourceCaptor.capture())).thenReturn(true);\n+        ArgumentCaptor<Collection<AclBinding>> aclBindingsCaptor = ArgumentCaptor.forClass(Collection.class);\n+        ArgumentCaptor<Collection<AclBindingFilter>> aclBindingFiltersCaptor = ArgumentCaptor.forClass(Collection.class);\n+        assertDoesNotThrow(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NjU2Ng==", "bodyText": "The mock creation methods call a future.get which raise a couple of exceptions (i.e. InterruptedException). The first version had a try - catch block failing the test in the catch, while after @samuel-hawker suggestion I moved to this more convenient way.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403856566", "createdAt": "2020-04-06T06:32:26Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorTest.java", "diffHunk": "@@ -62,162 +71,187 @@ public static void after() {\n \n     @Test\n     public void testGetUsersFromAcls(VertxTestContext context)  {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl fooAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal bar = new KafkaPrincipal(\"User\", \"CN=bar\");\n-        Acl barAcl = new Acl(bar, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal baz = new KafkaPrincipal(\"User\", \"baz\");\n-        Acl bazAcl = new Acl(baz, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal all = new KafkaPrincipal(\"User\", \"*\");\n-        Acl allAcl = new Acl(all, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        KafkaPrincipal anonymous = new KafkaPrincipal(\"User\", \"ANONYMOUS\");\n-        Acl anonymousAcl = new Acl(anonymous, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Resource res1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource res2 = new Resource(Group$.MODULE$, \"my-group\", PatternType.LITERAL);\n-        scala.collection.immutable.Set<Acl> set1 = new scala.collection.immutable.Set.Set3<>(fooAcl, barAcl, allAcl);\n-        scala.collection.immutable.Set<Acl> set2 = new scala.collection.immutable.Set.Set2<>(bazAcl, anonymousAcl);\n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map2<>(res1, set1, res2, set2);\n-        when(mockAuthorizer.getAcls()).thenReturn(map);\n-\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n-\n-        assertThat(aclOp.getUsersWithAcls(), is(new HashSet(asList(\"foo\", \"bar\", \"baz\"))));\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n+\n+        ResourcePattern res1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern res2 = new ResourcePattern(ResourceType.GROUP, \"my-group\", PatternType.LITERAL);\n+\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding fooAclBinding = new AclBinding(res1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal bar = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=bar\");\n+        AclBinding barAclBinding = new AclBinding(res1, new AccessControlEntry(bar.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal baz = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"baz\");\n+        AclBinding bazAclBinding = new AclBinding(res2, new AccessControlEntry(baz.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal all = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"*\");\n+        AclBinding allAclBinding = new AclBinding(res1, new AccessControlEntry(all.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        KafkaPrincipal anonymous = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"ANONYMOUS\");\n+        AclBinding anonymousAclBinding = new AclBinding(res2, new AccessControlEntry(anonymous.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+\n+        Collection<AclBinding> aclBindings =\n+                asList(fooAclBinding, barAclBinding, bazAclBinding, allAclBinding, anonymousAclBinding);\n+\n+        assertDoesNotThrow(() -> mockDescribeAcls(mockAdminClient, AclBindingFilter.ANY, aclBindings));\n+        assertThat(aclOp.getUsersWithAcls(), is(new HashSet<>(asList(\"foo\", \"bar\", \"baz\"))));\n         context.completeNow();\n     }\n \n     @Test\n     public void testReconcileInternalCreateAddsAclsToAuthorizer(VertxTestContext context) {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.HashMap<Resource, scala.collection.immutable.Set<Acl>>();\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n+        ResourcePattern resource1 = new ResourcePattern(ResourceType.CLUSTER, \"kafka-cluster\", PatternType.LITERAL);\n+        ResourcePattern resource2 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> aclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> resourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        doNothing().when(mockAuthorizer).addAcls(aclCaptor.capture(), resourceCaptor.capture());\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding describeAclBinding = new AclBinding(resource1, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.DESCRIBE, AclPermissionType.ALLOW));\n+        AclBinding readAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        AclBinding writeAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\",\n+                org.apache.kafka.common.acl.AclOperation.WRITE, AclPermissionType.ALLOW));\n \n-        SimpleAclRuleResource ruleResource1 = new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.CLUSTER, AclResourcePatternType.LITERAL);\n+        SimpleAclRuleResource ruleResource1 = new SimpleAclRuleResource(\"kafka-cluster\", SimpleAclRuleResourceType.CLUSTER, AclResourcePatternType.LITERAL);\n         SimpleAclRuleResource ruleResource2 = new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n         SimpleAclRule resource1DescribeRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource1, \"*\", AclOperation.DESCRIBE);\n         SimpleAclRule resource2ReadRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource2, \"*\", AclOperation.READ);\n         SimpleAclRule resource2WriteRule = new SimpleAclRule(AclRuleType.ALLOW, ruleResource2, \"*\", AclOperation.WRITE);\n \n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl readAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        Acl writeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Write$.MODULE$);\n-        Acl describeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Describe$.MODULE$);\n-        scala.collection.immutable.Set<Acl> expectedResource1RuleSet = new scala.collection.immutable.Set.Set1<>(describeAcl);\n-        scala.collection.immutable.Set<Acl> expectedResource2RuleSet = new scala.collection.immutable.Set.Set2<>(readAcl, writeAcl);\n-\n-        Resource resource1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource resource2 = new Resource(Cluster$.MODULE$, \"kafka-cluster\", PatternType.LITERAL);\n+        ArgumentCaptor<Collection<AclBinding>> aclBindingsCaptor = ArgumentCaptor.forClass(Collection.class);\n+        assertDoesNotThrow(() -> {\n+            mockDescribeAcls(mockAdminClient, null, emptyList());\n+            mockCreateAcls(mockAdminClient, aclBindingsCaptor);\n+        });\n \n         Checkpoint async = context.checkpoint();\n         aclOp.reconcile(\"CN=foo\", new LinkedHashSet<>(asList(resource2ReadRule, resource2WriteRule, resource1DescribeRule)))\n-            .setHandler(context.succeeding(rr -> context.verify(() -> {\n-                List<scala.collection.immutable.Set<Acl>> capturedAcls = aclCaptor.getAllValues();\n-                List<Resource> capturedResource = resourceCaptor.getAllValues();\n-\n-                assertThat(capturedAcls, hasSize(2));\n-                assertThat(capturedResource, hasSize(2));\n-\n-                assertThat(capturedResource, hasItems(resource1, resource2));\n-                assertThat(capturedAcls, hasItems(expectedResource1RuleSet, expectedResource2RuleSet));\n-\n-                async.flag();\n-            })));\n+                .setHandler(context.succeeding(rr -> context.verify(() -> {\n+                    Collection<AclBinding> capturedAclBindings = aclBindingsCaptor.getValue();\n+                    assertThat(capturedAclBindings, hasSize(3));\n+                    assertThat(capturedAclBindings, hasItems(describeAclBinding, readAclBinding, writeAclBinding));\n+\n+                    Set<ResourcePattern> capturedResourcePatterns =\n+                            capturedAclBindings.stream().map(AclBinding::pattern).collect(Collectors.toSet());\n+                    assertThat(capturedResourcePatterns, hasSize(2));\n+                    assertThat(capturedResourcePatterns, hasItems(resource1, resource2));\n+\n+                    async.flag();\n+                })));\n     }\n \n     @Test\n     public void testReconcileInternalUpdateCreatesNewAclsAndDeletesOldAcls(VertxTestContext context) {\n-        SimpleAclAuthorizer mockAuthorizer = mock(SimpleAclAuthorizer.class);\n-        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAuthorizer);\n+        Admin mockAdminClient = mock(AdminClient.class);\n+        SimpleAclOperator aclOp = new SimpleAclOperator(vertx, mockAdminClient);\n \n-        SimpleAclRuleResource resource = new SimpleAclRuleResource(\"my-topic2\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n-        SimpleAclRule rule1 = new SimpleAclRule(AclRuleType.ALLOW, resource, \"*\", AclOperation.WRITE);\n-\n-        KafkaPrincipal foo = new KafkaPrincipal(\"User\", \"CN=foo\");\n-        Acl readAcl = new Acl(foo, Allow$.MODULE$, \"*\", Read$.MODULE$);\n-        scala.collection.immutable.Set<Acl> readAclSet = new scala.collection.immutable.Set.Set1<>(readAcl);\n-        Acl writeAcl = new Acl(foo, Allow$.MODULE$, \"*\", Write$.MODULE$);\n-        scala.collection.immutable.Set<Acl> writeAclSet = new scala.collection.immutable.Set.Set1<>(writeAcl);\n-\n-        Resource resource1 = new Resource(Topic$.MODULE$, \"my-topic\", PatternType.LITERAL);\n-        Resource resource2 = new Resource(Topic$.MODULE$, \"my-topic2\", PatternType.LITERAL);\n+        ResourcePattern resource1 = new ResourcePattern(ResourceType.TOPIC, \"my-topic\", PatternType.LITERAL);\n+        ResourcePattern resource2 = new ResourcePattern(ResourceType.TOPIC, \"my-topic2\", PatternType.LITERAL);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> map = new scala.collection.immutable.Map.Map1<>(resource1, readAclSet);\n-        ArgumentCaptor<KafkaPrincipal> principalCaptor = ArgumentCaptor.forClass(KafkaPrincipal.class);\n-        when(mockAuthorizer.getAcls(principalCaptor.capture())).thenReturn(map);\n+        KafkaPrincipal foo = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, \"CN=foo\");\n+        AclBinding readAclBinding = new AclBinding(resource1, new AccessControlEntry(foo.toString(), \"*\", org.apache.kafka.common.acl.AclOperation.READ, AclPermissionType.ALLOW));\n+        AclBinding writeAclBinding = new AclBinding(resource2, new AccessControlEntry(foo.toString(), \"*\", org.apache.kafka.common.acl.AclOperation.WRITE, AclPermissionType.ALLOW));\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> aclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> resourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        doNothing().when(mockAuthorizer).addAcls(aclCaptor.capture(), resourceCaptor.capture());\n+        SimpleAclRuleResource resource = new SimpleAclRuleResource(\"my-topic2\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL);\n+        SimpleAclRule rule1 = new SimpleAclRule(AclRuleType.ALLOW, resource, \"*\", AclOperation.WRITE);\n \n-        ArgumentCaptor<scala.collection.immutable.Set<Acl>> deleteAclCaptor = ArgumentCaptor.forClass(scala.collection.immutable.Set.class);\n-        ArgumentCaptor<Resource> deleterResourceCaptor = ArgumentCaptor.forClass(Resource.class);\n-        when(mockAuthorizer.removeAcls(deleteAclCaptor.capture(), deleterResourceCaptor.capture())).thenReturn(true);\n+        ArgumentCaptor<Collection<AclBinding>> aclBindingsCaptor = ArgumentCaptor.forClass(Collection.class);\n+        ArgumentCaptor<Collection<AclBindingFilter>> aclBindingFiltersCaptor = ArgumentCaptor.forClass(Collection.class);\n+        assertDoesNotThrow(() -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTE5MQ=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 228}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjg0ODE4OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMDozN1rOGAx0qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMDozN1rOGAx0qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTQ4Mw==", "bodyText": "This will be blocking. I think you should use getAsync or wrap the whole thing into executeBlocking (I think doing it async would be obviously better).", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403469483", "createdAt": "2020-04-04T13:20:37Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "diffHunk": "@@ -104,19 +109,19 @@ public static void main(String[] args) {\n         return promise.future();\n     }\n \n-    private static kafka.security.auth.SimpleAclAuthorizer createSimpleAclAuthorizer(UserOperatorConfig config) {\n-        log.debug(\"Creating SimpleAclAuthorizer for Zookeeper {}\", config.getZookeperConnect());\n-        Map<String, Object> authorizerConfig = new HashMap<>();\n-        // The SimpleAclAuthorizer from KAfka requires the Zookeeper URL to be provided twice.\n-        // See the comments in the SimpleAclAuthorizer.scala class for more details\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkUrlProp(), config.getZookeperConnect());\n-        authorizerConfig.put(\"zookeeper.connect\", config.getZookeperConnect());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkConnectionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkSessionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n+    private static Admin createAdminClient(AdminClientProvider adminClientProvider, UserOperatorConfig config, SecretOperator secretOperations) {\n+        Secret clusterCaCert = null;\n+        if (config.getClusterCaCertSecretName() != null && !config.getClusterCaCertSecretName().isEmpty()) {\n+            clusterCaCert = secretOperations.get(config.getCaNamespace(), config.getClusterCaCertSecretName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjg0ODM4OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMTowNFrOGAx0yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMTowNFrOGAx0yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTUxMg==", "bodyText": "Same as above ... getAsync or executeBlocking.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403469512", "createdAt": "2020-04-04T13:21:04Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "diffHunk": "@@ -104,19 +109,19 @@ public static void main(String[] args) {\n         return promise.future();\n     }\n \n-    private static kafka.security.auth.SimpleAclAuthorizer createSimpleAclAuthorizer(UserOperatorConfig config) {\n-        log.debug(\"Creating SimpleAclAuthorizer for Zookeeper {}\", config.getZookeperConnect());\n-        Map<String, Object> authorizerConfig = new HashMap<>();\n-        // The SimpleAclAuthorizer from KAfka requires the Zookeeper URL to be provided twice.\n-        // See the comments in the SimpleAclAuthorizer.scala class for more details\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkUrlProp(), config.getZookeperConnect());\n-        authorizerConfig.put(\"zookeeper.connect\", config.getZookeperConnect());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkConnectionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkSessionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n+    private static Admin createAdminClient(AdminClientProvider adminClientProvider, UserOperatorConfig config, SecretOperator secretOperations) {\n+        Secret clusterCaCert = null;\n+        if (config.getClusterCaCertSecretName() != null && !config.getClusterCaCertSecretName().isEmpty()) {\n+            clusterCaCert = secretOperations.get(config.getCaNamespace(), config.getClusterCaCertSecretName());\n+        }\n+        Secret eoKey = null;\n+        if (config.getEoKeySecretName() != null && !config.getEoKeySecretName().isEmpty()) {\n+            eoKey = secretOperations.get(config.getCaNamespace(), config.getEoKeySecretName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjg0OTQ2OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMjo0MFrOGAx1TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMjo0MFrOGAx1TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTY0NQ==", "bodyText": "I think the naming here is a bit confusing for me. Could we call this clusterCaCertSecret?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403469645", "createdAt": "2020-04-04T13:22:40Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "diffHunk": "@@ -104,19 +109,19 @@ public static void main(String[] args) {\n         return promise.future();\n     }\n \n-    private static kafka.security.auth.SimpleAclAuthorizer createSimpleAclAuthorizer(UserOperatorConfig config) {\n-        log.debug(\"Creating SimpleAclAuthorizer for Zookeeper {}\", config.getZookeperConnect());\n-        Map<String, Object> authorizerConfig = new HashMap<>();\n-        // The SimpleAclAuthorizer from KAfka requires the Zookeeper URL to be provided twice.\n-        // See the comments in the SimpleAclAuthorizer.scala class for more details\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkUrlProp(), config.getZookeperConnect());\n-        authorizerConfig.put(\"zookeeper.connect\", config.getZookeperConnect());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkConnectionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkSessionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n+    private static Admin createAdminClient(AdminClientProvider adminClientProvider, UserOperatorConfig config, SecretOperator secretOperations) {\n+        Secret clusterCaCert = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwMjg0OTg1OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMzoyNFrOGAx1hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNFQxMzoyMzoyNFrOGAx1hQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ2OTcwMQ==", "bodyText": "Could we name this eoKeySecret? It is a bit confusing when reading the code since the key is also inside the secret.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403469701", "createdAt": "2020-04-04T13:23:24Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/Main.java", "diffHunk": "@@ -104,19 +109,19 @@ public static void main(String[] args) {\n         return promise.future();\n     }\n \n-    private static kafka.security.auth.SimpleAclAuthorizer createSimpleAclAuthorizer(UserOperatorConfig config) {\n-        log.debug(\"Creating SimpleAclAuthorizer for Zookeeper {}\", config.getZookeperConnect());\n-        Map<String, Object> authorizerConfig = new HashMap<>();\n-        // The SimpleAclAuthorizer from KAfka requires the Zookeeper URL to be provided twice.\n-        // See the comments in the SimpleAclAuthorizer.scala class for more details\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkUrlProp(), config.getZookeperConnect());\n-        authorizerConfig.put(\"zookeeper.connect\", config.getZookeperConnect());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkConnectionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n-        authorizerConfig.put(kafka.security.auth.SimpleAclAuthorizer.ZkSessionTimeOutProp(), config.getZookeeperSessionTimeoutMs());\n+    private static Admin createAdminClient(AdminClientProvider adminClientProvider, UserOperatorConfig config, SecretOperator secretOperations) {\n+        Secret clusterCaCert = null;\n+        if (config.getClusterCaCertSecretName() != null && !config.getClusterCaCertSecretName().isEmpty()) {\n+            clusterCaCert = secretOperations.get(config.getCaNamespace(), config.getClusterCaCertSecretName());\n+        }\n+        Secret eoKey = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNjA4NDU5OnYy", "diffSide": "RIGHT", "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzoyMzozMVrOGBKyAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMDo1MDoxN1rOGCVl9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3ODQwMA==", "bodyText": "It seems to me that this method now copes with various cases where kets in secrets are absent etc. I guess that must imply that the AdminClientProvider contract is broader, so we should probably javadoc what the various cases are in the AdminClientProvider, right?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403878400", "createdAt": "2020-04-06T07:23:31Z", "author": {"login": "tombentley"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE3NTA3NA==", "bodyText": "@tombentley can you take a look now please?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404175074", "createdAt": "2020-04-06T15:19:25Z", "author": {"login": "ppatierno"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3ODQwMA=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg2MzExMA==", "bodyText": "I think this should be documented in the interface.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404863110", "createdAt": "2020-04-07T14:41:06Z", "author": {"login": "tombentley"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3ODQwMA=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwNDExOQ==", "bodyText": "I documented on the specific \"Default\" implementation, because the behaviour of this method is defined by the implementation itself. I mean, we could have another implementation where if you pass Secrets as null, you got an exception because it's a sort of \"TLS only\" interface implementation. Documenting on the interface level we are saying that all the implementations should behave in the same way, or? Of course they have same interface but could have a different internal behavior.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r405104119", "createdAt": "2020-04-07T20:50:17Z", "author": {"login": "ppatierno"}, "path": "operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java", "diffHunk": "@@ -23,34 +23,57 @@\n     @Override\n     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg3ODQwMA=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNjEwMTY2OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzoyODozNVrOGBK7_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNDo1OTozOFrOGBb-9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg4MDk1Nw==", "bodyText": "Do we stil need to have our own AclPermissionType, since it seems to have a subset of the cases of type?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403880957", "createdAt": "2020-04-06T07:28:35Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE1ODQxMQ==", "bodyText": "Maybe I didn't get what you mean but the type is a AclRuleType from our API model which is used in how we describe the ACLs in our KafkaUser resource. Here we are mapping this one to the Kafka provided AclPermissionType which is necessary for creating the Kafka objects (see AccessControlEntry) used by the Admin Client.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404158411", "createdAt": "2020-04-06T14:57:28Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg4MDk1Nw=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE2MDI0Nw==", "bodyText": "Ah, OK! I didn't notice that it was from our api model (I thought it might be something internal to the UO). That's OK then.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404160247", "createdAt": "2020-04-06T14:59:38Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg4MDk1Nw=="}, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNjEwMzUyOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzoyOTowNFrOGBK9FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNzoyOTowNFrOGBK9FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg4MTIzNg==", "bodyText": "Similarly, is there a benefit to having operation and kafkaOperation?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r403881236", "createdAt": "2020-04-06T07:29:04Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "daa28e0fb8719b18e275c285e90347abdd529105"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNzk5NjUxOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNToyNToyMVrOGBdLog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0NTowOFrOGBeGRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE3OTg3NA==", "bodyText": "I think it would be clearer to have a case for ANY, even if it only falls through to the default case.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404179874", "createdAt": "2020-04-06T15:25:21Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4ODI3MQ==", "bodyText": "but our current API model doesn't allow ANY. The type enum, so AclRuleType is just ALLOW and DENY.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404188271", "createdAt": "2020-04-06T15:36:28Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE3OTg3NA=="}, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5NDg4NA==", "bodyText": "True, this is going the other way than I thought. Obviously I must be tired \ud83d\ude04", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404194884", "createdAt": "2020-04-06T15:45:08Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE3OTg3NA=="}, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODAwNDc2OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNToyNzoxNVrOGBdRCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTozNzoxOVrOGBdvFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MTI1Ng==", "bodyText": "Again, there's an ANY which is probably meant to be handled in the same way as the default case, but it would be good to be explicit.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404181256", "createdAt": "2020-04-06T15:27:15Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4ODk0OA==", "bodyText": "Ditto as above, ANY is not a valid value in our corresponding API.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404188948", "createdAt": "2020-04-06T15:37:19Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MTI1Ng=="}, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODAxMDAyOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNToyODoxOVrOGBdUWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0ODo1OFrOGBeReQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MjEwNw==", "bodyText": "It's tidier to have a method which just converns the permission type, and another which just converts the operation, than to put the logic for both in here.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404182107", "createdAt": "2020-04-06T15:28:19Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5Nzc1Mw==", "bodyText": "I had this in mind since the beginning and ... of course, I forgot to refactor!", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404197753", "createdAt": "2020-04-06T15:48:58Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -118,6 +121,118 @@ public String toString() {\n                 \"operation: \" + operation + \")\";\n     }\n \n+    public AccessControlEntry toKafkaAccessControlEntry(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }\n+\n+        switch (operation) {\n+            case READ:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.READ;\n+                break;\n+            case WRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTERACTION:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.CLUSTER_ACTION;\n+                break;\n+            case ALTERCONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALTER_CONFIGS;\n+                break;\n+            case DESCRIBECONFIGS:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.DESCRIBE_CONFIGS;\n+                break;\n+            case IDEMPOTENTWRITE:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.IDEMPOTENT_WRITE;\n+                break;\n+            case ALL:\n+                kafkaOperation = org.apache.kafka.common.acl.AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl operation: \" + operation);\n+        }\n+\n+        return new AccessControlEntry(principal.toString(), getHost(), kafkaOperation, kafkaType);\n+    }\n+\n+    public AccessControlEntryFilter toKafkaAccessControlEntryFilter(KafkaPrincipal principal)   {\n+        AclPermissionType kafkaType;\n+        org.apache.kafka.common.acl.AclOperation kafkaOperation;\n+\n+        switch (type) {\n+            case DENY:\n+                kafkaType = AclPermissionType.DENY;\n+                break;\n+            case ALLOW:\n+                kafkaType = AclPermissionType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid Acl type: \" + type);\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MjEwNw=="}, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODAxMzMwOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNToyODo1OVrOGBdWWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0OToxOFrOGBeSgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MjYxNg==", "bodyText": "Can comment here about having two separate methods for these.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404182616", "createdAt": "2020-04-06T15:28:59Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -180,6 +295,62 @@ public Acl toKafkaAcl(KafkaPrincipal principal)   {\n         return new Acl(principal, kafkaType, getHost(), kafkaOperation);\n     }\n \n+    public static SimpleAclRule fromKafkaAccessControlEntry(SimpleAclRuleResource resource, AccessControlEntry accessControlEntry)   {\n+        AclRuleType type;\n+        AclOperation operation;\n+\n+        switch (accessControlEntry.permissionType()) {\n+            case DENY:\n+                type = AclRuleType.DENY;\n+                break;\n+            case ALLOW:\n+                type = AclRuleType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid AclRule type: \" + accessControlEntry.permissionType());\n+        }\n+\n+        switch (accessControlEntry.operation()) {\n+            case READ:\n+                operation = AclOperation.READ;\n+                break;\n+            case WRITE:\n+                operation = AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                operation = AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                operation = AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                operation = AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                operation = AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTER_ACTION:\n+                operation = AclOperation.CLUSTERACTION;\n+                break;\n+            case ALTER_CONFIGS:\n+                operation = AclOperation.ALTERCONFIGS;\n+                break;\n+            case DESCRIBE_CONFIGS:\n+                operation = AclOperation.DESCRIBECONFIGS;\n+                break;\n+            case IDEMPOTENT_WRITE:\n+                operation = AclOperation.IDEMPOTENTWRITE;\n+                break;\n+            case ALL:\n+                operation = AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid AclRule operation: \" + accessControlEntry.operation());\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5ODAxNw==", "bodyText": "Ditto as above", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404198017", "createdAt": "2020-04-06T15:49:18Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRule.java", "diffHunk": "@@ -180,6 +295,62 @@ public Acl toKafkaAcl(KafkaPrincipal principal)   {\n         return new Acl(principal, kafkaType, getHost(), kafkaOperation);\n     }\n \n+    public static SimpleAclRule fromKafkaAccessControlEntry(SimpleAclRuleResource resource, AccessControlEntry accessControlEntry)   {\n+        AclRuleType type;\n+        AclOperation operation;\n+\n+        switch (accessControlEntry.permissionType()) {\n+            case DENY:\n+                type = AclRuleType.DENY;\n+                break;\n+            case ALLOW:\n+                type = AclRuleType.ALLOW;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid AclRule type: \" + accessControlEntry.permissionType());\n+        }\n+\n+        switch (accessControlEntry.operation()) {\n+            case READ:\n+                operation = AclOperation.READ;\n+                break;\n+            case WRITE:\n+                operation = AclOperation.WRITE;\n+                break;\n+            case CREATE:\n+                operation = AclOperation.CREATE;\n+                break;\n+            case DELETE:\n+                operation = AclOperation.DELETE;\n+                break;\n+            case ALTER:\n+                operation = AclOperation.ALTER;\n+                break;\n+            case DESCRIBE:\n+                operation = AclOperation.DESCRIBE;\n+                break;\n+            case CLUSTER_ACTION:\n+                operation = AclOperation.CLUSTERACTION;\n+                break;\n+            case ALTER_CONFIGS:\n+                operation = AclOperation.ALTERCONFIGS;\n+                break;\n+            case DESCRIBE_CONFIGS:\n+                operation = AclOperation.DESCRIBECONFIGS;\n+                break;\n+            case IDEMPOTENT_WRITE:\n+                operation = AclOperation.IDEMPOTENTWRITE;\n+                break;\n+            case ALL:\n+                operation = AclOperation.ALL;\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Invalid AclRule operation: \" + accessControlEntry.operation());\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MjYxNg=="}, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODAxOTI2OnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRuleResource.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTozMDoyMlrOGBdaTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTozMDoyMlrOGBdaTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE4MzYyOA==", "bodyText": "I think there's a method you can factor out here.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404183628", "createdAt": "2020-04-06T15:30:22Z", "author": {"login": "tombentley"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRuleResource.java", "diffHunk": "@@ -145,6 +235,71 @@ public Resource toKafkaResource()   {\n         return new Resource(kafkaType, kafkaName, kafkaPattern);\n     }\n \n+    public static SimpleAclRuleResource fromKafkaResourcePattern(ResourcePattern kafkaResourcePattern) {\n+        String resourceName;\n+        SimpleAclRuleResourceType resourceType;\n+        AclResourcePatternType resourcePattern = null;\n+\n+        switch (kafkaResourcePattern.resourceType()) {\n+            case TOPIC:\n+                resourceName = kafkaResourcePattern.name();\n+                resourceType = SimpleAclRuleResourceType.TOPIC;\n+\n+                switch (kafkaResourcePattern.patternType()) {\n+                    case LITERAL:\n+                        resourcePattern = AclResourcePatternType.LITERAL;\n+                        break;\n+                    case PREFIXED:\n+                        resourcePattern = AclResourcePatternType.PREFIX;\n+                        break;\n+                    default:\n+                        throw new IllegalArgumentException(\"Invalid Resource type: \" + kafkaResourcePattern.resourceType());\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c3bd1f92c5008aab5f598efd54b44dab3f5120"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjM3ODg1OnYy", "diffSide": "RIGHT", "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorIT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNDo1Mjo1OFrOGCHd4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMDo0ODowOVrOGCVhMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg3MjY3NA==", "bodyText": "I guess we ought to have broader coverage of the space than just this. Can we try creating a whole bunch of rules with different rule types, operations, resource types and pattern types? Maybe try a parameterized test?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r404872674", "createdAt": "2020-04-07T14:52:58Z", "author": {"login": "tombentley"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorIT.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.user.operator;\n+\n+import io.debezium.kafka.KafkaCluster;\n+import io.debezium.util.Testing;\n+import io.strimzi.api.kafka.model.AclOperation;\n+import io.strimzi.api.kafka.model.AclResourcePatternType;\n+import io.strimzi.api.kafka.model.AclRuleType;\n+import io.strimzi.operator.common.DefaultAdminClientProvider;\n+import io.strimzi.operator.user.model.acl.SimpleAclRule;\n+import io.strimzi.operator.user.model.acl.SimpleAclRuleResource;\n+import io.strimzi.operator.user.model.acl.SimpleAclRuleResourceType;\n+import io.vertx.core.Vertx;\n+import io.vertx.junit5.VertxExtension;\n+import io.vertx.junit5.VertxTestContext;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.hamcrest.collection.IsEmptyCollection;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static java.util.Arrays.asList;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.hasItem;\n+import static org.hamcrest.CoreMatchers.hasItems;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+\n+@ExtendWith(VertxExtension.class)\n+public class SimpleAclOperatorIT {\n+\n+    private static final Logger log = LogManager.getLogger(SimpleAclOperatorIT.class);\n+    private static final int TEST_TIMEOUT = 60;\n+\n+    private static Vertx vertx;\n+\n+    private static KafkaCluster kafkaCluster;\n+\n+    private static SimpleAclOperator simpleAclOperator;\n+\n+    private static Properties kafkaClusterConfig() {\n+        Properties config = new Properties();\n+        config.setProperty(\"authorizer.class.name\", \"kafka.security.auth.SimpleAclAuthorizer\");\n+        config.setProperty(\"super.users\", \"User:ANONYMOUS\");\n+        return config;\n+    }\n+\n+    @BeforeAll\n+    public static void beforeAll() {\n+        vertx = Vertx.vertx();\n+\n+        try {\n+            kafkaCluster =\n+                    new KafkaCluster()\n+                            .usingDirectory(Testing.Files.createTestingDirectory(\"simple-acl-operator-integration-test\"))\n+                            .deleteDataPriorToStartup(true)\n+                            .deleteDataUponShutdown(true)\n+                            .addBrokers(1)\n+                            .withKafkaConfiguration(kafkaClusterConfig())\n+                            .startup();\n+        } catch (IOException e) {\n+            assertThat(false, is(true));\n+        }\n+\n+        simpleAclOperator = new SimpleAclOperator(vertx,\n+                new DefaultAdminClientProvider().createAdminClient(kafkaCluster.brokerList(), null, null, null));\n+    }\n+\n+    @Test\n+    public void testNoAclRules(VertxTestContext context) {\n+        Set<SimpleAclRule> acls = simpleAclOperator.getAcls(\"no-acls-user\");\n+        context.verify(() -> {\n+            assertThat(acls, IsEmptyCollection.empty());\n+        });\n+        context.completeNow();\n+    }\n+\n+    @Test\n+    public void testCreateAclRule(VertxTestContext context) throws InterruptedException {\n+        SimpleAclRule rule = new SimpleAclRule(\n+                AclRuleType.ALLOW,\n+                new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL),\n+                \"*\",\n+                AclOperation.READ);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9f3af7b824c883a6876dd607b7865f68cdaf005f"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwMjg5OQ==", "bodyText": "I was wondering how much is it important for what we are testing here.\nWe are not testing that the rule is really enforced after its creation, I mean we are not starting a real client authenticating with the user and trying to read from that topic; we are testing that the rule is created and this operation should be independent from what kind of rule we are creating (on topic, group, ... read, write, ...).", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r405102899", "createdAt": "2020-04-07T20:48:09Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorIT.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.operator.user.operator;\n+\n+import io.debezium.kafka.KafkaCluster;\n+import io.debezium.util.Testing;\n+import io.strimzi.api.kafka.model.AclOperation;\n+import io.strimzi.api.kafka.model.AclResourcePatternType;\n+import io.strimzi.api.kafka.model.AclRuleType;\n+import io.strimzi.operator.common.DefaultAdminClientProvider;\n+import io.strimzi.operator.user.model.acl.SimpleAclRule;\n+import io.strimzi.operator.user.model.acl.SimpleAclRuleResource;\n+import io.strimzi.operator.user.model.acl.SimpleAclRuleResourceType;\n+import io.vertx.core.Vertx;\n+import io.vertx.junit5.VertxExtension;\n+import io.vertx.junit5.VertxTestContext;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.hamcrest.collection.IsEmptyCollection;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static java.util.Arrays.asList;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.hasItem;\n+import static org.hamcrest.CoreMatchers.hasItems;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+\n+@ExtendWith(VertxExtension.class)\n+public class SimpleAclOperatorIT {\n+\n+    private static final Logger log = LogManager.getLogger(SimpleAclOperatorIT.class);\n+    private static final int TEST_TIMEOUT = 60;\n+\n+    private static Vertx vertx;\n+\n+    private static KafkaCluster kafkaCluster;\n+\n+    private static SimpleAclOperator simpleAclOperator;\n+\n+    private static Properties kafkaClusterConfig() {\n+        Properties config = new Properties();\n+        config.setProperty(\"authorizer.class.name\", \"kafka.security.auth.SimpleAclAuthorizer\");\n+        config.setProperty(\"super.users\", \"User:ANONYMOUS\");\n+        return config;\n+    }\n+\n+    @BeforeAll\n+    public static void beforeAll() {\n+        vertx = Vertx.vertx();\n+\n+        try {\n+            kafkaCluster =\n+                    new KafkaCluster()\n+                            .usingDirectory(Testing.Files.createTestingDirectory(\"simple-acl-operator-integration-test\"))\n+                            .deleteDataPriorToStartup(true)\n+                            .deleteDataUponShutdown(true)\n+                            .addBrokers(1)\n+                            .withKafkaConfiguration(kafkaClusterConfig())\n+                            .startup();\n+        } catch (IOException e) {\n+            assertThat(false, is(true));\n+        }\n+\n+        simpleAclOperator = new SimpleAclOperator(vertx,\n+                new DefaultAdminClientProvider().createAdminClient(kafkaCluster.brokerList(), null, null, null));\n+    }\n+\n+    @Test\n+    public void testNoAclRules(VertxTestContext context) {\n+        Set<SimpleAclRule> acls = simpleAclOperator.getAcls(\"no-acls-user\");\n+        context.verify(() -> {\n+            assertThat(acls, IsEmptyCollection.empty());\n+        });\n+        context.completeNow();\n+    }\n+\n+    @Test\n+    public void testCreateAclRule(VertxTestContext context) throws InterruptedException {\n+        SimpleAclRule rule = new SimpleAclRule(\n+                AclRuleType.ALLOW,\n+                new SimpleAclRuleResource(\"my-topic\", SimpleAclRuleResourceType.TOPIC, AclResourcePatternType.LITERAL),\n+                \"*\",\n+                AclOperation.READ);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg3MjY3NA=="}, "originalCommit": {"oid": "9f3af7b824c883a6876dd607b7865f68cdaf005f"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTcxMTExOnYy", "diffSide": "RIGHT", "path": "user-operator/src/main/java/io/strimzi/operator/user/operator/SimpleAclOperator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxOTowNToyN1rOGGHoIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDo1MDo0NlrOGGLEOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA2OTYwMw==", "bodyText": "Do we need to check the message here to make sure this does not hide some other exception?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r409069603", "createdAt": "2020-04-15T19:05:27Z", "author": {"login": "scholzj"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/operator/SimpleAclOperator.java", "diffHunk": "@@ -190,84 +200,72 @@ public SimpleAclOperator(Vertx vertx, kafka.security.auth.SimpleAclAuthorizer au\n      */\n     public Set<SimpleAclRule> getAcls(String username)   {\n         log.debug(\"Searching for ACL rules of user {}\", username);\n-        Set<SimpleAclRule> result = new HashSet<SimpleAclRule>();\n+        Set<SimpleAclRule> result = new HashSet<>();\n         KafkaPrincipal principal = new KafkaPrincipal(\"User\", username);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> rules;\n+        AclBindingFilter aclBindingFilter = new AclBindingFilter(ResourcePatternFilter.ANY,\n+            new AccessControlEntryFilter(principal.toString(), null, AclOperation.ANY, AclPermissionType.ANY));\n \n+        Collection<AclBinding> aclBindings = null;\n         try {\n-            rules = authorizer.getAcls(principal);\n-        } catch (Exception e)   {\n-            log.error(\"Failed to get existing Acls rules for user {}\", username, e);\n-            throw e;\n+            aclBindings = adminClient.describeAcls(aclBindingFilter).values().get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            // Admin Client API needs authorizer enabled on the Kafka brokers\n+            if (e.getCause() instanceof SecurityDisabledException) {\n+                throw new InvalidResourceException(\"Authorization needs to be enabled in the Kafka custom resource\", e.getCause());\n+            } else if (e.getCause() instanceof UnknownServerException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ab7b1745d460a74ea4f577ca0668ab869c495bd"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTEyNTk0NQ==", "bodyText": "Taking a look at Kafka codebase it could make sense because there are other scenarios raising this kind of exception.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2783#discussion_r409125945", "createdAt": "2020-04-15T20:50:46Z", "author": {"login": "ppatierno"}, "path": "user-operator/src/main/java/io/strimzi/operator/user/operator/SimpleAclOperator.java", "diffHunk": "@@ -190,84 +200,72 @@ public SimpleAclOperator(Vertx vertx, kafka.security.auth.SimpleAclAuthorizer au\n      */\n     public Set<SimpleAclRule> getAcls(String username)   {\n         log.debug(\"Searching for ACL rules of user {}\", username);\n-        Set<SimpleAclRule> result = new HashSet<SimpleAclRule>();\n+        Set<SimpleAclRule> result = new HashSet<>();\n         KafkaPrincipal principal = new KafkaPrincipal(\"User\", username);\n \n-        scala.collection.immutable.Map<Resource, scala.collection.immutable.Set<Acl>> rules;\n+        AclBindingFilter aclBindingFilter = new AclBindingFilter(ResourcePatternFilter.ANY,\n+            new AccessControlEntryFilter(principal.toString(), null, AclOperation.ANY, AclPermissionType.ANY));\n \n+        Collection<AclBinding> aclBindings = null;\n         try {\n-            rules = authorizer.getAcls(principal);\n-        } catch (Exception e)   {\n-            log.error(\"Failed to get existing Acls rules for user {}\", username, e);\n-            throw e;\n+            aclBindings = adminClient.describeAcls(aclBindingFilter).values().get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            // Admin Client API needs authorizer enabled on the Kafka brokers\n+            if (e.getCause() instanceof SecurityDisabledException) {\n+                throw new InvalidResourceException(\"Authorization needs to be enabled in the Kafka custom resource\", e.getCause());\n+            } else if (e.getCause() instanceof UnknownServerException) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA2OTYwMw=="}, "originalCommit": {"oid": "7ab7b1745d460a74ea4f577ca0668ab869c495bd"}, "originalPosition": 197}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 401, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}