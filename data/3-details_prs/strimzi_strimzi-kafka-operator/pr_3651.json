{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3MzU5Njcw", "number": 3651, "title": "[MO] - [system test] -> test suite of multiple listeners", "bodyText": "Signed-off-by: morsak xorsak02@stud.fit.vutbr.cz\nType of change\n\nEnhancement / new feature\nRefactoring\n\nDescription\nThis PR introduces a new system suite for a related feature of #3603.\nTest cases\nHere is so abstract overview of the test cases which I have designed. Description is not needed because names are self-explanatory:\n\ntestMultipleNodePorts\ntestMultipleInternal\ntestCombinationOfInternalAndExternalListeners\ntestMultipleLoadBalancers\ntestMultipleRoutes\ntestMixtureOfExternalListeners\ntestCombinationOfEveryKindOfListener\n\nTime Consumption = [TODO] minutes\nChecklist\n\n Write tests\n Make sure all tests pass", "createdAt": "2020-09-15T14:59:32Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651", "merged": true, "mergeCommit": {"oid": "1b90a5c68422c5ba6a381161bad59a30422216d2"}, "closed": true, "closedAt": "2020-10-10T11:08:54Z", "author": {"login": "see-quick"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdJy4QLgFqTQ5MDczMTI5Mw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdQ7k4BAFqTUwNTk0NjQ4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwNzMxMjkz", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-490731293", "createdAt": "2020-09-17T15:39:14Z", "commit": {"oid": "367b5a51f2efa338c51913db8ee031a377f00cf6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOToxNFrOHToqXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOToxNFrOHToqXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTE5OA==", "bodyText": "this will be removed because Route or Ingress type listener requires enabled TLS encryption", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r490351198", "createdAt": "2020-09-17T15:39:14Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.kafkaclients.AbstractKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicClientResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.DynamicTest;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    private ProducerProperties producerProperties;\n+    private ConsumerProperties consumerProperties;\n+\n+    @TestFactory\n+    Iterator<DynamicTest> testMultipleListeners() {\n+\n+        List<DynamicTest> dynamicTests = new ArrayList<>(10);\n+        List<List<GenericKafkaListener>> testCases = generateTestCases();\n+\n+        testCases.forEach(listener -> dynamicTests.add(DynamicTest.dynamicTest(\"Test \" + listener.get(0).getType() + \" with count of \" + listener.size(), () -> {\n+            // TODO: profiling...assume for profiles NODE_PORT, LOAD_BALANCER, ROUTE...\n+\n+            // exercise phase\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewListeners()\n+                .withGenericKafkaListeners(listener)\n+                .endListeners()\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+            KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+\n+            if (listener.get(0).getType() != KafkaListenerType.INTERNAL) {\n+                // using external clients\n+                producerProperties = new ProducerProperties.ProducerPropertiesBuilder()\n+                    .withNamespaceName(NAMESPACE)\n+                    .withClusterName(CLUSTER_NAME)\n+                    .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME))\n+                    .withKeySerializerConfig(StringSerializer.class)\n+                    .withValueSerializerConfig(StringSerializer.class)\n+                    .withClientIdConfig(\"producer-plain-\" + new Random().nextInt(Integer.MAX_VALUE))\n+                    .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                    .withSharedProperties()\n+                    .build();\n+\n+                consumerProperties = new ConsumerProperties.ConsumerPropertiesBuilder()\n+                    .withNamespaceName(NAMESPACE)\n+                    .withClusterName(CLUSTER_NAME)\n+                    .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME))\n+                    .withKeyDeserializerConfig(StringDeserializer.class)\n+                    .withValueDeserializerConfig(StringDeserializer.class)\n+                    .withClientIdConfig(\"consumer-plain-\" + new Random().nextInt(Integer.MAX_VALUE))\n+                    .withGroupIdConfig(\"consumer-group-test\")\n+                    .withAutoOffsetResetConfig(OffsetResetStrategy.EARLIEST)\n+                    .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                    .withSharedProperties()\n+                    .build();\n+\n+                // verify phase\n+\n+                for (int i = 0; i < listener.size() - 1; i++) {\n+\n+                    KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+\n+                    BasicExternalKafkaClient clientForExternal1 = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(TOPIC_NAME)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withProducerProperties(producerProperties)\n+                        .withConsumerProperties(consumerProperties)\n+                        .build();\n+\n+                    // verify phase\n+                    clientForExternal1.verifyProducedAndConsumedMessages(\n+                        clientForExternal1.sendMessagesPlain(),\n+                        clientForExternal1.receiveMessagesPlain()\n+                    );\n+\n+                    BasicExternalKafkaClient clientForExternal2 = clientForExternal1.toBuilder(clientForExternal1)\n+                        .withProducerProperties(\n+                            producerProperties.toBuilder(producerProperties)\n+                                .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME, listener.get(i + 1).getName()))\n+                                .build())\n+                        .withConsumerProperties(\n+                            consumerProperties.toBuilder(consumerProperties)\n+                                .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME, listener.get(i + 1).getName()))\n+                                .build())\n+                        .build();\n+\n+                    // verify phase\n+                    clientForExternal2.verifyProducedAndConsumedMessages(\n+                        clientForExternal2.sendMessagesPlain(),\n+                        clientForExternal2.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                for (int i = 0; i < listener.size() - 1; i++) {\n+\n+                    // exercise phase\n+                    final String producerName =  \"producer-name\";\n+                    final String consumerName  = \"consumer-name\";\n+\n+                    // tls or plain\n+                    KafkaBasicClientResource kafkaBasicClientJob = listener.get(i).isTls() ? new KafkaBasicClientResource(producerName, consumerName,\n+                        KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), TOPIC_NAME, MESSAGE_COUNT, \"\", ClientUtils.generateRandomConsumerGroup(), 1000) :\n+                        new KafkaBasicClientResource(producerName, consumerName,\n+                            KafkaResources.plainBootstrapAddress(CLUSTER_NAME), TOPIC_NAME, MESSAGE_COUNT, \"\", ClientUtils.generateRandomConsumerGroup(), 1000);\n+\n+                    kafkaBasicClientJob.producerStrimzi().done();\n+                    kafkaBasicClientJob.consumerStrimzi().done();\n+\n+                    // verify phase\n+                    ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n+                    ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n+\n+\n+                    LOGGER.info(\"Deleting the Jobs\");\n+                    // teardown (for clients)\n+                    JobUtils.deleteJobWithWait(NAMESPACE, producerName);\n+                    JobUtils.deleteJobWithWait(NAMESPACE, consumerName);\n+                }\n+            }\n+        })));\n+        return dynamicTests.iterator();\n+    }\n+\n+    private List<List<GenericKafkaListener>> generateTestCases() {\n+\n+        List<List<GenericKafkaListener>> testCases = new ArrayList<>(10);\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        for (int i = 0; i < 10; i++) {\n+\n+            KafkaListenerType stochasticChosenListener = KafkaListenerType.values()[ThreadLocalRandom.current().nextInt(0, KafkaListenerType.values().length - 1)];\n+            List<GenericKafkaListener> testCase = new ArrayList<>(5);\n+            int stochasticCount;\n+\n+            switch (stochasticChosenListener) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCase.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(6090 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCase.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(7090 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "367b5a51f2efa338c51913db8ee031a377f00cf6"}, "originalPosition": 213}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6a9454bab7d2ff7d29fb39583db2f4ca5607c79c", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6a9454bab7d2ff7d29fb39583db2f4ca5607c79c", "committedDate": "2020-09-25T11:38:03Z", "message": "fix route\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}, "afterCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0f2dca7fcdf599a854c13e5aa5669afe961f6982", "committedDate": "2020-09-25T11:40:02Z", "message": "fix route\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MzY2NDIy", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-496366422", "createdAt": "2020-09-25T12:17:53Z", "commit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNzo1M1rOHYBN0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNzo1M1rOHYBN0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0Nzc5Mg==", "bodyText": "Removing because these dependencies are un-used in systemtest module", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494947792", "createdAt": "2020-09-25T12:17:53Z", "author": {"login": "see-quick"}, "path": "systemtest/pom.xml", "diffHunk": "@@ -38,14 +38,6 @@\n             <groupId>org.apache.logging.log4j</groupId>\n             <artifactId>log4j-api</artifactId>\n         </dependency>\n-        <dependency>\n-            <groupId>org.apache.logging.log4j</groupId>\n-            <artifactId>log4j-core</artifactId>\n-        </dependency>\n-        <dependency>\n-            <groupId>org.apache.logging.log4j</groupId>\n-            <artifactId>log4j-slf4j-impl</artifactId>\n-        </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MzYxMDcw", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-496361070", "createdAt": "2020-09-25T12:09:56Z", "commit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjowOTo1NlrOHYA-rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNjowOVrOHYBKeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0MzkxNw==", "bodyText": "I'm not sure I think we really need this here.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494943917", "createdAt": "2020-09-25T12:09:56Z", "author": {"login": "scholzj"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaResources.java", "diffHunk": "@@ -138,6 +138,19 @@ public static String tlsBootstrapAddress(String clusterName) {\n         return bootstrapServiceName(clusterName) + \":9093\";\n     }\n \n+    /**\n+     * Returns the address (<em>&lt;host&gt;</em>:<em>&lt;port&gt;</em>)\n+     * of the generic bootstrap {@code Service} for a {@code Kafka} cluster, and {@code port} of the given.\n+     * @param clusterName  The {@code metadata.name} of the {@code Kafka} resource.\n+     * @param port The {@code spec.kafka.listeners.port} of the {@code Kafka} resource.\n+     * @return The address of the corresponding bootstrap {@code Service}.\n+     * @see #plainBootstrapAddress(String)\n+     * @see #tlsBootstrapAddress(String)\n+     */\n+    public static String bootstrapAddressOnSpecificPort(String clusterName, int port) {\n+        return bootstrapServiceName(clusterName) + \":\" + port;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NTY5MA==", "bodyText": "When you deploy Kafka, the bootstrap addresses for all listeners get filled in the status section. Is there any actual reason why you need to reverse engineer the address here instead of reading it simply from the status? All you would need is a listener name, you would not need to both with OpenShfit, service types etc.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494945690", "createdAt": "2020-09-25T12:13:40Z", "author": {"login": "scholzj"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "diffHunk": "@@ -142,48 +170,67 @@ public void verifyProducedAndConsumedMessages(int producedMessages, int consumed\n      * Get external bootstrap connection\n      * @param namespace kafka namespace\n      * @param clusterName kafka cluster name\n+     * @param listenerName name of the listener\n      * @return bootstrap url as string\n      */\n-    public static String getExternalBootstrapConnect(String namespace, String clusterName) {\n+    @SuppressWarnings(\"Regexp\") // because of extBootstrapService.getSpec().getType().toLowerCase()\n+    @SuppressFBWarnings(\"DM_CONVERT_CASE\")\n+    public static String getExternalBootstrapConnect(String namespace, String clusterName, String listenerName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NjkzNg==", "bodyText": "Aren't we removing this in the other PRs? Please check with @stanlyDoge and @mstruk. It is IIRC also not what the docs suggest ... we should primarily follow our docs to make sure the docs are valid and test them this way as well.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494946936", "createdAt": "2020-09-25T12:16:09Z", "author": {"login": "scholzj"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java", "diffHunk": "@@ -169,7 +169,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl\n                         .endGenericKafkaListener()\n                     .endListeners()\n                     .withNewInlineLogging()\n-                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG\")\n+                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG, CONSOLE\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MzcyMDkw", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-496372090", "createdAt": "2020-09-25T12:26:33Z", "commit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoyNjozM1rOHYBfAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjozNTo0NVrOHYByGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1MjE5NA==", "bodyText": "I guess we discussed this when I was working on the example clients builder but -> isn't there some way how to just set the \"properties\" that are specific for Oauth external clients here and the others set in the Abstract? I know that there can be some dependency (etc.) issues, but still asking...", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494952194", "createdAt": "2020-09-25T12:26:33Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java", "diffHunk": "@@ -81,6 +82,29 @@ protected Builder self() {\n         }\n     }\n \n+    @Override\n+    public AbstractKafkaClient.Builder<OauthExternalKafkaClient.Builder> toBuilder(OauthExternalKafkaClient oauthExternalKafkaClient) {\n+        OauthExternalKafkaClient.Builder builder = new OauthExternalKafkaClient.Builder();\n+\n+        builder.withTopicName(oauthExternalKafkaClient.getTopicName());\n+        builder.withPartition(oauthExternalKafkaClient.getPartition());\n+        builder.withMessageCount(oauthExternalKafkaClient.getMessageCount());\n+        builder.withNamespaceName(oauthExternalKafkaClient.getNamespaceName());\n+        builder.withClusterName(oauthExternalKafkaClient.getClusterName());\n+        builder.withConsumerGroupName(oauthExternalKafkaClient.getConsumerGroup());\n+        builder.withKafkaUsername(oauthExternalKafkaClient.getKafkaUsername());\n+        builder.withSecurityProtocol(oauthExternalKafkaClient.getSecurityProtocol());\n+        builder.withCertificateAuthorityCertificateName(oauthExternalKafkaClient.getCaCertName());\n+        builder.withProducerProperties(oauthExternalKafkaClient.getProducerProperties());\n+        builder.withConsumerProperties(oauthExternalKafkaClient.getConsumerProperties());\n+        builder.withOauthClientId(oauthExternalKafkaClient.getClientId());\n+        builder.withClientSecretName(oauthExternalKafkaClient.getClientSecretName());\n+        builder.withOauthTokenEndpointUri(oauthExternalKafkaClient.getOauthTokenEndpointUri());\n+        builder.withIntrospectionEndpointUri(oauthExternalKafkaClient.getIntrospectionEndpointUri());\n+\n+        return builder;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDkxMg==", "bodyText": "Maybe different name?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494954912", "createdAt": "2020-09-25T12:31:39Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NzA4MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        List<GenericKafkaListener> testCase = new ArrayList<>(5);\n          \n          \n            \n                        List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n          \n      \n    \n    \n  \n\n?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494957081", "createdAt": "2020-09-25T12:35:45Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .build();\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                            .withUsingPodName(kafkaClientsTlsPodName)\n+                            .withBootstrapServer(KafkaResources.bootstrapAddressOnSpecificPort(CLUSTER_NAME, listener.getPort()))\n+                            .withTopicName(topicName)\n+                            .withNamespaceName(NAMESPACE)\n+                            .withClusterName(CLUSTER_NAME)\n+                            .withKafkaUsername(kafkaUsername)\n+                            .withMessageCount(MESSAGE_COUNT)\n+                            .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withBootstrapServer(KafkaResources.bootstrapAddressOnSpecificPort(CLUSTER_NAME, listener.getPort()))\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCase = new ArrayList<>(5);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 257}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwNjYxMjU1", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-500661255", "createdAt": "2020-10-01T19:38:59Z", "commit": {"oid": "f44fd3475716f563d46477c4a02e7e3f75647b91"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwNjYyODkz", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-500662893", "createdAt": "2020-10-01T19:41:32Z", "commit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwNjg3NjMx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-500687631", "createdAt": "2020-10-01T20:18:51Z", "commit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxODo1MVrOHbZfqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoyNDozOFrOHbZqDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5MTMwNw==", "bodyText": "Why is this needed? You should use it like this  .toLowerCase(Locale.ENGLISH) I think you can remove DM_CONVERT_CASE as well after the change.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498491307", "createdAt": "2020-10-01T20:18:51Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ConsumerProperties extends AbstractKafkaClientProperties<ConsumerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ConsumerProperties.class);\n+\n+    public static class ConsumerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ConsumerPropertiesBuilder> {\n+\n+        public ConsumerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withKeyDeserializerConfig(Class<? extends Deserializer> keyDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keyDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withValueDeserializerConfig(Class<? extends Deserializer> valueDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withGroupIdConfig(String groupIdConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupIdConfig);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        @SuppressWarnings(\"Regexp\") // for the `.toLowerCase()` because kafka needs this property as lower-case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5MTUyNA==", "bodyText": "Same here", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498491524", "createdAt": "2020-10-01T20:19:18Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ConsumerProperties extends AbstractKafkaClientProperties<ConsumerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ConsumerProperties.class);\n+\n+    public static class ConsumerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ConsumerPropertiesBuilder> {\n+\n+        public ConsumerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withKeyDeserializerConfig(Class<? extends Deserializer> keyDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keyDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withValueDeserializerConfig(Class<? extends Deserializer> valueDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withGroupIdConfig(String groupIdConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupIdConfig);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        @SuppressWarnings(\"Regexp\") // for the `.toLowerCase()` because kafka needs this property as lower-case\n+        @SuppressFBWarnings(\"DM_CONVERT_CASE\")\n+        public ConsumerPropertiesBuilder withAutoOffsetResetConfig(OffsetResetStrategy offsetResetConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, offsetResetConfig.name().toLowerCase());\n+            return this;\n+        }\n+\n+        @Override\n+        public ConsumerProperties build() {\n+            return new ConsumerProperties(this);\n+        }\n+\n+        @Override\n+        protected ConsumerPropertiesBuilder self() {\n+            return this;\n+        }\n+    }\n+\n+    private ConsumerProperties(ConsumerPropertiesBuilder builder) {\n+        super(builder);\n+        properties = builder.properties;\n+    }\n+\n+    @Override\n+    @SuppressWarnings({\"Regexp\", \"unchecked\"}) // for the `.toUpperCase()` because OffsetStrategy needs to be upper-case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mzk2NQ==", "bodyText": "debug?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498493965", "createdAt": "2020-10-01T20:24:38Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ProducerProperties.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Serializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ProducerProperties extends AbstractKafkaClientProperties<ProducerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ProducerProperties.class);\n+    private static final String DEFAULT_MAX_BLOG_MS_CONFIG = \"6000\"; // 60 * 100\n+    private static final String DEFAULT_ACKS_CONFIG = \"1\";\n+\n+    public static class ProducerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ProducerPropertiesBuilder> {\n+\n+        public ProducerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withKeySerializerConfig(Class<? extends Serializer> keySerializer) {\n+\n+            this.properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, keySerializer.getName());\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withValueSerializerConfig(Class<? extends Serializer> valueSerializer) {\n+\n+            this.properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, valueSerializer.getName());\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withMaxBlockMsConfig(String maxBlockMsConfig) {\n+\n+            this.properties.setProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG, maxBlockMsConfig);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ProducerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withAcksConfig(String acksConfig) {\n+\n+            this.properties.setProperty(ProducerConfig.ACKS_CONFIG, acksConfig);\n+            return this;\n+        }\n+\n+        @Override\n+        public ProducerProperties build() {\n+            return new ProducerProperties(this);\n+        }\n+\n+        @Override\n+        protected ProducerPropertiesBuilder self() {\n+            return this;\n+        }\n+    }\n+\n+    private ProducerProperties(ProducerPropertiesBuilder builder) {\n+        super(builder);\n+\n+        if (builder.properties.getProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG) == null || builder.properties.getProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG).isEmpty()) {\n+            LOGGER.info(\"Setting default value of {} to {}\", ProducerConfig.MAX_BLOCK_MS_CONFIG, DEFAULT_MAX_BLOG_MS_CONFIG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMDM2ODIx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-501036821", "createdAt": "2020-10-02T10:51:24Z", "commit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6fd7786b1f38286302a5d92967f0565ed7a54bd5", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6fd7786b1f38286302a5d92967f0565ed7a54bd5", "committedDate": "2020-10-07T19:08:15Z", "message": "re-write all using clients to immutable objects\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}, "afterCommit": {"oid": "4bc2612e559709cd71c4c4c7e8db746c11062354", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4bc2612e559709cd71c4c4c7e8db746c11062354", "committedDate": "2020-10-07T19:38:54Z", "message": "re-write all using clients to immutable objects\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0MzE4MDM2", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-504318036", "createdAt": "2020-10-07T22:42:59Z", "commit": {"oid": "4bc2612e559709cd71c4c4c7e8db746c11062354"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0NTI4MTk4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-504528198", "createdAt": "2020-10-08T08:10:18Z", "commit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxMDoxOFrOHeS0pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyNzozN1rOHeTdsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUyNzcxNg==", "bodyText": "I'm guessing this is because the fluent pattern on the builder with each method having to cast (SELF) this results in lots of warnings. It is best to use @SuppressWarnings on the smallest scope possible, so that genuine warnings are not suppressed accidentally. But you understandably don't want to have to annotate each method, so the solution is to write a method self() does the cast and is annotated, then all the rest get to return self(); and not needing annotating. Basically the rule of thumb is always to refactor you untypesafe code into a method and annotate just that method.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501527716", "createdAt": "2020-10-08T08:10:18Z", "author": {"login": "tombentley"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "diffHunk": "@@ -4,21 +4,20 @@\n  */\n package io.strimzi.systemtest.kafkaclients;\n \n-import io.fabric8.kubernetes.api.model.LoadBalancerIngress;\n-import io.fabric8.kubernetes.api.model.Service;\n-import io.fabric8.openshift.api.model.Route;\n-import io.fabric8.openshift.client.OpenShiftClient;\n+import io.strimzi.api.kafka.model.status.ListenerStatus;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.security.InvalidParameterException;\n+import java.util.List;\n \n-import static io.strimzi.api.kafka.model.KafkaResources.externalBootstrapServiceName;\n-import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n-\n-public abstract class AbstractKafkaClient {\n+@SuppressWarnings(\"unchecked\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMTAzMg==", "bodyText": "Probably best to have a consistent order for the annotations, and not split annotations of the same type.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501531032", "createdAt": "2020-10-08T08:15:49Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMjAzMQ==", "bodyText": "The two branches of this if look very similar.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501532031", "createdAt": "2020-10-08T08:17:31Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE0MQ==", "bodyText": "Why not a random number of routes?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533141", "createdAt": "2020-10-08T08:19:34Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE2Ng==", "bodyText": "Deserves some javadoc to explain what this is doing.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533166", "createdAt": "2020-10-08T08:19:36Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 256}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzU0OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    LOGGER.info(\"Finished will generation of test cases for multiple listeners\");\n          \n          \n            \n                    LOGGER.info(\"Finished with generation of test cases for multiple listeners\");\n          \n      \n    \n    \n  \n\nand maybe log the listeners generated, if it's not logged elsewhere?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533548", "createdAt": "2020-10-08T08:20:09Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                        .withName(generateRandomListenerName())\n+                        .withPort(12091)\n+                        .withType(KafkaListenerType.ROUTE)\n+                        // Route or Ingress type listener and requires enabled TLS encryption\n+                        .withTls(true)\n+                        .build());\n+                    break;\n+                case INTERNAL:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 4);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(13900 + j)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+            }\n+            testCases.put(kafkaListenerType, testCaseListeners);\n+        }\n+\n+        LOGGER.info(\"Finished will generation of test cases for multiple listeners\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 326}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzg5OA==", "bodyText": "You could perhaps reuse the PasswordGenerator we have somewhere?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533898", "createdAt": "2020-10-08T08:20:42Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                        .withName(generateRandomListenerName())\n+                        .withPort(12091)\n+                        .withType(KafkaListenerType.ROUTE)\n+                        // Route or Ingress type listener and requires enabled TLS encryption\n+                        .withTls(true)\n+                        .build());\n+                    break;\n+                case INTERNAL:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 4);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(13900 + j)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+            }\n+            testCases.put(kafkaListenerType, testCaseListeners);\n+        }\n+\n+        LOGGER.info(\"Finished will generation of test cases for multiple listeners\");\n+\n+        return testCases;\n+    }\n+\n+    private String generateRandomListenerName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzODIyNg==", "bodyText": "The problem with random tests is that they're not reproducible, so if you get a failure and think you've fixed it how do you re-run the same test again? The solution is in the fact that java.util.Random is a pseudo-random number generator and the contract says if you give it the same seed it will generate the same sequence. But got can't get the seed. So in normal running you can generate a seed using one Random (or use System.nanoTime() or whatever) and use it as the seed for another Random instance and log the seed. Then you can reproduce any failed test for which you have the logs by having some System property or env var which allows you to set the seed, rather than using a Random/System.nanoTime() whatever.\nIf we're going to use more random testing in the future this is a pattern we should encapsulate, but in another PR.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501538226", "createdAt": "2020-10-08T08:27:37Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 270}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0ODEzNzY0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-504813764", "createdAt": "2020-10-08T13:59:38Z", "commit": {"oid": "74826658b71b02d8cb143d2728d5cd79e76f1d06"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzo1OTozOFrOHegBhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzo1OTozOFrOHegBhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTc0NDAwNg==", "bodyText": "Wouldn't be better name them like legacy ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501744006", "createdAt": "2020-10-08T13:59:38Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "diffHunk": "@@ -264,4 +264,11 @@\n     String CRUISE_CONTROL_CONFIGURATION_ENV = \"CRUISE_CONTROL_CONFIGURATION\";\n     String CRUISE_CONTROL_CAPACITY_FILE_PATH = \"/tmp/capacity.json\";\n     String CRUISE_CONTROL_CONFIGURATION_FILE_PATH = \"/tmp/cruisecontrol.properties\";\n+\n+    /**\n+     * Default listeners names", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74826658b71b02d8cb143d2728d5cd79e76f1d06"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55a8a110d0765fb15c7cb3d690a5aa8528c39957", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/55a8a110d0765fb15c7cb3d690a5aa8528c39957", "committedDate": "2020-10-09T09:54:29Z", "message": "[MO] - [system test] -> test suite of multiple listeners\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "199df7e5e302f1e5970a3d8fb7977d9b026ffe2f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/199df7e5e302f1e5970a3d8fb7977d9b026ffe2f", "committedDate": "2020-10-09T09:54:29Z", "message": "[MO] - [listeners] -> dynamic tests\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99fd6669e394f7c80f5c93bc95816cdbef77dd3a", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/99fd6669e394f7c80f5c93bc95816cdbef77dd3a", "committedDate": "2020-10-09T09:54:29Z", "message": "filtering\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b094cce0c637cfcac7f93ef423d71fad19bd962c", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b094cce0c637cfcac7f93ef423d71fad19bd962c", "committedDate": "2020-10-09T09:54:29Z", "message": "except routes done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59e031f307fc4ff372d453f3c6bdb4322edd1c3f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/59e031f307fc4ff372d453f3c6bdb4322edd1c3f", "committedDate": "2020-10-09T09:54:29Z", "message": "fix route\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3691c62e4cbebd33a04d419a89562e947efe4971", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3691c62e4cbebd33a04d419a89562e947efe4971", "committedDate": "2020-10-09T09:54:29Z", "message": "fix dependencies\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd256a06d771f7134642798a9029c58a75be88cc", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/dd256a06d771f7134642798a9029c58a75be88cc", "committedDate": "2020-10-09T09:54:29Z", "message": "[MO] - change builder way\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf4b827475b84436da64604aec45465117e8af14", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/cf4b827475b84436da64604aec45465117e8af14", "committedDate": "2020-10-09T09:54:29Z", "message": "checkstyle\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca6ef6f05f332185565af5d1936cb7d25f81446b", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ca6ef6f05f332185565af5d1936cb7d25f81446b", "committedDate": "2020-10-09T09:54:29Z", "message": "re-desing\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "050d849cbaa63afa9fa0bdec864e949bb3f9209f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/050d849cbaa63afa9fa0bdec864e949bb3f9209f", "committedDate": "2020-10-09T09:54:29Z", "message": "done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b26226594de8549f27e4564a2f82e5a67b25028", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9b26226594de8549f27e4564a2f82e5a67b25028", "committedDate": "2020-10-09T09:54:29Z", "message": "s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4351cbbe552959c81596f064cd514f1a6337c38", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a4351cbbe552959c81596f064cd514f1a6337c38", "committedDate": "2020-10-09T09:54:29Z", "message": "werror\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9cbeaf50f68e596e4a4e09fcd60187d57564ec5", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d9cbeaf50f68e596e4a4e09fcd60187d57564ec5", "committedDate": "2020-10-09T09:54:29Z", "message": "regression\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b37febbdad4d828523fb6c1b3336b427ff7a34d8", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b37febbdad4d828523fb6c1b3336b427ff7a34d8", "committedDate": "2020-10-09T09:54:29Z", "message": "done toBuilder()\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21cdf6efdb8e327f7090ae27a75b8ad5897f9cc9", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/21cdf6efdb8e327f7090ae27a75b8ad5897f9cc9", "committedDate": "2020-10-09T09:54:29Z", "message": "removing listeners method\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13b9b369f6a72fa6354ddcf9097c8e4af76b4f63", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/13b9b369f6a72fa6354ddcf9097c8e4af76b4f63", "committedDate": "2020-10-09T09:54:29Z", "message": "checkstyke\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db58e4682ae44d515c261b70fbe83646cf46fda0", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/db58e4682ae44d515c261b70fbe83646cf46fda0", "committedDate": "2020-10-09T09:54:29Z", "message": "spotbugs\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "365a0b0f9d7fb620db613b3c59d15efe202a8ed9", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/365a0b0f9d7fb620db613b3c59d15efe202a8ed9", "committedDate": "2020-10-09T09:54:29Z", "message": "ich wei\u00df nich\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df1a0dd31d2fd757d21609c47920ea9f1dcb3072", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/df1a0dd31d2fd757d21609c47920ea9f1dcb3072", "committedDate": "2020-10-09T09:54:29Z", "message": "removing method\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "756d9dc4a9bb024c1a36408dc37a7efbcc5228f1", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/756d9dc4a9bb024c1a36408dc37a7efbcc5228f1", "committedDate": "2020-10-09T09:54:29Z", "message": "default name listeneer\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85fd6176ef216003d660fd6215a8fbabb332067f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/85fd6176ef216003d660fd6215a8fbabb332067f", "committedDate": "2020-10-09T09:54:29Z", "message": "list\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9504e5075d5f65fc855a36bcaa510ffb3a793199", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9504e5075d5f65fc855a36bcaa510ffb3a793199", "committedDate": "2020-10-09T09:54:29Z", "message": "re-change size of namespace\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41ecc57059d28065b5a1518c448fa358c8748e3c", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/41ecc57059d28065b5a1518c448fa358c8748e3c", "committedDate": "2020-10-09T09:54:29Z", "message": "change-port-values\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fdbfd810e42655b05d6263a19f1ed64d97b64fd", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6fdbfd810e42655b05d6263a19f1ed64d97b64fd", "committedDate": "2020-10-09T09:54:29Z", "message": "last-change\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "382df0f5679226c5fafc19697f5e42238af18e91", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/382df0f5679226c5fafc19697f5e42238af18e91", "committedDate": "2020-10-09T09:54:30Z", "message": "re-write all using clients to immutable objects\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79ea4122b4077110c30e1970d342737249b5f87c", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/79ea4122b4077110c30e1970d342737249b5f87c", "committedDate": "2020-10-09T09:54:30Z", "message": "fix all failures hope so!\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "822760d89c32f16b04e0680fe6089cbd42784960", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/822760d89c32f16b04e0680fe6089cbd42784960", "committedDate": "2020-10-09T09:54:30Z", "message": "fixing listeners name\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d878f285d13e47796063018172fea53a60c7b1c7", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d878f285d13e47796063018172fea53a60c7b1c7", "committedDate": "2020-10-09T09:54:30Z", "message": "tracing fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59e3fa0e6d02ee3b88734843ae031fdb514b64e2", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/59e3fa0e6d02ee3b88734843ae031fdb514b64e2", "committedDate": "2020-10-09T09:54:30Z", "message": "3/5 fixes\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0111b2c2645d3dfcc40b5bda47ffbd31e1442680", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0111b2c2645d3dfcc40b5bda47ffbd31e1442680", "committedDate": "2020-10-09T09:54:30Z", "message": "lets go\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad71eed99acc4604974c486a4d5466fc3c2a5717", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ad71eed99acc4604974c486a4d5466fc3c2a5717", "committedDate": "2020-10-09T09:54:30Z", "message": "last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d575c2f1e712b42b0121965c9981bc9740daf8a4", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d575c2f1e712b42b0121965c9981bc9740daf8a4", "committedDate": "2020-10-09T07:55:55Z", "message": "last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}, "afterCommit": {"oid": "ad71eed99acc4604974c486a4d5466fc3c2a5717", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ad71eed99acc4604974c486a4d5466fc3c2a5717", "committedDate": "2020-10-09T09:54:30Z", "message": "last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3a1ed9019f5668ae41369e8dd43e3311ec7a734", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d3a1ed9019f5668ae41369e8dd43e3311ec7a734", "committedDate": "2020-10-09T19:41:46Z", "message": "last test\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fb867d6d8ae7d4b6163d2849b0185dc74731f14", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4fb867d6d8ae7d4b6163d2849b0185dc74731f14", "committedDate": "2020-10-09T19:43:54Z", "message": "remove\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA1OTQ2NDg4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#pullrequestreview-505946488", "createdAt": "2020-10-09T19:44:42Z", "commit": {"oid": "4fb867d6d8ae7d4b6163d2849b0185dc74731f14"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 970, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}