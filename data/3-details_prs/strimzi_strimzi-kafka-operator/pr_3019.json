{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3OTI5NDA1", "number": 3019, "title": "fix: Allow the same secret to hold client auth details and TLS certs", "bodyText": "Type of change\nSelect the type of your PR\n\nBugfix\n\nDescription\n\nThis PR fixes the creation of volumes in the MirrorMaker2,\nMirrorMaker, Connect and Bridge deployments so that the same Kubernetes\nsecret can be used to hold both the TLS certs and authentication\npasswords/certs/keys/tokens. Currently this will fail due to multiple\nvolumes with the same name being created, causing Kubernetes to reject\nthe deployment.\nUsing the same secret to hold multiple TLS/auth values can be\nuseful for those who want keep all their security credentials in one\nplace.\n\nChecklist\nPlease go through this checklist and make sure all applicable tasks have been done\n\n[ X ] Write tests\n[ X ] Make sure all tests pass\n[ X ] Try your changes from Pod inside your Kubernetes and OpenShift cluster, not just locally", "createdAt": "2020-05-14T11:21:45Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019", "merged": true, "mergeCommit": {"oid": "f7d251711c64d2b24424c3f09e5704b768c2ccd9"}, "closed": true, "closedAt": "2020-05-14T23:09:56Z", "author": {"login": "ajborley"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABchLlSaAH2gAyNDE3OTI5NDA1OmJhNGM5NWRkODlmOWY1YTM0MjdiYzU2NzI1ZWQ4MjUyNTQ5MzYzYzU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABchSHylgFqTQxMjA5MzkxOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5", "author": {"user": {"login": "ajborley", "name": "Andrew Borley"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ba4c95dd89f9f5a3427bc56725ed8252549363c5", "committedDate": "2020-05-14T11:15:16Z", "message": "fix: Allow the same secret to hold client auth details and TLS certs\n\n - This commit fixes the creation of volumes in the MirrorMaker2,\nMirrorMaker, Connect and Bridge deployments so that the same Kubernetes\nsecret can be used to hold both the TLS certs and authentication\npasswords/certs/keys/tokens. Currently this will fail due to multiple\nvolumes with the same name being created, causing Kubernetes to reject\nthe deployment.\n - Using the same secret to hold multiple TLS/auth values can be\nuseful for those who want keep all their security credentials in one\nplace.\n\nSigned-off-by: Andrew Borley <borley@uk.ibm.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExNzI1NDkx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#pullrequestreview-411725491", "createdAt": "2020-05-14T11:50:14Z", "commit": {"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1MDoxNFrOGVYn5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNFQxMTo1MzoxMFrOGVYtzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3NjcwOA==", "bodyText": "This is a useful function, thanks for the addition.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425076708", "createdAt": "2020-05-14T11:50:14Z", "author": {"login": "samuel-hawker"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java", "diffHunk": "@@ -111,37 +111,44 @@ public static void configureClientAuthenticationVolumes(KafkaClientAuthenticatio\n         if (authentication != null) {\n             if (authentication instanceof KafkaClientAuthenticationTls) {\n                 KafkaClientAuthenticationTls tlsAuth = (KafkaClientAuthenticationTls) authentication;\n-\n-                // skipping if a volume with same Secret name was already added\n-                if (!volumeList.stream().anyMatch(v -> v.getName().equals(volumeNamePrefix + tlsAuth.getCertificateAndKey().getSecretName()))) {\n-                    volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + tlsAuth.getCertificateAndKey().getSecretName(), tlsAuth.getCertificateAndKey().getSecretName(), isOpenShift));\n-                }\n+                addNewVolume(volumeList, volumeNamePrefix, tlsAuth.getCertificateAndKey().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationPlain) {\n                 KafkaClientAuthenticationPlain passwordAuth = (KafkaClientAuthenticationPlain) authentication;\n-                volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + passwordAuth.getPasswordSecret().getSecretName(), passwordAuth.getPasswordSecret().getSecretName(), isOpenShift));\n+                addNewVolume(volumeList, volumeNamePrefix, passwordAuth.getPasswordSecret().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationScramSha512) {\n                 KafkaClientAuthenticationScramSha512 passwordAuth = (KafkaClientAuthenticationScramSha512) authentication;\n-                volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + passwordAuth.getPasswordSecret().getSecretName(), passwordAuth.getPasswordSecret().getSecretName(), isOpenShift));\n+                addNewVolume(volumeList, volumeNamePrefix, passwordAuth.getPasswordSecret().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationOAuth) {\n                 KafkaClientAuthenticationOAuth oauth = (KafkaClientAuthenticationOAuth) authentication;\n                 volumeList.addAll(configureOauthCertificateVolumes(oauthVolumeNamePrefix, oauth.getTlsTrustedCertificates(), isOpenShift));\n \n                 if (createOAuthSecretVolumes) {\n                     if (oauth.getClientSecret() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getClientSecret().getSecretName(), oauth.getClientSecret().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getClientSecret().getSecretName(), isOpenShift);\n                     }\n                     if (oauth.getAccessToken() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getAccessToken().getSecretName(), oauth.getAccessToken().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getAccessToken().getSecretName(), isOpenShift);\n                     }\n                     if (oauth.getRefreshToken() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getRefreshToken().getSecretName(), oauth.getRefreshToken().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getRefreshToken().getSecretName(), isOpenShift);\n                     }\n                 }\n             }\n         }\n     }\n \n-        /**\n+    /**\n+     * Creates the Volumes used for authentication of Kafka client based components, checking that the named volume has not already been\n+     * created.\n+     */\n+    private static void addNewVolume(List<Volume> volumeList, String volumeNamePrefix, String secretName, boolean isOpenShift) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3NzM5MQ==", "bodyText": "assertThat(AbstractModel.containerEnvVars(containers.get(0)), hasEntry(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_PASSWORD_FILE, \"my-secret/user1.password\"));\n\nIs minutely more informative if the key is missing, but this is unlikely for this test.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425077391", "createdAt": "2020-05-14T11:51:30Z", "author": {"login": "samuel-hawker"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "diffHunk": "@@ -387,6 +387,45 @@ public void testGenerateDeploymentWithScramSha512Auth() {\n         assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_MECHANISM), is(\"scram-sha-512\"));\n     }\n \n+    @Test\n+    public void testGenerateDeploymentWithScramSha512AuthAndTLSSameSecret() {\n+        KafkaConnect resource = new KafkaConnectBuilder(this.resource)\n+            .editSpec()\n+                .editOrNewTls()\n+                    .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName(\"my-secret\").withCertificate(\"cert.crt\").build())\n+                .endTls()\n+                .withNewKafkaClientAuthenticationScramSha512()\n+                    .withUsername(\"user1\")\n+                    .withNewPasswordSecret()\n+                        .withSecretName(\"my-secret\")\n+                        .withPassword(\"user1.password\")\n+                    .endPasswordSecret()\n+                .endKafkaClientAuthenticationScramSha512()\n+            .endSpec()\n+            .build();\n+        KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);\n+        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);\n+\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().size(), is(2));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(0).getName(), is(\"kafka-metrics-and-logging\"));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(1).getName(), is(\"my-secret\"));\n+\n+        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();\n+\n+        assertThat(containers.get(0).getVolumeMounts().size(), is(3));\n+        assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(\"kafka-metrics-and-logging\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(0).getMountPath(), is(\"/opt/kafka/custom-config/\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(1).getName(), is(\"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(1).getMountPath(), is(KafkaConnectCluster.TLS_CERTS_BASE_VOLUME_MOUNT + \"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(2).getName(), is(\"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaConnectCluster.PASSWORD_VOLUME_MOUNT + \"my-secret\"));\n+\n+        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_PASSWORD_FILE), is(\"my-secret/user1.password\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODIyMA==", "bodyText": "I do wonder if a small JavaDoc comment expanding on why the test of the same secret is important and how without the deduplication of the volumes it would result in a Kube error", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425078220", "createdAt": "2020-05-14T11:53:10Z", "author": {"login": "samuel-hawker"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java", "diffHunk": "@@ -413,6 +413,53 @@ public void testGenerateDeploymentWithScramSha512Auth() {\n         assertThat(AbstractModel.containerEnvVars(cont).get(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_SASL_MECHANISM), is(\"scram-sha-512\"));\n     }\n \n+    @Test\n+    public void testGenerateDeploymentWithScramSha512AuthAndTLSSameSecret() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfe1ce9620c517b33675272c0e9fe462f3d6cbac", "author": {"user": {"login": "ajborley", "name": "Andrew Borley"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/cfe1ce9620c517b33675272c0e9fe462f3d6cbac", "committedDate": "2020-05-14T15:27:59Z", "message": "fix: Address review comments\n\n - This commit adds some javadoc about the new tests and switches the\nenv var checks to use `hasEntry` to guard against missing keys.\n\nSigned-off-by: Andrew Borley <borley@uk.ibm.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyMDAyODU3", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#pullrequestreview-412002857", "createdAt": "2020-05-14T16:57:19Z", "commit": {"oid": "cfe1ce9620c517b33675272c0e9fe462f3d6cbac"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyMDkzOTE4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#pullrequestreview-412093918", "createdAt": "2020-05-14T18:52:24Z", "commit": {"oid": "cfe1ce9620c517b33675272c0e9fe462f3d6cbac"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1712, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}