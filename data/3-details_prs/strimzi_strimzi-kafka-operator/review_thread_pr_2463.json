{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY3NjkyMDMy", "number": 2463, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMTo1N1rODbJh-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMjo1MlrODbJjIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5Nzk0Mjk5OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMTo1N1rOFid5SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMTo1N1rOFid5SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTY4NTcwNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                            \"KafkaConnectS2I seems to exists longer and will be used while this custom resource will be ignored.\");\n          \n          \n            \n                                            \"KafkaConnectS2I is older and will be used while this custom resource will be ignored.\");", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2463#discussion_r371685704", "createdAt": "2020-01-28T09:21:57Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java", "diffHunk": "@@ -100,7 +107,26 @@ public KafkaConnectAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pf\n         annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));\n \n         log.debug(\"{}: Updating Kafka Connect cluster\", reconciliation, name, namespace);\n-        connectServiceAccount(namespace, connect)\n+\n+        Future<KafkaConnectS2I> connectS2ICheck;\n+        if (connectS2IOperations != null)   {\n+            connectS2ICheck = connectS2IOperations.getAsync(kafkaConnect.getMetadata().getNamespace(), kafkaConnect.getMetadata().getName());\n+        } else {\n+            connectS2ICheck = Future.succeededFuture(null);\n+        }\n+\n+        connectS2ICheck\n+                .compose(otherConnect -> {\n+                    if (otherConnect != null\n+                            // There is a KafkaConnectS2I with the same name which is older than this KafkaConnect\n+                            && kafkaConnect.getMetadata().getCreationTimestamp().compareTo(otherConnect.getMetadata().getCreationTimestamp()) > 0)    {\n+                        return Future.failedFuture(\"Both KafkaConnect and KafkaConnectS2I exist with the same name. \" +\n+                                \"KafkaConnectS2I seems to exists longer and will be used while this custom resource will be ignored.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eece63785e65bd29eec403c3d76080130e5e0687"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5Nzk0NTkzOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMjo1MlrOFid7FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQwOToyMjo1MlrOFid7FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTY4NjE2NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                            \"KafkaConnect seems to exists longer and will be used while this custom resource will be ignored.\");\n          \n          \n            \n                                            \"KafkaConnect is older and will be used while this custom resource will be ignored.\");", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2463#discussion_r371686164", "createdAt": "2020-01-28T09:22:52Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java", "diffHunk": "@@ -91,75 +92,84 @@ public KafkaConnectS2IAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability\n \n     @Override\n     public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2I kafkaConnectS2I) {\n+        Promise<Void> createOrUpdatePromise = Promise.promise();\n+        String name = reconciliation.name();\n         String namespace = reconciliation.namespace();\n-        if (kafkaConnectS2I.getSpec() == null) {\n-            log.error(\"{} spec cannot be null\", kafkaConnectS2I.getMetadata().getName());\n-            return Future.failedFuture(\"Spec cannot be null\");\n-        }\n-        if (pfa.hasImages() && pfa.hasApps() && pfa.hasBuilds()) {\n-            Promise<Void> createOrUpdatePromise = Promise.promise();\n-            KafkaConnectS2ICluster connect;\n-            KafkaConnectS2Istatus kafkaConnectS2Istatus = new KafkaConnectS2Istatus();\n-            try {\n-                connect = KafkaConnectS2ICluster.fromCrd(kafkaConnectS2I, versions);\n-            } catch (Exception e) {\n-                StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnectS2I, kafkaConnectS2Istatus, Future.failedFuture(e));\n-                return updateStatus(kafkaConnectS2I, reconciliation, kafkaConnectS2Istatus);\n+        KafkaConnectS2ICluster connect;\n+        KafkaConnectS2IStatus kafkaConnectS2Istatus = new KafkaConnectS2IStatus();\n+\n+        try {\n+            if (kafkaConnectS2I.getSpec() == null) {\n+                log.error(\"{}: Resource lacks spec property\", reconciliation, kafkaConnectS2I.getMetadata().getName());\n+                throw new InvalidResourceException(\"spec property is required\");\n             }\n-            connect.generateBuildConfig();\n-            ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(connect.getLogging() instanceof ExternalLogging ?\n-                    configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :\n-                    null);\n-\n-            HashMap<String, String> annotations = new HashMap<>();\n-            annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));\n-            connectServiceAccount(namespace, connect)\n-                    .compose(i -> deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas()))\n-                    .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))\n-                    .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))\n-                    .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))\n-                    .compose(i -> imagesStreamOperations.reconcile(namespace, KafkaConnectS2IResources.sourceImageStreamName(connect.getCluster()), connect.generateSourceImageStream()))\n-                    .compose(i -> imagesStreamOperations.reconcile(namespace, KafkaConnectS2IResources.targetImageStreamName(connect.getCluster()), connect.generateTargetImageStream()))\n-                    .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, connect.getName(), connect.generatePodDisruptionBudget()))\n-                    .compose(i -> buildConfigOperations.reconcile(namespace, KafkaConnectS2IResources.buildConfigName(connect.getCluster()), connect.generateBuildConfig()))\n-                    .compose(i -> deploymentConfigOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))\n-                    .compose(i -> deploymentConfigOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))\n-                    .compose(i -> deploymentConfigOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))\n-                    .compose(i -> reconcileConnectors(reconciliation, kafkaConnectS2I, kafkaConnectS2Istatus))\n-                    .setHandler(reconciliationResult -> {\n-                        StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnectS2I, kafkaConnectS2Istatus, reconciliationResult);\n-                        kafkaConnectS2Istatus.setUrl(KafkaConnectS2IResources.url(connect.getCluster(), namespace, KafkaConnectS2ICluster.REST_API_PORT));\n-                        kafkaConnectS2Istatus.setBuildConfigName(KafkaConnectS2IResources.buildConfigName(connect.getCluster()));\n-\n-                        updateStatus(kafkaConnectS2I, reconciliation, kafkaConnectS2Istatus).setHandler(statusResult -> {\n-                            // If both features succeeded, createOrUpdate succeeded as well\n-                            // If one or both of them failed, we prefer the reconciliation failure as the main error\n-                            if (reconciliationResult.succeeded() && statusResult.succeeded()) {\n-                                createOrUpdatePromise.complete();\n-                            } else if (reconciliationResult.failed()) {\n-                                createOrUpdatePromise.fail(reconciliationResult.cause());\n-                            } else {\n-                                createOrUpdatePromise.fail(statusResult.cause());\n-                            }\n-                        });\n-                    });\n-            return createOrUpdatePromise.future();\n \n-        } else {\n-            return Future.failedFuture(\"The OpenShift build, image or apps APIs are not available in this Kubernetes cluster. Kafka Connect S2I deployment cannot be enabled.\");\n+            connect = KafkaConnectS2ICluster.fromCrd(kafkaConnectS2I, versions);\n+        } catch (Exception e) {\n+            StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnectS2I, kafkaConnectS2Istatus, Future.failedFuture(e));\n+            return updateStatus(kafkaConnectS2I, reconciliation, kafkaConnectS2Istatus);\n         }\n-    }\n \n-    @Override\n-    protected Future<Void> reconcileConnectors(Reconciliation reconciliation, KafkaConnectS2I connects2i, KafkaConnectS2Istatus connects2istatus) {\n-        return connectOperations.getAsync(connects2i.getMetadata().getNamespace(), connects2i.getMetadata().getName()).compose(connect -> {\n-            // If there's a non-s2i of the same name then do nothing, since that takes precedence\n-            if (connect != null) {\n-                return Future.succeededFuture();\n-            } else {\n-                return super.reconcileConnectors(reconciliation, connects2i, connects2istatus);\n-            }\n-        });\n+        connect.generateBuildConfig();\n+        ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(connect.getLogging() instanceof ExternalLogging ?\n+                configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :\n+                null);\n+\n+        HashMap<String, String> annotations = new HashMap<>();\n+        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));\n+\n+        log.debug(\"{}: Updating Kafka Connect S2I cluster\", reconciliation, name, namespace);\n+\n+        connectOperations.getAsync(kafkaConnectS2I.getMetadata().getNamespace(), kafkaConnectS2I.getMetadata().getName())\n+                .compose(otherConnect -> {\n+                    if (otherConnect != null\n+                            // There is a KafkaConnect with the same name which is older than  or equally old as this KafkaConnectS2I\n+                            && kafkaConnectS2I.getMetadata().getCreationTimestamp().compareTo(otherConnect.getMetadata().getCreationTimestamp()) >= 0)    {\n+                        return Future.failedFuture(\"Both KafkaConnect and KafkaConnectS2I exist with the same name. \" +\n+                                \"KafkaConnect seems to exists longer and will be used while this custom resource will be ignored.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eece63785e65bd29eec403c3d76080130e5e0687"}, "originalPosition": 123}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 676, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}