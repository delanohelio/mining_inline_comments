{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0ODU2MjE2", "number": 3200, "title": "[systemtest][kafkabridge] Remove dependency of external listeners", "bodyText": "Signed-off-by: Lukas Kral lukywill16@gmail.com\nType of change\n\nEnhancement\n\nDescription\nThis PR is focused on removing dependency of external listeners from Bridge tests. After discussion, we decided to use example-clients for sending/receiving messages via bridge service.\nFor our tests with weird usernames I had to keep the external listeners configuration -> so I moved it to separate suite. Earlier we found issue in our configuration -> the internal clients cannot handle names we used in weird usernames tests -> so with special characters, longer than (I think) 64 characters etc. I want to look at it in future PR, so I'll remove this suite later if it will be not needed.\nI removed all of our HTTP methods, because we are using example-http-clients everywhere, so there is no reason to keep them. After I removed all the WebClient and Vertx usage, I had to remove it from systemtests/pom.xml -> the mvn build was failing because of unused dependency.\nThe change of internalKafkaClient properties (the change from --broker-list to --bootstrap-servers) has been done because of impossibility to send messages to KafkaBridge -> this problem was discussed with @ppatierno.\nI added deployment of NP for Bridge -> this is needed for all operations between Bridge and other resources -> OCP4.x\nChecklist\n\n Make sure all tests pass", "createdAt": "2020-06-15T22:41:23Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200", "merged": true, "mergeCommit": {"oid": "88cb30375620ff5e396c99f2fff398962d7804d6"}, "closed": true, "closedAt": "2020-08-19T21:12:00Z", "author": {"login": "im-konge"}, "timelineItems": {"totalCount": 56, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwAoIigBqjM0OTI1NzY4OTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAhVg0AH2gAyNDM0ODU2MjE2OjlkNWVjYTg1OTczODdkMzkzNWIxYTdiMjc4MzYxYTgyODgyYWNhNWE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6fafe0de1247fafbb333e25bde719654df13cde", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b6fafe0de1247fafbb333e25bde719654df13cde", "committedDate": "2020-06-29T09:56:36Z", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "c48ae74f69b25a96df1f89f4ac58322175e1490d", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c48ae74f69b25a96df1f89f4ac58322175e1490d", "committedDate": "2020-06-29T12:58:06Z", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c48ae74f69b25a96df1f89f4ac58322175e1490d", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c48ae74f69b25a96df1f89f4ac58322175e1490d", "committedDate": "2020-06-29T12:58:06Z", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "67405d6de811116ff27875b862ce74c6ceac47a1", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/67405d6de811116ff27875b862ce74c6ceac47a1", "committedDate": "2020-06-29T19:20:02Z", "message": "remove bad label\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMDUxNTQ3", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-440051547", "createdAt": "2020-06-30T14:07:08Z", "commit": {"oid": "da430c28cd7f303033b94f4ffc7976627482af5f"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDowNzowOFrOGq-Gqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDoxMTo1OVrOGq-VQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcxMDg5MA==", "bodyText": "indentation", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447710890", "createdAt": "2020-06-30T14:07:08Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {\n+        IngressBackend backend = new IngressBackend();\n+        backend.setServiceName(serviceName);\n+        backend.setServicePort(new IntOrString(port));\n+\n+        HTTPIngressPath path = new HTTPIngressPath();\n+        path.setPath(\"/\");\n+        path.setBackend(backend);\n+\n+        return new IngressBuilder()\n+            .withNewMetadata()\n+            .withName(serviceName)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da430c28cd7f303033b94f4ffc7976627482af5f"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcxNDYyNw==", "bodyText": "why the choice of makingthe host an explicit parameter while hiding the port (80) inside the method?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447714627", "createdAt": "2020-06-30T14:11:59Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCors.java", "diffHunk": "@@ -59,7 +53,7 @@ void testCorsOriginAllowed(VertxTestContext context) {\n         JsonObject topics = new JsonObject();\n         topics.put(\"topics\", topic);\n \n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n+        client.request(HttpMethod.OPTIONS, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da430c28cd7f303033b94f4ffc7976627482af5f"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5f1a54a76429c4d28a6653720333ba226fdc0342", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5f1a54a76429c4d28a6653720333ba226fdc0342", "committedDate": "2020-06-30T14:49:50Z", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/583a9dca77079f36310b69fa9998bdf5b33334f0", "committedDate": "2020-06-30T14:50:56Z", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMDk4MjE1", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-440098215", "createdAt": "2020-06-30T14:52:23Z", "commit": {"oid": "5f1a54a76429c4d28a6653720333ba226fdc0342"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1Mjo0MFrOGrAShQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxNDo1OToyNFrOGrAn6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NjY5Mw==", "bodyText": "ingress as. a method name would probably suffice, since it is in the system tests, writing system test is redundant.\nSimilarly we are creating a resource and the return type suggests that.\nMight be worth adding a doc comment explaining a few of the config options if they're not clear why they are the way they are.\nI would suggest it be called createIngress but that clashes with the function with the name below.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447746693", "createdAt": "2020-06-30T14:52:40Z", "author": {"login": "samuel-hawker"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzI1NQ==", "bodyText": "Needs indenting", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447747255", "createdAt": "2020-06-30T14:53:19Z", "author": {"login": "samuel-hawker"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {\n+        IngressBackend backend = new IngressBackend();\n+        backend.setServiceName(serviceName);\n+        backend.setServicePort(new IntOrString(port));\n+\n+        HTTPIngressPath path = new HTTPIngressPath();\n+        path.setPath(\"/\");\n+        path.setBackend(backend);\n+\n+        return new IngressBuilder()\n+            .withNewMetadata()\n+                .withName(serviceName)\n+            .endMetadata()\n+            .withNewSpec()\n+            .withRules(new IngressRuleBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjAzOQ==", "bodyText": "testScramShaAuthWithWeirdUsername\nMight be worth testing this with several other names, or perhaps having the name containing more potentially problematic characters?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447752039", "createdAt": "2020-06-30T14:59:15Z", "author": {"login": "samuel-hawker"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeBaseST {\n+    private static final String BRIDGE_EXTERNAL_SERVICE = CLUSTER_NAME + \"-bridge-external-service\";\n+\n+    @Test\n+    void testScramShaAuthWithWeirdNamedUser() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjE3MQ==", "bodyText": "ditto naming", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447752171", "createdAt": "2020-06-30T14:59:24Z", "author": {"login": "samuel-hawker"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeBaseST {\n+    private static final String BRIDGE_EXTERNAL_SERVICE = CLUSTER_NAME + \"-bridge-external-service\";\n+\n+    @Test\n+    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n+        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n+        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n+\n+        // Initialize PasswordSecret to set this as PasswordSecret in Mirror Maker spec\n+        PasswordSecretSource passwordSecret = new PasswordSecretSource();\n+        passwordSecret.setSecretName(weirdUserName);\n+        passwordSecret.setPassword(\"password\");\n+\n+        // Initialize CertSecretSource with certificate and secret names for consumer\n+        CertSecretSource certSecret = new CertSecretSource();\n+        certSecret.setCertificate(\"ca.crt\");\n+        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));\n+\n+        KafkaBridgeSpec bridgeSpec = new KafkaBridgeSpecBuilder()\n+            .withNewKafkaClientAuthenticationScramSha512()\n+                .withNewUsername(weirdUserName)\n+                .withPasswordSecret(passwordSecret)\n+            .endKafkaClientAuthenticationScramSha512()\n+            .withNewTls()\n+                .withTrustedCertificates(certSecret)\n+            .endTls()\n+            .build();\n+\n+        testWeirdUsername(weirdUserName, new KafkaListenerAuthenticationScramSha512(), bridgeSpec, SecurityProtocol.SASL_SSL);\n+    }\n+\n+    @Test\n+    void testTlsAuthWithWeirdNamedUser() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0"}, "originalPosition": 72}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6a112014811c43e75b7ad09dbe66b00c720bd9a6", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6a112014811c43e75b7ad09dbe66b00c720bd9a6", "committedDate": "2020-06-30T15:51:42Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "e0850a72a2b76ab0e4c006af31bddad10f8328ef", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e0850a72a2b76ab0e4c006af31bddad10f8328ef", "committedDate": "2020-07-02T15:19:31Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyNjg4Mjc4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-442688278", "createdAt": "2020-07-05T15:58:05Z", "commit": {"oid": "e0850a72a2b76ab0e4c006af31bddad10f8328ef"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e0850a72a2b76ab0e4c006af31bddad10f8328ef", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e0850a72a2b76ab0e4c006af31bddad10f8328ef", "committedDate": "2020-07-02T15:19:31Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "b416bc314f10cad2928f663a6fedd8f023da1184", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b416bc314f10cad2928f663a6fedd8f023da1184", "committedDate": "2020-07-20T10:21:45Z", "message": "fixup! comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "825b89091f28da7d9b5c560b20941e72cccb77f7", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/825b89091f28da7d9b5c560b20941e72cccb77f7", "committedDate": "2020-07-20T20:58:50Z", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "7a204efdd3e86095a44801b6f926371ab64edd8b", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7a204efdd3e86095a44801b6f926371ab64edd8b", "committedDate": "2020-07-20T21:05:33Z", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7a204efdd3e86095a44801b6f926371ab64edd8b", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7a204efdd3e86095a44801b6f926371ab64edd8b", "committedDate": "2020-07-20T21:05:33Z", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "a309feece878fbbbadc39f22399fc09bec3f71f5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a309feece878fbbbadc39f22399fc09bec3f71f5", "committedDate": "2020-07-28T21:56:57Z", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cac00ca40cb5624683f99d6da4e226affcaa7400", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/cac00ca40cb5624683f99d6da4e226affcaa7400", "committedDate": "2020-07-29T22:27:12Z", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "f3b7ae72687114a37658fc8bc47f7c03e5d19230", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f3b7ae72687114a37658fc8bc47f7c03e5d19230", "committedDate": "2020-08-06T08:53:09Z", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f3b7ae72687114a37658fc8bc47f7c03e5d19230", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f3b7ae72687114a37658fc8bc47f7c03e5d19230", "committedDate": "2020-08-06T08:53:09Z", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "6e96a500acd7a2778f6918b2cba22f600b6c643d", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6e96a500acd7a2778f6918b2cba22f600b6c643d", "committedDate": "2020-08-10T09:18:17Z", "message": "rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fbe51f8f8dee163f68e76b03af5677a3fa3ac271", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fbe51f8f8dee163f68e76b03af5677a3fa3ac271", "committedDate": "2020-08-10T09:40:50Z", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "f9f430604a28a12951b2f65ae1a81d512ea9aab7", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f9f430604a28a12951b2f65ae1a81d512ea9aab7", "committedDate": "2020-08-10T10:41:58Z", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f9f430604a28a12951b2f65ae1a81d512ea9aab7", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f9f430604a28a12951b2f65ae1a81d512ea9aab7", "committedDate": "2020-08-10T10:41:58Z", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "201c4817b611c7248349111485c480e3cfbedbaf", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/201c4817b611c7248349111485c480e3cfbedbaf", "committedDate": "2020-08-10T15:55:17Z", "message": "back to strimzi image\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "18abc8c5ccdc1254606bd108ad0d90a616371b49", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/18abc8c5ccdc1254606bd108ad0d90a616371b49", "committedDate": "2020-08-11T07:02:24Z", "message": "do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2556563e992cf9760019c6bb383c7989089cfd5", "committedDate": "2020-08-13T19:57:11Z", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDYxNDY0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-468061464", "createdAt": "2020-08-16T12:44:22Z", "commit": {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQxMjo0NDoyM1rOHBSMkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQxMjo1MjoxOVrOHBSPwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwODc1Mw==", "bodyText": "Why do we have these tags if we are removing external access?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471108753", "createdAt": "2020-08-16T12:44:23Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java", "diffHunk": "@@ -37,40 +27,18 @@\n @Tag(NODEPORT_SUPPORTED)\n @Tag(EXTERNAL_CLIENTS_USED)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwOTU3MA==", "bodyText": "I think you should be running this in a separate pod. Not from the bridge pod it self.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471109570", "createdAt": "2020-08-16T12:52:19Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java", "diffHunk": "@@ -4,129 +4,109 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.KafkaBridgeHttpCors;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.ClientUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n import io.vertx.core.http.HttpMethod;\n-import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxTestContext;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Test;\n \n-import java.util.Arrays;\n-import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n \n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.hasItem;\n+import static org.hamcrest.Matchers.containsString;\n \n public class HttpBridgeCorsST extends HttpBridgeAbstractST {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCorsST.class);\n-    public static final String NAMESPACE = \"bridge-cluster-test\";\n-    private static final String CORS_ORIGIN = \"https://strimzi.io\";\n+    private static final String NAMESPACE = \"bridge-cors-cluster-test\";\n \n-    protected static String bridgeExternalService = CLUSTER_NAME + \"-bridge-external-service\";\n-    private static String bridgeHost;\n-    private static int bridgePort;\n+    private static final String ALLOWED_ORIGIN = \"https://strimzi.io\";\n+    private static final String NOT_ALLOWED_ORIGIN = \"https://evil.io\";\n+\n+    private static String podName = \"\";\n \n     @Test\n-    void testCorsOriginAllowed(VertxTestContext context) {\n+    void testCorsOriginAllowed() {\n         final String kafkaBridgeUser = \"bridge-user-example\";\n-        final String topicName = \"topic-simple-receive\";\n         final String groupId = ClientUtils.generateRandomConsumerGroup();\n \n         JsonObject config = new JsonObject();\n         config.put(\"name\", kafkaBridgeUser);\n         config.put(\"format\", \"json\");\n         config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n \n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(topicName);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-            .putHeader(\"Origin\", CORS_ORIGIN)\n-            .putHeader(\"Access-Control-Request-Method\", \"POST\")\n-            .putHeader(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .putHeader(\"Content-type\", Constants.KAFKA_BRIDGE_JSON)\n-            .sendJsonObject(config, ar -> context.verify(() -> {\n-                assertThat(ar.result().statusCode(), is(200));\n-                assertThat(ar.result().getHeader(\"access-control-allow-origin\"), is(CORS_ORIGIN));\n-                assertThat(ar.result().getHeader(\"access-control-allow-headers\"), is(\"access-control-allow-origin,origin,x-requested-with,content-type,access-control-allow-methods,accept\"));\n-                List<String> list = Arrays.asList(ar.result().getHeader(\"access-control-allow-methods\").split(\",\"));\n-                assertThat(list, hasItem(\"POST\"));\n-                client.request(HttpMethod.POST, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-                    .putHeader(\"Origin\", CORS_ORIGIN)\n-                    .send(ar2 -> context.verify(() -> {\n-                        assertThat(ar2.result().statusCode(), is(404));\n-                        context.completeNow();\n-                    }));\n-            }));\n+        Map<String, String> additionalHeaders = new HashMap<>();\n+        additionalHeaders.put(\"Origin\", ALLOWED_ORIGIN);\n+        additionalHeaders.put(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+\n+        String url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        String headers = BridgeUtils.addHeadersToString(additionalHeaders, Constants.KAFKA_BRIDGE_JSON_JSON, config.toString());\n+        String response = BridgeUtils.executeCurlCommand(HttpMethod.OPTIONS, podName, config.toString(), url, headers);\n+        String allowedHeaders = \"access-control-allow-origin,origin,x-requested-with,content-type,access-control-allow-methods,accept\";\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"200 OK\"));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-origin\", response), is(ALLOWED_ORIGIN));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-headers\", response), is(allowedHeaders));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-methods\", response), containsString(HttpMethod.POST.toString()));\n+\n+        url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        headers = BridgeUtils.addHeadersToString(Collections.singletonMap(\"Origin\", ALLOWED_ORIGIN));\n+        response = BridgeUtils.executeCurlCommand(HttpMethod.POST, podName, config.toString(), url, headers);\n+\n+        assertThat(response.contains(\"404\"), is(true));\n     }\n \n     @Test\n-    void testCorsForbidden(VertxTestContext context) {\n+    void testCorsForbidden() {\n         final String kafkaBridgeUser = \"bridge-user-example\";\n         final String groupId = ClientUtils.generateRandomConsumerGroup();\n \n-        final String notAllowedOrigin = \"https://evil.io\";\n-\n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-            .putHeader(\"Origin\", notAllowedOrigin)\n-            .putHeader(\"Access-Control-Request-Method\", \"POST\")\n-            .send(ar -> context.verify(() -> {\n-                assertThat(ar.result().statusCode(), is(403));\n-                assertThat(ar.result().statusMessage(), is(\"CORS Rejected - Invalid origin\"));\n-                client.request(HttpMethod.POST, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-                    .putHeader(\"Origin\", notAllowedOrigin)\n-                    .send(ar2 -> context.verify(() -> {\n-                        assertThat(ar2.result().statusCode(), is(403));\n-                        assertThat(ar2.result().statusMessage(), is(\"CORS Rejected - Invalid origin\"));\n-                        context.completeNow();\n-                    }));\n-            }));\n+        Map<String, String> additionalHeaders = new HashMap<>();\n+        additionalHeaders.put(\"Origin\", NOT_ALLOWED_ORIGIN);\n+        additionalHeaders.put(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+\n+        String url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        String headers = BridgeUtils.addHeadersToString(additionalHeaders);\n+        String response = BridgeUtils.executeCurlCommand(HttpMethod.OPTIONS, podName, url, headers);\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"403\"));\n+        assertThat(response, containsString(\"CORS Rejected - Invalid origin\"));\n+\n+        additionalHeaders.remove(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+        headers = BridgeUtils.addHeadersToString(additionalHeaders);\n+        response = BridgeUtils.executeCurlCommand(HttpMethod.POST, podName, url, headers);\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"403\"));\n+        assertThat(response, containsString(\"CORS Rejected - Invalid origin\"));\n     }\n \n     @BeforeAll\n-    static void beforeAll() throws InterruptedException {\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n-            .editSpec()\n-                .editKafka()\n-                    .editListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withTls(false)\n-                        .endKafkaListenerExternalNodePort()\n-                    .endListeners()\n-                .endKafka()\n-            .endSpec()\n-            .done();\n+    void beforeAll() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1).done();\n \n         KafkaBridgeResource.kafkaBridgeWithCors(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME),\n-            1, CORS_ORIGIN, null).done();\n+            1, ALLOWED_ORIGIN, null).done();\n \n         KafkaBridgeHttpCors kafkaBridgeHttpCors = KafkaBridgeResource.kafkaBridgeClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getHttp().getCors();\n         LOGGER.info(\"Bridge with the following CORS settings {}\", kafkaBridgeHttpCors.toString());\n \n-        Service service = KafkaBridgeUtils.createBridgeNodePortService(CLUSTER_NAME, NAMESPACE, bridgeExternalService);\n-        KubernetesResource.createServiceResource(service, NAMESPACE).done();\n-        ServiceUtils.waitForNodePortService(bridgeExternalService);\n-\n-        bridgePort = KafkaBridgeUtils.getBridgeNodePort(NAMESPACE, bridgeExternalService);\n-        bridgeHost = kubeClient(NAMESPACE).getNodeAddress();\n+        podName = kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-bridge\").get(0).getMetadata().getName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5"}, "originalPosition": 183}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2556563e992cf9760019c6bb383c7989089cfd5", "committedDate": "2020-08-13T19:57:11Z", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "committedDate": "2020-08-17T07:14:04Z", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4NTgzMjU3", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-468583257", "createdAt": "2020-08-17T15:47:24Z", "commit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNTo0NzoyNFrOHBua1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNTo0ODo1N1rOHBufFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTE1Ng==", "bodyText": "Kinda strange log, what should it say?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571156", "createdAt": "2020-08-17T15:47:24Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n-    }\n-\n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/topics/\" + topicName;\n+        headers = addHeadersToString(Constants.KAFKA_BRIDGE_JSON_JSON, records.toString());\n+        response = executeCurlCommand(HttpMethod.POST, podName, records.toString(), url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_PATTERN.matcher(response);\n+        JsonObject jsonResponse = new JsonObject(matcher.replaceFirst(\"{\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            LOGGER.debug(\"Server accepted post\");\n+        } else {\n+            throw new RuntimeException(\"Server didn't accept post: \" + response);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessagesHttpRequest(String podName, String groupID, String name) {\n+        LOGGER.info(\"Trying to receive messages\");\n+        JsonArray jsonResponse = receiveMessages(podName, groupID, name);\n+        if (jsonResponse.size() == 0) {\n+            LOGGER.info(\"Received 0 messages, trying again after subscribing to offset\");\n+            jsonResponse = receiveMessages(podName, groupID, name);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessages(String podName, String groupID, String name) {\n+        LOGGER.info(\"Receiving records from KafkaBridge\");\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000;\n+        headers = addHeadersToString(Collections.singletonMap(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON));\n+        response = executeCurlCommand(HttpMethod.GET, podName, \"\", url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_ARRAY_PATTERN.matcher(response);\n+        JsonArray jsonResponse = new JsonArray(matcher.replaceFirst(\"[\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            if (jsonResponse.size() > 0) {\n+                for (int i = 0; i < jsonResponse.size(); i++) {\n+                    JsonObject jsonObject = jsonResponse.getJsonObject(i);\n+                    LOGGER.info(\"JsonResponse: {}\", jsonObject.toString());\n+                    String kafkaTopic = jsonObject.getString(\"topic\");\n+                    int kafkaPartition = jsonObject.getInteger(\"partition\");\n+                    String key = jsonObject.getString(\"key\");\n+                    Object value = jsonObject.getValue(\"value\");\n+                    long offset = jsonObject.getLong(\"offset\");\n+                    LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n                 }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+                LOGGER.info(\"Received {} messages from KafkaBridge\", jsonResponse.size());\n+            } else {\n+                LOGGER.warn(\"Received body 0 messages: {}\", jsonResponse);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTU1MA==", "bodyText": "Maybe add the expected message count to the log?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571550", "createdAt": "2020-08-17T15:47:57Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n-    }\n-\n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/topics/\" + topicName;\n+        headers = addHeadersToString(Constants.KAFKA_BRIDGE_JSON_JSON, records.toString());\n+        response = executeCurlCommand(HttpMethod.POST, podName, records.toString(), url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_PATTERN.matcher(response);\n+        JsonObject jsonResponse = new JsonObject(matcher.replaceFirst(\"{\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            LOGGER.debug(\"Server accepted post\");\n+        } else {\n+            throw new RuntimeException(\"Server didn't accept post: \" + response);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessagesHttpRequest(String podName, String groupID, String name) {\n+        LOGGER.info(\"Trying to receive messages\");\n+        JsonArray jsonResponse = receiveMessages(podName, groupID, name);\n+        if (jsonResponse.size() == 0) {\n+            LOGGER.info(\"Received 0 messages, trying again after subscribing to offset\");\n+            jsonResponse = receiveMessages(podName, groupID, name);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessages(String podName, String groupID, String name) {\n+        LOGGER.info(\"Receiving records from KafkaBridge\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTY3NA==", "bodyText": "Maybe add expected records count?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571674", "createdAt": "2020-08-17T15:48:08Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MjI0NA==", "bodyText": "you should use bridge service address", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471572244", "createdAt": "2020-08-17T15:48:57Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,31 +4,35 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n+import io.vertx.core.http.HttpMethod;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n+    public static final Pattern ALL_BEFORE_JSON_PATTERN = Pattern.compile(\"(.*\\\\s)\\\\{\", Pattern.DOTALL);\n+    private static final Pattern ALL_BEFORE_JSON_ARRAY_PATTERN = Pattern.compile(\"(.*\\\\s)\\\\[\", Pattern.DOTALL);\n+\n+    public static final String DEFAULT_BRIDGE_HOST = \"localhost:\" + Constants.HTTP_BRIDGE_DEFAULT_PORT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5MTkzMTM1", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-469193135", "createdAt": "2020-08-18T10:26:35Z", "commit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMDoyNjozNVrOHCNQqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMDo0Njo0N1rOHCN4Xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NjQ1Ng==", "bodyText": "Change commend ? :)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472076456", "createdAt": "2020-08-18T10:26:35Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java", "diffHunk": "@@ -62,7 +62,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me\n \n     private static long timeoutForClientFinishJob(int messagesCount) {\n         // need to add at least 1-2minutes for finishing the job", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NzcwNw==", "bodyText": "I would prefer called it buildCurlCommand but it's just  suggestion.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472077707", "createdAt": "2020-08-18T10:29:11Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4MDgyMg==", "bodyText": "I know that the base idea was good. In a practise if you create method, which has one line to encapsulate some logic. You can end-up having these one-liners with different names but most likely same behaviour. Wouldn't you think that having:\ncmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", BridgeUtils.getCurlCommand(httpMethod, url, headers, data)).out().trim();\n\nwill be better?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472080822", "createdAt": "2020-08-18T10:35:08Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NTExNQ==", "bodyText": "The point of this test was to send the encrypted (tls) and moreover with support of simple authentication (scram-sha). You have changed to plain communication. Why? I am assuming that you wanted to just test thee scram-sha with plain communication. If this is the case please change the name of the test :)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472085115", "createdAt": "2020-08-18T10:43:37Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw==", "bodyText": "Why do you remove BRIDGE + REGRESSION tag?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472086623", "createdAt": "2020-08-18T10:46:47Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java", "diffHunk": "@@ -4,191 +4,102 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5MjEzODc4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-469213878", "createdAt": "2020-08-18T10:58:35Z", "commit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMDo1ODozNVrOHCOPpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMToxMzowOFrOHCOrHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MjU4MA==", "bodyText": "Does it work with Kafka 2.5.x ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472092580", "createdAt": "2020-08-18T10:58:35Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgument.java", "diffHunk": "@@ -23,7 +23,7 @@\n     ASSIGMENT_STRATEGY(\"--assignment-strategy\"),\n \n     // Producer\n-    BROKER_LIST(\"--broker-list\"),\n+    BOOTSTRAP_SERVER(\"--bootstrap-server\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5Mjk5NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (!data.equals(\"\")) {\n          \n          \n            \n                    if (data.isEmpty()) {\n          \n          \n            \n            ``` is maybe better?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472092995", "createdAt": "2020-08-18T10:59:28Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MzMxMw==", "bodyText": "Same as above", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472093313", "createdAt": "2020-08-18T11:00:03Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {\n+        return cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", getCurlCommand(httpMethod, url, headers, data)).out().trim();\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        return subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client, Collections.emptyMap());\n+    public static String addHeadersToString(Map<String, String> additionalHeaders) {\n+        return addHeadersToString(additionalHeaders, \"\",  \"\");\n     }\n \n-    public static JsonObject createBridgeConsumer(JsonObject config, String bridgeHost, int bridgePort, String groupId,\n-                                                  WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static String addHeadersToString(Map<String, String> additionalHeaders,  String contentType, String content) {\n+        StringBuilder headerString = new StringBuilder();\n \n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(config.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n+        if (!content.equals(\"\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MzM3Mw==", "bodyText": "same as above", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472093373", "createdAt": "2020-08-18T11:00:10Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {\n+        return cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", getCurlCommand(httpMethod, url, headers, data)).out().trim();\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        return subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client, Collections.emptyMap());\n+    public static String addHeadersToString(Map<String, String> additionalHeaders) {\n+        return addHeadersToString(additionalHeaders, \"\",  \"\");\n     }\n \n-    public static JsonObject createBridgeConsumer(JsonObject config, String bridgeHost, int bridgePort, String groupId,\n-                                                  WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static String addHeadersToString(Map<String, String> additionalHeaders,  String contentType, String content) {\n+        StringBuilder headerString = new StringBuilder();\n \n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(config.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n+        if (!content.equals(\"\")) {\n+            headerString.append(\" -H 'Content-length: \").append(content.length()).append(\"'\");\n+        }\n+\n+        if (!contentType.equals(\"\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDIwNQ==", "bodyText": "Wouldn't be better to use KafkaBridgeResources.url() instead just service name?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472094205", "createdAt": "2020-08-18T11:01:57Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java", "diffHunk": "@@ -34,43 +22,19 @@\n @ExtendWith(VertxExtension.class)\n @Tag(BRIDGE)\n @Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n public class HttpBridgeAbstractST extends AbstractST {\n-    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeAbstractST.class);\n-\n-    protected WebClient client;\n-    protected String bridgeExternalService = CLUSTER_NAME + \"-bridge-external-service\";\n+    public static int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    public static String bridgeHost = \"\";\n+    public static String kafkaClientsPodName = \"\";\n+    public static String bridgeServiceName = KafkaBridgeResources.serviceName(CLUSTER_NAME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA==", "bodyText": "Why?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472094378", "createdAt": "2020-08-18T11:02:17Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java", "diffHunk": "@@ -62,7 +62,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me\n \n     private static long timeoutForClientFinishJob(int messagesCount) {\n         // need to add at least 1-2minutes for finishing the job\n-        return (long) messagesCount * 1000 + Duration.ofMinutes(2).toMillis();\n+        return (long) messagesCount * 1000 + Duration.ofMinutes(3).toMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NTY0NA==", "bodyText": "The name is kinda misleading from my POV. IT looks like bridge have external listener here, which is not true.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472095644", "createdAt": "2020-08-18T11:04:59Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeAbstractST {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NjQ4Ng==", "bodyText": "Same as Maros mentioned above I guess", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472096486", "createdAt": "2020-08-18T11:06:39Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NjkyNg==", "bodyText": "Some new lines/indents?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472096926", "createdAt": "2020-08-18T11:07:36Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void setup() throws InterruptedException {\n+    void setup() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n-        KafkaListenerAuthenticationTls auth = new KafkaListenerAuthenticationTls();\n-        KafkaListenerTls listenerTls = new KafkaListenerTls();\n-        listenerTls.setAuth(auth);\n-\n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n                     .withNewListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationScramSha512())\n-                        .endKafkaListenerExternalNodePort()\n-                        .withNewTls().withAuth(new KafkaListenerAuthenticationScramSha512()).endTls()\n+                        .withNewPlain().withAuth(new KafkaListenerAuthenticationScramSha512()).endPlain()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NzI1MQ==", "bodyText": "Probably same as above? tls -> plain", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472097251", "createdAt": "2020-08-18T11:08:15Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void setup() throws InterruptedException {\n+    void setup() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n-        KafkaListenerAuthenticationTls auth = new KafkaListenerAuthenticationTls();\n-        KafkaListenerTls listenerTls = new KafkaListenerTls();\n-        listenerTls.setAuth(auth);\n-\n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n                     .withNewListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationScramSha512())\n-                        .endKafkaListenerExternalNodePort()\n-                        .withNewTls().withAuth(new KafkaListenerAuthenticationScramSha512()).endTls()\n+                        .withNewPlain().withAuth(new KafkaListenerAuthenticationScramSha512()).endPlain()\n                     .endListeners()\n                 .endKafka()\n             .endSpec().done();\n \n         // Create Kafka user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, USER_NAME).done();\n+        KafkaUser scramShaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME, scramShaUser).done();\n+\n+        kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n \n         // Initialize PasswordSecret to set this as PasswordSecret in Mirror Maker spec\n         PasswordSecretSource passwordSecret = new PasswordSecretSource();\n         passwordSecret.setSecretName(USER_NAME);\n         passwordSecret.setPassword(\"password\");\n \n-        // Initialize CertSecretSource with certificate and secret names for consumer\n-        CertSecretSource certSecret = new CertSecretSource();\n-        certSecret.setCertificate(\"ca.crt\");\n-        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));\n-\n         // Deploy http bridge\n-        KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1)\n+        KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NzYwOA==", "bodyText": "I wonder if we should keep it in all classes instead of inheriting it. It's a little bit confusing.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472097608", "createdAt": "2020-08-18T11:08:58Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java", "diffHunk": "@@ -4,191 +4,102 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw=="}, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5ODE5Mw==", "bodyText": "I think format before this changes looks better.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472098193", "createdAt": "2020-08-18T11:10:08Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java", "diffHunk": "@@ -4,191 +4,102 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n @Tag(ACCEPTANCE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeTlsST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);\n-\n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private static final String NAMESPACE = \"bridge-tls-cluster-test\";\n \n     @Test\n-    void testSendSimpleMessageTls() throws Exception {\n-        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+    void testSendSimpleMessageTls() {\n         // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-\n-        JsonObject records = BridgeUtils.generateHttpMessages(MESSAGE_COUNT);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, topicName, client);\n-        KafkaBridgeUtils.checkSendResponse(response, MESSAGE_COUNT);\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(topicName)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SSL)\n-            .withKafkaUsername(USER_NAME)\n-            .build();\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        assertThat(basicExternalKafkaClient.receiveMessagesTls(), is(MESSAGE_COUNT));\n-    }\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-    @Test\n-    void testReceiveSimpleMessageTls() throws Exception {\n-        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-        KafkaTopicUtils.waitForKafkaTopicCreation(topicName);\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", USER_NAME);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(USER_NAME));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(topicName);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client), is(true));\n-        // Send messages to Kafka\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(topicName)\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n             .withSecurityProtocol(SecurityProtocol.SSL)\n             .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-\n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client), is(true));\n+        assertThat(internalKafkaClient.receiveMessagesTls(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testTlsAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and maximum of 64 chars -> TLS\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n+    void testReceiveSimpleMessageTls() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n \n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        // Send messages to Kafka\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n             .withSecurityProtocol(SecurityProtocol.SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void createClassResources() throws InterruptedException {\n+    void createClassResources() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n-                    .editListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationTls())\n-                        .endKafkaListenerExternalNodePort()\n+                    .withNewListeners()\n+                        .withNewTls().withAuth(new KafkaListenerAuthenticationTls()).endTls()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTU4Mg==", "bodyText": "Why this change is needed?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472099582", "createdAt": "2020-08-18T11:13:02Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java", "diffHunk": "@@ -556,7 +551,7 @@ void testProducerConsumerMirrorMakerService() {\n         KafkaClientsResource.consumerWithTracing(KafkaResources.plainBootstrapAddress(kafkaClusterTargetName)).done();\n \n         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaClusterSourceName, kafkaClusterTargetName,\n-            ClientUtils.generateRandomConsumerGroup(), 1, false)\n+                \"my-group\" + new Random().nextInt(Integer.MAX_VALUE), 1, false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTYxNA==", "bodyText": "Same as above", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472099614", "createdAt": "2020-08-18T11:13:08Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java", "diffHunk": "@@ -688,7 +683,7 @@ void testProducerConsumerMirrorMakerConnectStreamsService() {\n                 + \"'\" + connectorConfig + \"'\" + \" http://localhost:8083/connectors\");\n \n         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaClusterSourceName, kafkaClusterTargetName,\n-            ClientUtils.generateRandomConsumerGroup(), 1, false)\n+                \"my-group\" + new Random().nextInt(Integer.MAX_VALUE), 1, false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5MzE5NDcy", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-469319472", "createdAt": "2020-08-18T11:52:46Z", "commit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMTo1Mjo0NlrOHCP58A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxMTo1NTo0OFrOHCQBgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjExOTc5Mg==", "bodyText": "I have another suggestion, but it's just that. You could also check that data has to be empty when the method is not  PUT or POST.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472119792", "createdAt": "2020-08-18T11:52:46Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NzcwNw=="}, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEyMTcyOQ==", "bodyText": "Agree", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472121729", "createdAt": "2020-08-18T11:55:48Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeAbstractST {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NTY0NA=="}, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 39}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f270223e235e5217f139d39574856fad239816e9", "committedDate": "2020-08-18T09:33:24Z", "message": "add NP for ocp4.x\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "3882d61f2b7b0d85461e8d5004b5346744720697", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3882d61f2b7b0d85461e8d5004b5346744720697", "committedDate": "2020-08-18T14:55:40Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5NTk2NzQ5", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-469596749", "createdAt": "2020-08-18T15:55:03Z", "commit": {"oid": "3882d61f2b7b0d85461e8d5004b5346744720697"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNTo1NTowNFrOHCbIvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNTo1NTowNFrOHCbIvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwMzgwNQ==", "bodyText": "I wonder why it needs additional time, maybe message count and timeout between messages is not set correctly?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472303805", "createdAt": "2020-08-18T15:55:04Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java", "diffHunk": "@@ -62,7 +62,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me\n \n     private static long timeoutForClientFinishJob(int messagesCount) {\n         // need to add at least 1-2minutes for finishing the job\n-        return (long) messagesCount * 1000 + Duration.ofMinutes(2).toMillis();\n+        return (long) messagesCount * 1000 + Duration.ofMinutes(3).toMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA=="}, "originalCommit": {"oid": "f270223e235e5217f139d39574856fad239816e9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5NzY4MDA1", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-469768005", "createdAt": "2020-08-18T19:42:38Z", "commit": {"oid": "584f1205aebd387a084c98fbd27b7cb32c343389"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwMTgwNzY2", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#pullrequestreview-470180766", "createdAt": "2020-08-19T07:10:02Z", "commit": {"oid": "584f1205aebd387a084c98fbd27b7cb32c343389"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "584f1205aebd387a084c98fbd27b7cb32c343389", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/584f1205aebd387a084c98fbd27b7cb32c343389", "committedDate": "2020-08-18T17:44:34Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "aff5a736ab785d0066bf356c7935bc8fe5273d59", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aff5a736ab785d0066bf356c7935bc8fe5273d59", "committedDate": "2020-08-19T14:53:04Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "aff5a736ab785d0066bf356c7935bc8fe5273d59", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aff5a736ab785d0066bf356c7935bc8fe5273d59", "committedDate": "2020-08-19T14:53:04Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "b036f6da83823b7c9c0033db69dea271da4e86a5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b036f6da83823b7c9c0033db69dea271da4e86a5", "committedDate": "2020-08-19T15:19:24Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f12e6327494facb64d6a58f0256e2d0e8102dab", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0f12e6327494facb64d6a58f0256e2d0e8102dab", "committedDate": "2020-08-19T19:47:38Z", "message": "remove external listeners and add ingress\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fab1b130afd5e75b2505f7e5e8f485d2bfc587da", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fab1b130afd5e75b2505f7e5e8f485d2bfc587da", "committedDate": "2020-08-19T19:47:38Z", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e1617cfab1e0d07540a3fc90cb3295703c46041", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7e1617cfab1e0d07540a3fc90cb3295703c46041", "committedDate": "2020-08-19T19:47:38Z", "message": "remove bad label\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f68e40d4b3652a533552b82a716bb230ff61f821", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f68e40d4b3652a533552b82a716bb230ff61f821", "committedDate": "2020-08-19T19:47:38Z", "message": "change the debug info\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d790838a24468b5931e5d0b4f7e15e99965cf0a5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d790838a24468b5931e5d0b4f7e15e99965cf0a5", "committedDate": "2020-08-19T19:47:38Z", "message": "new class, some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85fddd81a46620313f8c96a9e03ae7806e63f990", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/85fddd81a46620313f8c96a9e03ae7806e63f990", "committedDate": "2020-08-19T19:47:38Z", "message": "change the bridge spec to be the right one\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18386c6b4216448fe7519aa3cf940aaac0d90c26", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/18386c6b4216448fe7519aa3cf940aaac0d90c26", "committedDate": "2020-08-19T19:47:38Z", "message": "add tag\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a641612564ef071d1936097d7b08bc26d7282f42", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a641612564ef071d1936097d7b08bc26d7282f42", "committedDate": "2020-08-19T19:47:38Z", "message": "add constant for ingress port\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fee3a8a8fa28c787145712c688a1e430e4fdd723", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fee3a8a8fa28c787145712c688a1e430e4fdd723", "committedDate": "2020-08-19T19:47:38Z", "message": "fix indent\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "554f6fcc909e711d5de035cb8cb6328d50748453", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/554f6fcc909e711d5de035cb8cb6328d50748453", "committedDate": "2020-08-19T19:47:38Z", "message": "remove unnecessary overloads\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "652efdd0536ac056b3992c48498f8b6d1b20a665", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/652efdd0536ac056b3992c48498f8b6d1b20a665", "committedDate": "2020-08-19T19:47:38Z", "message": "add back ports for bridge requests\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae5006fadf0d49ec0ee014580d793427a775d8f1", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ae5006fadf0d49ec0ee014580d793427a775d8f1", "committedDate": "2020-08-19T19:47:38Z", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a1914607a72a2604fb6381154bdf285289eeddd", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0a1914607a72a2604fb6381154bdf285289eeddd", "committedDate": "2020-08-19T19:47:38Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "833954ca3bc5b6e43d61b0ee3eb5baee77a2b18d", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/833954ca3bc5b6e43d61b0ee3eb5baee77a2b18d", "committedDate": "2020-08-19T19:47:38Z", "message": "fixup! comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b163fa1cff58912500a6b83967094602d9f1f49b", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b163fa1cff58912500a6b83967094602d9f1f49b", "committedDate": "2020-08-19T19:47:38Z", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "807297c4100c70a9969abc6f74b0c9566d0f93b1", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/807297c4100c70a9969abc6f74b0c9566d0f93b1", "committedDate": "2020-08-19T19:48:16Z", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3351cad1172f6260d405495e1d84eedc436f3bba", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3351cad1172f6260d405495e1d84eedc436f3bba", "committedDate": "2020-08-19T19:48:17Z", "message": "rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "75a530c1d1e1bfeb9852f8d470bca9d7b28a37a8", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/75a530c1d1e1bfeb9852f8d470bca9d7b28a37a8", "committedDate": "2020-08-19T19:48:17Z", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e32b06515afa1df80dd1588c95c616c0921a60d9", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e32b06515afa1df80dd1588c95c616c0921a60d9", "committedDate": "2020-08-19T19:48:17Z", "message": "back to strimzi image\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "272f22d7c0cb18e1c0733ad15954e25a731b6cfc", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/272f22d7c0cb18e1c0733ad15954e25a731b6cfc", "committedDate": "2020-08-19T19:48:52Z", "message": "do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa7abcb7f2dcfece49b7eb8db62470f98354f807", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aa7abcb7f2dcfece49b7eb8db62470f98354f807", "committedDate": "2020-08-19T19:48:54Z", "message": "fixup! do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7456dfa1c03a5770ebb5ad1466d2224020d013e", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f7456dfa1c03a5770ebb5ad1466d2224020d013e", "committedDate": "2020-08-19T19:48:54Z", "message": "fixup! fixup! do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ba7a9c64b8956405f341c50fb4aa774e08e2c88", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1ba7a9c64b8956405f341c50fb4aa774e08e2c88", "committedDate": "2020-08-19T19:48:54Z", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "858f6f994df1efaa9818c1d33e8daa400ee73734", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/858f6f994df1efaa9818c1d33e8daa400ee73734", "committedDate": "2020-08-19T19:50:00Z", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8afa9e589cd8ed66f8b407e151d422c7efbe3d0f", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/8afa9e589cd8ed66f8b407e151d422c7efbe3d0f", "committedDate": "2020-08-19T19:50:01Z", "message": "add NP for ocp4.x\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f79d17d328a89890ba87cdf88bec1b253a340f9", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6f79d17d328a89890ba87cdf88bec1b253a340f9", "committedDate": "2020-08-19T19:50:01Z", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1902d72052fa58ec046564d28b52fb078ff219e3", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1902d72052fa58ec046564d28b52fb078ff219e3", "committedDate": "2020-08-19T19:50:16Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b036f6da83823b7c9c0033db69dea271da4e86a5", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b036f6da83823b7c9c0033db69dea271da4e86a5", "committedDate": "2020-08-19T15:19:24Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}, "afterCommit": {"oid": "1902d72052fa58ec046564d28b52fb078ff219e3", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1902d72052fa58ec046564d28b52fb078ff219e3", "committedDate": "2020-08-19T19:50:16Z", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d5eca8597387d3935b1a7b278361a82882aca5a", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9d5eca8597387d3935b1a7b278361a82882aca5a", "committedDate": "2020-08-19T20:07:36Z", "message": "fixup! fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1557, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}