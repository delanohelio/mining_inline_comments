{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY1NTU2NzAx", "number": 3489, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDo0MTo1OFrOEW9OOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToyOTowNVrOEXQ_hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNTA3MTk1OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDo0MTo1OFrOG-fELg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQwOToyOToyNVrOG-v28g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3Mzg3MA==", "bodyText": "How does this one differ from the original one? I didn't compare it in detail. But it looks similar.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468173870", "createdAt": "2020-08-10T20:41:58Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,61 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = INFO\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = WARN\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = WARN\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e096e578d8ca3160576cbbc153d0addb76cfe3d2"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ0OTAxMA==", "bodyText": "You are right, I'm gonna change it -> the only difference was in lining and white spaces. Thanks!", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468449010", "createdAt": "2020-08-11T09:29:25Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,61 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = INFO\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = WARN\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = WARN\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3Mzg3MA=="}, "originalCommit": {"oid": "e096e578d8ca3160576cbbc153d0addb76cfe3d2"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNTA3MzkxOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDo0MjozOVrOG-fFXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMDo0MjozOVrOG-fFXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3NDE3NQ==", "bodyText": "This is all good. But I do not see anything to check the actual log level used by CO. This is testing Kubernetes.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468174175", "createdAt": "2020-08-10T20:42:39Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,61 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = INFO\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = WARN\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = WARN\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";\n+\n+        ConfigMap coMap = new ConfigMapBuilder()\n+            .withNewMetadata()\n+                .addToLabels(\"app\", \"strimzi\")\n+                .withName(STRIMZI_DEPLOYMENT_NAME)\n+                .withNamespace(NAMESPACE)\n+            .endMetadata()\n+            .withData(Collections.singletonMap(\"log4j2.properties\", log4jConfig))\n+            .build();\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        String command = \"cat /opt/strimzi/custom-config/log4j2.properties\";\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(log4jConfig)\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        String podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e096e578d8ca3160576cbbc153d0addb76cfe3d2"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNzM0NDc2OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMTo0NTo1NFrOG-0IQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxMTo0Njo1NFrOG-0KWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUxODk3OQ==", "bodyText": "Waiting {} ms log not to be empty\n// wait some time and check whether logs after this time are not empty", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468518979", "createdAt": "2020-08-11T11:45:54Z", "author": {"login": "sknot-rh"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,97 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() throws InterruptedException {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+        String command = \"cat /opt/strimzi/custom-config/log4j2.properties\";\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = OFF\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = OFF\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = OFF\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";\n+\n+        ConfigMap coMap = new ConfigMapBuilder()\n+            .withNewMetadata()\n+                .addToLabels(\"app\", \"strimzi\")\n+                .withName(STRIMZI_DEPLOYMENT_NAME)\n+                .withNamespace(NAMESPACE)\n+            .endMetadata()\n+            .withData(Collections.singletonMap(\"log4j2.properties\", log4jConfig))\n+            .build();\n+\n+        LOGGER.info(\"Checking that original logging config is different from the new one\");\n+        assertThat(log4jConfig, not(equalTo(cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim())));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = OFF\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        String podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));\n+\n+        LOGGER.info(\"Waiting {} ms log to be empty\", LOGGING_RELOADING_INTERVAL * 2);\n+        // wait some time and check whether logs after this time are empty\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain no records\");\n+        assertThat(StUtils.getLogFromPodByTime(coPodName, STRIMZI_DEPLOYMENT_NAME, \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing all levels from OFF to INFO/WARN\");\n+        log4jConfig = log4jConfig.replaceAll(\"OFF\", \"INFO\");\n+        coMap.setData(Collections.singletonMap(\"log4j2.properties\", log4jConfig));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = INFO\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));\n+\n+        LOGGER.info(\"Waiting {} ms log to be empty\", LOGGING_RELOADING_INTERVAL * 2);\n+        // wait some time and check whether logs after this time are empty", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a873af6a3485d638ee6bfcef3bbad2b56cb509c9"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUxOTUxMw==", "bodyText": "Yep copy-paste fault :D", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468519513", "createdAt": "2020-08-11T11:46:54Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,97 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() throws InterruptedException {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+        String command = \"cat /opt/strimzi/custom-config/log4j2.properties\";\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = OFF\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = OFF\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = OFF\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";\n+\n+        ConfigMap coMap = new ConfigMapBuilder()\n+            .withNewMetadata()\n+                .addToLabels(\"app\", \"strimzi\")\n+                .withName(STRIMZI_DEPLOYMENT_NAME)\n+                .withNamespace(NAMESPACE)\n+            .endMetadata()\n+            .withData(Collections.singletonMap(\"log4j2.properties\", log4jConfig))\n+            .build();\n+\n+        LOGGER.info(\"Checking that original logging config is different from the new one\");\n+        assertThat(log4jConfig, not(equalTo(cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim())));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = OFF\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        String podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));\n+\n+        LOGGER.info(\"Waiting {} ms log to be empty\", LOGGING_RELOADING_INTERVAL * 2);\n+        // wait some time and check whether logs after this time are empty\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain no records\");\n+        assertThat(StUtils.getLogFromPodByTime(coPodName, STRIMZI_DEPLOYMENT_NAME, \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing all levels from OFF to INFO/WARN\");\n+        log4jConfig = log4jConfig.replaceAll(\"OFF\", \"INFO\");\n+        coMap.setData(Collections.singletonMap(\"log4j2.properties\", log4jConfig));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = INFO\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));\n+\n+        LOGGER.info(\"Waiting {} ms log to be empty\", LOGGING_RELOADING_INTERVAL * 2);\n+        // wait some time and check whether logs after this time are empty", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUxODk3OQ=="}, "originalCommit": {"oid": "a873af6a3485d638ee6bfcef3bbad2b56cb509c9"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODMwODk1OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToyODozN1rOG-9WIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToyODozN1rOG-9WIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY2OTk4NA==", "bodyText": "\"its\"", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468669984", "createdAt": "2020-08-11T15:28:37Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,99 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() throws InterruptedException {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+        String command = \"cat /opt/strimzi/custom-config/log4j2.properties\";\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = OFF\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = OFF\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = OFF\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";\n+\n+        ConfigMap coMap = new ConfigMapBuilder()\n+            .withNewMetadata()\n+                .addToLabels(\"app\", \"strimzi\")\n+                .withName(STRIMZI_DEPLOYMENT_NAME)\n+                .withNamespace(NAMESPACE)\n+            .endMetadata()\n+            .withData(Collections.singletonMap(\"log4j2.properties\", log4jConfig))\n+            .build();\n+\n+        LOGGER.info(\"Checking that original logging config is different from the new one\");\n+        assertThat(log4jConfig, not(equalTo(cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim())));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = OFF\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        String podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abcba21c4c99346724db64dfd2bd3ff48ffc4fc1"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODMxMTA4OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToyOTowNVrOG-9XdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNToyOTowNVrOG-9XdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY3MDMyNA==", "bodyText": "\"its\"", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3489#discussion_r468670324", "createdAt": "2020-08-11T15:29:05Z", "author": {"login": "ppatierno"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -456,6 +457,99 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {\n         assertThat(\"Bridge pod should not roll\", DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(CLUSTER_NAME)), equalTo(bridgeSnapshot));\n     }\n \n+    @Test\n+    void testDynamicallySetClusterOperatorLoggingLevels() throws InterruptedException {\n+        Map<String, String> coPod = DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME);\n+        String coPodName = kubeClient().listPodsByPrefixInName(STRIMZI_DEPLOYMENT_NAME).get(0).getMetadata().getName();\n+        String command = \"cat /opt/strimzi/custom-config/log4j2.properties\";\n+\n+        String log4jConfig =\n+            \"name = COConfig\\n\" +\n+            \"monitorInterval = 30\\n\" +\n+            \"\\n\" +\n+            \"    appender.console.type = Console\\n\" +\n+            \"    appender.console.name = STDOUT\\n\" +\n+            \"    appender.console.layout.type = PatternLayout\\n\" +\n+            \"    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\\n\" +\n+            \"\\n\" +\n+            \"    rootLogger.level = OFF\\n\" +\n+            \"    rootLogger.appenderRefs = stdout\\n\" +\n+            \"    rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+            \"    rootLogger.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Kafka AdminClient logging is a bit noisy at INFO level\\n\" +\n+            \"    logger.kafka.name = org.apache.kafka\\n\" +\n+            \"    logger.kafka.level = OFF\\n\" +\n+            \"    logger.kafka.additivity = false\\n\" +\n+            \"\\n\" +\n+            \"    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default\\n\" +\n+            \"    logger.zookeepertrustmanager.name = org.apache.zookeeper\\n\" +\n+            \"    logger.zookeepertrustmanager.level = OFF\\n\" +\n+            \"    logger.zookeepertrustmanager.additivity = false\";\n+\n+        ConfigMap coMap = new ConfigMapBuilder()\n+            .withNewMetadata()\n+                .addToLabels(\"app\", \"strimzi\")\n+                .withName(STRIMZI_DEPLOYMENT_NAME)\n+                .withNamespace(NAMESPACE)\n+            .endMetadata()\n+            .withData(Collections.singletonMap(\"log4j2.properties\", log4jConfig))\n+            .build();\n+\n+        LOGGER.info(\"Checking that original logging config is different from the new one\");\n+        assertThat(log4jConfig, not(equalTo(cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim())));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = OFF\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        String podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");\n+        assertThat(coPod, equalTo(DeploymentUtils.depSnapshot(STRIMZI_DEPLOYMENT_NAME)));\n+\n+        LOGGER.info(\"Waiting {} ms log to be empty\", LOGGING_RELOADING_INTERVAL);\n+        // wait some time and check whether logs after this time are empty\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL);\n+\n+        LOGGER.info(\"Asserting if log will contain no records\");\n+        assertThat(StUtils.getLogFromPodByTime(coPodName, STRIMZI_DEPLOYMENT_NAME, \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing all levels from OFF to INFO/WARN\");\n+        log4jConfig = log4jConfig.replaceAll(\"OFF\", \"INFO\");\n+        coMap.setData(Collections.singletonMap(\"log4j2.properties\", log4jConfig));\n+\n+        LOGGER.info(\"Changing logging for cluster-operator\");\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(coMap);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().contains(\"rootLogger.level = INFO\")\n+        );\n+\n+        LOGGER.info(\"Checking log4j2.properties in CO pod\");\n+        podLogConfig = cmdKubeClient().execInPod(coPodName, \"/bin/bash\", \"-c\", command).out().trim();\n+        assertThat(podLogConfig, equalTo(log4jConfig));\n+\n+        LOGGER.info(\"Checking if CO rolled it's pod\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abcba21c4c99346724db64dfd2bd3ff48ffc4fc1"}, "originalPosition": 92}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1285, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}