{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4MjE1MzA3", "number": 3854, "title": "[MO] - [OLM] - upgrade suite", "bodyText": "Signed-off-by: morsak xorsak02@stud.fit.vutbr.cz\nType of change\n\nEnhancement / new feature\nRefactoring\n\nDescription\nThis PR adding OlmUpgradeST test suite which does upgrade from the specific version using OLM_OPERATOR_PREVIOUS_RELEASE_VERSION variable to the latest one.\nChecklist\n\n Write tests\n Make sure all tests pass", "createdAt": "2020-10-22T11:20:59Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854", "merged": true, "mergeCommit": {"oid": "1b425956e43a05ac3ebef24c40dc18bb7bbb4cdd"}, "closed": true, "closedAt": "2020-11-13T17:59:20Z", "author": {"login": "see-quick"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdVIzxXAFqTUxNTEyMzY4Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdcIu1vgH2gAyNTA4MjE1MzA3OjJiNWZiMjg4Mzc2Y2U4NGYwZDRiYzZkMjJkY2UzYWIzODA2Mzk1YTk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MTIzNjg3", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-515123687", "createdAt": "2020-10-22T21:13:46Z", "commit": {"oid": "4966817492d873b649ca31aa69ea31fc00a88944"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMToxMzo0NlrOHm0EjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMToxODoyN1rOHm0OOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ2MTA2OA==", "bodyText": "You can use kubeClient().getClusterOperatorPodName(); in methods where you checking if the pod exist. If it returns the null or something, you can handle it. Just suggestion.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r510461068", "createdAt": "2020-10-22T21:13:46Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,266 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    private static final String CO_POD_PREFIX_NAME = \"strimzi-cluster-operator-\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4966817492d873b649ca31aa69ea31fc00a88944"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ2MTk0MQ==", "bodyText": "But then you will need to handle the NPE ... so maybe that's not good idea \ud83d\ude04 . Other suggestion is to add it to Constants..", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r510461941", "createdAt": "2020-10-22T21:15:27Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,266 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    private static final String CO_POD_PREFIX_NAME = \"strimzi-cluster-operator-\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ2MTA2OA=="}, "originalCommit": {"oid": "4966817492d873b649ca31aa69ea31fc00a88944"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ2MzU0Nw==", "bodyText": "Extra line?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r510463547", "createdAt": "2020-10-22T21:18:27Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/enums/OlmInstallationStrategy.java", "diffHunk": "@@ -0,0 +1,11 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.enums;\n+\n+public enum OlmInstallationStrategy {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4966817492d873b649ca31aa69ea31fc00a88944"}, "originalPosition": 8}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1NzU0MTA2", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-515754106", "createdAt": "2020-10-23T15:04:57Z", "commit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxNTowNDo1OFrOHnR0xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QxODo1NDowMlrOHnaC1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk0ODU1MA==", "bodyText": "Utils?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r510948550", "createdAt": "2020-10-23T15:04:58Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,280 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    private static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, true);\n+    }\n+\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, isLatest);\n+    }\n+\n+    public static void upgradeAbleClusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+        if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).size() == 0) {\n+            clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+                olmInstallationStrategy, isLatest);\n+        } else {\n+            // upgrade if CO is present\n+            upgradeClusterOperator();\n+        }\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, true);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (isLatest) {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n+        } else {\n+            createAndModifySubscriptionPreviousRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_PREVIOUS_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            waitUntilSomeInstallPlanIsPresent();\n+            obtainInstallPlanName();\n+            approveInstallation();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    public static void waitUntilSomeInstallPlanIsPresent() {\n+        TestUtils.waitFor(\"install plan is present\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> {\n+                try {\n+                    obtainInstallPlanName();\n+                    return true;\n+                } catch (RuntimeException e)  {\n+                    return false;\n+                }\n+            });\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTA3ODI4NA==", "bodyText": "This is a little bit confusing. You want to patch and approve non used install plan. Maybe better naming?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r511078284", "createdAt": "2020-10-23T18:44:31Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,280 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    private static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, true);\n+    }\n+\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, isLatest);\n+    }\n+\n+    public static void upgradeAbleClusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+        if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).size() == 0) {\n+            clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+                olmInstallationStrategy, isLatest);\n+        } else {\n+            // upgrade if CO is present\n+            upgradeClusterOperator();\n+        }\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, true);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, boolean isLatest) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (isLatest) {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n+        } else {\n+            createAndModifySubscriptionPreviousRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_PREVIOUS_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            waitUntilSomeInstallPlanIsPresent();\n+            obtainInstallPlanName();\n+            approveInstallation();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    public static void waitUntilSomeInstallPlanIsPresent() {\n+        TestUtils.waitFor(\"install plan is present\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> {\n+                try {\n+                    obtainInstallPlanName();\n+                    return true;\n+                } catch (RuntimeException e)  {\n+                    return false;\n+                }\n+            });\n+    }\n+\n+    /**\n+     * Get install plan name and store it to closedMapInstallPlan\n+     */\n+    public static void obtainInstallPlanName() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line NAME  CSV  APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\" \");\n+\n+            // name\n+            if (wholeLine[0].startsWith(\"install-\")) {\n+\n+                // if is not already applied add to closed map\n+                if (!CLOSED_MAP_INSTALL_PLAN.containsKey(wholeLine[0])) {\n+                    LOGGER.info(\"CLOSED_MAP_INSTALL_PLAN does not contain {} install plan so this is not used and will \" +\n+                        \"be in the following upgrade.\", wholeLine[0]);\n+                    CLOSED_MAP_INSTALL_PLAN.put(wholeLine[0], Boolean.FALSE);\n+                }\n+            }\n+        }\n+        if (!(CLOSED_MAP_INSTALL_PLAN.keySet().size() > 0)) {\n+            throw new RuntimeException(\"No install plans located in namespace:\" + cmdKubeClient().namespace());\n+        }\n+    }\n+\n+    /**\n+     * Get specific version of cluster operator with prefix name in format: 'strimzi-cluster-operator.v0.18.0'\n+     * @return version with prefix name\n+     */\n+    public static String getClusterOperatorVersion() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line = NAME   CSV   APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\"   \");\n+\n+            // non-used install plan\n+            if (wholeLine[0].equals(getNonUsedInstallPlan())) {\n+                return wholeLine[1];\n+            }\n+        }\n+        throw new RuntimeException(\"Version was not found in the install plan.\");\n+    }\n+\n+    public static boolean isUpgradeable() {\n+        return !getNonUsedInstallPlan().equals(NO_MORE_NON_USED_INSTALL_PLANS);\n+    }\n+\n+    public static String getNonUsedInstallPlan() {\n+        String[] nonUsedInstallPlan = new String[1];\n+\n+        for (Map.Entry<String, Boolean> entry : CLOSED_MAP_INSTALL_PLAN.entrySet()) {\n+            // if value is FALSE we are gonna use it = non-used install plan\n+            if (!entry.getValue()) {\n+                nonUsedInstallPlan[0] = entry.getKey();\n+                break;\n+            }\n+            nonUsedInstallPlan[0] = NO_MORE_NON_USED_INSTALL_PLANS;\n+        }\n+\n+        LOGGER.info(\"Non-used install plan is {}\", nonUsedInstallPlan[0]);\n+        return nonUsedInstallPlan[0];\n+    }\n+\n+    /**\n+     * Patches specific non used install plan, which will approve installation. Only for manual installation strategy.\n+     * Also updates closedMapInstallPlan map and set specific install plan to true.\n+     */\n+    private static void approveInstallation() {\n+        String nonUsedInstallPlan = getNonUsedInstallPlan();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTA4MDY4MQ==", "bodyText": "Wonder if wouldn't be better to use StrimziUpgradeST.json for each upgrade phase as we do in StrimziUpgradeST to avoid mistakes during manfiests image build. Imagine, that manifest image iwll does not contain latest manifests cause some issue during build. The tests will pass anyway, because it will not care if latest version should be X or Y. WDYT?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r511080681", "createdAt": "2020-10-23T18:48:39Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @Test\n+    void testUpgrade() {\n+        Map<String, String> kafkaSnapshot = null;\n+        boolean isUpgradeAble = true;\n+\n+        while (isUpgradeAble) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTA4MTg3Nw==", "bodyText": "6.6.6 should be passed to STs via som env var. In case the latest version in our image will change, we case easily forget to chage it here and it could take some time to debug", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r511081877", "createdAt": "2020-10-23T18:51:12Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @Test\n+    void testUpgrade() {\n+        Map<String, String> kafkaSnapshot = null;\n+        boolean isUpgradeAble = true;\n+\n+        while (isUpgradeAble) {\n+            // 1. Create subscription (+ operator group) with version latest - 1 (manual approval strategy) already done...!\n+            // 2. Approve installation\n+            //   a) get name of install-plan\n+            //   b) approve installation\n+            OlmResource.upgradeAbleClusterOperator(namespace, OlmInstallationStrategy.Manual, false);\n+\n+            String currentVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+            LOGGER.info(\"====================================================================================\");\n+            LOGGER.info(\"============== Verification version of CO:\" + currentVersionOfCo);\n+            LOGGER.info(\"====================================================================================\");\n+\n+            // wait until RU is finished (first run skipping)\n+            if (kafkaSnapshot != null) {\n+                StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+            }\n+\n+            // 3. perform verification of specific version\n+            performUpgradeVerification();\n+            kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+            OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+            OlmResource.obtainInstallPlanName();\n+            isUpgradeAble = OlmResource.isUpgradeable();\n+        }\n+    }\n+\n+    private void performUpgradeVerification() {\n+        // fetch the tag from imageName: docker.io/strimzi/operator:'[latest|0.19.0|0.18.0]'\n+        String containerImageTag = kubeClient().getDeployment(kubeClient().getDeploymentNameByPrefix(Constants.STRIMZI_DEPLOYMENT_NAME))\n+            .getSpec()\n+            .getTemplate()\n+            .getMetadata()\n+            .getAnnotations()\n+            .get(\"containerImage\").split(\":\")[1];\n+\n+        LOGGER.info(\"Image tag of strimzi operator is {}\", containerImageTag);\n+\n+        // NOT (latest image or default substring(1)) for skipping 'v'0.19.0 on the start...\n+        // '6.6.6' is the latest version of cluster operator\n+        if (!containerImageTag.equals(\"6.6.6\") && (!(containerImageTag.equals(\"latest\") || containerImageTag.equals(Environment.OLM_OPERATOR_VERSION_DEFAULT.substring(1))))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTA4MzIyMg==", "bodyText": "You should attach clients at the beginning of the upgrade as we do it in StrimziUpgradeST.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r511083222", "createdAt": "2020-10-23T18:54:02Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @Test\n+    void testUpgrade() {\n+        Map<String, String> kafkaSnapshot = null;\n+        boolean isUpgradeAble = true;\n+\n+        while (isUpgradeAble) {\n+            // 1. Create subscription (+ operator group) with version latest - 1 (manual approval strategy) already done...!\n+            // 2. Approve installation\n+            //   a) get name of install-plan\n+            //   b) approve installation\n+            OlmResource.upgradeAbleClusterOperator(namespace, OlmInstallationStrategy.Manual, false);\n+\n+            String currentVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+            LOGGER.info(\"====================================================================================\");\n+            LOGGER.info(\"============== Verification version of CO:\" + currentVersionOfCo);\n+            LOGGER.info(\"====================================================================================\");\n+\n+            // wait until RU is finished (first run skipping)\n+            if (kafkaSnapshot != null) {\n+                StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+            }\n+\n+            // 3. perform verification of specific version\n+            performUpgradeVerification();\n+            kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+            OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+            OlmResource.obtainInstallPlanName();\n+            isUpgradeAble = OlmResource.isUpgradeable();\n+        }\n+    }\n+\n+    private void performUpgradeVerification() {\n+        // fetch the tag from imageName: docker.io/strimzi/operator:'[latest|0.19.0|0.18.0]'\n+        String containerImageTag = kubeClient().getDeployment(kubeClient().getDeploymentNameByPrefix(Constants.STRIMZI_DEPLOYMENT_NAME))\n+            .getSpec()\n+            .getTemplate()\n+            .getMetadata()\n+            .getAnnotations()\n+            .get(\"containerImage\").split(\":\")[1];\n+\n+        LOGGER.info(\"Image tag of strimzi operator is {}\", containerImageTag);\n+\n+        // NOT (latest image or default substring(1)) for skipping 'v'0.19.0 on the start...\n+        // '6.6.6' is the latest version of cluster operator\n+        if (!containerImageTag.equals(\"6.6.6\") && (!(containerImageTag.equals(\"latest\") || containerImageTag.equals(Environment.OLM_OPERATOR_VERSION_DEFAULT.substring(1))))) {\n+            try {\n+                File dir = FileUtils.downloadAndUnzip(\"https://github.com/strimzi/strimzi-kafka-operator/releases/download/\" + containerImageTag + \"/strimzi-\" + containerImageTag + \".zip\");\n+\n+                deployKafkaFromFile(dir, containerImageTag);\n+                waitForReadinessOfKafkaCluster();\n+\n+                KafkaTopicResource.topic(CLUSTER_NAME, topicUpgradeName).done();\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+        //  this is round only last version (so kafka is not present)\n+        } else if (KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get() == null) {\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3).done();\n+        }\n+\n+        String currentKafkaVersion = KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get().getSpec().getKafka().getVersion();\n+\n+        LOGGER.info(\"Current Kafka message version is {}\", currentKafkaVersion);\n+\n+        if (mapOfKafkaVersionsWithSupportedClusterOperators.containsKey(currentKafkaVersion)) {\n+            // supported co version for specific kafka version\n+            List<String> supportedClusterOperatorVersion = mapOfKafkaVersionsWithSupportedClusterOperators.get(currentKafkaVersion);\n+\n+            // exist version of cluster operator in list of supported\n+            if (supportedClusterOperatorVersion.contains(containerImageTag)) {\n+                LOGGER.info(\"Current Kafka Version {} supports Cluster operator version {}. So we are not gonna upgrade Kafka\", currentKafkaVersion, containerImageTag);\n+            } else {\n+                LOGGER.warn(\"Current Kafka Version {} does not supports Cluster operator version {}. So we are gonna upgrade Kafka\", currentKafkaVersion, containerImageTag);\n+\n+                // sort keys and pick 'next version'\n+                SortedSet<String> sortedKeys = new TreeSet<>(mapOfKafkaVersionsWithSupportedClusterOperators.keySet());\n+                Iterator<String> kafkaVersions = sortedKeys.iterator();\n+                String[] newKafkaVersion = new String[1];\n+\n+                while (kafkaVersions.hasNext()) {\n+                    String kafkaVersion = kafkaVersions.next();\n+                    if (kafkaVersion.equals(currentKafkaVersion)) {\n+                        LOGGER.info(\"This is current version {} but we need next one!\", kafkaVersion);\n+                        if (kafkaVersions.hasNext()) {\n+                            newKafkaVersion[0] = kafkaVersions.next();\n+                            LOGGER.info(\"New Kafka version is {} and we are gonna update Kafka custom resource.\", newKafkaVersion[0]);\n+                        }\n+                    }\n+                }\n+\n+                if (newKafkaVersion[0] == null || newKafkaVersion[0].isEmpty()) {\n+                    throw new RuntimeException(\"There is not new Kafka version! Latest is:\" + currentKafkaVersion);\n+                }\n+\n+                Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+                // we are gonna use latest Kafka\n+                if (containerImageTag.equals(\"6.6.6\")) {\n+                    newKafkaVersion[0] = sortedKeys.last();\n+                }\n+\n+                KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+                    //  2.2.1 -> 2.2 (gonna trim from kafka version)\n+                    String logMessageFormatVersion = newKafkaVersion[0].substring(0, 2);\n+                    LOGGER.info(\"We are gonna update Kafka CR with following versions:\\n\" +\n+                        \"Kafka version: {}\\n\" +\n+                        \"Log message format version: {}\", newKafkaVersion[0], logMessageFormatVersion);\n+                    kafka.getSpec().getKafka().getConfig().put(\"log.message.format.version\", logMessageFormatVersion);\n+                    kafka.getSpec().getKafka().setVersion(newKafkaVersion[0]);\n+                });\n+\n+                // wait until RU\n+                StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+            }\n+        }\n+\n+        KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+            .withProducerName(producerName)\n+            .withConsumerName(consumerName)\n+            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+            .withTopicName(topicUpgradeName)\n+            .withMessageCount(messageUpgradeCount)\n+            .withDelayMs(1)\n+            .build();\n+\n+        kafkaBasicClientJob.producerStrimzi().done();\n+        kafkaBasicClientJob.consumerStrimzi().done();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "698529073720d4226b252a59ba23138a3059d48a"}, "originalPosition": 176}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6684600ed1c29257a6f2db772e1130ea2f56f5e8", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6684600ed1c29257a6f2db772e1130ea2f56f5e8", "committedDate": "2020-11-05T10:51:46Z", "message": "[MO] - [OLM] - upgrade suite\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30e2a279a4c4fa04e9103814dbc54d1b0ad58ba7", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/30e2a279a4c4fa04e9103814dbc54d1b0ad58ba7", "committedDate": "2020-11-05T10:51:46Z", "message": "refactor\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d3d520a3bb19d05d337278d6a69a8fb378f7e39", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0d3d520a3bb19d05d337278d6a69a8fb378f7e39", "committedDate": "2020-11-05T10:51:46Z", "message": "better logging of  version\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cbd1e6e928f138a9e64b5cb5b829bfb45be51bd2", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/cbd1e6e928f138a9e64b5cb5b829bfb45be51bd2", "committedDate": "2020-11-05T10:51:46Z", "message": "done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "73d43cd472fde77cf1743ee0db1acd87aeb6d061", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/73d43cd472fde77cf1743ee0db1acd87aeb6d061", "committedDate": "2020-11-05T10:51:46Z", "message": "controlling message-log and  kafka version\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54a0afd6f44b8d455285baa6137d80d3a72028dc", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/54a0afd6f44b8d455285baa6137d80d3a72028dc", "committedDate": "2020-11-05T10:51:46Z", "message": "done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a4326e53ea840ff9c3ab4b19d739febaaebb7bb", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3a4326e53ea840ff9c3ab4b19d739febaaebb7bb", "committedDate": "2020-11-05T10:51:46Z", "message": "parametrized test\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "429d1545079871396e41eef90d83e7324b4d8a2f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/429d1545079871396e41eef90d83e7324b4d8a2f", "committedDate": "2020-11-05T10:51:46Z", "message": "checkstyle\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37313c5a19d4385d8c9be8b6b028d8bb40d01156", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/37313c5a19d4385d8c9be8b6b028d8bb40d01156", "committedDate": "2020-11-05T10:51:46Z", "message": "deletion of install-plan fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e9de68f3d3cb7688962a9170d75b9d574f4d3ce", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2e9de68f3d3cb7688962a9170d75b9d574f4d3ce", "committedDate": "2020-11-05T10:38:47Z", "message": "deletion of install-plan fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}, "afterCommit": {"oid": "37313c5a19d4385d8c9be8b6b028d8bb40d01156", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/37313c5a19d4385d8c9be8b6b028d8bb40d01156", "committedDate": "2020-11-05T10:51:46Z", "message": "deletion of install-plan fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e0bca4072a8ed6cd53a12594d42d9025d5087f2", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6e0bca4072a8ed6cd53a12594d42d9025d5087f2", "committedDate": "2020-11-05T12:25:12Z", "message": "install-plan delay with append fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b35c88d6f070e3bca46b32b47abe4a030a8348a", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2b35c88d6f070e3bca46b32b47abe4a030a8348a", "committedDate": "2020-11-05T13:48:59Z", "message": "redundant first verification\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66d067f946cfc3cb24e508d6f72c77f7f208010c", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/66d067f946cfc3cb24e508d6f72c77f7f208010c", "committedDate": "2020-11-06T08:41:44Z", "message": "last changes;\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87d11e19d2757e8a872d2447536df1e57b27e1e3", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/87d11e19d2757e8a872d2447536df1e57b27e1e3", "committedDate": "2020-11-06T08:48:49Z", "message": "last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4d2a7c04ce6a07bff1fa700a50d71e5b0491661e", "committedDate": "2020-11-06T10:03:44Z", "message": "6.6.6 version covered all  done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1MDE2MTgw", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-525016180", "createdAt": "2020-11-06T10:09:29Z", "commit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83a572b9d82746d5a2488c18cd8b510efa3bd612", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/83a572b9d82746d5a2488c18cd8b510efa3bd612", "committedDate": "2020-11-06T11:26:09Z", "message": "last fix with 6.6.6\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MDY3MDA5", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-527067009", "createdAt": "2020-11-10T10:35:32Z", "commit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMDozNTozMlrOHwWRHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNzoyNzoyNVrOHwneQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ1ODUyNA==", "bodyText": "typo?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520458524", "createdAt": "2020-11-10T10:35:32Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,260 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    public static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, null);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, fromVersion);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, Environment.OLM_OPERATOR_VERSION_PREVIOUS);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (fromVersion != null) {\n+            createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);\n+            // must be strimzi-cluster-operator.0.18.0v", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDczNDM0Nw==", "bodyText": "It's message format or Kafka version? 2.3.1 is not a valid message format AFAIK.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520734347", "createdAt": "2020-11-10T17:18:51Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.params.provider.Arguments;\n+\n+import javax.json.Json;\n+import javax.json.JsonArray;\n+import javax.json.JsonObject;\n+import javax.json.JsonReader;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Stream;\n+\n+public class AbstractUpgradeST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(AbstractUpgradeST.class);\n+\n+    protected static JsonArray readUpgradeJson() {\n+        try (InputStream fis = new FileInputStream(TestUtils.USER_PATH + \"/src/main/resources/StrimziUpgradeST.json\")) {\n+            JsonReader reader = Json.createReader(fis);\n+            return reader.readArray();\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(TestUtils.USER_PATH + \"/src/main/resources/StrimziUpgradeST.json\" + \" file was not found.\");\n+        }\n+    }\n+\n+    /**\n+     * List cluster operator versions which supports specific kafka version. It uses StrimziUpgradeST.json file to parse\n+     * the 'toVersion' and 'proceduresAfter' JsonObjects.\n+     * example:\n+     *      2.6.0->[HEAD]\n+     *      2.3.1->[0.15.0]\n+     *      2.4.0->[0.16.2, 0.17.0]\n+     *      2.5.0->[0.18.0, 0.19.0]\n+     *      2.2.1->[0.12.1]\n+     *      2.3.0->[0.13.0, 0.14.0]\n+     * @return map key -> kafka version | value -> list of cluster operator versions\n+     */\n+    protected static Map<String, List<String>> getMapKafkaVersionsWithSupportedClusterOperatorVersions() {\n+        // message format -> [co versions]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDczNTM1Mg==", "bodyText": "I don't think Kafka supports Cluster Operator", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520735352", "createdAt": "2020-11-10T17:20:12Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.Environment.OLM_LATEST_CONTAINER_IMAGE_TAG;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject parameters) {\n+\n+        int clusterOperatorVersion = Integer.parseInt(fromVersion.split(\"\\\\.\")[1]);\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(clusterOperatorVersion >= 18);\n+\n+        // 5. make snapshots\n+        Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // 6. wait until non-used install plan is present (sometimes install-plan did not append immediately and we need to wait for at least 10m)\n+        OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+\n+        // 7. upgrade cluster operator\n+        OlmResource.upgradeClusterOperator();\n+\n+        // 8. wait until RU is finished (first run skipping)\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+\n+        // 9. verification that cluster operator has correct version (install-plan) - strimzi-cluster-operator.v[version]\n+        String afterUpgradeVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+        // if HEAD -> 6.6.6 version\n+        toVersion = toVersion.equals(\"HEAD\") ? Environment.OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT : toVersion;\n+        assertThat(afterUpgradeVersionOfCo, is(Environment.OLM_APP_BUNDLE_PREFIX + \".v\" + toVersion));\n+\n+        // 10. perform verification of to version\n+        performUpgradeVerification(afterUpgradeVersionOfCo);\n+\n+        // 11. save install-plan to closed-map\n+        OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+    }\n+\n+    private void performUpgradeVerification(String version) {\n+        LOGGER.info(\"====================================================================================\");\n+        LOGGER.info(\"============== Verification version of CO:\" + version);\n+        LOGGER.info(\"====================================================================================\");\n+\n+        // fetch the tag from imageName: docker.io/strimzi/operator:'[latest|0.19.0|0.18.0]'\n+        String containerImageTag = kubeClient().getDeployment(kubeClient().getDeploymentNameByPrefix(Constants.STRIMZI_DEPLOYMENT_NAME))\n+            .getSpec()\n+            .getTemplate()\n+            .getMetadata()\n+            .getAnnotations()\n+            .get(\"containerImage\").split(\":\")[1];\n+\n+        LOGGER.info(\"Image tag of strimzi operator is {}\", containerImageTag);\n+\n+        // NOT (latest image or default substring(1)) for skipping 'v'0.19.0 on the start...\n+        // '6.6.6' is the latest version of cluster operator\n+        if (!containerImageTag.equals(OLM_LATEST_CONTAINER_IMAGE_TAG) && (!(containerImageTag.equals(\"latest\") || containerImageTag.equals(Environment.OLM_OPERATOR_VERSION_DEFAULT.substring(1))))) {\n+            try {\n+                File dir = FileUtils.downloadAndUnzip(\"https://github.com/strimzi/strimzi-kafka-operator/releases/download/\" + containerImageTag + \"/strimzi-\" + containerImageTag + \".zip\");\n+\n+                deployKafkaFromFile(dir, containerImageTag);\n+                waitForReadinessOfKafkaCluster();\n+\n+                KafkaTopicResource.topic(CLUSTER_NAME, topicUpgradeName).done();\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+        //  this is round only last version (so kafka is not present)\n+        } else if (KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get() == null) {\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3).done();\n+        }\n+\n+        KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+            .withProducerName(producerName)\n+            .withConsumerName(consumerName)\n+            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+            .withTopicName(topicUpgradeName)\n+            .withMessageCount(messageUpgradeCount)\n+            .withDelayMs(1)\n+            .build();\n+\n+        kafkaBasicClientJob.producerStrimzi().done();\n+        kafkaBasicClientJob.consumerStrimzi().done();\n+\n+        String currentKafkaVersion = KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get().getSpec().getKafka().getVersion();\n+\n+        LOGGER.info(\"Current Kafka message version is {}\", currentKafkaVersion);\n+\n+        if (mapOfKafkaVersionsWithSupportedClusterOperators.containsKey(currentKafkaVersion)) {\n+            // supported co version for specific kafka version\n+            List<String> supportedClusterOperatorVersion = mapOfKafkaVersionsWithSupportedClusterOperators.get(currentKafkaVersion);\n+\n+            // exist version of cluster operator in list of supported\n+            if (supportedClusterOperatorVersion.contains(containerImageTag)) {\n+                LOGGER.info(\"Current Kafka Version {} supports Cluster operator version {}. So we are not gonna upgrade Kafka\", currentKafkaVersion, containerImageTag);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDczNjYwMA==", "bodyText": "So you actually don't keep clients  attached for whole upgrade, but only for Kafka upgrade. I think you should start clients when the oldest version of CO and kafka is deployed and stop them when all parts of upgrade are done.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520736600", "createdAt": "2020-11-10T17:22:03Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.Environment.OLM_LATEST_CONTAINER_IMAGE_TAG;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject parameters) {\n+\n+        int clusterOperatorVersion = Integer.parseInt(fromVersion.split(\"\\\\.\")[1]);\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(clusterOperatorVersion >= 18);\n+\n+        // 5. make snapshots\n+        Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // 6. wait until non-used install plan is present (sometimes install-plan did not append immediately and we need to wait for at least 10m)\n+        OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+\n+        // 7. upgrade cluster operator\n+        OlmResource.upgradeClusterOperator();\n+\n+        // 8. wait until RU is finished (first run skipping)\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+\n+        // 9. verification that cluster operator has correct version (install-plan) - strimzi-cluster-operator.v[version]\n+        String afterUpgradeVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+        // if HEAD -> 6.6.6 version\n+        toVersion = toVersion.equals(\"HEAD\") ? Environment.OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT : toVersion;\n+        assertThat(afterUpgradeVersionOfCo, is(Environment.OLM_APP_BUNDLE_PREFIX + \".v\" + toVersion));\n+\n+        // 10. perform verification of to version\n+        performUpgradeVerification(afterUpgradeVersionOfCo);\n+\n+        // 11. save install-plan to closed-map\n+        OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+    }\n+\n+    private void performUpgradeVerification(String version) {\n+        LOGGER.info(\"====================================================================================\");\n+        LOGGER.info(\"============== Verification version of CO:\" + version);\n+        LOGGER.info(\"====================================================================================\");\n+\n+        // fetch the tag from imageName: docker.io/strimzi/operator:'[latest|0.19.0|0.18.0]'\n+        String containerImageTag = kubeClient().getDeployment(kubeClient().getDeploymentNameByPrefix(Constants.STRIMZI_DEPLOYMENT_NAME))\n+            .getSpec()\n+            .getTemplate()\n+            .getMetadata()\n+            .getAnnotations()\n+            .get(\"containerImage\").split(\":\")[1];\n+\n+        LOGGER.info(\"Image tag of strimzi operator is {}\", containerImageTag);\n+\n+        // NOT (latest image or default substring(1)) for skipping 'v'0.19.0 on the start...\n+        // '6.6.6' is the latest version of cluster operator\n+        if (!containerImageTag.equals(OLM_LATEST_CONTAINER_IMAGE_TAG) && (!(containerImageTag.equals(\"latest\") || containerImageTag.equals(Environment.OLM_OPERATOR_VERSION_DEFAULT.substring(1))))) {\n+            try {\n+                File dir = FileUtils.downloadAndUnzip(\"https://github.com/strimzi/strimzi-kafka-operator/releases/download/\" + containerImageTag + \"/strimzi-\" + containerImageTag + \".zip\");\n+\n+                deployKafkaFromFile(dir, containerImageTag);\n+                waitForReadinessOfKafkaCluster();\n+\n+                KafkaTopicResource.topic(CLUSTER_NAME, topicUpgradeName).done();\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+        //  this is round only last version (so kafka is not present)\n+        } else if (KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get() == null) {\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3).done();\n+        }\n+\n+        KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+            .withProducerName(producerName)\n+            .withConsumerName(consumerName)\n+            .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+            .withTopicName(topicUpgradeName)\n+            .withMessageCount(messageUpgradeCount)\n+            .withDelayMs(1)\n+            .build();\n+\n+        kafkaBasicClientJob.producerStrimzi().done();\n+        kafkaBasicClientJob.consumerStrimzi().done();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDczODI0OA==", "bodyText": "Wouldn't be better to get Kafka examples from CSV?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520738248", "createdAt": "2020-11-10T17:24:25Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.Environment.OLM_LATEST_CONTAINER_IMAGE_TAG;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  10_000;\n+    private final Map<String, List<String>> mapOfKafkaVersionsWithSupportedClusterOperators = getMapKafkaVersionsWithSupportedClusterOperatorVersions();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject parameters) {\n+\n+        int clusterOperatorVersion = Integer.parseInt(fromVersion.split(\"\\\\.\")[1]);\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(clusterOperatorVersion >= 18);\n+\n+        // 5. make snapshots\n+        Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // 6. wait until non-used install plan is present (sometimes install-plan did not append immediately and we need to wait for at least 10m)\n+        OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+\n+        // 7. upgrade cluster operator\n+        OlmResource.upgradeClusterOperator();\n+\n+        // 8. wait until RU is finished (first run skipping)\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+\n+        // 9. verification that cluster operator has correct version (install-plan) - strimzi-cluster-operator.v[version]\n+        String afterUpgradeVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+        // if HEAD -> 6.6.6 version\n+        toVersion = toVersion.equals(\"HEAD\") ? Environment.OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT : toVersion;\n+        assertThat(afterUpgradeVersionOfCo, is(Environment.OLM_APP_BUNDLE_PREFIX + \".v\" + toVersion));\n+\n+        // 10. perform verification of to version\n+        performUpgradeVerification(afterUpgradeVersionOfCo);\n+\n+        // 11. save install-plan to closed-map\n+        OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+    }\n+\n+    private void performUpgradeVerification(String version) {\n+        LOGGER.info(\"====================================================================================\");\n+        LOGGER.info(\"============== Verification version of CO:\" + version);\n+        LOGGER.info(\"====================================================================================\");\n+\n+        // fetch the tag from imageName: docker.io/strimzi/operator:'[latest|0.19.0|0.18.0]'\n+        String containerImageTag = kubeClient().getDeployment(kubeClient().getDeploymentNameByPrefix(Constants.STRIMZI_DEPLOYMENT_NAME))\n+            .getSpec()\n+            .getTemplate()\n+            .getMetadata()\n+            .getAnnotations()\n+            .get(\"containerImage\").split(\":\")[1];\n+\n+        LOGGER.info(\"Image tag of strimzi operator is {}\", containerImageTag);\n+\n+        // NOT (latest image or default substring(1)) for skipping 'v'0.19.0 on the start...\n+        // '6.6.6' is the latest version of cluster operator\n+        if (!containerImageTag.equals(OLM_LATEST_CONTAINER_IMAGE_TAG) && (!(containerImageTag.equals(\"latest\") || containerImageTag.equals(Environment.OLM_OPERATOR_VERSION_DEFAULT.substring(1))))) {\n+            try {\n+                File dir = FileUtils.downloadAndUnzip(\"https://github.com/strimzi/strimzi-kafka-operator/releases/download/\" + containerImageTag + \"/strimzi-\" + containerImageTag + \".zip\");\n+\n+                deployKafkaFromFile(dir, containerImageTag);\n+                waitForReadinessOfKafkaCluster();\n+\n+                KafkaTopicResource.topic(CLUSTER_NAME, topicUpgradeName).done();\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+        //  this is round only last version (so kafka is not present)\n+        } else if (KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get() == null) {\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3).done();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc0MDQxOA==", "bodyText": "I think this method is a little bit complicated. You are building some map and based on it you are doing upgrade of Kafka and log message format. Why don't you use data from JSON directly?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r520740418", "createdAt": "2020-11-10T17:27:25Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.params.provider.Arguments;\n+\n+import javax.json.Json;\n+import javax.json.JsonArray;\n+import javax.json.JsonObject;\n+import javax.json.JsonReader;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Stream;\n+\n+public class AbstractUpgradeST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(AbstractUpgradeST.class);\n+\n+    protected static JsonArray readUpgradeJson() {\n+        try (InputStream fis = new FileInputStream(TestUtils.USER_PATH + \"/src/main/resources/StrimziUpgradeST.json\")) {\n+            JsonReader reader = Json.createReader(fis);\n+            return reader.readArray();\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(TestUtils.USER_PATH + \"/src/main/resources/StrimziUpgradeST.json\" + \" file was not found.\");\n+        }\n+    }\n+\n+    /**\n+     * List cluster operator versions which supports specific kafka version. It uses StrimziUpgradeST.json file to parse\n+     * the 'toVersion' and 'proceduresAfter' JsonObjects.\n+     * example:\n+     *      2.6.0->[HEAD]\n+     *      2.3.1->[0.15.0]\n+     *      2.4.0->[0.16.2, 0.17.0]\n+     *      2.5.0->[0.18.0, 0.19.0]\n+     *      2.2.1->[0.12.1]\n+     *      2.3.0->[0.13.0, 0.14.0]\n+     * @return map key -> kafka version | value -> list of cluster operator versions\n+     */\n+    protected static Map<String, List<String>> getMapKafkaVersionsWithSupportedClusterOperatorVersions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d2a7c04ce6a07bff1fa700a50d71e5b0491661e"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/416115bb9c6c96692834deb283f84ebca9122a94", "committedDate": "2020-11-11T15:35:04Z", "message": "jakubs commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4MzA3NDgw", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-528307480", "createdAt": "2020-11-11T16:01:29Z", "commit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNjowMToyOVrOHxTdtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNjowNzoyOVrOHxTtWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2MTE3Mw==", "bodyText": "Shouldn't it fail?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521461173", "createdAt": "2020-11-11T16:01:29Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,260 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    public static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, null);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, fromVersion);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, Environment.OLM_OPERATOR_VERSION_PREVIOUS);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (fromVersion != null) {\n+            createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);\n+            // must be strimzi-cluster-operator.v0.18.0\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + fromVersion;\n+        } else {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+            obtainInstallPlanName();\n+            approveNonUsedInstallPlan();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    /**\n+     * Get install plan name and store it to closedMapInstallPlan\n+     */\n+    public static void obtainInstallPlanName() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line NAME  CSV  APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\" \");\n+\n+            // name\n+            if (wholeLine[0].startsWith(\"install-\")) {\n+\n+                // if is not already applied add to closed map\n+                if (!CLOSED_MAP_INSTALL_PLAN.containsKey(wholeLine[0])) {\n+                    LOGGER.info(\"CLOSED_MAP_INSTALL_PLAN does not contain {} install plan so this is not used and will \" +\n+                        \"be in the following upgrade.\", wholeLine[0]);\n+                    CLOSED_MAP_INSTALL_PLAN.put(wholeLine[0], Boolean.FALSE);\n+                }\n+            }\n+        }\n+        if (!(CLOSED_MAP_INSTALL_PLAN.keySet().size() > 0)) {\n+            throw new RuntimeException(\"No install plans located in namespace:\" + cmdKubeClient().namespace());\n+        }\n+    }\n+\n+    /**\n+     * Get specific version of cluster operator with prefix name in format: 'strimzi-cluster-operator.v0.18.0'\n+     * @return version with prefix name\n+     */\n+    public static String getClusterOperatorVersion() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line = NAME   CSV   APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\"   \");\n+\n+            // non-used install plan\n+            if (wholeLine[0].equals(getNonUsedInstallPlan())) {\n+                return wholeLine[1];\n+            }\n+        }\n+        throw new RuntimeException(\"Version was not found in the install plan.\");\n+    }\n+\n+    public static boolean isUpgradeable() {\n+        return !getNonUsedInstallPlan().equals(NO_MORE_NON_USED_INSTALL_PLANS);\n+    }\n+\n+    public static String getNonUsedInstallPlan() {\n+        String[] nonUsedInstallPlan = new String[1];\n+\n+        for (Map.Entry<String, Boolean> entry : CLOSED_MAP_INSTALL_PLAN.entrySet()) {\n+            // if value is FALSE we are gonna use it = non-used install plan\n+            if (!entry.getValue()) {\n+                nonUsedInstallPlan[0] = entry.getKey();\n+                break;\n+            }\n+            nonUsedInstallPlan[0] = NO_MORE_NON_USED_INSTALL_PLANS;\n+        }\n+\n+        LOGGER.info(\"Non-used install plan is {}\", nonUsedInstallPlan[0]);\n+        return nonUsedInstallPlan[0];\n+    }\n+\n+    /**\n+     * Patches specific non used install plan, which will approve installation. Only for manual installation strategy.\n+     * Also updates closedMapInstallPlan map and set specific install plan to true.\n+     */\n+    private static void approveNonUsedInstallPlan() {\n+        String nonUsedInstallPlan = getNonUsedInstallPlan();\n+\n+        try {\n+            LOGGER.info(\"Approving {} install plan\", nonUsedInstallPlan);\n+            String dynamicScriptContent =\n+                \"#!/bin/bash\\n\" +\n+                    cmdKubeClient().cmd() +\n+                    \" patch installplan \" + nonUsedInstallPlan + \" --type json  --patch '[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/spec/approved\\\", \\\"value\\\": true}]'\";\n+\n+            InputStream inputStream = new ByteArrayInputStream(dynamicScriptContent.getBytes(Charset.defaultCharset()));\n+            File patchScript = File.createTempFile(\"installplan_patch\",  \".sh\");\n+            Files.copy(inputStream, patchScript.toPath(), StandardCopyOption.REPLACE_EXISTING);\n+\n+            Exec.exec(\"bash\", patchScript.getAbsolutePath());\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2MTUzMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).get(0) == null) {\n          \n          \n            \n                    if (kubeClient().listPodsByPrefixInName(ResourceManager.getDeploymentName()).get(0) == null) {", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521461532", "createdAt": "2020-11-11T16:02:00Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,260 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    public static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, null);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, fromVersion);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, Environment.OLM_OPERATOR_VERSION_PREVIOUS);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (fromVersion != null) {\n+            createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);\n+            // must be strimzi-cluster-operator.v0.18.0\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + fromVersion;\n+        } else {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+            obtainInstallPlanName();\n+            approveNonUsedInstallPlan();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    /**\n+     * Get install plan name and store it to closedMapInstallPlan\n+     */\n+    public static void obtainInstallPlanName() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line NAME  CSV  APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\" \");\n+\n+            // name\n+            if (wholeLine[0].startsWith(\"install-\")) {\n+\n+                // if is not already applied add to closed map\n+                if (!CLOSED_MAP_INSTALL_PLAN.containsKey(wholeLine[0])) {\n+                    LOGGER.info(\"CLOSED_MAP_INSTALL_PLAN does not contain {} install plan so this is not used and will \" +\n+                        \"be in the following upgrade.\", wholeLine[0]);\n+                    CLOSED_MAP_INSTALL_PLAN.put(wholeLine[0], Boolean.FALSE);\n+                }\n+            }\n+        }\n+        if (!(CLOSED_MAP_INSTALL_PLAN.keySet().size() > 0)) {\n+            throw new RuntimeException(\"No install plans located in namespace:\" + cmdKubeClient().namespace());\n+        }\n+    }\n+\n+    /**\n+     * Get specific version of cluster operator with prefix name in format: 'strimzi-cluster-operator.v0.18.0'\n+     * @return version with prefix name\n+     */\n+    public static String getClusterOperatorVersion() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line = NAME   CSV   APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\"   \");\n+\n+            // non-used install plan\n+            if (wholeLine[0].equals(getNonUsedInstallPlan())) {\n+                return wholeLine[1];\n+            }\n+        }\n+        throw new RuntimeException(\"Version was not found in the install plan.\");\n+    }\n+\n+    public static boolean isUpgradeable() {\n+        return !getNonUsedInstallPlan().equals(NO_MORE_NON_USED_INSTALL_PLANS);\n+    }\n+\n+    public static String getNonUsedInstallPlan() {\n+        String[] nonUsedInstallPlan = new String[1];\n+\n+        for (Map.Entry<String, Boolean> entry : CLOSED_MAP_INSTALL_PLAN.entrySet()) {\n+            // if value is FALSE we are gonna use it = non-used install plan\n+            if (!entry.getValue()) {\n+                nonUsedInstallPlan[0] = entry.getKey();\n+                break;\n+            }\n+            nonUsedInstallPlan[0] = NO_MORE_NON_USED_INSTALL_PLANS;\n+        }\n+\n+        LOGGER.info(\"Non-used install plan is {}\", nonUsedInstallPlan[0]);\n+        return nonUsedInstallPlan[0];\n+    }\n+\n+    /**\n+     * Patches specific non used install plan, which will approve installation. Only for manual installation strategy.\n+     * Also updates closedMapInstallPlan map and set specific install plan to true.\n+     */\n+    private static void approveNonUsedInstallPlan() {\n+        String nonUsedInstallPlan = getNonUsedInstallPlan();\n+\n+        try {\n+            LOGGER.info(\"Approving {} install plan\", nonUsedInstallPlan);\n+            String dynamicScriptContent =\n+                \"#!/bin/bash\\n\" +\n+                    cmdKubeClient().cmd() +\n+                    \" patch installplan \" + nonUsedInstallPlan + \" --type json  --patch '[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/spec/approved\\\", \\\"value\\\": true}]'\";\n+\n+            InputStream inputStream = new ByteArrayInputStream(dynamicScriptContent.getBytes(Charset.defaultCharset()));\n+            File patchScript = File.createTempFile(\"installplan_patch\",  \".sh\");\n+            Files.copy(inputStream, patchScript.toPath(), StandardCopyOption.REPLACE_EXISTING);\n+\n+            Exec.exec(\"bash\", patchScript.getAbsolutePath());\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    /**\n+     * Upgrade cluster operator by obtaining new install plan, which was not used and also approves installation by\n+     * changing the install plan YAML\n+     */\n+    public static void upgradeClusterOperator() {\n+        if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).get(0) == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 214}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2MjEzNA==", "bodyText": "Why it's int try/catch block?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521462134", "createdAt": "2020-11-11T16:02:58Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,260 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    public static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, null);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, fromVersion);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, Environment.OLM_OPERATOR_VERSION_PREVIOUS);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (fromVersion != null) {\n+            createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);\n+            // must be strimzi-cluster-operator.v0.18.0\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + fromVersion;\n+        } else {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+            obtainInstallPlanName();\n+            approveNonUsedInstallPlan();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    /**\n+     * Get install plan name and store it to closedMapInstallPlan\n+     */\n+    public static void obtainInstallPlanName() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line NAME  CSV  APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\" \");\n+\n+            // name\n+            if (wholeLine[0].startsWith(\"install-\")) {\n+\n+                // if is not already applied add to closed map\n+                if (!CLOSED_MAP_INSTALL_PLAN.containsKey(wholeLine[0])) {\n+                    LOGGER.info(\"CLOSED_MAP_INSTALL_PLAN does not contain {} install plan so this is not used and will \" +\n+                        \"be in the following upgrade.\", wholeLine[0]);\n+                    CLOSED_MAP_INSTALL_PLAN.put(wholeLine[0], Boolean.FALSE);\n+                }\n+            }\n+        }\n+        if (!(CLOSED_MAP_INSTALL_PLAN.keySet().size() > 0)) {\n+            throw new RuntimeException(\"No install plans located in namespace:\" + cmdKubeClient().namespace());\n+        }\n+    }\n+\n+    /**\n+     * Get specific version of cluster operator with prefix name in format: 'strimzi-cluster-operator.v0.18.0'\n+     * @return version with prefix name\n+     */\n+    public static String getClusterOperatorVersion() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line = NAME   CSV   APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\"   \");\n+\n+            // non-used install plan\n+            if (wholeLine[0].equals(getNonUsedInstallPlan())) {\n+                return wholeLine[1];\n+            }\n+        }\n+        throw new RuntimeException(\"Version was not found in the install plan.\");\n+    }\n+\n+    public static boolean isUpgradeable() {\n+        return !getNonUsedInstallPlan().equals(NO_MORE_NON_USED_INSTALL_PLANS);\n+    }\n+\n+    public static String getNonUsedInstallPlan() {\n+        String[] nonUsedInstallPlan = new String[1];\n+\n+        for (Map.Entry<String, Boolean> entry : CLOSED_MAP_INSTALL_PLAN.entrySet()) {\n+            // if value is FALSE we are gonna use it = non-used install plan\n+            if (!entry.getValue()) {\n+                nonUsedInstallPlan[0] = entry.getKey();\n+                break;\n+            }\n+            nonUsedInstallPlan[0] = NO_MORE_NON_USED_INSTALL_PLANS;\n+        }\n+\n+        LOGGER.info(\"Non-used install plan is {}\", nonUsedInstallPlan[0]);\n+        return nonUsedInstallPlan[0];\n+    }\n+\n+    /**\n+     * Patches specific non used install plan, which will approve installation. Only for manual installation strategy.\n+     * Also updates closedMapInstallPlan map and set specific install plan to true.\n+     */\n+    private static void approveNonUsedInstallPlan() {\n+        String nonUsedInstallPlan = getNonUsedInstallPlan();\n+\n+        try {\n+            LOGGER.info(\"Approving {} install plan\", nonUsedInstallPlan);\n+            String dynamicScriptContent =\n+                \"#!/bin/bash\\n\" +\n+                    cmdKubeClient().cmd() +\n+                    \" patch installplan \" + nonUsedInstallPlan + \" --type json  --patch '[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/spec/approved\\\", \\\"value\\\": true}]'\";\n+\n+            InputStream inputStream = new ByteArrayInputStream(dynamicScriptContent.getBytes(Charset.defaultCharset()));\n+            File patchScript = File.createTempFile(\"installplan_patch\",  \".sh\");\n+            Files.copy(inputStream, patchScript.toPath(), StandardCopyOption.REPLACE_EXISTING);\n+\n+            Exec.exec(\"bash\", patchScript.getAbsolutePath());\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    /**\n+     * Upgrade cluster operator by obtaining new install plan, which was not used and also approves installation by\n+     * changing the install plan YAML\n+     */\n+    public static void upgradeClusterOperator() {\n+        if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).get(0) == null) {\n+            throw new RuntimeException(\"We can not perform upgrade! Cluster operator pod is not present.\");\n+        }\n+\n+        obtainInstallPlanName();\n+        approveNonUsedInstallPlan();\n+    }\n+\n+    /**\n+     * Creates OperatorGroup from `olm/operator-group.yaml` and modify \"${OPERATOR_NAMESPACE}\" attribute in YAML\n+     * @param namespace namespace where you want to apply OperatorGroup  kind\n+     */\n+    private static void createOperatorGroup(String namespace) {\n+        try {\n+            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n+            String operatorGroup = TestUtils.readResource(groupInputStream);\n+            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n+            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2MjI1Nw==", "bodyText": "Same as above", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521462257", "createdAt": "2020-11-11T16:03:11Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java", "diffHunk": "@@ -6,71 +6,260 @@\n \n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n import io.strimzi.test.TestUtils;\n+import io.strimzi.test.executor.Exec;\n import io.strimzi.test.k8s.KubeClusterResource;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n+import java.io.ByteArrayInputStream;\n import java.io.File;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.Charset;\n+import java.nio.file.Files;\n+import java.nio.file.StandardCopyOption;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.stream.Collectors;\n \n import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n \n public class OlmResource {\n     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);\n \n+    public static final String NO_MORE_NON_USED_INSTALL_PLANS = \"NoMoreNonUsedInstallPlans\";\n+\n+    // only three versions\n+    private static final Map<String, Boolean> CLOSED_MAP_INSTALL_PLAN = new HashMap<>(3);\n+\n     private static Map<String, JsonObject> exampleResources = new HashMap<>();\n \n-    public static void clusterOperator(String namespace) throws Exception {\n-        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);\n+    public static void clusterOperator(String namespace) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL, OlmInstallationStrategy.Automatic, null);\n     }\n \n-    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) throws IOException {\n+    public static void clusterOperator(String namespace, OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+        clusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL,\n+            olmInstallationStrategy, fromVersion);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {\n+        clusterOperator(namespace, operationTimeout, reconciliationInterval, OlmInstallationStrategy.Automatic, Environment.OLM_OPERATOR_VERSION_PREVIOUS);\n+    }\n+\n+    public static void clusterOperator(String namespace, long operationTimeout, long reconciliationInterval,\n+                                       OlmInstallationStrategy olmInstallationStrategy, String fromVersion) {\n+\n+        // if on cluster is not defaultOlmNamespace apply 'operator group' in current namespace\n         if (!KubeClusterResource.getInstance().getDefaultOlmNamespace().equals(namespace)) {\n-            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            createOperatorGroup(namespace);\n+        }\n \n-            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n-            String operatorGroup = TestUtils.readResource(groupInputStream);\n-            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n-            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        String csvName;\n+\n+        if (fromVersion != null) {\n+            createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);\n+            // must be strimzi-cluster-operator.v0.18.0\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + fromVersion;\n+        } else {\n+            createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);\n+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;\n         }\n \n-        String csvName = Environment.OLM_APP_BUNDLE_PREFIX + \".\" + Environment.OLM_OPERATOR_VERSION;\n+        // manual installation needs approval with patch\n+        if (olmInstallationStrategy == OlmInstallationStrategy.Manual) {\n+            OlmUtils.waitUntilNonUsedInstallPlanIsPresent(fromVersion);\n+            obtainInstallPlanName();\n+            approveNonUsedInstallPlan();\n+        }\n \n-        File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n-        InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n-        String subscription = TestUtils.readResource(subscriptionInputStream);\n-        TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n-                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n-                .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n-                .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n-                .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n-                .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n-                .replace(\"${OLM_OPERATOR_VERSION}\", Environment.OLM_OPERATOR_VERSION)\n-                .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n-                .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n-\n-        ResourceManager.cmdKubeClient().apply(subscriptionFile);\n         // Make sure that operator will be deleted\n         TestUtils.waitFor(\"Cluster Operator deployment creation\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME) != null);\n+\n         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n         ResourceManager.setCoDeploymentName(deploymentName);\n+\n+\n         ResourceManager.getPointerResources().push(() -> deleteOlm(deploymentName, namespace, csvName));\n         // Wait for operator creation\n         waitFor(deploymentName, namespace, 1);\n \n         exampleResources = parseExamplesFromCsv(csvName, namespace);\n     }\n \n+    /**\n+     * Get install plan name and store it to closedMapInstallPlan\n+     */\n+    public static void obtainInstallPlanName() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line NAME  CSV  APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\" \");\n+\n+            // name\n+            if (wholeLine[0].startsWith(\"install-\")) {\n+\n+                // if is not already applied add to closed map\n+                if (!CLOSED_MAP_INSTALL_PLAN.containsKey(wholeLine[0])) {\n+                    LOGGER.info(\"CLOSED_MAP_INSTALL_PLAN does not contain {} install plan so this is not used and will \" +\n+                        \"be in the following upgrade.\", wholeLine[0]);\n+                    CLOSED_MAP_INSTALL_PLAN.put(wholeLine[0], Boolean.FALSE);\n+                }\n+            }\n+        }\n+        if (!(CLOSED_MAP_INSTALL_PLAN.keySet().size() > 0)) {\n+            throw new RuntimeException(\"No install plans located in namespace:\" + cmdKubeClient().namespace());\n+        }\n+    }\n+\n+    /**\n+     * Get specific version of cluster operator with prefix name in format: 'strimzi-cluster-operator.v0.18.0'\n+     * @return version with prefix name\n+     */\n+    public static String getClusterOperatorVersion() {\n+        String installPlansPureString = cmdKubeClient().exec(\"get\", \"installplan\").out();\n+        String[] installPlansLines = installPlansPureString.split(\"\\n\");\n+\n+        for (String line : installPlansLines) {\n+            // line = NAME   CSV   APPROVAL   APPROVED\n+            String[] wholeLine = line.split(\"   \");\n+\n+            // non-used install plan\n+            if (wholeLine[0].equals(getNonUsedInstallPlan())) {\n+                return wholeLine[1];\n+            }\n+        }\n+        throw new RuntimeException(\"Version was not found in the install plan.\");\n+    }\n+\n+    public static boolean isUpgradeable() {\n+        return !getNonUsedInstallPlan().equals(NO_MORE_NON_USED_INSTALL_PLANS);\n+    }\n+\n+    public static String getNonUsedInstallPlan() {\n+        String[] nonUsedInstallPlan = new String[1];\n+\n+        for (Map.Entry<String, Boolean> entry : CLOSED_MAP_INSTALL_PLAN.entrySet()) {\n+            // if value is FALSE we are gonna use it = non-used install plan\n+            if (!entry.getValue()) {\n+                nonUsedInstallPlan[0] = entry.getKey();\n+                break;\n+            }\n+            nonUsedInstallPlan[0] = NO_MORE_NON_USED_INSTALL_PLANS;\n+        }\n+\n+        LOGGER.info(\"Non-used install plan is {}\", nonUsedInstallPlan[0]);\n+        return nonUsedInstallPlan[0];\n+    }\n+\n+    /**\n+     * Patches specific non used install plan, which will approve installation. Only for manual installation strategy.\n+     * Also updates closedMapInstallPlan map and set specific install plan to true.\n+     */\n+    private static void approveNonUsedInstallPlan() {\n+        String nonUsedInstallPlan = getNonUsedInstallPlan();\n+\n+        try {\n+            LOGGER.info(\"Approving {} install plan\", nonUsedInstallPlan);\n+            String dynamicScriptContent =\n+                \"#!/bin/bash\\n\" +\n+                    cmdKubeClient().cmd() +\n+                    \" patch installplan \" + nonUsedInstallPlan + \" --type json  --patch '[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/spec/approved\\\", \\\"value\\\": true}]'\";\n+\n+            InputStream inputStream = new ByteArrayInputStream(dynamicScriptContent.getBytes(Charset.defaultCharset()));\n+            File patchScript = File.createTempFile(\"installplan_patch\",  \".sh\");\n+            Files.copy(inputStream, patchScript.toPath(), StandardCopyOption.REPLACE_EXISTING);\n+\n+            Exec.exec(\"bash\", patchScript.getAbsolutePath());\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    /**\n+     * Upgrade cluster operator by obtaining new install plan, which was not used and also approves installation by\n+     * changing the install plan YAML\n+     */\n+    public static void upgradeClusterOperator() {\n+        if (kubeClient().listPodsByPrefixInName(Constants.CO_POD_PREFIX_NAME).get(0) == null) {\n+            throw new RuntimeException(\"We can not perform upgrade! Cluster operator pod is not present.\");\n+        }\n+\n+        obtainInstallPlanName();\n+        approveNonUsedInstallPlan();\n+    }\n+\n+    /**\n+     * Creates OperatorGroup from `olm/operator-group.yaml` and modify \"${OPERATOR_NAMESPACE}\" attribute in YAML\n+     * @param namespace namespace where you want to apply OperatorGroup  kind\n+     */\n+    private static void createOperatorGroup(String namespace) {\n+        try {\n+            File operatorGroupFile = File.createTempFile(\"operatorgroup\", \".yaml\");\n+            InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/operator-group.yaml\");\n+            String operatorGroup = TestUtils.readResource(groupInputStream);\n+            TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace(\"${OPERATOR_NAMESPACE}\", namespace));\n+            ResourceManager.cmdKubeClient().apply(operatorGroupFile);\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    /**\n+     * Creates Subscription from \"olm/subscription.yaml\" and modify \"${OPERATOR_NAMESPACE}\", \"${OLM_OPERATOR_NAME}...\n+     * attributes.\n+     * @param namespace namespace where you want to apply Subscription kind\n+     * @param reconciliationInterval reconciliation interval of cluster operator\n+     * @param operationTimeout operation timeout  of cluster operator\n+     * @param installationStrategy type of installation\n+     */\n+    private static void createAndModifySubscription(String namespace, long reconciliationInterval, long operationTimeout,\n+                                                    OlmInstallationStrategy installationStrategy, String version) {\n+        try {\n+            File subscriptionFile = File.createTempFile(\"subscription\", \".yaml\");\n+            InputStream subscriptionInputStream = OlmResource.class.getClassLoader().getResourceAsStream(\"olm/subscription.yaml\");\n+            String subscription = TestUtils.readResource(subscriptionInputStream);\n+            TestUtils.writeFile(subscriptionFile.getAbsolutePath(),\n+                subscription.replace(\"${OPERATOR_NAMESPACE}\", namespace)\n+                    .replace(\"${OLM_OPERATOR_NAME}\", Environment.OLM_OPERATOR_NAME)\n+                    .replace(\"${OLM_SOURCE_NAME}\", Environment.OLM_SOURCE_NAME)\n+                    .replace(\"${OLM_SOURCE_NAMESPACE}\", ResourceManager.cmdKubeClient().defaultOlmNamespace())\n+                    .replace(\"${OLM_APP_BUNDLE_PREFIX}\", Environment.OLM_APP_BUNDLE_PREFIX)\n+                    .replace(\"${OLM_OPERATOR_VERSION}\", version)\n+                    .replace(\"${OLM_INSTALL_PLAN_APPROVAL}\", installationStrategy.toString())\n+                    .replace(\"${STRIMZI_FULL_RECONCILIATION_INTERVAL_MS}\", Long.toString(reconciliationInterval))\n+                    .replace(\"${STRIMZI_OPERATION_TIMEOUT_MS}\", Long.toString(operationTimeout)));\n+\n+            ResourceManager.cmdKubeClient().apply(subscriptionFile);\n+        }  catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2MzMyOQ==", "bodyText": "What about Strimzi 1.0.0 ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521463329", "createdAt": "2020-11-11T16:04:47Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import io.strimzi.test.k8s.KubeClusterResource;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  50_000; // 10k ~= 23s, 50k ~= 115s\n+    private final KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+        .withProducerName(producerName)\n+        .withConsumerName(consumerName)\n+        .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+        .withTopicName(topicUpgradeName)\n+        .withMessageCount(messageUpgradeCount)\n+        .withDelayMs(1)\n+        .build();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject testParameters) {\n+\n+        int clusterOperatorVersion = Integer.parseInt(fromVersion.split(\"\\\\.\")[1]);\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(clusterOperatorVersion >= 18);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NTE3OA==", "bodyText": "Wonder if adding some metadata to environment in ugprade json wouldn't be better solution", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521465178", "createdAt": "2020-11-11T16:07:29Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import io.strimzi.test.k8s.KubeClusterResource;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  50_000; // 10k ~= 23s, 50k ~= 115s\n+    private final KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+        .withProducerName(producerName)\n+        .withConsumerName(consumerName)\n+        .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+        .withTopicName(topicUpgradeName)\n+        .withMessageCount(messageUpgradeCount)\n+        .withDelayMs(1)\n+        .build();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject testParameters) {\n+\n+        int clusterOperatorVersion = Integer.parseInt(fromVersion.split(\"\\\\.\")[1]);\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(clusterOperatorVersion >= 18);\n+\n+        // perform verification of to version\n+        performUpgradeVerification(fromVersion, toVersion, testParameters);\n+    }\n+\n+    private void performUpgradeVerification(String fromVersion, String toVersion, JsonObject testParameters) {\n+        LOGGER.info(\"====================================================================================\");\n+        LOGGER.info(\"============== Verification version of CO:\" + fromVersion + \" => \" + toVersion);\n+        LOGGER.info(\"====================================================================================\");\n+\n+        kafkaBasicClientJob.producerStrimzi().done();\n+        kafkaBasicClientJob.consumerStrimzi().done();\n+\n+        // ======== Cluster Operator upgrade starts ========\n+        Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // wait until non-used install plan is present (sometimes install-plan did not append immediately and we need to wait for at least 10m)\n+        OlmUtils.waitUntilNonUsedInstallPlanIsPresent(toVersion);\n+\n+        // Cluster Operator\n+        OlmResource.upgradeClusterOperator();\n+\n+        // wait until RU is finished (first run skipping)\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+        // ======== Cluster Operator upgrade ends ========\n+\n+        // verification that cluster operator has correct version (install-plan) - strimzi-cluster-operator.v[version]\n+        String afterUpgradeVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+        // if HEAD -> 6.6.6 version\n+        toVersion = toVersion.equals(\"HEAD\") ? Environment.OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT : toVersion;\n+        assertThat(afterUpgradeVersionOfCo, is(Environment.OLM_APP_BUNDLE_PREFIX + \".v\" + toVersion));\n+\n+        // ======== Kafka upgrade starts ========\n+        // Make snapshots of all pods\n+        makeSnapshots();\n+        logPodImages();\n+        changeKafkaAndLogFormatVersion(testParameters.getJsonObject(\"proceduresAfter\"));\n+        logPodImages();\n+        // ======== Kafka upgrade ends ========\n+\n+        ClientUtils.waitForClientSuccess(producerName, namespace, messageUpgradeCount);\n+        ClientUtils.waitForClientSuccess(consumerName, namespace, messageUpgradeCount);\n+\n+        // Delete jobs to make same names available for next upgrade\n+        kubeClient().deleteJob(producerName);\n+        kubeClient().deleteJob(consumerName);\n+\n+        // Check errors in CO log\n+        assertNoCoErrorsLogged(0);\n+\n+        // Save install-plan to closed-map\n+        OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+    }\n+\n+    /**\n+     * Loads auxiliary information from StrimziUpgradeST.json\n+     * [0] -> from version\n+     * [1] -> to version\n+     * [2] -> whole JsonObject for first supported version\n+     * @param indexOfItem specific index which you want to access\n+     * @return exception || first supported version || json object with upgrade information\n+     */\n+    private Object getFirstSupportedItemFromUpgradeJson(int indexOfItem) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "416115bb9c6c96692834deb283f84ebca9122a94"}, "originalPosition": 129}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d47aec28f7fc507b19c100c5f65c9ef66b08800f", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d47aec28f7fc507b19c100c5f65c9ef66b08800f", "committedDate": "2020-11-11T16:33:44Z", "message": "last commends? :D\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cefebd4b9c2332ffd075b8f5ccf427871ac4d0b", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5cefebd4b9c2332ffd075b8f5ccf427871ac4d0b", "committedDate": "2020-11-11T16:42:56Z", "message": "last last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a151b2e47fcf9d687a4a5ba0586fe7d46923efcb", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a151b2e47fcf9d687a4a5ba0586fe7d46923efcb", "committedDate": "2020-11-11T18:18:30Z", "message": "versions\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NDI4Njg2", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-528428686", "createdAt": "2020-11-11T18:25:23Z", "commit": {"oid": "a151b2e47fcf9d687a4a5ba0586fe7d46923efcb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxODoyNToyNFrOHxZMFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxODoyNToyNFrOHxZMFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU1NDk2Ng==", "bodyText": "It's not used", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521554966", "createdAt": "2020-11-11T18:25:24Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "diffHunk": "@@ -62,6 +65,7 @@\n \n     String KAFKA_CLIENTS = \"kafka-clients\";\n     String STRIMZI_DEPLOYMENT_NAME = \"strimzi-cluster-operator\";\n+    String CO_POD_PREFIX_NAME = \"strimzi-cluster-operator-\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a151b2e47fcf9d687a4a5ba0586fe7d46923efcb"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed7b231e91c71e9551792a8b5132af1ee58a2655", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ed7b231e91c71e9551792a8b5132af1ee58a2655", "committedDate": "2020-11-11T19:19:17Z", "message": "all in perfom\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4713ff8c20594986e587c9cf7ef94142ef7e22d", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e4713ff8c20594986e587c9cf7ef94142ef7e22d", "committedDate": "2020-11-11T19:20:29Z", "message": "s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4NDc1NTkx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#pullrequestreview-528475591", "createdAt": "2020-11-11T19:34:14Z", "commit": {"oid": "e4713ff8c20594986e587c9cf7ef94142ef7e22d"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxOTozNDoxNFrOHxbbHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxOTozNDoxNFrOHxbbHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU5MTU4Mw==", "bodyText": "I think you should use Env var for OLM version instead of the hardcoded random version which we use in our automation.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3854#discussion_r521591583", "createdAt": "2020-11-11T19:34:14Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.enums.OlmInstallationStrategy;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;\n+import io.strimzi.systemtest.resources.operator.OlmResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.FileUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.specific.OlmUtils;\n+import io.strimzi.test.k8s.KubeClusterResource;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import javax.json.JsonObject;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static io.strimzi.systemtest.Constants.OLM_UPGRADE;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assumptions.assumeTrue;\n+\n+@Tag(OLM_UPGRADE)\n+public class OlmUpgradeST extends AbstractUpgradeST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);\n+\n+    private final String namespace = \"olm-upgrade-namespace\";\n+    private final String producerName = \"producer\";\n+    private final String consumerName = \"consumer\";\n+    private final String topicUpgradeName = \"topic-upgrade\";\n+    private final int messageUpgradeCount =  50_000; // 10k ~= 23s, 50k ~= 115s\n+    private final KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()\n+        .withProducerName(producerName)\n+        .withConsumerName(consumerName)\n+        .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+        .withTopicName(topicUpgradeName)\n+        .withMessageCount(messageUpgradeCount)\n+        .withDelayMs(1)\n+        .build();\n+\n+    @ParameterizedTest(name = \"testUpgradeStrimziVersion-{0}-{1}\")\n+    @MethodSource(\"loadJsonUpgradeData\")\n+    void testChainUpgrade(String fromVersion, String toVersion, JsonObject testParameters) throws IOException {\n+\n+        // only 0.|18|.0 and more is supported\n+        assumeTrue(testParameters.getBoolean(\"olmUpgrade\"));\n+\n+        // perform verification of to version\n+        performUpgradeVerification(fromVersion, toVersion, testParameters);\n+    }\n+\n+    private void performUpgradeVerification(String fromVersion, String toVersion, JsonObject testParameters) throws IOException {\n+        LOGGER.info(\"====================================================================================\");\n+        LOGGER.info(\"============== Verification version of CO:\" + fromVersion + \" => \" + toVersion);\n+        LOGGER.info(\"====================================================================================\");\n+\n+        // In chainUpgrade we want to setup CO only at the start\n+        if (kubeClient().listPodsByPrefixInName(ResourceManager.getCoDeploymentName()).size() == 0) {\n+\n+            // we need to push CO class stack because of subscription (if CO is in method stack after upgrade subscription will be deleted)\n+            ResourceManager.setClassResources();\n+\n+            // 1. Create subscription (+ operator group) with manual approval strategy\n+            // 2. Approve installation\n+            //   a) get name of install-plan\n+            //   b) approve installation\n+            // strimzi-cluster-operator-v0.19.0 <-- need concatenate version with starting 'v' before version\n+            OlmResource.clusterOperator(namespace, OlmInstallationStrategy.Manual, \"v\" + getFirstSupportedItemFromUpgradeJson().getString(\"fromVersion\"));\n+        }\n+\n+        // In chainUpgrade we want to setup Kafka only at the start and then upgrade it via CO\n+        if (KafkaResource.kafkaClient().inNamespace(namespace).withName(CLUSTER_NAME).get() == null) {\n+            JsonObject firstSupportedItemFromUpgradeJsonArray = getFirstSupportedItemFromUpgradeJson();\n+            String url = firstSupportedItemFromUpgradeJsonArray.getString(\"urlFrom\");\n+            File dir = FileUtils.downloadAndUnzip(url);\n+\n+            // In chainUpgrade we want to setup Kafka only at the begging and then upgrade it via CO\n+            kafkaYaml = new File(dir, firstSupportedItemFromUpgradeJsonArray.getString(\"fromExamples\") + \"/examples/kafka/kafka-persistent.yaml\");\n+            LOGGER.info(\"Going to deploy Kafka from: {}\", kafkaYaml.getPath());\n+            KubeClusterResource.cmdKubeClient().create(kafkaYaml);\n+            // Wait for readiness\n+            waitForReadinessOfKafkaCluster();\n+\n+            OlmResource.getClosedMapInstallPlan().put(OlmResource.getNonUsedInstallPlan(), Boolean.TRUE);\n+\n+            ResourceManager.setMethodResources();\n+        }\n+\n+        kafkaBasicClientJob.producerStrimzi().done();\n+        kafkaBasicClientJob.consumerStrimzi().done();\n+\n+        String clusterOperatorDeploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n+        LOGGER.info(\"Old deployment name of cluster operator is {}\", clusterOperatorDeploymentName);\n+\n+        // ======== Cluster Operator upgrade starts ========\n+        Map<String, String> kafkaSnapshot = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // wait until non-used install plan is present (sometimes install-plan did not append immediately and we need to wait for at least 10m)\n+        OlmUtils.waitUntilNonUsedInstallPlanIsPresent(toVersion);\n+\n+        // Cluster Operator\n+        OlmResource.upgradeClusterOperator();\n+\n+        // wait until RU is finished (first run skipping)\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);\n+        // ======== Cluster Operator upgrade ends ========\n+\n+        clusterOperatorDeploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);\n+        LOGGER.info(\"New deployment name of cluster operator is {}\", clusterOperatorDeploymentName);\n+        ResourceManager.setCoDeploymentName(clusterOperatorDeploymentName);\n+\n+        // verification that cluster operator has correct version (install-plan) - strimzi-cluster-operator.v[version]\n+        String afterUpgradeVersionOfCo = OlmResource.getClusterOperatorVersion();\n+\n+        // if HEAD -> 6.6.6 version\n+        toVersion = toVersion.equals(\"HEAD\") ? \"6.6.6\" : toVersion;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4713ff8c20594986e587c9cf7ef94142ef7e22d"}, "originalPosition": 136}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83d476a47c4ec51963de45ea88f9c4b2199e173a", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/83d476a47c4ec51963de45ea88f9c4b2199e173a", "committedDate": "2020-11-12T07:49:35Z", "message": "env for olm latest tag\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b5fb288376ce84f0d4bc6d22dce3ab3806395a9", "author": {"user": {"login": "see-quick", "name": "Ors\u00e1k Maro\u0161"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2b5fb288376ce84f0d4bc6d22dce3ab3806395a9", "committedDate": "2020-11-13T15:17:31Z", "message": "evn var\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 841, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}