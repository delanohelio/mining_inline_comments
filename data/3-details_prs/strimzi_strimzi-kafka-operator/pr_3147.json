{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI3MzQyNjg0", "number": 3147, "title": "[DOC] New procedure for config of external clients in deployment guide", "bodyText": "Signed-off-by: prmellor pmellor@redhat.com\nDocumentation\nSetting up external clients\nNew procedure shows the config of Kafka and KafkaUser resource to set up a connection from an external client.\nThe procedure will be presented in the Deployment Guide as part of the chapter to verify a deployment.\nThe procedure aims to show the steps required and the options available. The procedure is generic, applying to all external listener types, with notes for specific listeners where necessary.\nThe example 'Kafka' configuration is not type specific.\nChecklist\nPlease go through this checklist and make sure all applicable tasks have been done\n\n Update/write design documentation in ./design\n Write tests\n Make sure all tests pass\n Update documentation\n Check RBAC rights for Kubernetes / OpenShift roles\n Try your changes from Pod inside your Kubernetes and OpenShift cluster, not just locally\n Reference relevant issue(s) and close them after merging\n Update CHANGELOG.md", "createdAt": "2020-06-03T17:13:40Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147", "merged": true, "mergeCommit": {"oid": "b68c87a04d6da324db480182100d9749b2f2feae"}, "closed": true, "closedAt": "2020-07-06T14:14:40Z", "author": {"login": "PaulRMellor"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcnsmFagH2gAyNDI3MzQyNjg0OmExOWFkYjM2M2RlYTY1ZTk4NjhjN2JkMmM2NGYzNGFhZTBmYWYzMDk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcyNULVAFqTQ0Mjg5MTAxOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a19adb363dea65e9868c7bd2c64f34aae0faf309", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a19adb363dea65e9868c7bd2c64f34aae0faf309", "committedDate": "2020-06-03T17:06:33Z", "message": "[DOC] New procedure to show config of external clients in deployment guide\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a77951f707ac66ca4c41b1af4ac92e49c59bb715", "committedDate": "2020-06-03T17:20:20Z", "message": "Merge branch 'master' into doc-setting-up-external-clients"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzNzkxNzk0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-423791794", "createdAt": "2020-06-03T17:48:43Z", "commit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNzo0ODo0M1rOGem4Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxODoxNToxOFrOGen0Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0NzQyNg==", "bodyText": "I would leave this out. This is confusing for users since it is not clear which port it is and where. It might not be the port which the users will use at the end.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434747426", "createdAt": "2020-06-03T17:48:43Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0ODA1OA==", "bodyText": "This seems a bit unnecedssary for me. Can't we just call the section Setting up access for clients outside of Kubernetes?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434748058", "createdAt": "2020-06-03T17:49:44Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0ODg2MQ==", "bodyText": "I would definitely leave out the security.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The type chosen depends on your requirements and approach to security.\n          \n          \n            \n            The type chosen depends on your requirements and environment / infrastructure.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434748861", "createdAt": "2020-06-03T17:51:00Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements and approach to security.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0OTgwMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            . An external listener is configured for the Kafka cluster, with TLS authentication and encryption, and Kafka _simple authorization_ enabled\n          \n          \n            \n            . An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434749801", "createdAt": "2020-06-03T17:52:39Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements and approach to security.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS authentication and encryption, and Kafka _simple authorization_ enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1NDUyOA==", "bodyText": "TBH, I'm not sure how ... but we should make it clear that this is just about TLS authentication and not TLS encryption.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434754528", "createdAt": "2020-06-03T18:00:39Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements and approach to security.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS authentication and encryption, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1NzUwOA==", "bodyText": "I think this is confusing and should be removed. These options apply only in some situations so I think they will confuse the read rather than help. You should leave them out and just link to the using guide or to the APi reference.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434757508", "createdAt": "2020-06-03T18:05:51Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements and approach to security.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS authentication and encryption, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          bootstrap:\n+            nodePort: 32100\n+          brokers:\n+            - broker: 0\n+              nodePort: 32000\n+            - broker: 1\n+              nodePort: 32001\n+            - broker: 2\n+              nodePort: 32002", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2Mjc2Ng==", "bodyText": "I think this can be removed?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r434762766", "createdAt": "2020-06-03T18:15:18Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,262 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up external clients\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+The process is the same for consumer and producer clients that need to read or write to the Kafka cluster.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+External listeners use port _9094_ to provide access from outside of Kubernetes.\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements and approach to security.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS authentication and encryption, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          bootstrap:\n+            nodePort: 32100\n+          brokers:\n+            - broker: 0\n+              nodePort: 32000\n+            - broker: 1\n+              nodePort: 32001\n+            - broker: 2\n+              nodePort: 32002\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster (CA) to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.\n++\n+NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,\n+you will need to link:{BookURLUsing}#renewing-your-own-ca-certificates-str[renew the certificates manually].\n+\n+. Create or modify a user representing the client that requires access to the Kafka cluster.\n++\n+* Specify the same authentication type as the `Kafka` listener.\n+* Specify the authorization ACLs for simple authorization.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaUserApiVersion}\n+kind: KafkaUser\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/cluster: my-cluster <1>\n+spec:\n+  authentication:\n+    type: tls <2>\n+  authorization:\n+    type: simple\n+    acls: <3>\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Read\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Describe\n+      - resource:\n+          type: group\n+          name: my-group\n+          patternType: literal\n+        operation: Read\n+----\n+<1> The label must match the label of the Kafka cluster for the user to be created.\n+<2> Authentication specified as `tls`.\n+<3> Simple authorization requires an accompanying list of ACL rules to apply to the user.\n+The rules define the operations allowed on Kafka resources based on the _username_ (`my-user`).\n+\n+. Create or modify the `KafkaUser` resource.\n++\n+[source,shell,subs=\"+quotes,attributes\"]\n+kubectl apply -f _USER-CONFIG-FILE_\n++\n+The user is created, as well as a Secret with the same name as the `KafkaUser` resource.\n+The Secret contains a private and public key for TLS client authentication.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/kind: KafkaUser\n+    strimzi.io/cluster: my-cluster\n+type: Opaque\n+data:\n+  ca.crt: _PUBLIC-KEY-OF-THE-CLIENT-CA_\n+  user.crt: _USER-CERTIFICATE-CONTAINING-PUBLIC-KEY-OF-USER_\n+  user.key: _PRIVATE-KEY-OF-USER_\n+  user.p12: _P12-ARCHIVE-FILE-STORING-CERTIFICATES-AND-KEYS_\n+  user.password: _PASSWORD-PROTECTING-P12-ARCHIVE_\n+----\n+\n+. Configure your client to connect to the Kafka cluster with the properties required to make a secure connection to the Kafka cluster.\n+\n+.. Add the authentication details for the public cluster certificates:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+security.protocol: SSL <1>\n+ssl.truststore.location: _PATH-TO/ssl/keys/truststore_ <2>\n+ssl.truststore.password: _CLUSTER-CERT-PASSWORD_ <3>\n+ssl.truststore.type=PKCS12 <4>\n+----\n+<1> Enables TLS encryption (with or without TLS authentication).\n+<2> Specifies the truststore location where the certificates were imported.\n+<3> Specifies the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.\n+<4> Identifies the truststore type.\n++\n+NOTE: Use `security.protocol: SASL_SSL` when using SCRAM-SHA authentication over TLS.\n+\n+.. Add the bootstrap address and port for connecting to the Kafka cluster:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+bootstrap.servers: _BOOTSTRAP-ADDRESS:PORT_\n+----\n++\n+The port number is 443 for connecting using `route` external listeners.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a77951f707ac66ca4c41b1af4ac92e49c59bb715"}, "originalPosition": 250}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74d9dbd2ab74259359e2619500e442b3044c6875", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/74d9dbd2ab74259359e2619500e442b3044c6875", "committedDate": "2020-06-04T10:29:00Z", "message": "review edits JS\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e0ca4f44b71e31d8186d8796cf78c964992a2e87", "committedDate": "2020-06-04T10:34:04Z", "message": "review edits JS - tls encryption\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxNjYwNTEy", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-431660512", "createdAt": "2020-06-16T16:00:14Z", "commit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNjowMDoxNFrOGkiadw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNjoxNjowNVrOGkjDTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2NTc1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n          \n          \n            \n            After you have xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section explain how to:", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440965751", "createdAt": "2020-06-16T16:00:14Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2NzA4Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * How to set up external client access to the Kafka cluster\n          \n          \n            \n            * Set up external client access to the Kafka cluster", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440967087", "createdAt": "2020-06-16T16:02:08Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n \n-The procedure assumes a Strimzi is available and running in a Kubernetes cluster.\n+* Deploy example producer and consumer clients, which you can use to verify your deployment\n+* How to set up external client access to the Kafka cluster", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2NzYxNA==", "bodyText": "Remove the +.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440967614", "createdAt": "2020-06-16T16:02:54Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n \n-The procedure assumes a Strimzi is available and running in a Kubernetes cluster.\n+* Deploy example producer and consumer clients, which you can use to verify your deployment\n+* How to set up external client access to the Kafka cluster\n++", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2ODczMQ==", "bodyText": "Not sure \"involved\" is friendly for localization. Maybe we can say \"more complex\" instead.\n\"The steps to set up access to the Kafka cluster for a client outside Kubernetes are more involved...\"", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440968731", "createdAt": "2020-06-16T16:04:41Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n \n-The procedure assumes a Strimzi is available and running in a Kubernetes cluster.\n+* Deploy example producer and consumer clients, which you can use to verify your deployment\n+* How to set up external client access to the Kafka cluster\n++\n+The steps to set up access to the Kafka cluster for a client outside Kubernetes are a lot more involved,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2OTcyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            and require familiarity with the process of link:{BookURLUsing}#assembly-deployment-configuration-str[configuring Kafka components^].\n          \n          \n            \n            and require familiarity with link:{BookURLUsing}#assembly-deployment-configuration-str[how to configure Kafka components^].", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440969726", "createdAt": "2020-06-16T16:06:07Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n \n-The procedure assumes a Strimzi is available and running in a Kubernetes cluster.\n+* Deploy example producer and consumer clients, which you can use to verify your deployment\n+* How to set up external client access to the Kafka cluster\n++\n+The steps to set up access to the Kafka cluster for a client outside Kubernetes are a lot more involved,\n+and require familiarity with the process of link:{BookURLUsing}#assembly-deployment-configuration-str[configuring Kafka components^].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MDc5OQ==", "bodyText": "In fact, The sentence on line 13 confused me a little. Is it related to the second bullet point?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440970799", "createdAt": "2020-06-16T16:07:47Z", "author": {"login": "laidan6000"}, "path": "documentation/assemblies/deploying/assembly-deploy-verify.adoc", "diffHunk": "@@ -3,11 +3,18 @@\n // deploying/master.adoc\n \n [id=\"deploy-verify_{context}\"]\n-= Verifying the Strimzi deployment\n+= Setting up client access to the Kafka cluster\n \n-Having xref:deploy-tasks_{context}[deployed Strimzi], the procedure in this section shows how to deploy example producer and consumer clients.\n+Having xref:deploy-tasks_{context}[deployed Strimzi], the procedures in this section show how to:\n \n-The procedure assumes a Strimzi is available and running in a Kubernetes cluster.\n+* Deploy example producer and consumer clients, which you can use to verify your deployment\n+* How to set up external client access to the Kafka cluster\n++", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2NzYxNA=="}, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MTY0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `route` to use OpenShift `Route` and the default HAProxy router\n          \n          \n            \n            * `route` to use OpenShift `Route` and the default HAProxy router.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440971641", "createdAt": "2020-06-16T16:09:07Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MTcyMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `loadbalancer` to use loadbalancer services\n          \n          \n            \n            * `loadbalancer` to use loadbalancer services.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440971720", "createdAt": "2020-06-16T16:09:14Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MTc5NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `nodeport` to use ports on Kubernetes nodes\n          \n          \n            \n            * `nodeport` to use ports on Kubernetes nodes.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440971794", "createdAt": "2020-06-16T16:09:20Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MTg1NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n          \n          \n            \n            * `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440971855", "createdAt": "2020-06-16T16:09:26Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3MjU0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            . An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled\n          \n          \n            \n            . An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440972544", "createdAt": "2020-06-16T16:10:20Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3Mjg2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            . A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n          \n          \n            \n            . A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440972865", "createdAt": "2020-06-16T16:10:51Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3NTU1NA==", "bodyText": "Is (CA) correct here?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440975554", "createdAt": "2020-06-16T16:15:07Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster (CA) to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk3NjIwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,\n          \n          \n            \n            NOTE: Cluster CA certificates renew automatically by default. If you are using your own Kafka listener certificates,", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r440976206", "createdAt": "2020-06-16T16:16:05Z", "author": {"login": "laidan6000"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ enabled\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster (CA) to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.\n++\n+NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0ca4f44b71e31d8186d8796cf78c964992a2e87"}, "originalPosition": 144}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/bba17b8c09cec1caf2cd29ccfa6c470005fbade5", "committedDate": "2020-06-17T08:42:24Z", "message": "review edits DL\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42bb3de56bfa8d4f9983a270b738508ae71e15fd", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/42bb3de56bfa8d4f9983a270b738508ae71e15fd", "committedDate": "2020-06-17T13:33:51Z", "message": "Merge branch 'master' of github.com:strimzi/strimzi-kafka-operator into doc-setting-up-external-clients"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMyNTg0MTM0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-432584134", "createdAt": "2020-06-17T16:43:31Z", "commit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5Nzc5MTEw", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-439779110", "createdAt": "2020-06-30T08:18:48Z", "commit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwODoxODo0OFrOGqxMqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwODozMTo0N1rOGqxu8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ5OTQzNA==", "bodyText": "I don't know if it's clear for users. It should say that you should have at least one listener supporting the authentication you want to use for the KafkaUser.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447499434", "createdAt": "2020-06-30T08:18:48Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwMDUxOA==", "bodyText": "it doesn't create \"CA\" certificates but the private key and certificate couple for secure access so for TLS client authentication.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447500518", "createdAt": "2020-06-30T08:20:31Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwMzk2MQ==", "bodyText": "not sure about the networkPolicyPeers section here. Are we describing how to access the Kafka cluster from outside of Kubernetes right? So it means that the Kafka client is running completely outside of Kubernetes and not in a pod in a different namespace. @scholzj am I missing something?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447503961", "createdAt": "2020-06-30T08:25:38Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwNDQ3OQ==", "bodyText": "kubectl instead of oc", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447504479", "createdAt": "2020-06-30T08:26:23Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwNTMzNA==", "bodyText": "I would highlight that this is for TLS encryption.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447505334", "createdAt": "2020-06-30T08:27:42Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster CA certificate to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwNjgwNA==", "bodyText": "\"TLS client authentication\"", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447506804", "createdAt": "2020-06-30T08:29:45Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster CA certificate to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.\n++\n+NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,\n+you will need to link:{BookURLUsing}#renewing-your-own-ca-certificates-str[renew the certificates manually].\n+\n+. Create or modify a user representing the client that requires access to the Kafka cluster.\n++\n+* Specify the same authentication type as the `Kafka` listener.\n+* Specify the authorization ACLs for simple authorization.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaUserApiVersion}\n+kind: KafkaUser\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/cluster: my-cluster <1>\n+spec:\n+  authentication:\n+    type: tls <2>\n+  authorization:\n+    type: simple\n+    acls: <3>\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Read\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Describe\n+      - resource:\n+          type: group\n+          name: my-group\n+          patternType: literal\n+        operation: Read\n+----\n+<1> The label must match the label of the Kafka cluster for the user to be created.\n+<2> Authentication specified as `tls`.\n+<3> Simple authorization requires an accompanying list of ACL rules to apply to the user.\n+The rules define the operations allowed on Kafka resources based on the _username_ (`my-user`).\n+\n+. Create or modify the `KafkaUser` resource.\n++\n+[source,shell,subs=\"+quotes,attributes\"]\n+kubectl apply -f _USER-CONFIG-FILE_\n++\n+The user is created, as well as a Secret with the same name as the `KafkaUser` resource.\n+The Secret contains a private and public key for TLS client authentication.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/kind: KafkaUser\n+    strimzi.io/cluster: my-cluster\n+type: Opaque\n+data:\n+  ca.crt: _PUBLIC-KEY-OF-THE-CLIENT-CA_\n+  user.crt: _USER-CERTIFICATE-CONTAINING-PUBLIC-KEY-OF-USER_\n+  user.key: _PRIVATE-KEY-OF-USER_\n+  user.p12: _P12-ARCHIVE-FILE-STORING-CERTIFICATES-AND-KEYS_\n+  user.password: _PASSWORD-PROTECTING-P12-ARCHIVE_\n+----\n+\n+. Configure your client to connect to the Kafka cluster with the properties required to make a secure connection to the Kafka cluster.\n+\n+.. Add the authentication details for the public cluster certificates:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+security.protocol: SSL <1>\n+ssl.truststore.location: _PATH-TO/ssl/keys/truststore_ <2>\n+ssl.truststore.password: _CLUSTER-CERT-PASSWORD_ <3>\n+ssl.truststore.type=PKCS12 <4>\n+----\n+<1> Enables TLS encryption (with or without TLS authentication).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwNzM0NA==", "bodyText": "I would specify CLUSTER-CA-CERT-PASSWORD", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447507344", "createdAt": "2020-06-30T08:30:33Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster CA certificate to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.\n++\n+NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,\n+you will need to link:{BookURLUsing}#renewing-your-own-ca-certificates-str[renew the certificates manually].\n+\n+. Create or modify a user representing the client that requires access to the Kafka cluster.\n++\n+* Specify the same authentication type as the `Kafka` listener.\n+* Specify the authorization ACLs for simple authorization.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaUserApiVersion}\n+kind: KafkaUser\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/cluster: my-cluster <1>\n+spec:\n+  authentication:\n+    type: tls <2>\n+  authorization:\n+    type: simple\n+    acls: <3>\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Read\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Describe\n+      - resource:\n+          type: group\n+          name: my-group\n+          patternType: literal\n+        operation: Read\n+----\n+<1> The label must match the label of the Kafka cluster for the user to be created.\n+<2> Authentication specified as `tls`.\n+<3> Simple authorization requires an accompanying list of ACL rules to apply to the user.\n+The rules define the operations allowed on Kafka resources based on the _username_ (`my-user`).\n+\n+. Create or modify the `KafkaUser` resource.\n++\n+[source,shell,subs=\"+quotes,attributes\"]\n+kubectl apply -f _USER-CONFIG-FILE_\n++\n+The user is created, as well as a Secret with the same name as the `KafkaUser` resource.\n+The Secret contains a private and public key for TLS client authentication.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/kind: KafkaUser\n+    strimzi.io/cluster: my-cluster\n+type: Opaque\n+data:\n+  ca.crt: _PUBLIC-KEY-OF-THE-CLIENT-CA_\n+  user.crt: _USER-CERTIFICATE-CONTAINING-PUBLIC-KEY-OF-USER_\n+  user.key: _PRIVATE-KEY-OF-USER_\n+  user.p12: _P12-ARCHIVE-FILE-STORING-CERTIFICATES-AND-KEYS_\n+  user.password: _PASSWORD-PROTECTING-P12-ARCHIVE_\n+----\n+\n+. Configure your client to connect to the Kafka cluster with the properties required to make a secure connection to the Kafka cluster.\n+\n+.. Add the authentication details for the public cluster certificates:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+security.protocol: SSL <1>\n+ssl.truststore.location: _PATH-TO/ssl/keys/truststore_ <2>\n+ssl.truststore.password: _CLUSTER-CERT-PASSWORD_ <3>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUwODIxMQ==", "bodyText": "This sentence is misleading. The certificate is already signed by the client CA when it's created not when the client connects to the Kafka cluster.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447508211", "createdAt": "2020-06-30T08:31:47Z", "author": {"login": "ppatierno"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.\n+\n+In this procedure:\n+\n+. An external listener is configured for the Kafka cluster, with TLS encryption and authentication, and Kafka _simple authorization_ is enabled.\n+. A `KafkaUser` is created for the client, with TLS authentication and Access Control Lists (ACLs) defined for _simple authorization_.\n+\n+You can configure your listener to use TLS or SCRAM-SHA authentication,\n+both of which can be used with TLS encryption.\n+If you are using an authorization server, you can use token-based link:{BookURLUsing}#assembly-oauth-authentication_str[{oauth} authentication] and link:{BookURLUsing}#assembly-oauth-authorization_str[{oauth} authorization].\n+\n+When you configure the `KafkaUser` authentication and authorization mechanisms, ensure they match the equivalent Kafka configuration:\n+\n+* `KafkaUser.spec.authentication` matches `Kafka.spec.kafka.listeners.*.authentication`\n+* `KafkaUser.spec.authorization` matches `Kafka.spec.kafka.authorization`\n+\n+NOTE: Authentication between Kafka users and Kafka brokers depends on the authentication settings for each.\n+For example, it is not possible to authenticate a user with TLS if it is not also enabled in the Kafka configuration.\n+\n+Strimzi operators automate the configuration process:\n+\n+* The Cluster Operator creates the listeners and sets up the cluster and client certificate authority (CA) certificates to enable authentication within the Kafka cluster.\n+* The User Operator creates the user representing the client and sets up the user CA certificates for secure access to the Kafka cluster.\n+\n+In this procedure, the certificates generated by the Cluster Operator are used, but you can replace them by link:{BookURLUsing}#installing-your-own-ca-certificates-str[installing your own certificates].\n+You can also configure your listener to link:{BookURLUsing}#kafka-listener-certificates-str[use a Kafka listener certificate managed by an external Certificate Authority].\n+\n+Certificates are available in PKCS #12 format (.p12) and PEM (.crt) formats.\n+\n+.Prerequisites\n+\n+* The Kafka cluster is available for the client\n+* The Cluster Operator and User Operator are running in the cluster\n+* A client outside the Kubernetes cluster to connect to the Kafka cluster\n+\n+.Procedure\n+\n+. Configure the Kafka cluster with an `external` Kafka listener.\n++\n+* Define the authentication required to access the Kafka broker through the listener\n+* Enable authorization on the Kafka broker\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaApiVersion}\n+kind: Kafka\n+spec:\n+  kafka:\n+    # ...\n+    listeners: <1>\n+      external:\n+        type: _LISTENER-TYPE_ <2>\n+        tls: true <3>\n+        authentication:\n+          type: tls <4>\n+        configuration:\n+          preferredAddressType: InternalDNS <5>\n+        networkPolicyPeers: <6>\n+          - podSelector:\n+              matchLabels:\n+                app: kafka-consumer\n+          - namespaceSelector:\n+              matchLabels:\n+                project: my-project\n+        overrides: <7>\n+          # ...\n+      authorization: <8>\n+        type: simple\n+        superUsers:\n+          - super-user-name <9>\n+  # ...\n+----\n+<1> Configuration options for enabling external listeners are described in the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^]\n+<2> External listener type specified as `route`, `loadbalancer`, `nodeport` or `ingress`.\n+<3> Enables TLS encryption on the listener. Not required for `route` listeners.\n+<4> Authentication specified as `tls`.\n+<5> (Optional, for `nodeport` listeners only) Configuration to link:{BookURLUsing}#con-kafka-broker-external-listeners-nodeports-{context}[specify a preference for the first address type used by Strimzi as the node address].\n+<6> (Optional) By default, Strimzi grants access to listeners to all applications and namespaces. The `networkPolicyPeers` property restricts access to specific pods and namespaces.\n+<7> (Optional, but not applicable to `ingress` listeners) Overrides customize the bootstrap and broker addresses advertised to clients.\n+Strimzi automatically determines the addresses to advertise to clients.\n+The addresses are automatically assigned by Kubernetes.\n+Use overrides if the infrastructure on which you are running Strimzi does not provide the right address.\n+Validation is not performed on overrides.\n+The override configuration differs according to the external listener type,\n+so you can override hosts for `route`, DNS names or IP addresses for `loadbalancer`, and node ports (shown) for `nodeport`.\n+Refer to the link:{BookURLUsing}#type-KafkaListeners-reference[Kafka listeners schema reference^] for more information on external listener `overrides`.\n+<8> Authorization link:{BookURLUsing}#ref-kafka-authorization-{context}[enables `simple` authorization on the Kafka broker using the `SimpleAclAuthorizer` Kafka plugin].\n+<9> (Optional) Super users can access all brokers regardless of any access restrictions defined in ACLs.\n+\n+. Create or update the `Kafka` resource.\n++\n+[source,shell,subs=+quotes]\n+oc apply -f _KAFKA-CONFIG-FILE_\n++\n+The Kafka cluster is configured with a Kafka broker listener using TLS authentication.\n++\n+A service is created for each Kafka broker pod.\n++\n+An additional service is created to serve as the _bootstrap address_ for connection to the Kafka cluster.\n++\n+The cluster CA certificate to verify the identity of the kafka brokers is also created with the same name as the `Kafka` resource.\n+\n+. Find the bootstrap address and port from the status of the `Kafka` resource.\n++\n+[source,shell, subs=+quotes]\n+kubectl get kafka _KAFKA-CLUSTER-NAME_ -o jsonpath='{.status.listeners[?(@.type==\"external\")].bootstrapServers}'\n++\n+Use the bootstrap address in your Kafka client to connect to the Kafka cluster.\n+\n+. Extract the public cluster CA certificate and password from the generated `_KAFKA-CLUSTER-NAME_-cluster-ca-cert` Secret.\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.p12}' | base64 -d > ca.p12\n++\n+[source,shell,subs=\"+quotes\"]\n+kubectl get secret _KAFKA-CLUSTER-NAME_-cluster-ca-cert -o jsonpath='{.data.ca\\.password}' | base64 -d > ca.password\n++\n+Use the certificate and password in your Kafka client to connect to the Kafka cluster.\n++\n+NOTE: Cluster CA certificates renew automatically by default. If your are using your own Kafka listener certificates,\n+you will need to link:{BookURLUsing}#renewing-your-own-ca-certificates-str[renew the certificates manually].\n+\n+. Create or modify a user representing the client that requires access to the Kafka cluster.\n++\n+* Specify the same authentication type as the `Kafka` listener.\n+* Specify the authorization ACLs for simple authorization.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: {KafkaUserApiVersion}\n+kind: KafkaUser\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/cluster: my-cluster <1>\n+spec:\n+  authentication:\n+    type: tls <2>\n+  authorization:\n+    type: simple\n+    acls: <3>\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Read\n+      - resource:\n+          type: topic\n+          name: my-topic\n+          patternType: literal\n+        operation: Describe\n+      - resource:\n+          type: group\n+          name: my-group\n+          patternType: literal\n+        operation: Read\n+----\n+<1> The label must match the label of the Kafka cluster for the user to be created.\n+<2> Authentication specified as `tls`.\n+<3> Simple authorization requires an accompanying list of ACL rules to apply to the user.\n+The rules define the operations allowed on Kafka resources based on the _username_ (`my-user`).\n+\n+. Create or modify the `KafkaUser` resource.\n++\n+[source,shell,subs=\"+quotes,attributes\"]\n+kubectl apply -f _USER-CONFIG-FILE_\n++\n+The user is created, as well as a Secret with the same name as the `KafkaUser` resource.\n+The Secret contains a private and public key for TLS client authentication.\n++\n+For example:\n++\n+[source,yaml,subs=\"+quotes,attributes\"]\n+----\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: my-user\n+  labels:\n+    strimzi.io/kind: KafkaUser\n+    strimzi.io/cluster: my-cluster\n+type: Opaque\n+data:\n+  ca.crt: _PUBLIC-KEY-OF-THE-CLIENT-CA_\n+  user.crt: _USER-CERTIFICATE-CONTAINING-PUBLIC-KEY-OF-USER_\n+  user.key: _PRIVATE-KEY-OF-USER_\n+  user.p12: _P12-ARCHIVE-FILE-STORING-CERTIFICATES-AND-KEYS_\n+  user.password: _PASSWORD-PROTECTING-P12-ARCHIVE_\n+----\n+\n+. Configure your client to connect to the Kafka cluster with the properties required to make a secure connection to the Kafka cluster.\n+\n+.. Add the authentication details for the public cluster certificates:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+security.protocol: SSL <1>\n+ssl.truststore.location: _PATH-TO/ssl/keys/truststore_ <2>\n+ssl.truststore.password: _CLUSTER-CERT-PASSWORD_ <3>\n+ssl.truststore.type=PKCS12 <4>\n+----\n+<1> Enables TLS encryption (with or without TLS authentication).\n+<2> Specifies the truststore location where the certificates were imported.\n+<3> Specifies the password for accessing the truststore. This property can be omitted if it is not needed by the truststore.\n+<4> Identifies the truststore type.\n++\n+NOTE: Use `security.protocol: SASL_SSL` when using SCRAM-SHA authentication over TLS.\n+\n+.. Add the bootstrap address and port for connecting to the Kafka cluster:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+bootstrap.servers: _BOOTSTRAP-ADDRESS:PORT_\n+----\n+\n+.. Add the authentication details for the public user certificates:\n++\n+[source,env,subs=\"+quotes,attributes\"]\n+----\n+ssl.keystore.location: _PATH-TO/ssl/keys/user1.keystore_ <1>\n+ssl.keystore.password: _USER-CERT-PASSWORD_ <2>\n+----\n+<1> Specifies the keystore location where the certificates were imported.\n+<2> Specifies the password for accessing the keystore. This property can be omitted if it is not needed by the keystore.\n++\n+The certificate is signed by the client CA when the client connects to the Kafka cluster.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bba17b8c09cec1caf2cd29ccfa6c470005fbade5"}, "originalPosition": 252}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87141fc25a75cf2cfd740968bd2a7b8aeee1fa4c", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/87141fc25a75cf2cfd740968bd2a7b8aeee1fa4c", "committedDate": "2020-06-30T10:14:27Z", "message": "review edits PP\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5OTU1ODk0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-439955894", "createdAt": "2020-06-30T12:18:42Z", "commit": {"oid": "87141fc25a75cf2cfd740968bd2a7b8aeee1fa4c"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjoxODo0MlrOGq5pxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxMjoxODo0MlrOGq5pxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzNzk1OQ==", "bodyText": "I would remove this sentence. It suggests it is insecure which is not trhough. Also the evaluation might be subjective. If you want some examples why you might use one or another:\n\nLoadbalancers might not be supported on all infras (e.g. bare metal), node ports might work fine there\nLoadbalancers often generate additional costs\n\netc.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#discussion_r447637959", "createdAt": "2020-06-30T12:18:42Z", "author": {"login": "scholzj"}, "path": "documentation/modules/deploying/proc-deploy-setup-external-clients.adoc", "diffHunk": "@@ -0,0 +1,254 @@\n+// Module included in the following assemblies:\n+//\n+// deploying/assembly_deploy-verify.adoc\n+// getting-started.adoc\n+\n+[id='setup-external-clients-{context}']\n+= Setting up access for clients outside of Kubernetes\n+\n+This procedure shows how to configure client access to a Kafka cluster from outside Kubernetes.\n+\n+Using the address of the Kafka cluster, you can provide external access to a client on a different Kubernetes namespace or outside Kubernetes entirely.\n+\n+You configure an external Kafka listener to provide the access.\n+\n+The following external listener types are supported:\n+\n+* `route` to use OpenShift `Route` and the default HAProxy router\n+* `loadbalancer` to use loadbalancer services\n+* `nodeport` to use ports on Kubernetes nodes\n+* `ingress` to use Kubernetes _Ingress_ and the {NginxIngressController}\n+\n+The type chosen depends on your requirements, and your environment and infrastructure.\n+For example, `nodeport` is the least secure, so you might not wish to use it in a production environment.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87141fc25a75cf2cfd740968bd2a7b8aeee1fa4c"}, "originalPosition": 23}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c90ac9aade2dd07e2f220a98d049c2cbe3c3910", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6c90ac9aade2dd07e2f220a98d049c2cbe3c3910", "committedDate": "2020-07-03T16:34:15Z", "message": "review edits JS\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b720fb0fb5da8a356fd5752c65c0369acae79a97", "author": {"user": {"login": "PaulRMellor", "name": null}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b720fb0fb5da8a356fd5752c65c0369acae79a97", "committedDate": "2020-07-03T16:43:12Z", "message": "review edit JS\n\nSigned-off-by: prmellor <pmellor@redhat.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQyODkxMDE5", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3147#pullrequestreview-442891019", "createdAt": "2020-07-06T08:53:06Z", "commit": {"oid": "b720fb0fb5da8a356fd5752c65c0369acae79a97"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1477, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}