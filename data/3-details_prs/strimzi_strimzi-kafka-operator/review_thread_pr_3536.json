{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyMDE4NzQ4", "number": 3536, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo0NToxNFrOEbPTIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxOTowMzo0N1rOEbPYWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTk3NjY1OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo0NToxNFrOHFG9og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo0NToxNFrOHFG9og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTExOTAxMA==", "bodyText": "I think the comment is a bit misleading. Maybe it should say something like Configuration of the node label which will be used as the client.rack consumer configuration.?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r475119010", "createdAt": "2020-08-22T18:45:14Z", "author": {"login": "scholzj"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java", "diffHunk": "@@ -50,6 +54,26 @@ public void setConfig(Map<String, Object> config) {\n         this.config = config;\n     }\n \n+    @Description(\"The image of the init container used for initializing the `client.rack`.\")\n+    @JsonInclude(value = JsonInclude.Include.NON_NULL)\n+    public String getClientRackInitImage() {\n+        return clientRackInitImage;\n+    }\n+\n+    public void setClientRackInitImage(String brokerRackInitImage) {\n+        this.clientRackInitImage = brokerRackInitImage;\n+    }\n+\n+    @Description(\"Configuration of the `client.rack` consumer config.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTk3NzM2OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo0NjoxOVrOHFG99A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo0NjoxOVrOHFG99A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTExOTA5Mg==", "bodyText": "I think this is not needed if it is the same name as the name in the method.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r475119092", "createdAt": "2020-08-22T18:46:19Z", "author": {"login": "scholzj"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java", "diffHunk": "@@ -50,6 +54,26 @@ public void setConfig(Map<String, Object> config) {\n         this.config = config;\n     }\n \n+    @Description(\"The image of the init container used for initializing the `client.rack`.\")\n+    @JsonInclude(value = JsonInclude.Include.NON_NULL)\n+    public String getClientRackInitImage() {\n+        return clientRackInitImage;\n+    }\n+\n+    public void setClientRackInitImage(String brokerRackInitImage) {\n+        this.clientRackInitImage = brokerRackInitImage;\n+    }\n+\n+    @Description(\"Configuration of the `client.rack` consumer config.\")\n+    @JsonProperty(\"rack\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTk4NDI3OnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo1NjoxM1rOHFHBNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxODo1NjoxM1rOHFHBNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTExOTkyNw==", "bodyText": "I do not think we need this if block since the init container should be used only when the rack is configure (and not null). You call it from getInitContainers only when rack is already not null I think.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r475119927", "createdAt": "2020-08-22T18:56:13Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java", "diffHunk": "@@ -459,6 +505,51 @@ public Deployment generateDeployment(Map<String, String> annotations, boolean is\n         return containers;\n     }\n \n+    protected List<EnvVar> getInitContainerEnvVars() {\n+        List<EnvVar> varList = new ArrayList<>();\n+        varList.add(buildEnvVarFromFieldRef(ENV_VAR_KAFKA_INIT_NODE_NAME, \"spec.nodeName\"));\n+\n+        if (rack != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTk4NzkyOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxOTowMDo1MlrOHFHC6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxOTozMjowNFrOHGmwfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTEyMDM2Mg==", "bodyText": "Should this be called from testGenerateDeploymentWithRack?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r475120362", "createdAt": "2020-08-22T19:00:52Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "diffHunk": "@@ -1346,4 +1337,93 @@ public void testNetworkPolicyWithoutConnectorOperator() {\n \n         assertThat(kc.generateNetworkPolicy(true, false), is(nullValue()));\n     }\n+\n+    @Test\n+    public void testClusterRoleBindingRack() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                    .editOrNewMetadata()\n+                        .withNamespace(testNamespace)\n+                    .endMetadata()\n+                    .editOrNewSpec()\n+                        .withNewRack(\"my-topology-label\")\n+                    .endSpec()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb.getMetadata().getName(), is(KafkaConnectCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));\n+        assertThat(crb.getMetadata().getNamespace(), is(nullValue()));\n+        assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));\n+        assertThat(crb.getSubjects().get(0).getName(), is(KafkaConnectCluster.initContainerServiceAccountName(cluster)));\n+    }\n+\n+    @Test\n+    public void testNullClusterRoleBinding() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                .editOrNewMetadata()\n+                    .withNamespace(testNamespace)\n+                .endMetadata()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb, is(nullValue()));\n+    }\n+\n+    private void checkDeployment(Deployment dep, KafkaConnect resource) {\n+        assertThat(dep.getMetadata().getName(), is(KafkaConnectResources.deploymentName(cluster)));\n+        assertThat(dep.getMetadata().getNamespace(), is(namespace));\n+        Map<String, String> expectedDeploymentLabels = expectedLabels(KafkaConnectResources.deploymentName(cluster));\n+        assertThat(dep.getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getSelector().getMatchLabels(), is(expectedSelectorLabels()));\n+        assertThat(dep.getSpec().getReplicas(), is(replicas));\n+        assertThat(dep.getSpec().getTemplate().getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().size(), is(1));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getName(), is(KafkaConnectResources.deploymentName(this.cluster)));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImage(), is(kc.image));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv(), is(getExpectedEnvVars()));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().size(), is(2));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getContainerPort(), is(KafkaConnectCluster.REST_API_PORT));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getName(), is(KafkaConnectCluster.REST_API_PORT_NAME));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getProtocol(), is(\"TCP\"));\n+        assertThat(dep.getSpec().getStrategy().getType(), is(\"RollingUpdate\"));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxSurge().getIntVal(), is(1));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxUnavailable().getIntVal(), is(0));\n+        assertThat(AbstractModel.containerEnvVars(dep.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_TLS), is(nullValue()));\n+        checkOwnerReference(kc.createOwnerReference(), dep);\n+        checkRack(dep, resource);\n+    }\n+\n+    private void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)  {\n+        assertThat(resource.getMetadata().getOwnerReferences().size(), is(1));\n+        assertThat(resource.getMetadata().getOwnerReferences().get(0), is(ownerRef));\n+    }\n+\n+    private void checkRack(Deployment deployment, KafkaConnect resource) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY4NjI4OQ==", "bodyText": "I have already the test method with testGenerateDeploymentWithRack name. This is only assertion of the rack specific properties. I couldn't find the better name, and just to be consistent with other methods I use checkRack. Any suggestions ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r476686289", "createdAt": "2020-08-25T19:27:48Z", "author": {"login": "klalafaryan"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "diffHunk": "@@ -1346,4 +1337,93 @@ public void testNetworkPolicyWithoutConnectorOperator() {\n \n         assertThat(kc.generateNetworkPolicy(true, false), is(nullValue()));\n     }\n+\n+    @Test\n+    public void testClusterRoleBindingRack() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                    .editOrNewMetadata()\n+                        .withNamespace(testNamespace)\n+                    .endMetadata()\n+                    .editOrNewSpec()\n+                        .withNewRack(\"my-topology-label\")\n+                    .endSpec()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb.getMetadata().getName(), is(KafkaConnectCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));\n+        assertThat(crb.getMetadata().getNamespace(), is(nullValue()));\n+        assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));\n+        assertThat(crb.getSubjects().get(0).getName(), is(KafkaConnectCluster.initContainerServiceAccountName(cluster)));\n+    }\n+\n+    @Test\n+    public void testNullClusterRoleBinding() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                .editOrNewMetadata()\n+                    .withNamespace(testNamespace)\n+                .endMetadata()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb, is(nullValue()));\n+    }\n+\n+    private void checkDeployment(Deployment dep, KafkaConnect resource) {\n+        assertThat(dep.getMetadata().getName(), is(KafkaConnectResources.deploymentName(cluster)));\n+        assertThat(dep.getMetadata().getNamespace(), is(namespace));\n+        Map<String, String> expectedDeploymentLabels = expectedLabels(KafkaConnectResources.deploymentName(cluster));\n+        assertThat(dep.getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getSelector().getMatchLabels(), is(expectedSelectorLabels()));\n+        assertThat(dep.getSpec().getReplicas(), is(replicas));\n+        assertThat(dep.getSpec().getTemplate().getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().size(), is(1));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getName(), is(KafkaConnectResources.deploymentName(this.cluster)));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImage(), is(kc.image));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv(), is(getExpectedEnvVars()));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().size(), is(2));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getContainerPort(), is(KafkaConnectCluster.REST_API_PORT));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getName(), is(KafkaConnectCluster.REST_API_PORT_NAME));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getProtocol(), is(\"TCP\"));\n+        assertThat(dep.getSpec().getStrategy().getType(), is(\"RollingUpdate\"));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxSurge().getIntVal(), is(1));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxUnavailable().getIntVal(), is(0));\n+        assertThat(AbstractModel.containerEnvVars(dep.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_TLS), is(nullValue()));\n+        checkOwnerReference(kc.createOwnerReference(), dep);\n+        checkRack(dep, resource);\n+    }\n+\n+    private void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)  {\n+        assertThat(resource.getMetadata().getOwnerReferences().size(), is(1));\n+        assertThat(resource.getMetadata().getOwnerReferences().get(0), is(ownerRef));\n+    }\n+\n+    private void checkRack(Deployment deployment, KafkaConnect resource) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTEyMDM2Mg=="}, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY4ODUwOQ==", "bodyText": "Never mind this comment. I thought it is never called form testGenerateDeploymentWithRack. But now I see it is called from checkDeployment which is called there. So just ignore this. Sorry.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r476688509", "createdAt": "2020-08-25T19:32:04Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "diffHunk": "@@ -1346,4 +1337,93 @@ public void testNetworkPolicyWithoutConnectorOperator() {\n \n         assertThat(kc.generateNetworkPolicy(true, false), is(nullValue()));\n     }\n+\n+    @Test\n+    public void testClusterRoleBindingRack() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                    .editOrNewMetadata()\n+                        .withNamespace(testNamespace)\n+                    .endMetadata()\n+                    .editOrNewSpec()\n+                        .withNewRack(\"my-topology-label\")\n+                    .endSpec()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb.getMetadata().getName(), is(KafkaConnectCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));\n+        assertThat(crb.getMetadata().getNamespace(), is(nullValue()));\n+        assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));\n+        assertThat(crb.getSubjects().get(0).getName(), is(KafkaConnectCluster.initContainerServiceAccountName(cluster)));\n+    }\n+\n+    @Test\n+    public void testNullClusterRoleBinding() {\n+        String testNamespace = \"other-namespace\";\n+\n+        KafkaConnect kafkaConnect = new KafkaConnectBuilder(this.resource)\n+                .editOrNewMetadata()\n+                    .withNamespace(testNamespace)\n+                .endMetadata()\n+                .build();\n+\n+        KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);\n+        ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding(testNamespace);\n+\n+        assertThat(crb, is(nullValue()));\n+    }\n+\n+    private void checkDeployment(Deployment dep, KafkaConnect resource) {\n+        assertThat(dep.getMetadata().getName(), is(KafkaConnectResources.deploymentName(cluster)));\n+        assertThat(dep.getMetadata().getNamespace(), is(namespace));\n+        Map<String, String> expectedDeploymentLabels = expectedLabels(KafkaConnectResources.deploymentName(cluster));\n+        assertThat(dep.getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getSelector().getMatchLabels(), is(expectedSelectorLabels()));\n+        assertThat(dep.getSpec().getReplicas(), is(replicas));\n+        assertThat(dep.getSpec().getTemplate().getMetadata().getLabels(), is(expectedDeploymentLabels));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().size(), is(1));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getName(), is(KafkaConnectResources.deploymentName(this.cluster)));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getImage(), is(kc.image));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv(), is(getExpectedEnvVars()));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds(), is(healthDelay));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds(), is(healthTimeout));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().size(), is(2));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getContainerPort(), is(KafkaConnectCluster.REST_API_PORT));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getName(), is(KafkaConnectCluster.REST_API_PORT_NAME));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getContainers().get(0).getPorts().get(0).getProtocol(), is(\"TCP\"));\n+        assertThat(dep.getSpec().getStrategy().getType(), is(\"RollingUpdate\"));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxSurge().getIntVal(), is(1));\n+        assertThat(dep.getSpec().getStrategy().getRollingUpdate().getMaxUnavailable().getIntVal(), is(0));\n+        assertThat(AbstractModel.containerEnvVars(dep.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_TLS), is(nullValue()));\n+        checkOwnerReference(kc.createOwnerReference(), dep);\n+        checkRack(dep, resource);\n+    }\n+\n+    private void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)  {\n+        assertThat(resource.getMetadata().getOwnerReferences().size(), is(1));\n+        assertThat(resource.getMetadata().getOwnerReferences().get(0), is(ownerRef));\n+    }\n+\n+    private void checkRack(Deployment deployment, KafkaConnect resource) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTEyMDM2Mg=="}, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2OTk5MDAxOnYy", "diffSide": "RIGHT", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxOTowMzo0N1rOHFHD7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQxOTowMzo0N1rOHFHD7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTEyMDYyMQ==", "bodyText": "I guess we need to add the Cluster role to the installation files? We will need to add it to install/ and for both Helm Charts.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3536#discussion_r475120621", "createdAt": "2020-08-22T19:03:47Z", "author": {"login": "scholzj"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java", "diffHunk": "@@ -682,4 +781,61 @@ public NetworkPolicy generateNetworkPolicy(boolean namespaceAndPodSelectorNetwor\n     public Tracing getTracing() {\n         return tracing;\n     }\n+\n+    /**\n+     * Get the name of the kafka connect service account given the name of the {@code kafkaResourceName}.\n+     *\n+     * @param resourceName The name of the Kafka connect resource.\n+     * @return The name of the ServiceAccount.\n+     */\n+    public static String initContainerServiceAccountName(String resourceName) {\n+        return KafkaConnectResources.deploymentName(resourceName);\n+    }\n+\n+    /**\n+     * Get the name of the kafka connect init container role binding given the name of the {@code namespace} and {@code cluster}.\n+     *\n+     * @param namespace The namespace.\n+     * @param cluster   The cluster name.\n+     * @return The name of the init container's cluster role binding.\n+     */\n+    public static String initContainerClusterRoleBindingName(String namespace, String cluster) {\n+        return \"strimzi-\" + namespace + \"-\" + cluster + \"-kafka-init\";\n+    }\n+\n+    /**\n+     * Creates the ClusterRoleBinding which is used to bind the Kafka Connect SA to the ClusterRole\n+     * which permissions the Kafka init container to access K8S nodes (necessary for rack-awareness).\n+     *\n+     * @param assemblyNamespace The namespace.\n+     * @return The cluster role binding.\n+     */\n+    public ClusterRoleBinding generateClusterRoleBinding(String assemblyNamespace) {\n+\n+        if (rack == null) {\n+            return null;\n+        }\n+\n+        Subject ks = new SubjectBuilder()\n+                .withKind(\"ServiceAccount\")\n+                .withName(initContainerServiceAccountName(cluster))\n+                .withNamespace(assemblyNamespace)\n+                .build();\n+\n+        RoleRef roleRef = new RoleRefBuilder()\n+                .withName(\"strimzi-kafka-client\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9f530164f6af66e985dca7eb802fd30a63d2c37"}, "originalPosition": 238}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1343, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}