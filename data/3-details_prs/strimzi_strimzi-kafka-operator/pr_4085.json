{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM1OTMxMzk4", "number": 4085, "title": "[systemtest] Tests for NetworkPolicy enhancements", "bodyText": "Signed-off-by: Lukas Kral lukywill16@gmail.com\nType of change\n\nNew tests\nNew ST\n\nDescription\nThis PR gonna add new ST for NetworkPolicy tests. Other than that, I added two tests for the new enhancement to our NP (especially new envs for CO).\nFirst test trying to set STRIMZI_OPERATOR_NAMESPACE with actual namespace (which should be added by default) and tests, if the Kafka cluster is correctly created and we can replace the configuration (the dynamic one) which will do the request to Kafka API. It will ensure us that NP are correctly set. Also there is little check if the NP are created for kafka and zookeeper.\nSecond test is trying to deploy CO with custom labels in one namespace (also labeling that namespace), adding the STRIMZI_OPERATOR_NAMESPACE_LABELS to the CO and then creating Kafka cluster (with the same labels) in different namespace. Again, I'm replacing dynamic configuration and checking, if the observed generation will be higher and the request on API will be successful.\nAlso this PR edits our methods so we can use the custom envs on CO deployment.\nChecklist\n\n Write tests\n Make sure all tests pass", "createdAt": "2020-12-10T13:19:34Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085", "merged": true, "mergeCommit": {"oid": "ca7f7893687336914e4246d55a6e71aa985ef6ce"}, "closed": true, "closedAt": "2020-12-11T23:42:36Z", "author": {"login": "im-konge"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdkzIPUAH2gAyNTM1OTMxMzk4OjMxYzEzMzJjNzY3NTQ1NTYyYTcxMWRhYWU0NDkzOGRkNjE3ZTUyYjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdlH3zLgFqTU1MDA5MjE3MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "31c1332c767545562a711daae44938dd617e52b1", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/31c1332c767545562a711daae44938dd617e52b1", "committedDate": "2020-12-10T13:12:40Z", "message": "add tests for np enhancements, create ST for NPs etc.\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/74ccf5ef8950e77eed6543f9eb49feb468db6a60", "committedDate": "2020-12-10T19:06:58Z", "message": "Jakub's comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NTM1NjU1", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#pullrequestreview-549535655", "createdAt": "2020-12-10T19:33:25Z", "commit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxOTozMzoyNVrOIDZ7hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxOTozNjoxMVrOIDaB9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MTQ3Ng==", "bodyText": "Correct me if I am wrong, but you should ut there an assertion, that the install type is bundle. Same for the second test. Otherwise, it will be executed in other install types as well.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540441476", "createdAt": "2020-12-10T19:33:25Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MjA3Mg==", "bodyText": "Just a question: shouldn't we check some specific value in NP? Just asking.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540442072", "createdAt": "2020-12-10T19:34:22Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();\n+\n+        prepareEnvForOperator(NAMESPACE);\n+        applyRoleBindings(NAMESPACE);\n+        // 060-Deployment\n+        BundleResource.clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorNamespaceEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();\n+\n+        checkNetworkPoliciesInNamespace(NAMESPACE);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(NAMESPACE);\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {\n+        String secondNamespace = \"second-\" + NAMESPACE;\n+\n+        Map<String, String> labels = new HashMap<>();\n+        labels.put(\"my-label\", \"my-value\");\n+\n+        EnvVar operatorLabelsEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE_LABELS\")\n+            .withValue(labels.toString().replaceAll(\"\\\\{|}\", \"\"))\n+            .build();\n+\n+        cluster.createNamespace(secondNamespace);\n+\n+        prepareEnvForOperator(NAMESPACE, Arrays.asList(NAMESPACE, secondNamespace));\n+\n+        // Apply role bindings in CO namespace\n+        applyRoleBindings(NAMESPACE);\n+\n+        // Create ClusterRoleBindings that grant cluster-wide access to all OpenShift projects\n+        List<ClusterRoleBinding> clusterRoleBindingList = KubernetesResource.clusterRoleBindingsForAllNamespaces(NAMESPACE);\n+        clusterRoleBindingList.forEach(clusterRoleBinding ->\n+            KubernetesResource.clusterRoleBinding(clusterRoleBinding, NAMESPACE));\n+        // 060-Deployment\n+        BundleResource.clusterOperator(\"*\", Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorLabelsEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        kubeClient().getClient().namespaces().withName(NAMESPACE).edit()\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        cluster.setNamespace(secondNamespace);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        checkNetworkPoliciesInNamespace(secondNamespace);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(secondNamespace);\n+    }\n+\n+    void checkNetworkPoliciesInNamespace(String namespace) {\n+        List<NetworkPolicy> networkPolicyList = new ArrayList<>(kubeClient().getClient().network().networkPolicies().inNamespace(namespace).list().getItems());\n+\n+        String networkPolicyPrefix = CLUSTER_NAME + \"-network-policy\";\n+\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-kafka\")).findFirst());\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-zookeeper\")).findFirst());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "originalPosition": 320}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MzEyNQ==", "bodyText": "Why this check is needed", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540443125", "createdAt": "2020-12-10T19:36:11Z", "author": {"login": "Frawless"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();\n+\n+        prepareEnvForOperator(NAMESPACE);\n+        applyRoleBindings(NAMESPACE);\n+        // 060-Deployment\n+        BundleResource.clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorNamespaceEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();\n+\n+        checkNetworkPoliciesInNamespace(NAMESPACE);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(NAMESPACE);\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {\n+        String secondNamespace = \"second-\" + NAMESPACE;\n+\n+        Map<String, String> labels = new HashMap<>();\n+        labels.put(\"my-label\", \"my-value\");\n+\n+        EnvVar operatorLabelsEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE_LABELS\")\n+            .withValue(labels.toString().replaceAll(\"\\\\{|}\", \"\"))\n+            .build();\n+\n+        cluster.createNamespace(secondNamespace);\n+\n+        prepareEnvForOperator(NAMESPACE, Arrays.asList(NAMESPACE, secondNamespace));\n+\n+        // Apply role bindings in CO namespace\n+        applyRoleBindings(NAMESPACE);\n+\n+        // Create ClusterRoleBindings that grant cluster-wide access to all OpenShift projects\n+        List<ClusterRoleBinding> clusterRoleBindingList = KubernetesResource.clusterRoleBindingsForAllNamespaces(NAMESPACE);\n+        clusterRoleBindingList.forEach(clusterRoleBinding ->\n+            KubernetesResource.clusterRoleBinding(clusterRoleBinding, NAMESPACE));\n+        // 060-Deployment\n+        BundleResource.clusterOperator(\"*\", Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorLabelsEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        kubeClient().getClient().namespaces().withName(NAMESPACE).edit()\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        cluster.setNamespace(secondNamespace);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        checkNetworkPoliciesInNamespace(secondNamespace);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(secondNamespace);\n+    }\n+\n+    void checkNetworkPoliciesInNamespace(String namespace) {\n+        List<NetworkPolicy> networkPolicyList = new ArrayList<>(kubeClient().getClient().network().networkPolicies().inNamespace(namespace).list().getItems());\n+\n+        String networkPolicyPrefix = CLUSTER_NAME + \"-network-policy\";\n+\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-kafka\")).findFirst());\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-zookeeper\")).findFirst());\n+    }\n+\n+    void changeKafkaConfigurationAndCheckObservedGeneration(String namespace) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "originalPosition": 323}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NjYyODY5", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#pullrequestreview-549662869", "createdAt": "2020-12-10T22:38:50Z", "commit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMjozODo1MFrOIDgiBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMjozODo1MFrOIDgiBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0OTYzNw==", "bodyText": "It is configured in the installation files (\n  \n    \n      strimzi-kafka-operator/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml\n    \n    \n         Line 87\n      in\n      e1e1035\n    \n    \n    \n    \n\n        \n          \n           - name: STRIMZI_OPERATOR_NAMESPACE \n        \n    \n  \n\n) ... why do you need to configure it again your self here? Isn't that unnecessary? I think you deploy using these files ...", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540549637", "createdAt": "2020-12-10T22:38:50Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60"}, "originalPosition": 235}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b46b0448f5b16679515f0f1b9ff76553ee352b0c", "author": {"user": {"login": "im-konge", "name": "Luk\u00e1\u0161 Kr\u00e1l"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b46b0448f5b16679515f0f1b9ff76553ee352b0c", "committedDate": "2020-12-11T12:18:24Z", "message": "Jakub's comment vol.2\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMDUyNjQ0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#pullrequestreview-550052644", "createdAt": "2020-12-11T12:23:24Z", "commit": {"oid": "b46b0448f5b16679515f0f1b9ff76553ee352b0c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMDkyMTcx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#pullrequestreview-550092171", "createdAt": "2020-12-11T13:22:43Z", "commit": {"oid": "b46b0448f5b16679515f0f1b9ff76553ee352b0c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 740, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}