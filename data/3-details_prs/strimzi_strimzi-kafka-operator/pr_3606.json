{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgxMTA2OTI1", "number": 3606, "title": "Fix detection and application of logging changes", "bodyText": "Signed-off-by: Marko Strukelj marko.strukelj@gmail.com\nType of change\nThis PR attempts to address the issue of synchronizing Kafka CR logging section with dynamic Kafka Broker configuration.\nApparently Kafka Broker iterates the Log4j loggers, and calls getLevel() on them. And if getLevel() returns null it communicates it as INFO, which is wrong as it masks the actual state of things with regards to logging level inheritance. This part should be addressed in Apache Kafka code base, however, such erroneous behaviour is mandated by KIP-412.\nTypically the list of loggers returned by using CLI tool:\nbin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type broker-loggers --entity-name 0\n\nis 100+ because all loggers with null level are also returned (as having INFO level), whereas Kafka CR logging configuration (plus defaults) only contains levels for maybe 10 categories.\nIn order to prevent detecting a difference every single time during configuration synchronisation, and updating the config every single time with updates that result in no apparent effect, the only way to currently address this seems to be to properly calculate logging levels of all the loggers based on Kafka CR logging configuration and setting them on the loggers - overriding the inheritance mechanism.\nSelect the type of your PR\n\nBugfix\n\nDescription\nPlease describe your pull request\nChecklist\nPlease go through this checklist and make sure all applicable tasks have been done\n\n Write tests\n Make sure all tests pass\n Update documentation\n Check RBAC rights for Kubernetes / OpenShift roles\n Try your changes from Pod inside your Kubernetes and OpenShift cluster, not just locally\n Reference relevant issue(s) and close them after merging\n Update CHANGELOG.md\n Supply screenshots for visual changes, such as Grafana dashboards", "createdAt": "2020-09-07T06:59:14Z", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606", "merged": true, "mergeCommit": {"oid": "5d50182bbc6e0149d5bd8dd5e38462d41d38e437"}, "closed": true, "closedAt": "2020-09-12T17:54:10Z", "author": {"login": "mstruk"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdGduotAFqTQ4MzI5Nzk2NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdH5vtGAFqTQ4NzAzMjg3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzMjk3OTY0", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-483297964", "createdAt": "2020-09-07T07:18:58Z", "commit": {"oid": "edfcda99b1cc44d06c80cc98cc9e4f424908941c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzoxODo1OFrOHNy9gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QwNzoxODo1OFrOHNy9gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIyODQ4Mg==", "bodyText": "See point 4 in rejected alternatives:\nhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-412%3A+Extend+Admin+API+to+support+dynamic+application+log+levels#KIP412:ExtendAdminAPItosupportdynamicapplicationloglevels-RejectedAlternatives", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#discussion_r484228482", "createdAt": "2020-09-07T07:18:58Z", "author": {"login": "sknot-rh"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiff.java", "diffHunk": "@@ -179,4 +104,47 @@ private static boolean isValidLoggerLevel(String level) {\n         return VALID_LOGGER_LEVELS.contains(level);\n     }\n \n+    static class LoggingLevelResolver {\n+\n+        Map<String, String> config;\n+\n+        LoggingLevelResolver(Map<String, String> loggingConfig) {\n+            this.config = loggingConfig;\n+        }\n+\n+        LoggingLevel resolveLevel(String name) {\n+            String level = config.get(name);\n+            if (level != null) {\n+                return LoggingLevel.valueOf(level.split(\",\")[0]);\n+            }\n+\n+            int e = name.length();\n+            int b = e;\n+            while (b > -1) {\n+                b = name.lastIndexOf('.', e);\n+                if (b == -1) {\n+                    level = config.get(\"root\");\n+                } else {\n+                    level = config.get(name.substring(0, b));\n+                }\n+                if (level != null) {\n+                    return LoggingLevel.valueOf(level.split(\",\")[0]);\n+                }\n+                e = b - 1;\n+            }\n+            // still here? Not even root logger defined?\n+            return LoggingLevel.INFO;\n+        }\n+    }\n+\n+    enum LoggingLevel {\n+        ALL,\n+        FATAL,\n+        ERROR,\n+        WARN,\n+        INFO,\n+        DEBUG,\n+        TRACE,\n+        OFF", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "edfcda99b1cc44d06c80cc98cc9e4f424908941c"}, "originalPosition": 199}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzNDkyNjA4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-483492608", "createdAt": "2020-09-07T11:46:36Z", "commit": {"oid": "8ebdda61a7b2e6c00d9081c8d09858b4f0c24cfb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMTo0NjozNlrOHN8S3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wN1QxMTo0NjozNlrOHN8S3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDM4MTQwNA==", "bodyText": "Can you put there any doc?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#discussion_r484381404", "createdAt": "2020-09-07T11:46:36Z", "author": {"login": "sknot-rh"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiff.java", "diffHunk": "@@ -179,4 +111,45 @@ private static boolean isValidLoggerLevel(String level) {\n         return VALID_LOGGER_LEVELS.contains(level);\n     }\n \n+    static class LoggingLevelResolver {\n+\n+        Map<String, String> config;\n+\n+        LoggingLevelResolver(Map<String, String> loggingConfig) {\n+            this.config = loggingConfig;\n+        }\n+\n+        LoggingLevel resolveLevel(String name) {\n+            String level = config.get(name);\n+            if (level != null) {\n+                return LoggingLevel.valueOf(level.split(\",\")[0]);\n+            }\n+\n+            int e = name.length();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ebdda61a7b2e6c00d9081c8d09858b4f0c24cfb"}, "originalPosition": 178}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgzNTMxNDQ4", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-483531448", "createdAt": "2020-09-07T12:50:37Z", "commit": {"oid": "8ebdda61a7b2e6c00d9081c8d09858b4f0c24cfb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MDM0MjA3", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-484034207", "createdAt": "2020-09-08T11:17:41Z", "commit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MTA0MDQx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-484104041", "createdAt": "2020-09-08T12:56:51Z", "commit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMjo1Njo1MVrOHObkaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMjo1Njo1MVrOHObkaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDg5MzgwMA==", "bodyText": "I don't understand how this is deprecated.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#discussion_r484893800", "createdAt": "2020-09-08T12:56:51Z", "author": {"login": "tombentley"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiff.java", "diffHunk": "@@ -68,115 +54,120 @@ public int getDiffSize() {\n         if (brokerConfigs == null || desired == null) {\n             return Collections.emptyList();\n         }\n-        Map<String, String> currentMap;\n+\n         Collection<AlterConfigOp> updatedCE = new ArrayList<>();\n-        currentMap = brokerConfigs.entries().stream().collect(\n-            Collectors.toMap(\n-                ConfigEntry::name,\n-                configEntry -> configEntry.value() == null ? \"null\" : configEntry.value()));\n \n         OrderedProperties orderedProperties = new OrderedProperties();\n         desired = desired.replaceAll(\"log4j\\\\.logger\\\\.\", \"\");\n         desired = desired.replaceAll(\"log4j\\\\.rootLogger\", \"root\");\n         orderedProperties.addStringPairs(desired);\n         Map<String, String> desiredMap = orderedProperties.asMap();\n \n-        ObjectMapper orderedMapper = patchMapper().configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true);\n-\n-        JsonNode source = orderedMapper.valueToTree(currentMap);\n-        JsonNode target = orderedMapper.valueToTree(desiredMap);\n-        JsonNode jsonDiff = JsonDiff.asJson(source, target);\n-\n-        for (JsonNode d : jsonDiff) {\n-            String pathValue = d.get(\"path\").asText();\n-            String pathValueWithoutSlash = pathValue.substring(1);\n+        LoggingLevelResolver levelResolver = new LoggingLevelResolver(desiredMap);\n \n-            Optional<ConfigEntry> optEntry = brokerConfigs.entries().stream()\n-                    .filter(configEntry -> configEntry.name().equals(pathValueWithoutSlash))\n-                    .findFirst();\n-\n-            if (pathValueWithoutSlash.equals(\"log4j.rootLogger\")) {\n-                if (!desiredMap.get(pathValueWithoutSlash).matches(\".+,.+\")) {\n-                    log.warn(\"Broker {} logging: Logger log4j.rootLogger should contain level and appender, e.g. \\'log4j.rootLogger = INFO, CONSOLE\\'\", brokerId);\n-                }\n-            }\n-            String op = d.get(\"op\").asText();\n-            if (optEntry.isPresent()) {\n-                ConfigEntry entry = optEntry.get();\n-                if (\"remove\".equals(op)) {\n-                    removeProperty(updatedCE, pathValueWithoutSlash, entry);\n-                } else if (\"replace\".equals(op)) {\n-                    // entry is in the current, desired is updated value\n-                    if (!entry.value().equals(parseLogLevelFromAppenderCouple(desiredMap.get(entry.name())))) {\n-                        updateOrAdd(entry.name(), desiredMap, updatedCE);\n-                    }\n-                }\n-            } else {\n-                if (\"add\".equals(op)) {\n-                    // entry is not in the current, it is added\n-                    updateOrAdd(pathValueWithoutSlash, desiredMap, updatedCE);\n-                }\n-            }\n-            if (\"remove\".equals(op)) {\n-                // there is a lot of properties set by default - not having them in desired causes very noisy log output\n-                log.trace(\"Kafka Broker {} Logging Config Differs : {}\", brokerId, d);\n-                log.trace(\"Current Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(source, pathValue));\n-                log.trace(\"Desired Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(target, pathValue));\n-            } else {\n-                log.debug(\"Kafka Broker {} Logging Config Differs : {}\", brokerId, d);\n-                log.debug(\"Current Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(source, pathValue));\n-                log.debug(\"Desired Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(target, pathValue));\n+        for (ConfigEntry entry: brokerConfigs.entries()) {\n+            LoggingLevel desiredLevel;\n+            try {\n+                desiredLevel = levelResolver.resolveLevel(entry.name());\n+            } catch (IllegalArgumentException e) {\n+                log.warn(\"Skipping {} - it is configured with an unsupported value (\\\"{}\\\")\", entry.name(), e.getMessage());\n+                continue;\n             }\n-        }\n-        return updatedCE;\n-    }\n \n-    private static String parseLogLevelFromAppenderCouple(String level) {\n-        int index = level.indexOf(\",\");\n-        if (index > 0) {\n-            return level.substring(0, index).trim();\n-        } else {\n-            return level.trim();\n+            if (!desiredLevel.name().equals(entry.value())) {\n+                updatedCE.add(new AlterConfigOp(new ConfigEntry(entry.name(), desiredLevel.name()), AlterConfigOp.OpType.SET));\n+                log.trace(\"{} has a deprecated value. Setting to {}\", entry.name(), desiredLevel.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471"}, "originalPosition": 122}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1Mjg0MDEx", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-485284011", "createdAt": "2020-09-09T18:22:30Z", "commit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxODoyMjozMVrOHPUXLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxODoyMjozMVrOHPUXLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTgyNDMwMA==", "bodyText": "Wouldn't it better to use this name or am I missing some meaning of e? )\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        int e = name.length();\n          \n          \n            \n                        int loggingCategoryNameLength = name.length();", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#discussion_r485824300", "createdAt": "2020-09-09T18:22:31Z", "author": {"login": "see-quick"}, "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiff.java", "diffHunk": "@@ -68,115 +54,120 @@ public int getDiffSize() {\n         if (brokerConfigs == null || desired == null) {\n             return Collections.emptyList();\n         }\n-        Map<String, String> currentMap;\n+\n         Collection<AlterConfigOp> updatedCE = new ArrayList<>();\n-        currentMap = brokerConfigs.entries().stream().collect(\n-            Collectors.toMap(\n-                ConfigEntry::name,\n-                configEntry -> configEntry.value() == null ? \"null\" : configEntry.value()));\n \n         OrderedProperties orderedProperties = new OrderedProperties();\n         desired = desired.replaceAll(\"log4j\\\\.logger\\\\.\", \"\");\n         desired = desired.replaceAll(\"log4j\\\\.rootLogger\", \"root\");\n         orderedProperties.addStringPairs(desired);\n         Map<String, String> desiredMap = orderedProperties.asMap();\n \n-        ObjectMapper orderedMapper = patchMapper().configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true);\n-\n-        JsonNode source = orderedMapper.valueToTree(currentMap);\n-        JsonNode target = orderedMapper.valueToTree(desiredMap);\n-        JsonNode jsonDiff = JsonDiff.asJson(source, target);\n-\n-        for (JsonNode d : jsonDiff) {\n-            String pathValue = d.get(\"path\").asText();\n-            String pathValueWithoutSlash = pathValue.substring(1);\n+        LoggingLevelResolver levelResolver = new LoggingLevelResolver(desiredMap);\n \n-            Optional<ConfigEntry> optEntry = brokerConfigs.entries().stream()\n-                    .filter(configEntry -> configEntry.name().equals(pathValueWithoutSlash))\n-                    .findFirst();\n-\n-            if (pathValueWithoutSlash.equals(\"log4j.rootLogger\")) {\n-                if (!desiredMap.get(pathValueWithoutSlash).matches(\".+,.+\")) {\n-                    log.warn(\"Broker {} logging: Logger log4j.rootLogger should contain level and appender, e.g. \\'log4j.rootLogger = INFO, CONSOLE\\'\", brokerId);\n-                }\n-            }\n-            String op = d.get(\"op\").asText();\n-            if (optEntry.isPresent()) {\n-                ConfigEntry entry = optEntry.get();\n-                if (\"remove\".equals(op)) {\n-                    removeProperty(updatedCE, pathValueWithoutSlash, entry);\n-                } else if (\"replace\".equals(op)) {\n-                    // entry is in the current, desired is updated value\n-                    if (!entry.value().equals(parseLogLevelFromAppenderCouple(desiredMap.get(entry.name())))) {\n-                        updateOrAdd(entry.name(), desiredMap, updatedCE);\n-                    }\n-                }\n-            } else {\n-                if (\"add\".equals(op)) {\n-                    // entry is not in the current, it is added\n-                    updateOrAdd(pathValueWithoutSlash, desiredMap, updatedCE);\n-                }\n-            }\n-            if (\"remove\".equals(op)) {\n-                // there is a lot of properties set by default - not having them in desired causes very noisy log output\n-                log.trace(\"Kafka Broker {} Logging Config Differs : {}\", brokerId, d);\n-                log.trace(\"Current Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(source, pathValue));\n-                log.trace(\"Desired Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(target, pathValue));\n-            } else {\n-                log.debug(\"Kafka Broker {} Logging Config Differs : {}\", brokerId, d);\n-                log.debug(\"Current Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(source, pathValue));\n-                log.debug(\"Desired Kafka Broker Logging Config path {} has value {}\", pathValueWithoutSlash, lookupPath(target, pathValue));\n+        for (ConfigEntry entry: brokerConfigs.entries()) {\n+            LoggingLevel desiredLevel;\n+            try {\n+                desiredLevel = levelResolver.resolveLevel(entry.name());\n+            } catch (IllegalArgumentException e) {\n+                log.warn(\"Skipping {} - it is configured with an unsupported value (\\\"{}\\\")\", entry.name(), e.getMessage());\n+                continue;\n             }\n-        }\n-        return updatedCE;\n-    }\n \n-    private static String parseLogLevelFromAppenderCouple(String level) {\n-        int index = level.indexOf(\",\");\n-        if (index > 0) {\n-            return level.substring(0, index).trim();\n-        } else {\n-            return level.trim();\n+            if (!desiredLevel.name().equals(entry.value())) {\n+                updatedCE.add(new AlterConfigOp(new ConfigEntry(entry.name(), desiredLevel.name()), AlterConfigOp.OpType.SET));\n+                log.trace(\"{} has a deprecated value. Setting to {}\", entry.name(), desiredLevel.name());\n+            }\n         }\n-    }\n \n-    private static void updateOrAdd(String propertyName, Map<String, String> desiredMap, Collection<AlterConfigOp> updatedCE) {\n-        if (!propertyName.contains(\"log4j.appender\") && !propertyName.equals(\"monitorInterval\")) {\n-            String level = parseLogLevelFromAppenderCouple(desiredMap.get(propertyName));\n-            if (isValidLoggerLevel(level)) {\n-                updatedCE.add(new AlterConfigOp(new ConfigEntry(propertyName, level), AlterConfigOp.OpType.SET));\n-                log.trace(\"{} not set in current or has deprecated value. Setting to {}\", propertyName, level);\n-            } else {\n-                log.warn(\"Level {} is not valid logging level\", level);\n+        for (Map.Entry<String, String> ent: desiredMap.entrySet()) {\n+            String name = ent.getKey();\n+            if (name.startsWith(\"log4j.appender\")) {\n+                continue;\n+            }\n+            ConfigEntry configEntry = brokerConfigs.get(name);\n+            if (configEntry == null) {\n+                updatedCE.add(new AlterConfigOp(new ConfigEntry(name, ent.getValue()), AlterConfigOp.OpType.SET));\n+                log.trace(\"{} not set. Setting to {}\", name, ent.getValue());\n             }\n         }\n-    }\n \n-    /**\n-     * All loggers can be set dynamically. If the logger is not set in desire, set it to ERROR. Loggers with already set to ERROR should be skipped.\n-     * ERROR is set as inactive because log4j does not support OFF logger value.\n-     * We want to skip \"root\" logger as well to avoid duplicated key in alterConfigOps collection.\n-     * @param alterConfigOps collection of AlterConfigOp\n-     * @param pathValueWithoutSlash name of \"removed\" logger\n-     * @param entry entry to be removed (set to ERROR)\n-     */\n-    private static void removeProperty(Collection<AlterConfigOp> alterConfigOps, String pathValueWithoutSlash, ConfigEntry entry) {\n-        if (!pathValueWithoutSlash.contains(\"log4j.appender\") && !pathValueWithoutSlash.equals(\"root\") && !\"ERROR\".equals(entry.value())) {\n-            alterConfigOps.add(new AlterConfigOp(new ConfigEntry(pathValueWithoutSlash, \"ERROR\"), AlterConfigOp.OpType.SET));\n-            log.trace(\"{} not set in desired, setting to ERROR\", entry.name());\n-        }\n+        return updatedCE;\n     }\n \n     /**\n      * @return whether the current config and the desired config are identical (thus, no update is necessary).\n      */\n     @Override\n     public boolean isEmpty() {\n-        return  diff.size() == 0;\n+        return diff.size() == 0;\n     }\n \n-    private static boolean isValidLoggerLevel(String level) {\n-        return VALID_LOGGER_LEVELS.contains(level);\n+    /**\n+     * This internal class calculates the logging level of an arbitrary category based on the logging configuration.\n+     *\n+     * It takes Log4j properties configuration in the form of a map of key:value pairs,\n+     * where key is the category name, and the value is whatever comes to the right of '=' sign in log4j.properties,\n+     * which is either a logging level, or a logging level followed by a comma, and followed by the appender name.\n+     */\n+    static class LoggingLevelResolver {\n+\n+        private final Map<String, String> config;\n+\n+        LoggingLevelResolver(Map<String, String> loggingConfig) {\n+            this.config = loggingConfig;\n+        }\n+\n+        /**\n+         * The method that returns the logging level of the category\n+         * based on logging configuration, taking inheritance into account.\n+         *\n+         * For example, if looking for a logging level for 'io.strimzi.kafka.oauth.server.OAuthKafkaPrincipalBuilder',\n+         * the following configuration lookups are performed until one is found:\n+         * <ul>\n+         *     <li>io.strimzi.kafka.oauth.server.OAuthKafkaPrincipalBuilder</li>\n+         *     <li>io.strimzi.kafka.oauth.server</li>\n+         *     <li>io.strimzi.kafka.oauth</li>\n+         *     <li>io.strimzi.kafka</li>\n+         *     <li>io.strimzi</li>\n+         *     <li>io</li>\n+         *     <li>root</li>\n+         * </ul>\n+         *\n+         * @param name The logging category name\n+         * @return The logging level\n+         */\n+        LoggingLevel resolveLevel(String name) {\n+            String level = config.get(name);\n+            if (level != null) {\n+                return LoggingLevel.valueOf(level.split(\",\")[0]);\n+            }\n+\n+            int e = name.length();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471"}, "originalPosition": 215}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3d16b8ab8353a91b4afb33288e679cc19765f79", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c3d16b8ab8353a91b4afb33288e679cc19765f79", "committedDate": "2020-09-10T11:55:30Z", "message": "Fix detection and application of logging changes\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c4c76afc4fa5b68d575bf04fc36ad8fcf8733ba", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9c4c76afc4fa5b68d575bf04fc36ad8fcf8733ba", "committedDate": "2020-09-10T11:55:30Z", "message": "Redundant local variable\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "387c8ce6d21910b2a28e97eeeeb19a280a5a48c6", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/387c8ce6d21910b2a28e97eeeeb19a280a5a48c6", "committedDate": "2020-09-10T11:55:30Z", "message": "Handle invalid logging levels during configuration sync\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b56c352669e99b48e5976eab986680cf0bcd615b", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b56c352669e99b48e5976eab986680cf0bcd615b", "committedDate": "2020-09-10T11:55:30Z", "message": "Javadoc and a little code cleanup\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10f5789dcf94bf643d97b52c80597fe38dafa4f4", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/10f5789dcf94bf643d97b52c80597fe38dafa4f4", "committedDate": "2020-09-10T20:03:01Z", "message": "Add unit test and make some improvements\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "72840982cd84f847fa9ce19face0f747320b3471", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/72840982cd84f847fa9ce19face0f747320b3471", "committedDate": "2020-09-07T13:28:41Z", "message": "Javadoc and a little code cleanup\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}, "afterCommit": {"oid": "10f5789dcf94bf643d97b52c80597fe38dafa4f4", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/10f5789dcf94bf643d97b52c80597fe38dafa4f4", "committedDate": "2020-09-10T20:03:01Z", "message": "Add unit test and make some improvements\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ff1e94f0a49ddbd98497fa466d88c18628a62d0", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9ff1e94f0a49ddbd98497fa466d88c18628a62d0", "committedDate": "2020-09-11T06:40:11Z", "message": "Fix build failures due to used undeclared dependencies\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40f4310ca48f8172ae094ee42766ab0e008d5654", "author": {"user": {"login": "mstruk", "name": "Marko Strukelj"}}, "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/40f4310ca48f8172ae094ee42766ab0e008d5654", "committedDate": "2020-09-11T09:06:44Z", "message": "Fix checkstyle issues\n\nSigned-off-by: Marko Strukelj <marko.strukelj@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3MDMyODc2", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3606#pullrequestreview-487032876", "createdAt": "2020-09-11T18:31:24Z", "commit": {"oid": "40f4310ca48f8172ae094ee42766ab0e008d5654"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 945, "cost": 1, "resetAt": "2021-10-28T19:08:13Z"}}}