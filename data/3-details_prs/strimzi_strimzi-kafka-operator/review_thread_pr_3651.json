{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3MzU5Njcw", "number": 3651, "reviewThreads": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOToxNFrOEkmatg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzo1OTozOFrOEroNog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2ODEzNjIyOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOToxNFrOHToqXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOToxNFrOHToqXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTE5OA==", "bodyText": "this will be removed because Route or Ingress type listener requires enabled TLS encryption", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r490351198", "createdAt": "2020-09-17T15:39:14Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.kafkaclients.AbstractKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicClientResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.DynamicTest;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    private ProducerProperties producerProperties;\n+    private ConsumerProperties consumerProperties;\n+\n+    @TestFactory\n+    Iterator<DynamicTest> testMultipleListeners() {\n+\n+        List<DynamicTest> dynamicTests = new ArrayList<>(10);\n+        List<List<GenericKafkaListener>> testCases = generateTestCases();\n+\n+        testCases.forEach(listener -> dynamicTests.add(DynamicTest.dynamicTest(\"Test \" + listener.get(0).getType() + \" with count of \" + listener.size(), () -> {\n+            // TODO: profiling...assume for profiles NODE_PORT, LOAD_BALANCER, ROUTE...\n+\n+            // exercise phase\n+            KafkaResource.kafkaPersistent(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewListeners()\n+                .withGenericKafkaListeners(listener)\n+                .endListeners()\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+            KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+\n+            if (listener.get(0).getType() != KafkaListenerType.INTERNAL) {\n+                // using external clients\n+                producerProperties = new ProducerProperties.ProducerPropertiesBuilder()\n+                    .withNamespaceName(NAMESPACE)\n+                    .withClusterName(CLUSTER_NAME)\n+                    .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME))\n+                    .withKeySerializerConfig(StringSerializer.class)\n+                    .withValueSerializerConfig(StringSerializer.class)\n+                    .withClientIdConfig(\"producer-plain-\" + new Random().nextInt(Integer.MAX_VALUE))\n+                    .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                    .withSharedProperties()\n+                    .build();\n+\n+                consumerProperties = new ConsumerProperties.ConsumerPropertiesBuilder()\n+                    .withNamespaceName(NAMESPACE)\n+                    .withClusterName(CLUSTER_NAME)\n+                    .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME))\n+                    .withKeyDeserializerConfig(StringDeserializer.class)\n+                    .withValueDeserializerConfig(StringDeserializer.class)\n+                    .withClientIdConfig(\"consumer-plain-\" + new Random().nextInt(Integer.MAX_VALUE))\n+                    .withGroupIdConfig(\"consumer-group-test\")\n+                    .withAutoOffsetResetConfig(OffsetResetStrategy.EARLIEST)\n+                    .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                    .withSharedProperties()\n+                    .build();\n+\n+                // verify phase\n+\n+                for (int i = 0; i < listener.size() - 1; i++) {\n+\n+                    KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+\n+                    BasicExternalKafkaClient clientForExternal1 = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(TOPIC_NAME)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withProducerProperties(producerProperties)\n+                        .withConsumerProperties(consumerProperties)\n+                        .build();\n+\n+                    // verify phase\n+                    clientForExternal1.verifyProducedAndConsumedMessages(\n+                        clientForExternal1.sendMessagesPlain(),\n+                        clientForExternal1.receiveMessagesPlain()\n+                    );\n+\n+                    BasicExternalKafkaClient clientForExternal2 = clientForExternal1.toBuilder(clientForExternal1)\n+                        .withProducerProperties(\n+                            producerProperties.toBuilder(producerProperties)\n+                                .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME, listener.get(i + 1).getName()))\n+                                .build())\n+                        .withConsumerProperties(\n+                            consumerProperties.toBuilder(consumerProperties)\n+                                .withBootstrapServerConfig(AbstractKafkaClient.getExternalBootstrapConnect(NAMESPACE, CLUSTER_NAME, listener.get(i + 1).getName()))\n+                                .build())\n+                        .build();\n+\n+                    // verify phase\n+                    clientForExternal2.verifyProducedAndConsumedMessages(\n+                        clientForExternal2.sendMessagesPlain(),\n+                        clientForExternal2.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                for (int i = 0; i < listener.size() - 1; i++) {\n+\n+                    // exercise phase\n+                    final String producerName =  \"producer-name\";\n+                    final String consumerName  = \"consumer-name\";\n+\n+                    // tls or plain\n+                    KafkaBasicClientResource kafkaBasicClientJob = listener.get(i).isTls() ? new KafkaBasicClientResource(producerName, consumerName,\n+                        KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), TOPIC_NAME, MESSAGE_COUNT, \"\", ClientUtils.generateRandomConsumerGroup(), 1000) :\n+                        new KafkaBasicClientResource(producerName, consumerName,\n+                            KafkaResources.plainBootstrapAddress(CLUSTER_NAME), TOPIC_NAME, MESSAGE_COUNT, \"\", ClientUtils.generateRandomConsumerGroup(), 1000);\n+\n+                    kafkaBasicClientJob.producerStrimzi().done();\n+                    kafkaBasicClientJob.consumerStrimzi().done();\n+\n+                    // verify phase\n+                    ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n+                    ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n+\n+\n+                    LOGGER.info(\"Deleting the Jobs\");\n+                    // teardown (for clients)\n+                    JobUtils.deleteJobWithWait(NAMESPACE, producerName);\n+                    JobUtils.deleteJobWithWait(NAMESPACE, consumerName);\n+                }\n+            }\n+        })));\n+        return dynamicTests.iterator();\n+    }\n+\n+    private List<List<GenericKafkaListener>> generateTestCases() {\n+\n+        List<List<GenericKafkaListener>> testCases = new ArrayList<>(10);\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        for (int i = 0; i < 10; i++) {\n+\n+            KafkaListenerType stochasticChosenListener = KafkaListenerType.values()[ThreadLocalRandom.current().nextInt(0, KafkaListenerType.values().length - 1)];\n+            List<GenericKafkaListener> testCase = new ArrayList<>(5);\n+            int stochasticCount;\n+\n+            switch (stochasticChosenListener) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCase.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(6090 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCase.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(7090 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "367b5a51f2efa338c51913db8ee031a377f00cf6"}, "originalPosition": 213}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5Nzc5OTY3OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaResources.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjowOTo1NlrOHYA-rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxNzo0MzozNFrOHYM61Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0MzkxNw==", "bodyText": "I'm not sure I think we really need this here.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494943917", "createdAt": "2020-09-25T12:09:56Z", "author": {"login": "scholzj"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaResources.java", "diffHunk": "@@ -138,6 +138,19 @@ public static String tlsBootstrapAddress(String clusterName) {\n         return bootstrapServiceName(clusterName) + \":9093\";\n     }\n \n+    /**\n+     * Returns the address (<em>&lt;host&gt;</em>:<em>&lt;port&gt;</em>)\n+     * of the generic bootstrap {@code Service} for a {@code Kafka} cluster, and {@code port} of the given.\n+     * @param clusterName  The {@code metadata.name} of the {@code Kafka} resource.\n+     * @param port The {@code spec.kafka.listeners.port} of the {@code Kafka} resource.\n+     * @return The address of the corresponding bootstrap {@code Service}.\n+     * @see #plainBootstrapAddress(String)\n+     * @see #tlsBootstrapAddress(String)\n+     */\n+    public static String bootstrapAddressOnSpecificPort(String clusterName, int port) {\n+        return bootstrapServiceName(clusterName) + \":\" + port;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEzOTU0MQ==", "bodyText": "Ok I will remove it.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r495139541", "createdAt": "2020-09-25T17:43:34Z", "author": {"login": "see-quick"}, "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaResources.java", "diffHunk": "@@ -138,6 +138,19 @@ public static String tlsBootstrapAddress(String clusterName) {\n         return bootstrapServiceName(clusterName) + \":9093\";\n     }\n \n+    /**\n+     * Returns the address (<em>&lt;host&gt;</em>:<em>&lt;port&gt;</em>)\n+     * of the generic bootstrap {@code Service} for a {@code Kafka} cluster, and {@code port} of the given.\n+     * @param clusterName  The {@code metadata.name} of the {@code Kafka} resource.\n+     * @param port The {@code spec.kafka.listeners.port} of the {@code Kafka} resource.\n+     * @return The address of the corresponding bootstrap {@code Service}.\n+     * @see #plainBootstrapAddress(String)\n+     * @see #tlsBootstrapAddress(String)\n+     */\n+    public static String bootstrapAddressOnSpecificPort(String clusterName, int port) {\n+        return bootstrapServiceName(clusterName) + \":\" + port;\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0MzkxNw=="}, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NzgxMTIwOnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxMzo0MFrOHYBFmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxMzo0MFrOHYBFmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NTY5MA==", "bodyText": "When you deploy Kafka, the bootstrap addresses for all listeners get filled in the status section. Is there any actual reason why you need to reverse engineer the address here instead of reading it simply from the status? All you would need is a listener name, you would not need to both with OpenShfit, service types etc.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494945690", "createdAt": "2020-09-25T12:13:40Z", "author": {"login": "scholzj"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "diffHunk": "@@ -142,48 +170,67 @@ public void verifyProducedAndConsumedMessages(int producedMessages, int consumed\n      * Get external bootstrap connection\n      * @param namespace kafka namespace\n      * @param clusterName kafka cluster name\n+     * @param listenerName name of the listener\n      * @return bootstrap url as string\n      */\n-    public static String getExternalBootstrapConnect(String namespace, String clusterName) {\n+    @SuppressWarnings(\"Regexp\") // because of extBootstrapService.getSpec().getType().toLowerCase()\n+    @SuppressFBWarnings(\"DM_CONVERT_CASE\")\n+    public static String getExternalBootstrapConnect(String namespace, String clusterName, String listenerName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NzgxOTMxOnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNjowOVrOHYBKeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjozMToyM1rOHYBpIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NjkzNg==", "bodyText": "Aren't we removing this in the other PRs? Please check with @stanlyDoge and @mstruk. It is IIRC also not what the docs suggest ... we should primarily follow our docs to make sure the docs are valid and test them this way as well.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494946936", "createdAt": "2020-09-25T12:16:09Z", "author": {"login": "scholzj"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java", "diffHunk": "@@ -169,7 +169,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl\n                         .endGenericKafkaListener()\n                     .endListeners()\n                     .withNewInlineLogging()\n-                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG\")\n+                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG, CONSOLE\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1MjYwMw==", "bodyText": "Leftover, when I was debugging some issues.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494952603", "createdAt": "2020-09-25T12:27:14Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java", "diffHunk": "@@ -169,7 +169,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl\n                         .endGenericKafkaListener()\n                     .endListeners()\n                     .withNewInlineLogging()\n-                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG\")\n+                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG, CONSOLE\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NjkzNg=="}, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDc4Ng==", "bodyText": "PR fixing this is not merged yet #3672", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494954786", "createdAt": "2020-09-25T12:31:23Z", "author": {"login": "sknot-rh"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java", "diffHunk": "@@ -169,7 +169,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl\n                         .endGenericKafkaListener()\n                     .endListeners()\n                     .withNewInlineLogging()\n-                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG\")\n+                        .addToLoggers(\"log4j.rootLogger\", \"DEBUG, CONSOLE\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0NjkzNg=="}, "originalCommit": {"oid": "0f2dca7fcdf599a854c13e5aa5669afe961f6982"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5NzgyNDg0OnYy", "diffSide": "LEFT", "path": "systemtest/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNzo1M1rOHYBN0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoxNzo1M1rOHYBN0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk0Nzc5Mg==", "bodyText": "Removing because these dependencies are un-used in systemtest module", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494947792", "createdAt": "2020-09-25T12:17:53Z", "author": {"login": "see-quick"}, "path": "systemtest/pom.xml", "diffHunk": "@@ -38,14 +38,6 @@\n             <groupId>org.apache.logging.log4j</groupId>\n             <artifactId>log4j-api</artifactId>\n         </dependency>\n-        <dependency>\n-            <groupId>org.apache.logging.log4j</groupId>\n-            <artifactId>log4j-core</artifactId>\n-        </dependency>\n-        <dependency>\n-            <groupId>org.apache.logging.log4j</groupId>\n-            <artifactId>log4j-slf4j-impl</artifactId>\n-        </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5Nzg1MzUzOnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjoyNjozM1rOHYBfAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNlQxNToxOTowOFrOHYg38w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1MjE5NA==", "bodyText": "I guess we discussed this when I was working on the example clients builder but -> isn't there some way how to just set the \"properties\" that are specific for Oauth external clients here and the others set in the Abstract? I know that there can be some dependency (etc.) issues, but still asking...", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494952194", "createdAt": "2020-09-25T12:26:33Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java", "diffHunk": "@@ -81,6 +82,29 @@ protected Builder self() {\n         }\n     }\n \n+    @Override\n+    public AbstractKafkaClient.Builder<OauthExternalKafkaClient.Builder> toBuilder(OauthExternalKafkaClient oauthExternalKafkaClient) {\n+        OauthExternalKafkaClient.Builder builder = new OauthExternalKafkaClient.Builder();\n+\n+        builder.withTopicName(oauthExternalKafkaClient.getTopicName());\n+        builder.withPartition(oauthExternalKafkaClient.getPartition());\n+        builder.withMessageCount(oauthExternalKafkaClient.getMessageCount());\n+        builder.withNamespaceName(oauthExternalKafkaClient.getNamespaceName());\n+        builder.withClusterName(oauthExternalKafkaClient.getClusterName());\n+        builder.withConsumerGroupName(oauthExternalKafkaClient.getConsumerGroup());\n+        builder.withKafkaUsername(oauthExternalKafkaClient.getKafkaUsername());\n+        builder.withSecurityProtocol(oauthExternalKafkaClient.getSecurityProtocol());\n+        builder.withCertificateAuthorityCertificateName(oauthExternalKafkaClient.getCaCertName());\n+        builder.withProducerProperties(oauthExternalKafkaClient.getProducerProperties());\n+        builder.withConsumerProperties(oauthExternalKafkaClient.getConsumerProperties());\n+        builder.withOauthClientId(oauthExternalKafkaClient.getClientId());\n+        builder.withClientSecretName(oauthExternalKafkaClient.getClientSecretName());\n+        builder.withOauthTokenEndpointUri(oauthExternalKafkaClient.getOauthTokenEndpointUri());\n+        builder.withIntrospectionEndpointUri(oauthExternalKafkaClient.getIntrospectionEndpointUri());\n+\n+        return builder;\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEzNDQxNg==", "bodyText": "Thanks for catch, I have re-designed it a little bit and now in the client will not be a redundant code.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r495134416", "createdAt": "2020-09-25T17:33:00Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java", "diffHunk": "@@ -81,6 +82,29 @@ protected Builder self() {\n         }\n     }\n \n+    @Override\n+    public AbstractKafkaClient.Builder<OauthExternalKafkaClient.Builder> toBuilder(OauthExternalKafkaClient oauthExternalKafkaClient) {\n+        OauthExternalKafkaClient.Builder builder = new OauthExternalKafkaClient.Builder();\n+\n+        builder.withTopicName(oauthExternalKafkaClient.getTopicName());\n+        builder.withPartition(oauthExternalKafkaClient.getPartition());\n+        builder.withMessageCount(oauthExternalKafkaClient.getMessageCount());\n+        builder.withNamespaceName(oauthExternalKafkaClient.getNamespaceName());\n+        builder.withClusterName(oauthExternalKafkaClient.getClusterName());\n+        builder.withConsumerGroupName(oauthExternalKafkaClient.getConsumerGroup());\n+        builder.withKafkaUsername(oauthExternalKafkaClient.getKafkaUsername());\n+        builder.withSecurityProtocol(oauthExternalKafkaClient.getSecurityProtocol());\n+        builder.withCertificateAuthorityCertificateName(oauthExternalKafkaClient.getCaCertName());\n+        builder.withProducerProperties(oauthExternalKafkaClient.getProducerProperties());\n+        builder.withConsumerProperties(oauthExternalKafkaClient.getConsumerProperties());\n+        builder.withOauthClientId(oauthExternalKafkaClient.getClientId());\n+        builder.withClientSecretName(oauthExternalKafkaClient.getClientSecretName());\n+        builder.withOauthTokenEndpointUri(oauthExternalKafkaClient.getOauthTokenEndpointUri());\n+        builder.withIntrospectionEndpointUri(oauthExternalKafkaClient.getIntrospectionEndpointUri());\n+\n+        return builder;\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1MjE5NA=="}, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTQ2NjQ4Mw==", "bodyText": "Thanks a lot :)", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r495466483", "createdAt": "2020-09-26T15:19:08Z", "author": {"login": "im-konge"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java", "diffHunk": "@@ -81,6 +82,29 @@ protected Builder self() {\n         }\n     }\n \n+    @Override\n+    public AbstractKafkaClient.Builder<OauthExternalKafkaClient.Builder> toBuilder(OauthExternalKafkaClient oauthExternalKafkaClient) {\n+        OauthExternalKafkaClient.Builder builder = new OauthExternalKafkaClient.Builder();\n+\n+        builder.withTopicName(oauthExternalKafkaClient.getTopicName());\n+        builder.withPartition(oauthExternalKafkaClient.getPartition());\n+        builder.withMessageCount(oauthExternalKafkaClient.getMessageCount());\n+        builder.withNamespaceName(oauthExternalKafkaClient.getNamespaceName());\n+        builder.withClusterName(oauthExternalKafkaClient.getClusterName());\n+        builder.withConsumerGroupName(oauthExternalKafkaClient.getConsumerGroup());\n+        builder.withKafkaUsername(oauthExternalKafkaClient.getKafkaUsername());\n+        builder.withSecurityProtocol(oauthExternalKafkaClient.getSecurityProtocol());\n+        builder.withCertificateAuthorityCertificateName(oauthExternalKafkaClient.getCaCertName());\n+        builder.withProducerProperties(oauthExternalKafkaClient.getProducerProperties());\n+        builder.withConsumerProperties(oauthExternalKafkaClient.getConsumerProperties());\n+        builder.withOauthClientId(oauthExternalKafkaClient.getClientId());\n+        builder.withClientSecretName(oauthExternalKafkaClient.getClientSecretName());\n+        builder.withOauthTokenEndpointUri(oauthExternalKafkaClient.getOauthTokenEndpointUri());\n+        builder.withIntrospectionEndpointUri(oauthExternalKafkaClient.getIntrospectionEndpointUri());\n+\n+        return builder;\n+    }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1MjE5NA=="}, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5Nzg3MTU2OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjozMTozOVrOHYBpoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNlQxNToyMDoxNFrOHYg4YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDkxMg==", "bodyText": "Maybe different name?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494954912", "createdAt": "2020-09-25T12:31:39Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk3OTM2Ng==", "bodyText": "Maybe suggest something?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494979366", "createdAt": "2020-09-25T13:15:55Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDkxMg=="}, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTQ2NjU5Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void runTestCase(List<GenericKafkaListener> listeners) {\n          \n          \n            \n                private void runMultipleListenersTest(List<GenericKafkaListener> listeners) {\n          \n      \n    \n    \n  \n\nor\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void runTestCase(List<GenericKafkaListener> listeners) {\n          \n          \n            \n                private void runListenersTest(List<GenericKafkaListener> listeners) {", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r495466592", "createdAt": "2020-09-26T15:20:14Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDkxMg=="}, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5Nzg4NTkwOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjozNTo0NVrOHYByGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxMjozNTo0NVrOHYByGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NzA4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        List<GenericKafkaListener> testCase = new ArrayList<>(5);\n          \n          \n            \n                        List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n          \n      \n    \n    \n  \n\n?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r494957081", "createdAt": "2020-09-25T12:35:45Z", "author": {"login": "im-konge"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multiple-listeners-cluster-test\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runTestCase(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runTestCase(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runTestCase(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runTestCase(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runTestCase(multipleDifferentListeners);\n+    }\n+\n+    private void runTestCase(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .build();\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                            .withUsingPodName(kafkaClientsTlsPodName)\n+                            .withBootstrapServer(KafkaResources.bootstrapAddressOnSpecificPort(CLUSTER_NAME, listener.getPort()))\n+                            .withTopicName(topicName)\n+                            .withNamespaceName(NAMESPACE)\n+                            .withClusterName(CLUSTER_NAME)\n+                            .withKafkaUsername(kafkaUsername)\n+                            .withMessageCount(MESSAGE_COUNT)\n+                            .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withBootstrapServer(KafkaResources.bootstrapAddressOnSpecificPort(CLUSTER_NAME, listener.getPort()))\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCase = new ArrayList<>(5);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "87b7dd94984d63ac09dceb2bb1d75ba7db83b13a"}, "originalPosition": 257}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMDc1MzEyOnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxODo1MVrOHbZfqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxODo1MVrOHbZfqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5MTMwNw==", "bodyText": "Why is this needed? You should use it like this  .toLowerCase(Locale.ENGLISH) I think you can remove DM_CONVERT_CASE as well after the change.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498491307", "createdAt": "2020-10-01T20:18:51Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ConsumerProperties extends AbstractKafkaClientProperties<ConsumerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ConsumerProperties.class);\n+\n+    public static class ConsumerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ConsumerPropertiesBuilder> {\n+\n+        public ConsumerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withKeyDeserializerConfig(Class<? extends Deserializer> keyDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keyDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withValueDeserializerConfig(Class<? extends Deserializer> valueDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withGroupIdConfig(String groupIdConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupIdConfig);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        @SuppressWarnings(\"Regexp\") // for the `.toLowerCase()` because kafka needs this property as lower-case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMDc1NDUxOnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxOToxOFrOHbZghA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoxOToxOFrOHbZghA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5MTUyNA==", "bodyText": "Same here", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498491524", "createdAt": "2020-10-01T20:19:18Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ConsumerProperties.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ConsumerProperties extends AbstractKafkaClientProperties<ConsumerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ConsumerProperties.class);\n+\n+    public static class ConsumerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ConsumerPropertiesBuilder> {\n+\n+        public ConsumerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withKeyDeserializerConfig(Class<? extends Deserializer> keyDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keyDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withValueDeserializerConfig(Class<? extends Deserializer> valueDeSerializer) {\n+\n+            this.properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer.getName());\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withGroupIdConfig(String groupIdConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupIdConfig);\n+            return this;\n+        }\n+\n+        public ConsumerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        @SuppressWarnings(\"Regexp\") // for the `.toLowerCase()` because kafka needs this property as lower-case\n+        @SuppressFBWarnings(\"DM_CONVERT_CASE\")\n+        public ConsumerPropertiesBuilder withAutoOffsetResetConfig(OffsetResetStrategy offsetResetConfig) {\n+\n+            this.properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, offsetResetConfig.name().toLowerCase());\n+            return this;\n+        }\n+\n+        @Override\n+        public ConsumerProperties build() {\n+            return new ConsumerProperties(this);\n+        }\n+\n+        @Override\n+        protected ConsumerPropertiesBuilder self() {\n+            return this;\n+        }\n+    }\n+\n+    private ConsumerProperties(ConsumerPropertiesBuilder builder) {\n+        super(builder);\n+        properties = builder.properties;\n+    }\n+\n+    @Override\n+    @SuppressWarnings({\"Regexp\", \"unchecked\"}) // for the `.toUpperCase()` because OffsetStrategy needs to be upper-case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEyMDc2ODc3OnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ProducerProperties.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoyNDozOFrOHbZqDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMVQyMDoyNDozOFrOHbZqDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mzk2NQ==", "bodyText": "debug?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r498493965", "createdAt": "2020-10-01T20:24:38Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clientproperties/ProducerProperties.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafkaclients.clientproperties;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.kafka.common.serialization.Serializer;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+public class ProducerProperties extends AbstractKafkaClientProperties<ProducerProperties> {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ProducerProperties.class);\n+    private static final String DEFAULT_MAX_BLOG_MS_CONFIG = \"6000\"; // 60 * 100\n+    private static final String DEFAULT_ACKS_CONFIG = \"1\";\n+\n+    public static class ProducerPropertiesBuilder extends AbstractKafkaClientProperties.KafkaClientPropertiesBuilder<ProducerPropertiesBuilder> {\n+\n+        public ProducerPropertiesBuilder withBootstrapServerConfig(String bootstrapServer) {\n+\n+            this.properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withKeySerializerConfig(Class<? extends Serializer> keySerializer) {\n+\n+            this.properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, keySerializer.getName());\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withValueSerializerConfig(Class<? extends Serializer> valueSerializer) {\n+\n+            this.properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, valueSerializer.getName());\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withMaxBlockMsConfig(String maxBlockMsConfig) {\n+\n+            this.properties.setProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG, maxBlockMsConfig);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withClientIdConfig(String clientId) {\n+\n+            this.properties.setProperty(ProducerConfig.CLIENT_ID_CONFIG, clientId);\n+            return this;\n+        }\n+\n+        public ProducerPropertiesBuilder withAcksConfig(String acksConfig) {\n+\n+            this.properties.setProperty(ProducerConfig.ACKS_CONFIG, acksConfig);\n+            return this;\n+        }\n+\n+        @Override\n+        public ProducerProperties build() {\n+            return new ProducerProperties(this);\n+        }\n+\n+        @Override\n+        protected ProducerPropertiesBuilder self() {\n+            return this;\n+        }\n+    }\n+\n+    private ProducerProperties(ProducerPropertiesBuilder builder) {\n+        super(builder);\n+\n+        if (builder.properties.getProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG) == null || builder.properties.getProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG).isEmpty()) {\n+            LOGGER.info(\"Setting default value of {} to {}\", ProducerConfig.MAX_BLOCK_MS_CONFIG, DEFAULT_MAX_BLOG_MS_CONFIG);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdda971531b55bacfb4b4eb72c8718f9bc5dc3f2"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ0NzY0OnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxMDoxOFrOHeS0pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwOTowOToyNFrOHeVGag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUyNzcxNg==", "bodyText": "I'm guessing this is because the fluent pattern on the builder with each method having to cast (SELF) this results in lots of warnings. It is best to use @SuppressWarnings on the smallest scope possible, so that genuine warnings are not suppressed accidentally. But you understandably don't want to have to annotate each method, so the solution is to write a method self() does the cast and is annotated, then all the rest get to return self(); and not needing annotating. Basically the rule of thumb is always to refactor you untypesafe code into a method and annotate just that method.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501527716", "createdAt": "2020-10-08T08:10:18Z", "author": {"login": "tombentley"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "diffHunk": "@@ -4,21 +4,20 @@\n  */\n package io.strimzi.systemtest.kafkaclients;\n \n-import io.fabric8.kubernetes.api.model.LoadBalancerIngress;\n-import io.fabric8.kubernetes.api.model.Service;\n-import io.fabric8.openshift.api.model.Route;\n-import io.fabric8.openshift.client.OpenShiftClient;\n+import io.strimzi.api.kafka.model.status.ListenerStatus;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.security.InvalidParameterException;\n+import java.util.List;\n \n-import static io.strimzi.api.kafka.model.KafkaResources.externalBootstrapServiceName;\n-import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n-\n-public abstract class AbstractKafkaClient {\n+@SuppressWarnings(\"unchecked\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTU2NTAzNA==", "bodyText": "Yeah, make sense thanks.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501565034", "createdAt": "2020-10-08T09:09:24Z", "author": {"login": "see-quick"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java", "diffHunk": "@@ -4,21 +4,20 @@\n  */\n package io.strimzi.systemtest.kafkaclients;\n \n-import io.fabric8.kubernetes.api.model.LoadBalancerIngress;\n-import io.fabric8.kubernetes.api.model.Service;\n-import io.fabric8.openshift.api.model.Route;\n-import io.fabric8.openshift.client.OpenShiftClient;\n+import io.strimzi.api.kafka.model.status.ListenerStatus;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;\n+import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.security.InvalidParameterException;\n+import java.util.List;\n \n-import static io.strimzi.api.kafka.model.KafkaResources.externalBootstrapServiceName;\n-import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n-\n-public abstract class AbstractKafkaClient {\n+@SuppressWarnings(\"unchecked\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUyNzcxNg=="}, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ2ODY4OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxNTo0OVrOHeTBmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxNTo0OVrOHeTBmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMTAzMg==", "bodyText": "Probably best to have a consistent order for the annotations, and not split annotations of the same type.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501531032", "createdAt": "2020-10-08T08:15:49Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ3NTExOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxNzozMVrOHeTFfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxNzozMVrOHeTFfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMjAzMQ==", "bodyText": "The two branches of this if look very similar.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501532031", "createdAt": "2020-10-08T08:17:31Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ4MjA1OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxOTozNFrOHeTJ1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjoyMDoxMVrOHeb1qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE0MQ==", "bodyText": "Why not a random number of routes?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533141", "createdAt": "2020-10-08T08:19:34Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTU2NzMyOA==", "bodyText": "That's an issue with the multiple routes we spoke with @scholzj (related with DNS) I don't know it is already resolved.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501567328", "createdAt": "2020-10-08T09:13:02Z", "author": {"login": "see-quick"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE0MQ=="}, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 300}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY3NTQzNQ==", "bodyText": "It is not related to DNS - this was the bug with unique ports per listener which should be fixed now in Kafka 2.7.0 - you should leave there some comment / TODO to add it later.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501675435", "createdAt": "2020-10-08T12:20:11Z", "author": {"login": "scholzj"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE0MQ=="}, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 300}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ4MjE4OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxOTozNlrOHeTJ7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoxOTozNlrOHeTJ7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzE2Ng==", "bodyText": "Deserves some javadoc to explain what this is doing.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533166", "createdAt": "2020-10-08T08:19:36Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 256}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ4NDUzOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyMDowOVrOHeTLbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyMDowOVrOHeTLbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzU0OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    LOGGER.info(\"Finished will generation of test cases for multiple listeners\");\n          \n          \n            \n                    LOGGER.info(\"Finished with generation of test cases for multiple listeners\");\n          \n      \n    \n    \n  \n\nand maybe log the listeners generated, if it's not logged elsewhere?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533548", "createdAt": "2020-10-08T08:20:09Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                        .withName(generateRandomListenerName())\n+                        .withPort(12091)\n+                        .withType(KafkaListenerType.ROUTE)\n+                        // Route or Ingress type listener and requires enabled TLS encryption\n+                        .withTls(true)\n+                        .build());\n+                    break;\n+                case INTERNAL:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 4);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(13900 + j)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+            }\n+            testCases.put(kafkaListenerType, testCaseListeners);\n+        }\n+\n+        LOGGER.info(\"Finished will generation of test cases for multiple listeners\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 326}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDQ4NjcxOnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyMDo0MlrOHeTMyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyMDo0MlrOHeTMyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzMzg5OA==", "bodyText": "You could perhaps reuse the PasswordGenerator we have somewhere?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501533898", "createdAt": "2020-10-08T08:20:42Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(10900 + j)\n+                            .withType(KafkaListenerType.NODEPORT)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case LOADBALANCER:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 3);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(11900 + j)\n+                            .withType(KafkaListenerType.LOADBALANCER)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+                    break;\n+                case ROUTE:\n+                    testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                        .withName(generateRandomListenerName())\n+                        .withPort(12091)\n+                        .withType(KafkaListenerType.ROUTE)\n+                        // Route or Ingress type listener and requires enabled TLS encryption\n+                        .withTls(true)\n+                        .build());\n+                    break;\n+                case INTERNAL:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 4);\n+\n+                    for (int j = 0; j < stochasticCount; j++) {\n+\n+                        boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;\n+\n+                        testCaseListeners.add(new GenericKafkaListenerBuilder()\n+                            .withName(generateRandomListenerName())\n+                            .withPort(13900 + j)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(stochasticCommunication)\n+                            .build());\n+                    }\n+            }\n+            testCases.put(kafkaListenerType, testCaseListeners);\n+        }\n+\n+        LOGGER.info(\"Finished will generation of test cases for multiple listeners\");\n+\n+        return testCases;\n+    }\n+\n+    private String generateRandomListenerName() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 331}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MDUxMzk2OnYy", "diffSide": "RIGHT", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyNzozN1rOHeTdsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwODoyNzozN1rOHeTdsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTUzODIyNg==", "bodyText": "The problem with random tests is that they're not reproducible, so if you get a failure and think you've fixed it how do you re-run the same test again? The solution is in the fact that java.util.Random is a pseudo-random number generator and the contract says if you give it the same seed it will generate the same sequence. But got can't get the seed. So in normal running you can generate a seed using one Random (or use System.nanoTime() or whatever) and use it as the seed for another Random instance and log the seed. Then you can reproduce any failed test for which you have the logs by having some System property or env var which allows you to set the seed, rather than using a Random/System.nanoTime() whatever.\nIf we're going to use more random testing in the future this is a pattern we should encapsulate, but in another PR.", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501538226", "createdAt": "2020-10-08T08:27:37Z", "author": {"login": "tombentley"}, "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.listeners;\n+\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.annotations.OpenShiftOnly;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+\n+@Tag(REGRESSION)\n+public class MultipleListenersST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);\n+    public static final String NAMESPACE = \"multi-listener-namespace\";\n+\n+    // only 4 type of listeners\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleNodePorts() {\n+        runListenersTest(testCases.get(KafkaListenerType.NODEPORT));\n+    }\n+\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleInternal() {\n+        runListenersTest(testCases.get(KafkaListenerType.INTERNAL));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Tag(ACCEPTANCE)\n+    @Test\n+    void testCombinationOfInternalAndExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run INTERNAL + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleLoadBalancers() {\n+        runListenersTest(testCases.get(KafkaListenerType.LOADBALANCER));\n+    }\n+\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMultipleRoutes() {\n+        runListenersTest(testCases.get(KafkaListenerType.ROUTE));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testMixtureOfExternalListeners() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+\n+        // run ROUTE + NODEPORT listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @OpenShiftOnly\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    @Test\n+    void testCombinationOfEveryKindOfListener() {\n+        List<GenericKafkaListener> multipleDifferentListeners = new ArrayList<>();\n+\n+        List<GenericKafkaListener> internalListeners = testCases.get(KafkaListenerType.INTERNAL);\n+        List<GenericKafkaListener> nodeportListeners = testCases.get(KafkaListenerType.NODEPORT);\n+        List<GenericKafkaListener> routeListeners = testCases.get(KafkaListenerType.ROUTE);\n+        List<GenericKafkaListener> loadbalancersListeners = testCases.get(KafkaListenerType.LOADBALANCER);\n+\n+        multipleDifferentListeners.addAll(internalListeners);\n+        multipleDifferentListeners.addAll(nodeportListeners);\n+        multipleDifferentListeners.addAll(routeListeners);\n+        multipleDifferentListeners.addAll(loadbalancersListeners);\n+\n+        // run INTERNAL + NODEPORT + ROUTE + LOADBALANCER listeners\n+        runListenersTest(multipleDifferentListeners);\n+    }\n+\n+    private void runListenersTest(List<GenericKafkaListener> listeners) {\n+\n+        LOGGER.info(\"This is listeners {}, which will verified.\", listeners);\n+\n+        // exercise phase\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withGenericKafkaListeners(listeners)\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaUsername = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUser kafkaUserInstance = KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();\n+\n+        for (GenericKafkaListener listener : listeners) {\n+\n+            String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+            KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+            boolean isTlsEnabled = listener.isTls();\n+\n+            if (listener.getType() != KafkaListenerType.INTERNAL) {\n+\n+                if (isTlsEnabled) {\n+                    BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withListenerName(listener.getName())\n+                        .withSecurityProtocol(SecurityProtocol.SSL)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.TLS_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalTlsKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalTlsKafkaClient.sendMessagesTls(),\n+                        externalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+                        .withListenerName(listener.getName())\n+                        .build();\n+\n+                    LOGGER.info(\"Verifying {} listener\", Constants.PLAIN_LISTENER_DEFAULT_NAME);\n+\n+                    // verify phase\n+                    externalPlainKafkaClient.verifyProducedAndConsumedMessages(\n+                        externalPlainKafkaClient.sendMessagesPlain(),\n+                        externalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            } else {\n+                // using internal clients\n+                if (isTlsEnabled) {\n+                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME + \"-tls\",\n+                        listener.getName(), kafkaUserInstance).done();\n+\n+                    final String kafkaClientsTlsPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-tls\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalTlsKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsTlsPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withKafkaUsername(kafkaUsername)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsTlsPodName);\n+\n+                    // verify phase\n+                    internalTlsKafkaClient.checkProducedAndConsumedMessages(\n+                        internalTlsKafkaClient.sendMessagesTls(),\n+                        internalTlsKafkaClient.receiveMessagesTls()\n+                    );\n+                } else {\n+                    KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME + \"-plain\").done();\n+\n+                    final String kafkaClientsPlainPodName =\n+                        ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME + \"-plain\").get(0).getMetadata().getName();\n+\n+                    InternalKafkaClient internalPlainKafkaClient = new InternalKafkaClient.Builder()\n+                        .withUsingPodName(kafkaClientsPlainPodName)\n+                        .withListenerName(listener.getName())\n+                        .withTopicName(topicName)\n+                        .withNamespaceName(NAMESPACE)\n+                        .withClusterName(CLUSTER_NAME)\n+                        .withMessageCount(MESSAGE_COUNT)\n+                        .build();\n+\n+                    LOGGER.info(\"Checking produced and consumed messages to pod:{}\", kafkaClientsPlainPodName);\n+\n+                    // verify phase\n+                    internalPlainKafkaClient.checkProducedAndConsumedMessages(\n+                        internalPlainKafkaClient.sendMessagesPlain(),\n+                        internalPlainKafkaClient.receiveMessagesPlain()\n+                    );\n+                }\n+            }\n+        }\n+    }\n+\n+    private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {\n+\n+        LOGGER.info(\"Starting to generate test cases for multiple listeners\");\n+\n+        int stochasticCount;\n+\n+        for (KafkaListenerType kafkaListenerType : KafkaListenerType.values()) {\n+\n+            LOGGER.info(\"Generating {} listener\", kafkaListenerType.name());\n+\n+            List<GenericKafkaListener> testCaseListeners = new ArrayList<>(5);\n+\n+            switch (kafkaListenerType) {\n+                case NODEPORT:\n+                    stochasticCount = ThreadLocalRandom.current().nextInt(2, 5);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d59969b24c90c8d48745bfeb6e3073c170a286ee"}, "originalPosition": 270}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0MTgzMDc0OnYy", "diffSide": "RIGHT", "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzo1OTozOFrOHegBhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMzo1OTozOFrOHegBhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTc0NDAwNg==", "bodyText": "Wouldn't be better name them like legacy ?", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3651#discussion_r501744006", "createdAt": "2020-10-08T13:59:38Z", "author": {"login": "Frawless"}, "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "diffHunk": "@@ -264,4 +264,11 @@\n     String CRUISE_CONTROL_CONFIGURATION_ENV = \"CRUISE_CONTROL_CONFIGURATION\";\n     String CRUISE_CONTROL_CAPACITY_FILE_PATH = \"/tmp/capacity.json\";\n     String CRUISE_CONTROL_CONFIGURATION_FILE_PATH = \"/tmp/cruisecontrol.properties\";\n+\n+    /**\n+     * Default listeners names", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74826658b71b02d8cb143d2728d5cd79e76f1d06"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1119, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}