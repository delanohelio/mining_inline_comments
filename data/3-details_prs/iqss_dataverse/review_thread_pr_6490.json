{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYwMTkyNDQ4", "number": 6490, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyMzowN1rODWrD1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMTozMTozM1rODWrMcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAwNzU5OnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyMzowN1rOFbkPXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMzowMjoxOFrOFbmgzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ0OTYzMA==", "bodyText": "Typo. \"uplod\". Also, do we consider unzipping zip files to be part of ingest? Is processing of FITS files part of ingest? (I thought special handling of FITS files is broken right now: #5919.) My sense is that when we say \"ingest\" we are usually only talking about tabular files, not zip files or FITS files. Please see http://guides.dataverse.org/en/4.18.1/user/tabulardataingest/ingestprocess.html", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364449630", "createdAt": "2020-01-08T21:23:07Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -6,7 +6,29 @@ Big data support is highly experimental. Eventually this content will move to th\n .. contents:: |toctitle|\n         :local:\n \n-Various components need to be installed and configured for big data support.\n+Various components need to be installed and/or configured for big data support.\n+\n+S3 Direct Upload and Download\n+-----------------------------\n+\n+A lightweight option for supporting file sizes beyond a few gigabytes - a size that can cause performance issues when uploaded through the Dataverse server itself - is to configure an S3 store to provide direct upload and download via 'pre-signed URLs'. When these options are configured, file uploads and downloads are made directly to and from a configured S3 store using secure (https) connections that enforce Dataverse's access controls. (The upload and download URLs are signed with a unique key that only allows access for a short time period and Dataverse will only generate such a URL if the user has permission to upload/download the specific file in question.)\n+\n+This option can handle files >40GB and could be appropriate for files up to a TB. Other options can scale farther, but this option has the advantages that it is simple to configure and does not require any user training - uploads and downloads are done via the same interface as normal uploads to Dataverse.\n+\n+To configure these options, an administrator must set two JVM options for the Dataverse server using the same process as for other configuration options:\n+\n+``./asadmin create-jvm-options \"-Ddataverse.files.<id>.download-redirect=true\"``\n+``./asadmin create-jvm-options \"-Ddataverse.files.<id>.upload-redirect=true\"``\n+\n+\n+With multiple stores configured, it is possible to configure one S3 store with direct upload and/or download to support large files (in general or for specific dataverses) while configuring only direct download, or no direct access for another store.  \n+\n+At present, one potential drawback for direct-upload is that files are only partially 'ingested', tabular and FITS files are processed, but zip files are not unzipped, and the file contents are not inspected to evaluate their mimetype. This could be appropriate for large files, or it may be useful to completely turn off ingest processing for performance reasons (ingest processing requires a copy of the file to be retrieved by Dataverse from the S3 store). A store using direct uplod can be configured to disable all ingest processing for files above a given size limit:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4Njg2MQ==", "bodyText": "What do you want to call the rest of it? Processing on upload?\nFor FITS, this branch should now be just-as-broken as the other. I just assured that the same processing is triggered when there is no temp file - handing the code a stream to the final file instead.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364486861", "createdAt": "2020-01-08T23:02:18Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -6,7 +6,29 @@ Big data support is highly experimental. Eventually this content will move to th\n .. contents:: |toctitle|\n         :local:\n \n-Various components need to be installed and configured for big data support.\n+Various components need to be installed and/or configured for big data support.\n+\n+S3 Direct Upload and Download\n+-----------------------------\n+\n+A lightweight option for supporting file sizes beyond a few gigabytes - a size that can cause performance issues when uploaded through the Dataverse server itself - is to configure an S3 store to provide direct upload and download via 'pre-signed URLs'. When these options are configured, file uploads and downloads are made directly to and from a configured S3 store using secure (https) connections that enforce Dataverse's access controls. (The upload and download URLs are signed with a unique key that only allows access for a short time period and Dataverse will only generate such a URL if the user has permission to upload/download the specific file in question.)\n+\n+This option can handle files >40GB and could be appropriate for files up to a TB. Other options can scale farther, but this option has the advantages that it is simple to configure and does not require any user training - uploads and downloads are done via the same interface as normal uploads to Dataverse.\n+\n+To configure these options, an administrator must set two JVM options for the Dataverse server using the same process as for other configuration options:\n+\n+``./asadmin create-jvm-options \"-Ddataverse.files.<id>.download-redirect=true\"``\n+``./asadmin create-jvm-options \"-Ddataverse.files.<id>.upload-redirect=true\"``\n+\n+\n+With multiple stores configured, it is possible to configure one S3 store with direct upload and/or download to support large files (in general or for specific dataverses) while configuring only direct download, or no direct access for another store.  \n+\n+At present, one potential drawback for direct-upload is that files are only partially 'ingested', tabular and FITS files are processed, but zip files are not unzipped, and the file contents are not inspected to evaluate their mimetype. This could be appropriate for large files, or it may be useful to completely turn off ingest processing for performance reasons (ingest processing requires a copy of the file to be retrieved by Dataverse from the S3 store). A store using direct uplod can be configured to disable all ingest processing for files above a given size limit:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ0OTYzMA=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAxMDczOnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyNDoyM1rOFbkRSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMjo0NToxM1rOFbmJlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDEyMQ==", "bodyText": "I'm not sure what's going on here. Maybe the JVM option was mis-documented? Also, I think .. means it's commented out but I'm not sure.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364450121", "createdAt": "2020-01-08T21:24:23Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -18,7 +40,7 @@ Install a DCM\n \n Installation instructions can be found at https://github.com/sbgrid/data-capture-module/blob/master/doc/installation.md. Note that shared storage (posix or AWS S3) between Dataverse and your DCM is required. You cannot use a DCM with Swift at this point in time.\n \n-.. FIXME: Explain what ``dataverse.files.dcm-s3-bucket-name`` is for and what it has to do with ``dataverse.files.s3-bucket-name``.\n+.. FIXME: Explain what ``dataverse.files.dcm-s3-bucket-name`` is for and what it has to do with ``dataverse.files.s3.bucket-name``.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4MDkxOA==", "bodyText": "My change is just to update the option name to what it will be. Whether the fixme is still considered relevant, I don't know.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364480918", "createdAt": "2020-01-08T22:45:13Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -18,7 +40,7 @@ Install a DCM\n \n Installation instructions can be found at https://github.com/sbgrid/data-capture-module/blob/master/doc/installation.md. Note that shared storage (posix or AWS S3) between Dataverse and your DCM is required. You cannot use a DCM with Swift at this point in time.\n \n-.. FIXME: Explain what ``dataverse.files.dcm-s3-bucket-name`` is for and what it has to do with ``dataverse.files.s3-bucket-name``.\n+.. FIXME: Explain what ``dataverse.files.dcm-s3-bucket-name`` is for and what it has to do with ``dataverse.files.s3.bucket-name``.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDEyMQ=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAxMjE2OnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyNTowMVrOFbkSJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMzowNjo0MVrOFbmmSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDM0Mw==", "bodyText": "Heads up to @pameyer about this if we merge this. Affects DCM.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364450343", "createdAt": "2020-01-08T21:25:01Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -100,6 +122,7 @@ Optional steps for setting up the S3 Docker DCM Variant\n ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \n - Before: the default bucket for DCM to hold files in S3 is named test-dcm. It is coded into `post_upload_s3.bash` (line 30). Change to a different bucket if needed.\n+- Also Note: With the new support for multiple file store in Dataverse, DCM requires a store with id=\"s3\" and DCM will only work with this store.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4ODI2NA==", "bodyText": "FWIW: As long as there's a store with the id 's3', as recommended for backward compatibility, DCM should be unaffected/ will continue to work on an instance that upgrades from a single s3 store today.\nIn looking through the DCM code, I did see that it creates an AWS client without using any of the s3 store options that have (since?) been created to support minio, etc. Given that, I think DCM can only currently work with a vanilla AWS S3 server and this branch won't affect that.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364488264", "createdAt": "2020-01-08T23:06:41Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -100,6 +122,7 @@ Optional steps for setting up the S3 Docker DCM Variant\n ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \n - Before: the default bucket for DCM to hold files in S3 is named test-dcm. It is coded into `post_upload_s3.bash` (line 30). Change to a different bucket if needed.\n+- Also Note: With the new support for multiple file store in Dataverse, DCM requires a store with id=\"s3\" and DCM will only work with this store.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDM0Mw=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAxMzQ3OnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyNTozM1rOFbkS9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMjo0OTozNlrOFbmPqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDU1MA==", "bodyText": "Why was this changed from a hyphen to a period?", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364450550", "createdAt": "2020-01-08T21:25:33Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -132,7 +158,7 @@ Optional steps for setting up the S3 Docker DCM Variant\n \n     - S3 bucket for Dataverse\n \n-      - ``/usr/local/glassfish4/glassfish/bin/asadmin create-jvm-options \"-Ddataverse.files.s3-bucket-name=iqsstestdcmbucket\"``\n+      - ``/usr/local/glassfish4/glassfish/bin/asadmin create-jvm-options \"-Ddataverse.files.s3.bucket-name=iqsstestdcmbucket\"``", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4MjQ3NQ==", "bodyText": "When there was only one possible s3-bucket-name, a hyphen made sense. Now that there can be multiple S3 stores, we need options for each store's bucket name. I chose to standardize on\n-Ddataverse.files.<id>.bucket-name\nand to have all of the options for all three types of stores be of the form\n-Ddataverse.files.<id>.<option name>\nrather than have a mix of . and hyphens depending on type.\nIf there's an argument for a better convention, I'm open.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364482475", "createdAt": "2020-01-08T22:49:36Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/developers/big-data-support.rst", "diffHunk": "@@ -132,7 +158,7 @@ Optional steps for setting up the S3 Docker DCM Variant\n \n     - S3 bucket for Dataverse\n \n-      - ``/usr/local/glassfish4/glassfish/bin/asadmin create-jvm-options \"-Ddataverse.files.s3-bucket-name=iqsstestdcmbucket\"``\n+      - ``/usr/local/glassfish4/glassfish/bin/asadmin create-jvm-options \"-Ddataverse.files.s3.bucket-name=iqsstestdcmbucket\"``", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MDU1MA=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAxNzA3OnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/installation/config.rst", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyNjo0OVrOFbkVDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyNjo0OVrOFbkVDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MTA4Nw==", "bodyText": "If single store configurations need to do something when they upgrade, I hope there's a release note about this.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364451087", "createdAt": "2020-01-08T21:26:49Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -208,10 +208,47 @@ As for the \"Remote only\" authentication mode, it means that:\n - ``:DefaultAuthProvider`` has been set to use the desired authentication provider\n - The \"builtin\" authentication provider has been disabled (:ref:`api-toggle-auth-provider`). Note that disabling the \"builtin\" authentication provider means that the API endpoint for converting an account from a remote auth provider will not work. Converting directly from one remote authentication provider to another (i.e. from GitHub to Google) is not supported. Conversion from remote is always to \"builtin\". Then the user initiates a conversion from \"builtin\" to remote. Note that longer term, the plan is to permit multiple login options to the same Dataverse account per https://github.com/IQSS/dataverse/issues/3487 (so all this talk of conversion will be moot) but for now users can only use a single login option, as explained in the :doc:`/user/account` section of the User Guide. In short, \"remote only\" might work for you if you only plan to use a single remote authentication provider such that no conversion between remote authentication providers will be necessary.\n \n-File Storage: Local Filesystem vs. Swift vs. S3\n------------------------------------------------\n+File Storage: Using a Local Filesystem and/or Swift and/or S3 object stores\n+---------------------------------------------------------------------------\n+\n+By default, a Dataverse installation stores all data files (files uploaded by end users) on the filesystem at ``/usr/local/glassfish4/glassfish/domains/domain1/files``. This path can vary based on answers you gave to the installer (see the :ref:`dataverse-installer` section of the Installation Guide) or afterward by reconfiguring the ``dataverse.files.directory`` JVM option described below.\n+\n+Dataverse can alternately store files in a Swift or S3-compatible object store, and can now be configured to support multiple stores at once. With a multi-store configuration, the location for new files can be controlled on a per-dataverse basis.\n+\n+The following sections describe how to set up various types of stores and how to configure for multiple stores.\n+\n+Multi-store Basics\n++++++++++++++++++\n+\n+To support multiple stores, Dataverse now requires an id, type, and label for each store (even for a single store configuration). These are configured by defining two required jvm options:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAyNDAxOnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/installation/config.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMToyOToxNVrOFbkZMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMjo1NToyOVrOFbmXkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MjE0NA==", "bodyText": "We typically put information like this (what to change after you deploy a new version) in release notes. I guess it's ok to have it here too but I prefer to think of the audience as being someone who is installing Dataverse for the first time. This could be their first day with Dataverse. They probably don't need information about how things used to be (Don't Make Me Think).", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364452144", "createdAt": "2020-01-08T21:29:15Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -208,10 +208,47 @@ As for the \"Remote only\" authentication mode, it means that:\n - ``:DefaultAuthProvider`` has been set to use the desired authentication provider\n - The \"builtin\" authentication provider has been disabled (:ref:`api-toggle-auth-provider`). Note that disabling the \"builtin\" authentication provider means that the API endpoint for converting an account from a remote auth provider will not work. Converting directly from one remote authentication provider to another (i.e. from GitHub to Google) is not supported. Conversion from remote is always to \"builtin\". Then the user initiates a conversion from \"builtin\" to remote. Note that longer term, the plan is to permit multiple login options to the same Dataverse account per https://github.com/IQSS/dataverse/issues/3487 (so all this talk of conversion will be moot) but for now users can only use a single login option, as explained in the :doc:`/user/account` section of the User Guide. In short, \"remote only\" might work for you if you only plan to use a single remote authentication provider such that no conversion between remote authentication providers will be necessary.\n \n-File Storage: Local Filesystem vs. Swift vs. S3\n------------------------------------------------\n+File Storage: Using a Local Filesystem and/or Swift and/or S3 object stores\n+---------------------------------------------------------------------------\n+\n+By default, a Dataverse installation stores all data files (files uploaded by end users) on the filesystem at ``/usr/local/glassfish4/glassfish/domains/domain1/files``. This path can vary based on answers you gave to the installer (see the :ref:`dataverse-installer` section of the Installation Guide) or afterward by reconfiguring the ``dataverse.files.directory`` JVM option described below.\n+\n+Dataverse can alternately store files in a Swift or S3-compatible object store, and can now be configured to support multiple stores at once. With a multi-store configuration, the location for new files can be controlled on a per-dataverse basis.\n+\n+The following sections describe how to set up various types of stores and how to configure for multiple stores.\n+\n+Multi-store Basics\n++++++++++++++++++\n+\n+To support multiple stores, Dataverse now requires an id, type, and label for each store (even for a single store configuration). These are configured by defining two required jvm options:\n+\n+.. code-block:: none\n+\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.type=<type>\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.label=<label>\"\n+\n+For backward compatibility, the id and type should be the same, and the label can be set to the same value as well. For example, the following would define a backward compatible file store:\n+\n+.. code-block:: none\n+\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.file.type=file\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.file.label=file\"\n+  \n+or a file or swift store, this is all that is needed for backward compatibility. For an s3 store, any additional options must be changed to conform to the new, more consistent naming convention using a . after the store's id ('s3' for backward compatibility) For example:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4NDQ5OQ==", "bodyText": "I'm fine with it being in release notes instead. I figured I'd put it here since I don't know what version this might become part of.", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364484499", "createdAt": "2020-01-08T22:55:29Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -208,10 +208,47 @@ As for the \"Remote only\" authentication mode, it means that:\n - ``:DefaultAuthProvider`` has been set to use the desired authentication provider\n - The \"builtin\" authentication provider has been disabled (:ref:`api-toggle-auth-provider`). Note that disabling the \"builtin\" authentication provider means that the API endpoint for converting an account from a remote auth provider will not work. Converting directly from one remote authentication provider to another (i.e. from GitHub to Google) is not supported. Conversion from remote is always to \"builtin\". Then the user initiates a conversion from \"builtin\" to remote. Note that longer term, the plan is to permit multiple login options to the same Dataverse account per https://github.com/IQSS/dataverse/issues/3487 (so all this talk of conversion will be moot) but for now users can only use a single login option, as explained in the :doc:`/user/account` section of the User Guide. In short, \"remote only\" might work for you if you only plan to use a single remote authentication provider such that no conversion between remote authentication providers will be necessary.\n \n-File Storage: Local Filesystem vs. Swift vs. S3\n------------------------------------------------\n+File Storage: Using a Local Filesystem and/or Swift and/or S3 object stores\n+---------------------------------------------------------------------------\n+\n+By default, a Dataverse installation stores all data files (files uploaded by end users) on the filesystem at ``/usr/local/glassfish4/glassfish/domains/domain1/files``. This path can vary based on answers you gave to the installer (see the :ref:`dataverse-installer` section of the Installation Guide) or afterward by reconfiguring the ``dataverse.files.directory`` JVM option described below.\n+\n+Dataverse can alternately store files in a Swift or S3-compatible object store, and can now be configured to support multiple stores at once. With a multi-store configuration, the location for new files can be controlled on a per-dataverse basis.\n+\n+The following sections describe how to set up various types of stores and how to configure for multiple stores.\n+\n+Multi-store Basics\n++++++++++++++++++\n+\n+To support multiple stores, Dataverse now requires an id, type, and label for each store (even for a single store configuration). These are configured by defining two required jvm options:\n+\n+.. code-block:: none\n+\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.type=<type>\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.label=<label>\"\n+\n+For backward compatibility, the id and type should be the same, and the label can be set to the same value as well. For example, the following would define a backward compatible file store:\n+\n+.. code-block:: none\n+\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.file.type=file\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.file.label=file\"\n+  \n+or a file or swift store, this is all that is needed for backward compatibility. For an s3 store, any additional options must be changed to conform to the new, more consistent naming convention using a . after the store's id ('s3' for backward compatibility) For example:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MjE0NA=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAyODA0OnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/installation/config.rst", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMTozMDo1OFrOFbkb2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMjo1OToxOFrOFbmcnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MjgyNw==", "bodyText": "I'm confused. Don't we need to explain in this section (Swift Storage) what to put for <id>?", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364452827", "createdAt": "2020-01-08T21:30:58Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -224,12 +261,13 @@ First, run all the following create commands with your Swift endpoint informatio\n \n .. code-block:: none\n \n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.defaultEndpoint=endpoint1\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.authType.endpoint1=your-auth-type\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.authUrl.endpoint1=your-auth-url\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.tenant.endpoint1=your-tenant-name\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.username.endpoint1=your-username\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.endpoint.endpoint1=your-swift-endpoint\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.type=swift\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4NTc4OQ==", "bodyText": "Whatever makes sense. The general concept is that all options are now of the form\n-Ddataverse.files.<id>.<option name>\nso there's nothing swift specific about the naming per se. I could say more in the multistore basics section?", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364485789", "createdAt": "2020-01-08T22:59:18Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -224,12 +261,13 @@ First, run all the following create commands with your Swift endpoint informatio\n \n .. code-block:: none\n \n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.defaultEndpoint=endpoint1\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.authType.endpoint1=your-auth-type\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.authUrl.endpoint1=your-auth-url\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.tenant.endpoint1=your-tenant-name\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.username.endpoint1=your-username\"\n-    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.swift.endpoint.endpoint1=your-swift-endpoint\"\n+    ./asadmin $ASADMIN_OPTS create-jvm-options \"\\-Ddataverse.files.<id>.type=swift\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MjgyNw=="}, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MTAyOTYyOnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/installation/config.rst", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMTozMTozM1rOFbkc1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQyMTozMTozM1rOFbkc1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ1MzA3Ng==", "bodyText": "I appreciate this clarification that the Compute button is currently tied to Swift. \ud83d\ude04", "url": "https://github.com/IQSS/dataverse/pull/6490#discussion_r364453076", "createdAt": "2020-01-08T21:31:33Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -267,8 +305,8 @@ You also have the option to set a custom expiration length, in seconds, for a ge\n In this example, you would be setting the expiration length for one hour.\n \n \n-Setting up Compute\n-+++++++++++++++++++\n+Setting up Compute with Swift", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14c71344174e363fca5ef68dd25dadaea908bf99"}, "originalPosition": 77}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3370, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}