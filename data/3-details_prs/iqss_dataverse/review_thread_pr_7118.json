{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1NzA3MDUz", "number": 7118, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo1MDo1NlrOERkvOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxOTowMDoxMlrOETYrwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2ODYzMTYzOnYy", "diffSide": "RIGHT", "path": "doc/sphinx-guides/source/installation/config.rst", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo1MDo1NlrOG2XVmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNDowMDoxMlrOG4N_NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ==", "bodyText": "policy question - should old settings be described when they no longer have an effect? I ask partly because in #7116 I'm just removing documentation of old jvm options. (A quick search for deprecated only showed a couple cases where something was deprecated but still supported.)", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459658651", "createdAt": "2020-07-23T18:50:56Z", "author": {"login": "qqmyers"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY3MDc4Ng==", "bodyText": "I think it's more comment to remove both the setting and the docs for it. eb861c7 is an example. In a release note we could include something about why the setting was removed.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459670786", "createdAt": "2020-07-23T19:13:55Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY4Njk1Ng==", "bodyText": "I felt like I should leave it in there marked as \"deprecated\", in case somebody sees it in their settings table and wonders what it is - ? (going through the older versions of the guide is an option - but would be an extra effort).\nBut I'm open to removing things that are no longer relevant too.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459686956", "createdAt": "2020-07-23T19:45:01Z", "author": {"login": "landreev"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNTgxNA==", "bodyText": "So what's the final word/vote - should I remove it? Or leave it in place?", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461115814", "createdAt": "2020-07-27T19:23:27Z", "author": {"login": "landreev"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEyMTY3OA==", "bodyText": "@landreev Can you remove and add a release note? We have a \"Notes for Installation Administrators\" section it can go under. I'll make sure it gets integrated.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461121678", "createdAt": "2020-07-27T19:34:41Z", "author": {"login": "djbrooke"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE1OTAzNg==", "bodyText": "Would it really provide any value in the release notes?\nThere's a lot in this release that the admins will actually have to do, in order to upgrade... Do we want to give them more stuff to read, that they don't necessarily have any use for?\nWouldn't take any effort to move it of course, if you still want me to.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461159036", "createdAt": "2020-07-27T20:45:32Z", "author": {"login": "landreev"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2OTM2OA==", "bodyText": "If we're voting, I vote for removing it from the docs (old versions of the docs are available indefinitely for a reason). A single line in the release notes saying \"[whatever] has been deprecated and can be removed from your setting table\" seems fine.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461169368", "createdAt": "2020-07-27T21:05:09Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE3MDc3NQ==", "bodyText": "OK, fine, I'm convinced - or outvoted, which is the same thing. Will remove.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461170775", "createdAt": "2020-07-27T21:07:49Z", "author": {"login": "landreev"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMjYxMw==", "bodyText": "OK, done.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r461602613", "createdAt": "2020-07-28T14:00:12Z", "author": {"login": "landreev"}, "path": "doc/sphinx-guides/source/installation/config.rst", "diffHunk": "@@ -1446,22 +1446,20 @@ Note that in either case, when using the ``sequentialNumber`` option, datasets a\n :FilePIDsEnabled\n ++++++++++++++++\n \n-Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true.\n+Toggles publishing of file-based PIDs for the entire installation. By default this setting is absent and Dataverse assumes it to be true. If enabled, the registration will be performed asynchronously (in the background) during publishing of a dataset.\n \n If you don't want to register file-based PIDs for your installation, set:\n \n ``curl -X PUT -d 'false' http://localhost:8080/api/admin/settings/:FilePIDsEnabled``\n \n-Note: File-level PID registration was added in 4.9 and is required until version 4.9.3.\n-\n-Note: The dataset will be locked, and the registration will be performed asynchronously, when there are more than N files in the dataset, where N is configured by the database setting ``:PIDAsynchRegFileCount`` (default: 10). \n+Note: File-level PID registration was added in 4.9; it could not be disabled until version 4.9.3.\n \n .. _:PIDAsynchRegFileCount:\n \n-:PIDAsynchRegFileCount\n-++++++++++++++++++++++\n+:PIDAsynchRegFileCount (DEPRECATED)\n++++++++++++++++++++++++++++++++++++\n \n-Configures the number of files in the dataset to warrant performing the registration of persistent identifiers (section above) and/or file validation asynchronously during publishing. The setting is optional, and the default value is 10.\n+Before v5.0 this setting used to specify the number of files in the dataset to warrant performing the registration of the persistent identifiers (section above) and/or file validation asynchronously (in the background) during publishing. As of v5.0 publishing *always* happens asynchronously, with the dataset locked for the duration of the process. The setting will be ignored if present. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY1ODY1MQ=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2ODY4Mzk2OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTowNjoyMFrOG2X2Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QyMDowMjo1OVrOG2Zntg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng==", "bodyText": "I thought I understood why the in transaction version of sendNotification was needed (to send the email even if the command transaction was rolling back), but this looks like the opposite - is it correct as is? (If so, what am I missing?)", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459666986", "createdAt": "2020-07-23T19:06:20Z", "author": {"login": "qqmyers"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY4NTY5OA==", "bodyText": "No, you were right. Since the notification needs to be saved in the database, rolling back the transaction un-saves it. And now that, in addition to the success notification, I am also sending notifications in situations when something goes bad and the transaction is going to be rolled back, I need to save the notification in a transaction of its own.\nOf course I should probably  only be using the \"InTransaction\" method when it is an on-failure notification; and stick with the normal, old way of doing it when it's the \"success\" notification at the end of the command. When nothing is expected to be rolled back that is.\nThe extra parameter - type - identifies the type of the notification that needs to be sent;  \"dataset's been published\" vs \"failed on account of registration error\" ...", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459685698", "createdAt": "2020-07-23T19:42:33Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY5MDUyNQ==", "bodyText": "Right - but notifyUserDatasetPublishStatus is the one being used for the failure message, and it's using sendNotification inside and not sendNotificationInTransaction - that means the notification won't get saved in the db for the failure? Or?", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459690525", "createdAt": "2020-07-23T19:52:25Z", "author": {"login": "qqmyers"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY5MzU2MQ==", "bodyText": "Did I check in the wrong version of it? - hold on...", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459693561", "createdAt": "2020-07-23T19:58:14Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY5NDQxMA==", "bodyText": "Of course I did. (I was messing with renaming the methods at the last moment - and did mess it up). Thank you.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459694410", "createdAt": "2020-07-23T19:59:51Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY5NTc5MQ==", "bodyText": "been there, done that!", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459695791", "createdAt": "2020-07-23T20:02:30Z", "author": {"login": "qqmyers"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY5NjA1NA==", "bodyText": "I was only looking at the line your comment was immediately referencing and got confused.\nOK, fixed - thanks again.\nOtherwise Kevin would run into this during QA, with no notification showing in the UI.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r459696054", "createdAt": "2020-07-23T20:02:59Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -399,16 +436,17 @@ private void notifyUsersFileDownload(CommandContext ctxt, DvObject subject) {\n             .filter(  ra -> ra.getRole().permissions().contains(Permission.DownloadFile) )\n             .flatMap( ra -> ctxt.roleAssignees().getExplicitUsers(ctxt.roleAssignees().getRoleAssignee(ra.getAssigneeIdentifier())).stream() )\n             .distinct() // prevent double-send\n-            .forEach( au -> ctxt.notifications().sendNotification(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n+            .forEach( au -> ctxt.notifications().sendNotificationInTransaction(au, getTimestamp(), UserNotification.Type.GRANTFILEACCESS, getDataset().getId()) );\n     }\n     \n-    private void notifyUsersDatasetPublish(CommandContext ctxt, DvObject subject) {\n+    private void notifyUsersDatasetPublishStatus(CommandContext ctxt, DvObject subject, UserNotification.Type type) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2Njk4Ng=="}, "originalCommit": {"oid": "a4c961ec99d69a1642eb4ee26bfb74df8f552596"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3NzUwODUzOnYy", "diffSide": "RIGHT", "path": "src/main/java/propertyFiles/Bundle.properties", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNDo0NToxNVrOG3lzOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNToxNjowMVrOG3nLRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0NDE4NA==", "bodyText": "Typo requires correction... \"Global Identifier\".", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r460944184", "createdAt": "2020-07-27T14:45:15Z", "author": {"login": "mheppler"}, "path": "src/main/java/propertyFiles/Bundle.properties", "diffHunk": "@@ -666,6 +668,7 @@ notification.email.createDataset=Your new dataset named {0} (view at {1} ) was c\n notification.email.wasSubmittedForReview={0} (view at {1}) was submitted for review to be published in {2} (view at {3}). Don''t forget to publish it or send it back to the contributor, {4} ({5})\\!\n notification.email.wasReturnedByReviewer={0} (view at {1}) was returned by the curator of {2} (view at {3}).\n notification.email.wasPublished={0} (view at {1}) was published in {2} (view at {3}).\n+notification.email.publishFailedPidReg={0} (view at {1}) in {2} (view at {3}) could not be published due to a failure to register, or update the Global Identifer for the dataset or one of the files in it. Contact support if this continues to happen. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e734dd88f209bb4b52965fbb7e8838ea48c420e4"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0NTc4Mw==", "bodyText": "Hold the line. Might also have some grammar revisions to suggest...", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r460945783", "createdAt": "2020-07-27T14:47:25Z", "author": {"login": "mheppler"}, "path": "src/main/java/propertyFiles/Bundle.properties", "diffHunk": "@@ -666,6 +668,7 @@ notification.email.createDataset=Your new dataset named {0} (view at {1} ) was c\n notification.email.wasSubmittedForReview={0} (view at {1}) was submitted for review to be published in {2} (view at {3}). Don''t forget to publish it or send it back to the contributor, {4} ({5})\\!\n notification.email.wasReturnedByReviewer={0} (view at {1}) was returned by the curator of {2} (view at {3}).\n notification.email.wasPublished={0} (view at {1}) was published in {2} (view at {3}).\n+notification.email.publishFailedPidReg={0} (view at {1}) in {2} (view at {3}) could not be published due to a failure to register, or update the Global Identifer for the dataset or one of the files in it. Contact support if this continues to happen. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0NDE4NA=="}, "originalCommit": {"oid": "e734dd88f209bb4b52965fbb7e8838ea48c420e4"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk2NjcyNA==", "bodyText": "OK!", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r460966724", "createdAt": "2020-07-27T15:16:01Z", "author": {"login": "landreev"}, "path": "src/main/java/propertyFiles/Bundle.properties", "diffHunk": "@@ -666,6 +668,7 @@ notification.email.createDataset=Your new dataset named {0} (view at {1} ) was c\n notification.email.wasSubmittedForReview={0} (view at {1}) was submitted for review to be published in {2} (view at {3}). Don''t forget to publish it or send it back to the contributor, {4} ({5})\\!\n notification.email.wasReturnedByReviewer={0} (view at {1}) was returned by the curator of {2} (view at {3}).\n notification.email.wasPublished={0} (view at {1}) was published in {2} (view at {3}).\n+notification.email.publishFailedPidReg={0} (view at {1}) in {2} (view at {3}) could not be published due to a failure to register, or update the Global Identifer for the dataset or one of the files in it. Contact support if this continues to happen. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0NDE4NA=="}, "originalCommit": {"oid": "e734dd88f209bb4b52965fbb7e8838ea48c420e4"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzYxNDM4OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/UserNotificationServiceBean.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1NjoxMVrOG5F1nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1NjoxMVrOG5F1nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxNzY2MQ==", "bodyText": "minor quibble, but maybe name of method should be \"sendNotificationInNewTransaction\" -  at least that's the naming scheme we used for, e.g., indexDataverseInNewTransaction.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462517661", "createdAt": "2020-07-29T18:56:11Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/UserNotificationServiceBean.java", "diffHunk": "@@ -83,6 +85,11 @@ public void delete(UserNotification userNotification) {\n         em.remove(em.merge(userNotification));\n     }\n \n+    @TransactionAttribute(TransactionAttributeType.REQUIRES_NEW)\n+    public void sendNotificationInTransaction(AuthenticatedUser dataverseUser, Timestamp sendDate, Type type, Long objectId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzYyMjI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1ODozM1rOG5F6hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1ODozM1rOG5F6hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxODkxOQ==", "bodyText": "minor type", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462518919", "createdAt": "2020-07-29T18:58:33Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -149,10 +159,14 @@ public Dataset execute(CommandContext ctxt) throws CommandException {\n         \n \tif (theDataset.getLatestVersion().getVersionState() != RELEASED) {\n             // some imported datasets may already be released.\n-\n+            \n             if (!datasetExternallyReleased) {\n                 publicizeExternalIdentifier(theDataset, ctxt);\n-                // (will throw a CommandException, unless successful)\n+                // Will throw a CommandException, unless successful.\n+                // This will end the exucition of the command, but the method ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzYyNTg2OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxODo1OTozNFrOG5F8wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMTo1MzoyNFrOG51Jvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA==", "bodyText": "possibly, out of scope, but should we move export into onSuccess?", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462519490", "createdAt": "2020-07-29T18:59:34Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxMzM2Ng==", "bodyText": "I don't see why not; maybe handle it in the same issue that you have opened for moving the indexing into onSuccess?\nOtherwise, I made that exception catch more general (that appeared to be the reason a recent problem with OpenAire export was resulting in a fatal error when publishing... and the code below suggested we never wanted to treat a failure to export as fatal).", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462613366", "createdAt": "2020-07-29T21:57:10Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxNzQwMA==", "bodyText": "I feel like export actually already is in onSuccess anyway? so are we exporting twice?? I think it's fine to handle in the other issue.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462617400", "createdAt": "2020-07-29T22:06:09Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI3ODAyMQ==", "bodyText": "Uh, you're right - it appears to already be in onSuccess.\nSo, what were you proposing then?\n(are you still waiting for something from me for this PR?)", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r463278021", "createdAt": "2020-07-30T21:20:48Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MzE1Mw==", "bodyText": "If we're sure the onsuccess export does everything the same, I would remove from here. If we're not, we can leave and add as a comment to the other issue to review and clean up then.\n(other than that, can move to QA)", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r463283153", "createdAt": "2020-07-30T21:31:36Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4ODYxMw==", "bodyText": "But, this is the method that's called from onSuccess. And it doesn't seem to be called from anywhere else... It's entirely possible that I'm missing something obvious.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r463288613", "createdAt": "2020-07-30T21:43:32Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI5Mjg2Mw==", "bodyText": "Oh. Not you, me --- the way it was truncated in github, it looked to me as if it were in execute. My mistake. (After expanding, yes, it is in onSuccess - which is good, since it's what we expected. Sorry for the noise.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r463292863", "createdAt": "2020-07-30T21:53:24Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -220,7 +235,7 @@ private void exportMetadata(Dataset dataset, SettingsServiceBean settingsService\n             ExportService instance = ExportService.getInstance(settingsServiceBean);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTQ5MA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzYyODE4OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxOTowMDoxMlrOG5F-Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTo1NzoyOVrOG5LsDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTg1NA==", "bodyText": "I already opened a separate issue for this, but index should be moved to onSuccess.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462519854", "createdAt": "2020-07-29T19:00:12Z", "author": {"login": "scolapasta"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -237,10 +252,24 @@ private void updateParentDataversesSubjectsField(Dataset savedDataset, CommandCo\n             if (dsf.getDatasetFieldType().getName().equals(DatasetFieldConstant.subject)) {\n                 Dataverse dv = savedDataset.getOwner();\n                 while (dv != null) {\n-                    if (dv.getDataverseSubjects().addAll(dsf.getControlledVocabularyValues())) {\n+                    boolean newSubjectsAdded = false;\n+                    for (ControlledVocabularyValue cvv : dsf.getControlledVocabularyValues()) {\n+                    \n+                        if (!dv.getDataverseSubjects().contains(cvv)) {\n+                            logger.fine(\"dv \"+dv.getAlias()+\" does not have subject \"+cvv.getStrValue());\n+                            newSubjectsAdded = true;\n+                            dv.getDataverseSubjects().add(cvv);\n+                        } else {\n+                            logger.fine(\"dv \"+dv.getAlias()+\" already has subject \"+cvv.getStrValue());\n+                        }\n+                    }\n+                    if (newSubjectsAdded) {\n+                        logger.fine(\"new dataverse subjects added - saving and reindexing\");\n                         Dataverse dvWithSubjectJustAdded = ctxt.em().merge(dv);\n                         ctxt.em().flush();\n                         ctxt.index().indexDataverse(dvWithSubjectJustAdded); // need to reindex to capture the new subjects", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxMzUxOA==", "bodyText": "Makes sense.", "url": "https://github.com/IQSS/dataverse/pull/7118#discussion_r462613518", "createdAt": "2020-07-29T21:57:29Z", "author": {"login": "landreev"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -237,10 +252,24 @@ private void updateParentDataversesSubjectsField(Dataset savedDataset, CommandCo\n             if (dsf.getDatasetFieldType().getName().equals(DatasetFieldConstant.subject)) {\n                 Dataverse dv = savedDataset.getOwner();\n                 while (dv != null) {\n-                    if (dv.getDataverseSubjects().addAll(dsf.getControlledVocabularyValues())) {\n+                    boolean newSubjectsAdded = false;\n+                    for (ControlledVocabularyValue cvv : dsf.getControlledVocabularyValues()) {\n+                    \n+                        if (!dv.getDataverseSubjects().contains(cvv)) {\n+                            logger.fine(\"dv \"+dv.getAlias()+\" does not have subject \"+cvv.getStrValue());\n+                            newSubjectsAdded = true;\n+                            dv.getDataverseSubjects().add(cvv);\n+                        } else {\n+                            logger.fine(\"dv \"+dv.getAlias()+\" already has subject \"+cvv.getStrValue());\n+                        }\n+                    }\n+                    if (newSubjectsAdded) {\n+                        logger.fine(\"new dataverse subjects added - saving and reindexing\");\n                         Dataverse dvWithSubjectJustAdded = ctxt.em().merge(dv);\n                         ctxt.em().flush();\n                         ctxt.index().indexDataverse(dvWithSubjectJustAdded); // need to reindex to capture the new subjects", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxOTg1NA=="}, "originalCommit": {"oid": "840d290d155410c13ab0b0bc640dc056ea35513b"}, "originalPosition": 110}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3278, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}