{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA1MDUxNjE5", "number": 7337, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QyMDo0MjowN1rOEyi6fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNTo1MzoxMVrOEz2p7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxNDM2Mjg1OnYy", "diffSide": "RIGHT", "path": "src/main/webapp/file.xhtml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QyMDo0MjowN1rOHpQDuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxMzo0MDo1OFrOHpqjuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzAxNjc2MQ==", "bodyText": "We're getting multiple replace file links here because of the change in render. Once a  released file has been replaced it can be replaced again, so taking out the \"isReleased\" gets two Replace links to render", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r513016761", "createdAt": "2020-10-27T20:42:07Z", "author": {"login": "sekmiller"}, "path": "src/main/webapp/file.xhtml", "diffHunk": "@@ -267,7 +267,7 @@\n                                                                 </li>\n                                                             </ui:fragment>     \n                                                         </ui:fragment>\n-                                                        <ui:fragment rendered=\"#{FilePage.fileMetadata.dataFile.released and FilePage.draftReplacementFile == false and !FilePage.fileMetadata.dataFile.filePackage}\">                                        \n+                                                        <ui:fragment rendered=\"#{FilePage.draftReplacementFile == false and !FilePage.fileMetadata.dataFile.filePackage}\">                                        \n                                                         <li><!-- start: replace file link -->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d16b3cbf7f937f5b0b6525e587a5e6444f743244"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzQ1MDkzNw==", "bodyText": "Good catch. The problem is the next lines though - the second Replace button that would trigger the warning dialog to not replace a file that's already being replaced in the draft version was showing and it shouldn't have. For now, I've just adjusted the logic there (only show the dialog if there is a draft replacement for the file, which is not true for the replacing file.)\nThe logic is simpler too. FWIW, I went back about 4 years in github to see if I could find out why the current terms were in there and didn't find a clear reason, so perhaps someone else might have a better sense and be able to see if there's anything my change misses?\nHowever, I'm also not sure that dialog is needed anymore - a file that has been replaced in the latest version now shows a dialog when you click the 'Edit' button itself, so you never get to the individual menu items like replace and delete and therefore can't trigger the dialogs related to them. If it's true that there is no way to get to those items for a file that has been replaced/deleted in the current version, they (those replace and delete items and the dialogs they trigger) should probably be deleted (new issue?).", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r513450937", "createdAt": "2020-10-28T13:40:58Z", "author": {"login": "qqmyers"}, "path": "src/main/webapp/file.xhtml", "diffHunk": "@@ -267,7 +267,7 @@\n                                                                 </li>\n                                                             </ui:fragment>     \n                                                         </ui:fragment>\n-                                                        <ui:fragment rendered=\"#{FilePage.fileMetadata.dataFile.released and FilePage.draftReplacementFile == false and !FilePage.fileMetadata.dataFile.filePackage}\">                                        \n+                                                        <ui:fragment rendered=\"#{FilePage.draftReplacementFile == false and !FilePage.fileMetadata.dataFile.filePackage}\">                                        \n                                                         <li><!-- start: replace file link -->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzAxNjc2MQ=="}, "originalCommit": {"oid": "d16b3cbf7f937f5b0b6525e587a5e6444f743244"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxOTA2MDI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/UpdateDatasetVersionCommand.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQyMDo0NDo0NlrOHp8tQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNjowMTo0MFrOHrVtQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc0ODI4OA==", "bodyText": "Getting a null pointer here when I try to delete a file via the EditDataFilesPage from the Dataset Page. Will investigate further.", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r513748288", "createdAt": "2020-10-28T20:44:46Z", "author": {"login": "sekmiller"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/UpdateDatasetVersionCommand.java", "diffHunk": "@@ -165,38 +167,77 @@ public Dataset execute(CommandContext ctxt) throws CommandException {\n             }\n             // we have to merge to update the database but not flush because\n             // we don't want to create two draft versions!\n-            // Dataset tempDataset = ctxt.em().merge(theDataset);\n-            //SEK 5/30/2019\n-            // This interim merge is causing:\n-            // java.lang.IllegalArgumentException: Cannot merge an entity that has been removed: edu.harvard.iq.dvn.core.study.FileMetadata\n-            // at the merge at line 177\n-            //Is this merge needed to add the lock?  - seems to be 'no' so what is it needed for?\n-            \n-        //    theDataset = ctxt.em().merge(theDataset);\n+            // Although not completely tested, it looks like this merge handles the\n+            // thumbnail case - if the filemetadata is removed from the context below and\n+            // the dataset still references it, that could cause an issue. Merging here\n+            // avoids any reference from it being the dataset thumbnail\n+            theDataset = ctxt.em().merge(theDataset);\n \n+            /*\n+             * This code has to handle many cases, and anyone making changes should\n+             * carefully check tests and basic methods that update the dataset version. The\n+             * differences between the cases stem primarily from differences in whether the\n+             * files to add, and there filemetadata, and files to delete, and their\n+             * filemetadata have been persisted at this point, which manifests itself as to\n+             * whether they have id numbers or not, and apparently, whether or not they\n+             * exists in lists, e.g. the getFileMetadatas() list of a datafile.\n+             *\n+             * To handle this, the code is carefully checking to make sure that deletions\n+             * are deleting the right things and not, for example, doing a remove(fmd) when\n+             * the fmd.getId() is null, which just removes the first element found.\n+             */\n             for (FileMetadata fmd : filesToDelete) {\n+                logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n+                // if file is draft (ie. new to this version), delete it. Otherwise just remove\n+                // filemetadata object)\n+                // There are a few cases to handle:\n+                // * the fmd has an id (has been persisted) and is the one in the current\n+                // (draft) version\n+                // * the fmd has an id (has been persisted) but it is from a published version\n+                // so we need the corresponding one from the draft version (i.e. created during\n+                // a getEditVersion call)\n+                // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n+                // means to identify it and remove it from lists\n+\n+                if (fmd.getId() != null) {\n+                    // If the datasetversion doesn't match, we have the fmd from a published version\n+                    // and we need to remove the one for the newly created draft instead, so we find\n+                    // it here\n+                    if (theDataset.getEditVersion() != fmd.getDatasetVersion()) {\n+                        fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n+                    }\n+                } else {\n+                    // Not sure if this is needed now that there is a dataset merge above, but we\n+                    // need to assure it is on the context\n+                    fmd = ctxt.em().merge(fmd);\n+                }\n+                // There are two datafile cases as well - the file has been released, so we're\n+                // jsut removing it from the current draft version or it is only in the draft\n+                // version and we completely remove the file.\n                 if (!fmd.getDataFile().isReleased()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d16b3cbf7f937f5b0b6525e587a5e6444f743244"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE1NDA0Ng==", "bodyText": "@sekmiller - The new commits should fix this - the test of the two dataset versions in line 208 needed to use ! .equals() instead of !=, and then an fmd merge was needed (removing the else around line 212.", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r515154046", "createdAt": "2020-10-30T14:51:17Z", "author": {"login": "qqmyers"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/UpdateDatasetVersionCommand.java", "diffHunk": "@@ -165,38 +167,77 @@ public Dataset execute(CommandContext ctxt) throws CommandException {\n             }\n             // we have to merge to update the database but not flush because\n             // we don't want to create two draft versions!\n-            // Dataset tempDataset = ctxt.em().merge(theDataset);\n-            //SEK 5/30/2019\n-            // This interim merge is causing:\n-            // java.lang.IllegalArgumentException: Cannot merge an entity that has been removed: edu.harvard.iq.dvn.core.study.FileMetadata\n-            // at the merge at line 177\n-            //Is this merge needed to add the lock?  - seems to be 'no' so what is it needed for?\n-            \n-        //    theDataset = ctxt.em().merge(theDataset);\n+            // Although not completely tested, it looks like this merge handles the\n+            // thumbnail case - if the filemetadata is removed from the context below and\n+            // the dataset still references it, that could cause an issue. Merging here\n+            // avoids any reference from it being the dataset thumbnail\n+            theDataset = ctxt.em().merge(theDataset);\n \n+            /*\n+             * This code has to handle many cases, and anyone making changes should\n+             * carefully check tests and basic methods that update the dataset version. The\n+             * differences between the cases stem primarily from differences in whether the\n+             * files to add, and there filemetadata, and files to delete, and their\n+             * filemetadata have been persisted at this point, which manifests itself as to\n+             * whether they have id numbers or not, and apparently, whether or not they\n+             * exists in lists, e.g. the getFileMetadatas() list of a datafile.\n+             *\n+             * To handle this, the code is carefully checking to make sure that deletions\n+             * are deleting the right things and not, for example, doing a remove(fmd) when\n+             * the fmd.getId() is null, which just removes the first element found.\n+             */\n             for (FileMetadata fmd : filesToDelete) {\n+                logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n+                // if file is draft (ie. new to this version), delete it. Otherwise just remove\n+                // filemetadata object)\n+                // There are a few cases to handle:\n+                // * the fmd has an id (has been persisted) and is the one in the current\n+                // (draft) version\n+                // * the fmd has an id (has been persisted) but it is from a published version\n+                // so we need the corresponding one from the draft version (i.e. created during\n+                // a getEditVersion call)\n+                // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n+                // means to identify it and remove it from lists\n+\n+                if (fmd.getId() != null) {\n+                    // If the datasetversion doesn't match, we have the fmd from a published version\n+                    // and we need to remove the one for the newly created draft instead, so we find\n+                    // it here\n+                    if (theDataset.getEditVersion() != fmd.getDatasetVersion()) {\n+                        fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n+                    }\n+                } else {\n+                    // Not sure if this is needed now that there is a dataset merge above, but we\n+                    // need to assure it is on the context\n+                    fmd = ctxt.em().merge(fmd);\n+                }\n+                // There are two datafile cases as well - the file has been released, so we're\n+                // jsut removing it from the current draft version or it is only in the draft\n+                // version and we completely remove the file.\n                 if (!fmd.getDataFile().isReleased()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc0ODI4OA=="}, "originalCommit": {"oid": "d16b3cbf7f937f5b0b6525e587a5e6444f743244"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNjQ2Ng==", "bodyText": "Ok. i'm able to delete a file from a draft version. Thanks!", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r515206466", "createdAt": "2020-10-30T16:01:40Z", "author": {"login": "sekmiller"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/UpdateDatasetVersionCommand.java", "diffHunk": "@@ -165,38 +167,77 @@ public Dataset execute(CommandContext ctxt) throws CommandException {\n             }\n             // we have to merge to update the database but not flush because\n             // we don't want to create two draft versions!\n-            // Dataset tempDataset = ctxt.em().merge(theDataset);\n-            //SEK 5/30/2019\n-            // This interim merge is causing:\n-            // java.lang.IllegalArgumentException: Cannot merge an entity that has been removed: edu.harvard.iq.dvn.core.study.FileMetadata\n-            // at the merge at line 177\n-            //Is this merge needed to add the lock?  - seems to be 'no' so what is it needed for?\n-            \n-        //    theDataset = ctxt.em().merge(theDataset);\n+            // Although not completely tested, it looks like this merge handles the\n+            // thumbnail case - if the filemetadata is removed from the context below and\n+            // the dataset still references it, that could cause an issue. Merging here\n+            // avoids any reference from it being the dataset thumbnail\n+            theDataset = ctxt.em().merge(theDataset);\n \n+            /*\n+             * This code has to handle many cases, and anyone making changes should\n+             * carefully check tests and basic methods that update the dataset version. The\n+             * differences between the cases stem primarily from differences in whether the\n+             * files to add, and there filemetadata, and files to delete, and their\n+             * filemetadata have been persisted at this point, which manifests itself as to\n+             * whether they have id numbers or not, and apparently, whether or not they\n+             * exists in lists, e.g. the getFileMetadatas() list of a datafile.\n+             *\n+             * To handle this, the code is carefully checking to make sure that deletions\n+             * are deleting the right things and not, for example, doing a remove(fmd) when\n+             * the fmd.getId() is null, which just removes the first element found.\n+             */\n             for (FileMetadata fmd : filesToDelete) {\n+                logger.fine(\"Deleting fmd: \" + fmd.getId() + \" for file: \" + fmd.getDataFile().getId());\n+                // if file is draft (ie. new to this version), delete it. Otherwise just remove\n+                // filemetadata object)\n+                // There are a few cases to handle:\n+                // * the fmd has an id (has been persisted) and is the one in the current\n+                // (draft) version\n+                // * the fmd has an id (has been persisted) but it is from a published version\n+                // so we need the corresponding one from the draft version (i.e. created during\n+                // a getEditVersion call)\n+                // * the fmd has no id (hasn't been persisted) so we have to use non-id based\n+                // means to identify it and remove it from lists\n+\n+                if (fmd.getId() != null) {\n+                    // If the datasetversion doesn't match, we have the fmd from a published version\n+                    // and we need to remove the one for the newly created draft instead, so we find\n+                    // it here\n+                    if (theDataset.getEditVersion() != fmd.getDatasetVersion()) {\n+                        fmd = FileMetadataUtil.getFmdForFileInEditVersion(fmd, theDataset.getEditVersion());\n+                    }\n+                } else {\n+                    // Not sure if this is needed now that there is a dataset merge above, but we\n+                    // need to assure it is on the context\n+                    fmd = ctxt.em().merge(fmd);\n+                }\n+                // There are two datafile cases as well - the file has been released, so we're\n+                // jsut removing it from the current draft version or it is only in the draft\n+                // version and we completely remove the file.\n                 if (!fmd.getDataFile().isReleased()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc0ODI4OA=="}, "originalCommit": {"oid": "d16b3cbf7f937f5b0b6525e587a5e6444f743244"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODA4MzAxOnYy", "diffSide": "RIGHT", "path": "src/main/java/edu/harvard/iq/dataverse/util/FileMetadataUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNTo1MzoxMVrOHrVXHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNjo1MjoxNlrOHrXm2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwMDc5Ng==", "bodyText": "Getting a null pointer here when I try the uncommon, but previously supported, action of uploading a number of files, but then deleting one before saving the rest to the draft version", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r515200796", "createdAt": "2020-10-30T15:53:11Z", "author": {"login": "sekmiller"}, "path": "src/main/java/edu/harvard/iq/dataverse/util/FileMetadataUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+   Copyright (C) 2005-2012, by the President and Fellows of Harvard College.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+         http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+\n+   Dataverse Network - A web application to share, preserve and analyze research data.\n+   Developed at the Institute for Quantitative Social Science, Harvard University.\n+   Version 3.0.\n+*/\n+\n+package edu.harvard.iq.dataverse.util;\n+\n+import edu.harvard.iq.dataverse.DataFile;\n+import edu.harvard.iq.dataverse.DatasetVersion;\n+import edu.harvard.iq.dataverse.FileMetadata;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.logging.Logger;\n+\n+public class FileMetadataUtil implements java.io.Serializable {\n+    private static final Logger logger = Logger.getLogger(FileMetadataUtil.class.getCanonicalName());\n+\n+    //Delete the filemetadata from the list if and only if it is in the list\n+    public static void removeFileMetadataFromList(Collection<FileMetadata> collection, FileMetadata fmToDelete) {\n+        // With an id, the standard remove will work\n+        if (fmToDelete.getId() != null) {\n+            collection.remove(fmToDelete);\n+        } else {\n+            Iterator<FileMetadata> fmit = collection.iterator();\n+            while (fmit.hasNext()) {\n+                FileMetadata fmd = fmit.next();\n+                // If not, we can remove based on a match based on the id of the related\n+                // datafile\n+                if (fmToDelete.getDataFile().getStorageIdentifier().equals(fmd.getDataFile().getStorageIdentifier())) {\n+                    // and a match on the datasetversion\n+                    if (fmToDelete.getDatasetVersion().getId() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64c9e8838b2049053d3fc2c454cf76714bd4414b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIzNzU5NA==", "bodyText": "Resolved - the new util method assumed that an fmd would always have an associated datasetversion which is not true for this case. - BTW - thanks for the thorough testing!", "url": "https://github.com/IQSS/dataverse/pull/7337#discussion_r515237594", "createdAt": "2020-10-30T16:52:16Z", "author": {"login": "qqmyers"}, "path": "src/main/java/edu/harvard/iq/dataverse/util/FileMetadataUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+   Copyright (C) 2005-2012, by the President and Fellows of Harvard College.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+         http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+\n+   Dataverse Network - A web application to share, preserve and analyze research data.\n+   Developed at the Institute for Quantitative Social Science, Harvard University.\n+   Version 3.0.\n+*/\n+\n+package edu.harvard.iq.dataverse.util;\n+\n+import edu.harvard.iq.dataverse.DataFile;\n+import edu.harvard.iq.dataverse.DatasetVersion;\n+import edu.harvard.iq.dataverse.FileMetadata;\n+\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.logging.Logger;\n+\n+public class FileMetadataUtil implements java.io.Serializable {\n+    private static final Logger logger = Logger.getLogger(FileMetadataUtil.class.getCanonicalName());\n+\n+    //Delete the filemetadata from the list if and only if it is in the list\n+    public static void removeFileMetadataFromList(Collection<FileMetadata> collection, FileMetadata fmToDelete) {\n+        // With an id, the standard remove will work\n+        if (fmToDelete.getId() != null) {\n+            collection.remove(fmToDelete);\n+        } else {\n+            Iterator<FileMetadata> fmit = collection.iterator();\n+            while (fmit.hasNext()) {\n+                FileMetadata fmd = fmit.next();\n+                // If not, we can remove based on a match based on the id of the related\n+                // datafile\n+                if (fmToDelete.getDataFile().getStorageIdentifier().equals(fmd.getDataFile().getStorageIdentifier())) {\n+                    // and a match on the datasetversion\n+                    if (fmToDelete.getDatasetVersion().getId() == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwMDc5Ng=="}, "originalCommit": {"oid": "64c9e8838b2049053d3fc2c454cf76714bd4414b"}, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3169, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}