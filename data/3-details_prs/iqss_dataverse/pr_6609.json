{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcwOTk4NzUw", "number": 6609, "title": "6524 dataset size api", "bodyText": "What this PR does / why we need it:\nThis PR add API endpoints for getting the storage size of a dataset and getting the sum of size of the files available for download in a particular version of a dataset.\nWhich issue(s) this PR closes:\nCloses #6524\nSpecial notes for your reviewer:\nNone\nSuggestions on how to test this:\nNote that the storage size api requires that the token passed has view unpublished. Likewise for the download size, if the version is :draft there must be a token passed with view unpublished permission. No token is required for a published version.\nDoes this PR introduce a user interface change?:\nNo\nIs there a release notes update needed for this change?:\nNo. (could be included in \"additional features/fixes.\"\nAdditional documentation:\nadded doc to native-apt.rst", "createdAt": "2020-02-04T19:00:48Z", "url": "https://github.com/IQSS/dataverse/pull/6609", "merged": true, "mergeCommit": {"oid": "03480232d9d899a89316f374781b743ae7d8c09f"}, "closed": true, "closedAt": "2020-02-06T20:21:07Z", "author": {"login": "sekmiller"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb_JVCegH2gAyMzcwOTk4NzUwOjgwMmFlN2JkMDIyNDQzOTU0MzY3Mzc2OWE0NjdiMDhlNzE0NTYwZWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcBv9FgAH2gAyMzcwOTk4NzUwOjk0NzhjYWExM2VkYTEwOWNmMzUzYWJkYzYzOTRlMTlkMzAzNmZmZTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "802ae7bd0224439543673769a467b08e714560ed", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/802ae7bd0224439543673769a467b08e714560ed", "committedDate": "2020-01-29T17:24:17Z", "message": "#6524 add dataset size api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7de306df8cb91872a2ac672c305b42a94d97fb6", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/e7de306df8cb91872a2ac672c305b42a94d97fb6", "committedDate": "2020-01-29T17:24:32Z", "message": "Merge branch 'develop' into 6524-dataset-size-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9457fec308a7c5537befcdb4c150134081226383", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/9457fec308a7c5537befcdb4c150134081226383", "committedDate": "2020-02-03T18:46:31Z", "message": "#6524 add api endpoints for file storage/download size\n\nat dataset/version level"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcc857d6bcc615ae08058e718ea1de3c14d6deb8", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/dcc857d6bcc615ae08058e718ea1de3c14d6deb8", "committedDate": "2020-02-03T18:46:47Z", "message": "Merge branch 'develop' into 6524-dataset-size-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fef91a8c6f30c2330536922d1b522b0c44ce3af5", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/fef91a8c6f30c2330536922d1b522b0c44ce3af5", "committedDate": "2020-02-03T21:15:03Z", "message": "#6524 update bundle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d18b8158eeeb6cba9ea164256f839a61b11321c", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/2d18b8158eeeb6cba9ea164256f839a61b11321c", "committedDate": "2020-02-04T15:11:22Z", "message": "#6524 add doc for dataset storage size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04f8a222b9c26f1675c439f64f5a02ada1b70b4c", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/04f8a222b9c26f1675c439f64f5a02ada1b70b4c", "committedDate": "2020-02-04T15:12:48Z", "message": "#6524 fix api url"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88851575b79cbbdbc94f0af65fd89827b001850c", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/88851575b79cbbdbc94f0af65fd89827b001850c", "committedDate": "2020-02-04T15:14:42Z", "message": "#6524 fix required permission for storage size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7237c4f6a44ffc72943e1d978a5f3eb599fb7edf", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/7237c4f6a44ffc72943e1d978a5f3eb599fb7edf", "committedDate": "2020-02-04T15:29:28Z", "message": "#6524 allow user with view draft permission to get size of download"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8669089ef59acca06304f088797f1217b599d5a9", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/8669089ef59acca06304f088797f1217b599d5a9", "committedDate": "2020-02-04T16:42:59Z", "message": "#6524 Add doc for download size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "770192b9e7e3c17dcd81192f51d7c3cc27414cda", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/770192b9e7e3c17dcd81192f51d7c3cc27414cda", "committedDate": "2020-02-04T19:03:14Z", "message": "Merge branch 'develop' into 6524-dataset-size-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e", "committedDate": "2020-02-04T19:08:49Z", "message": "#6524 remove unused import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzODg4Mjkw", "url": "https://github.com/IQSS/dataverse/pull/6609#pullrequestreview-353888290", "createdAt": "2020-02-05T17:07:13Z", "commit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxNzowNzoxM1rOFl_3ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxODoyNDozMVrOFmCU7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM4ODA0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              export ID=xxxxxx\n          \n          \n            \n            export ID=42", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375388042", "createdAt": "2020-02-05T17:07:13Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/api/native-api.rst", "diffHunk": "@@ -898,6 +898,52 @@ In practice, you only need one the ``dataset_id`` or the ``persistentId``. The e\n     print '-' * 40\n     print r.json()\n     print r.status_code\n+    \n+Report the data (file) size of a Dataset\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files uploaded into the dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM4ODMzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/storagesize\n          \n          \n            \n              curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/42/storagesize", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375388336", "createdAt": "2020-02-05T17:07:44Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/api/native-api.rst", "diffHunk": "@@ -898,6 +898,52 @@ In practice, you only need one the ``dataset_id`` or the ``persistentId``. The e\n     print '-' * 40\n     print r.json()\n     print r.status_code\n+    \n+Report the data (file) size of a Dataset\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files uploaded into the dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+\n+  curl -H X-Dataverse-key:$API_TOKEN $SERVER_URL/api/datasets/$ID/storagesize\n+\n+The fully expanded example above (without environment variables) looks like this:\n+\n+.. code-block:: bash\n+\n+  curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/storagesize", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM4ODkzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              export ID=xxxxxx\n          \n          \n            \n              export ID=42", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375388936", "createdAt": "2020-02-05T17:08:47Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/api/native-api.rst", "diffHunk": "@@ -898,6 +898,52 @@ In practice, you only need one the ``dataset_id`` or the ``persistentId``. The e\n     print '-' * 40\n     print r.json()\n     print r.status_code\n+    \n+Report the data (file) size of a Dataset\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files uploaded into the dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+\n+  curl -H X-Dataverse-key:$API_TOKEN $SERVER_URL/api/datasets/$ID/storagesize\n+\n+The fully expanded example above (without environment variables) looks like this:\n+\n+.. code-block:: bash\n+\n+  curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/storagesize\n+\n+The size of published and unpublished files will be summed in the dataset specified. \n+By default, only the archival files are counted - i.e., the files uploaded by users (plus the tab-delimited versions generated for tabular data files on ingest). If the optional argument ``includeCached=true`` is specified, the API will also add the sizes of all the extra files generated and cached by Dataverse - the resized thumbnail versions for image files, the metadata exports for published datasets, etc. Because this deals with unpublished files the token supplied must have permission to view unpublished drafts. \n+\n+\n+Get the size of Downloading all the files of a Dataset Version\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files available for download from version ``versionId`` of dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM4OTI1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              export VERSIONID=x.x\n          \n          \n            \n              export VERSIONID=1.0", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375389259", "createdAt": "2020-02-05T17:09:19Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/api/native-api.rst", "diffHunk": "@@ -898,6 +898,52 @@ In practice, you only need one the ``dataset_id`` or the ``persistentId``. The e\n     print '-' * 40\n     print r.json()\n     print r.status_code\n+    \n+Report the data (file) size of a Dataset\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files uploaded into the dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+\n+  curl -H X-Dataverse-key:$API_TOKEN $SERVER_URL/api/datasets/$ID/storagesize\n+\n+The fully expanded example above (without environment variables) looks like this:\n+\n+.. code-block:: bash\n+\n+  curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/storagesize\n+\n+The size of published and unpublished files will be summed in the dataset specified. \n+By default, only the archival files are counted - i.e., the files uploaded by users (plus the tab-delimited versions generated for tabular data files on ingest). If the optional argument ``includeCached=true`` is specified, the API will also add the sizes of all the extra files generated and cached by Dataverse - the resized thumbnail versions for image files, the metadata exports for published datasets, etc. Because this deals with unpublished files the token supplied must have permission to view unpublished drafts. \n+\n+\n+Get the size of Downloading all the files of a Dataset Version\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files available for download from version ``versionId`` of dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+  export VERSIONID=x.x", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM4OTUyMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/versions/x.x/downloadsize\n          \n          \n            \n              curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/42/versions/1.0/downloadsize", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375389522", "createdAt": "2020-02-05T17:09:48Z", "author": {"login": "pdurbin"}, "path": "doc/sphinx-guides/source/api/native-api.rst", "diffHunk": "@@ -898,6 +898,52 @@ In practice, you only need one the ``dataset_id`` or the ``persistentId``. The e\n     print '-' * 40\n     print r.json()\n     print r.status_code\n+    \n+Report the data (file) size of a Dataset\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files uploaded into the dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+\n+  curl -H X-Dataverse-key:$API_TOKEN $SERVER_URL/api/datasets/$ID/storagesize\n+\n+The fully expanded example above (without environment variables) looks like this:\n+\n+.. code-block:: bash\n+\n+  curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/storagesize\n+\n+The size of published and unpublished files will be summed in the dataset specified. \n+By default, only the archival files are counted - i.e., the files uploaded by users (plus the tab-delimited versions generated for tabular data files on ingest). If the optional argument ``includeCached=true`` is specified, the API will also add the sizes of all the extra files generated and cached by Dataverse - the resized thumbnail versions for image files, the metadata exports for published datasets, etc. Because this deals with unpublished files the token supplied must have permission to view unpublished drafts. \n+\n+\n+Get the size of Downloading all the files of a Dataset Version\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Shows the combined size in bytes of all the files available for download from version ``versionId`` of dataset ``id``. ::\n+\n+.. code-block:: bash\n+\n+  export API_TOKEN=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n+  export SERVER_URL=https://demo.dataverse.org\n+  export ID=xxxxxx\n+  export VERSIONID=x.x\n+\n+  curl -H X-Dataverse-key:$API_TOKEN $SERVER_URL/api/datasets/$ID/versions/$VERSIONID/downloadsize\n+\n+The fully expanded example above (without environment variables) looks like this:\n+\n+.. code-block:: bash\n+\n+  curl -H X-Dataverse-key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx https://demo.dataverse.org/api/datasets/xxxxxx/versions/x.x/downloadsize", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTM5MTEwMA==", "bodyText": "Sorry to nitpick but it's \"tally\" without an \"e\".", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375391100", "createdAt": "2020-02-05T17:12:33Z", "author": {"login": "pdurbin"}, "path": "src/main/java/edu/harvard/iq/dataverse/DatasetServiceBean.java", "diffHunk": "@@ -866,45 +866,67 @@ public void obtainPersistentIdentifiersForDatafiles(Dataset dataset) {\n     }\n     \n     public long findStorageSize(Dataset dataset) throws IOException {\n-        return findStorageSize(dataset, false);\n+        return findStorageSize(dataset, false, \"storage\", null);\n     }\n     \n+    \n+    public long findStorageSize(Dataset dataset, boolean countCachedExtras) throws IOException {\n+        return findStorageSize(dataset, countCachedExtras, \"storage\", null);\n+    }\n+  \n     /**\n      * Returns the total byte size of the files in this dataset \n      * \n      * @param dataset\n      * @param countCachedExtras boolean indicating if the cached disposable extras should also be counted\n+     * @param mode String indicating whether we are getting the result for storage (entire dataset) or download version based\n+     * @param version optional param for dataset version\n      * @return total size \n      * @throws IOException if it can't access the objects via StorageIO \n      * (in practice, this can only happen when called with countCachedExtras=true; when run in the \n      * default mode, the method doesn't need to access the storage system, as the \n      * sizes of the main files are recorded in the database)\n      */\n-    public long findStorageSize(Dataset dataset, boolean countCachedExtras) throws IOException {\n+    public long findStorageSize(Dataset dataset, boolean countCachedExtras, String mode, DatasetVersion version) throws IOException {\n         long total = 0L; \n         \n         if (dataset.isHarvested()) {\n             return 0L;\n         }\n+\n+        List<DataFile> filesToTalley = new ArrayList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTQyNzgyMg==", "bodyText": "It would be nice to document the accepted values for \"mode\".", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375427822", "createdAt": "2020-02-05T18:23:28Z", "author": {"login": "pdurbin"}, "path": "src/main/java/edu/harvard/iq/dataverse/DatasetServiceBean.java", "diffHunk": "@@ -866,45 +866,67 @@ public void obtainPersistentIdentifiersForDatafiles(Dataset dataset) {\n     }\n     \n     public long findStorageSize(Dataset dataset) throws IOException {\n-        return findStorageSize(dataset, false);\n+        return findStorageSize(dataset, false, \"storage\", null);\n     }\n     \n+    \n+    public long findStorageSize(Dataset dataset, boolean countCachedExtras) throws IOException {\n+        return findStorageSize(dataset, countCachedExtras, \"storage\", null);\n+    }\n+  \n     /**\n      * Returns the total byte size of the files in this dataset \n      * \n      * @param dataset\n      * @param countCachedExtras boolean indicating if the cached disposable extras should also be counted\n+     * @param mode String indicating whether we are getting the result for storage (entire dataset) or download version based", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTQyODMzNA==", "bodyText": "Instead of a String for \"mode\" and enum would be nice. More type safe that way. And auto documenting.", "url": "https://github.com/IQSS/dataverse/pull/6609#discussion_r375428334", "createdAt": "2020-02-05T18:24:31Z", "author": {"login": "pdurbin"}, "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/GetDatasetStorageSizeCommand.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * To change this license header, choose License Headers in Project Properties.\n+ * To change this template file, choose Tools | Templates\n+ * and open the template in the editor.\n+ */\n+package edu.harvard.iq.dataverse.engine.command.impl;\n+\n+import edu.harvard.iq.dataverse.Dataset;\n+import edu.harvard.iq.dataverse.DatasetVersion;\n+import edu.harvard.iq.dataverse.Dataverse;\n+import edu.harvard.iq.dataverse.authorization.Permission;\n+import edu.harvard.iq.dataverse.engine.command.AbstractCommand;\n+import edu.harvard.iq.dataverse.engine.command.CommandContext;\n+import edu.harvard.iq.dataverse.engine.command.DataverseRequest;\n+import edu.harvard.iq.dataverse.engine.command.RequiredPermissions;\n+import edu.harvard.iq.dataverse.engine.command.exception.CommandException;\n+import edu.harvard.iq.dataverse.util.BundleUtil;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+/**\n+ *\n+ * @author skraffmi\n+ */\n+@RequiredPermissions({})\n+public class GetDatasetStorageSizeCommand extends AbstractCommand<Long> {\n+\n+    private static final Logger logger = Logger.getLogger(GetDataverseStorageSizeCommand.class.getCanonicalName());\n+\n+    private final Dataset dataset;\n+    private final Boolean countCachedFiles;\n+    private final String mode;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9dc2fdafbc387fb848e1c3b7edb5c95dc5993d0e"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "915c9e05aacc3479f12dd48e54f46dd568b179b2", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/915c9e05aacc3479f12dd48e54f46dd568b179b2", "committedDate": "2020-02-05T22:01:21Z", "message": "Merge branch 'develop' into 6524-dataset-size-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87225bd46ef25f6d152f075c5eed5b3687882f41", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/87225bd46ef25f6d152f075c5eed5b3687882f41", "committedDate": "2020-02-06T15:19:21Z", "message": "#6524 make \"mode\" enum and fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd3b97fde322c6f5dd68fdde196f9819c6915b20", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/bd3b97fde322c6f5dd68fdde196f9819c6915b20", "committedDate": "2020-02-06T15:22:33Z", "message": "#6524 fix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ed63c5770f213ce0bf30243c6aa63a94a7e52ac", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/8ed63c5770f213ce0bf30243c6aa63a94a7e52ac", "committedDate": "2020-02-06T18:58:05Z", "message": "Merge branch 'develop' into 6524-dataset-size-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9478caa13eda109cf353abdc6394e19d3036ffe5", "author": {"user": {"login": "sekmiller", "name": "Stephen Kraffmiller"}}, "url": "https://github.com/IQSS/dataverse/commit/9478caa13eda109cf353abdc6394e19d3036ffe5", "committedDate": "2020-02-06T19:32:16Z", "message": "#6524 fix required permissions add tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1029, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}