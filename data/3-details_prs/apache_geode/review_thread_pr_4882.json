{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1NDUwNTA5", "number": 4882, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzoyMjo1OFrODsxoQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODo1MToxMVrODsztjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Mjc3MDU5OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzoyMjo1OFrOF90PRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzo0ODo1MFrOF91Qeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2MzMzMw==", "bodyText": "Typo here, this should be destroysByRegion.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400363333", "createdAt": "2020-03-30T17:22:58Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -211,8 +357,52 @@ public void afterRegionClear(RegionEvent event) {\n       clears.incrementAndGet();\n     }\n \n+    @Override\n+    public void afterRegionDestroy(RegionEvent event) {\n+      Region region = event.getRegion();\n+      logger.info(\"Region \" + region.getFullPath() + \" is destroyed.\");\n+      destroyes.incrementAndGet();\n+    }\n+\n     int getClears() {\n       return clears.get();\n     }\n+\n+    int getDestroys() {\n+      return destroyes.get();\n+    }\n+  }\n+\n+  public static HashMap<String, AtomicInteger> clearsByRegion = new HashMap<>();\n+  public static HashMap<String, AtomicInteger> destroyesByRegion = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4MDAyNg==", "bodyText": "I will fix it.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400380026", "createdAt": "2020-03-30T17:48:50Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -211,8 +357,52 @@ public void afterRegionClear(RegionEvent event) {\n       clears.incrementAndGet();\n     }\n \n+    @Override\n+    public void afterRegionDestroy(RegionEvent event) {\n+      Region region = event.getRegion();\n+      logger.info(\"Region \" + region.getFullPath() + \" is destroyed.\");\n+      destroyes.incrementAndGet();\n+    }\n+\n     int getClears() {\n       return clears.get();\n     }\n+\n+    int getDestroys() {\n+      return destroyes.get();\n+    }\n+  }\n+\n+  public static HashMap<String, AtomicInteger> clearsByRegion = new HashMap<>();\n+  public static HashMap<String, AtomicInteger> destroyesByRegion = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2MzMzMw=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 289}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4Mjc5NzA2OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzoyOTozMFrOF90f-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODozODowOVrOF93GFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2NzYxMQ==", "bodyText": "It seems inefficient and confusing to set the cache writer for all three data stores, then to immediately remove the writers for datastores1 and 2. Could you instead just pass false as the second argument for initDataStore() for those datastores?", "url": "https://github.com/apache/geode/pull/4882#discussion_r400367611", "createdAt": "2020-03-30T17:29:30Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4MDg5OQ==", "bodyText": "I don't have to remove them. But I want to make sure the test is more deterministic.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400380899", "createdAt": "2020-03-30T17:50:09Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2NzYxMQ=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMDEzMg==", "bodyText": "I agree with Donal, doing this we are testing the behavior of AttributesMutator, not for clear.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400410132", "createdAt": "2020-03-30T18:38:09Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2NzYxMQ=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgwMjk2OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozMDo1OFrOF90jwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODo0NDozOFrOF93U0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2ODU3OA==", "bodyText": "Typo here, this should be destroys.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400368578", "createdAt": "2020-03-30T17:30:58Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n+  }\n+\n+  @Test\n+  public void normalClearFromAccessorWithoutWriterButWithWriterOnDataStore() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    accessor.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n   }\n \n   @Test\n   public void normalClearFromClient() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     client1.invoke(() -> feed(true));\n     verifyClientRegionSize(NUM_ENTRIES);\n     verifyServerRegionSize(NUM_ENTRIES);\n \n     client1.invoke(() -> getRegion(true).clear());\n     verifyServerRegionSize(0);\n     verifyClientRegionSize(0);\n-    verifyCacheListenerTriggerCount(null);\n+    // verifyCacheListenerTriggerCount(null);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    client1.invoke(() -> {\n+      Region region = getRegion(true);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n   }\n \n   private static class CountingCacheListener extends CacheListenerAdapter {\n     private final AtomicInteger clears = new AtomicInteger();\n+    private final AtomicInteger destroyes = new AtomicInteger();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMzkwNg==", "bodyText": "Does this PR requires CacheListener testing.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400413906", "createdAt": "2020-03-30T18:44:38Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n+  }\n+\n+  @Test\n+  public void normalClearFromAccessorWithoutWriterButWithWriterOnDataStore() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    accessor.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n   }\n \n   @Test\n   public void normalClearFromClient() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     client1.invoke(() -> feed(true));\n     verifyClientRegionSize(NUM_ENTRIES);\n     verifyServerRegionSize(NUM_ENTRIES);\n \n     client1.invoke(() -> getRegion(true).clear());\n     verifyServerRegionSize(0);\n     verifyClientRegionSize(0);\n-    verifyCacheListenerTriggerCount(null);\n+    // verifyCacheListenerTriggerCount(null);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    client1.invoke(() -> {\n+      Region region = getRegion(true);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n   }\n \n   private static class CountingCacheListener extends CacheListenerAdapter {\n     private final AtomicInteger clears = new AtomicInteger();\n+    private final AtomicInteger destroyes = new AtomicInteger();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2ODU3OA=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 264}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgwOTgxOnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozMjo0MFrOF90n4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzo1MTo0MVrOF91XfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2OTYzMg==", "bodyText": "Is there something missing here, or can this comment be removed?", "url": "https://github.com/apache/geode/pull/4882#discussion_r400369632", "createdAt": "2020-03-30T17:32:40Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4MTgyMA==", "bodyText": "The listener verification will also pass. But since the whole listener parts maybe refactoring, I comment it out for now. But we will revisit it.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400381820", "createdAt": "2020-03-30T17:51:41Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2OTYzMg=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgyNzkyOnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNjo1OVrOF90y5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNjo1OVrOF90y5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3MjQ1Mw==", "bodyText": "Remove commented code.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400372453", "createdAt": "2020-03-30T17:36:59Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgyODcwOnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNzoxMlrOF90zXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzo1MjowNVrOF91YUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3MjU3Mg==", "bodyText": "Remove commented code.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400372572", "createdAt": "2020-03-30T17:37:12Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4MjAzMg==", "bodyText": "It's kind of \"TODO\".", "url": "https://github.com/apache/geode/pull/4882#discussion_r400382032", "createdAt": "2020-03-30T17:52:05Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3MjU3Mg=="}, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 190}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgyOTY4OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNzoyNlrOF90z_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNzoyNlrOF90z_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3MjczMw==", "bodyText": "Remove commented code.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400372733", "createdAt": "2020-03-30T17:37:26Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n+  }\n+\n+  @Test\n+  public void normalClearFromAccessorWithoutWriterButWithWriterOnDataStore() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    accessor.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(accessor);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MjgzMDExOnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNzozNVrOF900TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxNzozNzozNVrOF900TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3MjgxMw==", "bodyText": "Remove commented code.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400372813", "createdAt": "2020-03-30T17:37:35Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,38 +183,172 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroyesByRegion.get(REGION_NAME) == null ? 0 : destroyesByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n+  }\n+\n   @Test\n-  public void normalClearFromDataStore() {\n+  public void normalClearFromDataStoreWithoutWriterOnDataStore() {\n+    configureServers(false, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     dataStore1.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(dataStore1);\n+    // verifyCacheListenerTriggerCount(dataStore1);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n   }\n \n   @Test\n-  public void normalClearFromAccessor() {\n+  public void normalClearFromAccessorWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     accessor.invoke(() -> feed(false));\n     verifyServerRegionSize(NUM_ENTRIES);\n     accessor.invoke(() -> getRegion(false).clear());\n     verifyServerRegionSize(0);\n-    verifyCacheListenerTriggerCount(accessor);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(1);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(1);\n+  }\n+\n+  @Test\n+  public void normalClearFromAccessorWithoutWriterButWithWriterOnDataStore() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    accessor.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    // verifyCacheListenerTriggerCount(accessor);\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    accessor.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();\n+    });\n+    assertThat(dataStore1.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterDestroys)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterDestroys)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterDestroys)).isEqualTo(0);\n   }\n \n   @Test\n   public void normalClearFromClient() {\n+    configureServers(true, false);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n     client1.invoke(() -> feed(true));\n     verifyClientRegionSize(NUM_ENTRIES);\n     verifyServerRegionSize(NUM_ENTRIES);\n \n     client1.invoke(() -> getRegion(true).clear());\n     verifyServerRegionSize(0);\n     verifyClientRegionSize(0);\n-    verifyCacheListenerTriggerCount(null);\n+    // verifyCacheListenerTriggerCount(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b412d216683fbc28fbc5fe8fb6d36d5edaa7d92f"}, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzA3NDM3OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODo0MDo1MVrOF93MPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMzozODo0NFrOF-AH5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMTcxMA==", "bodyText": "There is \"PartitionedRegionLoaderWriterDUnitTest\" specific to testing loader and writers on PR. Probably we should move these tests over there.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400411710", "createdAt": "2020-03-30T18:40:51Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -104,14 +102,21 @@ private void initClientCache() {\n     region.registerInterestForAllKeys(InterestResultPolicy.KEYS);\n   }\n \n-  private void initDataStore() {\n-    getCache().createRegionFactory(getRegionShortCut())\n-        .setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(10).create())\n-        .addCacheListener(new CountingCacheListener())\n-        .create(REGION_NAME);\n+  private void initDataStore(boolean withListener, boolean withWriter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ5MTY5Ng==", "bodyText": "I read the PartitionedRegionLoaderWriterDUnitTest. That is only to verify compatibility when creating region. We are testing the clear() operation's behavior.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400491696", "createdAt": "2020-03-30T21:02:27Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -104,14 +102,21 @@ private void initClientCache() {\n     region.registerInterestForAllKeys(InterestResultPolicy.KEYS);\n   }\n \n-  private void initDataStore() {\n-    getCache().createRegionFactory(getRegionShortCut())\n-        .setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(10).create())\n-        .addCacheListener(new CountingCacheListener())\n-        .create(REGION_NAME);\n+  private void initDataStore(boolean withListener, boolean withWriter) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMTcxMA=="}, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU1ODA1Mw==", "bodyText": "You can add/extend the test as per your needs. The tests seems to be added for CacheLaderWriter and may be during that time, the need is to test create region.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400558053", "createdAt": "2020-03-30T23:38:44Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -104,14 +102,21 @@ private void initClientCache() {\n     region.registerInterestForAllKeys(InterestResultPolicy.KEYS);\n   }\n \n-  private void initDataStore() {\n-    getCache().createRegionFactory(getRegionShortCut())\n-        .setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(10).create())\n-        .addCacheListener(new CountingCacheListener())\n-        .create(REGION_NAME);\n+  private void initDataStore(boolean withListener, boolean withWriter) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMTcxMA=="}, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzA3ODU4OnYy", "diffSide": "RIGHT", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODo0MjowM1rOF93O4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMzozOToyN1rOF-AJAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjM4NQ==", "bodyText": "The test is doing region destroy but the name suggests it is for clear. All the tests are doing region destroy, rather than clear.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400412385", "createdAt": "2020-03-30T18:42:03Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,26 +183,146 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroysByRegion.get(REGION_NAME) == null ? 0 : destroysByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    verifyCacheListenerTriggerCount(dataStore3);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ5MjMwNg==", "bodyText": "I use destroy to compare. I can add a comments in the case. If I removed the destroy part, it's hard to show what's the expected behavior.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400492306", "createdAt": "2020-03-30T21:03:35Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,26 +183,146 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroysByRegion.get(REGION_NAME) == null ? 0 : destroysByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    verifyCacheListenerTriggerCount(dataStore3);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjM4NQ=="}, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU1ODMzNg==", "bodyText": "Probably separating test may be good idea. One for destroy and one for Clear.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400558336", "createdAt": "2020-03-30T23:39:27Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -171,26 +183,146 @@ private void verifyCacheListenerTriggerCount(MemberVM serverVM) {\n     }\n   }\n \n+  SerializableCallableIF<Integer> getWriterClears = () -> {\n+    int clears =\n+        clearsByRegion.get(REGION_NAME) == null ? 0 : clearsByRegion.get(REGION_NAME).get();\n+    return clears;\n+  };\n+\n+  SerializableCallableIF<Integer> getWriterDestroys = () -> {\n+    int destroys =\n+        destroysByRegion.get(REGION_NAME) == null ? 0 : destroysByRegion.get(REGION_NAME).get();\n+    return destroys;\n+  };\n+\n+  void configureServers(boolean dataStoreWithWriter, boolean accessorWithWriter) {\n+    dataStore1.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore2.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    dataStore3.invoke(() -> initDataStore(true, dataStoreWithWriter));\n+    accessor.invoke(() -> initAccessor(true, accessorWithWriter));\n+    // make sure only datastore3 has cacheWriter\n+    dataStore1.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+    dataStore2.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.getAttributesMutator().setCacheWriter(null);\n+    });\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStoreWithWriterOnDataStore() {\n+    configureServers(true, true);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+\n+    accessor.invoke(() -> feed(false));\n+    verifyServerRegionSize(NUM_ENTRIES);\n+    dataStore3.invoke(() -> getRegion(false).clear());\n+    verifyServerRegionSize(0);\n+    verifyCacheListenerTriggerCount(dataStore3);\n+\n+    assertThat(dataStore1.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore2.invoke(getWriterClears)).isEqualTo(0);\n+    assertThat(dataStore3.invoke(getWriterClears)).isEqualTo(1);\n+    assertThat(accessor.invoke(getWriterClears)).isEqualTo(0);\n+\n+    dataStore3.invoke(() -> {\n+      Region region = getRegion(false);\n+      region.destroyRegion();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjM4NQ=="}, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzExMTgxOnYy", "diffSide": "RIGHT", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQxODo1MToxMVrOF93j5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMzoyNDo0NFrOF9_1sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNzc2Ng==", "bodyText": "Can the caller pass in the Processor. We could avoid checking for operation.\nAlso is paction -> processorAction ? can we make it clear. Sorry for nitpicking. Just wanted to be clear with what we are doing.", "url": "https://github.com/apache/geode/pull/4882#discussion_r400417766", "createdAt": "2020-03-30T18:51:11Z", "author": {"login": "agingade"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -4428,6 +4431,35 @@ public Object getFromLocalBucket(int bucketId, final Object key, final Object aC\n     return null;\n   }\n \n+  boolean triggerWriter(RegionEventImpl event) {\n+    CacheWriter localWriter = basicGetWriter();\n+    Set netWriteRecipients = localWriter == null ? this.distAdvisor.adviseNetWrite() : null;\n+\n+    if (localWriter == null && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {\n+      return false;\n+    }\n+\n+    final long start = getCachePerfStats().startCacheWriterCall();\n+    try {\n+      SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();\n+      String theKey = \"preDestroyRegion\";\n+      int paction = 0;\n+      if (event.getOperation().isRegionDestroy()) {\n+        theKey = \"preDestroyRegion\";\n+        paction = SearchLoadAndWriteProcessor.BEFOREREGIONDESTROY;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU1MzM5Mg==", "bodyText": "fixed and I removed all the listener part tests", "url": "https://github.com/apache/geode/pull/4882#discussion_r400553392", "createdAt": "2020-03-30T23:24:44Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -4428,6 +4431,35 @@ public Object getFromLocalBucket(int bucketId, final Object key, final Object aC\n     return null;\n   }\n \n+  boolean triggerWriter(RegionEventImpl event) {\n+    CacheWriter localWriter = basicGetWriter();\n+    Set netWriteRecipients = localWriter == null ? this.distAdvisor.adviseNetWrite() : null;\n+\n+    if (localWriter == null && (netWriteRecipients == null || netWriteRecipients.isEmpty())) {\n+      return false;\n+    }\n+\n+    final long start = getCachePerfStats().startCacheWriterCall();\n+    try {\n+      SearchLoadAndWriteProcessor processor = SearchLoadAndWriteProcessor.getProcessor();\n+      String theKey = \"preDestroyRegion\";\n+      int paction = 0;\n+      if (event.getOperation().isRegionDestroy()) {\n+        theKey = \"preDestroyRegion\";\n+        paction = SearchLoadAndWriteProcessor.BEFOREREGIONDESTROY;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNzc2Ng=="}, "originalCommit": {"oid": "3437617085ff9416bcf5c163a692a2bc45a2d9c5"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4461, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}