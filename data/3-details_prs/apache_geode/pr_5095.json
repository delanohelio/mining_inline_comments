{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2NDE3NDc1", "number": 5095, "title": "GEODE-7680: PR.clear must be successful when interacting with rebalance", "bodyText": "Added DUnit tests to confirm that clear does not interfere with\nrebalance or vice versa\nFixed typo in PartitionedRegionClearWithExpirationDUnitTest\nFixed typo in PartitionedRegion\n\nAuthored-by: Donal Evans doevans@pivotal.io\nThank you for submitting a contribution to Apache Geode.\nIn order to streamline the review of the contribution we ask you\nto ensure the following steps have been taken:\nFor all changes:\n\n\n Is there a JIRA ticket associated with this PR? Is it referenced in the commit message?\n\n\n Has your PR been rebased against the latest commit within the target branch (typically develop)?\n\n\n Is your initial contribution a single, squashed commit?\n\n\n Does gradlew build run cleanly?\n\n\n Have you written or updated unit tests to verify your changes?\n\n\n[N/A] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under ASF 2.0?\n\n\nNote:\nPlease ensure that once the PR is submitted, check Concourse for build issues and\nsubmit an update to your PR as soon as possible. If you need help, please send an\nemail to dev@geode.apache.org.", "createdAt": "2020-05-12T00:28:26Z", "url": "https://github.com/apache/geode/pull/5095", "merged": true, "mergeCommit": {"oid": "b941d7fe7fb0df69636fbb7847899d10cf281dea"}, "closed": true, "closedAt": "2020-07-23T15:14:18Z", "author": {"login": "DonalEvans"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcg17quAFqTQwOTgwMTI0MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3e4DxAFqTQ1MzU2NDg0OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5ODAxMjQx", "url": "https://github.com/apache/geode/pull/5095#pullrequestreview-409801241", "createdAt": "2020-05-12T08:12:37Z", "commit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODoxMjozOFrOGT7IHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODoxMjo0M1rOGT7ITQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NDg2MQ==", "bodyText": "Good catch!.", "url": "https://github.com/apache/geode/pull/5095#discussion_r423544861", "createdAt": "2020-05-12T08:12:38Z", "author": {"login": "jujoramos"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithExpirationDUnitTest.java", "diffHunk": "@@ -323,7 +323,7 @@ public void clearShouldRemoveRegisteredExpirationTasks(TestVM coordinatorVM,\n \n     // Assert Region Buckets are consistent and region is empty,\n     accessor.invoke(this::assertRegionBucketsConsistency);\n-    assertRegionIsEmpty(asList(accessor, server1, server1));\n+    assertRegionIsEmpty(asList(accessor, server1, server2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NDkwOQ==", "bodyText": "Good catch!.", "url": "https://github.com/apache/geode/pull/5095#discussion_r423544909", "createdAt": "2020-05-12T08:12:43Z", "author": {"login": "jujoramos"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithExpirationDUnitTest.java", "diffHunk": "@@ -460,7 +460,7 @@ public void clearShouldSucceedAndRemoveRegisteredExpirationTasksWhenNonCoordinat\n \n     // Assert Region Buckets are consistent and region is empty,\n     accessor.invoke(this::assertRegionBucketsConsistency);\n-    assertRegionIsEmpty(asList(accessor, server1, server1));\n+    assertRegionIsEmpty(asList(accessor, server1, server2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDExMjUyODI1", "url": "https://github.com/apache/geode/pull/5095#pullrequestreview-411252825", "createdAt": "2020-05-13T19:56:30Z", "commit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QxOTo1NjozMFrOGVBTqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xM1QyMDoyNjowNVrOGVCRiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDY5OQ==", "bodyText": "There could be possibility that, by the time the \"wait\" here and \"wait\" in before the clear call (the sleep after first unsuccessful check); and with thread scheduling, the rebalance of buckets may be completed, before the clear start. Very less likely, but may be.", "url": "https://github.com/apache/geode/pull/5095#discussion_r424694699", "createdAt": "2020-05-13T19:56:30Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwMTMxNg==", "bodyText": "Its same as \"startRebalanceAndGetResults()\"; can it be called here as done in previous test.", "url": "https://github.com/apache/geode/pull/5095#discussion_r424701316", "createdAt": "2020-05-13T20:08:50Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));\n+    getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+    return rebalanceOp.getResults();\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      Assertions.assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress())\n+          .isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress())\n+          .isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      Assertions.assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no bucket creates failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalanceBucketCreatesFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalancePrimaryReassignmentClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until primary reassignment has started before signalling the\n+      // blackboard\n+      RebalanceOperation rebalanceOp =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxMDUzNg==", "bodyText": "Do we need additional check to see cache is closed...When this vm is restarted, it creates the cache again.", "url": "https://github.com/apache/geode/pull/5095#discussion_r424710536", "createdAt": "2020-05-13T20:26:05Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));\n+    getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+    return rebalanceOp.getResults();\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      Assertions.assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress())\n+          .isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress())\n+          .isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      Assertions.assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no bucket creates failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalanceBucketCreatesFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalancePrimaryReassignmentClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until primary reassignment has started before signalling the\n+      // blackboard\n+      RebalanceOperation rebalanceOp =\n+          cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+      await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+          .getStats().getRebalancePrimaryTransfersCompleted(), greaterThan(0)));\n+      getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+      // Verify that rebalance did some work\n+      RebalanceResults results = rebalanceOp.getResults();\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no primary transfers failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalancePrimaryTransfersFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegionWhenNonCoordinatorIsBounced(\n+      TestVM clearCoordinatorVM, TestVM rebalanceVM, RegionShortcut regionType)\n+      throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    // Server 2 is never the clear coordinator\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until bucket creation for redundancy recovery has started before\n+      // signalling the blackboard\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Bring server 2 back online and assign buckets\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionType);\n+      await().untilAsserted(\n+          () -> Assertions.assertThat(InternalDistributedSystem.getConnectedInstance())\n+              .isNotNull());\n+      PartitionRegionHelper.assignBucketsToPartitions(cacheRule.getCache().getRegion(REGION_NAME));\n+    });\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * Shutdowns a member while the clear operation is in progress.\n+   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n+   * it's the clear coordinator or another member holding primary buckets.\n+   */\n+  public static class MemberKiller extends CacheWriterAdapter<String, String> {\n+\n+    @Override\n+    public synchronized void beforeRegionClear(RegionEvent<String, String> event)\n+        throws CacheWriterException {\n+      InternalDistributedSystem.getConnectedInstance().stopReconnectingNoDisconnect();\n+      MembershipManagerHelper.crashDistributedSystem(\n+          InternalDistributedSystem.getConnectedInstance());\n+      await().untilAsserted(\n+          () -> Assertions.assertThat(InternalDistributedSystem.getConnectedInstance()).isNull());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2"}, "originalPosition": 372}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2717630164a15fc493c06eeafc647ac7c8e238e2", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/2717630164a15fc493c06eeafc647ac7c8e238e2", "committedDate": "2020-05-12T00:25:04Z", "message": "GEODE-7680: PR.clear must be successful when interacting with rebalance\n\n- Added DUnit tests to confirm that clear does not interfere with\nrebalance or vice versa\n- Fixed typo in PartitionedRegionClearWithExpirationDUnitTest\n- Fixed typo in PartitionedRegion\n\nAuthored-by: Donal Evans <doevans@pivotal.io>"}, "afterCommit": {"oid": "471174e0428631bf9382e293c04ce2da8de78a06", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/471174e0428631bf9382e293c04ce2da8de78a06", "committedDate": "2020-05-26T19:33:37Z", "message": "Rebased on feature branch, added tests for colocated regions\n\n- Call assignBucketsToPartitions() on leader colocated region during clear\ninstead of target region\n- Remove HA test, since clear always throws PartialClearException when\nmember departs and rebalance behaviour when member departs is already\ncovered\n\nAuthored-by: Donal Evans <doevans@pivotal.io>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4Njg2MjAz", "url": "https://github.com/apache/geode/pull/5095#pullrequestreview-418686203", "createdAt": "2020-05-26T21:17:52Z", "commit": {"oid": "471174e0428631bf9382e293c04ce2da8de78a06"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToxNzo1MlrOGawpyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToxNzo1MlrOGawpyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMzI5MA==", "bodyText": "Looks good. If it is fine with you, can you add one more scenario, where there are 3 data nodes/servers and one of the server is brought down (case 1) and brought up (case 2); during clear, rebalance in progress....", "url": "https://github.com/apache/geode/pull/5095#discussion_r430713290", "createdAt": "2020-05-26T21:17:52Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,386 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.SerializableRunnableIF;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "471174e0428631bf9382e293c04ce2da8de78a06"}, "originalPosition": 63}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "471174e0428631bf9382e293c04ce2da8de78a06", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/471174e0428631bf9382e293c04ce2da8de78a06", "committedDate": "2020-05-26T19:33:37Z", "message": "Rebased on feature branch, added tests for colocated regions\n\n- Call assignBucketsToPartitions() on leader colocated region during clear\ninstead of target region\n- Remove HA test, since clear always throws PartialClearException when\nmember departs and rebalance behaviour when member departs is already\ncovered\n\nAuthored-by: Donal Evans <doevans@pivotal.io>"}, "afterCommit": {"oid": "929aee49153e7c1b1eece5ae7349883916ccce71", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/929aee49153e7c1b1eece5ae7349883916ccce71", "committedDate": "2020-07-10T01:03:44Z", "message": "Add HA test cases\n\n- Test when member departs during clear/rebalance\n- Test when member joins during clear/rebalance\n- Add retry to clear if PartialClearException is thrown\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "929aee49153e7c1b1eece5ae7349883916ccce71", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/929aee49153e7c1b1eece5ae7349883916ccce71", "committedDate": "2020-07-10T01:03:44Z", "message": "Add HA test cases\n\n- Test when member departs during clear/rebalance\n- Test when member joins during clear/rebalance\n- Add retry to clear if PartialClearException is thrown\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}, "afterCommit": {"oid": "84b7f96cb6934816ba34228ba1317836f6343c73", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/84b7f96cb6934816ba34228ba1317836f6343c73", "committedDate": "2020-07-15T20:38:08Z", "message": "Refactor DUnit tests, remove redundant test cases\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "84b7f96cb6934816ba34228ba1317836f6343c73", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/84b7f96cb6934816ba34228ba1317836f6343c73", "committedDate": "2020-07-15T20:38:08Z", "message": "Refactor DUnit tests, remove redundant test cases\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}, "afterCommit": {"oid": "94deeb83f26761b935c7e98657f379f3a1e1fc7b", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/94deeb83f26761b935c7e98657f379f3a1e1fc7b", "committedDate": "2020-07-17T19:59:56Z", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e40815146e960c5957db1b479b2733caaba0178b", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/e40815146e960c5957db1b479b2733caaba0178b", "committedDate": "2020-07-17T20:04:44Z", "message": "GEODE-7680: PR.clear must be successful when interacting with rebalance\n\n- Added DUnit tests to confirm that clear does not interfere with\nrebalance or vice versa\n- Fixed typo in PartitionedRegionClearWithExpirationDUnitTest\n- Fixed typo in PartitionedRegion\n\nAuthored-by: Donal Evans <doevans@pivotal.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "858dc74fc3d092abcf48b0d7c34a19bba1212edf", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/858dc74fc3d092abcf48b0d7c34a19bba1212edf", "committedDate": "2020-07-17T20:04:45Z", "message": "Rebased on feature branch, added tests for colocated regions\n\n- Call assignBucketsToPartitions() on leader colocated region during clear\ninstead of target region\n- Remove HA test, since clear always throws PartialClearException when\nmember departs and rebalance behaviour when member departs is already\ncovered\n\nAuthored-by: Donal Evans <doevans@pivotal.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46192dea9398fea92951eeb853a5ced997f9946e", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/46192dea9398fea92951eeb853a5ced997f9946e", "committedDate": "2020-07-17T20:04:45Z", "message": "Add HA test cases\n\n- Test when member departs during clear/rebalance\n- Test when member joins during clear/rebalance\n- Add retry to clear if PartialClearException is thrown\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9d910e2bf2ea99667c77ad17b8f1ef3377dabea", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/f9d910e2bf2ea99667c77ad17b8f1ef3377dabea", "committedDate": "2020-07-17T20:04:45Z", "message": "Fix failing unit tests\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cadadaad343badd1b3a30153f449e6c68a10844", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/4cadadaad343badd1b3a30153f449e6c68a10844", "committedDate": "2020-07-17T20:04:45Z", "message": "Refactor DUnit tests, remove redundant test cases\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e03b1e796669f05c8debc07c256b7d99d94ce18", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/8e03b1e796669f05c8debc07c256b7d99d94ce18", "committedDate": "2020-07-17T20:04:45Z", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "94deeb83f26761b935c7e98657f379f3a1e1fc7b", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/94deeb83f26761b935c7e98657f379f3a1e1fc7b", "committedDate": "2020-07-17T19:59:56Z", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}, "afterCommit": {"oid": "8e03b1e796669f05c8debc07c256b7d99d94ce18", "author": {"user": {"login": "DonalEvans", "name": "Donal Evans"}}, "url": "https://github.com/apache/geode/commit/8e03b1e796669f05c8debc07c256b7d99d94ce18", "committedDate": "2020-07-17T20:04:45Z", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNTY0ODQ5", "url": "https://github.com/apache/geode/pull/5095#pullrequestreview-453564849", "createdAt": "2020-07-22T18:10:18Z", "commit": {"oid": "8e03b1e796669f05c8debc07c256b7d99d94ce18"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4509, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}