{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzNzEwNjE1", "number": 4848, "title": "GEODE-7670: Add Tests for PR clear", "bodyText": "Added distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed).\nThank you for submitting a contribution to Apache Geode.\nIn order to streamline the review of the contribution we ask you\nto ensure the following steps have been taken:\nFor all changes:\n\n\n Is there a JIRA ticket associated with this PR? Is it referenced in the commit message?\n\n\n Has your PR been rebased against the latest commit within the target branch (typically develop)?\n\n\n Is your initial contribution a single, squashed commit?\n\n\n Does gradlew build run cleanly?\n\n\n Have you written or updated unit tests to verify your changes?\n\n\n If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under ASF 2.0?\n\n\nNote:\nPlease ensure that once the PR is submitted, check Concourse for build issues and\nsubmit an update to your PR as soon as possible. If you need help, please send an\nemail to dev@geode.apache.org.", "createdAt": "2020-03-25T17:01:42Z", "url": "https://github.com/apache/geode/pull/4848", "merged": true, "mergeCommit": {"oid": "1c7f15ff8c0465f402fb1ece530c2ed2f10826b5"}, "closed": true, "closedAt": "2020-07-22T08:36:00Z", "author": {"login": "jujoramos"}, "timelineItems": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcRbQitABqjMxNjgwMjU3NTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3IaXEgFqTQ1MjYwNTM2Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cc6a89b72a0877ab90f7d261e6768e20cd76d3ae", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/cc6a89b72a0877ab90f7d261e6768e20cd76d3ae", "committedDate": "2020-03-26T11:22:53Z", "message": "GEODE-7670: Fixed and added tests"}, "afterCommit": {"oid": "1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "committedDate": "2020-03-26T12:28:04Z", "message": "GEODE-7670: Fixed and added tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "committedDate": "2020-03-26T12:28:04Z", "message": "GEODE-7670: Fixed and added tests"}, "afterCommit": {"oid": "267897885f9ee57967de5266ce3f6cdd96c4a90e", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/267897885f9ee57967de5266ce3f6cdd96c4a90e", "committedDate": "2020-03-26T13:10:45Z", "message": "GEODE-7670: Fixed and added tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "267897885f9ee57967de5266ce3f6cdd96c4a90e", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/267897885f9ee57967de5266ce3f6cdd96c4a90e", "committedDate": "2020-03-26T13:10:45Z", "message": "GEODE-7670: Fixed and added tests"}, "afterCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "committedDate": "2020-03-26T13:22:48Z", "message": "GEODE-7670: Fixed and added tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMzA3NDMz", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382307433", "createdAt": "2020-03-26T18:43:15Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxODo0MzoxNVrOF8VVYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxODo0MzoxNVrOF8VVYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgwODQxOQ==", "bodyText": "can you add more shortcuts?", "url": "https://github.com/apache/geode/pull/4848#discussion_r398808419", "createdAt": "2020-03-26T18:43:15Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMzYzMjU3", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382363257", "createdAt": "2020-03-26T19:51:07Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxOTo1MTowN1rOF8X2bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxOTo1MTowN1rOF8X2bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg0OTY0NQ==", "bodyText": "after the first clear, all other gets() will not really do anything. You should re-populateRegion again before next clear.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398849645", "createdAt": "2020-03-26T19:51:07Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 297}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNDEyMTA0", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382412104", "createdAt": "2020-03-26T20:58:20Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMDo1ODoyMFrOF8aJZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMDo1ODoyMFrOF8aJZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4NzI3MQ==", "bodyText": "you need to measure how long a clear() took. If it's more than 5 seconds, something must be wrong.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398887271", "createdAt": "2020-03-26T20:58:20Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 263}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNDE0MDQ2", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382414046", "createdAt": "2020-03-26T21:00:14Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMTowMDoxNVrOF8aNCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMTowMDoxNVrOF8aNCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4ODIwMg==", "bodyText": "it's better to change the continuous put into continuous putAll.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398888202", "createdAt": "2020-03-26T21:00:15Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 249}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNDE0OTYw", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382414960", "createdAt": "2020-03-26T21:00:43Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMzY3MDAx", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-382367001", "createdAt": "2020-03-26T19:56:39Z", "commit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxOTo1NjozOVrOF8YCXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQyMzo1MToxNFrOF8egtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw==", "bodyText": "Shortening the test name :)\nWe have PRConcurrentMapOpsJUnitTest - similar to this?", "url": "https://github.com/apache/geode/pull/4848#discussion_r398852703", "createdAt": "2020-03-26T19:56:39Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTMwOA==", "bodyText": "2 secs may be long pauses...Since there is continuous cache operation, how about sleeping for few mili secs (say 50)", "url": "https://github.com/apache/geode/pull/4848#discussion_r398945308", "createdAt": "2020-03-26T23:10:05Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTM5Ng==", "bodyText": "3 secs long sleep.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398945396", "createdAt": "2020-03-26T23:10:21Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 334}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUyMg==", "bodyText": "This waits for message pertaining to region creation or status change. There is DistributionMessageObserver that can be used to see if any messages are still in progress.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398949522", "createdAt": "2020-03-26T23:22:39Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw==", "bodyText": "This is going over the PRs entry/key set getting all the values. This will be consistent where-ever this is called.\nAre we trying to see if the data in one vm is same as in another vm. Or are we trying to see data in primary buckets are same as in secondary buckets.\nFetching the local PR data-set and iterating over it will give the data stored in that vm.\nOr just to see an op could be executed successfully after clear?", "url": "https://github.com/apache/geode/pull/4848#discussion_r398952027", "createdAt": "2020-03-26T23:29:57Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1Mjg3NQ==", "bodyText": "No need to specify time; if someone changes the time and doesn't update it, this will become incorrect.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398952875", "createdAt": "2020-03-26T23:32:32Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches threads to continuously execute puts and gets for 60 seconds.\n+   * - Clears the Partition Region continuously (once every 10 seconds for 60 seconds).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 348}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1NzY4Mg==", "bodyText": "Instead of CacheWriter, you can use DistributionMessageObserver. And can use VM.bounce* to kill vms. No need to wait for CacheWriter messaging implementation.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398957682", "createdAt": "2020-03-26T23:47:45Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches threads to continuously execute puts and gets for 60 seconds.\n+   * - Clears the Partition Region continuously (once every 10 seconds for 60 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsAndGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut)\n+      throws InterruptedException {\n+    final int entries = 15000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts and gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        server2.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region every 10 seconds for 60 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(60, 10));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following:\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n+   * clear is in progress.\n+   * - Clears the Partition Region (at this point the coordinator is restarted).\n+   * - Asserts that, after the member joins again, entries have not been deleted.\n+   */\n+  @Test\n+  @TestCaseName(\"[{index}] {method}(Region:{0})\")\n+  @Parameters(method = \"regionTypes\")\n+  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n+    final int entries = 1000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n+\n+    // Clear the region.\n+    server1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      assertThatThrownBy(region::clear)\n+          .isInstanceOf(DistributedSystemDisconnectedException.class)\n+          .hasCauseInstanceOf(ForcedDisconnectException.class);\n+    });\n+\n+    // Wait for member to get back online.\n+    server1.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute gets for 60 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7500;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executeGets(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute puts for 30 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7000;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * Shutdowns a member while the clear operation is in progress.\n+   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n+   * it's the clear coordinator or another member holding primary buckets.\n+   *\n+   * TODO: Review once GEODE-7678 / GEODE-7912 are merged (CacheWriter lifecycle might change).\n+   */\n+  public static class MemberKiller extends CacheWriterAdapter<String, String> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 513}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1ODc3Mg==", "bodyText": "This is a good start; other cache ops that can be added in mix are Region ops (destroyRegion, invalidateRegion), querying; Region with index, rebalance, etc.", "url": "https://github.com/apache/geode/pull/4848#discussion_r398958772", "createdAt": "2020-03-26T23:51:14Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw=="}, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgzMDk3NDY4", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-383097468", "createdAt": "2020-03-27T18:16:42Z", "commit": {"oid": "5ff62b4e20689f8b0d76df4cd182a112f98feee1"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODoxNjo0MlrOF881ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODoxOToxMFrOF887Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1NTY1MQ==", "bodyText": "What I am trying to says is, since you are iterating over the PR region; it will get the data from all the nodes. Thats remains same across all the nodes.", "url": "https://github.com/apache/geode/pull/4848#discussion_r399455651", "createdAt": "2020-03-27T18:16:42Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw=="}, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1NzA3MQ==", "bodyText": "I don't think lifecycle of listeners changing. Its your choice.", "url": "https://github.com/apache/geode/pull/4848#discussion_r399457071", "createdAt": "2020-03-27T18:19:10Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches threads to continuously execute puts and gets for 60 seconds.\n+   * - Clears the Partition Region continuously (once every 10 seconds for 60 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsAndGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut)\n+      throws InterruptedException {\n+    final int entries = 15000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts and gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        server2.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region every 10 seconds for 60 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(60, 10));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following:\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n+   * clear is in progress.\n+   * - Clears the Partition Region (at this point the coordinator is restarted).\n+   * - Asserts that, after the member joins again, entries have not been deleted.\n+   */\n+  @Test\n+  @TestCaseName(\"[{index}] {method}(Region:{0})\")\n+  @Parameters(method = \"regionTypes\")\n+  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n+    final int entries = 1000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n+\n+    // Clear the region.\n+    server1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      assertThatThrownBy(region::clear)\n+          .isInstanceOf(DistributedSystemDisconnectedException.class)\n+          .hasCauseInstanceOf(ForcedDisconnectException.class);\n+    });\n+\n+    // Wait for member to get back online.\n+    server1.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute gets for 60 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7500;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executeGets(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute puts for 30 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7000;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * Shutdowns a member while the clear operation is in progress.\n+   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n+   * it's the clear coordinator or another member holding primary buckets.\n+   *\n+   * TODO: Review once GEODE-7678 / GEODE-7912 are merged (CacheWriter lifecycle might change).\n+   */\n+  public static class MemberKiller extends CacheWriterAdapter<String, String> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1NzY4Mg=="}, "originalCommit": {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6"}, "originalPosition": 513}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5ff62b4e20689f8b0d76df4cd182a112f98feee1", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/5ff62b4e20689f8b0d76df4cd182a112f98feee1", "committedDate": "2020-03-27T14:37:01Z", "message": "GEODE-7670: Changes requested by reviewers."}, "afterCommit": {"oid": "725e652cb1804300394de294ae5f61d61a9c3a22", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/725e652cb1804300394de294ae5f61d61a9c3a22", "committedDate": "2020-04-02T16:54:47Z", "message": "More tests for troubleshooting purposes."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "80832a084149957573b2894edef0a3abce0835b0", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/80832a084149957573b2894edef0a3abce0835b0", "committedDate": "2020-04-03T14:28:23Z", "message": "Minor changes, still troubleshooting."}, "afterCommit": {"oid": "80f14caedc1605c6e689af62aa3a3bded678d406", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/80f14caedc1605c6e689af62aa3a3bded678d406", "committedDate": "2020-04-15T10:35:18Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "80f14caedc1605c6e689af62aa3a3bded678d406", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/80f14caedc1605c6e689af62aa3a3bded678d406", "committedDate": "2020-04-15T10:35:18Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}, "afterCommit": {"oid": "9aea509566690a717892f352a65619a5dfdffff2", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/9aea509566690a717892f352a65619a5dfdffff2", "committedDate": "2020-05-13T10:04:10Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9aea509566690a717892f352a65619a5dfdffff2", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/9aea509566690a717892f352a65619a5dfdffff2", "committedDate": "2020-05-13T10:04:10Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}, "afterCommit": {"oid": "bc4956d19c87fff0300c7008ae8db1c1759d0825", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/bc4956d19c87fff0300c7008ae8db1c1759d0825", "committedDate": "2020-05-13T10:16:27Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bc4956d19c87fff0300c7008ae8db1c1759d0825", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/bc4956d19c87fff0300c7008ae8db1c1759d0825", "committedDate": "2020-05-13T10:16:27Z", "message": "- Rebase against latest changes from feature/GEODE-7665."}, "afterCommit": {"oid": "bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "committedDate": "2020-05-21T10:46:07Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "committedDate": "2020-05-21T10:46:07Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed)."}, "afterCommit": {"oid": "c5a4a76a471858274b345622a71004025bd1c14f", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/c5a4a76a471858274b345622a71004025bd1c14f", "committedDate": "2020-06-02T15:55:24Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c5a4a76a471858274b345622a71004025bd1c14f", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/c5a4a76a471858274b345622a71004025bd1c14f", "committedDate": "2020-06-02T15:55:24Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed)."}, "afterCommit": {"oid": "e03690916dd18a0a7c40962f120d1df6c716e864", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/e03690916dd18a0a7c40962f120d1df6c716e864", "committedDate": "2020-06-04T13:26:38Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f0b8391a6e81f94505364aadc5fbbd7f2a92f56", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/8f0b8391a6e81f94505364aadc5fbbd7f2a92f56", "committedDate": "2020-06-04T15:44:31Z", "message": "- Handle PartitionedRegionPartialClearException."}, "afterCommit": {"oid": "bfc40f4eff22ae338c429549040bde08f43dceba", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/bfc40f4eff22ae338c429549040bde08f43dceba", "committedDate": "2020-06-18T14:26:17Z", "message": "- Handle PartitionedRegionPartialClearException."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NTYwNDg4", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-439560488", "createdAt": "2020-06-29T23:05:16Z", "commit": {"oid": "bfc40f4eff22ae338c429549040bde08f43dceba"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzowNToxNlrOGqlihw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzowNToxNlrOGqlihw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwODQyMw==", "bodyText": "This validation needs to be changed....The RVV's are maintained as local-rvv (local to the node/member) and array of remote-rvvs (all other members). The RVVs has to be taken for corresponding member from both dumps and compared.", "url": "https://github.com/apache/geode/pull/4848#discussion_r447308423", "createdAt": "2020-06-29T23:05:16Z", "author": {"login": "agingade"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,680 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] vms() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bucketId = 0; bucketId < BUCKETS; bucketId++) {\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+\n+          assertThat(otherDump.getRvv())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfc40f4eff22ae338c429549040bde08f43dceba"}, "originalPosition": 226}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27b13e2967e627df529725b3ccd028b1a87a6e4c", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/27b13e2967e627df529725b3ccd028b1a87a6e4c", "committedDate": "2020-07-13T11:40:47Z", "message": "GEODE-7682: add PR.clear  API (#4755)\n\n* GEODE-7683: introduce BR.cmnClearRegion\n\nCo-authored-by: Xiaojian Zhou <gzhou@pivotal.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e863e842e5a57ac505cf5d4f9a957283c0fd124e", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/e863e842e5a57ac505cf5d4f9a957283c0fd124e", "committedDate": "2020-07-13T11:40:48Z", "message": "PR.clear's event id should be created and used in BR (#4805)\n\n* GEODE-7857: PR.clear's event id should be created and used in BR"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6e95e51262803ea0cecc2760671148e446f0ead5", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/6e95e51262803ea0cecc2760671148e446f0ead5", "committedDate": "2020-07-03T15:29:01Z", "message": "- Fix RVV comparisson."}, "afterCommit": {"oid": "a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440", "committedDate": "2020-07-13T15:02:20Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NjUxMDgx", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-447651081", "createdAt": "2020-07-13T22:22:09Z", "commit": {"oid": "a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyMjowOVrOGw8iwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyMjowOVrOGw8iwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ==", "bodyText": "The PartialClearException could happen here but not 100% will happen. Your assertion could fail here.", "url": "https://github.com/apache/geode/pull/4848#discussion_r453976769", "createdAt": "2020-07-13T22:22:09Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,715 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    List<String> keysToRemove = new ArrayList<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish).forEach(i -> keysToRemove.add(String.valueOf(i)));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.removeAll(keysToRemove);\n+    }\n+  }\n+\n+  /**\n+   * Execute the clear operation and retry until success.\n+   */\n+  private void executeClearWithRetry(VM coordinator) {\n+    coordinator.invoke(() -> {\n+      boolean retry;\n+\n+      do {\n+        retry = false;\n+\n+        try {\n+          cacheRule.getCache().getRegion(REGION_NAME).clear();\n+        } catch (PartitionedRegionPartialClearException pce) {\n+          retry = true;\n+        }\n+      } while (retry);\n+    });\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInMilliseconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInMilliseconds);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator and regionType are parametrized):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region continuously every X milliseconds for a given time.\n+   * - Asserts that, after the clears have finished, the Region Buckets are consistent across\n+   * members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"coordinatorsAndRegionTypes\")\n+  public void clearWithConcurrentPutGetRemoveShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 15000;\n+    final int workSeconds = 60;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts and gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        server2.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Clear the region every second for 60 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(workSeconds, 1000));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator and regionType are parametrized):\n+   * - Launches two threads per VM to continuously execute putAll and removeAll for a given time.\n+   * - Clears the Partition Region continuously every X milliseconds for a given time.\n+   * - Asserts that, after the clears have finished, the Region Buckets are consistent across\n+   * members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"coordinatorsAndRegionTypes\")\n+  public void clearWithConcurrentPutAllRemoveAllShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int workSeconds = 15;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute putAll for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePutAlls(0, 2000, workSeconds)),\n+        server1.invokeAsync(() -> executeRemoveAlls(0, 2000, workSeconds)),\n+        server2.invokeAsync(() -> executePutAlls(2000, 4000, workSeconds)),\n+        server2.invokeAsync(() -> executeRemoveAlls(2000, 4000, workSeconds)),\n+        accessor.invokeAsync(() -> executePutAlls(4000, 6000, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoveAlls(4000, 6000, workSeconds)));\n+\n+    // Clear the region every half second for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(workSeconds, 500));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (regionType is parametrized):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n+   * clear is in progress.\n+   * - Clears the Partition Region (at this point the coordinator is restarted).\n+   * - Asserts that, after the member joins again, the Region Buckets are consistent.\n+   */\n+  @Test\n+  @TestCaseName(\"[{index}] {method}(RegionType:{0})\")\n+  @Parameters(method = \"regionTypes\")\n+  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n+    final int entries = 1000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n+\n+    // Clear the region.\n+    server1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      assertThatThrownBy(region::clear)\n+          .isInstanceOf(DistributedSystemDisconnectedException.class)\n+          .hasCauseInstanceOf(ForcedDisconnectException.class);\n+    });\n+\n+    // Wait for member to get back online and assign all buckets.\n+    server1.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+      PartitionRegionHelper.assignBucketsToPartitions(cacheRule.getCache().getRegion(REGION_NAME));\n+    });\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches two threads per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clear has finished, the Region Buckets are consistent across members.\n+   */\n+  @Test\n+  @Parameters(method = \"coordinators\")\n+  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n+  public void clearOnRedundantPartitionRegionWithConcurrentPutGetRemoveShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM) throws InterruptedException {\n+    final int entries = 7500;\n+    final int workSeconds = 60;\n+    parametrizedSetup(RegionShortcut.PARTITION_REDUNDANT);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets, put and removes for 60\n+    // seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Retry the clear operation on the region until success (server2 will go down, but other\n+    // members will become primary for those buckets previously hosted by server2).\n+    executeClearWithRetry(getVM(coordinatorVM.vmNumber));\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(RegionShortcut.PARTITION_REDUNDANT);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches two threads per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that the clear operation failed with PartitionedRegionPartialClearException (primary\n+   * buckets on the the restarted members are not available).\n+   */\n+  @Test\n+  @Parameters(method = \"coordinators\")\n+  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n+  public void clearOnNonRedundantPartitionRegionWithConcurrentPutGetRemoveShouldFailWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM) throws InterruptedException {\n+    final int entries = 7500;\n+    final int workSeconds = 45;\n+    parametrizedSetup(RegionShortcut.PARTITION);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets, put and removes for 45\n+    // seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> {\n+      assertThatThrownBy(() -> cacheRule.getCache().getRegion(REGION_NAME).clear())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440"}, "originalPosition": 600}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce5d045b11ab57cabbdfbfd2b797219b0acb2ab9", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/ce5d045b11ab57cabbdfbfd2b797219b0acb2ab9", "committedDate": "2020-07-14T11:41:39Z", "message": "- Reduce threads per VM."}, "afterCommit": {"oid": "8d913c51b9f24933fc1efb1370ebb24cf66eeb94", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/8d913c51b9f24933fc1efb1370ebb24cf66eeb94", "committedDate": "2020-07-14T13:14:10Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "169f0db3f1f34e1c2a9d32adc8fd54bf9e613fe0", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/169f0db3f1f34e1c2a9d32adc8fd54bf9e613fe0", "committedDate": "2020-07-14T14:00:37Z", "message": "- Split workload."}, "afterCommit": {"oid": "57223db057da98ad76be13bb6d0933907b3e0f5c", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/57223db057da98ad76be13bb6d0933907b3e0f5c", "committedDate": "2020-07-14T14:47:32Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57223db057da98ad76be13bb6d0933907b3e0f5c", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/57223db057da98ad76be13bb6d0933907b3e0f5c", "committedDate": "2020-07-14T14:47:32Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}, "afterCommit": {"oid": "6ddee4249c54644c19b10d4ae307e4c3e78c912f", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/6ddee4249c54644c19b10d4ae307e4c3e78c912f", "committedDate": "2020-07-14T15:19:56Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "committedDate": "2020-07-16T13:03:05Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6602017c72336e21ad73ff8d547d7811d8f46046", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/6602017c72336e21ad73ff8d547d7811d8f46046", "committedDate": "2020-07-16T11:52:29Z", "message": "- Change member restart approach."}, "afterCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "committedDate": "2020-07-16T13:03:05Z", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed)."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxNjkyNDEy", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-451692412", "createdAt": "2020-07-20T15:02:08Z", "commit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxNTowMjowOVrOG0RvBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxNTozMzozMlrOG0TiVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ2OTcwMA==", "bodyText": "It's recommended not to declare multiple variables inline, so this should ideally be split into three separate lines.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457469700", "createdAt": "2020-07-20T15:02:09Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3MTg0Nw==", "bodyText": "This warning suppression is not necessary, as the method is used in coordinatorsAndRegionTypes() below.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457471847", "createdAt": "2020-07-20T15:04:28Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3NTEwMQ==", "bodyText": "This warning suppression can be removed if the below line is changed to PartitionAttributes<String, String> attributes = new PartitionAttributesFactory<String, String>()", "url": "https://github.com/apache/geode/pull/4848#discussion_r457475101", "createdAt": "2020-07-20T15:08:07Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3NTM0Nw==", "bodyText": "This warning suppression can be removed if the below line is changed to PartitionAttributes<String, String> attributes = new PartitionAttributesFactory<String, String>()", "url": "https://github.com/apache/geode/pull/4848#discussion_r457475347", "createdAt": "2020-07-20T15:08:26Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4MTY4MQ==", "bodyText": "These warning suppressions can be safely removed if some changes are made in this method, as described below.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457481681", "createdAt": "2020-07-20T15:14:53Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4MzA0MQ==", "bodyText": "These can be changed to RegionVersionVector<?> to prevent \"rawtypes\" warnings.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457483041", "createdAt": "2020-07-20T15:16:10Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4Njk0NA==", "bodyText": "The following change set will remove the need for suppressed \"unchecked\" and \"rawtypes\" warnings in this method:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Map<VersionSource, RegionVersionHolder> rvv2Members =\n          \n          \n            \n                    new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n          \n          \n            \n                Map<VersionSource, RegionVersionHolder> rvv1Members =\n          \n          \n            \n                    new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n          \n          \n            \n                for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n          \n          \n            \n                  VersionSource memberId = entry.getKey();\n          \n          \n            \n                  RegionVersionHolder versionHolder1 = entry.getValue();\n          \n          \n            \n                  RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n          \n          \n            \n                Map<VersionSource<?>, RegionVersionHolder<?>> rvv2Members =\n          \n          \n            \n                    new HashMap<>(rvv1.getMemberToVersion());\n          \n          \n            \n                Map<VersionSource<?>, RegionVersionHolder<?>> rvv1Members =\n          \n          \n            \n                    new HashMap<>(rvv1.getMemberToVersion());\n          \n          \n            \n                for (Map.Entry<VersionSource<?>, RegionVersionHolder<?>> entry : rvv1Members.entrySet()) {\n          \n          \n            \n                  VersionSource<?> memberId = entry.getKey();\n          \n          \n            \n                  RegionVersionHolder<?> versionHolder1 = entry.getValue();\n          \n          \n            \n                  RegionVersionHolder<?> versionHolder2 = rvv2Members.remove(memberId);", "url": "https://github.com/apache/geode/pull/4848#discussion_r457486944", "createdAt": "2020-07-20T15:20:12Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5MjYyMA==", "bodyText": "The arguments \"start\" and \"finish\" here might be better named as \"startKey\" and \"endKey\" or something similar, to make it clear that they are not related to time.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457492620", "createdAt": "2020-07-20T15:26:17Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5MzM0Mw==", "bodyText": "The arguments \"start\" and \"finish\" here might be better named as \"startKey\" and \"endKey\" or something similar, to make it clear that they are not related to time.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457493343", "createdAt": "2020-07-20T15:27:04Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 343}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5OTIyMg==", "bodyText": "Instead of a while loop with a Thread.sleep(), it might be better to use the Timer and TimerTask classes to execute clears (specifically the scheduleAtFixedRate() method.) Entirely personal preference, but I do know that in general we try not to use Thread.sleep() directly in tests.", "url": "https://github.com/apache/geode/pull/4848#discussion_r457499222", "createdAt": "2020-07-20T15:33:32Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    List<String> keysToRemove = new ArrayList<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish).forEach(i -> keysToRemove.add(String.valueOf(i)));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.removeAll(keysToRemove);\n+    }\n+  }\n+\n+  /**\n+   * Execute the clear operation and retry until success.\n+   */\n+  private void executeClearWithRetry(VM coordinator) {\n+    coordinator.invoke(() -> {\n+      boolean retry;\n+\n+      do {\n+        retry = false;\n+\n+        try {\n+          cacheRule.getCache().getRegion(REGION_NAME).clear();\n+        } catch (PartitionedRegionPartialClearException pce) {\n+          retry = true;\n+        }\n+\n+      } while (retry);\n+    });\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInMilliseconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInMilliseconds);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565"}, "originalPosition": 386}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2471e8ea2aff1f53781690bb5d107818f656c39", "author": {"user": {"login": "jujoramos", "name": "Juan Jos\u00e9 Ramos"}}, "url": "https://github.com/apache/geode/commit/e2471e8ea2aff1f53781690bb5d107818f656c39", "committedDate": "2020-07-21T08:53:09Z", "message": "- Changes requested by reviewers.\n- Standardized time unit used through the test."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNjA1MzY3", "url": "https://github.com/apache/geode/pull/4848#pullrequestreview-452605367", "createdAt": "2020-07-21T15:59:57Z", "commit": {"oid": "e2471e8ea2aff1f53781690bb5d107818f656c39"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4922, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}