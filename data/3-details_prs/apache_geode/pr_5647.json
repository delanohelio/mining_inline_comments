{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3NTk0Njc3", "number": 5647, "title": "GEODE-8633: Add concurrency tests for Redis HDEL", "bodyText": "Also add the ability for ConcurrentLoopingThreads to be run\nasynchronously.\n\nAuthored-by: Jens Deppe jdeppe@vmware.com\nThank you for submitting a contribution to Apache Geode.\nIn order to streamline the review of the contribution we ask you\nto ensure the following steps have been taken:\nFor all changes:\n\n\n Is there a JIRA ticket associated with this PR? Is it referenced in the commit message?\n\n\n Has your PR been rebased against the latest commit within the target branch (typically develop)?\n\n\n Is your initial contribution a single, squashed commit?\n\n\n Does gradlew build run cleanly?\n\n\n Have you written or updated unit tests to verify your changes?\n\n\n If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under ASF 2.0?\n\n\nNote:\nPlease ensure that once the PR is submitted, check Concourse for build issues and\nsubmit an update to your PR as soon as possible. If you need help, please send an\nemail to dev@geode.apache.org.", "createdAt": "2020-10-21T14:29:18Z", "url": "https://github.com/apache/geode/pull/5647", "merged": true, "mergeCommit": {"oid": "99f51c37211e657ee3bd17b4fec3eeadf2537974"}, "closed": true, "closedAt": "2020-10-22T02:33:25Z", "author": {"login": "jdeppe-pivotal"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUuO1_AH2gAyNTA3NTk0Njc3OjY0ZDA5MWI3MzU3Yzk1NTg5MDIwYjk2ZTllMmYzMGE5OTY3YzUzOGI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdU2ECKAH2gAyNTA3NTk0Njc3OjU3NmRmOTYwZDRhMWE4NWFhM2M1ZjU5YTY0YjJjMjFkODFiZmQ1ZDM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "64d091b7357c95589020b96e9e2f30a9967c538b", "author": {"user": {"login": "jdeppe-pivotal", "name": "Jens Deppe"}}, "url": "https://github.com/apache/geode/commit/64d091b7357c95589020b96e9e2f30a9967c538b", "committedDate": "2020-10-21T14:27:34Z", "message": "GEODE-8633: Add concurrency tests for Redis HDEL\n\n- Also add the ability for ConcurrentLoopingThreads to be run\n  asynchronously.\n\nAuthored-by: Jens Deppe <jdeppe@vmware.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzODMwMDcz", "url": "https://github.com/apache/geode/pull/5647#pullrequestreview-513830073", "createdAt": "2020-10-21T15:41:40Z", "commit": {"oid": "64d091b7357c95589020b96e9e2f30a9967c538b"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxNTo0MTo0MFrOHlzFIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxNTo0MzoxNVrOHlzKVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NjI1OA==", "bodyText": "Since you'll have to re-trigger anyway, the name could be changed to correct some grammatical errors/fit in with the test name below it: testConcurrentHDel_returnsExpectedNumberOfDeletions", "url": "https://github.com/apache/geode/pull/5647#discussion_r509396258", "createdAt": "2020-10-21T15:41:40Z", "author": {"login": "sabbey37"}, "path": "geode-redis/src/distributedTest/java/org/apache/geode/redis/internal/executor/hash/HdelDUnitTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.REDIS_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import io.lettuce.core.ClientOptions;\n+import io.lettuce.core.RedisClient;\n+import io.lettuce.core.api.StatefulRedisConnection;\n+import io.lettuce.core.api.sync.RedisCommands;\n+import io.lettuce.core.resource.ClientResources;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.redis.ConcurrentLoopingThreads;\n+import org.apache.geode.redis.session.springRedisTestApplication.config.DUnitSocketAddressResolver;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.dunit.rules.RedisClusterStartupRule;\n+import org.apache.geode.test.junit.rules.ExecutorServiceRule;\n+\n+public class HdelDUnitTest {\n+\n+  @ClassRule\n+  public static RedisClusterStartupRule cluster = new RedisClusterStartupRule();\n+\n+  @ClassRule\n+  public static ExecutorServiceRule executor = new ExecutorServiceRule();\n+\n+  private static final int HASH_SIZE = 50000;\n+  private static MemberVM locator;\n+  private static MemberVM server1;\n+  private static MemberVM server2;\n+  private static int[] redisPorts;\n+  private static RedisCommands<String, String> lettuce;\n+  private static StatefulRedisConnection<String, String> connection;\n+  private static ClientResources resources;\n+\n+  @BeforeClass\n+  public static void classSetup() {\n+    redisPorts = AvailablePortHelper.getRandomAvailableTCPPorts(3);\n+\n+    String redisPort1 = \"\" + redisPorts[0];\n+    String redisPort2 = \"\" + redisPorts[1];\n+\n+    locator = cluster.startLocatorVM(0);\n+\n+    server1 = startRedisVM(1, redisPorts[0]);\n+    server2 = startRedisVM(2, redisPorts[1]);\n+\n+    DUnitSocketAddressResolver dnsResolver =\n+        new DUnitSocketAddressResolver(new String[] {redisPort2, redisPort1});\n+\n+    resources = ClientResources.builder()\n+        .socketAddressResolver(dnsResolver)\n+        .build();\n+\n+    RedisClient redisClient = RedisClient.create(resources, \"redis://localhost\");\n+    redisClient.setOptions(ClientOptions.builder()\n+        .autoReconnect(true)\n+        .build());\n+    connection = redisClient.connect();\n+    lettuce = connection.sync();\n+  }\n+\n+  private static MemberVM startRedisVM(int vmID, int redisPort) {\n+    int locatorPort = locator.getPort();\n+\n+    return cluster.startRedisVM(vmID, x -> x\n+        .withConnectionToLocator(locatorPort)\n+        .withProperty(REDIS_PORT, \"\" + redisPort));\n+  }\n+\n+  @Before\n+  public void testSetup() {\n+    lettuce.flushall();\n+  }\n+\n+  @AfterClass\n+  public static void tearDown() throws Exception {\n+    resources.shutdown().get();\n+    connection.close();\n+    server1.stop();\n+    server2.stop();\n+  }\n+\n+  @Test\n+  public void testConcurrentHDelReturnExceptedNumberOfDeletions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d091b7357c95589020b96e9e2f30a9967c538b"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NzU4OQ==", "bodyText": "Since you have to re-trigger anyway, you could change the name to HDel instead of Del and better fit with the test name above: testConcurrentHDel_whenServerCrashesAndRestarts_deletesAllHashFieldsAndValues", "url": "https://github.com/apache/geode/pull/5647#discussion_r509397589", "createdAt": "2020-10-21T15:43:15Z", "author": {"login": "sabbey37"}, "path": "geode-redis/src/distributedTest/java/org/apache/geode/redis/internal/executor/hash/HdelDUnitTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.REDIS_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import io.lettuce.core.ClientOptions;\n+import io.lettuce.core.RedisClient;\n+import io.lettuce.core.api.StatefulRedisConnection;\n+import io.lettuce.core.api.sync.RedisCommands;\n+import io.lettuce.core.resource.ClientResources;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.redis.ConcurrentLoopingThreads;\n+import org.apache.geode.redis.session.springRedisTestApplication.config.DUnitSocketAddressResolver;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.dunit.rules.RedisClusterStartupRule;\n+import org.apache.geode.test.junit.rules.ExecutorServiceRule;\n+\n+public class HdelDUnitTest {\n+\n+  @ClassRule\n+  public static RedisClusterStartupRule cluster = new RedisClusterStartupRule();\n+\n+  @ClassRule\n+  public static ExecutorServiceRule executor = new ExecutorServiceRule();\n+\n+  private static final int HASH_SIZE = 50000;\n+  private static MemberVM locator;\n+  private static MemberVM server1;\n+  private static MemberVM server2;\n+  private static int[] redisPorts;\n+  private static RedisCommands<String, String> lettuce;\n+  private static StatefulRedisConnection<String, String> connection;\n+  private static ClientResources resources;\n+\n+  @BeforeClass\n+  public static void classSetup() {\n+    redisPorts = AvailablePortHelper.getRandomAvailableTCPPorts(3);\n+\n+    String redisPort1 = \"\" + redisPorts[0];\n+    String redisPort2 = \"\" + redisPorts[1];\n+\n+    locator = cluster.startLocatorVM(0);\n+\n+    server1 = startRedisVM(1, redisPorts[0]);\n+    server2 = startRedisVM(2, redisPorts[1]);\n+\n+    DUnitSocketAddressResolver dnsResolver =\n+        new DUnitSocketAddressResolver(new String[] {redisPort2, redisPort1});\n+\n+    resources = ClientResources.builder()\n+        .socketAddressResolver(dnsResolver)\n+        .build();\n+\n+    RedisClient redisClient = RedisClient.create(resources, \"redis://localhost\");\n+    redisClient.setOptions(ClientOptions.builder()\n+        .autoReconnect(true)\n+        .build());\n+    connection = redisClient.connect();\n+    lettuce = connection.sync();\n+  }\n+\n+  private static MemberVM startRedisVM(int vmID, int redisPort) {\n+    int locatorPort = locator.getPort();\n+\n+    return cluster.startRedisVM(vmID, x -> x\n+        .withConnectionToLocator(locatorPort)\n+        .withProperty(REDIS_PORT, \"\" + redisPort));\n+  }\n+\n+  @Before\n+  public void testSetup() {\n+    lettuce.flushall();\n+  }\n+\n+  @AfterClass\n+  public static void tearDown() throws Exception {\n+    resources.shutdown().get();\n+    connection.close();\n+    server1.stop();\n+    server2.stop();\n+  }\n+\n+  @Test\n+  public void testConcurrentHDelReturnExceptedNumberOfDeletions() {\n+    AtomicLong client1Deletes = new AtomicLong();\n+    AtomicLong client2Deletes = new AtomicLong();\n+\n+    String key = \"HSET\";\n+\n+    Map<String, String> setUpData =\n+        makeHashMap(HASH_SIZE, \"field\", \"value\");\n+\n+    lettuce.hset(key, setUpData);\n+\n+    new ConcurrentLoopingThreads(HASH_SIZE,\n+        i -> {\n+          long deleted = lettuce.hdel(key, \"field\" + i, \"value\" + i);\n+          client1Deletes.addAndGet(deleted);\n+        },\n+        i -> {\n+          long deleted = lettuce.hdel(key, \"field\" + i, \"value\" + i);\n+          client2Deletes.addAndGet(deleted);\n+        })\n+            .run();\n+\n+    assertThat(client1Deletes.get() + client2Deletes.get()).isEqualTo(HASH_SIZE);\n+  }\n+\n+  @Test\n+  public void testConcurrentDel_whenServerCrashesAndRestarts() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d091b7357c95589020b96e9e2f30a9967c538b"}, "originalPosition": 135}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71d590572157c2afee7dc299875eaac9f8b54654", "author": {"user": {"login": "jdeppe-pivotal", "name": "Jens Deppe"}}, "url": "https://github.com/apache/geode/commit/71d590572157c2afee7dc299875eaac9f8b54654", "committedDate": "2020-10-21T19:23:40Z", "message": "Review updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "576df960d4a1a85aa3c5f59a64b2c21d81bfd5d3", "author": {"user": {"login": "jdeppe-pivotal", "name": "Jens Deppe"}}, "url": "https://github.com/apache/geode/commit/576df960d4a1a85aa3c5f59a64b2c21d81bfd5d3", "committedDate": "2020-10-21T23:35:00Z", "message": "Retry command if it received a 'connection reset by peer' error"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3951, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}