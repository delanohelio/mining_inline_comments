{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgyNjIxODUy", "number": 4755, "title": "GEODE-7682: add PR.clear  API", "bodyText": "Thank you for submitting a contribution to Apache Geode.\nIn order to streamline the review of the contribution we ask you\nto ensure the following steps have been taken:\nFor all changes:\n\n\n Is there a JIRA ticket associated with this PR? Is it referenced in the commit message?\n\n\n Has your PR been rebased against the latest commit within the target branch (typically develop)?\n\n\n Is your initial contribution a single, squashed commit?\n\n\n Does gradlew build run cleanly?\n\n\n Have you written or updated unit tests to verify your changes?\n\n\n If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under ASF 2.0?\n\n\nNote:\nPlease ensure that once the PR is submitted, check Concourse for build issues and\nsubmit an update to your PR as soon as possible. If you need help, please send an\nemail to dev@geode.apache.org.", "createdAt": "2020-03-02T21:39:00Z", "url": "https://github.com/apache/geode/pull/4755", "merged": true, "mergeCommit": {"oid": "43bd36442c0472eb5c139e7aa7dff61fe6425879"}, "closed": true, "closedAt": "2020-03-06T07:46:36Z", "author": {"login": "gesterzhou"}, "timelineItems": {"totalCount": 34, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcI4aIRAH2gAyMzgyNjIxODUyOjE1YzgwMDMwNGE1MDc4NTVjZDA0YTk5NDhkMjRkNjFiNWRhNTQyMTE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcK4TIHAH2gAyMzgyNjIxODUyOjRjOTlhYTEwNWExZTRhNzkxY2FlZDg2OWRhYWE0MGZmN2QxNzllMWM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "15c800304a507855cd04a9948d24d61b5da54211", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/15c800304a507855cd04a9948d24d61b5da54211", "committedDate": "2020-02-28T23:20:42Z", "message": "GEODE-7683: introduce BR.cmnClearRegion\n\nCo-authored-by: Xiaojian Zhou <gzhou@pivotal.io>\n\nGEODE-7684: Create messaging class for PR Clear (#4689)\n\n* Added new message class and test\n\nCo-authored-by: Benjamin Ross <bross@pivotal.io>\nCo-authored-by: Donal Evans <doevans@pivotal.io>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25177d3968f6140df3521d844769006da6fb795e", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/25177d3968f6140df3521d844769006da6fb795e", "committedDate": "2020-03-02T07:45:31Z", "message": "GEODE-7682: add PR.clear API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38c4c45a243aeaae074e2b531bac4dc4bb924f00", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/38c4c45a243aeaae074e2b531bac4dc4bb924f00", "committedDate": "2020-03-02T17:27:30Z", "message": "fix warnings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2912becea43acc49971338cb8ef7ec4053203f2f", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/2912becea43acc49971338cb8ef7ec4053203f2f", "committedDate": "2020-03-02T23:30:23Z", "message": "add dunit test case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4465d95e6b07c3e0328c8d6932615393d53782e8", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/4465d95e6b07c3e0328c8d6932615393d53782e8", "committedDate": "2020-03-03T02:16:02Z", "message": "add dunit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "committedDate": "2020-03-03T22:37:48Z", "message": "add test case for client/server"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY4Mzg4MTE0", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-368388114", "createdAt": "2020-03-03T22:57:34Z", "commit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QyMjo1NzozNVrOFxZs8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wM1QyMzoxMDozN1rOFxZ__Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NTY1MQ==", "bodyText": "Would it make sense to just remove this as part of unsupported?\nIt looks like putAll was once unsupported and now it just falls through, but we don't verify anything... we can probably just remove clear from this unsupported test", "url": "https://github.com/apache/geode/pull/4755#discussion_r387345651", "createdAt": "2020-03-03T22:57:35Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java", "diffHunk": "@@ -1309,12 +1309,7 @@ public void test023UnsupportedOps() throws Exception {\n       pr.put(new Integer(3), \"three\");\n       pr.getEntry(\"key\");\n \n-      try {\n-        pr.clear();\n-        fail(\n-            \"PartitionedRegionSingleNodeOperationTest:testUnSupportedOps() operation failed on a blank PartitionedRegion\");\n-      } catch (UnsupportedOperationException expected) {\n-      }\n+      pr.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NjQ4NA==", "bodyText": "we can possibly not get the lock, throw an illegal state exception and then just continue as if we have the lock?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387346484", "createdAt": "2020-03-03T22:59:45Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NzQ1Ng==", "bodyText": "with comment from before, there is a chance we didn't acquire the lock (due to illegal state exception.. this might see a problem in that case.", "url": "https://github.com/apache/geode/pull/4755#discussion_r387347456", "createdAt": "2020-03-03T23:02:07Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (logger.isDebugEnabled()) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODI5MQ==", "bodyText": "Is this new code?  If so, this is a fairly long method, any chance we can break it into smaller helper methods?  I would assume unit testing this method would be a lot easier at that point as we could unit test the individual smaller methods instead", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348291", "createdAt": "2020-03-03T23:04:23Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (logger.isDebugEnabled()) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODg1OA==", "bodyText": "Any reason why we removed the type?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348858", "createdAt": "2020-03-03T23:06:01Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -109,14 +106,9 @@ public boolean isSevereAlertCompatible() {\n     return true;\n   }\n \n-  public RegionEventImpl getRegionEvent() {\n-    return regionEvent;\n-  }\n-\n   public ClearResponse send(DistributedMember recipient, PartitionedRegion region)\n       throws ForceReattemptException {\n-    Set<InternalDistributedMember> recipients =\n-        Collections.singleton((InternalDistributedMember) recipient);\n+    Set recipients = Collections.singleton(recipient);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODkzNA==", "bodyText": "why is this null now?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348934", "createdAt": "2020-03-03T23:06:16Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -143,20 +135,18 @@ public void toData(DataOutput out, SerializationContext context) throws IOExcept\n     } else {\n       InternalDataSerializer.writeSignedVL(bucketId, out);\n     }\n-    DataSerializer.writeObject(regionEvent, out);\n   }\n \n   @Override\n   public void fromData(DataInput in, DeserializationContext context)\n       throws IOException, ClassNotFoundException {\n     super.fromData(in, context);\n     this.bucketId = (int) InternalDataSerializer.readSignedVL(in);\n-    this.regionEvent = DataSerializer.readObject(in);\n   }\n \n   @Override\n   public EventID getEventID() {\n-    return regionEvent.getEventId();\n+    return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDA0Mw==", "bodyText": "Should this now be changed to say //Check if we obtained primary lock...", "url": "https://github.com/apache/geode/pull/4755#discussion_r387350043", "createdAt": "2020-03-03T23:09:10Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +169,31 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region, int bucketId)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n     // Check if we are primary, throw exception if not", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDUyNQ==", "bodyText": "remove?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387350525", "createdAt": "2020-03-03T23:10:37Z", "author": {"login": "jhuynh1"}, "path": "geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java", "diffHunk": "@@ -61,64 +60,43 @@\n   @Before\n   public void setup() throws ForceReattemptException {\n     message = spy(new ClearPRMessage());\n+    InternalDistributedMember member = mock(InternalDistributedMember.class);\n     region = mock(PartitionedRegion.class, RETURNS_DEEP_STUBS);\n     dataStore = mock(PartitionedRegionDataStore.class);\n     when(region.getDataStore()).thenReturn(dataStore);\n+    when(region.getFullPath()).thenReturn(\"/test\");\n     bucketRegion = mock(BucketRegion.class);\n     when(dataStore.getInitializedBucketForId(any(), any())).thenReturn(bucketRegion);\n+    RegionEventImpl bucketRegionEventImpl = mock(RegionEventImpl.class);\n+    // RegionEventImpl(bucketRegion, Operation.REGION_CLEAR, null, false, member, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY4NDEzMjY4", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-368413268", "createdAt": "2020-03-04T00:00:29Z", "commit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMDowMDoyOVrOFxbAYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMDowMDoyOVrOFxbAYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NzAwOA==", "bodyText": "The int bucketId in the parameter list is never used.", "url": "https://github.com/apache/geode/pull/4755#discussion_r387367008", "createdAt": "2020-03-04T00:00:29Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +169,31 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region, int bucketId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "originalPosition": 90}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY4NDczMTU5", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-368473159", "createdAt": "2020-03-04T02:49:12Z", "commit": {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/605f37ae56a6b01489595afa30cbfcf9ab81f704", "committedDate": "2020-03-04T07:43:01Z", "message": "fix based on jason's comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e1847b1e8b306038eb1d87080fba8983af9c868", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/5e1847b1e8b306038eb1d87080fba8983af9c868", "committedDate": "2020-03-04T17:05:10Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7e11f681cd658d5cf3253369be93dd165f6661c", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/b7e11f681cd658d5cf3253369be93dd165f6661c", "committedDate": "2020-03-04T17:18:29Z", "message": "fix based on comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "committedDate": "2020-03-04T17:25:52Z", "message": "fix based on review comments, and POE handling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDAzMDMy", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369003032", "createdAt": "2020-03-04T18:06:32Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODowNjozMlrOFx36Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODowNjozMlrOFx36Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg0MDUyNw==", "bodyText": "typo", "url": "https://github.com/apache/geode/pull/4755#discussion_r387840527", "createdAt": "2020-03-04T18:06:32Z", "author": {"login": "gesterzhou"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +171,35 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();\n+      regionEvent.setOperation(Operation.REGION_CLEAR);\n+      regionEvent.setRegion(bucketRegion);\n+      bucketRegion.cmnClearRegion(regionEvent, true, true);\n+    } catch (PartitionOfflineException poe) {\n+      logger.info(\"There is no member to hold bukcet {}, not to retry any more\", this.bucketId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDUzNTIx", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369053521", "createdAt": "2020-03-04T19:20:04Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxOToyMDowNFrOFx6Uzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxOToyMDowNFrOFx6Uzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4MDE0Mg==", "bodyText": "Based on the API doc, ALL_KEYS behavior is now deprecated, please use an alternative.", "url": "https://github.com/apache/geode/pull/4755#discussion_r387880142", "createdAt": "2020-03-04T19:20:04Z", "author": {"login": "jchen21"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.stream.IntStream;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, accessor;\n+  protected ClientVM client1, client2;\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    locator = cluster.startLocatorVM(0);\n+    locatorPort = locator.getPort();\n+    dataStore1 = cluster.startServerVM(1, locatorPort);\n+    dataStore2 = cluster.startServerVM(2, locatorPort);\n+    accessor = cluster.startServerVM(3, locatorPort);\n+    client1 = cluster.startClientVM(4,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    client2 = cluster.startClientVM(5,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    dataStore1.invoke(this::initDataStore);\n+    dataStore2.invoke(this::initDataStore);\n+    accessor.invoke(this::initAccessor);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+  }\n+\n+  protected RegionShortcut getRegionShortCut() {\n+    return RegionShortcut.PARTITION_REDUNDANT;\n+  }\n+\n+  private Region getRegion(boolean isClient) {\n+    if (isClient) {\n+      return getClientCache().getRegion(REGION_NAME);\n+    } else {\n+      return getCache().getRegion(REGION_NAME);\n+    }\n+  }\n+\n+  private void verifyRegionSize(boolean isClient, int expectedNum) {\n+    assertThat(getRegion(isClient).size()).isEqualTo(expectedNum);\n+  }\n+\n+  private void initClientCache() {\n+    Region region = getClientCache().createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)\n+        .create(REGION_NAME);\n+    region.registerInterest(\"ALL_KEYS\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDc1NzIx", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369075721", "createdAt": "2020-03-04T19:52:28Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxOTo1MjoyOVrOFx7bYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxOTo1MjoyOVrOFx7bYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5ODIwOQ==", "bodyText": "clearPRMessage.doLocalClear never returns false. It either returns true or throws exception. Is it expected?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387898209", "createdAt": "2020-03-04T19:52:29Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 154}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDgxNjI4", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369081628", "createdAt": "2020-03-04T20:01:01Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowMTowMVrOFx7tkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowMTowMVrOFx7tkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMjg2Ng==", "bodyText": "Why this variable is called prce?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387902866", "createdAt": "2020-03-04T20:01:01Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 165}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDgyNjEz", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369082613", "createdAt": "2020-03-04T20:02:32Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowMjozMlrOFx7wjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowMjozMlrOFx7wjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMzYzMQ==", "bodyText": "If  lastTarget is the same as currentTarget, we have two debug messages: line 2305 and line 2300. This is a little bit duplicate.", "url": "https://github.com/apache/geode/pull/4755#discussion_r387903631", "createdAt": "2020-03-04T20:02:32Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 178}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MDg0MTEx", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369084111", "createdAt": "2020-03-04T20:04:48Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowNDo0OFrOFx70zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDowNDo0OFrOFx70zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwNDcxOQ==", "bodyText": "Should this code block be executed even when lastTarget is not equal to currentTarget?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387904719", "createdAt": "2020-03-04T20:04:48Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, prce.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 186}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTA2NTMw", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369106530", "createdAt": "2020-03-04T20:41:37Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo0MTozN1rOFx84Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo0MTozN1rOFx84Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyMTk5NQ==", "bodyText": "Do we need to make any change for this function?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387921995", "createdAt": "2020-03-04T20:41:37Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, prce.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();\n+        }\n+      }\n+\n+      // It's possible this is a GemFire thread e.g. ServerConnection\n+      // which got to this point because of a distributed system shutdown or\n+      // region closure which uses interrupt to break any sleep() or wait()\n+      // calls\n+      // e.g. waitForPrimary or waitForBucketRecovery in which case throw\n+      // exception\n+      checkShutdown();\n+\n+      // If we get here, the attempt failed...\n+      if (count == 1) {\n+        // TODO prStats add ClearPRMsg retried\n+        this.prStats.incPutAllMsgsRetried();\n+      }\n+    }\n+  }\n+\n+  List<ClearPRMessage> createClearPRMessages() {\n+    if (cache.isCacheAtShutdownAll()) {\n+      throw cache.getCacheClosedException(\"Cache is shutting down\");\n+    }\n+\n+    ArrayList<ClearPRMessage> clearMsgList = new ArrayList<>();\n+    for (int bucketId = 0; bucketId < this.totalNumberOfBuckets; bucketId++) {\n+      ClearPRMessage clearPRMessage = new ClearPRMessage(bucketId);\n+      clearMsgList.add(clearPRMessage);\n+    }\n+    return clearMsgList;\n   }\n \n   @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 219}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTExNjQz", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369111643", "createdAt": "2020-03-04T20:49:38Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo0OTozOVrOFx9HqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMDo0OTozOVrOFx9HqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyNTkyOA==", "bodyText": "Better update the Javadoc, a new parameter is introduced.", "url": "https://github.com/apache/geode/pull/4755#discussion_r387925928", "createdAt": "2020-03-04T20:49:39Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -3122,7 +3307,7 @@ private boolean putInBucket(final InternalDistributedMember targetNode, final In\n    * @return a Node which contains the bucket, potentially null\n    */\n   private InternalDistributedMember waitForNodeOrCreateBucket(RetryTimeKeeper retryTime,\n-      EntryEventImpl event, Integer bucketId) {\n+      EntryEventImpl event, Integer bucketId, boolean createIfNotExist) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 252}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5MTIwNTQx", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369120541", "createdAt": "2020-03-04T21:03:32Z", "commit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTowMzozMlrOFx9igQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQyMTowMzozMlrOFx9igQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkzMjgwMQ==", "bodyText": "Why not use the other non-zero-argument constructor of RegionEventImpl? Then we don't have to the setters in the next two lines. Is there any concern of side effect?", "url": "https://github.com/apache/geode/pull/4755#discussion_r387932801", "createdAt": "2020-03-04T21:03:32Z", "author": {"login": "jchen21"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +171,35 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf"}, "originalPosition": 114}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47c0f5c690a36878507008aa366ecc0d82580789", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/47c0f5c690a36878507008aa366ecc0d82580789", "committedDate": "2020-03-04T22:27:13Z", "message": "add more datastore members and listener in test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "committedDate": "2020-03-04T22:52:42Z", "message": "fix based on jianxia's comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/08550c037c9c36ec9d677d70be67a0c7eaf282a0", "committedDate": "2020-03-05T07:56:32Z", "message": "fix based on jianxia's comments on mesg"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5ODMyMDgw", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369832080", "createdAt": "2020-03-05T19:00:24Z", "commit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "state": "DISMISSED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQxOTowMDoyNFrOFyf_SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMDowNTo1MFrOFyiNDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5NzIyNA==", "bodyText": "Could this lock name be extracted to a constant, since it's used multiple times in a couple of different classes.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388497224", "createdAt": "2020-03-05T19:00:24Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5OTY5OA==", "bodyText": "We make this same check as soon as we get inside the createClearPRMessages() method. Is it needed in both places?", "url": "https://github.com/apache/geode/pull/4755#discussion_r388499698", "createdAt": "2020-03-05T19:04:57Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMDk3Nw==", "bodyText": "A more descriptive name for this might be \"sendMessagesStartTime\" or something along those lines.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388500977", "createdAt": "2020-03-05T19:07:09Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMjI4OA==", "bodyText": "Why do we only log this message if the time taken was more than 10 seconds? Would it be acceptable to just always log it if debug is enabled?", "url": "https://github.com/apache/geode/pull/4755#discussion_r388502288", "createdAt": "2020-03-05T19:09:27Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwNDQ4Mw==", "bodyText": "while(true) might be better here, just personal preference.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388504483", "createdAt": "2020-03-05T19:13:04Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxNjgyMA==", "bodyText": "Looking at this code, it seems possible that we can enter the loop with currentTarget == null, then attempt to find a target using waitForNodeOrCreateBucket() and get a non-null target. However, we don't try to use that target immediately, but rather return to the start of the loop with count now equal to 1, even though we haven't actually failed, and there is no true retry happening. This means that when we get to the if (count == 1) check at the bottom of the loop on the next iteration, count will have been incremented to 2, and we never increment the stats. Should the continue here be removed, to allow us to attempt to send the message to the target we just got?", "url": "https://github.com/apache/geode/pull/4755#discussion_r388516820", "createdAt": "2020-03-05T19:34:58Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxODkwOQ==", "bodyText": "The op string should be \"clear a bucket\"", "url": "https://github.com/apache/geode/pull/4755#discussion_r388518909", "createdAt": "2020-03-05T19:38:48Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException fre) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, fre.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxOTMzOA==", "bodyText": "This should be \"PR.sendClearMsgByBucket\"", "url": "https://github.com/apache/geode/pull/4755#discussion_r388519338", "createdAt": "2020-03-05T19:39:32Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException fre) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, fre.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyMzk0MA==", "bodyText": "This might be better as \"All members holding data for bucket {} are offline, no more retries will be attempted\"", "url": "https://github.com/apache/geode/pull/4755#discussion_r388523940", "createdAt": "2020-03-05T19:47:39Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,50 +153,40 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public Integer getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();\n+      regionEvent.setOperation(Operation.REGION_CLEAR);\n+      regionEvent.setRegion(bucketRegion);\n+      bucketRegion.cmnClearRegion(regionEvent, true, true);\n+    } catch (PartitionOfflineException poe) {\n+      logger.info(\"There is no member to hold bucket {}, not to retry any more\", this.bucketId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMTA2OA==", "bodyText": "There is an Assert.assertNotNull() that would be better here than assertTrue().\nAlso, it might be clearer with a message of \"ClearReplyMessage recipient was NULL.\"", "url": "https://github.com/apache/geode/pull/4755#discussion_r388531068", "createdAt": "2020-03-05T20:00:43Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -293,16 +225,21 @@ public ClearReplyMessage() {}\n \n     private ClearReplyMessage(int processorId, boolean result, ReplyException ex) {\n       super();\n-      this.result = result;\n       setProcessorId(processorId);\n-      setException(ex);\n+      if (ex != null) {\n+        setException(ex);\n+      } else {\n+        setReturnValue(result);\n+      }\n     }\n \n-    /** Send an ack */\n+    /**\n+     * Send an ack\n+     */\n     public static void send(InternalDistributedMember recipient, int processorId,\n         ReplySender replySender,\n         boolean result, ReplyException ex) {\n-      Assert.assertTrue(recipient != null, \"ClearReplyMessage NULL reply message\");\n+      Assert.assertTrue(recipient != null, \"ClearReplyMessage NULL recipient.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMzUxOA==", "bodyText": "These verifications of region size on the data stores are called multiple times in multiple tests. Could they be extracted to helper methods to reduce code duplication?", "url": "https://github.com/apache/geode/pull/4755#discussion_r388533518", "createdAt": "2020-03-05T20:05:50Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.stream.IntStream;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.InterestResultPolicy;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.util.CacheListenerAdapter;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, dataStore3, accessor;\n+  protected ClientVM client1, client2;\n+\n+  private static final Logger logger = LogManager.getLogger();\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    locator = cluster.startLocatorVM(0);\n+    locatorPort = locator.getPort();\n+    dataStore1 = cluster.startServerVM(1, locatorPort);\n+    dataStore2 = cluster.startServerVM(2, locatorPort);\n+    dataStore3 = cluster.startServerVM(3, locatorPort);\n+    accessor = cluster.startServerVM(4, locatorPort);\n+    client1 = cluster.startClientVM(5,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    client2 = cluster.startClientVM(6,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    dataStore1.invoke(this::initDataStore);\n+    dataStore2.invoke(this::initDataStore);\n+    dataStore3.invoke(this::initDataStore);\n+    accessor.invoke(this::initAccessor);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+  }\n+\n+  protected RegionShortcut getRegionShortCut() {\n+    return RegionShortcut.PARTITION_REDUNDANT;\n+  }\n+\n+  private Region getRegion(boolean isClient) {\n+    if (isClient) {\n+      return getClientCache().getRegion(REGION_NAME);\n+    } else {\n+      return getCache().getRegion(REGION_NAME);\n+    }\n+  }\n+\n+  private void verifyRegionSize(boolean isClient, int expectedNum) {\n+    assertThat(getRegion(isClient).size()).isEqualTo(expectedNum);\n+  }\n+\n+  private void initClientCache() {\n+    Region region = getClientCache().createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)\n+        .create(REGION_NAME);\n+    region.registerInterestForAllKeys(InterestResultPolicy.KEYS);\n+  }\n+\n+  private void initDataStore() {\n+    getCache().createRegionFactory(getRegionShortCut())\n+        .setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(10).create())\n+        .addCacheListener(new CacheListenerAdapter() {\n+          @Override\n+          public void afterRegionDestroy(RegionEvent event) {\n+            Region region = event.getRegion();\n+            logger.info(\"Region \" + region.getFullPath() + \" is destroyed.\");\n+          }\n+\n+          @Override\n+          public void afterRegionClear(RegionEvent event) {\n+            Region region = event.getRegion();\n+            logger.info(\"Region \" + region.getFullPath() + \" is cleared.\");\n+          }\n+        })\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initAccessor() {\n+    getCache().createRegionFactory(getRegionShortCut())\n+        .setPartitionAttributes(\n+            new PartitionAttributesFactory().setTotalNumBuckets(10).setLocalMaxMemory(0).create())\n+        .create(REGION_NAME);\n+  }\n+\n+  private void feed(boolean isClient) {\n+    Region region = getRegion(isClient);\n+    IntStream.range(0, NUM_ENTRIES).forEach(i -> region.put(i, \"value\" + i));\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStore() {\n+    accessor.invoke(() -> feed(false));\n+    dataStore1.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+    dataStore2.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+    dataStore3.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+\n+    dataStore1.invoke(() -> getRegion(false).clear());\n+    dataStore1.invoke(() -> verifyRegionSize(false, 0));\n+    dataStore2.invoke(() -> verifyRegionSize(false, 0));\n+    dataStore3.invoke(() -> verifyRegionSize(false, 0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "originalPosition": 139}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/1dfc0a0e82930d442ce3d5db93c624d228a97856", "committedDate": "2020-03-05T23:18:33Z", "message": "fix based on donal's comments and add listener check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5OTg4NzY5", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369988769", "createdAt": "2020-03-05T23:38:46Z", "commit": {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY5OTg4ODc3", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-369988877", "createdAt": "2020-03-05T23:39:04Z", "commit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMzozOTowNFrOFyn_Tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMzo0NzoyNFrOFyoIWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyODMwMg==", "bodyText": "You need to also update the lock name in lockService.unlock() on line 2192.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388628302", "createdAt": "2020-03-05T23:39:04Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2151,7 +2151,7 @@ void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMDYxOQ==", "bodyText": "Why is this being cast to Boolean? The returnValue field is primitive and the waitForResult() method returns a primitive as well. It feels like they should all agree on what the type is.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388630619", "createdAt": "2020-03-05T23:47:24Z", "author": {"login": "DonalEvans"}, "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -298,7 +299,7 @@ public ClearResponse(InternalDistributedSystem distributedSystem,\n \n     public void setResponse(ClearReplyMessage response) {\n       if (response.getException() == null) {\n-        this.returnValue = (boolean) response.getReturnValue();\n+        this.returnValue = (Boolean) response.getReturnValue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "803e8b112a59faca3f562c6a9e176eebaabb0ddb", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/803e8b112a59faca3f562c6a9e176eebaabb0ddb", "committedDate": "2020-03-05T23:48:22Z", "message": "add a new dunit test to try"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fd4819c1fbd62ee1bd5ffcff530de33518cf85a", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/6fd4819c1fbd62ee1bd5ffcff530de33518cf85a", "committedDate": "2020-03-05T23:51:10Z", "message": "fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwMDA4NTQ4", "url": "https://github.com/apache/geode/pull/4755#pullrequestreview-370008548", "createdAt": "2020-03-06T00:33:26Z", "commit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQwMDozMzoyN1rOFypBAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQwMDozMzoyN1rOFypBAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0NTEyMg==", "bodyText": "The number of VMs should be 7.", "url": "https://github.com/apache/geode/pull/4755#discussion_r388645122", "createdAt": "2020-03-06T00:33:27Z", "author": {"login": "jchen21"}, "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.IntStream;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.InterestResultPolicy;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.util.CacheListenerAdapter;\n+import org.apache.geode.test.dunit.SerializableCallableIF;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, dataStore3, accessor;\n+  protected ClientVM client1, client2;\n+\n+  private static final Logger logger = LogManager.getLogger();\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856"}, "originalPosition": 56}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "945a898d3115d5d86fa6aa1387ce1ba85b874802", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/945a898d3115d5d86fa6aa1387ce1ba85b874802", "committedDate": "2020-03-06T00:45:03Z", "message": "fix junit test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c99aa105a1e4a791caed869daaa40ff7d179e1c", "author": {"user": {"login": "gesterzhou", "name": "Xiaojian Zhou"}}, "url": "https://github.com/apache/geode/commit/4c99aa105a1e4a791caed869daaa40ff7d179e1c", "committedDate": "2020-03-06T04:20:54Z", "message": "Merge branch 'feature/GEODE-7665' into feature/GEODE-7682-2"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4979, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}