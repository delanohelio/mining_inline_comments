{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIwMDAzNTg4", "number": 867, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxNjoxMTo0OVrOE4uiag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxODo1NDowMlrOE4ysKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3OTE4MTg2OnYy", "diffSide": "RIGHT", "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/i18n/KafkaLogging.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxNjoxMTo0OVrOHy0gWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNVQxOTo1MDoyM1rOHzif1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA1MTA5Nw==", "bodyText": "I'm not sure if the remark about the maximum capacity is always true. In my case, only the timeout hit (I have 89 messages waiting in batching). Not sure if you should change the wording.", "url": "https://github.com/smallrye/smallrye-reactive-messaging/pull/867#discussion_r523051097", "createdAt": "2020-11-13T16:11:49Z", "author": {"login": "andreas-eberle"}, "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/i18n/KafkaLogging.java", "diffHunk": "@@ -139,8 +139,11 @@\n     void configuredPattern(String channel, String pattern);\n \n     @LogMessage(level = Logger.Level.WARN)\n-    @Message(id = 18231, value = \"The amount of received messages without acking is too high for topic partition '%s', amount %d.\")\n-    void receivedTooManyMessagesWithoutAcking(String topicPartition, long amount);\n+    @Message(id = 18231, value = \"The amount of received messages without acking is too high for topic partition '%s', \"\n+            + \"amount %d. The last committed offset was %d. It means that the Kafka connector received Kafka Records that \"\n+            + \"have neither be acked nor nacked in a timely fashion. The connector accumulates records in memory, but that \"\n+            + \"buffer reached its maximum capacity. The connector cannot commit as a record processing has not completed.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e0f888978cfa2cd91f30bc16ee6b40c0b6a6288"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzgwNDYyOA==", "bodyText": "You are right, there is also a deadline.\nI fixed it.", "url": "https://github.com/smallrye/smallrye-reactive-messaging/pull/867#discussion_r523804628", "createdAt": "2020-11-15T19:50:23Z", "author": {"login": "cescoffier"}, "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/i18n/KafkaLogging.java", "diffHunk": "@@ -139,8 +139,11 @@\n     void configuredPattern(String channel, String pattern);\n \n     @LogMessage(level = Logger.Level.WARN)\n-    @Message(id = 18231, value = \"The amount of received messages without acking is too high for topic partition '%s', amount %d.\")\n-    void receivedTooManyMessagesWithoutAcking(String topicPartition, long amount);\n+    @Message(id = 18231, value = \"The amount of received messages without acking is too high for topic partition '%s', \"\n+            + \"amount %d. The last committed offset was %d. It means that the Kafka connector received Kafka Records that \"\n+            + \"have neither be acked nor nacked in a timely fashion. The connector accumulates records in memory, but that \"\n+            + \"buffer reached its maximum capacity. The connector cannot commit as a record processing has not completed.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA1MTA5Nw=="}, "originalCommit": {"oid": "9e0f888978cfa2cd91f30bc16ee6b40c0b6a6288"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3OTg2MjE2OnYy", "diffSide": "RIGHT", "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/commit/KafkaThrottledLatestProcessedCommit.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxODo1NDowMlrOHy7KAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNVQxOTo1MDo1NlrOHzigKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE2MDA2Nw==", "bodyText": "This null check isn't strictly necessary since the code block is in a while received offset is not empty. But this is fine.", "url": "https://github.com/smallrye/smallrye-reactive-messaging/pull/867#discussion_r523160067", "createdAt": "2020-11-13T18:54:02Z", "author": {"login": "pcasaes"}, "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/commit/KafkaThrottledLatestProcessedCommit.java", "diffHunk": "@@ -355,10 +366,14 @@ long clearLesserSequentiallyProcessedOffsetsAndReturnLargestOffset() {\n                         break;\n                     }\n                     unProcessedTotal--;\n-                    largestSequentialProcessedOffset = receivedOffsets.poll().getOffset();\n+                    OffsetReceivedAt poll = receivedOffsets.poll();\n+                    if (poll != null) {\n+                        largestSequentialProcessedOffset = poll.getOffset();\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9e0f888978cfa2cd91f30bc16ee6b40c0b6a6288"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzgwNDcxMw==", "bodyText": "Yes, some weird issues have been reported. So, better to be safe...", "url": "https://github.com/smallrye/smallrye-reactive-messaging/pull/867#discussion_r523804713", "createdAt": "2020-11-15T19:50:56Z", "author": {"login": "cescoffier"}, "path": "smallrye-reactive-messaging-kafka/src/main/java/io/smallrye/reactive/messaging/kafka/commit/KafkaThrottledLatestProcessedCommit.java", "diffHunk": "@@ -355,10 +366,14 @@ long clearLesserSequentiallyProcessedOffsetsAndReturnLargestOffset() {\n                         break;\n                     }\n                     unProcessedTotal--;\n-                    largestSequentialProcessedOffset = receivedOffsets.poll().getOffset();\n+                    OffsetReceivedAt poll = receivedOffsets.poll();\n+                    if (poll != null) {\n+                        largestSequentialProcessedOffset = poll.getOffset();\n+                    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE2MDA2Nw=="}, "originalCommit": {"oid": "9e0f888978cfa2cd91f30bc16ee6b40c0b6a6288"}, "originalPosition": 56}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 19, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}