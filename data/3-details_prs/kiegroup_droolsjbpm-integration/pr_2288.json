{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA1ODMxODY5", "number": 2288, "title": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer", "bodyText": "Implementing Kafka server extension\nJIRA:\nJBPM-9436\nDepends on:\n#drools-build-bootstrap:1502 and #jbpm:1785", "createdAt": "2020-10-19T09:36:08Z", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288", "merged": true, "mergeCommit": {"oid": "1032eeb870afeea6dd9a9211b894badb4f1874d6"}, "closed": true, "closedAt": "2020-11-16T07:48:39Z", "author": {"login": "fjtirado"}, "timelineItems": {"totalCount": 63, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUbN0VgBqjM4OTk2MzczNTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABddAELQAFqTUzMDk5NTYzMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8e5ee1776b86fc7d0fb4480e9029327cff85813b", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8e5ee1776b86fc7d0fb4480e9029327cff85813b", "committedDate": "2020-10-19T08:58:49Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka dependency to common ones so it is added to war and\nstarters"}, "afterCommit": {"oid": "d79eae8548866858e58088e3ea29b2dd33025563", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d79eae8548866858e58088e3ea29b2dd33025563", "committedDate": "2020-10-20T16:18:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d79eae8548866858e58088e3ea29b2dd33025563", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d79eae8548866858e58088e3ea29b2dd33025563", "committedDate": "2020-10-20T16:18:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "committedDate": "2020-10-21T11:36:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzNzEwOTg1", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-513710985", "createdAt": "2020-10-21T13:52:46Z", "commit": {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxMzo1Mjo0NlrOHltjLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQxMzo1Mjo0NlrOHltjLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTMwNTY0Ng==", "bodyText": "fix this to 7.46.0-SNAPSHOT", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r509305646", "createdAt": "2020-10-21T13:52:46Z", "author": {"login": "mareknovotny"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/pom.xml", "diffHunk": "@@ -0,0 +1,104 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>org.kie.server</groupId>\n+    <artifactId>kie-server-services</artifactId>\n+    <version>7.45.0-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzNzEyNjE1", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-513712615", "createdAt": "2020-10-21T13:54:11Z", "commit": {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "committedDate": "2020-10-21T11:36:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "committedDate": "2020-10-21T14:57:34Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "committedDate": "2020-10-21T14:57:34Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "67f19ebca307e4d3c223b704c040d024d16bc600", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/67f19ebca307e4d3c223b704c040d024d16bc600", "committedDate": "2020-10-21T15:29:59Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "67f19ebca307e4d3c223b704c040d024d16bc600", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/67f19ebca307e4d3c223b704c040d024d16bc600", "committedDate": "2020-10-21T15:29:59Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "e29dee4abca91ee94fa1028d6837290b9e0d3f50", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e29dee4abca91ee94fa1028d6837290b9e0d3f50", "committedDate": "2020-10-22T14:20:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e29dee4abca91ee94fa1028d6837290b9e0d3f50", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e29dee4abca91ee94fa1028d6837290b9e0d3f50", "committedDate": "2020-10-22T14:20:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "c42d9cdb39dda016b37754a2dae093952e4b3f9e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/c42d9cdb39dda016b37754a2dae093952e4b3f9e", "committedDate": "2020-10-22T14:42:23Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c42d9cdb39dda016b37754a2dae093952e4b3f9e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/c42d9cdb39dda016b37754a2dae093952e4b3f9e", "committedDate": "2020-10-22T14:42:23Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "committedDate": "2020-10-23T17:26:57Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "committedDate": "2020-10-23T17:26:57Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "34ff698efbf4c1aa19008897dcfaaba18a3b5596", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/34ff698efbf4c1aa19008897dcfaaba18a3b5596", "committedDate": "2020-10-23T18:41:27Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "34ff698efbf4c1aa19008897dcfaaba18a3b5596", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/34ff698efbf4c1aa19008897dcfaaba18a3b5596", "committedDate": "2020-10-23T18:41:27Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "committedDate": "2020-10-26T10:20:05Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "committedDate": "2020-10-26T10:20:05Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "0d1dddbc5234e2dbf427989466eca1e4551e98b3", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0d1dddbc5234e2dbf427989466eca1e4551e98b3", "committedDate": "2020-10-26T13:33:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d1dddbc5234e2dbf427989466eca1e4551e98b3", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0d1dddbc5234e2dbf427989466eca1e4551e98b3", "committedDate": "2020-10-26T13:33:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "3bd246b0b13958748a0ef793ea34a08c7665d8cd", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3bd246b0b13958748a0ef793ea34a08c7665d8cd", "committedDate": "2020-10-26T15:54:34Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3bd246b0b13958748a0ef793ea34a08c7665d8cd", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3bd246b0b13958748a0ef793ea34a08c7665d8cd", "committedDate": "2020-10-26T15:54:34Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "committedDate": "2020-10-26T15:59:52Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "committedDate": "2020-10-26T15:59:52Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "committedDate": "2020-10-26T16:06:38Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "committedDate": "2020-10-26T16:06:38Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "810d0ff22b517a4abd002d813b18888d4f4c98f1", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/810d0ff22b517a4abd002d813b18888d4f4c98f1", "committedDate": "2020-10-26T16:28:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "810d0ff22b517a4abd002d813b18888d4f4c98f1", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/810d0ff22b517a4abd002d813b18888d4f4c98f1", "committedDate": "2020-10-26T16:28:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "be3cb973510d04f8aabe096d1c4d01db934e719f", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/be3cb973510d04f8aabe096d1c4d01db934e719f", "committedDate": "2020-10-26T18:00:43Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "be3cb973510d04f8aabe096d1c4d01db934e719f", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/be3cb973510d04f8aabe096d1c4d01db934e719f", "committedDate": "2020-10-26T18:00:43Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "committedDate": "2020-10-27T08:17:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "committedDate": "2020-10-27T08:17:03Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "af57f54bddf624b72405dba9b935ead67b97fb89", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af57f54bddf624b72405dba9b935ead67b97fb89", "committedDate": "2020-10-28T17:15:41Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af57f54bddf624b72405dba9b935ead67b97fb89", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af57f54bddf624b72405dba9b935ead67b97fb89", "committedDate": "2020-10-28T17:15:41Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/702567a869b50937e72c6dd7c121751cda401833", "committedDate": "2020-10-30T08:13:55Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwNDQ1NjIy", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-520445622", "createdAt": "2020-10-30T08:07:46Z", "commit": {"oid": "af57f54bddf624b72405dba9b935ead67b97fb89"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwODoxMDo1MlrOHrEz6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxMTozOToyN1rOHrLY3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyOTY0MA==", "bodyText": "jBPM or BPM-Kafka\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <description>KIE Kafka JPBM Execution Server Extension</description>\n          \n          \n            \n              <description>KIE Kafka jBPM Execution Server Extension</description>", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r514929640", "createdAt": "2020-10-30T08:10:52Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/pom.xml", "diffHunk": "@@ -0,0 +1,92 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <parent>\n+    <groupId>org.kie.server</groupId>\n+    <artifactId>kie-server-services</artifactId>\n+    <version>7.46.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>kie-server-services-kafka</artifactId>\n+\n+  <name>KIE :: Execution Server :: Services :: Kafka Extension</name>\n+  <description>KIE Kafka JPBM Execution Server Extension</description>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af57f54bddf624b72405dba9b935ead67b97fb89"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk3Mjk5Nw==", "bodyText": "Maybe it's worth checking node is not null to avoid any potential NPE", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r514972997", "createdAt": "2020-10-30T09:37:07Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/CloudEvent.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+class CloudEvent<T> {\n+\n+    private static ObjectMapper mapper = new ObjectMapper()\n+            .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                    KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"json.date_format\", System.getProperty(\n+                            \"org.kie.server.json.date_format\",\n+                            \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))));\n+\n+    private String specVersion;\n+    private Date time;\n+    private String id;\n+    private String type;\n+    private String source;\n+    private T data;\n+\n+    public static <T> CloudEvent<T> read(byte[] bytes, Class<T> type) throws IOException, ParseException {\n+        JsonNode node = mapper.readTree(bytes);\n+        CloudEvent<T> cloudEvent = new CloudEvent<>();\n+        if (node.has(\"id\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk4OTE2Mg==", "bodyText": "Does it make to have it defined as public? As we already have a public method getExtensionName already defined? maybe it's useful to use it in a static context? just wondering.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r514989162", "createdAt": "2020-10-30T10:06:15Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAwMTY4Mg==", "bodyText": "Should we instead try to force user to specify a port number through properties? I mean, by removing this default port number?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515001682", "createdAt": "2020-10-30T10:29:56Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAwMTg1Nw==", "bodyText": "typo\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // read only commited events\n          \n          \n            \n                    // read only committed events", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515001857", "createdAt": "2020-10-30T10:30:17Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only commited events", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNDY4Ng==", "bodyText": "Red Hat copyright is missing.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515024686", "createdAt": "2020-10-30T11:15:48Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNTcyNg==", "bodyText": "Can be replaced with empty diamonds\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n          \n          \n            \n                    private MockConsumer<String, byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515025726", "createdAt": "2020-10-30T11:17:43Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNzMxMA==", "bodyText": "Typo\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class KakfaServerExtensionTest {\n          \n          \n            \n            public class KafkaServerExtensionTest {", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515027310", "createdAt": "2020-10-30T11:20:22Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTI5Ng==", "bodyText": "Checked exception is not thrown within this method\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorMessage() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorMessage() {", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029296", "createdAt": "2020-10-30T11:24:06Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTUwNw==", "bodyText": "Checked exception is not thrown within this method\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorMessageTopic() {", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029507", "createdAt": "2020-10-30T11:24:27Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTY3MA==", "bodyText": "Checked exception is not thrown within this method\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorSignal() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorSignal() {", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029670", "createdAt": "2020-10-30T11:24:44Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNjk2OQ==", "bodyText": "Can be replaced with empty diamonds\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515036969", "createdAt": "2020-10-30T11:38:38Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNzIyNA==", "bodyText": "same as above\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",\n          \n          \n            \n                    extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515037224", "createdAt": "2020-10-30T11:39:07Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        long records = 10L;\n+        for (TopicPartition partition : partitions) {\n+            partitionsBeginningMap.put(partition, 0l);\n+            partitionsEndMap.put(partition, records);\n+        }\n+        extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n+        extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n+        extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNzQwNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        partitionsBeginningMap.put(partition, 0l);\n          \n          \n            \n                        partitionsBeginningMap.put(partition, 0L);", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515037406", "createdAt": "2020-10-30T11:39:27Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        long records = 10L;\n+        for (TopicPartition partition : partitions) {\n+            partitionsBeginningMap.put(partition, 0l);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833"}, "originalPosition": 140}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "702567a869b50937e72c6dd7c121751cda401833", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/702567a869b50937e72c6dd7c121751cda401833", "committedDate": "2020-10-30T08:13:55Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/5162c4b335dc9d4e66a42d45755478723f9ecd40", "committedDate": "2020-10-30T15:15:43Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/5162c4b335dc9d4e66a42d45755478723f9ecd40", "committedDate": "2020-10-30T15:15:43Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "committedDate": "2020-10-30T15:17:23Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxNTQ5ODAz", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-521549803", "createdAt": "2020-11-02T11:32:33Z", "commit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMTozMjozM1rOHsAufA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMjoxMjoyM1rOHsB5XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkxMTI5Mg==", "bodyText": "why is this required ?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515911292", "createdAt": "2020-11-02T11:32:33Z", "author": {"login": "elguardian"}, "path": "drools-ha/pom.xml", "diffHunk": "@@ -73,17 +73,6 @@\n       </dependency>\n \n       <!-- kafka -->\n-      <dependency>\n-        <groupId>org.apache.kafka</groupId>\n-        <artifactId>kafka-clients</artifactId>\n-        <version>${version.org.apache.kafka}</version>\n-      </dependency>\n-      <dependency>\n-        <groupId>org.apache.kafka</groupId>\n-        <artifactId>kafka-clients</artifactId>\n-        <version>${version.org.apache.kafka}</version>\n-        <classifier>test</classifier>\n-      </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkxNzk0Mg==", "bodyText": "extract DeploymentEventListener (this is the topic manager) and Runnable (this is the event executor) from here.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515917942", "createdAt": "2020-11-02T11:45:53Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMTEwOA==", "bodyText": "test signal first and then messages. there is no such thing as signal type message (in spite it is implemented that way)\nif (there is no signal  defined should log a warn message like there is no way I sent this to jbpm or signal not bounded to any process in kjar bla bla bal\nif there is a parse exception should ignore the error (dont't log at that level) as you are doing content based routing (log as warn message) -> ignoring event by jbpm (you have the structure ref (if that is defined then use it) -> getClassData", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515921108", "createdAt": "2020-11-02T11:52:19Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 277}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMjA5Mw==", "bodyText": "the only thing missing here is the class loader. Maybe you can reuse the json marshaller (already has all this logic)\nAt least I cannot see how you can reach kjar class loader from here.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515922093", "createdAt": "2020-11-02T11:54:22Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/CloudEvent.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+class CloudEvent<T> {\n+\n+    private static ObjectMapper mapper = new ObjectMapper()\n+            .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                    KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"json.date_format\", System.getProperty(\n+                            \"org.kie.server.json.date_format\",\n+                            \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))));\n+\n+    private String specVersion;\n+    private Date time;\n+    private String id;\n+    private String type;\n+    private String source;\n+    private T data;\n+\n+    public static <T> CloudEvent<T> read(byte[] bytes, Class<T> type) throws IOException, ParseException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMjY4MQ==", "bodyText": "this is not going to find any class at project leve AFAIK.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515922681", "createdAt": "2020-11-02T11:55:31Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        if (signalInfo != null) {\n+            try {\n+                String type = signalInfo.getSignalDesc().getName();\n+                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n+                    type = \"Message-\" + type;\n+                }\n+                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),\n+                        getDataClass(signalInfo.getSignalDesc())).getData());\n+            } catch (IOException | ParseException e) {\n+                logger.error(\"Error deserializing event\", e);\n+            }\n+        }\n+    }\n+\n+    private Class<?> getDataClass(SignalDesc signalDesc) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 292}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyNjA0Nw==", "bodyText": "If you are setting by default this extension as true\nhttps://github.com/kiegroup/droolsjbpm-integration/pull/2288/files#diff-821631efbb543afdf97147bcc31174b3fa3f48fc3b97159a0536a484468d0c4cR82\n(disable false)\nthis is not necessaraly true as this can be active without any kafka server in the environment. Have you checked ?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515926047", "createdAt": "2020-11-02T12:02:45Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTExNA==", "bodyText": "this is far to generic and it is not documented in the BAPL.\nsignal names within process does not necessarily mean the same among process I would argue this is a good idea in the general case.\nWhile I can see the benefit (and indeed you can leave it like this). You would need to search first for more particular signal definition\nThe most particular case (this should be mandatory at least)\nTOPIC_PREFIX...signalName=signalName\nmore general (by deployment)\nTOPIC_PREFIX..signalName = signalName\nor your case (by entire server -> this is ok too)\nTOPIC_PREFIX.signalName = signalName\nAlso requires to say that some signal is bounded. For instance is there is a signal registed by a process there is need to set an info kjar - process id - signal has been bounded to topic (whatever topic is mapped) through system property whaever.\nThe spec how to define the mapping should be part of the documentation of your BAPL as well.\nThis would add a lot of info regarding the mapping and allow diagnostics.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929114", "createdAt": "2020-11-02T12:09:27Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTc5OA==", "bodyText": "debug levels regarding what signal you received and where are you sending it.\ntrace would be the message content.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929798", "createdAt": "2020-11-02T12:10:55Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        if (signalInfo != null) {\n+            try {\n+                String type = signalInfo.getSignalDesc().getName();\n+                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n+                    type = \"Message-\" + type;\n+                }\n+                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTkzNw==", "bodyText": "make this configurable (number of threads)", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929937", "createdAt": "2020-11-02T12:11:13Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkzMDQ2MA==", "bodyText": "if we have several deployments with the same signal name, wouldn't be overriding the deployment Id ?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515930460", "createdAt": "2020-11-02T12:12:23Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 170}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "committedDate": "2020-10-30T15:17:23Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "committedDate": "2020-11-03T13:02:22Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "committedDate": "2020-11-03T13:02:22Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "1ab6958fe0bfbaf2245278de193e40219f168da9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1ab6958fe0bfbaf2245278de193e40219f168da9", "committedDate": "2020-11-03T15:58:11Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1ab6958fe0bfbaf2245278de193e40219f168da9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1ab6958fe0bfbaf2245278de193e40219f168da9", "committedDate": "2020-11-03T15:58:11Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/89ec48820033dc591dbdd8172b8ed967bee3bb4e", "committedDate": "2020-11-03T17:06:57Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/89ec48820033dc591dbdd8172b8ed967bee3bb4e", "committedDate": "2020-11-03T17:06:57Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "committedDate": "2020-11-03T18:13:12Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "committedDate": "2020-11-03T18:13:12Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "committedDate": "2020-11-03T19:02:31Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "committedDate": "2020-11-03T19:02:31Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "committedDate": "2020-11-03T19:32:47Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "committedDate": "2020-11-03T19:32:47Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "committedDate": "2020-11-03T19:39:10Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "committedDate": "2020-11-03T19:39:10Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "13cf2e3acbca0ecf0342470b14c72fcea677bcad", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13cf2e3acbca0ecf0342470b14c72fcea677bcad", "committedDate": "2020-11-03T20:04:32Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "13cf2e3acbca0ecf0342470b14c72fcea677bcad", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13cf2e3acbca0ecf0342470b14c72fcea677bcad", "committedDate": "2020-11-03T20:04:32Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "committedDate": "2020-11-03T20:27:35Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "committedDate": "2020-11-03T20:27:35Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "committedDate": "2020-11-03T21:22:24Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "committedDate": "2020-11-03T21:22:24Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "committedDate": "2020-11-04T16:01:06Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "committedDate": "2020-11-04T16:01:06Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "1a508f60083129fe949114e3c0b19f457c8587f9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1a508f60083129fe949114e3c0b19f457c8587f9", "committedDate": "2020-11-05T08:23:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1a508f60083129fe949114e3c0b19f457c8587f9", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1a508f60083129fe949114e3c0b19f457c8587f9", "committedDate": "2020-11-05T08:23:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "committedDate": "2020-11-05T08:30:33Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "committedDate": "2020-11-05T08:30:33Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "236d02e2b3dd570d51810a2d32af040e427aaa3f", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/236d02e2b3dd570d51810a2d32af040e427aaa3f", "committedDate": "2020-11-05T10:30:35Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "236d02e2b3dd570d51810a2d32af040e427aaa3f", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/236d02e2b3dd570d51810a2d32af040e427aaa3f", "committedDate": "2020-11-05T10:30:35Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "committedDate": "2020-11-05T12:06:51Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI0MjkzOTQz", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-524293943", "createdAt": "2020-11-05T14:07:32Z", "commit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNDowNzozMlrOHuE4TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNDozMTo0NFrOHuF_UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA3NjQ5Mw==", "bodyText": "what a about just removing\n\n  \n    \n      droolsjbpm-integration/drools-ha/pom.xml\n    \n    \n         Line 27\n      in\n      a95e268\n    \n    \n    \n    \n\n        \n          \n           <version.org.apache.kafka>2.2.1</version.org.apache.kafka> \n        \n    \n  \n\n ?\nand remove the version element of those dependencies ?\nthis modules depends on kie parent", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518076493", "createdAt": "2020-11-05T14:07:32Z", "author": {"login": "elguardian"}, "path": "drools-ha/pom.xml", "diffHunk": "@@ -73,17 +73,6 @@\n       </dependency>\n \n       <!-- kafka -->\n-      <dependency>\n-        <groupId>org.apache.kafka</groupId>\n-        <artifactId>kafka-clients</artifactId>\n-        <version>${version.org.apache.kafka}</version>\n-      </dependency>\n-      <dependency>\n-        <groupId>org.apache.kafka</groupId>\n-        <artifactId>kafka-clients</artifactId>\n-        <version>${version.org.apache.kafka}</version>\n-        <classifier>test</classifier>\n-      </dependency>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkxMTI5Mg=="}, "originalCommit": {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA4MDk2MA==", "bodyText": "change not required. remove this file from the commit", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518080960", "createdAt": "2020-11-05T14:13:38Z", "author": {"login": "elguardian"}, "path": "process-migration-service/frontend/package-lock.json", "diffHunk": "@@ -6,7 +6,7 @@\n   \"dependencies\": {\n     \"@babel/cli\": {\n       \"version\": \"7.5.5\",\n-      \"resolved\": \"https://repository.engineering.redhat.com/nexus/repository/registry.npmjs.org/@babel/cli/-/cli-7.5.5.tgz\",\n+      \"resolved\": \"https://registry.npmjs.org/@babel/cli/-/cli-7.5.5.tgz\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5MjcwMg==", "bodyText": "if we have consumer but not topics this loop does not sleep. we will eat CPU non stop without interruption.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518092702", "createdAt": "2020-11-05T14:29:04Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        classes.clear();\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                notifyService.shutdownNow();\n+                consumer.close();\n+                notifyService = null;\n+                consumer = null;\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService =\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n+            Thread pollService = new Thread(this);\n+            pollService.start();\n+        }\n+        else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        while (consumerReady.get()) {\n+            if (isSubscribed()) {\n+                ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+                consumerLock.lock();\n+                try {\n+                    try {\n+                        events = consumer.poll(duration);\n+                    } catch (WakeupException ex) {\n+                        logger.trace(\"Kafka wait interrupted\");\n+                    } catch (Exception ex) {\n+                        logger.error(\"Error polling kafka consumer\", ex);\n+                    }\n+                } finally {\n+                    consumerLock.unlock();\n+                }\n+                if (consumerReady.get() && !events.isEmpty()) {\n+                    if (logger.isDebugEnabled()) {\n+                        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+                        for (ConsumerRecord<String, byte[]> event : events) {\n+                            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+                        }\n+                        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+                    }\n+                    for (ConsumerRecord<String, byte[]> event : events) {\n+                        notifyService.submit(() -> processEvent(event));\n+                    }\n+                }\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6"}, "originalPosition": 375}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5NDY3Mg==", "bodyText": "this is ok but has a limitation. we won't support in kafka events typed json unmarshaller.\n{\n    map : {\n         \"key1\" : {\n               \"com.my.simple.type\" : {\n                       \"field\" : \"hello\"\n               }\n          }\n    }\n\n\n(for instance when we have Map, List so the values are not clear and require types being in the json.\nThis limitation should be in the BAPL.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518094672", "createdAt": "2020-11-05T14:31:44Z", "author": {"login": "elguardian"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        classes.clear();\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                notifyService.shutdownNow();\n+                consumer.close();\n+                notifyService = null;\n+                consumer = null;\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService =\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n+            Thread pollService = new Thread(this);\n+            pollService.start();\n+        }\n+        else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        while (consumerReady.get()) {\n+            if (isSubscribed()) {\n+                ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+                consumerLock.lock();\n+                try {\n+                    try {\n+                        events = consumer.poll(duration);\n+                    } catch (WakeupException ex) {\n+                        logger.trace(\"Kafka wait interrupted\");\n+                    } catch (Exception ex) {\n+                        logger.error(\"Error polling kafka consumer\", ex);\n+                    }\n+                } finally {\n+                    consumerLock.unlock();\n+                }\n+                if (consumerReady.get() && !events.isEmpty()) {\n+                    if (logger.isDebugEnabled()) {\n+                        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+                        for (ConsumerRecord<String, byte[]> event : events) {\n+                            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+                        }\n+                        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+                    }\n+                    for (ConsumerRecord<String, byte[]> event : events) {\n+                        notifyService.submit(() -> processEvent(event));\n+                    }\n+                }\n+            }\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private boolean isSubscribed() {\n+        changeRegistrationLock.lock();\n+        try {\n+            return !topic2Message.isEmpty() || !topic2Signal.isEmpty();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+    }\n+\n+    @FunctionalInterface\n+    private static interface Signaller {\n+        void signalEvent(String deploymentId, String signalName, Object data);\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        changeRegistrationLock.lock();\n+        try {\n+            processEvent(topic2Signal, event, this::signalEvent);\n+            processEvent(topic2Message, event,\n+                    (deployment, signalName, data) -> signalEvent(deployment, \"Message-\" + signalName, data));\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+    \n+    private void signalEvent  (String deployment, String signalName, Object data) {\n+        processService.signalEvent(deployment,signalName, data);\n+    }\n+\n+    private <T extends SignalDescBase> void processEvent(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         ConsumerRecord<String, byte[]> event,\n+                                                         Signaller signaller) {\n+        Map<T, Collection<String>> signalInfo = topic2SignalBase.get(event.topic());\n+        if (signalInfo != null) {\n+            for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n+                try {\n+                    String signalName = entry.getKey().getName();\n+                    for (String deploymentId : entry.getValue()) {\n+                        CloudEvent<?> cloudEvent = CloudEvent.read(event.value(), getDataClass(deploymentId, entry\n+                                .getKey()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6"}, "originalPosition": 419}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "committedDate": "2020-11-05T12:06:51Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "a3f08ded394724d463262a6e934d9be600fab800", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a3f08ded394724d463262a6e934d9be600fab800", "committedDate": "2020-11-05T16:13:11Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a3f08ded394724d463262a6e934d9be600fab800", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a3f08ded394724d463262a6e934d9be600fab800", "committedDate": "2020-11-05T16:13:11Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "7dce599fbdcbb724217d646951918e2c2412074a", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7dce599fbdcbb724217d646951918e2c2412074a", "committedDate": "2020-11-05T16:35:15Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7dce599fbdcbb724217d646951918e2c2412074a", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7dce599fbdcbb724217d646951918e2c2412074a", "committedDate": "2020-11-05T16:35:15Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "ad0cfb89fa112f2a98b9419495ae25c836094dba", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/ad0cfb89fa112f2a98b9419495ae25c836094dba", "committedDate": "2020-11-05T16:43:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ad0cfb89fa112f2a98b9419495ae25c836094dba", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/ad0cfb89fa112f2a98b9419495ae25c836094dba", "committedDate": "2020-11-05T16:43:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "committedDate": "2020-11-05T17:12:18Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "committedDate": "2020-11-05T17:12:18Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "b3cdbcd530a752855d2657df035376a16d5b541c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b3cdbcd530a752855d2657df035376a16d5b541c", "committedDate": "2020-11-05T17:27:09Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b3cdbcd530a752855d2657df035376a16d5b541c", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b3cdbcd530a752855d2657df035376a16d5b541c", "committedDate": "2020-11-05T17:27:09Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "b383dc295882ea537dda989cb83658f1016326f8", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b383dc295882ea537dda989cb83658f1016326f8", "committedDate": "2020-11-05T17:38:29Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b383dc295882ea537dda989cb83658f1016326f8", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b383dc295882ea537dda989cb83658f1016326f8", "committedDate": "2020-11-05T17:38:29Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "6b6c758a858eb67417179f99d9af440200aaeb14", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/6b6c758a858eb67417179f99d9af440200aaeb14", "committedDate": "2020-11-05T17:39:06Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6b6c758a858eb67417179f99d9af440200aaeb14", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/6b6c758a858eb67417179f99d9af440200aaeb14", "committedDate": "2020-11-05T17:39:06Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "19526fb11d032f56e2c6a03171fe675b72b52056", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19526fb11d032f56e2c6a03171fe675b72b52056", "committedDate": "2020-11-05T17:41:33Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "19526fb11d032f56e2c6a03171fe675b72b52056", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19526fb11d032f56e2c6a03171fe675b72b52056", "committedDate": "2020-11-05T17:41:33Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "66bd82c671d96ca07b334754c8cf6985ef7bb72e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/66bd82c671d96ca07b334754c8cf6985ef7bb72e", "committedDate": "2020-11-06T08:38:22Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "66bd82c671d96ca07b334754c8cf6985ef7bb72e", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/66bd82c671d96ca07b334754c8cf6985ef7bb72e", "committedDate": "2020-11-06T08:38:22Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "committedDate": "2020-11-06T08:39:17Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "committedDate": "2020-11-06T08:39:17Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "committedDate": "2020-11-06T08:59:13Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "committedDate": "2020-11-06T08:59:13Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af43ecf49d1bad0773753abb586837ea7760d0dd", "committedDate": "2020-11-06T12:32:28Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1MTAyOTA0", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-525102904", "createdAt": "2020-11-06T12:21:15Z", "commit": {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoyMToxNVrOHur-Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxNTozNDo0MlrOHuy1qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNjk0Mw==", "bodyText": "shouldn't we try to unsubscribe from topics before closing the consumer? wdyt?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518716943", "createdAt": "2020-11-06T12:21:15Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNzg1OQ==", "bodyText": "would be beneficial to parameterized a timeout when closing consumer? wdyt?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518717859", "createdAt": "2020-11-06T12:23:11Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczMjA3OQ==", "bodyText": "is there any chance for this to be null, if so, shouldn't we at least log warn message informing about an error while dispatching events? wdyt?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518732079", "createdAt": "2020-11-06T12:52:56Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (!consumerReady.get() && topic2Register.isEmpty()) {\n+            logger.debug(\"There are no topics to subscribe and consumer is not active yet, so skipping\");\n+            return;\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService.set(\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>()));\n+            new Thread(this).start();\n+        } else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+            if (!topic2Register.isEmpty()) {\n+                changeRegistrationLock.lock();\n+                try {\n+                    isSubscribedCond.signal();\n+                } finally {\n+                    changeRegistrationLock.unlock();\n+                }\n+            }\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return true;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        try {\n+            while (consumerReady.get()) {\n+                checkSubscribed();\n+                dispatchEvents(pollEvents(duration));\n+            }\n+        } catch (InterruptedException e) {\n+            logger.warn(\"Polling thread interrupted\", e);\n+            Thread.currentThread().interrupt();\n+        } catch (Exception e) {\n+            logger.error(\"Polling thread unexpectedly finished\", e);\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private void checkSubscribed() throws InterruptedException {\n+        changeRegistrationLock.lock();\n+        try {\n+            while (consumerReady.get() && topic2Signal.isEmpty() && topic2Message.isEmpty()) {\n+                isSubscribedCond.await();\n+            }\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private ConsumerRecords<String, byte[]> pollEvents(Duration duration) {\n+        ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+        if (consumerReady.get()) {\n+            consumerLock.lock();\n+            try {\n+                events = consumer.poll(duration);\n+            } catch (WakeupException ex) {\n+                logger.trace(\"Kafka wait interrupted\");\n+            } catch (Exception ex) {\n+                logger.error(\"Error polling Kafka consumer\", ex);\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        return events;\n+    }\n+\n+    private void dispatchEvents(ConsumerRecords<String, byte[]> events) {\n+        if (consumerReady.get() && !events.isEmpty()) {\n+            if (logger.isDebugEnabled()) {\n+                printEventsLog(events);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                if (notifyService.get() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 415}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczMjUzMg==", "bodyText": "static is redundant for inner interfaces\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static interface Signaller {\n          \n          \n            \n                private interface Signaller {", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518732532", "createdAt": "2020-11-06T12:53:56Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (!consumerReady.get() && topic2Register.isEmpty()) {\n+            logger.debug(\"There are no topics to subscribe and consumer is not active yet, so skipping\");\n+            return;\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService.set(\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>()));\n+            new Thread(this).start();\n+        } else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+            if (!topic2Register.isEmpty()) {\n+                changeRegistrationLock.lock();\n+                try {\n+                    isSubscribedCond.signal();\n+                } finally {\n+                    changeRegistrationLock.unlock();\n+                }\n+            }\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return true;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        try {\n+            while (consumerReady.get()) {\n+                checkSubscribed();\n+                dispatchEvents(pollEvents(duration));\n+            }\n+        } catch (InterruptedException e) {\n+            logger.warn(\"Polling thread interrupted\", e);\n+            Thread.currentThread().interrupt();\n+        } catch (Exception e) {\n+            logger.error(\"Polling thread unexpectedly finished\", e);\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private void checkSubscribed() throws InterruptedException {\n+        changeRegistrationLock.lock();\n+        try {\n+            while (consumerReady.get() && topic2Signal.isEmpty() && topic2Message.isEmpty()) {\n+                isSubscribedCond.await();\n+            }\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private ConsumerRecords<String, byte[]> pollEvents(Duration duration) {\n+        ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+        if (consumerReady.get()) {\n+            consumerLock.lock();\n+            try {\n+                events = consumer.poll(duration);\n+            } catch (WakeupException ex) {\n+                logger.trace(\"Kafka wait interrupted\");\n+            } catch (Exception ex) {\n+                logger.error(\"Error polling Kafka consumer\", ex);\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        return events;\n+    }\n+\n+    private void dispatchEvents(ConsumerRecords<String, byte[]> events) {\n+        if (consumerReady.get() && !events.isEmpty()) {\n+            if (logger.isDebugEnabled()) {\n+                printEventsLog(events);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                if (notifyService.get() != null) {\n+                    notifyService.get().submit(() -> processEvent(event));\n+                }\n+            }\n+        }\n+    }\n+\n+    private void printEventsLog(ConsumerRecords<String, byte[]> events) {\n+        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+        for (ConsumerRecord<String, byte[]> event : events) {\n+            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+        }\n+        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+    }\n+\n+    @FunctionalInterface\n+    private static interface Signaller {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 431}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc0NzE1NA==", "bodyText": "Shouldn't we also stop consumer when undeploying? just wondering, wdyt?", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518747154", "createdAt": "2020-11-06T13:22:35Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc0NzMyNg==", "bodyText": "same as above", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518747326", "createdAt": "2020-11-06T13:22:57Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgwNDIzNg==", "bodyText": "Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000 will always return 2 seconds as the property org.kie.server.jbpm-kafka.ext.poll.interval is not defined anywhere in the test.\nNot an issue, but I was thinking about testing all these different sets of properties and make sure it behaves properly", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518804236", "createdAt": "2020-11-06T14:57:10Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.MessageDescImpl;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KafkaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer;\n+\n+        public MockKafkaServerExtension(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public void setKafkaConsumer(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+    private MockConsumer<String, byte[]> mockConsumer;\n+    private static Logger logger = LoggerFactory.getLogger(KafkaServerExtensionTest.class);\n+\n+\n+    @Before\n+    public void setup() {\n+        mockConsumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n+        extension = new MockKafkaServerExtension(mockConsumer);\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionChange() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"ChangedSignal\", \"ChangedSignal\", \"String\"))));\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"ChangedSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionEmpty() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.onUnDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEventWithoutTopicCheck(\"ChangedSignal\",\n+                \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout(0)).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"NewSignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"NewSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"NewSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() {\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() {\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy3\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy3\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal2\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy4\", deployedUnit));\n+        publishEvent(\"MySignal2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy4\", \"MySignal2\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy5\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy5\", \"Message-Hello2\", \"pepe\");\n+    }\n+\n+\n+    private VerificationMode getTimeout() {\n+        return getTimeout(1);\n+    }\n+\n+    private VerificationMode getTimeout(int times) {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgyOTQ4Mw==", "bodyText": "It would be nice to check some other data structure for the cloudEvent rather than always a String.", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518829483", "createdAt": "2020-11-06T15:34:42Z", "author": {"login": "afalhambra"}, "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.MessageDescImpl;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KafkaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer;\n+\n+        public MockKafkaServerExtension(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public void setKafkaConsumer(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+    private MockConsumer<String, byte[]> mockConsumer;\n+    private static Logger logger = LoggerFactory.getLogger(KafkaServerExtensionTest.class);\n+\n+\n+    @Before\n+    public void setup() {\n+        mockConsumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n+        extension = new MockKafkaServerExtension(mockConsumer);\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionChange() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"ChangedSignal\", \"ChangedSignal\", \"String\"))));\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"ChangedSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionEmpty() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.onUnDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEventWithoutTopicCheck(\"ChangedSignal\",\n+                \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout(0)).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"NewSignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"NewSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"NewSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() {\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() {\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy3\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy3\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal2\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy4\", deployedUnit));\n+        publishEvent(\"MySignal2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy4\", \"MySignal2\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy5\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy5\", \"Message-Hello2\", \"pepe\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd"}, "originalPosition": 202}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af43ecf49d1bad0773753abb586837ea7760d0dd", "committedDate": "2020-11-06T12:32:28Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d63411f76bc17e334fe358f8c70b90e4dd1ac424", "committedDate": "2020-11-06T16:50:53Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d63411f76bc17e334fe358f8c70b90e4dd1ac424", "committedDate": "2020-11-06T16:50:53Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "committedDate": "2020-11-10T10:14:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "committedDate": "2020-11-10T10:14:14Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "95e21534d050bff56d13074948950be9df939956", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95e21534d050bff56d13074948950be9df939956", "committedDate": "2020-11-12T10:22:47Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "95e21534d050bff56d13074948950be9df939956", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95e21534d050bff56d13074948950be9df939956", "committedDate": "2020-11-12T10:22:47Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "95b49e57d4cffeeb11e2932450b8e238634c0922", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95b49e57d4cffeeb11e2932450b8e238634c0922", "committedDate": "2020-11-12T10:24:52Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "95b49e57d4cffeeb11e2932450b8e238634c0922", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95b49e57d4cffeeb11e2932450b8e238634c0922", "committedDate": "2020-11-12T10:24:52Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "945d353841d850912e6eefcc695cd7d4d91389cc", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/945d353841d850912e6eefcc695cd7d4d91389cc", "committedDate": "2020-11-12T10:28:49Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "945d353841d850912e6eefcc695cd7d4d91389cc", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/945d353841d850912e6eefcc695cd7d4d91389cc", "committedDate": "2020-11-12T10:28:49Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "3f70db10544811cf5d8d5efcd041deec80f2b89b", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3f70db10544811cf5d8d5efcd041deec80f2b89b", "committedDate": "2020-11-12T15:41:58Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8979388bc0e800adb102dfb3c4a9fbae2a868590", "committedDate": "2020-11-12T17:38:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3f70db10544811cf5d8d5efcd041deec80f2b89b", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3f70db10544811cf5d8d5efcd041deec80f2b89b", "committedDate": "2020-11-12T15:41:58Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}, "afterCommit": {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590", "author": {"user": {"login": "fjtirado", "name": "Francisco Javier Tirado Sarti"}}, "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8979388bc0e800adb102dfb3c4a9fbae2a868590", "committedDate": "2020-11-12T17:38:02Z", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwOTc3MjA2", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-530977206", "createdAt": "2020-11-16T07:35:34Z", "commit": {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwOTk1NjMz", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#pullrequestreview-530995633", "createdAt": "2020-11-16T07:45:36Z", "commit": {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1231, "cost": 1, "resetAt": "2021-11-01T15:33:45Z"}}}