{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkwMDk1MTY0", "number": 1672, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjoyNjozNFrOFGrtWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjozMDozNlrOFGrztQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNTUxODk3OnYy", "diffSide": "RIGHT", "path": "full/src/main/java/apoc/ttl/TTLLifeCycle.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjoyNjozNFrOIHzSdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjoyNjozNFrOIHzSdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTA1MTI1NQ==", "bodyText": "let's just use limit as parameter for batch size, we don't need this inner limit anymore it was just used as a \"poor mans\" single batch in the beginning.\nBut now with periodic iterate we have proper batching and can just delete everything in batches of size \"limit\"", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1672#discussion_r545051255", "createdAt": "2020-12-17T12:26:34Z", "author": {"login": "jexp"}, "path": "full/src/main/java/apoc/ttl/TTLLifeCycle.java", "diffHunk": "@@ -45,22 +46,34 @@ public void start() {\n             long ttlScheduleDb = configValues.schedule;\n             ttlIndexJobHandle = scheduler.schedule(TTL_GROUP, this::createTTLIndex, (int)(ttlScheduleDb*0.8), TimeUnit.SECONDS);\n             long limitDb = configValues.limit;\n-            ttlJobHandle = scheduler.scheduleRecurring(TTL_GROUP, () -> expireNodes(limitDb), ttlScheduleDb, ttlScheduleDb, TimeUnit.SECONDS);\n+            long batchSizeDb = configValues.batchSize;\n+            ttlJobHandle = scheduler.scheduleRecurring(TTL_GROUP, () -> expireNodes(limitDb, batchSizeDb), ttlScheduleDb, ttlScheduleDb, TimeUnit.SECONDS);\n         }\n     }\n \n-    public void expireNodes(long limit) {\n+    public void expireNodes(long limit, long batchSize) {\n         try {\n             if (!Util.isWriteableInstance(db)) return;\n-            db.executeTransactionally(\"MATCH (t:TTL) where t.ttl < timestamp() WITH t LIMIT $limit DETACH DELETE t\",\n-                    Util.map(\"limit\", limit),\n-                    result -> {\n-                        QueryStatistics stats = result.getQueryStatistics();\n-                        if (stats.getNodesDeleted()>0) {\n-                            log.info(\"TTL: Expired %d nodes %d relationships\", stats.getNodesDeleted(), stats.getRelationshipsDeleted());\n-                        }\n-                        return null;\n-                    });\n+            String withLimit = (limit > 0) ? \"LIMIT $limit\" : \"\";\n+            String matchTTL = \"MATCH (t:TTL) WHERE t.ttl < timestamp() \";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be0a94d463938da7cf8f41fb140e82fc1bbbe243"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNTUzNTI1OnYy", "diffSide": "RIGHT", "path": "full/src/main/java/apoc/ttl/TTLLifeCycle.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjozMDozNlrOIHzbwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxMjozMDozNlrOIHzbwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTA1MzYzNA==", "bodyText": "see the id(n) thing I sent to @conker84", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1672#discussion_r545053634", "createdAt": "2020-12-17T12:30:36Z", "author": {"login": "jexp"}, "path": "full/src/main/java/apoc/ttl/TTLLifeCycle.java", "diffHunk": "@@ -45,22 +46,34 @@ public void start() {\n             long ttlScheduleDb = configValues.schedule;\n             ttlIndexJobHandle = scheduler.schedule(TTL_GROUP, this::createTTLIndex, (int)(ttlScheduleDb*0.8), TimeUnit.SECONDS);\n             long limitDb = configValues.limit;\n-            ttlJobHandle = scheduler.scheduleRecurring(TTL_GROUP, () -> expireNodes(limitDb), ttlScheduleDb, ttlScheduleDb, TimeUnit.SECONDS);\n+            long batchSizeDb = configValues.batchSize;\n+            ttlJobHandle = scheduler.scheduleRecurring(TTL_GROUP, () -> expireNodes(limitDb, batchSizeDb), ttlScheduleDb, ttlScheduleDb, TimeUnit.SECONDS);\n         }\n     }\n \n-    public void expireNodes(long limit) {\n+    public void expireNodes(long limit, long batchSize) {\n         try {\n             if (!Util.isWriteableInstance(db)) return;\n-            db.executeTransactionally(\"MATCH (t:TTL) where t.ttl < timestamp() WITH t LIMIT $limit DETACH DELETE t\",\n-                    Util.map(\"limit\", limit),\n-                    result -> {\n-                        QueryStatistics stats = result.getQueryStatistics();\n-                        if (stats.getNodesDeleted()>0) {\n-                            log.info(\"TTL: Expired %d nodes %d relationships\", stats.getNodesDeleted(), stats.getRelationshipsDeleted());\n-                        }\n-                        return null;\n-                    });\n+            String withLimit = (limit > 0) ? \"LIMIT $limit\" : \"\";\n+            String matchTTL = \"MATCH (t:TTL) WHERE t.ttl < timestamp() \";\n+            String queryRels = matchTTL + \"WITH t \" + withLimit + \" MATCH (t)-[r]-() RETURN r\";\n+            String queryNodes = matchTTL +  \"RETURN t \" + withLimit;\n+            Map<String,Object> params = Util.map(\"limit\", limit, \"batchSize\", batchSize, \"queryRels\", queryRels, \"queryNodes\", queryNodes);\n+            long relationshipsDeleted = db.executeTransactionally(\n+                    \"CALL apoc.periodic.iterate($queryRels, 'DELETE r', {batchSize: $batchSize, params:{limit: $limit}})\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be0a94d463938da7cf8f41fb140e82fc1bbbe243"}, "originalPosition": 46}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4278, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}