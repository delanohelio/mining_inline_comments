{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1MzcxNjIx", "number": 2190, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozMzozOFrOE_mRBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMjo0MVrOE_uhUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIyNjk1OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-cli/hapi-fhir-cli-api/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozMzozOFrOH9Y1hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozMzozOFrOH9Y1hQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjEwMQ==", "bodyText": "The version should be declared in the root pom file <dependencyManagement> section", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534132101", "createdAt": "2020-12-02T12:33:38Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-api/pom.xml", "diffHunk": "@@ -259,8 +259,14 @@\n \t\t\t<artifactId>awaitility</artifactId>\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n+        <dependency>\n+            <groupId>org.rauschig</groupId>\n+            <artifactId>jarchivelib</artifactId>\n+            <version>1.0.0</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTIzMzA0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozNToxNlrOH9Y5Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzowMDo1NVrOH9k7yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzA0Mw==", "bodyText": "Ah nice they finally renamed this property... \"autoregister_listeners\" has to be the most unintuitive name imaginable for the \"completely disable everything\" flag.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534133043", "createdAt": "2020-12-02T12:35:16Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -90,14 +98,13 @@ public Properties jpaProperties() {\n \t\textraProperties.put(\"hibernate.cache.use_second_level_cache\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_structured_entries\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_minimal_puts\", \"false\");\n-\t\textraProperties.put(\"hibernate.search.model_mapping\", LuceneSearchMappingFactory.class.getName());\n-\t\textraProperties.put(\"hibernate.search.default.directory_provider\", \"filesystem\");\n-\t\textraProperties.put(\"hibernate.search.default.indexBase\", \"target/lucenefiles\");\n-\t\textraProperties.put(\"hibernate.search.lucene_version\", \"LUCENE_CURRENT\");\n-\t\textraProperties.put(\"hibernate.search.default.worker.execution\", \"async\");\n \n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.ANALYSIS_CONFIGURER), HapiLuceneAnalysisConfigurer.class.getName());\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_TYPE), \"local-filesystem\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_ROOT), \"target/lucenefiles\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.LUCENE_VERSION), \"LUCENE_CURRENT\");\n \t\tif (System.getProperty(\"lowmem\") != null) {\n-\t\t\textraProperties.put(\"hibernate.search.autoregister_listeners\", \"false\");\n+\t\t\textraProperties.put(HibernateOrmMapperSettings.ENABLED, \"false\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMzMDMxNQ==", "bodyText": "Yeah threw me for a loop for sure", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534330315", "createdAt": "2020-12-02T17:00:55Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -90,14 +98,13 @@ public Properties jpaProperties() {\n \t\textraProperties.put(\"hibernate.cache.use_second_level_cache\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_structured_entries\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_minimal_puts\", \"false\");\n-\t\textraProperties.put(\"hibernate.search.model_mapping\", LuceneSearchMappingFactory.class.getName());\n-\t\textraProperties.put(\"hibernate.search.default.directory_provider\", \"filesystem\");\n-\t\textraProperties.put(\"hibernate.search.default.indexBase\", \"target/lucenefiles\");\n-\t\textraProperties.put(\"hibernate.search.lucene_version\", \"LUCENE_CURRENT\");\n-\t\textraProperties.put(\"hibernate.search.default.worker.execution\", \"async\");\n \n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.ANALYSIS_CONFIGURER), HapiLuceneAnalysisConfigurer.class.getName());\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_TYPE), \"local-filesystem\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_ROOT), \"target/lucenefiles\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.LUCENE_VERSION), \"LUCENE_CURRENT\");\n \t\tif (System.getProperty(\"lowmem\") != null) {\n-\t\t\textraProperties.put(\"hibernate.search.autoregister_listeners\", \"false\");\n+\t\t\textraProperties.put(HibernateOrmMapperSettings.ENABLED, \"false\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzA0Mw=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTI2MzMzOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/lastn/ElasticsearchSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0MzozN1rOH9ZLrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0MzozN1rOH9ZLrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNzc3NQ==", "bodyText": "nitpick: drop commented line if it is no longer needed", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534137775", "createdAt": "2020-12-02T12:43:37Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/lastn/ElasticsearchSvcImpl.java", "diffHunk": "@@ -721,7 +720,7 @@ public void close() throws IOException {\n \tprivate IndexRequest createIndexRequest(String theIndexName, String theDocumentId, String theObservationDocument, String theDocumentType) {\n \t\tIndexRequest request = new IndexRequest(theIndexName);\n \t\trequest.id(theDocumentId);\n-\t\trequest.type(theDocumentType);\n+//\t\trequest.type(theDocumentType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTI2OTcwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0NToxM1rOH9ZPmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0NToxM1rOH9ZPmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzODc3OQ==", "bodyText": "When this is merged I'll have a look at this, it's probably my bug", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534138779", "createdAt": "2020-12-02T12:45:13Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -536,6 +535,8 @@ private void expandConcepts(IValueSetConceptAccumulator theAccumulator, TermValu\n \t\t\tconceptViews = myTermValueSetConceptViewDao.findByTermValueSetId(theTermValueSet.getId(), displayValue);\n \t\t\twasFilteredResult = true;\n \t\t} else {\n+\t\t\t// TODO GGG HS: I'm pretty sure we are overfetching here.  test says offset 3, count 4, but we are fetching index 3 -> 10 here, grabbing 7 concepts.\n+\t\t\t//Specifically this test testExpandInline_IncludePreExpandedValueSetByUri_FilterOnDisplay_LeftMatch_SelectRange", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTI4NTU3OnYy", "diffSide": "RIGHT", "path": "pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0OToyMVrOH9ZY-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0OToyMVrOH9ZY-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE0MTE3Ng==", "bodyText": "Add these library version changes (except any that are only used in scope test) to here: https://github.com/jamesagnew/hapi-fhir/blob/master/hapi-fhir-docs/src/main/resources/ca/uhn/hapi/fhir/changelog/5_3_0/changes.yaml", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534141176", "createdAt": "2020-12-02T12:49:21Z", "author": {"login": "jamesagnew"}, "path": "pom.xml", "diffHunk": "@@ -742,11 +742,11 @@\n \t\t<jsr305_version>3.0.2</jsr305_version>\n \t\t<junit_version>5.6.2</junit_version>\n \t\t<flyway_version>6.5.4</flyway_version>\n-\t\t<!--<hibernate_version>5.2.10.Final</hibernate_version>-->\n-\t\t<hibernate_version>5.4.22.Final</hibernate_version>\n+\t\t<hibernate_version>5.4.24.Final</hibernate_version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MTYzNzMwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNDoxMjoxNlrOH9cvZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxNzowNjoyNFrOIBqLhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE5NjA2OQ==", "bodyText": "One general comment I'm adding here for lack of a better spot:\nBefore merging, can you try uploading a CodeSystem to an ES-backed server.. then wiping elasticsearch and marking all resources for reindexing, just to confirm that we reload elastic properly? That process will presumably go on to become the migration path assuming it works.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534196069", "createdAt": "2020-12-02T14:12:16Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -23,10 +23,16 @@\n import ca.uhn.fhir.jpa.api.config.DaoConfig;\n import ca.uhn.fhir.jpa.model.config.PartitionSettings;\n import ca.uhn.fhir.jpa.model.entity.ModelConfig;\n-import ca.uhn.fhir.jpa.search.LuceneSearchMappingFactory;\n+import ca.uhn.fhir.jpa.search.HapiLuceneAnalysisConfigurer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODYxMDU2NQ==", "bodyText": "Done!", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r538610565", "createdAt": "2020-12-08T17:06:24Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -23,10 +23,16 @@\n import ca.uhn.fhir.jpa.api.config.DaoConfig;\n import ca.uhn.fhir.jpa.model.config.PartitionSettings;\n import ca.uhn.fhir.jpa.model.entity.ModelConfig;\n-import ca.uhn.fhir.jpa.search.LuceneSearchMappingFactory;\n+import ca.uhn.fhir.jpa.search.HapiLuceneAnalysisConfigurer;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE5NjA2OQ=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjM0Mzc4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/ElasticsearchHibernatePropertiesBuilder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjozMjowMVrOH9jl9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzo0MDo0MVrOH9moNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwODM0MA==", "bodyText": "This file still has a lot of the old implementation but commented out. Can this be removed?\nWon't call out each instance; it's pretty much all of the properties here.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534308340", "createdAt": "2020-12-02T16:32:01Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/ElasticsearchHibernatePropertiesBuilder.java", "diffHunk": "@@ -56,36 +61,50 @@ public ElasticsearchHibernatePropertiesBuilder setPassword(String thePassword) {\n \n \tpublic void apply(Properties theProperties) {\n \n-\t\t// Don't use the Lucene properties as they conflict\n-\t\ttheProperties.remove(\"hibernate.search.model_mapping\");\n-\n \t\t// the below properties are used for ElasticSearch integration\n-\t\ttheProperties.put(\"hibernate.search.default.\" + Environment.INDEX_MANAGER_IMPL_NAME, \"elasticsearch\");\n-\t\ttheProperties.put(\"hibernate.search.\" + ElasticsearchEnvironment.ANALYSIS_DEFINITION_PROVIDER, ElasticsearchMappingProvider.class.getName());\n+\t\ttheProperties.put(BackendSettings.backendKey(BackendSettings.TYPE), \"elasticsearch\");\n+\n+\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchIndexSettings.ANALYSIS_CONFIGURER), HapiElasticsearchAnalysisConfigurer.class.getName());\n+\n+\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.HOSTS), myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.PROTOCOL), myProtocol);\n \n-\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n \t\tif (StringUtils.isNotBlank(myUsername)) {\n-\t\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);\n+\t\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM1ODA3MQ==", "bodyText": "For sure, i just wanted eyes on the intial property swap. removing them all now.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534358071", "createdAt": "2020-12-02T17:40:41Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/ElasticsearchHibernatePropertiesBuilder.java", "diffHunk": "@@ -56,36 +61,50 @@ public ElasticsearchHibernatePropertiesBuilder setPassword(String thePassword) {\n \n \tpublic void apply(Properties theProperties) {\n \n-\t\t// Don't use the Lucene properties as they conflict\n-\t\ttheProperties.remove(\"hibernate.search.model_mapping\");\n-\n \t\t// the below properties are used for ElasticSearch integration\n-\t\ttheProperties.put(\"hibernate.search.default.\" + Environment.INDEX_MANAGER_IMPL_NAME, \"elasticsearch\");\n-\t\ttheProperties.put(\"hibernate.search.\" + ElasticsearchEnvironment.ANALYSIS_DEFINITION_PROVIDER, ElasticsearchMappingProvider.class.getName());\n+\t\ttheProperties.put(BackendSettings.backendKey(BackendSettings.TYPE), \"elasticsearch\");\n+\n+\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchIndexSettings.ANALYSIS_CONFIGURER), HapiElasticsearchAnalysisConfigurer.class.getName());\n+\n+\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.HOSTS), myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.PROTOCOL), myProtocol);\n \n-\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n \t\tif (StringUtils.isNotBlank(myUsername)) {\n-\t\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);\n+\t\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwODM0MA=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjM1MzE5OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/HapiElasticsearchAnalysisConfigurer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjozMzo1NlrOH9jrwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjozMzo1NlrOH9jrwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwOTgyNQ==", "bodyText": "TODOs in this file. I believe you may have already called them out. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534309825", "createdAt": "2020-12-02T16:33:56Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/HapiElasticsearchAnalysisConfigurer.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package ca.uhn.fhir.jpa.search.elastic;\n+\n+/*-\n+ * #%L\n+ * HAPI FHIR JPA Server\n+ * %%\n+ * Copyright (C) 2014 - 2020 University Health Network\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+\n+import org.hibernate.search.backend.elasticsearch.analysis.ElasticsearchAnalysisConfigurationContext;\n+import org.hibernate.search.backend.elasticsearch.analysis.ElasticsearchAnalysisConfigurer;\n+\n+public class HapiElasticsearchAnalysisConfigurer implements ElasticsearchAnalysisConfigurer{\n+\n+\t@Override\n+\tpublic void configure(ElasticsearchAnalysisConfigurationContext theConfigCtx) {\n+\n+\t\ttheConfigCtx.analyzer(\"autocompleteEdgeAnalyzer\").custom()\n+\t\t\t.tokenizer(\"pattern_all\")\n+\t\t\t.tokenFilters(\"lowercase\", \"stop\", \"edgengram_3_50\");\n+\n+\t\ttheConfigCtx.tokenizer(\"pattern_all\")\n+\t\t\t.type(\"pattern\")\n+\t\t\t.param(\"pattern\", \"(.*)\")\n+\t\t\t.param(\"group\", \"1\");\n+\n+\t\ttheConfigCtx.tokenFilter(\"edgengram_3_50\")\n+\t\t\t.type(\"edgeNGram\")\n+\t\t\t.param(\"min_gram\", \"3\")\n+\t\t\t.param(\"max_gram\", \"4\");\n+//\t\t\t.param(\"max_gram\", \"50\");//TODO GGG HS ES 7.10 says we have to set `max_ngram_diff:47` on each index we create, since the default is 1.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjM5NTg0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/provider/dstu3/ResourceProviderDstu3ValueSetVersionedTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjo0MjozN1rOH9kFig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjo0MjozN1rOH9kFig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxNjQyNg==", "bodyText": "These tests are muuuch better. Thanks!", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534316426", "createdAt": "2020-12-02T16:42:37Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/provider/dstu3/ResourceProviderDstu3ValueSetVersionedTest.java", "diffHunk": "@@ -1110,68 +1112,24 @@ private void validateTermValueSetExpandedAndChildrenV1(String theValueSetName, C\n \t\t\tassertEquals(theCodeSystem.getConcept().size(), termValueSet.getConcepts().size());\n \t\t\tassertEquals(TermValueSetPreExpansionStatusEnum.EXPANDED, termValueSet.getExpansionStatus());\n \n-\t\t\tTermValueSetConcept concept = termValueSet.getConcepts().get(0);\n-\t\t\tourLog.info(\"Concept:\\n\" + concept.toString());\n-\t\t\tassertEquals(\"http://acme.org\", concept.getSystem());\n-\t\t\tassertEquals(\"1\", concept.getSystemVersion());\n-\t\t\tassertEquals(\"8450-9\", concept.getCode());\n-\t\t\tassertEquals(\"Systolic blood pressure--expiration\", concept.getDisplay());\n-\t\t\tassertEquals(2, concept.getDesignations().size());\n-\t\t\tassertEquals(0, concept.getOrder());\n-\n-\t\t\tTermValueSetConceptDesignation designation = concept.getDesignations().get(0);\n-\t\t\tassertEquals(\"nl\", designation.getLanguage());\n-\t\t\tassertEquals(\"http://snomed.info/sct\", designation.getUseSystem());\n-\t\t\tassertEquals(\"900000000000013009\", designation.getUseCode());\n-\t\t\tassertEquals(\"Synonym\", designation.getUseDisplay());\n-\t\t\tassertEquals(\"Systolische bloeddruk - expiratie\", designation.getValue());\n-\n-\t\t\tdesignation = concept.getDesignations().get(1);\n-\t\t\tassertEquals(\"sv\", designation.getLanguage());\n-\t\t\tassertEquals(\"http://snomed.info/sct\", designation.getUseSystem());\n-\t\t\tassertEquals(\"900000000000013009\", designation.getUseCode());\n-\t\t\tassertEquals(\"Synonym\", designation.getUseDisplay());\n-\t\t\tassertEquals(\"Systoliskt blodtryck - utg\u00e5ng\", designation.getValue());\n-\n-\t\t\tconcept = termValueSet.getConcepts().get(1);\n-\t\t\tourLog.info(\"Concept:\\n\" + concept.toString());\n-\t\t\tassertEquals(\"http://acme.org\", concept.getSystem());\n-\t\t\tassertEquals(\"1\", concept.getSystemVersion());\n-\t\t\tassertEquals(\"11378-7\", concept.getCode());\n-\t\t\tassertEquals(\"Systolic blood pressure at First encounter\", concept.getDisplay());\n-\t\t\tassertEquals(0, concept.getDesignations().size());\n-\t\t\tassertEquals(1, concept.getOrder());\n+\t\t\tTermValueSetConcept concept = assertTermValueSetContainsConceptAndIsInDeclaredOrder(termValueSet, \"http://acme.org\", \"8450-9\", \"Systolic blood pressure--expiration\", 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjQ4MTcxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/term/ValueSetExpansionR4Test.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzowMDoyMVrOH9k6Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzo0MjowN1rOH9mr5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMyOTkyNw==", "bodyText": "Commenting these out will use the default offset and count values for this test. Below, you've also commented out the related assertions.\nDid you forget to uncomment these? The test name indicates count is relevant to the test.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534329927", "createdAt": "2020-12-02T17:00:21Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/term/ValueSetExpansionR4Test.java", "diffHunk": "@@ -826,62 +660,31 @@ public void testExpandTermValueSetAndChildrenWithCountWithClientAssignedId() thr\n \n \t\tmyTermSvc.preExpandDeferredValueSetsToTerminologyTables();\n \n-\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n-\t\t\t.setOffset(0)\n-\t\t\t.setCount(23);\n-\t\tValueSet expandedValueSet = myTermSvc.expandValueSet(options, valueSet);\n+//\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n+//\t\t\t.setOffset(0)\n+//\t\t\t.setCount(23);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 454}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM1OTAxNQ==", "bodyText": "yeah could be a forgotten wip-refactor. checking", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534359015", "createdAt": "2020-12-02T17:42:07Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/term/ValueSetExpansionR4Test.java", "diffHunk": "@@ -826,62 +660,31 @@ public void testExpandTermValueSetAndChildrenWithCountWithClientAssignedId() thr\n \n \t\tmyTermSvc.preExpandDeferredValueSetsToTerminologyTables();\n \n-\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n-\t\t\t.setOffset(0)\n-\t\t\t.setCount(23);\n-\t\tValueSet expandedValueSet = myTermSvc.expandValueSet(options, valueSet);\n+//\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n+//\t\t\t.setOffset(0)\n+//\t\t\t.setCount(23);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMyOTkyNw=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 454}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjUyNDYzOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxMDowOVrOH9lVhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzo0NDo1OFrOH9mzKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMzNjkwMQ==", "bodyText": "What's the impact of this change?", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534336901", "createdAt": "2020-12-02T17:10:09Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -885,68 +886,41 @@ private Boolean expandValueSetHandleIncludeOrExcludeUsingDatabase(IValueSetConce\n \t\t/*\n \t\t * Ok, let's use hibernate search to build the expansion\n \t\t */\n-\t\tQueryBuilder qb = em.getSearchFactory().buildQueryBuilder().forEntity(TermConcept.class).get();\n-\t\tBooleanJunction<?> bool = qb.bool();\n+\t\t//Manually building a predicate since we need to throw it around.\n+\t\tSearchPredicateFactory predicate = searchSession.scope(TermConcept.class).predicate();\n \n-\t\tbool.must(qb.keyword().onField(\"myCodeSystemVersionPid\").matching(csv.getPid()).createQuery());\n+\t\t//Build the top-level expansion on filters.\n+\t\tPredicateFinalStep step = predicate.bool(b -> {\n+\t\t\tb.must(predicate.match().field(\"myCodeSystemVersionPid\").matching(csv.getPid()));\n \n-\t\tif (theExpansionFilter.hasCode()) {\n-\t\t\tbool.must(qb.keyword().onField(\"myCode\").matching(theExpansionFilter.getCode()).createQuery());\n-\t\t}\n-\n-\t\t/*\n-\t\t * Filters\n-\t\t */\n-\t\tString codeSystemUrlAndVersion;\n-\t\tif (includeOrExcludeVersion != null) {\n-\t\t\tcodeSystemUrlAndVersion = theSystem + \"|\" + includeOrExcludeVersion;\n-\t\t} else {\n-\t\t\tcodeSystemUrlAndVersion = theSystem;\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\n-\t\tQuery luceneQuery = bool.createQuery();\n-\n-\t\t/*\n-\t\t * Include/Exclude Concepts\n-\t\t */\n-\t\tList<Term> codes = theIncludeOrExclude\n-\t\t\t.getConcept()\n-\t\t\t.stream()\n-\t\t\t.filter(Objects::nonNull)\n-\t\t\t.map(ValueSet.ConceptReferenceComponent::getCode)\n-\t\t\t.filter(StringUtils::isNotBlank)\n-\t\t\t.map(t -> new Term(\"myCode\", t))\n-\t\t\t.collect(Collectors.toList());\n-\t\tif (codes.size() > 0) {\n+\t\t\tif (theExpansionFilter.hasCode()) {\n+\t\t\t\tb.must(predicate.match().field(\"myCode\").matching(theExpansionFilter.getCode()));\n+\t\t\t}\n \n-\t\t\tBooleanQuery.Builder builder = new BooleanQuery.Builder();\n-\t\t\tbuilder.setMinimumNumberShouldMatch(1);\n-\t\t\tfor (Term nextCode : codes) {\n-\t\t\t\tbuilder.add(new TermQuery(nextCode), BooleanClause.Occur.SHOULD);\n+\t\t\tString codeSystemUrlAndVersion = buildCodeSystemUrlAndVersion(theSystem, includeOrExcludeVersion);\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n+\t\t\t}\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n \t\t\t}\n+\t\t});\n \n-\t\t\tluceneQuery = new BooleanQuery.Builder()\n-\t\t\t\t.add(luceneQuery, BooleanClause.Occur.MUST)\n-\t\t\t\t.add(builder.build(), BooleanClause.Occur.MUST)\n-\t\t\t\t.build();\n+\t\tPredicateFinalStep expansionStep = buildExpansionPredicate(theIncludeOrExclude, predicate);\n+\t\tfinal PredicateFinalStep finishedQuery;\n+\t\tif (expansionStep == null) {\n+\t\t\tfinishedQuery = step;\n+\t\t} else {\n+\t\t\tfinishedQuery = predicate.bool().must(step).must(expansionStep);\n \t\t}\n \n-\t\t/*\n-\t\t * Execute the query\n-\t\t */\n-\t\tFullTextQuery jpaQuery = em.createFullTextQuery(luceneQuery, TermConcept.class);\n-\n \t\t/*\n \t\t * DM 2019-08-21 - Processing slows after any ValueSets with many codes explicitly identified. This might\n \t\t * be due to the dark arts that is memory management. Will monitor but not do anything about this right now.\n \t\t */\n-\t\tBooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//BooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//TODO GGG HS looks like we can't set max clause count, but it can be set server side.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM2MDg3NA==", "bodyText": "unclear to me at the moment, all tests continue to pass. Worth another look by somebody else.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534360874", "createdAt": "2020-12-02T17:44:58Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -885,68 +886,41 @@ private Boolean expandValueSetHandleIncludeOrExcludeUsingDatabase(IValueSetConce\n \t\t/*\n \t\t * Ok, let's use hibernate search to build the expansion\n \t\t */\n-\t\tQueryBuilder qb = em.getSearchFactory().buildQueryBuilder().forEntity(TermConcept.class).get();\n-\t\tBooleanJunction<?> bool = qb.bool();\n+\t\t//Manually building a predicate since we need to throw it around.\n+\t\tSearchPredicateFactory predicate = searchSession.scope(TermConcept.class).predicate();\n \n-\t\tbool.must(qb.keyword().onField(\"myCodeSystemVersionPid\").matching(csv.getPid()).createQuery());\n+\t\t//Build the top-level expansion on filters.\n+\t\tPredicateFinalStep step = predicate.bool(b -> {\n+\t\t\tb.must(predicate.match().field(\"myCodeSystemVersionPid\").matching(csv.getPid()));\n \n-\t\tif (theExpansionFilter.hasCode()) {\n-\t\t\tbool.must(qb.keyword().onField(\"myCode\").matching(theExpansionFilter.getCode()).createQuery());\n-\t\t}\n-\n-\t\t/*\n-\t\t * Filters\n-\t\t */\n-\t\tString codeSystemUrlAndVersion;\n-\t\tif (includeOrExcludeVersion != null) {\n-\t\t\tcodeSystemUrlAndVersion = theSystem + \"|\" + includeOrExcludeVersion;\n-\t\t} else {\n-\t\t\tcodeSystemUrlAndVersion = theSystem;\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\n-\t\tQuery luceneQuery = bool.createQuery();\n-\n-\t\t/*\n-\t\t * Include/Exclude Concepts\n-\t\t */\n-\t\tList<Term> codes = theIncludeOrExclude\n-\t\t\t.getConcept()\n-\t\t\t.stream()\n-\t\t\t.filter(Objects::nonNull)\n-\t\t\t.map(ValueSet.ConceptReferenceComponent::getCode)\n-\t\t\t.filter(StringUtils::isNotBlank)\n-\t\t\t.map(t -> new Term(\"myCode\", t))\n-\t\t\t.collect(Collectors.toList());\n-\t\tif (codes.size() > 0) {\n+\t\t\tif (theExpansionFilter.hasCode()) {\n+\t\t\t\tb.must(predicate.match().field(\"myCode\").matching(theExpansionFilter.getCode()));\n+\t\t\t}\n \n-\t\t\tBooleanQuery.Builder builder = new BooleanQuery.Builder();\n-\t\t\tbuilder.setMinimumNumberShouldMatch(1);\n-\t\t\tfor (Term nextCode : codes) {\n-\t\t\t\tbuilder.add(new TermQuery(nextCode), BooleanClause.Occur.SHOULD);\n+\t\t\tString codeSystemUrlAndVersion = buildCodeSystemUrlAndVersion(theSystem, includeOrExcludeVersion);\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n+\t\t\t}\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n \t\t\t}\n+\t\t});\n \n-\t\t\tluceneQuery = new BooleanQuery.Builder()\n-\t\t\t\t.add(luceneQuery, BooleanClause.Occur.MUST)\n-\t\t\t\t.add(builder.build(), BooleanClause.Occur.MUST)\n-\t\t\t\t.build();\n+\t\tPredicateFinalStep expansionStep = buildExpansionPredicate(theIncludeOrExclude, predicate);\n+\t\tfinal PredicateFinalStep finishedQuery;\n+\t\tif (expansionStep == null) {\n+\t\t\tfinishedQuery = step;\n+\t\t} else {\n+\t\t\tfinishedQuery = predicate.bool().must(step).must(expansionStep);\n \t\t}\n \n-\t\t/*\n-\t\t * Execute the query\n-\t\t */\n-\t\tFullTextQuery jpaQuery = em.createFullTextQuery(luceneQuery, TermConcept.class);\n-\n \t\t/*\n \t\t * DM 2019-08-21 - Processing slows after any ValueSets with many codes explicitly identified. This might\n \t\t * be due to the dark arts that is memory management. Will monitor but not do anything about this right now.\n \t\t */\n-\t\tBooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//BooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//TODO GGG HS looks like we can't set max clause count, but it can be set server side.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMzNjkwMQ=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjU0NjE4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxNTowOFrOH9lizQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxNTowOFrOH9lizQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0MDMwMQ==", "bodyText": "This looks correct to me. There are related tests (or should be) so if they're happy, so am I.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534340301", "createdAt": "2020-12-02T17:15:08Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.REGEX) {\n+\n+\t\t\t/*\n+\t\t\t * We treat the regex filter as a match on the regex\n+\t\t\t * anywhere in the property string. The spec does not\n+\t\t\t * say whether or not this is the right behaviour, but\n+\t\t\t * there are examples that seem to suggest that it is.\n+\t\t\t */\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tif (value.endsWith(\"$\")) {\n+\t\t\t\tvalue = value.substring(0, value.length() - 1);\n+\t\t\t} else if (!value.endsWith(\".*\")) {\n+\t\t\t\tvalue = value + \".*\";\n+\t\t\t}\n+\t\t\tif (!value.startsWith(\"^\") && !value.startsWith(\".*\")) {\n+\t\t\t\tvalue = \".*\" + value;\n+\t\t\t} else if (value.startsWith(\"^\")) {\n+\t\t\t\tvalue = value.substring(1);\n+\t\t\t}\n+\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\tRegexpQuery query = new RegexpQuery(term);\n+\t\t\t//TODO GGG HS write the equivalent ES Query here.\n+\t\t\ttheB.must(theF.extension(LuceneExtension.get()).fromLuceneQuery(query));\n+\n+\t\t\t//Given that we want to be backend-agnostic, we can't really suport RegExpQuery here as it is lucene based. Will\n+\t\t\t//Probably have to replace with wildcard query :https://docs.jboss.org/hibernate/search/6.0/reference/en-US/html_single/#search-dsl-predicate-wildcard.\n+\t\t\t//This query is _almost certainly wrong right now_\n+\t\t\t//theB.must(theF.match().field(term.field()).matching(term.text()));\n+//\t\t\ttheB.must(theF.match().field(term.field()).matching(term.text()));\n+\n+\n+\t\t} else {\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\ttheB.must(theF.match().field(term.field()).matching(term.text()));\n+\n \t\t}\n \t}\n \n-\tprivate boolean isCodeSystemLoinc(String theSystem) {\n-\t\treturn ITermLoaderSvc.LOINC_URI.equals(theSystem);\n-\t}\n+\tprivate void handleFilterLoincCopyright(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n \n-\tprivate void handleFilterDisplay(QueryBuilder theQb, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\tif (theFilter.getProperty().equals(\"display:exact\") && theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n-\t\t\taddDisplayFilterExact(theQb, theBool, theFilter);\n-\t\t} else if (theFilter.getProperty().equals(\"display\") && theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n-\t\t\tif (theFilter.getValue().trim().contains(\" \")) {\n-\t\t\t\taddDisplayFilterExact(theQb, theBool, theFilter);\n-\t\t\t} else {\n-\t\t\t\taddDisplayFilterInexact(theQb, theBool, theFilter);\n+\t\t\tString copyrightFilterValue = defaultString(theFilter.getValue()).toLowerCase();\n+\t\t\tswitch (copyrightFilterValue) {\n+\t\t\t\tcase \"3rdparty\":\n+\t\t\t\t\tlogFilteringValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n+\t\t\t\t\taddFilterLoincCopyright3rdParty(theF, theB);\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase \"loinc\":\n+\t\t\t\t\tlogFilteringValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n+\t\t\t\t\taddFilterLoincCopyrightLoinc(theF, theB);\n+\t\t\t\t\tbreak;\n+\t\t\t\tdefault:\n+\t\t\t\t\tthrowInvalidRequestForValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n \t\t\t}\n-\t\t}\n-\t}\n \n-\tprivate void addDisplayFilterExact(QueryBuilder qb, BooleanJunction<?> bool, ValueSet.ConceptSetFilterComponent nextFilter) {\n-\t\tbool.must(qb.phrase().onField(\"myDisplay\").sentence(nextFilter.getValue()).createQuery());\n+\t\t} else {\n+\t\t\tthrowInvalidRequestForOpOnProperty(theFilter.getOp(), theFilter.getProperty());\n+\t\t}\n \t}\n \n-\tprivate void addDisplayFilterInexact(QueryBuilder qb, BooleanJunction<?> bool, ValueSet.ConceptSetFilterComponent nextFilter) {\n-\t\tQuery textQuery = qb\n-\t\t\t.phrase()\n-\t\t\t.withSlop(2)\n-\t\t\t.onField(\"myDisplay\").boostedTo(4.0f)\n-\t\t\t//.andField(\"myDisplayEdgeNGram\").boostedTo(2.0f)\n-\t\t\t.andField(\"myDisplayWordEdgeNGram\").boostedTo(1.0f)\n-\t\t\t// .andField(\"myDisplayPhonetic\").boostedTo(0.5f)\n-\t\t\t.sentence(nextFilter.getValue().toLowerCase()).createQuery();\n-\t\tbool.must(textQuery);\n+\tprivate void addFilterLoincCopyrightLoinc(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB) {\n+\t\ttheB.mustNot(theF.exists().field(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + \"EXTERNAL_COPYRIGHT_NOTICE\"));\n \t}\n \n-\tprivate void handleFilterConceptAndCode(String theSystem, QueryBuilder theQb, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\tTermConcept code = findCode(theSystem, theFilter.getValue())\n-\t\t\t.orElseThrow(() -> new InvalidRequestException(\"Invalid filter criteria - code does not exist: {\" + Constants.codeSystemWithDefaultDescription(theSystem) + \"}\" + theFilter.getValue()));\n-\n-\t\tif (theFilter.getOp() == ValueSet.FilterOperator.ISA) {\n-\t\t\tourLog.debug(\" * Filtering on codes with a parent of {}/{}/{}\", code.getId(), code.getCode(), code.getDisplay());\n-\t\t\ttheBool.must(theQb.keyword().onField(\"myParentPids\").matching(\"\" + code.getId()).createQuery());\n-\t\t} else {\n-\t\t\tthrow new InvalidRequestException(\"Don't know how to handle op=\" + theFilter.getOp() + \" on property \" + theFilter.getProperty());\n-\t\t}\n+\tprivate void addFilterLoincCopyright3rdParty(SearchPredicateFactory f, BooleanPredicateClausesStep<?> b) {\n+\t\t//TODO GGG HS These used to be Term term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + \"EXTERNAL_COPYRIGHT_NOTICE\", \".*\");, which was lucene-specific.\n+\t\t//TODO GGG HS ask diederik if this is equivalent.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 387}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjU2MTcyOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxODo0NFrOH9lsqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoxODo0NFrOH9lsqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0MjgyNg==", "bodyText": "I think this meets our needs. This is only used in debug logging. If there's something more meaningful that can be logged here, by all means add it. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534342826", "createdAt": "2020-12-02T17:18:44Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -967,22 +941,27 @@ private Boolean expandValueSetHandleIncludeOrExcludeUsingDatabase(IValueSetConce\n \t\t\t}\n \t\t}\n \n-\t\tjpaQuery.setMaxResults(maxResultsPerBatch);\n-\t\tjpaQuery.setFirstResult(theQueryIndex * maxResultsPerBatch);\n+//\t\tjpaQuery.setMaxResults(maxResultsPerBatch);\n+//\t\tjpaQuery.setFirstResult(theQueryIndex * maxResultsPerBatch);\n \n \t\tourLog.debug(\"Beginning batch expansion for {} with max results per batch: {}\", (theAdd ? \"inclusion\" : \"exclusion\"), maxResultsPerBatch);\n \n \t\tStopWatch swForBatch = new StopWatch();\n \t\tAtomicInteger countForBatch = new AtomicInteger(0);\n \n-\t\tList<?> resultList = jpaQuery.getResultList();\n-\t\tint resultsInBatch = resultList.size();\n-\t\tint firstResult = jpaQuery.getFirstResult();\n+\t\tSearchQuery<TermConcept> termConceptsQuery = searchSession.search(TermConcept.class)\n+\t\t\t.where(f -> finishedQuery).toQuery();\n+\n+\t\tSystem.out.println(\"About to query:\" +  termConceptsQuery.queryString());\n+\t\tList<TermConcept> termConcepts = termConceptsQuery.fetchHits(theQueryIndex * maxResultsPerBatch, maxResultsPerBatch);\n+\n+\n+\t\tint resultsInBatch = termConcepts.size();\n+\t\tint firstResult = theQueryIndex * maxResultsPerBatch;// TODO GGG HS we lose the ability to check the index of the first result, so just best-guessing it here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjU2OTYxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMDozMFrOH9lxqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzo0NjoyNFrOH9m3Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NDEwNA==", "bodyText": "Nitpick! Meaningful names make the code more readable.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534344104", "createdAt": "2020-12-02T17:20:30Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 283}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM2MTg3NA==", "bodyText": "These are super verbose and used all over the place, I think I am going to keep them as f and b, as this matches what is in the hibernate search docs, but i will add javadocs indicating what they are", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534361874", "createdAt": "2020-12-02T17:46:24Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NDEwNA=="}, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 283}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjU3NjQ0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMTo1OFrOH9l19g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMTo1OFrOH9l19g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NTIwNg==", "bodyText": "Nitpick! If this isn't needed, can it be removed?", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534345206", "createdAt": "2020-12-02T17:21:58Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1188,37 +1294,55 @@ private void addLoincFilterAncestorIn(String theSystem, BooleanJunction<?> theBo\n \t}\n \n \t@SuppressWarnings(\"EnumSwitchStatementWhichMissesCases\")\n-\tprivate void handleFilterLoincDescendant(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n+\tprivate void handleFilterLoincDescendant(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n \t\tswitch (theFilter.getOp()) {\n \t\t\tcase EQUAL:\n-\t\t\t\taddLoincFilterDescendantEqual(theSystem, theBool, theFilter);\n+\t\t\t\taddLoincFilterDescendantEqual(theSystem, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase IN:\n-\t\t\t\taddLoincFilterDescendantIn(theSystem, theBool, theFilter);\n+\t\t\t\taddLoincFilterDescendantIn(theSystem, f,b , theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n \t\t\t\tthrow new InvalidRequestException(\"Don't know how to handle op=\" + theFilter.getOp() + \" on property \" + theFilter.getProperty());\n \t\t}\n \t}\n \n-\tprivate void addLoincFilterDescendantEqual(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\taddLoincFilterDescendantEqual(theSystem, theBool, theFilter.getProperty(), theFilter.getValue());\n-\t}\n \n-\tprivate void addLoincFilterDescendantEqual(String theSystem, BooleanJunction<?> theBool, String theProperty, String theValue) {\n-\t\tList<Term> terms = getDescendantTerms(theSystem, theProperty, theValue);\n-\t\ttheBool.must(new TermsQuery(terms));\n+\tprivate void addLoincFilterDescendantEqual(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\taddLoincFilterDescendantEqual(theSystem, f, b, theFilter.getProperty(), theFilter.getValue());\n \t}\n \n-\tprivate void addLoincFilterDescendantIn(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n+\tprivate void addLoincFilterDescendantIn(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n \t\tString[] values = theFilter.getValue().split(\",\");\n \t\tList<Term> terms = new ArrayList<>();\n \t\tfor (String value : values) {\n \t\t\tterms.addAll(getDescendantTerms(theSystem, theFilter.getProperty(), value));\n \t\t}\n-\t\ttheBool.must(new TermsQuery(terms));\n+\t\tsearchByParentPids(f, b, terms);\n+\t}\n+\n+\tprivate void addLoincFilterDescendantEqual(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, String theProperty, String theValue) {\n+\t\tList<Term> terms = getDescendantTerms(theSystem, theProperty, theValue);\n+\t\tsearchByParentPids(f, b, terms);\n \t}\n \n+\tprivate void searchByParentPids(SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, List<Term> theTerms) {\n+\t\tList<Long> parentPids = convertTermsToParentPids(theTerms);\n+\t\tb.must(f.bool(innerB -> {\n+\t\t\tparentPids.forEach(pid -> innerB.should(f.match().field(theTerms.get(0).field()).matching(pid)));\n+\t\t}));\n+\n+//\t\tparentPids.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 604}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1MjU3OTM3OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMjo0MVrOH9l38w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMjo0MVrOH9l38w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NTcxNQ==", "bodyText": "Lots of TODOs in this file. Let me know if/when it needs another review. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534345715", "createdAt": "2020-12-02T17:22:41Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.REGEX) {\n+\n+\t\t\t/*\n+\t\t\t * We treat the regex filter as a match on the regex\n+\t\t\t * anywhere in the property string. The spec does not\n+\t\t\t * say whether or not this is the right behaviour, but\n+\t\t\t * there are examples that seem to suggest that it is.\n+\t\t\t */\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tif (value.endsWith(\"$\")) {\n+\t\t\t\tvalue = value.substring(0, value.length() - 1);\n+\t\t\t} else if (!value.endsWith(\".*\")) {\n+\t\t\t\tvalue = value + \".*\";\n+\t\t\t}\n+\t\t\tif (!value.startsWith(\"^\") && !value.startsWith(\".*\")) {\n+\t\t\t\tvalue = \".*\" + value;\n+\t\t\t} else if (value.startsWith(\"^\")) {\n+\t\t\t\tvalue = value.substring(1);\n+\t\t\t}\n+\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\tRegexpQuery query = new RegexpQuery(term);\n+\t\t\t//TODO GGG HS write the equivalent ES Query here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 306}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1736, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}