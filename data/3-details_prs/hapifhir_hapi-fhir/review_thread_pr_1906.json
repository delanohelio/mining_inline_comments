{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxNDYwOTIz", "number": 1906, "reviewThreads": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxOTo0MzoyOFrOEEB0wA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo0NTozMlrOEEDDbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjU5NjQ4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/api/IBatchJobSubmitter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxOTo0MzoyOFrOGhZjmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1NTowOVrOGhfIxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NDkwNQ==", "bodyText": "Javadoc on interfaces", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437674905", "createdAt": "2020-06-09T19:43:28Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/api/IBatchJobSubmitter.java", "diffHunk": "@@ -0,0 +1,11 @@\n+package ca.uhn.fhir.jpa.batch.api;\n+\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+\n+public interface IBatchJobSubmitter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1d2ab7619e86d84952b69bb0ff16e6af1b6513c"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjM0MA==", "bodyText": "\ud83d\udc4d", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437766340", "createdAt": "2020-06-09T22:55:09Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/api/IBatchJobSubmitter.java", "diffHunk": "@@ -0,0 +1,11 @@\n+package ca.uhn.fhir.jpa.batch.api;\n+\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+\n+public interface IBatchJobSubmitter {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NDkwNQ=="}, "originalCommit": {"oid": "b1d2ab7619e86d84952b69bb0ff16e6af1b6513c"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjYwNzM0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/config/InMemoryJobRepositoryBatchConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQxOTo0Njo1M1rOGhZqow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoxMToyOVrOGhfecQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NjcwNw==", "bodyText": "This claims to be a Spring Config but doesn't contain any beans?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437676707", "createdAt": "2020-06-09T19:46:53Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/config/InMemoryJobRepositoryBatchConfig.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package ca.uhn.fhir.jpa.batch.config;\n+\n+import org.springframework.batch.core.configuration.annotation.BatchConfigurer;\n+import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.explore.JobExplorer;\n+import org.springframework.batch.core.explore.support.MapJobExplorerFactoryBean;\n+import org.springframework.batch.core.launch.JobLauncher;\n+import org.springframework.batch.core.launch.support.SimpleJobLauncher;\n+import org.springframework.batch.core.repository.JobRepository;\n+import org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean;\n+import org.springframework.batch.support.transaction.ResourcelessTransactionManager;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.transaction.PlatformTransactionManager;\n+\n+import javax.annotation.PostConstruct;\n+\n+@Configuration", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1d2ab7619e86d84952b69bb0ff16e6af1b6513c"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTg4OQ==", "bodyText": "@EnableBatchProcessing does, and the @configuration is required on it.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437771889", "createdAt": "2020-06-09T23:11:29Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/config/InMemoryJobRepositoryBatchConfig.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package ca.uhn.fhir.jpa.batch.config;\n+\n+import org.springframework.batch.core.configuration.annotation.BatchConfigurer;\n+import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.explore.JobExplorer;\n+import org.springframework.batch.core.explore.support.MapJobExplorerFactoryBean;\n+import org.springframework.batch.core.launch.JobLauncher;\n+import org.springframework.batch.core.launch.support.SimpleJobLauncher;\n+import org.springframework.batch.core.repository.JobRepository;\n+import org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean;\n+import org.springframework.batch.support.transaction.ResourcelessTransactionManager;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.transaction.PlatformTransactionManager;\n+\n+import javax.annotation.PostConstruct;\n+\n+@Configuration", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NjcwNw=="}, "originalCommit": {"oid": "b1d2ab7619e86d84952b69bb0ff16e6af1b6513c"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY1MTE5OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowMDowOVrOGhaGQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjoxMToyNFrOGheNAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4Mzc3OA==", "bodyText": "move to common?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437683778", "createdAt": "2020-06-09T20:00:09Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1MTA0MQ==", "bodyText": "This is specifically for bulk export, so I don't think it should live in common", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437751041", "createdAt": "2020-06-09T22:11:24Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4Mzc3OA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY1MjAwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowMDoyMlrOGhaGxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzoyODo1NFrOGhfz4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4MzkwOQ==", "bodyText": "rename", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437683909", "createdAt": "2020-06-09T20:00:22Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NzM3Nw==", "bodyText": "done", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437777377", "createdAt": "2020-06-09T23:28:54Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4MzkwOQ=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY1MjgwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowMDo0MFrOGhaHTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo1MDo1N1rOGhb0Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDA0NA==", "bodyText": "move to common?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437684044", "createdAt": "2020-06-09T20:00:40Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {\n+\t\treturn myStepBuilderFactory.get(\"partitionStep\")\n+\t\t\t.partitioner(\"bulkExportGenerateResourceFilesStep\", partitioner(null))\n+\t\t\t.step(bulkExportGenerateResourceFilesStep())\n+\t\t\t.taskExecutor(myTaskExecutor)\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic BulkItemReader bulkItemReader(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\tBulkItemReader bulkItemReader = new BulkItemReader();\n+\t\tbulkItemReader.setJobUUID(theJobUUID);\n+\t\treturn bulkItemReader;\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic ResourceTypePartitioner partitioner(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcxMTk3MA==", "bodyText": "It isn't really common, since this step actually comes a BulkExportEntity job UUID, it isn't really reusable. Maybe It's possible to refactor such that it doesn't need it directly though", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437711970", "createdAt": "2020-06-09T20:50:57Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {\n+\t\treturn myStepBuilderFactory.get(\"partitionStep\")\n+\t\t\t.partitioner(\"bulkExportGenerateResourceFilesStep\", partitioner(null))\n+\t\t\t.step(bulkExportGenerateResourceFilesStep())\n+\t\t\t.taskExecutor(myTaskExecutor)\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic BulkItemReader bulkItemReader(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\tBulkItemReader bulkItemReader = new BulkItemReader();\n+\t\tbulkItemReader.setJobUUID(theJobUUID);\n+\t\treturn bulkItemReader;\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic ResourceTypePartitioner partitioner(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDA0NA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY1NTAxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowMToxNlrOGhaIrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjoxMTo0NVrOGheNhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDM5OQ==", "bodyText": "move to common?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437684399", "createdAt": "2020-06-09T20:01:16Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {\n+\t\treturn myStepBuilderFactory.get(\"partitionStep\")\n+\t\t\t.partitioner(\"bulkExportGenerateResourceFilesStep\", partitioner(null))\n+\t\t\t.step(bulkExportGenerateResourceFilesStep())\n+\t\t\t.taskExecutor(myTaskExecutor)\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic BulkItemReader bulkItemReader(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\tBulkItemReader bulkItemReader = new BulkItemReader();\n+\t\tbulkItemReader.setJobUUID(theJobUUID);\n+\t\treturn bulkItemReader;\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic ResourceTypePartitioner partitioner(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\treturn new ResourceTypePartitioner(theJobUUID);\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic ItemWriter<List<IBaseResource>> resourceToFileWriter() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1MTE3Mg==", "bodyText": "Also relies on specific bulk export stuff", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437751172", "createdAt": "2020-06-09T22:11:45Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobConfig.java", "diffHunk": "@@ -0,0 +1,101 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.batch.processors.PidToIBaseResourceProcessor;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.JobScope;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.core.task.TaskExecutor;\n+\n+import java.util.List;\n+\n+/**\n+ * Spring batch Job configuration file. Contains all necessary plumbing to run a\n+ * Bulk Export job.\n+ */\n+@Configuration\n+public class BulkExportJobConfig {\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate PidToIBaseResourceProcessor myPidToIBaseResourceProcessor;\n+\n+\t@Autowired\n+\tprivate TaskExecutor myTaskExecutor;\n+\n+\t@Bean\n+\tpublic Job bulkExportJob() {\n+\t\treturn myJobBuilderFactory.get(\"bulkExportJob\")\n+\t\t\t.validator(jobExistsValidator())\n+\t\t\t.start(partitionStep())\n+\t\t\t.listener(bulkExportJobCompletionListener())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\tpublic JobParametersValidator jobExistsValidator() {\n+\t\treturn new JobExistsParameterValidator();\n+\t}\n+\n+\n+\t@Bean\n+\tpublic Step bulkExportGenerateResourceFilesStep() {\n+\t\treturn myStepBuilderFactory.get(\"bulkExportGenerateResourceFilesStep\")\n+\t\t\t.<List<ResourcePersistentId>, List<IBaseResource>> chunk(100) //1000 resources per generated file, as the reader returns 10 resources at a time.\n+\t\t\t.reader(bulkItemReader(null))\n+\t\t\t.processor(myPidToIBaseResourceProcessor)\n+\t\t\t.writer(resourceToFileWriter())\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic BulkExportJobStatusChangeListener bulkExportJobCompletionListener() {\n+\t\treturn new BulkExportJobStatusChangeListener();\n+\t}\n+\n+\t@Bean\n+\tpublic Step partitionStep() {\n+\t\treturn myStepBuilderFactory.get(\"partitionStep\")\n+\t\t\t.partitioner(\"bulkExportGenerateResourceFilesStep\", partitioner(null))\n+\t\t\t.step(bulkExportGenerateResourceFilesStep())\n+\t\t\t.taskExecutor(myTaskExecutor)\n+\t\t\t.build();\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic BulkItemReader bulkItemReader(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\tBulkItemReader bulkItemReader = new BulkItemReader();\n+\t\tbulkItemReader.setJobUUID(theJobUUID);\n+\t\treturn bulkItemReader;\n+\t}\n+\n+\t@Bean\n+\t@JobScope\n+\tpublic ResourceTypePartitioner partitioner(@Value(\"#{jobParameters['jobUUID']}\") String theJobUUID) {\n+\t\treturn new ResourceTypePartitioner(theJobUUID);\n+\t}\n+\n+\t@Bean\n+\t@StepScope\n+\tpublic ItemWriter<List<IBaseResource>> resourceToFileWriter() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDM5OQ=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY1OTg3OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobStatusChangeListener.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowMjo0NVrOGhaLrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo0NToyMVrOGhe8AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NTE2NA==", "bodyText": "Won't it just keep failing endlessly?  I wonder if failed jobs should move to an error state with maybe a way to retry them?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437685164", "createdAt": "2020-06-09T20:02:45Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobStatusChangeListener.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import org.springframework.batch.core.BatchStatus;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobExecutionListener;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+/**\n+ * Will run before and after a job to set the status to whatever is appropriate.\n+ */\n+public class BulkExportJobStatusChangeListener implements JobExecutionListener {\n+\n+\t@Value(\"#{jobParameters['jobUUID']}\")\n+\tprivate String myJobUUID;\n+\n+\t@Autowired\n+\tprivate BulkExportDaoSvc myBulkExportDaoSvc;\n+\n+\t@Override\n+\tpublic void beforeJob(JobExecution theJobExecution) {\n+\t\tif (theJobExecution.getStatus() == BatchStatus.STARTING) {\n+\t\t\tmyBulkExportDaoSvc.setJobToStatus(myJobUUID, BulkJobStatusEnum.BUILDING);\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void afterJob(JobExecution theJobExecution) {\n+\t\tif (theJobExecution.getStatus() == BatchStatus.COMPLETED) {\n+\t\t\tmyBulkExportDaoSvc.setJobToStatus(myJobUUID, BulkJobStatusEnum.COMPLETE);\n+\t\t} else {\n+\t\t\t//If the job didn't complete successfully, just set it back to submitted so that it gets picked up again by the scheduler.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MzA3Mg==", "bodyText": "Good point, I've changed this to set it to ERROR state instead. It's probably worth looking into a restart policy. James said for now it's fine to just fail out of it with an error state.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437763072", "createdAt": "2020-06-09T22:45:21Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkExportJobStatusChangeListener.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import org.springframework.batch.core.BatchStatus;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobExecutionListener;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+/**\n+ * Will run before and after a job to set the status to whatever is appropriate.\n+ */\n+public class BulkExportJobStatusChangeListener implements JobExecutionListener {\n+\n+\t@Value(\"#{jobParameters['jobUUID']}\")\n+\tprivate String myJobUUID;\n+\n+\t@Autowired\n+\tprivate BulkExportDaoSvc myBulkExportDaoSvc;\n+\n+\t@Override\n+\tpublic void beforeJob(JobExecution theJobExecution) {\n+\t\tif (theJobExecution.getStatus() == BatchStatus.STARTING) {\n+\t\t\tmyBulkExportDaoSvc.setJobToStatus(myJobUUID, BulkJobStatusEnum.BUILDING);\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void afterJob(JobExecution theJobExecution) {\n+\t\tif (theJobExecution.getStatus() == BatchStatus.COMPLETED) {\n+\t\t\tmyBulkExportDaoSvc.setJobToStatus(myJobUUID, BulkJobStatusEnum.COMPLETE);\n+\t\t} else {\n+\t\t\t//If the job didn't complete successfully, just set it back to submitted so that it gets picked up again by the scheduler.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NTE2NA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY2NDE2OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowNDoyMFrOGhaOjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjoxMjoxNlrOGheOPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NTkwMQ==", "bodyText": "should this be configurable?  (e.g. one of the job params...?)", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437685901", "createdAt": "2020-06-09T20:04:20Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "diffHunk": "@@ -0,0 +1,106 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.interceptor.model.RequestPartitionId;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.dao.IResultIterator;\n+import ca.uhn.fhir.jpa.dao.ISearchBuilder;\n+import ca.uhn.fhir.jpa.dao.SearchBuilderFactory;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import ca.uhn.fhir.jpa.model.search.SearchRuntimeDetails;\n+import ca.uhn.fhir.jpa.searchparam.SearchParameterMap;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import ca.uhn.fhir.rest.param.DateRangeParam;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.NonTransientResourceException;\n+import org.springframework.batch.item.ParseException;\n+import org.springframework.batch.item.UnexpectedInputException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+\n+public class BulkItemReader implements ItemReader<List<ResourcePersistentId>> {\n+\tprivate static final Logger ourLog = LoggerFactory.getLogger(BulkItemReader.class);\n+\n+\tprivate static final int READ_CHUNK_SIZE = 10;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1MTM1Nw==", "bodyText": "Yeah makes sense for it to be. I just copied what was hardcoded in the original implementation.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437751357", "createdAt": "2020-06-09T22:12:16Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "diffHunk": "@@ -0,0 +1,106 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.interceptor.model.RequestPartitionId;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.dao.IResultIterator;\n+import ca.uhn.fhir.jpa.dao.ISearchBuilder;\n+import ca.uhn.fhir.jpa.dao.SearchBuilderFactory;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import ca.uhn.fhir.jpa.model.search.SearchRuntimeDetails;\n+import ca.uhn.fhir.jpa.searchparam.SearchParameterMap;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import ca.uhn.fhir.rest.param.DateRangeParam;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.NonTransientResourceException;\n+import org.springframework.batch.item.ParseException;\n+import org.springframework.batch.item.UnexpectedInputException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+\n+public class BulkItemReader implements ItemReader<List<ResourcePersistentId>> {\n+\tprivate static final Logger ourLog = LoggerFactory.getLogger(BulkItemReader.class);\n+\n+\tprivate static final int READ_CHUNK_SIZE = 10;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NTkwMQ=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY2Njc4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowNTowOVrOGhaQRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowNTowOVrOGhaQRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NjM0MA==", "bodyText": "warn", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437686340", "createdAt": "2020-06-09T20:05:09Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "diffHunk": "@@ -0,0 +1,106 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.interceptor.model.RequestPartitionId;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.dao.IResultIterator;\n+import ca.uhn.fhir.jpa.dao.ISearchBuilder;\n+import ca.uhn.fhir.jpa.dao.SearchBuilderFactory;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import ca.uhn.fhir.jpa.model.search.SearchRuntimeDetails;\n+import ca.uhn.fhir.jpa.searchparam.SearchParameterMap;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import ca.uhn.fhir.rest.param.DateRangeParam;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.NonTransientResourceException;\n+import org.springframework.batch.item.ParseException;\n+import org.springframework.batch.item.UnexpectedInputException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+\n+public class BulkItemReader implements ItemReader<List<ResourcePersistentId>> {\n+\tprivate static final Logger ourLog = LoggerFactory.getLogger(BulkItemReader.class);\n+\n+\tprivate static final int READ_CHUNK_SIZE = 10;\n+\n+\t@Autowired\n+\tprivate IBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tprivate DaoRegistry myDaoRegistry;\n+\n+\t@Autowired\n+\tprivate FhirContext myContext;\n+\n+\t@Autowired\n+\tprivate SearchBuilderFactory mySearchBuilderFactory;\n+\n+\tprivate BulkExportJobEntity myJobEntity;\n+\n+\tprivate String myJobUUID;\n+\n+\t@Value(\"#{stepExecutionContext['resourceType']}\")\n+\tprivate String myResourceType;\n+\n+\tIterator<ResourcePersistentId> myPidIterator;\n+\n+\tprivate void loadResourcePids() {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(myJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY3MDgwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDowNjozMlrOGhaS-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMjo1MjozMlrOGhfFUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NzAzMw==", "bodyText": "feels like we'll probably want a separate logger for batch jobs so they don't get swamped by fhir request logs", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437687033", "createdAt": "2020-06-09T20:06:32Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "diffHunk": "@@ -0,0 +1,106 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.interceptor.model.RequestPartitionId;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.dao.IResultIterator;\n+import ca.uhn.fhir.jpa.dao.ISearchBuilder;\n+import ca.uhn.fhir.jpa.dao.SearchBuilderFactory;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import ca.uhn.fhir.jpa.model.search.SearchRuntimeDetails;\n+import ca.uhn.fhir.jpa.searchparam.SearchParameterMap;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import ca.uhn.fhir.rest.param.DateRangeParam;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.NonTransientResourceException;\n+import org.springframework.batch.item.ParseException;\n+import org.springframework.batch.item.UnexpectedInputException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+\n+public class BulkItemReader implements ItemReader<List<ResourcePersistentId>> {\n+\tprivate static final Logger ourLog = LoggerFactory.getLogger(BulkItemReader.class);\n+\n+\tprivate static final int READ_CHUNK_SIZE = 10;\n+\n+\t@Autowired\n+\tprivate IBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tprivate DaoRegistry myDaoRegistry;\n+\n+\t@Autowired\n+\tprivate FhirContext myContext;\n+\n+\t@Autowired\n+\tprivate SearchBuilderFactory mySearchBuilderFactory;\n+\n+\tprivate BulkExportJobEntity myJobEntity;\n+\n+\tprivate String myJobUUID;\n+\n+\t@Value(\"#{stepExecutionContext['resourceType']}\")\n+\tprivate String myResourceType;\n+\n+\tIterator<ResourcePersistentId> myPidIterator;\n+\n+\tprivate void loadResourcePids() {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(myJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");\n+\t\t\treturn;\n+\t\t}\n+\t\tmyJobEntity = jobOpt.get();\n+\t\tourLog.info(\"Bulk export starting generation for batch export job: {}\", myJobEntity);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NTQ1OQ==", "bodyText": "Good call. I've duplicated the work done in EMPI for batch", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437765459", "createdAt": "2020-06-09T22:52:32Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/BulkItemReader.java", "diffHunk": "@@ -0,0 +1,106 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.interceptor.model.RequestPartitionId;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.dao.IResultIterator;\n+import ca.uhn.fhir.jpa.dao.ISearchBuilder;\n+import ca.uhn.fhir.jpa.dao.SearchBuilderFactory;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import ca.uhn.fhir.jpa.model.search.SearchRuntimeDetails;\n+import ca.uhn.fhir.jpa.searchparam.SearchParameterMap;\n+import ca.uhn.fhir.rest.api.server.storage.ResourcePersistentId;\n+import ca.uhn.fhir.rest.param.DateRangeParam;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.NonTransientResourceException;\n+import org.springframework.batch.item.ParseException;\n+import org.springframework.batch.item.UnexpectedInputException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+\n+public class BulkItemReader implements ItemReader<List<ResourcePersistentId>> {\n+\tprivate static final Logger ourLog = LoggerFactory.getLogger(BulkItemReader.class);\n+\n+\tprivate static final int READ_CHUNK_SIZE = 10;\n+\n+\t@Autowired\n+\tprivate IBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tprivate DaoRegistry myDaoRegistry;\n+\n+\t@Autowired\n+\tprivate FhirContext myContext;\n+\n+\t@Autowired\n+\tprivate SearchBuilderFactory mySearchBuilderFactory;\n+\n+\tprivate BulkExportJobEntity myJobEntity;\n+\n+\tprivate String myJobUUID;\n+\n+\t@Value(\"#{stepExecutionContext['resourceType']}\")\n+\tprivate String myResourceType;\n+\n+\tIterator<ResourcePersistentId> myPidIterator;\n+\n+\tprivate void loadResourcePids() {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(myJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");\n+\t\t\treturn;\n+\t\t}\n+\t\tmyJobEntity = jobOpt.get();\n+\t\tourLog.info(\"Bulk export starting generation for batch export job: {}\", myJobEntity);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NzAzMw=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY4MjM2OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/JobExistsParameterValidator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMDoxMFrOGhaaVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMDoxMFrOGhaaVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4ODkxOA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * This class will prevent job running if the UUID is found to be non-existent, or invalid.\n          \n          \n            \n             * This class will prevent a job from running if the UUID does not exist or is invalid.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437688918", "createdAt": "2020-06-09T20:10:10Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/JobExistsParameterValidator.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import java.util.Optional;\n+\n+/**\n+ * This class will prevent job running if the UUID is found to be non-existent, or invalid.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY4NjA4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/JobExistsParameterValidator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMToyNVrOGhacyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMToyNVrOGhacyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4OTU0Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tthrow new JobParametersInvalidException(\"You did not pass a jobUUID to this job!\");\n          \n          \n            \n            \t\t\tthrow new JobParametersInvalidException(\"Missing jobUUID job parameter\");", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437689546", "createdAt": "2020-06-09T20:11:25Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/JobExistsParameterValidator.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.JobParametersValidator;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import java.util.Optional;\n+\n+/**\n+ * This class will prevent job running if the UUID is found to be non-existent, or invalid.\n+ */\n+public class JobExistsParameterValidator implements JobParametersValidator {\n+\t@Autowired\n+\tprivate IBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Override\n+\tpublic void validate(JobParameters theJobParameters) throws JobParametersInvalidException {\n+\t\tString jobUUID = theJobParameters.getString(\"jobUUID\");\n+\t\tif (StringUtils.isBlank(jobUUID)) {\n+\t\t\tthrow new JobParametersInvalidException(\"You did not pass a jobUUID to this job!\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY4OTMyOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMjoyOVrOGhae6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxMjoyOVrOGhae6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MDA5MA==", "bodyText": "I like the way the steps are separated out by Spring Batch.  Feels like it cleans up and organizes our batch jobs--plus provides for better re-use", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437690090", "createdAt": "2020-06-09T20:12:29Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "diffHunk": "@@ -0,0 +1,103 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.parser.IParser;\n+import ca.uhn.fhir.rest.api.Constants;\n+import ca.uhn.fhir.util.BinaryUtil;\n+import org.hl7.fhir.instance.model.api.IBaseBinary;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.hl7.fhir.instance.model.api.IIdType;\n+import org.slf4j.Logger;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import javax.annotation.PostConstruct;\n+import java.io.ByteArrayOutputStream;\n+import java.io.OutputStreamWriter;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class ResourceToFileWriter implements ItemWriter<List<IBaseResource>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjY5NDcxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNDoxMVrOGhaiYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNDoxMVrOGhaiYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MDk3Ng==", "bodyText": "nitpick: there are so many contexts, I like to call these myFhirContext", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437690976", "createdAt": "2020-06-09T20:14:11Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "diffHunk": "@@ -0,0 +1,103 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.parser.IParser;\n+import ca.uhn.fhir.rest.api.Constants;\n+import ca.uhn.fhir.util.BinaryUtil;\n+import org.hl7.fhir.instance.model.api.IBaseBinary;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.hl7.fhir.instance.model.api.IIdType;\n+import org.slf4j.Logger;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import javax.annotation.PostConstruct;\n+import java.io.ByteArrayOutputStream;\n+import java.io.OutputStreamWriter;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class ResourceToFileWriter implements ItemWriter<List<IBaseResource>> {\n+\tprivate static final Logger ourLog = getLogger(ResourceToFileWriter.class);\n+\n+\t@Autowired\n+\tprivate FhirContext myContext;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcwNTUxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNzoxOVrOGhao-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxNzoxOVrOGhao-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MjY2Nw==", "bodyText": "nitpick: simple if statements are more approachable to junior developers", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437692667", "createdAt": "2020-06-09T20:17:19Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceToFileWriter.java", "diffHunk": "@@ -0,0 +1,103 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.context.FhirContext;\n+import ca.uhn.fhir.jpa.api.dao.DaoRegistry;\n+import ca.uhn.fhir.jpa.api.dao.IFhirResourceDao;\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.parser.IParser;\n+import ca.uhn.fhir.rest.api.Constants;\n+import ca.uhn.fhir.util.BinaryUtil;\n+import org.hl7.fhir.instance.model.api.IBaseBinary;\n+import org.hl7.fhir.instance.model.api.IBaseResource;\n+import org.hl7.fhir.instance.model.api.IIdType;\n+import org.slf4j.Logger;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.beans.factory.annotation.Value;\n+\n+import javax.annotation.PostConstruct;\n+import java.io.ByteArrayOutputStream;\n+import java.io.OutputStreamWriter;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class ResourceToFileWriter implements ItemWriter<List<IBaseResource>> {\n+\tprivate static final Logger ourLog = getLogger(ResourceToFileWriter.class);\n+\n+\t@Autowired\n+\tprivate FhirContext myContext;\n+\n+\t@Autowired\n+\tprivate DaoRegistry myDaoRegistry;\n+\n+\t@Autowired\n+\tprivate BulkExportDaoSvc myBulkExportDaoSvc;\n+\n+\tprivate ByteArrayOutputStream myOutputStream;\n+\tprivate OutputStreamWriter myWriter;\n+\tprivate IParser myParser;\n+\n+\t@Value(\"#{stepExecutionContext['bulkExportCollectionEntityId']}\")\n+\tprivate Long myBulkExportCollectionEntityId;\n+\n+\tprivate IFhirResourceDao<IBaseBinary> myBinaryDao;\n+\n+\n+\tpublic ResourceToFileWriter() {\n+\t\tmyOutputStream = new ByteArrayOutputStream();\n+\t\tmyWriter = new OutputStreamWriter(myOutputStream, Constants.CHARSET_UTF8);\n+\t}\n+\n+\t@PostConstruct\n+\tpublic void start() {\n+\t\tmyParser = myContext.newJsonParser().setPrettyPrint(false);\n+\t\tmyBinaryDao = getBinaryDao();\n+\t}\n+\n+\tprivate Optional<IIdType> flushToFiles() {\n+\t\tif (myOutputStream.size() > 0) {\n+\t\t\tIIdType createdId = createBinaryFromOutputStream();\n+\t\t\tBulkExportCollectionFileEntity file = new BulkExportCollectionFileEntity();\n+\t\t\tfile.setResource(createdId.getIdPart());\n+\n+\t\t\tmyBulkExportDaoSvc.addFileToCollectionWithId(myBulkExportCollectionEntityId, file);\n+\n+\t\t\tmyOutputStream.reset();\n+\n+\t\t\treturn Optional.of(createdId);\n+\t\t}\n+\n+\t\treturn Optional.empty();\n+\t}\n+\n+\tprivate IIdType createBinaryFromOutputStream() {\n+\t\tIBaseBinary binary = BinaryUtil.newBinary(myContext);\n+\t\tbinary.setContentType(Constants.CT_FHIR_NDJSON);\n+\t\tbinary.setContent(myOutputStream.toByteArray());\n+\n+\t\treturn myBinaryDao.create(binary).getResource().getIdElement();\n+\t}\n+\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate IFhirResourceDao<IBaseBinary> getBinaryDao() {\n+\t\treturn myDaoRegistry.getResourceDao(\"Binary\");\n+\t}\n+\n+\t@Override\n+\tpublic void write(List<? extends List<IBaseResource>> theList) throws Exception {\n+\n+\t\tfor (List<IBaseResource> resourceList : theList) {\n+\t\t\tfor (IBaseResource nextFileResource : resourceList) {\n+\t\t\t\tmyParser.encodeResourceToWriter(nextFileResource, myWriter);\n+\t\t\t\tmyWriter.append(\"\\n\");\n+\t\t\t}\n+\t\t}\n+\n+\t\tOptional<IIdType> createdId = flushToFiles();\n+\t\tcreatedId.ifPresent(theIIdType -> ourLog.warn(\"Created resources for bulk export file containing {} resources of type \", theIIdType.toUnqualifiedVersionless().getValue()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcwODA0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceTypePartitioner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxODowN1rOGhaqjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxODowN1rOGhaqjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MzA3MQ==", "bodyText": "commented out code", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437693071", "createdAt": "2020-06-09T20:18:07Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceTypePartitioner.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import org.slf4j.Logger;\n+import org.springframework.batch.core.partition.support.Partitioner;\n+import org.springframework.batch.item.ExecutionContext;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class ResourceTypePartitioner implements Partitioner {\n+\tprivate static final Logger ourLog = getLogger(ResourceTypePartitioner.class);\n+\n+\tprivate String myJobUUID;\n+\n+\t@Autowired\n+\tprivate BulkExportDaoSvc myBulkExportDaoSvc;\n+\n+\tpublic ResourceTypePartitioner(String theJobUUID) {\n+\t\tmyJobUUID = theJobUUID;\n+\t}\n+\n+\t@Override\n+\tpublic Map<String, ExecutionContext> partition(int gridSize) {\n+\t\tMap<String, ExecutionContext> partitionContextMap = new HashMap<>();\n+\n+\t\tMap<Long, String> idToResourceType = myBulkExportDaoSvc.getBulkJobCollectionIdToResourceTypeMap(\tmyJobUUID);\n+\t\t//observation -> obs1.json, obs2.json, obs3.json BulkJobCollectionEntity", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcxMTEyOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceTypePartitioner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxOToxM1rOGhaskg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoxOToxM1rOGhaskg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MzU4Ng==", "bodyText": "nitpick: replace large block with method reference", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437693586", "createdAt": "2020-06-09T20:19:13Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/job/ResourceTypePartitioner.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package ca.uhn.fhir.jpa.bulk.job;\n+\n+import ca.uhn.fhir.jpa.bulk.svc.BulkExportDaoSvc;\n+import org.slf4j.Logger;\n+import org.springframework.batch.core.partition.support.Partitioner;\n+import org.springframework.batch.item.ExecutionContext;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class ResourceTypePartitioner implements Partitioner {\n+\tprivate static final Logger ourLog = getLogger(ResourceTypePartitioner.class);\n+\n+\tprivate String myJobUUID;\n+\n+\t@Autowired\n+\tprivate BulkExportDaoSvc myBulkExportDaoSvc;\n+\n+\tpublic ResourceTypePartitioner(String theJobUUID) {\n+\t\tmyJobUUID = theJobUUID;\n+\t}\n+\n+\t@Override\n+\tpublic Map<String, ExecutionContext> partition(int gridSize) {\n+\t\tMap<String, ExecutionContext> partitionContextMap = new HashMap<>();\n+\n+\t\tMap<Long, String> idToResourceType = myBulkExportDaoSvc.getBulkJobCollectionIdToResourceTypeMap(\tmyJobUUID);\n+\t\t//observation -> obs1.json, obs2.json, obs3.json BulkJobCollectionEntity\n+\t\t//bulk Collection Entity ID -> patient\n+\n+\t\t// 123123-> Patient\n+\t\t// 91876389126-> Observation\n+\t\tidToResourceType.entrySet().stream()\n+\t\t\t.forEach(entry -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcxNjczOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkDataExportSvcImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyMDo0NlrOGhav5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyMDo0NlrOGhav5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NDQzNw==", "bodyText": "nice to see this class shrink in size!  :-)", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437694437", "createdAt": "2020-06-09T20:20:46Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkDataExportSvcImpl.java", "diffHunk": "@@ -429,7 +320,7 @@ private void updateExpiry(BulkExportJobEntity theJob) {\n \n \t@Transactional\n \t@Override\n-\tpublic JobInfo getJobStatusOrThrowResourceNotFound(String theJobId) {\n+\tpublic JobInfo getJobInfoOrThrowResourceNotFound(String theJobId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 233}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcyMjI0OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyMjoxMFrOGhazEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyMjoyMlrOGhazZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTI1MA==", "bodyText": "warn", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437695250", "createdAt": "2020-06-09T20:22:10Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package ca.uhn.fhir.jpa.bulk.svc;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionFileDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.slf4j.Logger;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Service;\n+\n+import javax.transaction.Transactional;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+@Service\n+public class BulkExportDaoSvc {\n+\tprivate static final Logger ourLog = getLogger(BulkExportDaoSvc.class);\n+\n+\t@Autowired\n+\tIBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionDao myBulkExportCollectionDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n+\n+\t@Transactional\n+\tpublic void addFileToCollectionWithId(Long theCollectionEntityId, BulkExportCollectionFileEntity theFile) {\n+\t\tOptional<BulkExportCollectionEntity> byId = myBulkExportCollectionDao.findById(theCollectionEntityId);\n+\t\tif (byId.isPresent()) {\n+\t\t\tBulkExportCollectionEntity exportCollectionEntity = byId.get();\n+\t\t\ttheFile.setCollection(exportCollectionEntity);;\n+\t\t\tmyBulkExportCollectionFileDao.saveAndFlush(theFile);\n+\t\t\tmyBulkExportCollectionDao.saveAndFlush(exportCollectionEntity);\n+\t\t}\n+\n+\t}\n+\n+\t@Transactional\n+\tpublic Map<Long, String> getBulkJobCollectionIdToResourceTypeMap(String theJobUUID) {\n+\t\tBulkExportJobEntity bulkExportJobEntity = loadJob(theJobUUID);\n+\t\tCollection<BulkExportCollectionEntity> collections = bulkExportJobEntity.getCollections();\n+\t\treturn collections.stream()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tBulkExportCollectionEntity::getId,\n+\t\t\t\tBulkExportCollectionEntity::getResourceType\n+\t\t\t));\n+\t}\n+\n+\tprivate BulkExportJobEntity loadJob(String theJobUUID) {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTMzNQ==", "bodyText": "and name the uuid", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437695335", "createdAt": "2020-06-09T20:22:22Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package ca.uhn.fhir.jpa.bulk.svc;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionFileDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.slf4j.Logger;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Service;\n+\n+import javax.transaction.Transactional;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+@Service\n+public class BulkExportDaoSvc {\n+\tprivate static final Logger ourLog = getLogger(BulkExportDaoSvc.class);\n+\n+\t@Autowired\n+\tIBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionDao myBulkExportCollectionDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n+\n+\t@Transactional\n+\tpublic void addFileToCollectionWithId(Long theCollectionEntityId, BulkExportCollectionFileEntity theFile) {\n+\t\tOptional<BulkExportCollectionEntity> byId = myBulkExportCollectionDao.findById(theCollectionEntityId);\n+\t\tif (byId.isPresent()) {\n+\t\t\tBulkExportCollectionEntity exportCollectionEntity = byId.get();\n+\t\t\ttheFile.setCollection(exportCollectionEntity);;\n+\t\t\tmyBulkExportCollectionFileDao.saveAndFlush(theFile);\n+\t\t\tmyBulkExportCollectionDao.saveAndFlush(exportCollectionEntity);\n+\t\t}\n+\n+\t}\n+\n+\t@Transactional\n+\tpublic Map<Long, String> getBulkJobCollectionIdToResourceTypeMap(String theJobUUID) {\n+\t\tBulkExportJobEntity bulkExportJobEntity = loadJob(theJobUUID);\n+\t\tCollection<BulkExportCollectionEntity> collections = bulkExportJobEntity.getCollections();\n+\t\treturn collections.stream()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tBulkExportCollectionEntity::getId,\n+\t\t\t\tBulkExportCollectionEntity::getResourceType\n+\t\t\t));\n+\t}\n+\n+\tprivate BulkExportJobEntity loadJob(String theJobUUID) {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTI1MA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjcyMzg2OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyMjo0M1rOGha0IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNzo0NjowNVrOGh_4FA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTUyMA==", "bodyText": "warn and name it.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437695520", "createdAt": "2020-06-09T20:22:43Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package ca.uhn.fhir.jpa.bulk.svc;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionFileDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.slf4j.Logger;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Service;\n+\n+import javax.transaction.Transactional;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+@Service\n+public class BulkExportDaoSvc {\n+\tprivate static final Logger ourLog = getLogger(BulkExportDaoSvc.class);\n+\n+\t@Autowired\n+\tIBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionDao myBulkExportCollectionDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n+\n+\t@Transactional\n+\tpublic void addFileToCollectionWithId(Long theCollectionEntityId, BulkExportCollectionFileEntity theFile) {\n+\t\tOptional<BulkExportCollectionEntity> byId = myBulkExportCollectionDao.findById(theCollectionEntityId);\n+\t\tif (byId.isPresent()) {\n+\t\t\tBulkExportCollectionEntity exportCollectionEntity = byId.get();\n+\t\t\ttheFile.setCollection(exportCollectionEntity);;\n+\t\t\tmyBulkExportCollectionFileDao.saveAndFlush(theFile);\n+\t\t\tmyBulkExportCollectionDao.saveAndFlush(exportCollectionEntity);\n+\t\t}\n+\n+\t}\n+\n+\t@Transactional\n+\tpublic Map<Long, String> getBulkJobCollectionIdToResourceTypeMap(String theJobUUID) {\n+\t\tBulkExportJobEntity bulkExportJobEntity = loadJob(theJobUUID);\n+\t\tCollection<BulkExportCollectionEntity> collections = bulkExportJobEntity.getCollections();\n+\t\treturn collections.stream()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tBulkExportCollectionEntity::getId,\n+\t\t\t\tBulkExportCollectionEntity::getResourceType\n+\t\t\t));\n+\t}\n+\n+\tprivate BulkExportJobEntity loadJob(String theJobUUID) {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");\n+\t\t\treturn null;\n+\t\t}\n+\t\treturn jobOpt.get();\n+\t}\n+\n+\t@Transactional\n+\tpublic void setJobToStatus(String theJobUUID, BulkJobStatusEnum theStatus) {\n+\t\tOptional<BulkExportJobEntity> oJob = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!oJob.isPresent()) {\n+\t\t\tourLog.error(\"Job doesn't exist!\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NjE2NA==", "bodyText": "nitpick: I'd be inclined to return here and drop the else", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437696164", "createdAt": "2020-06-09T20:24:00Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package ca.uhn.fhir.jpa.bulk.svc;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionFileDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.slf4j.Logger;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Service;\n+\n+import javax.transaction.Transactional;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+@Service\n+public class BulkExportDaoSvc {\n+\tprivate static final Logger ourLog = getLogger(BulkExportDaoSvc.class);\n+\n+\t@Autowired\n+\tIBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionDao myBulkExportCollectionDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n+\n+\t@Transactional\n+\tpublic void addFileToCollectionWithId(Long theCollectionEntityId, BulkExportCollectionFileEntity theFile) {\n+\t\tOptional<BulkExportCollectionEntity> byId = myBulkExportCollectionDao.findById(theCollectionEntityId);\n+\t\tif (byId.isPresent()) {\n+\t\t\tBulkExportCollectionEntity exportCollectionEntity = byId.get();\n+\t\t\ttheFile.setCollection(exportCollectionEntity);;\n+\t\t\tmyBulkExportCollectionFileDao.saveAndFlush(theFile);\n+\t\t\tmyBulkExportCollectionDao.saveAndFlush(exportCollectionEntity);\n+\t\t}\n+\n+\t}\n+\n+\t@Transactional\n+\tpublic Map<Long, String> getBulkJobCollectionIdToResourceTypeMap(String theJobUUID) {\n+\t\tBulkExportJobEntity bulkExportJobEntity = loadJob(theJobUUID);\n+\t\tCollection<BulkExportCollectionEntity> collections = bulkExportJobEntity.getCollections();\n+\t\treturn collections.stream()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tBulkExportCollectionEntity::getId,\n+\t\t\t\tBulkExportCollectionEntity::getResourceType\n+\t\t\t));\n+\t}\n+\n+\tprivate BulkExportJobEntity loadJob(String theJobUUID) {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");\n+\t\t\treturn null;\n+\t\t}\n+\t\treturn jobOpt.get();\n+\t}\n+\n+\t@Transactional\n+\tpublic void setJobToStatus(String theJobUUID, BulkJobStatusEnum theStatus) {\n+\t\tOptional<BulkExportJobEntity> oJob = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!oJob.isPresent()) {\n+\t\t\tourLog.error(\"Job doesn't exist!\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTUyMA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMjc0MA==", "bodyText": "Done", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r438302740", "createdAt": "2020-06-10T17:46:05Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/bulk/svc/BulkExportDaoSvc.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package ca.uhn.fhir.jpa.bulk.svc;\n+\n+import ca.uhn.fhir.jpa.bulk.model.BulkJobStatusEnum;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportCollectionFileDao;\n+import ca.uhn.fhir.jpa.dao.data.IBulkExportJobDao;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportCollectionFileEntity;\n+import ca.uhn.fhir.jpa.entity.BulkExportJobEntity;\n+import org.slf4j.Logger;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Service;\n+\n+import javax.transaction.Transactional;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+@Service\n+public class BulkExportDaoSvc {\n+\tprivate static final Logger ourLog = getLogger(BulkExportDaoSvc.class);\n+\n+\t@Autowired\n+\tIBulkExportJobDao myBulkExportJobDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionDao myBulkExportCollectionDao;\n+\n+\t@Autowired\n+\tIBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n+\n+\t@Transactional\n+\tpublic void addFileToCollectionWithId(Long theCollectionEntityId, BulkExportCollectionFileEntity theFile) {\n+\t\tOptional<BulkExportCollectionEntity> byId = myBulkExportCollectionDao.findById(theCollectionEntityId);\n+\t\tif (byId.isPresent()) {\n+\t\t\tBulkExportCollectionEntity exportCollectionEntity = byId.get();\n+\t\t\ttheFile.setCollection(exportCollectionEntity);;\n+\t\t\tmyBulkExportCollectionFileDao.saveAndFlush(theFile);\n+\t\t\tmyBulkExportCollectionDao.saveAndFlush(exportCollectionEntity);\n+\t\t}\n+\n+\t}\n+\n+\t@Transactional\n+\tpublic Map<Long, String> getBulkJobCollectionIdToResourceTypeMap(String theJobUUID) {\n+\t\tBulkExportJobEntity bulkExportJobEntity = loadJob(theJobUUID);\n+\t\tCollection<BulkExportCollectionEntity> collections = bulkExportJobEntity.getCollections();\n+\t\treturn collections.stream()\n+\t\t\t.collect(Collectors.toMap(\n+\t\t\t\tBulkExportCollectionEntity::getId,\n+\t\t\t\tBulkExportCollectionEntity::getResourceType\n+\t\t\t));\n+\t}\n+\n+\tprivate BulkExportJobEntity loadJob(String theJobUUID) {\n+\t\tOptional<BulkExportJobEntity> jobOpt = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!jobOpt.isPresent()) {\n+\t\t\tourLog.info(\"Job appears to be deleted\");\n+\t\t\treturn null;\n+\t\t}\n+\t\treturn jobOpt.get();\n+\t}\n+\n+\t@Transactional\n+\tpublic void setJobToStatus(String theJobUUID, BulkJobStatusEnum theStatus) {\n+\t\tOptional<BulkExportJobEntity> oJob = myBulkExportJobDao.findByJobId(theJobUUID);\n+\t\tif (!oJob.isPresent()) {\n+\t\t\tourLog.error(\"Job doesn't exist!\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTUyMA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjczMjI4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/dao/data/IBulkExportCollectionDao.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyNTozMlrOGha5ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyNTozMlrOGha5ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5Njk1NA==", "bodyText": "commented code", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437696954", "createdAt": "2020-06-09T20:25:32Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/dao/data/IBulkExportCollectionDao.java", "diffHunk": "@@ -36,4 +36,6 @@\n \t@Query(\"DELETE FROM BulkExportCollectionEntity t WHERE t.myId = :pid\")\n \tvoid deleteByPid(@Param(\"pid\") Long theId);\n \n+//\t@Query(\"SELECT BulkExportCollectionEntity \")\n+//\tvoid findByJobId(Long theId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjczNTYzOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDoyNjozN1rOGha7zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMjozMDoxNFrOGhivYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzQ4NA==", "bodyText": "Would it make sense for us to subclass Job and autowire by type?  (Would save the @Qualifier)", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437697484", "createdAt": "2020-06-09T20:26:37Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -41,6 +52,12 @@\n \tprivate IBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n \t@Autowired\n \tprivate IBulkDataExportSvc myBulkDataExportSvc;\n+\t@Autowired\n+\tprivate IBatchJobSubmitter myBatchJobSubmitter;\n+\n+\t@Autowired\n+\t@Qualifier(\"bulkExportJob\")\n+\tprivate Job myBulkJob;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgyNTM3OA==", "bodyText": "Maybe? I'll look into this. JobBuilderFactory returns a Job specifically, so I'll see if theres a way to do this without the builder.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437825378", "createdAt": "2020-06-10T02:30:14Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -41,6 +52,12 @@\n \tprivate IBulkExportCollectionFileDao myBulkExportCollectionFileDao;\n \t@Autowired\n \tprivate IBulkDataExportSvc myBulkDataExportSvc;\n+\t@Autowired\n+\tprivate IBatchJobSubmitter myBatchJobSubmitter;\n+\n+\t@Autowired\n+\t@Qualifier(\"bulkExportJob\")\n+\tprivate Job myBulkJob;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzQ4NA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc1MTgxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozMTo0MlrOGhbF4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozMTo0MlrOGhbF4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMDA2Nw==", "bodyText": "This is a nice test.  Demonstrates how simple and clean it is to create and submit a job.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437700067", "createdAt": "2020-06-09T20:31:42Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -234,7 +251,45 @@ public void testSubmitReusesExisting() {\n \t}\n \n \n-\t\t@Test\n+\t@Test\n+\tpublic void testBatchJobSubmitsAndRuns() throws Exception {\n+\t\tcreateResources();\n+\n+\t\t// Create a bulk job\n+\t\tIBulkDataExportSvc.JobInfo jobDetails = myBulkDataExportSvc.submitJob(null, Sets.newHashSet(\"Patient\", \"Observation\"), null, null);\n+\n+\t\t//Add the UUID to the job\n+\t\tJobParametersBuilder paramBuilder = new JobParametersBuilder().addString(\"jobUUID\", jobDetails.getJobId());\n+\t\tmyBatchJobSubmitter.runJob(myBulkJob, paramBuilder.toJobParameters());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc1MzUyOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozMjoxNVrOGhbG_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMjoxNToxN1rOGhif-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMDM0OA==", "bodyText": "Feels like needing to create a uuid is such a common thing all the services are going to want to do, I wonder if we should hide this by default and just do it for them.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437700348", "createdAt": "2020-06-09T20:32:15Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -234,7 +251,45 @@ public void testSubmitReusesExisting() {\n \t}\n \n \n-\t\t@Test\n+\t@Test\n+\tpublic void testBatchJobSubmitsAndRuns() throws Exception {\n+\t\tcreateResources();\n+\n+\t\t// Create a bulk job\n+\t\tIBulkDataExportSvc.JobInfo jobDetails = myBulkDataExportSvc.submitJob(null, Sets.newHashSet(\"Patient\", \"Observation\"), null, null);\n+\n+\t\t//Add the UUID to the job\n+\t\tJobParametersBuilder paramBuilder = new JobParametersBuilder().addString(\"jobUUID\", jobDetails.getJobId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgyMTQzMw==", "bodyText": "So this is a thing Specific (i believe) to bulk export. When you ask for a bulk export, it creates a BulkExportJobEntity which has a UUID. When the job runs, all the generated files end up pointing to this entity, via BulkExportCollectionEntity which each contain a set of BulkExportCollectionFileEntity The UUID is the UUID of this persisted job. I suppose we could remove the UUID from there, and just have a foreign reference to the existing Spring Batch job, but thats probably a separate discussion. By default, each Spring batch Job execution has a job execution ID, it just isn't shown here.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437821433", "createdAt": "2020-06-10T02:15:17Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -234,7 +251,45 @@ public void testSubmitReusesExisting() {\n \t}\n \n \n-\t\t@Test\n+\t@Test\n+\tpublic void testBatchJobSubmitsAndRuns() throws Exception {\n+\t\tcreateResources();\n+\n+\t\t// Create a bulk job\n+\t\tIBulkDataExportSvc.JobInfo jobDetails = myBulkDataExportSvc.submitJob(null, Sets.newHashSet(\"Patient\", \"Observation\"), null, null);\n+\n+\t\t//Add the UUID to the job\n+\t\tJobParametersBuilder paramBuilder = new JobParametersBuilder().addString(\"jobUUID\", jobDetails.getJobId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMDM0OA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc1OTUwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozNDoxMFrOGhbKrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozNDoxMFrOGhbKrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMTI5Mw==", "bodyText": "await().until(() -> myBulkDataExportSvc.getJobInfoOrThrowResourceNotFound(theJobId).getStatus() == BulkJobStatusEnum.COMPLETE)", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437701293", "createdAt": "2020-06-09T20:34:10Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/bulk/BulkDataExportSvcImplR4Test.java", "diffHunk": "@@ -234,7 +251,45 @@ public void testSubmitReusesExisting() {\n \t}\n \n \n-\t\t@Test\n+\t@Test\n+\tpublic void testBatchJobSubmitsAndRuns() throws Exception {\n+\t\tcreateResources();\n+\n+\t\t// Create a bulk job\n+\t\tIBulkDataExportSvc.JobInfo jobDetails = myBulkDataExportSvc.submitJob(null, Sets.newHashSet(\"Patient\", \"Observation\"), null, null);\n+\n+\t\t//Add the UUID to the job\n+\t\tJobParametersBuilder paramBuilder = new JobParametersBuilder().addString(\"jobUUID\", jobDetails.getJobId());\n+\t\tmyBatchJobSubmitter.runJob(myBulkJob, paramBuilder.toJobParameters());\n+\n+\t\tIBulkDataExportSvc.JobInfo jobInfo = awaitJobCompletion(jobDetails.getJobId());\n+\t\tassertThat(jobInfo.getStatus(), equalTo(BulkJobStatusEnum.COMPLETE));\n+\t}\n+\n+\t@Test\n+\tpublic void testJobParametersValidatorRejectsInvalidParameters() {\n+\t\tJobParametersBuilder paramBuilder = new JobParametersBuilder().addString(\"jobUUID\", \"I'm not real!\");\n+\t\ttry {\n+\t\t\tmyBatchJobSubmitter.runJob(myBulkJob, paramBuilder.toJobParameters());\n+\t\t\tfail(\"Should have had invalid parameter execption!\");\n+\t\t} catch (JobParametersInvalidException e) {\n+\n+\t\t}\n+\n+\t}\n+\n+\tpublic IBulkDataExportSvc.JobInfo awaitJobCompletion(String theJobId) throws InterruptedException {\n+\t\twhile(true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc2NzY2OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozNjo1MVrOGhbP3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMjoxNzo1M1rOGhiidg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMjYyMg==", "bodyText": "Change this comment so it makes sense outside the context of this commit:\nPlease do not rename this bean to \"transactionManager\" as that will conflict with the Spring Batch transactionManager.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437702622", "createdAt": "2020-06-09T20:36:51Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "diffHunk": "@@ -40,8 +40,12 @@ public ModelConfig modelConfig() {\n \t\treturn daoConfig().getModelConfig();\n \t}\n \n+\t/*\n+\tI had to rename this bean as it was clashing with Spring Batch `transactionManager` in SimpleBatchConfiguration", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMjc4MQ==", "bodyText": "or something like that", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437702781", "createdAt": "2020-06-09T20:37:09Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "diffHunk": "@@ -40,8 +40,12 @@ public ModelConfig modelConfig() {\n \t\treturn daoConfig().getModelConfig();\n \t}\n \n+\t/*\n+\tI had to rename this bean as it was clashing with Spring Batch `transactionManager` in SimpleBatchConfiguration", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMjYyMg=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgyMjA3MA==", "bodyText": "Sounds good!", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437822070", "createdAt": "2020-06-10T02:17:53Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "diffHunk": "@@ -40,8 +40,12 @@ public ModelConfig modelConfig() {\n \t\treturn daoConfig().getModelConfig();\n \t}\n \n+\t/*\n+\tI had to rename this bean as it was clashing with Spring Batch `transactionManager` in SimpleBatchConfiguration", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMjYyMg=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc3MDM5OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozNzozOVrOGhbRlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo1MToyNVrOGhb2Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMzA2MQ==", "bodyText": "is it possible to call it jpaTransactionManager ?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437703061", "createdAt": "2020-06-09T20:37:39Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "diffHunk": "@@ -40,8 +40,12 @@ public ModelConfig modelConfig() {\n \t\treturn daoConfig().getModelConfig();\n \t}\n \n+\t/*\n+\tI had to rename this bean as it was clashing with Spring Batch `transactionManager` in SimpleBatchConfiguration\n+\t */\n \t@Bean\n-\tpublic JpaTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {\n+\t@Primary\n+\tpublic JpaTransactionManager hapiTransactionManager(EntityManagerFactory entityManagerFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcxMjM4Nw==", "bodyText": "When I tried that, it conflicted with the one provided with @EnableBatchProcessing", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437712387", "createdAt": "2020-06-09T20:51:25Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/config/TestJPAConfig.java", "diffHunk": "@@ -40,8 +40,12 @@ public ModelConfig modelConfig() {\n \t\treturn daoConfig().getModelConfig();\n \t}\n \n+\t/*\n+\tI had to rename this bean as it was clashing with Spring Batch `transactionManager` in SimpleBatchConfiguration\n+\t */\n \t@Bean\n-\tpublic JpaTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {\n+\t@Primary\n+\tpublic JpaTransactionManager hapiTransactionManager(EntityManagerFactory entityManagerFactory) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMzA2MQ=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc3NDYyOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/svc/BatchJobSubmitterImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDozODo1NlrOGhbUWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzozMzowOVrOGhf5GA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMzc2OQ==", "bodyText": "add another version where JobParameters is optional and we auto-create a uuid for the caller?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437703769", "createdAt": "2020-06-09T20:38:56Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/svc/BatchJobSubmitterImpl.java", "diffHunk": "@@ -0,0 +1,40 @@\n+package ca.uhn.fhir.jpa.batch.svc;\n+\n+import ca.uhn.fhir.jpa.batch.api.IBatchJobSubmitter;\n+import org.slf4j.Logger;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.launch.JobLauncher;\n+import org.springframework.batch.core.repository.JobExecutionAlreadyRunningException;\n+import org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException;\n+import org.springframework.batch.core.repository.JobRepository;\n+import org.springframework.batch.core.repository.JobRestartException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class BatchJobSubmitterImpl implements IBatchJobSubmitter {\n+\n+\tprivate static final Logger ourLog = getLogger(BatchJobSubmitterImpl.class);\n+\n+\t@Autowired\n+\tprivate JobLauncher myJobLauncher;\n+\n+\t@Autowired\n+\tprivate JobRepository myJobRepository;\n+\n+\t@Override\n+\tpublic JobExecution runJob(Job theJob, JobParameters theJobParameters) throws JobParametersInvalidException{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3ODcxMg==", "bodyText": "We actually are relying on an existing UUID from a BulkExportJobEntity.", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437778712", "createdAt": "2020-06-09T23:33:09Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-batch/src/main/java/ca/uhn/fhir/jpa/batch/svc/BatchJobSubmitterImpl.java", "diffHunk": "@@ -0,0 +1,40 @@\n+package ca.uhn.fhir.jpa.batch.svc;\n+\n+import ca.uhn.fhir.jpa.batch.api.IBatchJobSubmitter;\n+import org.slf4j.Logger;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.JobExecution;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.launch.JobLauncher;\n+import org.springframework.batch.core.repository.JobExecutionAlreadyRunningException;\n+import org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException;\n+import org.springframework.batch.core.repository.JobRepository;\n+import org.springframework.batch.core.repository.JobRestartException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+import static org.slf4j.LoggerFactory.getLogger;\n+\n+public class BatchJobSubmitterImpl implements IBatchJobSubmitter {\n+\n+\tprivate static final Logger ourLog = getLogger(BatchJobSubmitterImpl.class);\n+\n+\t@Autowired\n+\tprivate JobLauncher myJobLauncher;\n+\n+\t@Autowired\n+\tprivate JobRepository myJobRepository;\n+\n+\t@Override\n+\tpublic JobExecution runJob(Job theJob, JobParameters theJobParameters) throws JobParametersInvalidException{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwMzc2OQ=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc4NTcxOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/config/BatchJobConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo0MjoxM1rOGhbbEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzozMjo0OFrOGhf4rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwNTQ5MA==", "bodyText": "this latch is never used...?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437705490", "createdAt": "2020-06-09T20:42:13Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/config/BatchJobConfig.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package ca.uhn.fhir.jpa.batch.config;\n+\n+import ca.uhn.fhir.interceptor.api.HookParams;\n+import ca.uhn.test.concurrency.IPointcutLatch;\n+import ca.uhn.test.concurrency.PointcutLatch;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.core.step.tasklet.Tasklet;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+\n+import java.util.List;\n+\n+@Configuration\n+public class BatchJobConfig implements IPointcutLatch {\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3ODYwNg==", "bodyText": "Right you are", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437778606", "createdAt": "2020-06-09T23:32:48Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/config/BatchJobConfig.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package ca.uhn.fhir.jpa.batch.config;\n+\n+import ca.uhn.fhir.interceptor.api.HookParams;\n+import ca.uhn.test.concurrency.IPointcutLatch;\n+import ca.uhn.test.concurrency.PointcutLatch;\n+import org.springframework.batch.core.Job;\n+import org.springframework.batch.core.Step;\n+import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;\n+import org.springframework.batch.core.configuration.annotation.StepScope;\n+import org.springframework.batch.core.step.tasklet.Tasklet;\n+import org.springframework.batch.item.ItemReader;\n+import org.springframework.batch.item.ItemWriter;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+\n+import java.util.List;\n+\n+@Configuration\n+public class BatchJobConfig implements IPointcutLatch {\n+\n+\t@Autowired\n+\tprivate JobBuilderFactory myJobBuilderFactory;\n+\n+\t@Autowired\n+\tprivate StepBuilderFactory myStepBuilderFactory;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwNTQ5MA=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc5Njc4OnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/svc/BatchSvcTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo0NToyMFrOGhbh1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMzozMzoxN1rOGhf5Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwNzIyMg==", "bodyText": "This job appears to run forever", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437707222", "createdAt": "2020-06-09T20:45:20Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/svc/BatchSvcTest.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package ca.uhn.fhir.jpa.batch.svc;\n+\n+import ca.uhn.fhir.jpa.batch.BaseBatchR4Test;\n+import ca.uhn.fhir.jpa.batch.config.BatchJobConfig;\n+import org.junit.Test;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.repository.JobExecutionAlreadyRunningException;\n+import org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException;\n+import org.springframework.batch.core.repository.JobRestartException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+public class BatchSvcTest extends BaseBatchR4Test {\n+\t@Autowired\n+\tprivate BatchJobConfig myBatchJobConfig;\n+\n+\t@Test\n+\tpublic void testApplicationContextLoads() throws JobParametersInvalidException, JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, InterruptedException {\n+\t\tmyBatchJobConfig.setExpectedCount(1);\n+\t\tmyJobLauncher.run(myJob, new JobParameters());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3ODc2Ng==", "bodyText": "Right you are. FIxed", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437778766", "createdAt": "2020-06-09T23:33:17Z", "author": {"login": "tadgh"}, "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/svc/BatchSvcTest.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package ca.uhn.fhir.jpa.batch.svc;\n+\n+import ca.uhn.fhir.jpa.batch.BaseBatchR4Test;\n+import ca.uhn.fhir.jpa.batch.config.BatchJobConfig;\n+import org.junit.Test;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.repository.JobExecutionAlreadyRunningException;\n+import org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException;\n+import org.springframework.batch.core.repository.JobRestartException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+public class BatchSvcTest extends BaseBatchR4Test {\n+\t@Autowired\n+\tprivate BatchJobConfig myBatchJobConfig;\n+\n+\t@Test\n+\tpublic void testApplicationContextLoads() throws JobParametersInvalidException, JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, InterruptedException {\n+\t\tmyBatchJobConfig.setExpectedCount(1);\n+\t\tmyJobLauncher.run(myJob, new JobParameters());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwNzIyMg=="}, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyNjc5NzkwOnYy", "diffSide": "RIGHT", "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/svc/BatchSvcTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo0NTozMlrOGhbibw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMDo0NTozMlrOGhbibw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcwNzM3NQ==", "bodyText": "I don't see how this could ever happen...?", "url": "https://github.com/hapifhir/hapi-fhir/pull/1906#discussion_r437707375", "createdAt": "2020-06-09T20:45:32Z", "author": {"login": "fil512"}, "path": "hapi-fhir-jpaserver-batch/src/test/java/ca/uhn/fhir/jpa/batch/svc/BatchSvcTest.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package ca.uhn.fhir.jpa.batch.svc;\n+\n+import ca.uhn.fhir.jpa.batch.BaseBatchR4Test;\n+import ca.uhn.fhir.jpa.batch.config.BatchJobConfig;\n+import org.junit.Test;\n+import org.springframework.batch.core.JobParameters;\n+import org.springframework.batch.core.JobParametersInvalidException;\n+import org.springframework.batch.core.repository.JobExecutionAlreadyRunningException;\n+import org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException;\n+import org.springframework.batch.core.repository.JobRestartException;\n+import org.springframework.beans.factory.annotation.Autowired;\n+\n+public class BatchSvcTest extends BaseBatchR4Test {\n+\t@Autowired\n+\tprivate BatchJobConfig myBatchJobConfig;\n+\n+\t@Test\n+\tpublic void testApplicationContextLoads() throws JobParametersInvalidException, JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, InterruptedException {\n+\t\tmyBatchJobConfig.setExpectedCount(1);\n+\t\tmyJobLauncher.run(myJob, new JobParameters());\n+\t\tmyBatchJobConfig.awaitExpected();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fdd0f17531bff1323e81303888a7584638e1e10"}, "originalPosition": 21}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1862, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}