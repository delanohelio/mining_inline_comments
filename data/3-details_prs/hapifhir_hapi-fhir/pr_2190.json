{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1MzcxNjIx", "number": 2190, "title": "Replacing Hibernate Search 5 with Hibernate Search 6", "bodyText": "This PR upgrades to Hibernate Search 6.0.0.CR2 for the purposes of removing various CVEs caused by old versions, along with our shaded jars.\n\nReplace all out of date properties with new versions\nReplace all POM references to old versions\nRemove the shaded ES jars as HS6 supports 7.10.0\nConvert \"Bridges\" to RoutingBinder and RoutingBridge as per new API.\nModernize all indexing annotations\nRefactor all search queries.\nAdd backwards compatible Lucene50 codec\nAdd missing CLI dependency.\nReplace MappingProvider with AnalysisConfigurer as per new API.\nRemove home-rolled SearchBox class, and replace with HS6 GeoBoundingBox\nRemove the Suggest Keywords operation from all Providers.\nRemove lucene-highlighter\nRemove Embedded Elasticsearch. That project is now defunct, and replaced with TestContainers\nRemove the hapi-elasticsearch-6 shaded project.\nRefactor the ElasticsearchSvcImpl to work with ES 7.10\nReplace usages of non-hibernate-orm deleteBy methods, as Hibernate Search literally ignores them for the purposes of indexing.\n\nOutstanding issues:\n\nCurrently, max-ngram-diff on elasticsearch is set on a per-index basis, controlled in an index setting. HS6 exposes no way currently to dynamically set this before the index is created. However there is an open enhancement that will be delivered in 6.1 which will resolve this issue. We may be able to fix it in the interim with a spring lifecycle hook in which we could quickly create an index template before Hibernate search 6 bootstrapping. In the meantime, you can circumvent this issue by applying the following template to your Elasticsearch Cluster before HAPI is upgraded:\n\n{\n\t\"index_patterns\": [\n\t\t\"termconcept-*\",\n\t\t\"resourcetable-*\"\n\t],\n\t\"settings\": {\n\t\t\"index\": {\n\t\t\t\"max_ngram_diff\": 50\n\t\t}\n\t}\n}\nBreaking changes:\n\nHAPI now relies on elasticsearch 7.10. If you have an install requiring elasticsearch, upgrade to 7.10\nHAPI now relies on lucene 8.7.0\nAnybody upgrading to this version will need to completely reindex their fulltext data due to large scale API changes and data field format changes between versions of hibernate search.\nSuggest keywords operation is deleted.", "createdAt": "2020-11-22T22:55:40Z", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190", "merged": true, "mergeCommit": {"oid": "efc6809ea689eb95436174f24ec498ecf77fb981"}, "closed": true, "closedAt": "2021-01-05T22:56:59Z", "author": {"login": "tadgh"}, "timelineItems": {"totalCount": 98, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfIpO_AH2gAyNTI1MzcxNjIxOjBlMzJkMjg0OGIwNGQ2N2Q0NWZiY2M5ZWExZDVjZWU4N2NlNjQ5NTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdtTEdvAFqTU2MjE5NzI2MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0e32d2848b04d67d45fbcc9ea1d5cee87ce64958", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0e32d2848b04d67d45fbcc9ea1d5cee87ce64958", "committedDate": "2020-11-22T22:53:10Z", "message": "Beginning work on converting to hibernate search 6\n* replace all out of date properties\n* replace all POM references to old versions\n* remove the shaded ES jars as HS6 supports 7.9\n* Convert \"Bridges\" to RoutingBinder and RoutingBridge\n* Modernize all indexing annotations\n* Begin refactoring of search queries (wip)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40cd9ba8252f03f8ebd6f2c52e60fb8ededeca08", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/40cd9ba8252f03f8ebd6f2c52e60fb8ededeca08", "committedDate": "2020-11-23T04:26:08Z", "message": "Fix spatial API changes, work on BaseTermReadSvcImpl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f85e7375786b686deba50676a4bb4c9ef6781ca", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4f85e7375786b686deba50676a4bb4c9ef6781ca", "committedDate": "2020-11-23T04:50:01Z", "message": "Most of the way through the various filter property conversions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c7f411a6a249de38ed9af3ec426fb7934624b81c", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/c7f411a6a249de38ed9af3ec426fb7934624b81c", "committedDate": "2020-11-23T15:01:03Z", "message": "Finished i think with BaseTermReadSvcImpl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30d8554d887752caf803903e5f0edf6087d533e8", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/30d8554d887752caf803903e5f0edf6087d533e8", "committedDate": "2020-11-23T17:30:22Z", "message": "Compiling, but definitely broken"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a3d191b844f05895a402914ac199eac8245ea0a", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0a3d191b844f05895a402914ac199eac8245ea0a", "committedDate": "2020-11-23T17:57:56Z", "message": "Start test compilation failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4285d409b6b84884070806624a7b5d65c9629d93", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4285d409b6b84884070806624a7b5d65c9629d93", "committedDate": "2020-11-23T19:31:32Z", "message": "All tests compiling (i think)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2125ccc0c35d32edc542a671964e045cfd0bebd", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/a2125ccc0c35d32edc542a671964e045cfd0bebd", "committedDate": "2020-11-24T00:53:26Z", "message": "remove suggest keywords operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bb315ebec802e7e37c0451a6a716924a3d8b624", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4bb315ebec802e7e37c0451a6a716924a3d8b624", "committedDate": "2020-11-24T17:28:24Z", "message": "Fix bootstrap errors, still have to deal with transient fields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0adabce101f06a402054adb0ddb22e15ffe57f7", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/e0adabce101f06a402054adb0ddb22e15ffe57f7", "committedDate": "2020-11-25T16:11:54Z", "message": "Rollback CR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4101c885eb49148f5235323717274b0b818571d1", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4101c885eb49148f5235323717274b0b818571d1", "committedDate": "2020-11-25T22:00:49Z", "message": "More refactoring, got IDs baked back into docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2ef725cf19689975db0ee9c5a8e788d7a54025f", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d2ef725cf19689975db0ee9c5a8e788d7a54025f", "committedDate": "2020-11-26T03:08:46Z", "message": "Fix coord util, fix a few more fields which require projection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d55e767624496f0a005dbf847e6ef8e92276a61", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/1d55e767624496f0a005dbf847e6ef8e92276a61", "committedDate": "2020-11-26T18:37:46Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "132a53a433a4063ea3dde788b1c807152dff87b4", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/132a53a433a4063ea3dde788b1c807152dff87b4", "committedDate": "2020-11-26T19:36:08Z", "message": "merge fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4407095e4e6f83632110e01bd18a84fc7a5aca51", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4407095e4e6f83632110e01bd18a84fc7a5aca51", "committedDate": "2020-11-27T00:52:04Z", "message": "begin refactor of valuesetexpansion tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d4a01a1be34b36f7b272f97ba954e0d601aa0e8", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/8d4a01a1be34b36f7b272f97ba954e0d601aa0e8", "committedDate": "2020-11-27T14:18:55Z", "message": "fix another test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "322ebdf353010f38d35665dc4d6255dfec539954", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/322ebdf353010f38d35665dc4d6255dfec539954", "committedDate": "2020-11-28T05:37:02Z", "message": "Update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ebd35e67f95e9909b385245dae25b9d78f3e2f8", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/5ebd35e67f95e9909b385245dae25b9d78f3e2f8", "committedDate": "2020-11-30T17:53:59Z", "message": "remove todos, add TestContainers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d292433c2f2154c1d8724a5f03b7feaada7d66d1", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d292433c2f2154c1d8724a5f03b7feaada7d66d1", "committedDate": "2020-11-30T18:41:57Z", "message": "Fix descendant in"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31f63a06df3ae51de0b0062c266ab436d035bfb0", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/31f63a06df3ae51de0b0062c266ab436d035bfb0", "committedDate": "2020-11-30T18:55:22Z", "message": "Add testcontainers, fix another test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3feca4e3575937f2088357e0f5eb5dfefa881c9", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/b3feca4e3575937f2088357e0f5eb5dfefa881c9", "committedDate": "2020-11-30T18:57:43Z", "message": "Merge branch 'gg-20201120-bump-to-hibernatesearch-beta' of github.com:jamesagnew/hapi-fhir into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b2ad7d246dca4520c50698752607868f7e32b30", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/9b2ad7d246dca4520c50698752607868f7e32b30", "committedDate": "2020-11-30T19:52:31Z", "message": "fix more tests, replace embedded es"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "223490411454468acc547098ddb4164f68f3b0bd", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/223490411454468acc547098ddb4164f68f3b0bd", "committedDate": "2020-11-30T21:56:10Z", "message": "Rip out embedded elastic, replace with TestContainer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9b5c30ac41d79c6069ec61eee0a1906e94cee34", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d9b5c30ac41d79c6069ec61eee0a1906e94cee34", "committedDate": "2020-11-30T23:14:25Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15a83b1d36120c552dc328b2cc0614d48ae01eb7", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/15a83b1d36120c552dc328b2cc0614d48ae01eb7", "committedDate": "2020-11-30T23:14:36Z", "message": "merge conflicts for new analyzers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c9fad5a963a3d0dc65893466bccf44adc879f68", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/2c9fad5a963a3d0dc65893466bccf44adc879f68", "committedDate": "2020-12-01T02:44:38Z", "message": "Bump to CR2 for hibernate search 6. Add forgotten CLI dep. Add backwards compatible codecs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "687c7db436c1b4aaeaf69014216c969926d327a4", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/687c7db436c1b4aaeaf69014216c969926d327a4", "committedDate": "2020-12-01T14:48:05Z", "message": "Remove dead deps, update testcontainer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e0f77bc9ad503d4006362ff72f93a84b9fb15f6", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/7e0f77bc9ad503d4006362ff72f93a84b9fb15f6", "committedDate": "2020-12-01T15:49:22Z", "message": "Remove java-hamcrest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bd47fa6a26db5fbf349332e83744ee6237111aa", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/7bd47fa6a26db5fbf349332e83744ee6237111aa", "committedDate": "2020-12-01T16:52:17Z", "message": "Pull asserts up, refactor tests to pass in RP tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d192f110c6f4b8d68d9d26c6dba0f54d453763f5", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d192f110c6f4b8d68d9d26c6dba0f54d453763f5", "committedDate": "2020-12-01T18:27:51Z", "message": "Update V2 check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "112dfaeeef51173a6ee9bc31fc1a57a8626b6b32", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/112dfaeeef51173a6ee9bc31fc1a57a8626b6b32", "committedDate": "2020-12-01T18:31:19Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd362034e261a4ade7169e198772bfc1aab7a092", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/dd362034e261a4ade7169e198772bfc1aab7a092", "committedDate": "2020-12-01T18:47:58Z", "message": "Remove suggest keyword tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab1f392ffa9161eaa7996e313f6c5bea209dc4df", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/ab1f392ffa9161eaa7996e313f6c5bea209dc4df", "committedDate": "2020-12-01T19:24:05Z", "message": "Split line for testing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "509331a81afeb176a4ba00eecaa9b3d881616130", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/509331a81afeb176a4ba00eecaa9b3d881616130", "committedDate": "2020-12-01T19:52:34Z", "message": "Fix perhaps one of the dumbest programming mistakes in my career so far"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "151cb6feb47ace00552425f27ee043e5feeb4ea1", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/151cb6feb47ace00552425f27ee043e5feeb4ea1", "committedDate": "2020-12-02T01:51:13Z", "message": "Refactor tests which no longer rely on a strict known order"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be771fe57e3d03fee26aafcbc0ad73296fd43e60", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/be771fe57e3d03fee26aafcbc0ad73296fd43e60", "committedDate": "2020-12-02T03:34:28Z", "message": "Fix up test config, disable log test temporarily"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/f8675c1950bc0c9e3a9ce7268479532495072307", "committedDate": "2020-12-02T03:42:31Z", "message": "Remove log4j from being transitively pulled in. re-enable test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyNzkwMjI1", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#pullrequestreview-542790225", "createdAt": "2020-12-02T12:33:38Z", "commit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjozMzozOFrOH9Y1hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxMjo0OToyMVrOH9ZY-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMjEwMQ==", "bodyText": "The version should be declared in the root pom file <dependencyManagement> section", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534132101", "createdAt": "2020-12-02T12:33:38Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-api/pom.xml", "diffHunk": "@@ -259,8 +259,14 @@\n \t\t\t<artifactId>awaitility</artifactId>\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n+        <dependency>\n+            <groupId>org.rauschig</groupId>\n+            <artifactId>jarchivelib</artifactId>\n+            <version>1.0.0</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzMzA0Mw==", "bodyText": "Ah nice they finally renamed this property... \"autoregister_listeners\" has to be the most unintuitive name imaginable for the \"completely disable everything\" flag.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534133043", "createdAt": "2020-12-02T12:35:16Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -90,14 +98,13 @@ public Properties jpaProperties() {\n \t\textraProperties.put(\"hibernate.cache.use_second_level_cache\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_structured_entries\", \"false\");\n \t\textraProperties.put(\"hibernate.cache.use_minimal_puts\", \"false\");\n-\t\textraProperties.put(\"hibernate.search.model_mapping\", LuceneSearchMappingFactory.class.getName());\n-\t\textraProperties.put(\"hibernate.search.default.directory_provider\", \"filesystem\");\n-\t\textraProperties.put(\"hibernate.search.default.indexBase\", \"target/lucenefiles\");\n-\t\textraProperties.put(\"hibernate.search.lucene_version\", \"LUCENE_CURRENT\");\n-\t\textraProperties.put(\"hibernate.search.default.worker.execution\", \"async\");\n \n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.ANALYSIS_CONFIGURER), HapiLuceneAnalysisConfigurer.class.getName());\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_TYPE), \"local-filesystem\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneIndexSettings.DIRECTORY_ROOT), \"target/lucenefiles\");\n+\t\textraProperties.put(BackendSettings.backendKey(LuceneBackendSettings.LUCENE_VERSION), \"LUCENE_CURRENT\");\n \t\tif (System.getProperty(\"lowmem\") != null) {\n-\t\t\textraProperties.put(\"hibernate.search.autoregister_listeners\", \"false\");\n+\t\t\textraProperties.put(HibernateOrmMapperSettings.ENABLED, \"false\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzNzc3NQ==", "bodyText": "nitpick: drop commented line if it is no longer needed", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534137775", "createdAt": "2020-12-02T12:43:37Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/lastn/ElasticsearchSvcImpl.java", "diffHunk": "@@ -721,7 +720,7 @@ public void close() throws IOException {\n \tprivate IndexRequest createIndexRequest(String theIndexName, String theDocumentId, String theObservationDocument, String theDocumentType) {\n \t\tIndexRequest request = new IndexRequest(theIndexName);\n \t\trequest.id(theDocumentId);\n-\t\trequest.type(theDocumentType);\n+//\t\trequest.type(theDocumentType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDEzODc3OQ==", "bodyText": "When this is merged I'll have a look at this, it's probably my bug", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534138779", "createdAt": "2020-12-02T12:45:13Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -536,6 +535,8 @@ private void expandConcepts(IValueSetConceptAccumulator theAccumulator, TermValu\n \t\t\tconceptViews = myTermValueSetConceptViewDao.findByTermValueSetId(theTermValueSet.getId(), displayValue);\n \t\t\twasFilteredResult = true;\n \t\t} else {\n+\t\t\t// TODO GGG HS: I'm pretty sure we are overfetching here.  test says offset 3, count 4, but we are fetching index 3 -> 10 here, grabbing 7 concepts.\n+\t\t\t//Specifically this test testExpandInline_IncludePreExpandedValueSetByUri_FilterOnDisplay_LeftMatch_SelectRange", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE0MTE3Ng==", "bodyText": "Add these library version changes (except any that are only used in scope test) to here: https://github.com/jamesagnew/hapi-fhir/blob/master/hapi-fhir-docs/src/main/resources/ca/uhn/hapi/fhir/changelog/5_3_0/changes.yaml", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534141176", "createdAt": "2020-12-02T12:49:21Z", "author": {"login": "jamesagnew"}, "path": "pom.xml", "diffHunk": "@@ -742,11 +742,11 @@\n \t\t<jsr305_version>3.0.2</jsr305_version>\n \t\t<junit_version>5.6.2</junit_version>\n \t\t<flyway_version>6.5.4</flyway_version>\n-\t\t<!--<hibernate_version>5.2.10.Final</hibernate_version>-->\n-\t\t<hibernate_version>5.4.22.Final</hibernate_version>\n+\t\t<hibernate_version>5.4.24.Final</hibernate_version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyODcyNTk2", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#pullrequestreview-542872596", "createdAt": "2020-12-02T14:12:16Z", "commit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNDoxMjoxNlrOH9cvZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNDoxMjoxNlrOH9cvZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE5NjA2OQ==", "bodyText": "One general comment I'm adding here for lack of a better spot:\nBefore merging, can you try uploading a CodeSystem to an ES-backed server.. then wiping elasticsearch and marking all resources for reindexing, just to confirm that we reload elastic properly? That process will presumably go on to become the migration path assuming it works.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534196069", "createdAt": "2020-12-02T14:12:16Z", "author": {"login": "jamesagnew"}, "path": "hapi-fhir-cli/hapi-fhir-cli-jpaserver/src/main/java/ca/uhn/fhir/jpa/demo/CommonConfig.java", "diffHunk": "@@ -23,10 +23,16 @@\n import ca.uhn.fhir.jpa.api.config.DaoConfig;\n import ca.uhn.fhir.jpa.model.config.PartitionSettings;\n import ca.uhn.fhir.jpa.model.entity.ModelConfig;\n-import ca.uhn.fhir.jpa.search.LuceneSearchMappingFactory;\n+import ca.uhn.fhir.jpa.search.HapiLuceneAnalysisConfigurer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23e50215baaad2547d80a50f4690324a5e03f7ca", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/23e50215baaad2547d80a50f4690324a5e03f7ca", "committedDate": "2020-12-02T16:52:05Z", "message": "Update log4j exclusions with new bridge. Update test to check for core class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f7ecaa66951c39bb92a68aae937c2b6ac7fd3ec", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/1f7ecaa66951c39bb92a68aae937c2b6ac7fd3ec", "committedDate": "2020-12-02T17:00:05Z", "message": "Move dependency to root pom in dep management section"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fda03c9f131dcb9d49989c6bb6cf273306ebfb78", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/fda03c9f131dcb9d49989c6bb6cf273306ebfb78", "committedDate": "2020-12-02T17:13:21Z", "message": "Update changelog, add changelog for HS6 with ES requirements. Remove dead comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzMDE4NTcw", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#pullrequestreview-543018570", "createdAt": "2020-12-02T16:32:01Z", "commit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjozMjowMVrOH9jl9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNzoyMjo0MVrOH9l38w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwODM0MA==", "bodyText": "This file still has a lot of the old implementation but commented out. Can this be removed?\nWon't call out each instance; it's pretty much all of the properties here.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534308340", "createdAt": "2020-12-02T16:32:01Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/ElasticsearchHibernatePropertiesBuilder.java", "diffHunk": "@@ -56,36 +61,50 @@ public ElasticsearchHibernatePropertiesBuilder setPassword(String thePassword) {\n \n \tpublic void apply(Properties theProperties) {\n \n-\t\t// Don't use the Lucene properties as they conflict\n-\t\ttheProperties.remove(\"hibernate.search.model_mapping\");\n-\n \t\t// the below properties are used for ElasticSearch integration\n-\t\ttheProperties.put(\"hibernate.search.default.\" + Environment.INDEX_MANAGER_IMPL_NAME, \"elasticsearch\");\n-\t\ttheProperties.put(\"hibernate.search.\" + ElasticsearchEnvironment.ANALYSIS_DEFINITION_PROVIDER, ElasticsearchMappingProvider.class.getName());\n+\t\ttheProperties.put(BackendSettings.backendKey(BackendSettings.TYPE), \"elasticsearch\");\n+\n+\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchIndexSettings.ANALYSIS_CONFIGURER), HapiElasticsearchAnalysisConfigurer.class.getName());\n+\n+\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.HOSTS), myRestUrl);\n+\t\ttheProperties.put(BackendSettings.backendKey(ElasticsearchBackendSettings.PROTOCOL), myProtocol);\n \n-\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.host\", myRestUrl);\n \t\tif (StringUtils.isNotBlank(myUsername)) {\n-\t\t\ttheProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);\n+\t\t\t//theProperties.put(\"hibernate.search.default.elasticsearch.username\", myUsername);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwOTgyNQ==", "bodyText": "TODOs in this file. I believe you may have already called them out. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534309825", "createdAt": "2020-12-02T16:33:56Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/search/elastic/HapiElasticsearchAnalysisConfigurer.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package ca.uhn.fhir.jpa.search.elastic;\n+\n+/*-\n+ * #%L\n+ * HAPI FHIR JPA Server\n+ * %%\n+ * Copyright (C) 2014 - 2020 University Health Network\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+\n+import org.hibernate.search.backend.elasticsearch.analysis.ElasticsearchAnalysisConfigurationContext;\n+import org.hibernate.search.backend.elasticsearch.analysis.ElasticsearchAnalysisConfigurer;\n+\n+public class HapiElasticsearchAnalysisConfigurer implements ElasticsearchAnalysisConfigurer{\n+\n+\t@Override\n+\tpublic void configure(ElasticsearchAnalysisConfigurationContext theConfigCtx) {\n+\n+\t\ttheConfigCtx.analyzer(\"autocompleteEdgeAnalyzer\").custom()\n+\t\t\t.tokenizer(\"pattern_all\")\n+\t\t\t.tokenFilters(\"lowercase\", \"stop\", \"edgengram_3_50\");\n+\n+\t\ttheConfigCtx.tokenizer(\"pattern_all\")\n+\t\t\t.type(\"pattern\")\n+\t\t\t.param(\"pattern\", \"(.*)\")\n+\t\t\t.param(\"group\", \"1\");\n+\n+\t\ttheConfigCtx.tokenFilter(\"edgengram_3_50\")\n+\t\t\t.type(\"edgeNGram\")\n+\t\t\t.param(\"min_gram\", \"3\")\n+\t\t\t.param(\"max_gram\", \"4\");\n+//\t\t\t.param(\"max_gram\", \"50\");//TODO GGG HS ES 7.10 says we have to set `max_ngram_diff:47` on each index we create, since the default is 1.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxNjQyNg==", "bodyText": "These tests are muuuch better. Thanks!", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534316426", "createdAt": "2020-12-02T16:42:37Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/provider/dstu3/ResourceProviderDstu3ValueSetVersionedTest.java", "diffHunk": "@@ -1110,68 +1112,24 @@ private void validateTermValueSetExpandedAndChildrenV1(String theValueSetName, C\n \t\t\tassertEquals(theCodeSystem.getConcept().size(), termValueSet.getConcepts().size());\n \t\t\tassertEquals(TermValueSetPreExpansionStatusEnum.EXPANDED, termValueSet.getExpansionStatus());\n \n-\t\t\tTermValueSetConcept concept = termValueSet.getConcepts().get(0);\n-\t\t\tourLog.info(\"Concept:\\n\" + concept.toString());\n-\t\t\tassertEquals(\"http://acme.org\", concept.getSystem());\n-\t\t\tassertEquals(\"1\", concept.getSystemVersion());\n-\t\t\tassertEquals(\"8450-9\", concept.getCode());\n-\t\t\tassertEquals(\"Systolic blood pressure--expiration\", concept.getDisplay());\n-\t\t\tassertEquals(2, concept.getDesignations().size());\n-\t\t\tassertEquals(0, concept.getOrder());\n-\n-\t\t\tTermValueSetConceptDesignation designation = concept.getDesignations().get(0);\n-\t\t\tassertEquals(\"nl\", designation.getLanguage());\n-\t\t\tassertEquals(\"http://snomed.info/sct\", designation.getUseSystem());\n-\t\t\tassertEquals(\"900000000000013009\", designation.getUseCode());\n-\t\t\tassertEquals(\"Synonym\", designation.getUseDisplay());\n-\t\t\tassertEquals(\"Systolische bloeddruk - expiratie\", designation.getValue());\n-\n-\t\t\tdesignation = concept.getDesignations().get(1);\n-\t\t\tassertEquals(\"sv\", designation.getLanguage());\n-\t\t\tassertEquals(\"http://snomed.info/sct\", designation.getUseSystem());\n-\t\t\tassertEquals(\"900000000000013009\", designation.getUseCode());\n-\t\t\tassertEquals(\"Synonym\", designation.getUseDisplay());\n-\t\t\tassertEquals(\"Systoliskt blodtryck - utg\u00e5ng\", designation.getValue());\n-\n-\t\t\tconcept = termValueSet.getConcepts().get(1);\n-\t\t\tourLog.info(\"Concept:\\n\" + concept.toString());\n-\t\t\tassertEquals(\"http://acme.org\", concept.getSystem());\n-\t\t\tassertEquals(\"1\", concept.getSystemVersion());\n-\t\t\tassertEquals(\"11378-7\", concept.getCode());\n-\t\t\tassertEquals(\"Systolic blood pressure at First encounter\", concept.getDisplay());\n-\t\t\tassertEquals(0, concept.getDesignations().size());\n-\t\t\tassertEquals(1, concept.getOrder());\n+\t\t\tTermValueSetConcept concept = assertTermValueSetContainsConceptAndIsInDeclaredOrder(termValueSet, \"http://acme.org\", \"8450-9\", \"Systolic blood pressure--expiration\", 2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMyOTkyNw==", "bodyText": "Commenting these out will use the default offset and count values for this test. Below, you've also commented out the related assertions.\nDid you forget to uncomment these? The test name indicates count is relevant to the test.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534329927", "createdAt": "2020-12-02T17:00:21Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/test/java/ca/uhn/fhir/jpa/term/ValueSetExpansionR4Test.java", "diffHunk": "@@ -826,62 +660,31 @@ public void testExpandTermValueSetAndChildrenWithCountWithClientAssignedId() thr\n \n \t\tmyTermSvc.preExpandDeferredValueSetsToTerminologyTables();\n \n-\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n-\t\t\t.setOffset(0)\n-\t\t\t.setCount(23);\n-\t\tValueSet expandedValueSet = myTermSvc.expandValueSet(options, valueSet);\n+//\t\tValueSetExpansionOptions options = new ValueSetExpansionOptions()\n+//\t\t\t.setOffset(0)\n+//\t\t\t.setCount(23);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 454}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMzNjkwMQ==", "bodyText": "What's the impact of this change?", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534336901", "createdAt": "2020-12-02T17:10:09Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -885,68 +886,41 @@ private Boolean expandValueSetHandleIncludeOrExcludeUsingDatabase(IValueSetConce\n \t\t/*\n \t\t * Ok, let's use hibernate search to build the expansion\n \t\t */\n-\t\tQueryBuilder qb = em.getSearchFactory().buildQueryBuilder().forEntity(TermConcept.class).get();\n-\t\tBooleanJunction<?> bool = qb.bool();\n+\t\t//Manually building a predicate since we need to throw it around.\n+\t\tSearchPredicateFactory predicate = searchSession.scope(TermConcept.class).predicate();\n \n-\t\tbool.must(qb.keyword().onField(\"myCodeSystemVersionPid\").matching(csv.getPid()).createQuery());\n+\t\t//Build the top-level expansion on filters.\n+\t\tPredicateFinalStep step = predicate.bool(b -> {\n+\t\t\tb.must(predicate.match().field(\"myCodeSystemVersionPid\").matching(csv.getPid()));\n \n-\t\tif (theExpansionFilter.hasCode()) {\n-\t\t\tbool.must(qb.keyword().onField(\"myCode\").matching(theExpansionFilter.getCode()).createQuery());\n-\t\t}\n-\n-\t\t/*\n-\t\t * Filters\n-\t\t */\n-\t\tString codeSystemUrlAndVersion;\n-\t\tif (includeOrExcludeVersion != null) {\n-\t\t\tcodeSystemUrlAndVersion = theSystem + \"|\" + includeOrExcludeVersion;\n-\t\t} else {\n-\t\t\tcodeSystemUrlAndVersion = theSystem;\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n-\t\t\thandleFilter(codeSystemUrlAndVersion, qb, bool, nextFilter);\n-\t\t}\n-\n-\t\tQuery luceneQuery = bool.createQuery();\n-\n-\t\t/*\n-\t\t * Include/Exclude Concepts\n-\t\t */\n-\t\tList<Term> codes = theIncludeOrExclude\n-\t\t\t.getConcept()\n-\t\t\t.stream()\n-\t\t\t.filter(Objects::nonNull)\n-\t\t\t.map(ValueSet.ConceptReferenceComponent::getCode)\n-\t\t\t.filter(StringUtils::isNotBlank)\n-\t\t\t.map(t -> new Term(\"myCode\", t))\n-\t\t\t.collect(Collectors.toList());\n-\t\tif (codes.size() > 0) {\n+\t\t\tif (theExpansionFilter.hasCode()) {\n+\t\t\t\tb.must(predicate.match().field(\"myCode\").matching(theExpansionFilter.getCode()));\n+\t\t\t}\n \n-\t\t\tBooleanQuery.Builder builder = new BooleanQuery.Builder();\n-\t\t\tbuilder.setMinimumNumberShouldMatch(1);\n-\t\t\tfor (Term nextCode : codes) {\n-\t\t\t\tbuilder.add(new TermQuery(nextCode), BooleanClause.Occur.SHOULD);\n+\t\t\tString codeSystemUrlAndVersion = buildCodeSystemUrlAndVersion(theSystem, includeOrExcludeVersion);\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theIncludeOrExclude.getFilter()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n+\t\t\t}\n+\t\t\tfor (ValueSet.ConceptSetFilterComponent nextFilter : theExpansionFilter.getFilters()) {\n+\t\t\t\thandleFilter(codeSystemUrlAndVersion, predicate, b, nextFilter);\n \t\t\t}\n+\t\t});\n \n-\t\t\tluceneQuery = new BooleanQuery.Builder()\n-\t\t\t\t.add(luceneQuery, BooleanClause.Occur.MUST)\n-\t\t\t\t.add(builder.build(), BooleanClause.Occur.MUST)\n-\t\t\t\t.build();\n+\t\tPredicateFinalStep expansionStep = buildExpansionPredicate(theIncludeOrExclude, predicate);\n+\t\tfinal PredicateFinalStep finishedQuery;\n+\t\tif (expansionStep == null) {\n+\t\t\tfinishedQuery = step;\n+\t\t} else {\n+\t\t\tfinishedQuery = predicate.bool().must(step).must(expansionStep);\n \t\t}\n \n-\t\t/*\n-\t\t * Execute the query\n-\t\t */\n-\t\tFullTextQuery jpaQuery = em.createFullTextQuery(luceneQuery, TermConcept.class);\n-\n \t\t/*\n \t\t * DM 2019-08-21 - Processing slows after any ValueSets with many codes explicitly identified. This might\n \t\t * be due to the dark arts that is memory management. Will monitor but not do anything about this right now.\n \t\t */\n-\t\tBooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//BooleanQuery.setMaxClauseCount(SearchBuilder.getMaximumPageSize());\n+\t\t//TODO GGG HS looks like we can't set max clause count, but it can be set server side.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0MDMwMQ==", "bodyText": "This looks correct to me. There are related tests (or should be) so if they're happy, so am I.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534340301", "createdAt": "2020-12-02T17:15:08Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.REGEX) {\n+\n+\t\t\t/*\n+\t\t\t * We treat the regex filter as a match on the regex\n+\t\t\t * anywhere in the property string. The spec does not\n+\t\t\t * say whether or not this is the right behaviour, but\n+\t\t\t * there are examples that seem to suggest that it is.\n+\t\t\t */\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tif (value.endsWith(\"$\")) {\n+\t\t\t\tvalue = value.substring(0, value.length() - 1);\n+\t\t\t} else if (!value.endsWith(\".*\")) {\n+\t\t\t\tvalue = value + \".*\";\n+\t\t\t}\n+\t\t\tif (!value.startsWith(\"^\") && !value.startsWith(\".*\")) {\n+\t\t\t\tvalue = \".*\" + value;\n+\t\t\t} else if (value.startsWith(\"^\")) {\n+\t\t\t\tvalue = value.substring(1);\n+\t\t\t}\n+\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\tRegexpQuery query = new RegexpQuery(term);\n+\t\t\t//TODO GGG HS write the equivalent ES Query here.\n+\t\t\ttheB.must(theF.extension(LuceneExtension.get()).fromLuceneQuery(query));\n+\n+\t\t\t//Given that we want to be backend-agnostic, we can't really suport RegExpQuery here as it is lucene based. Will\n+\t\t\t//Probably have to replace with wildcard query :https://docs.jboss.org/hibernate/search/6.0/reference/en-US/html_single/#search-dsl-predicate-wildcard.\n+\t\t\t//This query is _almost certainly wrong right now_\n+\t\t\t//theB.must(theF.match().field(term.field()).matching(term.text()));\n+//\t\t\ttheB.must(theF.match().field(term.field()).matching(term.text()));\n+\n+\n+\t\t} else {\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\ttheB.must(theF.match().field(term.field()).matching(term.text()));\n+\n \t\t}\n \t}\n \n-\tprivate boolean isCodeSystemLoinc(String theSystem) {\n-\t\treturn ITermLoaderSvc.LOINC_URI.equals(theSystem);\n-\t}\n+\tprivate void handleFilterLoincCopyright(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n \n-\tprivate void handleFilterDisplay(QueryBuilder theQb, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\tif (theFilter.getProperty().equals(\"display:exact\") && theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n-\t\t\taddDisplayFilterExact(theQb, theBool, theFilter);\n-\t\t} else if (theFilter.getProperty().equals(\"display\") && theFilter.getOp() == ValueSet.FilterOperator.EQUAL) {\n-\t\t\tif (theFilter.getValue().trim().contains(\" \")) {\n-\t\t\t\taddDisplayFilterExact(theQb, theBool, theFilter);\n-\t\t\t} else {\n-\t\t\t\taddDisplayFilterInexact(theQb, theBool, theFilter);\n+\t\t\tString copyrightFilterValue = defaultString(theFilter.getValue()).toLowerCase();\n+\t\t\tswitch (copyrightFilterValue) {\n+\t\t\t\tcase \"3rdparty\":\n+\t\t\t\t\tlogFilteringValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n+\t\t\t\t\taddFilterLoincCopyright3rdParty(theF, theB);\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase \"loinc\":\n+\t\t\t\t\tlogFilteringValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n+\t\t\t\t\taddFilterLoincCopyrightLoinc(theF, theB);\n+\t\t\t\t\tbreak;\n+\t\t\t\tdefault:\n+\t\t\t\t\tthrowInvalidRequestForValueOnProperty(theFilter.getValue(), theFilter.getProperty());\n \t\t\t}\n-\t\t}\n-\t}\n \n-\tprivate void addDisplayFilterExact(QueryBuilder qb, BooleanJunction<?> bool, ValueSet.ConceptSetFilterComponent nextFilter) {\n-\t\tbool.must(qb.phrase().onField(\"myDisplay\").sentence(nextFilter.getValue()).createQuery());\n+\t\t} else {\n+\t\t\tthrowInvalidRequestForOpOnProperty(theFilter.getOp(), theFilter.getProperty());\n+\t\t}\n \t}\n \n-\tprivate void addDisplayFilterInexact(QueryBuilder qb, BooleanJunction<?> bool, ValueSet.ConceptSetFilterComponent nextFilter) {\n-\t\tQuery textQuery = qb\n-\t\t\t.phrase()\n-\t\t\t.withSlop(2)\n-\t\t\t.onField(\"myDisplay\").boostedTo(4.0f)\n-\t\t\t//.andField(\"myDisplayEdgeNGram\").boostedTo(2.0f)\n-\t\t\t.andField(\"myDisplayWordEdgeNGram\").boostedTo(1.0f)\n-\t\t\t// .andField(\"myDisplayPhonetic\").boostedTo(0.5f)\n-\t\t\t.sentence(nextFilter.getValue().toLowerCase()).createQuery();\n-\t\tbool.must(textQuery);\n+\tprivate void addFilterLoincCopyrightLoinc(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB) {\n+\t\ttheB.mustNot(theF.exists().field(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + \"EXTERNAL_COPYRIGHT_NOTICE\"));\n \t}\n \n-\tprivate void handleFilterConceptAndCode(String theSystem, QueryBuilder theQb, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\tTermConcept code = findCode(theSystem, theFilter.getValue())\n-\t\t\t.orElseThrow(() -> new InvalidRequestException(\"Invalid filter criteria - code does not exist: {\" + Constants.codeSystemWithDefaultDescription(theSystem) + \"}\" + theFilter.getValue()));\n-\n-\t\tif (theFilter.getOp() == ValueSet.FilterOperator.ISA) {\n-\t\t\tourLog.debug(\" * Filtering on codes with a parent of {}/{}/{}\", code.getId(), code.getCode(), code.getDisplay());\n-\t\t\ttheBool.must(theQb.keyword().onField(\"myParentPids\").matching(\"\" + code.getId()).createQuery());\n-\t\t} else {\n-\t\t\tthrow new InvalidRequestException(\"Don't know how to handle op=\" + theFilter.getOp() + \" on property \" + theFilter.getProperty());\n-\t\t}\n+\tprivate void addFilterLoincCopyright3rdParty(SearchPredicateFactory f, BooleanPredicateClausesStep<?> b) {\n+\t\t//TODO GGG HS These used to be Term term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + \"EXTERNAL_COPYRIGHT_NOTICE\", \".*\");, which was lucene-specific.\n+\t\t//TODO GGG HS ask diederik if this is equivalent.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 387}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0MjgyNg==", "bodyText": "I think this meets our needs. This is only used in debug logging. If there's something more meaningful that can be logged here, by all means add it. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534342826", "createdAt": "2020-12-02T17:18:44Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -967,22 +941,27 @@ private Boolean expandValueSetHandleIncludeOrExcludeUsingDatabase(IValueSetConce\n \t\t\t}\n \t\t}\n \n-\t\tjpaQuery.setMaxResults(maxResultsPerBatch);\n-\t\tjpaQuery.setFirstResult(theQueryIndex * maxResultsPerBatch);\n+//\t\tjpaQuery.setMaxResults(maxResultsPerBatch);\n+//\t\tjpaQuery.setFirstResult(theQueryIndex * maxResultsPerBatch);\n \n \t\tourLog.debug(\"Beginning batch expansion for {} with max results per batch: {}\", (theAdd ? \"inclusion\" : \"exclusion\"), maxResultsPerBatch);\n \n \t\tStopWatch swForBatch = new StopWatch();\n \t\tAtomicInteger countForBatch = new AtomicInteger(0);\n \n-\t\tList<?> resultList = jpaQuery.getResultList();\n-\t\tint resultsInBatch = resultList.size();\n-\t\tint firstResult = jpaQuery.getFirstResult();\n+\t\tSearchQuery<TermConcept> termConceptsQuery = searchSession.search(TermConcept.class)\n+\t\t\t.where(f -> finishedQuery).toQuery();\n+\n+\t\tSystem.out.println(\"About to query:\" +  termConceptsQuery.queryString());\n+\t\tList<TermConcept> termConcepts = termConceptsQuery.fetchHits(theQueryIndex * maxResultsPerBatch, maxResultsPerBatch);\n+\n+\n+\t\tint resultsInBatch = termConcepts.size();\n+\t\tint firstResult = theQueryIndex * maxResultsPerBatch;// TODO GGG HS we lose the ability to check the index of the first result, so just best-guessing it here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NDEwNA==", "bodyText": "Nitpick! Meaningful names make the code more readable.", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534344104", "createdAt": "2020-12-02T17:20:30Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 283}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NTIwNg==", "bodyText": "Nitpick! If this isn't needed, can it be removed?", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534345206", "createdAt": "2020-12-02T17:21:58Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1188,37 +1294,55 @@ private void addLoincFilterAncestorIn(String theSystem, BooleanJunction<?> theBo\n \t}\n \n \t@SuppressWarnings(\"EnumSwitchStatementWhichMissesCases\")\n-\tprivate void handleFilterLoincDescendant(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n+\tprivate void handleFilterLoincDescendant(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n \t\tswitch (theFilter.getOp()) {\n \t\t\tcase EQUAL:\n-\t\t\t\taddLoincFilterDescendantEqual(theSystem, theBool, theFilter);\n+\t\t\t\taddLoincFilterDescendantEqual(theSystem, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase IN:\n-\t\t\t\taddLoincFilterDescendantIn(theSystem, theBool, theFilter);\n+\t\t\t\taddLoincFilterDescendantIn(theSystem, f,b , theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n \t\t\t\tthrow new InvalidRequestException(\"Don't know how to handle op=\" + theFilter.getOp() + \" on property \" + theFilter.getProperty());\n \t\t}\n \t}\n \n-\tprivate void addLoincFilterDescendantEqual(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n-\t\taddLoincFilterDescendantEqual(theSystem, theBool, theFilter.getProperty(), theFilter.getValue());\n-\t}\n \n-\tprivate void addLoincFilterDescendantEqual(String theSystem, BooleanJunction<?> theBool, String theProperty, String theValue) {\n-\t\tList<Term> terms = getDescendantTerms(theSystem, theProperty, theValue);\n-\t\ttheBool.must(new TermsQuery(terms));\n+\tprivate void addLoincFilterDescendantEqual(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\taddLoincFilterDescendantEqual(theSystem, f, b, theFilter.getProperty(), theFilter.getValue());\n \t}\n \n-\tprivate void addLoincFilterDescendantIn(String theSystem, BooleanJunction<?> theBool, ValueSet.ConceptSetFilterComponent theFilter) {\n+\tprivate void addLoincFilterDescendantIn(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, ValueSet.ConceptSetFilterComponent theFilter) {\n \t\tString[] values = theFilter.getValue().split(\",\");\n \t\tList<Term> terms = new ArrayList<>();\n \t\tfor (String value : values) {\n \t\t\tterms.addAll(getDescendantTerms(theSystem, theFilter.getProperty(), value));\n \t\t}\n-\t\ttheBool.must(new TermsQuery(terms));\n+\t\tsearchByParentPids(f, b, terms);\n+\t}\n+\n+\tprivate void addLoincFilterDescendantEqual(String theSystem, SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, String theProperty, String theValue) {\n+\t\tList<Term> terms = getDescendantTerms(theSystem, theProperty, theValue);\n+\t\tsearchByParentPids(f, b, terms);\n \t}\n \n+\tprivate void searchByParentPids(SearchPredicateFactory f, BooleanPredicateClausesStep<?> b, List<Term> theTerms) {\n+\t\tList<Long> parentPids = convertTermsToParentPids(theTerms);\n+\t\tb.must(f.bool(innerB -> {\n+\t\t\tparentPids.forEach(pid -> innerB.should(f.match().field(theTerms.get(0).field()).matching(pid)));\n+\t\t}));\n+\n+//\t\tparentPids.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 604}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM0NTcxNQ==", "bodyText": "Lots of TODOs in this file. Let me know if/when it needs another review. : )", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#discussion_r534345715", "createdAt": "2020-12-02T17:22:41Z", "author": {"login": "dmuylwyk"}, "path": "hapi-fhir-jpaserver-base/src/main/java/ca/uhn/fhir/jpa/term/BaseTermReadSvcImpl.java", "diffHunk": "@@ -1030,149 +1049,236 @@ private void handleFilter(String theCodeSystemIdentifier, QueryBuilder theQb, Bo\n \t\tswitch (theFilter.getProperty()) {\n \t\t\tcase \"display:exact\":\n \t\t\tcase \"display\":\n-\t\t\t\thandleFilterDisplay(theQb, theBool, theFilter);\n+\t\t\t\thandleFilterDisplay(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"concept\":\n \t\t\tcase \"code\":\n-\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, theQb, theBool, theFilter);\n+\t\t\t\thandleFilterConceptAndCode(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"parent\":\n \t\t\tcase \"child\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincParentChild(theBool, theFilter);\n+\t\t\t\thandleFilterLoincParentChild(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"ancestor\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincAncestor(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincAncestor2(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"descendant\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, theBool, theFilter);\n+\t\t\t\thandleFilterLoincDescendant(theCodeSystemIdentifier, f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tcase \"copyright\":\n \t\t\t\tisCodeSystemLoincOrThrowInvalidRequestException(theCodeSystemIdentifier, theFilter.getProperty());\n-\t\t\t\thandleFilterLoincCopyright(theBool, theFilter);\n+\t\t\t\thandleFilterLoincCopyright(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t\tdefault:\n-\t\t\t\thandleFilterRegex(theBool, theFilter);\n+\t\t\t\thandleFilterRegex(f, b, theFilter);\n \t\t\t\tbreak;\n \t\t}\n \t}\n \n-\tprivate void isCodeSystemLoincOrThrowInvalidRequestException(String theSystemIdentifier, String theProperty) {\n-\t\tString systemUrl = getUrlFromIdentifier(theSystemIdentifier);\n-\t\tif (!isCodeSystemLoinc(systemUrl)) {\n-\t\t\tthrow new InvalidRequestException(\"Invalid filter, property \" + theProperty + \" is LOINC-specific and cannot be used with system: \" + systemUrl);\n+\tprivate void handleFilterRegex(SearchPredicateFactory theF, BooleanPredicateClausesStep<?> theB, ValueSet.ConceptSetFilterComponent theFilter) {\n+\t\tif (theFilter.getOp() == ValueSet.FilterOperator.REGEX) {\n+\n+\t\t\t/*\n+\t\t\t * We treat the regex filter as a match on the regex\n+\t\t\t * anywhere in the property string. The spec does not\n+\t\t\t * say whether or not this is the right behaviour, but\n+\t\t\t * there are examples that seem to suggest that it is.\n+\t\t\t */\n+\t\t\tString value = theFilter.getValue();\n+\t\t\tif (value.endsWith(\"$\")) {\n+\t\t\t\tvalue = value.substring(0, value.length() - 1);\n+\t\t\t} else if (!value.endsWith(\".*\")) {\n+\t\t\t\tvalue = value + \".*\";\n+\t\t\t}\n+\t\t\tif (!value.startsWith(\"^\") && !value.startsWith(\".*\")) {\n+\t\t\t\tvalue = \".*\" + value;\n+\t\t\t} else if (value.startsWith(\"^\")) {\n+\t\t\t\tvalue = value.substring(1);\n+\t\t\t}\n+\n+\t\t\tTerm term = new Term(TermConceptPropertyBinder.CONCEPT_FIELD_PROPERTY_PREFIX + theFilter.getProperty(), value);\n+\t\t\tRegexpQuery query = new RegexpQuery(term);\n+\t\t\t//TODO GGG HS write the equivalent ES Query here.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8675c1950bc0c9e3a9ce7268479532495072307"}, "originalPosition": 306}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2d6faf39c6c7b7e9654988cd350d9e4423d26e6", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d2d6faf39c6c7b7e9654988cd350d9e4423d26e6", "committedDate": "2020-12-02T18:40:44Z", "message": " update testst, remove todos"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f7ab4b03de2c9fa2f6ba882482f8fdbf80a0e61", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/2f7ab4b03de2c9fa2f6ba882482f8fdbf80a0e61", "committedDate": "2020-12-02T20:47:53Z", "message": "Add hibernate props provider method, add elastic regexp query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd2b2b74871e94a68da49139da832822d059b883", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/bd2b2b74871e94a68da49139da832822d059b883", "committedDate": "2020-12-03T04:14:41Z", "message": "Add todo for high level client builder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c873ca2dfa0e56d9bea73f7af0f86d824312cd0d", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/c873ca2dfa0e56d9bea73f7af0f86d824312cd0d", "committedDate": "2020-12-03T14:16:13Z", "message": "Modify ElasticsearchRestClientFactory to support HTTPS hosts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a710d14c4339c0fff4693e08be60e5e18b4768bd", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/a710d14c4339c0fff4693e08be60e5e18b4768bd", "committedDate": "2020-12-03T14:34:00Z", "message": "Remove protocol extraction from rest url"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bbc2bbc3e6e7981fa562da335ac7b3470137380", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/8bbc2bbc3e6e7981fa562da335ac7b3470137380", "committedDate": "2020-12-04T00:15:23Z", "message": "do we even need to index this...?"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b7a4f72034b45e5ea6186a39cec001e6946aebf", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/7b7a4f72034b45e5ea6186a39cec001e6946aebf", "committedDate": "2020-12-04T00:56:09Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9f8e224333b6aa855774fd262ca93521566b389", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/a9f8e224333b6aa855774fd262ca93521566b389", "committedDate": "2020-12-04T02:13:34Z", "message": "remove purge of non-indexed resources"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f936c99b688f24f95d776babb0a007d9dffcdaab", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/f936c99b688f24f95d776babb0a007d9dffcdaab", "committedDate": "2020-12-04T04:25:02Z", "message": "Add longer timeout to testcontainers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "117e66b33f86893dfbd72c56c1e5f677637c24be", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/117e66b33f86893dfbd72c56c1e5f677637c24be", "committedDate": "2020-12-04T16:28:47Z", "message": "Add task to add docker CLI to azure pipeline via task, for testcontainers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "33c2a9b573b5a6d27e6561fc1ec10799dfa199d4", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/33c2a9b573b5a6d27e6561fc1ec10799dfa199d4", "committedDate": "2020-12-05T01:07:04Z", "message": "WIP remove this"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0832e6577f8efa60df135744b4ca044340ca121b", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0832e6577f8efa60df135744b4ca044340ca121b", "committedDate": "2020-12-05T01:40:44Z", "message": "Dont update version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "967f39def0f74cb0195a5a226334b4a4ba3f6953", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/967f39def0f74cb0195a5a226334b4a4ba3f6953", "committedDate": "2020-12-07T20:03:54Z", "message": "Add test for duplicate termconcepts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a64affd5e95c01b58a4be064e3a243a279dfbe71", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/a64affd5e95c01b58a4be064e3a243a279dfbe71", "committedDate": "2020-12-08T16:23:41Z", "message": "Use real hibernate ORM methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f578f0421f237cf2198d766e9a1d18870027693", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/3f578f0421f237cf2198d766e9a1d18870027693", "committedDate": "2020-12-08T16:54:38Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a37dd4f633d38c5dd2d4dafd28145e23256f11f", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/7a37dd4f633d38c5dd2d4dafd28145e23256f11f", "committedDate": "2020-12-08T16:54:45Z", "message": "merge issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57326c8c13cb5ebb983021194bcbe8968a28060e", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/57326c8c13cb5ebb983021194bcbe8968a28060e", "committedDate": "2020-12-08T17:33:40Z", "message": "Add partitionsettigns bean to match master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a593e2e55ae05ed61047b057f930202041b0cb3", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0a593e2e55ae05ed61047b057f930202041b0cb3", "committedDate": "2020-12-08T18:25:33Z", "message": "Trying to debug testcontainers on azure..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "36ea97471a3b9dede5f2e8b57e68aae26525ecc1", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/36ea97471a3b9dede5f2e8b57e68aae26525ecc1", "committedDate": "2020-12-08T18:38:49Z", "message": "Trying to debug testcontainers on azure..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66c298a29cc355b8a6df883fe4c1293b99b3a118", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/66c298a29cc355b8a6df883fe4c1293b99b3a118", "committedDate": "2020-12-08T19:04:08Z", "message": "Run even on previous failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e8e26b73b943d56f8ff1904f4c7b67a1b7a7b41", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/1e8e26b73b943d56f8ff1904f4c7b67a1b7a7b41", "committedDate": "2020-12-08T20:27:45Z", "message": "Fix testcontainer port binds"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5c4622daf1df482cba39f250be6396b3685cf4b", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/f5c4622daf1df482cba39f250be6396b3685cf4b", "committedDate": "2020-12-08T21:43:49Z", "message": "Add full text logs attaching, and test reporting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d99a050faae353733b03a3a98e29bd27b621410", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/1d99a050faae353733b03a3a98e29bd27b621410", "committedDate": "2020-12-08T21:52:55Z", "message": "I love yaml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "758f879bae035667ffce9def27f7a37ade9dfd8a", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/758f879bae035667ffce9def27f7a37ade9dfd8a", "committedDate": "2020-12-08T23:27:14Z", "message": "Remove comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5510f598c94e1fdea3c0c246e475c9deedc8070", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/f5510f598c94e1fdea3c0c246e475c9deedc8070", "committedDate": "2020-12-09T01:16:06Z", "message": "Refactor delta remove to not do a once-over traversal and flatten all children pre-delete. Resolves transaction commit boundary issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "081e97ca6423a910e4fcbd5be3bfe92d755e7a6e", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/081e97ca6423a910e4fcbd5be3bfe92d755e7a6e", "committedDate": "2020-12-09T02:19:38Z", "message": "Modify TX beheaviour"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e04c126d302c3e77cb0716bbba3aa0627252c3fc", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/e04c126d302c3e77cb0716bbba3aa0627252c3fc", "committedDate": "2020-12-09T04:00:51Z", "message": "wip"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61503e593a91d24b23d32b8e516dc11360394e23", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/61503e593a91d24b23d32b8e516dc11360394e23", "committedDate": "2020-12-09T14:40:33Z", "message": "Rework to use config and mocked beans for partition-aware lastN"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be93ba120daa63c869a7e149d00b607f9d8d3dde", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/be93ba120daa63c869a7e149d00b607f9d8d3dde", "committedDate": "2020-12-09T15:04:51Z", "message": "rework to not use beans and just inject vars i need for test, keps test envs cleaner"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7797d32b8fce607d8c2c0514196aa943bc13558", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d7797d32b8fce607d8c2c0514196aa943bc13558", "committedDate": "2020-12-09T16:44:59Z", "message": "update azure pipeline to only copy test results"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8ffdc3a7f9574092d6e2906730c2e26b9ba9077", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/e8ffdc3a7f9574092d6e2906730c2e26b9ba9077", "committedDate": "2020-12-09T16:57:16Z", "message": "Remove erroneous publish"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95c8f35defc077f4eca226fb670a1f6d38314e85", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/95c8f35defc077f4eca226fb670a1f6d38314e85", "committedDate": "2020-12-09T19:28:48Z", "message": "Always get test logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8534d86d271b18a5a6248610b86d3ba159bc9387", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/8534d86d271b18a5a6248610b86d3ba159bc9387", "committedDate": "2020-12-09T20:38:25Z", "message": "Make it so indexing works,"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f72e71fd3c6767e7cb879631246ee4097e3c20e5", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/f72e71fd3c6767e7cb879631246ee4097e3c20e5", "committedDate": "2020-12-09T21:47:05Z", "message": "Add todos"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fed4d2b0f1f77c7814c3a8c9324b5aede2a5839", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4fed4d2b0f1f77c7814c3a8c9324b5aede2a5839", "committedDate": "2020-12-10T18:33:44Z", "message": "revert deleteByPid"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d79ee6dea1554a4e0d446ff80a188216daa0fa0", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0d79ee6dea1554a4e0d446ff80a188216daa0fa0", "committedDate": "2020-12-14T17:05:23Z", "message": "Work on test fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51fed052a6406e0ed78169509d252af432446ab7", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/51fed052a6406e0ed78169509d252af432446ab7", "committedDate": "2020-12-15T11:21:56Z", "message": "Test fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e6a91571f206de56ef992eab2aa1d0322c0a340", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/5e6a91571f206de56ef992eab2aa1d0322c0a340", "committedDate": "2020-12-15T19:36:56Z", "message": "Test fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54af1ff7e8d8b3437278f35896fde37abcd976fe", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/54af1ff7e8d8b3437278f35896fde37abcd976fe", "committedDate": "2020-12-15T22:00:51Z", "message": "Another test fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "02190210d483788cdb3357eba430c06f5b804bbb", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/02190210d483788cdb3357eba430c06f5b804bbb", "committedDate": "2020-12-15T22:29:45Z", "message": "Test fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a168e715ba28d553330f0ec75e51bf2103063d8", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/4a168e715ba28d553330f0ec75e51bf2103063d8", "committedDate": "2020-12-16T13:53:32Z", "message": "Work on tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c7ebb4d144c4cda0820326b7c27258824e4f14c", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/0c7ebb4d144c4cda0820326b7c27258824e4f14c", "committedDate": "2020-12-17T14:12:31Z", "message": "Test fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95c25459d50a77b80aef6cde187cd87145332e4e", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/95c25459d50a77b80aef6cde187cd87145332e4e", "committedDate": "2020-12-17T16:24:41Z", "message": "All tests passing locally"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56a373fcdf4c43fcac18c0612f8b6e4d47acef62", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/56a373fcdf4c43fcac18c0612f8b6e4d47acef62", "committedDate": "2020-12-17T17:21:29Z", "message": "Merge branch 'master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eed79620c75d72df016b09a405ea183afa6122e4", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/eed79620c75d72df016b09a405ea183afa6122e4", "committedDate": "2020-12-17T18:22:09Z", "message": "Fix test failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20fad72f89b04faa516f2d4a143d9abb799d08a8", "author": {"user": {"login": "jamesagnew", "name": "James Agnew"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/20fad72f89b04faa516f2d4a143d9abb799d08a8", "committedDate": "2020-12-17T19:44:04Z", "message": "FIx build error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "533eab33fc56dbd6cd69cf7e2975b3e77f0ea522", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/533eab33fc56dbd6cd69cf7e2975b3e77f0ea522", "committedDate": "2021-01-04T15:16:40Z", "message": "Merge branch 'master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e019584a5fe752514ddae1c5e9f4149df339b648", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/e019584a5fe752514ddae1c5e9f4149df339b648", "committedDate": "2021-01-04T15:16:59Z", "message": "Rename usages of HibernateDialectProvider -> HibernatePropertiesProvider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61645fd39ba03b0887458fb0a4b9f9b760af707f", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/61645fd39ba03b0887458fb0a4b9f9b760af707f", "committedDate": "2021-01-05T17:53:35Z", "message": "Update ngram of token filters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8f5be175ce94a43afead560ef6cc87aad501c9a", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/d8f5be175ce94a43afead560ef6cc87aad501c9a", "committedDate": "2021-01-05T18:12:55Z", "message": "Tidying"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db5de316fcea82506d4a9ebab39911187471411f", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/db5de316fcea82506d4a9ebab39911187471411f", "committedDate": "2021-01-05T18:59:23Z", "message": "subvert the purpose of hibernate elastic props builder to inject template"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad468c5ec12f319df750f8f45700b1062430a13b", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/ad468c5ec12f319df750f8f45700b1062430a13b", "committedDate": "2021-01-05T20:47:49Z", "message": "dead space"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5d5c4ebc33464b5c6a839552f341c48f35f31ec", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/a5d5c4ebc33464b5c6a839552f341c48f35f31ec", "committedDate": "2021-01-05T20:48:16Z", "message": "Merge remote-tracking branch 'origin/master' into gg-20201120-bump-to-hibernatesearch-beta"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a3f507dbfdfa82c88e380cd921927d61c679560", "author": {"user": {"login": "tadgh", "name": "Tadgh"}}, "url": "https://github.com/hapifhir/hapi-fhir/commit/7a3f507dbfdfa82c88e380cd921927d61c679560", "committedDate": "2021-01-05T20:49:54Z", "message": "Rename changed class"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMTk3MjYx", "url": "https://github.com/hapifhir/hapi-fhir/pull/2190#pullrequestreview-562197261", "createdAt": "2021-01-05T22:56:54Z", "commit": {"oid": "7a3f507dbfdfa82c88e380cd921927d61c679560"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3799, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}