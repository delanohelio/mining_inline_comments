{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ1ODMxMTMx", "number": 1817, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwODowMDo1OVrOFOBxYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwODowMDo1OVrOFOBxYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwMjUzNDExOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFExceptionInVertex.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QwODowMDo1OVrOISjfJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxMzoyNjoyMlrOIUcNxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMyNjY5NQ==", "bodyText": "I know it will be mostly just us using this - but it would be helpfull to document the accepted format (and probably throw an exception if something else is passed)", "url": "https://github.com/apache/hive/pull/1817#discussion_r556326695", "createdAt": "2021-01-13T08:00:59Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFExceptionInVertex.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.udf.generic;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;\n+import org.apache.hadoop.hive.ql.exec.tez.TezProcessor;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantIntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantStringObjectInspector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class implements the UDF which can throw an exception in arbitrary vertex (typically mapper)\n+ * / task / task attempt. For throwing exception in reducer side, where most probably\n+ * GroupByOperator codepath applies, GenericUDAFExceptionInVertex is used.\n+ */\n+@Description(name = \"exception_in_vertex_udf\", value = \"_FUNC_(vertexName, taskNumberExpression, taskAttemptNumberExpression)\")\n+public class GenericUDFExceptionInVertex extends GenericUDF {\n+  private static final Logger LOG = LoggerFactory.getLogger(GenericUDFExceptionInVertex.class);\n+\n+  private String vertexName;\n+  private String taskNumberExpr;\n+  private String taskAttemptNumberExpr;\n+  private String currentVertexName;\n+  private int currentTaskNumber;\n+  private int currentTaskAttemptNumber;\n+  private boolean alreadyCheckedAndPassed;\n+\n+  @Override\n+  public ObjectInspector initialize(ObjectInspector[] parameters) throws UDFArgumentException {\n+    if (parameters.length < 2) {\n+      throw new UDFArgumentTypeException(-1,\n+          \"At least two argument is expected (fake column ref, vertex name)\");\n+    }\n+\n+    this.vertexName = getVertexName(parameters, 1);\n+    this.taskNumberExpr = getTaskNumber(parameters, 2);\n+    this.taskAttemptNumberExpr = getTaskAttemptNumber(parameters, 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7dd331879e49994ffac4e73e5ff519f6ddeaff7d"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ1NjUzNw==", "bodyText": "thanks for taking a look @kgyrtkirk! there are examples in exception_in_vertex_udf.q, do you think it's enough to mention it here?", "url": "https://github.com/apache/hive/pull/1817#discussion_r557456537", "createdAt": "2021-01-14T14:58:21Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFExceptionInVertex.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.udf.generic;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;\n+import org.apache.hadoop.hive.ql.exec.tez.TezProcessor;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantIntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantStringObjectInspector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class implements the UDF which can throw an exception in arbitrary vertex (typically mapper)\n+ * / task / task attempt. For throwing exception in reducer side, where most probably\n+ * GroupByOperator codepath applies, GenericUDAFExceptionInVertex is used.\n+ */\n+@Description(name = \"exception_in_vertex_udf\", value = \"_FUNC_(vertexName, taskNumberExpression, taskAttemptNumberExpression)\")\n+public class GenericUDFExceptionInVertex extends GenericUDF {\n+  private static final Logger LOG = LoggerFactory.getLogger(GenericUDFExceptionInVertex.class);\n+\n+  private String vertexName;\n+  private String taskNumberExpr;\n+  private String taskAttemptNumberExpr;\n+  private String currentVertexName;\n+  private int currentTaskNumber;\n+  private int currentTaskAttemptNumber;\n+  private boolean alreadyCheckedAndPassed;\n+\n+  @Override\n+  public ObjectInspector initialize(ObjectInspector[] parameters) throws UDFArgumentException {\n+    if (parameters.length < 2) {\n+      throw new UDFArgumentTypeException(-1,\n+          \"At least two argument is expected (fake column ref, vertex name)\");\n+    }\n+\n+    this.vertexName = getVertexName(parameters, 1);\n+    this.taskNumberExpr = getTaskNumber(parameters, 2);\n+    this.taskAttemptNumberExpr = getTaskAttemptNumber(parameters, 3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMyNjY5NQ=="}, "originalCommit": {"oid": "7dd331879e49994ffac4e73e5ff519f6ddeaff7d"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ1OTg4Mw==", "bodyText": "I was thinking to add some notes about it to the @Description - I would look there first in an UDF", "url": "https://github.com/apache/hive/pull/1817#discussion_r557459883", "createdAt": "2021-01-14T15:02:21Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFExceptionInVertex.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.udf.generic;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;\n+import org.apache.hadoop.hive.ql.exec.tez.TezProcessor;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantIntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantStringObjectInspector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class implements the UDF which can throw an exception in arbitrary vertex (typically mapper)\n+ * / task / task attempt. For throwing exception in reducer side, where most probably\n+ * GroupByOperator codepath applies, GenericUDAFExceptionInVertex is used.\n+ */\n+@Description(name = \"exception_in_vertex_udf\", value = \"_FUNC_(vertexName, taskNumberExpression, taskAttemptNumberExpression)\")\n+public class GenericUDFExceptionInVertex extends GenericUDF {\n+  private static final Logger LOG = LoggerFactory.getLogger(GenericUDFExceptionInVertex.class);\n+\n+  private String vertexName;\n+  private String taskNumberExpr;\n+  private String taskAttemptNumberExpr;\n+  private String currentVertexName;\n+  private int currentTaskNumber;\n+  private int currentTaskAttemptNumber;\n+  private boolean alreadyCheckedAndPassed;\n+\n+  @Override\n+  public ObjectInspector initialize(ObjectInspector[] parameters) throws UDFArgumentException {\n+    if (parameters.length < 2) {\n+      throw new UDFArgumentTypeException(-1,\n+          \"At least two argument is expected (fake column ref, vertex name)\");\n+    }\n+\n+    this.vertexName = getVertexName(parameters, 1);\n+    this.taskNumberExpr = getTaskNumber(parameters, 2);\n+    this.taskAttemptNumberExpr = getTaskAttemptNumber(parameters, 3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMyNjY5NQ=="}, "originalCommit": {"oid": "7dd331879e49994ffac4e73e5ff519f6ddeaff7d"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwNDcxMQ==", "bodyText": "sure, fixed in new commit", "url": "https://github.com/apache/hive/pull/1817#discussion_r558304711", "createdAt": "2021-01-15T13:26:22Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFExceptionInVertex.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.udf.generic;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.ql.exec.Description;\n+import org.apache.hadoop.hive.ql.exec.MapredContext;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;\n+import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;\n+import org.apache.hadoop.hive.ql.exec.tez.TezProcessor;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantIntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantStringObjectInspector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class implements the UDF which can throw an exception in arbitrary vertex (typically mapper)\n+ * / task / task attempt. For throwing exception in reducer side, where most probably\n+ * GroupByOperator codepath applies, GenericUDAFExceptionInVertex is used.\n+ */\n+@Description(name = \"exception_in_vertex_udf\", value = \"_FUNC_(vertexName, taskNumberExpression, taskAttemptNumberExpression)\")\n+public class GenericUDFExceptionInVertex extends GenericUDF {\n+  private static final Logger LOG = LoggerFactory.getLogger(GenericUDFExceptionInVertex.class);\n+\n+  private String vertexName;\n+  private String taskNumberExpr;\n+  private String taskAttemptNumberExpr;\n+  private String currentVertexName;\n+  private int currentTaskNumber;\n+  private int currentTaskAttemptNumber;\n+  private boolean alreadyCheckedAndPassed;\n+\n+  @Override\n+  public ObjectInspector initialize(ObjectInspector[] parameters) throws UDFArgumentException {\n+    if (parameters.length < 2) {\n+      throw new UDFArgumentTypeException(-1,\n+          \"At least two argument is expected (fake column ref, vertex name)\");\n+    }\n+\n+    this.vertexName = getVertexName(parameters, 1);\n+    this.taskNumberExpr = getTaskNumber(parameters, 2);\n+    this.taskAttemptNumberExpr = getTaskAttemptNumber(parameters, 3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMyNjY5NQ=="}, "originalCommit": {"oid": "7dd331879e49994ffac4e73e5ff519f6ddeaff7d"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 102, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}