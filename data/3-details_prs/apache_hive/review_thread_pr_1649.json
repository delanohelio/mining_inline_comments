{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0ODAzNjM4", "number": 1649, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTo0MzoyNFrOE8RkeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMDoyMTowNlrOE9KNNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjM3ODgwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTo0MzoyNFrOH4TRJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwODoyNjo1OVrOH5n9Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ==", "bodyText": "We do check if the element is present twice here -- add method already checks if the element is part of the Set so we dont need to call contains. I would just add a comment here instead.", "url": "https://github.com/apache/hive/pull/1649#discussion_r528797991", "createdAt": "2020-11-23T15:43:24Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);\n+        }\n+      }\n+    }\n+  }\n+\n+  protected void countValue(ColumnVector colVector, int i) {\n+    Object value = getValue(colVector, i);\n+    if (!uniqueObjects.contains(value)) {\n+      uniqueObjects.add(value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE3ODYwNA==", "bodyText": "yeah, thanks, forgot that Set takes care of uniqueness :)", "url": "https://github.com/apache/hive/pull/1649#discussion_r530178604", "createdAt": "2020-11-25T08:14:23Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);\n+        }\n+      }\n+    }\n+  }\n+\n+  protected void countValue(ColumnVector colVector, int i) {\n+    Object value = getValue(colVector, i);\n+    if (!uniqueObjects.contains(value)) {\n+      uniqueObjects.add(value);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ=="}, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE4NTU0Ng==", "bodyText": "btw, I copied this wrong approach from GenericUDAFCount, I'm fixing it there also", "url": "https://github.com/apache/hive/pull/1649#discussion_r530185546", "createdAt": "2020-11-25T08:26:59Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);\n+        }\n+      }\n+    }\n+  }\n+\n+  protected void countValue(ColumnVector colVector, int i) {\n+    Object value = getValue(colVector, i);\n+    if (!uniqueObjects.contains(value)) {\n+      uniqueObjects.add(value);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ=="}, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjM5NDQ0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTo0NjozMFrOH4Tamw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwODoxNjo0OFrOH5nnQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwMDQxMQ==", "bodyText": "Instead of updating the inherited count variable we could override getLongGroupResult() with uniqueObjects.size", "url": "https://github.com/apache/hive/pull/1649#discussion_r528800411", "createdAt": "2020-11-23T15:46:30Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE3OTkwNg==", "bodyText": "right! updating it", "url": "https://github.com/apache/hive/pull/1649#discussion_r530179906", "createdAt": "2020-11-25T08:16:48Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwMDQxMQ=="}, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjUyMDAzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorBytesCountDistinct.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNjowODo1MFrOH4Upmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwODoyMTozNlrOH5nxJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgyMDYzNQ==", "bodyText": "What is the benefit of returning Murmur hash directly here? Adding a String to the HashSet will also hash the input (so essentially we are hashing twice)", "url": "https://github.com/apache/hive/pull/1649#discussion_r528820635", "createdAt": "2020-11-23T16:08:50Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorBytesCountDistinct.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+/**\n+ * Bytes (String) implementation for VectorPTFEvaluatorCountDistinct.\n+ */\n+public class VectorPTFEvaluatorBytesCountDistinct extends VectorPTFEvaluatorCountDistinct {\n+\n+  public VectorPTFEvaluatorBytesCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  protected Object getValue(ColumnVector colVector, int i) {\n+    BytesColumnVector inV = (BytesColumnVector) colVector;\n+    return Murmur3.hash32(inV.vector[i], inV.start[i], inV.length[i], Murmur3.DEFAULT_SEED);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE4MjQzOA==", "bodyText": "I used hashing for memory considerations, I was hoping that this way the unique set will consume less memory (storing hashes instead of strings of arbitrary length)...now I think that we could be fine with storing strings and prevent additional hashing, as we tend to optimize CPU cycles instead of memory in the very-first round...I'll change this to new String(byte[])", "url": "https://github.com/apache/hive/pull/1649#discussion_r530182438", "createdAt": "2020-11-25T08:21:36Z", "author": {"login": "abstractdog"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorBytesCountDistinct.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+/**\n+ * Bytes (String) implementation for VectorPTFEvaluatorCountDistinct.\n+ */\n+public class VectorPTFEvaluatorBytesCountDistinct extends VectorPTFEvaluatorCountDistinct {\n+\n+  public VectorPTFEvaluatorBytesCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  protected Object getValue(ColumnVector colVector, int i) {\n+    BytesColumnVector inV = (BytesColumnVector) colVector;\n+    return Murmur3.hash32(inV.vector[i], inV.start[i], inV.length[i], Murmur3.DEFAULT_SEED);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgyMDYzNQ=="}, "originalCommit": {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTY1ODEyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMDoyMTowNlrOH5skEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMDoyMTowNlrOH5skEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI2MTAxMA==", "bodyText": "Thanks for taking care of this", "url": "https://github.com/apache/hive/pull/1649#discussion_r530261010", "createdAt": "2020-11-25T10:21:06Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java", "diffHunk": "@@ -180,14 +181,13 @@ public void iterate(AggregationBuffer agg, Object[] parameters)\n           if (((CountAgg) agg).uniqueObjects == null) {\n             ((CountAgg) agg).uniqueObjects = new HashSet<ObjectInspectorObject>();\n           }\n-          HashSet<ObjectInspectorObject> uniqueObjs = ((CountAgg) agg).uniqueObjects;\n+          Set<ObjectInspectorObject> uniqueObjs = ((CountAgg) agg).uniqueObjects;\n \n           ObjectInspectorObject obj = new ObjectInspectorObject(\n               ObjectInspectorUtils.copyToStandardObject(parameters, inputOI, ObjectInspectorCopyOption.JAVA),\n               outputOI);\n-          if (!uniqueObjs.contains(obj)) {\n-            uniqueObjs.add(obj);\n-          } else {\n+          boolean inserted = uniqueObjs.add(obj);\n+          if (!inserted){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86b53d35c302c7f92fd70aee52c67b896d6f40ba"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 224, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}