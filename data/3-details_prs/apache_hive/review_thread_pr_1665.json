{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE5Mjk5ODQ5", "number": 1665, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMDoyMDo1NlrOE4GAXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyODowM1rOE4ZkdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MjU0MTEwOnYy", "diffSide": "RIGHT", "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMDoyMDo1NlrOHx0CJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjoyMzowMlrOHx4ZNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk5NDc5MA==", "bodyText": "How can this be null?", "url": "https://github.com/apache/hive/pull/1665#discussion_r521994790", "createdAt": "2020-11-12T10:20:56Z", "author": {"login": "pvary"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static final ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR =\n+        Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder()\n+            .setNameFormat(\"Proactive-Eviction-Sweeper\").setDaemon(true).build());\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e9107fab7cbc403ae868387f7b4d6ddf180b93c"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA2NjIzMQ==", "bodyText": "See other comment.", "url": "https://github.com/apache/hive/pull/1665#discussion_r522066231", "createdAt": "2020-11-12T12:23:02Z", "author": {"login": "szlta"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static final ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR =\n+        Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder()\n+            .setNameFormat(\"Proactive-Eviction-Sweeper\").setDaemon(true).build());\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk5NDc5MA=="}, "originalCommit": {"oid": "8e9107fab7cbc403ae868387f7b4d6ddf180b93c"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MjU0OTc2OnYy", "diffSide": "RIGHT", "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMDoyMzowNFrOHx0Hhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjoyMjo1M1rOHx4Y6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk5NjE2Nw==", "bodyText": "Do not we want to create the executor here?", "url": "https://github.com/apache/hive/pull/1665#discussion_r521996167", "createdAt": "2020-11-12T10:23:04Z", "author": {"login": "pvary"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static final ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR =\n+        Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder()\n+            .setNameFormat(\"Proactive-Eviction-Sweeper\").setDaemon(true).build());\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {\n+            PROACTIVE_EVICTION_SWEEPER_EXECUTOR.shutdownNow();\n+          }\n+        }\n+      });\n+    }\n+\n+    protected Impl(Configuration conf) {\n+      proactiveEvictionEnabled = HiveConf.getBoolVar(conf, HiveConf.ConfVars.LLAP_IO_PROACTIVE_EVICTION_ENABLED);\n+      proactiveEvictionSweepIntervalInMs = HiveConf.getTimeVar(conf,\n+          HiveConf.ConfVars.LLAP_IO_PROACTIVE_EVICTION_SWEEP_INTERVAL, TimeUnit.MILLISECONDS);\n+\n+      if (proactiveEvictionEnabled) {\n+        PROACTIVE_EVICTION_SWEEPER_EXECUTOR.scheduleWithFixedDelay(new Runnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8e9107fab7cbc403ae868387f7b4d6ddf180b93c"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA2NjE1NA==", "bodyText": "Yes thanks for spotting this, looks like I was thinking about something like this when I put the null check in the static block :)", "url": "https://github.com/apache/hive/pull/1665#discussion_r522066154", "createdAt": "2020-11-12T12:22:53Z", "author": {"login": "szlta"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static final ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR =\n+        Executors.newSingleThreadScheduledExecutor(new ThreadFactoryBuilder()\n+            .setNameFormat(\"Proactive-Eviction-Sweeper\").setDaemon(true).build());\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {\n+            PROACTIVE_EVICTION_SWEEPER_EXECUTOR.shutdownNow();\n+          }\n+        }\n+      });\n+    }\n+\n+    protected Impl(Configuration conf) {\n+      proactiveEvictionEnabled = HiveConf.getBoolVar(conf, HiveConf.ConfVars.LLAP_IO_PROACTIVE_EVICTION_ENABLED);\n+      proactiveEvictionSweepIntervalInMs = HiveConf.getTimeVar(conf,\n+          HiveConf.ConfVars.LLAP_IO_PROACTIVE_EVICTION_SWEEP_INTERVAL, TimeUnit.MILLISECONDS);\n+\n+      if (proactiveEvictionEnabled) {\n+        PROACTIVE_EVICTION_SWEEPER_EXECUTOR.scheduleWithFixedDelay(new Runnable() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk5NjE2Nw=="}, "originalCommit": {"oid": "8e9107fab7cbc403ae868387f7b4d6ddf180b93c"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzA3NDc2OnYy", "diffSide": "RIGHT", "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo0NDowNlrOHx5Heg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMzowODo0NlrOHx6Aog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3ODA3NA==", "bodyText": "Maybe set it to null after shutdown?\nGenerally a good practice, it does not really matter here..", "url": "https://github.com/apache/hive/pull/1665#discussion_r522078074", "createdAt": "2020-11-12T12:44:06Z", "author": {"login": "pvary"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR = null;\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {\n+            PROACTIVE_EVICTION_SWEEPER_EXECUTOR.shutdownNow();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MjcwNg==", "bodyText": "Yeah I guess it makes no difference here.", "url": "https://github.com/apache/hive/pull/1665#discussion_r522092706", "createdAt": "2020-11-12T13:08:46Z", "author": {"login": "szlta"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/ProactiveEvictingCachePolicy.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.llap.cache;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.common.util.ShutdownHookManager;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * Interface for classes required to be able to receive notifyProactiveEvictionMark event. Had to be this way due to\n+ * how CacheContentsTracker is designed to wrap around actual cache policies.\n+ *\n+ * Implementing this interface is required but not sufficient for a cache policy to be proactive eviction supporting.\n+ * Such policies also need to extend the implementation below, so that the asynchronous sweeping is taken care of,\n+ * and they need to implement evictProactively() method.\n+ */\n+public interface ProactiveEvictingCachePolicy {\n+\n+  /**\n+   * Invoking this signals that new buffers have been marked for proactive eviction. Cache policies implementing this\n+   * need this information to correctly time sweep runs.\n+   */\n+  void notifyProactiveEvictionMark();\n+\n+  abstract class Impl implements ProactiveEvictingCachePolicy {\n+    protected final boolean proactiveEvictionEnabled;\n+    private final long proactiveEvictionSweepIntervalInMs;\n+    private static ScheduledExecutorService PROACTIVE_EVICTION_SWEEPER_EXECUTOR = null;\n+\n+    // Last sweep starts higher, so we don't trigger sweeps before the first mark\n+    AtomicLong lastMarkTime = new AtomicLong(0L);\n+    AtomicLong lastSweepTime = new AtomicLong(1L);\n+\n+    static {\n+      ShutdownHookManager.addShutdownHook(new Runnable() {\n+        @Override\n+        public void run() {\n+          if (PROACTIVE_EVICTION_SWEEPER_EXECUTOR != null) {\n+            PROACTIVE_EVICTION_SWEEPER_EXECUTOR.shutdownNow();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3ODA3NA=="}, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTc0NTgzOnYy", "diffSide": "RIGHT", "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/EvictionListener.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyNzo1MlrOHyS7bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxMjowMTo1M1rOHyrvbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUwMDk3NA==", "bodyText": "Why is this required?", "url": "https://github.com/apache/hive/pull/1665#discussion_r522500974", "createdAt": "2020-11-12T23:27:52Z", "author": {"login": "asinkovits"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/EvictionListener.java", "diffHunk": "@@ -20,4 +20,5 @@\n \n public interface EvictionListener {\n   void notifyEvicted(LlapCacheableBuffer buffer);\n+  void notifyEvictedBytes(long size);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkwNzUwMw==", "bodyText": "Good point, reworked in follow-up commit as discussed offline.", "url": "https://github.com/apache/hive/pull/1665#discussion_r522907503", "createdAt": "2020-11-13T12:01:53Z", "author": {"login": "szlta"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/cache/EvictionListener.java", "diffHunk": "@@ -20,4 +20,5 @@\n \n public interface EvictionListener {\n   void notifyEvicted(LlapCacheableBuffer buffer);\n+  void notifyEvictedBytes(long size);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUwMDk3NA=="}, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTc0NjQ1OnYy", "diffSide": "RIGHT", "path": "llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapIoImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyODowM1rOHyS72g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxMjowMzowMVrOHyrxKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUwMTA4Mg==", "bodyText": "I think this would make sense in the mark phase as well.", "url": "https://github.com/apache/hive/pull/1665#discussion_r522501082", "createdAt": "2020-11-12T23:28:03Z", "author": {"login": "asinkovits"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapIoImpl.java", "diffHunk": "@@ -151,8 +151,10 @@ private LlapIoImpl(Configuration conf) throws IOException {\n       LowLevelCachePolicy\n           realCachePolicy =\n           useLrfu ? new LowLevelLrfuCachePolicy(minAllocSize, totalMemorySize, conf) : new LowLevelFifoCachePolicy();\n-      // TODO: if realCachePolicy is not something that supports proactive caching\n-      // turn the feature off (LLAP_IO_PROACTIVE_EVICTION_ENABLED) and log it\n+      if (!(realCachePolicy instanceof ProactiveEvictingCachePolicy.Impl)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkwNzk0Nw==", "bodyText": "It would be very cumbersome to check this on HS2 side due to potentially different config files being used for HS2 and LLAP side. Also these services might get restarted independently from each other with different config.", "url": "https://github.com/apache/hive/pull/1665#discussion_r522907947", "createdAt": "2020-11-13T12:03:01Z", "author": {"login": "szlta"}, "path": "llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapIoImpl.java", "diffHunk": "@@ -151,8 +151,10 @@ private LlapIoImpl(Configuration conf) throws IOException {\n       LowLevelCachePolicy\n           realCachePolicy =\n           useLrfu ? new LowLevelLrfuCachePolicy(minAllocSize, totalMemorySize, conf) : new LowLevelFifoCachePolicy();\n-      // TODO: if realCachePolicy is not something that supports proactive caching\n-      // turn the feature off (LLAP_IO_PROACTIVE_EVICTION_ENABLED) and log it\n+      if (!(realCachePolicy instanceof ProactiveEvictingCachePolicy.Impl)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUwMTA4Mg=="}, "originalCommit": {"oid": "b8fae5273e8e8ce927fb56f61a2efdc3d40be452"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 242, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}