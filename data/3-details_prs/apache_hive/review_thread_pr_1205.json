{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ0MDY3NDQx", "number": 1205, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwODozNDo0NlrOEL-jag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjoxMjo0N1rOErJgfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwOTk0NjY2OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwODozNDo0NlrOGt0fIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMToxNTowNFrOGt57oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY5OTA0MA==", "bodyText": "please reuse parts of HookRunner for loading stuff\nand why would you need setAccessible ?", "url": "https://github.com/apache/hive/pull/1205#discussion_r450699040", "createdAt": "2020-07-07T08:34:46Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc4ODI1Nw==", "bodyText": "Thanks for the review! Like DefaultOomHook, the hook declared as private as nobody would access it  except the HiveServer2OomHookRunner.  In this case, the default constructor cannot be used directly to create a instance until calling setAccessible(true).  The hooks loaded by HookRunner::loadHooksFromConf should be declared as public access and I'm willing to follow this principal.", "url": "https://github.com/apache/hive/pull/1205#discussion_r450788257", "createdAt": "2020-07-07T11:15:04Z", "author": {"login": "dengzhhu653"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY5OTA0MA=="}, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwOTk0OTczOnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwODozNToyN1rOGt0g4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMzoyMjozMlrOGunywA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY5OTQ4OA==", "bodyText": "don't swallow exceptions...", "url": "https://github.com/apache/hive/pull/1205#discussion_r450699488", "createdAt": "2020-07-07T08:35:27Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);\n+          hooks.add((OomHookWithContext)ctor.newInstance());\n+        } catch (Exception e) {\n+          LOG.error(\"Skip adding oom hook '\" + hookClass + \"'\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUzOTY0OA==", "bodyText": "done", "url": "https://github.com/apache/hive/pull/1205#discussion_r451539648", "createdAt": "2020-07-08T13:22:32Z", "author": {"login": "dengzhhu653"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);\n+          hooks.add((OomHookWithContext)ctor.newInstance());\n+        } catch (Exception e) {\n+          LOG.error(\"Skip adding oom hook '\" + hookClass + \"'\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY5OTQ4OA=="}, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwOTk1NjE5OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwODozNzowNVrOGt0k2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMzoyMjo1NVrOGunzzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcwMDUwNw==", "bodyText": "why is this private?", "url": "https://github.com/apache/hive/pull/1205#discussion_r450700507", "createdAt": "2020-07-07T08:37:05Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);\n+          hooks.add((OomHookWithContext)ctor.newInstance());\n+        } catch (Exception e) {\n+          LOG.error(\"Skip adding oom hook '\" + hookClass + \"'\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public HiveServer2OomHookRunner(HiveConf hiveConf) {\n+    init(hiveConf);\n+  }\n+\n+  @VisibleForTesting\n+  public List<OomHookWithContext> getHooks() {\n+    return hooks;\n+  }\n+\n+  @Override\n+  public void run() {\n+    for (OomHookWithContext hook : hooks) {\n+      hook.run(context);\n+    }\n+  }\n+\n+  public static interface OomHookWithContext {\n+    public void run(OomHookContext context);\n+  }\n+\n+  public static class OomHookContext {\n+    private final HiveServer2 hiveServer2;\n+    public OomHookContext(HiveServer2 hiveServer2) {\n+      this.hiveServer2 = hiveServer2;\n+    }\n+    public HiveServer2 getHiveServer2() {\n+      return hiveServer2;\n+    }\n+  }\n+\n+  /**\n+   * Used as default oom hook\n+   */\n+  private static class DefaultOomHook implements OomHookWithContext {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUzOTkxOA==", "bodyText": "done", "url": "https://github.com/apache/hive/pull/1205#discussion_r451539918", "createdAt": "2020-07-08T13:22:55Z", "author": {"login": "dengzhhu653"}, "path": "service/src/java/org/apache/hive/service/server/HiveServer2OomHookRunner.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hive.common.JavaUtils;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.lang.reflect.Constructor;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class HiveServer2OomHookRunner implements Runnable {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveServer2OomHookRunner.class);\n+  private OomHookContext context;\n+  private final List<OomHookWithContext> hooks = new ArrayList<OomHookWithContext>();\n+\n+  HiveServer2OomHookRunner(HiveServer2 hiveServer2, HiveConf hiveConf) {\n+    context = new OomHookContext(hiveServer2);\n+    // The hs2 has not been initialized yet, hiveServer2.getHiveConf() would be null\n+    init(hiveConf);\n+  }\n+\n+  private void init(HiveConf hiveConf) {\n+    String csHooks = hiveConf.getVar(ConfVars.HIVE_SERVER2_OOM_HOOKS);\n+    if (!StringUtils.isBlank(csHooks)) {\n+      String[] hookClasses = csHooks.split(\",\");\n+      for (String hookClass : hookClasses) {\n+        try {\n+          Class clazz =  JavaUtils.loadClass(hookClass.trim());\n+          Constructor ctor = clazz.getDeclaredConstructor();\n+          ctor.setAccessible(true);\n+          hooks.add((OomHookWithContext)ctor.newInstance());\n+        } catch (Exception e) {\n+          LOG.error(\"Skip adding oom hook '\" + hookClass + \"'\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public HiveServer2OomHookRunner(HiveConf hiveConf) {\n+    init(hiveConf);\n+  }\n+\n+  @VisibleForTesting\n+  public List<OomHookWithContext> getHooks() {\n+    return hooks;\n+  }\n+\n+  @Override\n+  public void run() {\n+    for (OomHookWithContext hook : hooks) {\n+      hook.run(context);\n+    }\n+  }\n+\n+  public static interface OomHookWithContext {\n+    public void run(OomHookContext context);\n+  }\n+\n+  public static class OomHookContext {\n+    private final HiveServer2 hiveServer2;\n+    public OomHookContext(HiveServer2 hiveServer2) {\n+      this.hiveServer2 = hiveServer2;\n+    }\n+    public HiveServer2 getHiveServer2() {\n+      return hiveServer2;\n+    }\n+  }\n+\n+  /**\n+   * Used as default oom hook\n+   */\n+  private static class DefaultOomHook implements OomHookWithContext {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcwMDUwNw=="}, "originalCommit": {"oid": "bf425d08ea7662c4cc9e0af2e76d2c89737a7662"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzI1ODE0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjoxNToxOFrOHR-4BA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzozNjo0OFrOHSe1Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxNzk4OA==", "bodyText": "I think this should be only confVar", "url": "https://github.com/apache/hive/pull/1205#discussion_r488617988", "createdAt": "2020-09-15T12:15:18Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;\n+  private SessionState.LogHelper console;\n+\n+  public HooksLoader(HiveConf conf) {\n+    this.conf = conf;\n+    this.hooks = new Hooks[HookContext.HookType.values().length];\n+    for (int i = 0; i < hooks.length; i++) {\n+      hooks[i] = new Hooks();\n+    }\n+  }\n+\n+  public HooksLoader(HiveConf conf, SessionState.LogHelper console) {\n+    this(conf);\n+    this.console = console;\n+  }\n+\n+  /**\n+   * Loads the configured hooks corresponding to the specific hook type.\n+   * @param type hook type\n+   */\n+  @VisibleForTesting\n+  void loadHooksFromConf(HookContext.HookType type) {\n+    Hooks container = hooks[type.ordinal()];\n+    if (!container.loadedFromConf) {\n+      container.loadedFromConf = true;\n+      List hooks = container.getHooks();\n+      HiveConf.ConfVars confVars = type.getConfVar();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0MTU5NA==", "bodyText": "Thank you very much for the careful review!  fixed.", "url": "https://github.com/apache/hive/pull/1205#discussion_r489141594", "createdAt": "2020-09-16T03:36:48Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;\n+  private SessionState.LogHelper console;\n+\n+  public HooksLoader(HiveConf conf) {\n+    this.conf = conf;\n+    this.hooks = new Hooks[HookContext.HookType.values().length];\n+    for (int i = 0; i < hooks.length; i++) {\n+      hooks[i] = new Hooks();\n+    }\n+  }\n+\n+  public HooksLoader(HiveConf conf, SessionState.LogHelper console) {\n+    this(conf);\n+    this.console = console;\n+  }\n+\n+  /**\n+   * Loads the configured hooks corresponding to the specific hook type.\n+   * @param type hook type\n+   */\n+  @VisibleForTesting\n+  void loadHooksFromConf(HookContext.HookType type) {\n+    Hooks container = hooks[type.ordinal()];\n+    if (!container.loadedFromConf) {\n+      container.loadedFromConf = true;\n+      List hooks = container.getHooks();\n+      HiveConf.ConfVars confVars = type.getConfVar();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxNzk4OA=="}, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzI2MTIyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjoxNjowNlrOHR-53A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzozNzowMFrOHSe1kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxODQ2MA==", "bodyText": "this will make an index based contract - instead of that we could utrilize a Map<HookType,Hook>", "url": "https://github.com/apache/hive/pull/1205#discussion_r488618460", "createdAt": "2020-09-15T12:16:06Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0MTY0OA==", "bodyText": "done", "url": "https://github.com/apache/hive/pull/1205#discussion_r489141648", "createdAt": "2020-09-16T03:37:00Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxODQ2MA=="}, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzI2NTU0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjoxNzoxN1rOHR-8iQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzo0ODowOVrOHSfABA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxOTE0NQ==", "bodyText": "I don't see any particular benefit of doing the loading lazily - just load all of them upfront in the constructor - the Conf may not change after the creation of this object", "url": "https://github.com/apache/hive/pull/1205#discussion_r488619145", "createdAt": "2020-09-15T12:17:17Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;\n+  private SessionState.LogHelper console;\n+\n+  public HooksLoader(HiveConf conf) {\n+    this.conf = conf;\n+    this.hooks = new Hooks[HookContext.HookType.values().length];\n+    for (int i = 0; i < hooks.length; i++) {\n+      hooks[i] = new Hooks();\n+    }\n+  }\n+\n+  public HooksLoader(HiveConf conf, SessionState.LogHelper console) {\n+    this(conf);\n+    this.console = console;\n+  }\n+\n+  /**\n+   * Loads the configured hooks corresponding to the specific hook type.\n+   * @param type hook type\n+   */\n+  @VisibleForTesting\n+  void loadHooksFromConf(HookContext.HookType type) {\n+    Hooks container = hooks[type.ordinal()];\n+    if (!container.loadedFromConf) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NDMyNA==", "bodyText": "When we use HooksLoader to load the session hooks, redactor hooks that running outside the HookRunner, maybe there is no need to initialize other types of hooks, so I make the hooks loading lazily on demand.", "url": "https://github.com/apache/hive/pull/1205#discussion_r489144324", "createdAt": "2020-09-16T03:48:09Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HooksLoader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.hooks;\n+\n+import com.cronutils.utils.VisibleForTesting;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.HiveStringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+/**\n+ *  Loads and stores different kinds of hooks, provides {@link HooksLoader#addHook(HookContext.HookType, Object)}} to\n+ *  add hook alone or {@link HooksLoader#getHooks(HookContext.HookType, Class)} to get all hooks\n+ *  corresponding to the specific hook type.\n+ */\n+public class HooksLoader {\n+  private static final Logger LOG = LoggerFactory.getLogger(HooksLoader.class);\n+  private final HiveConf conf;\n+  private final Hooks[] hooks;\n+  private SessionState.LogHelper console;\n+\n+  public HooksLoader(HiveConf conf) {\n+    this.conf = conf;\n+    this.hooks = new Hooks[HookContext.HookType.values().length];\n+    for (int i = 0; i < hooks.length; i++) {\n+      hooks[i] = new Hooks();\n+    }\n+  }\n+\n+  public HooksLoader(HiveConf conf, SessionState.LogHelper console) {\n+    this(conf);\n+    this.console = console;\n+  }\n+\n+  /**\n+   * Loads the configured hooks corresponding to the specific hook type.\n+   * @param type hook type\n+   */\n+  @VisibleForTesting\n+  void loadHooksFromConf(HookContext.HookType type) {\n+    Hooks container = hooks[type.ordinal()];\n+    if (!container.loadedFromConf) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYxOTE0NQ=="}, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzI4NzcwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxMjoyMzoxMFrOHR_J-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzo0ODozMVrOHSfAaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYyMjU4NQ==", "bodyText": "please keep some kind of naming contract between the varname and the enum key", "url": "https://github.com/apache/hive/pull/1205#discussion_r488622585", "createdAt": "2020-09-15T12:23:10Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "diffHunk": "@@ -45,7 +47,50 @@\n public class HookContext {\n \n   static public enum HookType {\n-    PRE_EXEC_HOOK, POST_EXEC_HOOK, ON_FAILURE_HOOK\n+\n+    PRE_EXEC_HOOK(HiveConf.ConfVars.PREEXECHOOKS, ExecuteWithHookContext.class,\n+        \"Pre-execution hooks to be invoked for each statement\"),\n+    POST_EXEC_HOOK(HiveConf.ConfVars.POSTEXECHOOKS, ExecuteWithHookContext.class,\n+        \"Post-execution hooks to be invoked for each statement\"),\n+    ON_FAILURE_HOOK(HiveConf.ConfVars.ONFAILUREHOOKS, ExecuteWithHookContext.class,\n+        \"On-failure hooks to be invoked for each statement\"),\n+    QUERY_LIFETIME_HOOKS(HiveConf.ConfVars.HIVE_QUERY_LIFETIME_HOOKS, QueryLifeTimeHook.class,\n+      \"Hooks that will be triggered before/after query compilation and before/after query execution\"),\n+    SEMANTIC_ANALYZER_HOOK(HiveConf.ConfVars.SEMANTIC_ANALYZER_HOOK, HiveSemanticAnalyzerHook.class,\n+      \"Hooks that invoked before/after Hive performs its own semantic analysis on a statement\"),\n+    DRIVER_RUN_HOOKS(HiveConf.ConfVars.HIVE_DRIVER_RUN_HOOKS, HiveDriverRunHook.class,\n+      \"Hooks that Will be run at the beginning and end of Driver.run\"),\n+    REDACTOR(HiveConf.ConfVars.QUERYREDACTORHOOKS, Redactor.class,\n+      \"Hooks to be invoked for each query which can tranform the query before it's placed in the job.xml file\"),\n+    // The HiveSessionHook.class cannot access, use Hook.class instead\n+    HIVE_SERVER2_SESSION_HOOK(HiveConf.ConfVars.HIVE_SERVER2_SESSION_HOOK, Hook.class,\n+      \"Hooks to be executed when session manager starts a new session\"),\n+    OOM(HiveConf.ConfVars.HIVE_SERVER2_OOM_HOOKS, Runnable.class,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NDQyNw==", "bodyText": "done, thank you", "url": "https://github.com/apache/hive/pull/1205#discussion_r489144427", "createdAt": "2020-09-16T03:48:31Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "diffHunk": "@@ -45,7 +47,50 @@\n public class HookContext {\n \n   static public enum HookType {\n-    PRE_EXEC_HOOK, POST_EXEC_HOOK, ON_FAILURE_HOOK\n+\n+    PRE_EXEC_HOOK(HiveConf.ConfVars.PREEXECHOOKS, ExecuteWithHookContext.class,\n+        \"Pre-execution hooks to be invoked for each statement\"),\n+    POST_EXEC_HOOK(HiveConf.ConfVars.POSTEXECHOOKS, ExecuteWithHookContext.class,\n+        \"Post-execution hooks to be invoked for each statement\"),\n+    ON_FAILURE_HOOK(HiveConf.ConfVars.ONFAILUREHOOKS, ExecuteWithHookContext.class,\n+        \"On-failure hooks to be invoked for each statement\"),\n+    QUERY_LIFETIME_HOOKS(HiveConf.ConfVars.HIVE_QUERY_LIFETIME_HOOKS, QueryLifeTimeHook.class,\n+      \"Hooks that will be triggered before/after query compilation and before/after query execution\"),\n+    SEMANTIC_ANALYZER_HOOK(HiveConf.ConfVars.SEMANTIC_ANALYZER_HOOK, HiveSemanticAnalyzerHook.class,\n+      \"Hooks that invoked before/after Hive performs its own semantic analysis on a statement\"),\n+    DRIVER_RUN_HOOKS(HiveConf.ConfVars.HIVE_DRIVER_RUN_HOOKS, HiveDriverRunHook.class,\n+      \"Hooks that Will be run at the beginning and end of Driver.run\"),\n+    REDACTOR(HiveConf.ConfVars.QUERYREDACTORHOOKS, Redactor.class,\n+      \"Hooks to be invoked for each query which can tranform the query before it's placed in the job.xml file\"),\n+    // The HiveSessionHook.class cannot access, use Hook.class instead\n+    HIVE_SERVER2_SESSION_HOOK(HiveConf.ConfVars.HIVE_SERVER2_SESSION_HOOK, Hook.class,\n+      \"Hooks to be executed when session manager starts a new session\"),\n+    OOM(HiveConf.ConfVars.HIVE_SERVER2_OOM_HOOKS, Runnable.class,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODYyMjU4NQ=="}, "originalCommit": {"oid": "46298011457bae7d49d956a3676611cfb108d7bc"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNjc3OTc0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjowNzozNlrOHdwDyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwMzowMTowN1rOHe5UkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk1ODE1NA==", "bodyText": "I like this approach - could you make a small check:\n\nif we have hook compiled for the old api (which uses say the enum key HookType.PRE_EXEC_HOOK)\nwill it work or not  (without recompilation) with the new implementation", "url": "https://github.com/apache/hive/pull/1205#discussion_r500958154", "createdAt": "2020-10-07T12:07:36Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "diffHunk": "@@ -45,7 +47,50 @@\n public class HookContext {\n \n   static public enum HookType {\n-    PRE_EXEC_HOOK, POST_EXEC_HOOK, ON_FAILURE_HOOK\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c64fcdd9e502c2ae13bf6160f727cc74e8f0a6a"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE1ODQ4MA==", "bodyText": "Checked on my test and production env,  it shows that the hooks compiled for the old api can be reused without any changes  with the new implementation.", "url": "https://github.com/apache/hive/pull/1205#discussion_r502158480", "createdAt": "2020-10-09T03:01:07Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java", "diffHunk": "@@ -45,7 +47,50 @@\n public class HookContext {\n \n   static public enum HookType {\n-    PRE_EXEC_HOOK, POST_EXEC_HOOK, ON_FAILURE_HOOK\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk1ODE1NA=="}, "originalCommit": {"oid": "0c64fcdd9e502c2ae13bf6160f727cc74e8f0a6a"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzNjc5OTk4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/HookRunner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxMjoxMjo0N1rOHdwQBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwMzowMToxMVrOHe5UpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk2MTI4Nw==", "bodyText": "this is great!\nsince from now on we can also dynamically add new hooks to it at runtime - we may rename it from \"Loader\" to something else.", "url": "https://github.com/apache/hive/pull/1205#discussion_r500961287", "createdAt": "2020-10-07T12:12:47Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/HookRunner.java", "diffHunk": "@@ -39,57 +36,27 @@\n import org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHook;\n import org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext;\n import org.apache.hadoop.hive.ql.session.SessionState;\n-import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;\n import org.apache.hive.common.util.HiveStringUtils;\n \n+import static org.apache.hadoop.hive.ql.hooks.HookContext.HookType.*;\n+\n /**\n  * Handles hook executions for {@link Driver}.\n  */\n public class HookRunner {\n \n   private static final String CLASS_NAME = Driver.class.getName();\n   private final HiveConf conf;\n-  private LogHelper console;\n-  private List<QueryLifeTimeHook> queryHooks = new ArrayList<>();\n-  private List<HiveSemanticAnalyzerHook> saHooks = new ArrayList<>();\n-  private List<HiveDriverRunHook> driverRunHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> preExecHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> postExecHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> onFailureHooks = new ArrayList<>();\n-  private boolean initialized = false;\n+  private final HooksLoader loader;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c64fcdd9e502c2ae13bf6160f727cc74e8f0a6a"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE1ODUwMQ==", "bodyText": "Rename it to HiveHooks instead.", "url": "https://github.com/apache/hive/pull/1205#discussion_r502158501", "createdAt": "2020-10-09T03:01:11Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/HookRunner.java", "diffHunk": "@@ -39,57 +36,27 @@\n import org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHook;\n import org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext;\n import org.apache.hadoop.hive.ql.session.SessionState;\n-import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;\n import org.apache.hive.common.util.HiveStringUtils;\n \n+import static org.apache.hadoop.hive.ql.hooks.HookContext.HookType.*;\n+\n /**\n  * Handles hook executions for {@link Driver}.\n  */\n public class HookRunner {\n \n   private static final String CLASS_NAME = Driver.class.getName();\n   private final HiveConf conf;\n-  private LogHelper console;\n-  private List<QueryLifeTimeHook> queryHooks = new ArrayList<>();\n-  private List<HiveSemanticAnalyzerHook> saHooks = new ArrayList<>();\n-  private List<HiveDriverRunHook> driverRunHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> preExecHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> postExecHooks = new ArrayList<>();\n-  private List<ExecuteWithHookContext> onFailureHooks = new ArrayList<>();\n-  private boolean initialized = false;\n+  private final HooksLoader loader;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk2MTI4Nw=="}, "originalCommit": {"oid": "0c64fcdd9e502c2ae13bf6160f727cc74e8f0a6a"}, "originalPosition": 42}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 702, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}