{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEzMDk4NzQz", "number": 1633, "reviewThreads": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxODo0NDoyMFrOEz6vMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMDowMzo0MVrOE7eTnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODc1MTg3OnYy", "diffSide": "RIGHT", "path": "service-rpc/if/TCLIService.thrift", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxODo0NDoyMFrOHrb5UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwOToxMTo0NVrOHr7wUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwNzg1Ng==", "bodyText": "Minor: Can we move PROCEDURAL_SQL to the line just before UNKNOWN? That way all the message ids would not be shifted. I dont believe it makes a practical difference but leaves a nicer commit.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515307856", "createdAt": "2020-10-30T18:44:20Z", "author": {"login": "mustafaiman"}, "path": "service-rpc/if/TCLIService.thrift", "diffHunk": "@@ -515,6 +515,7 @@ struct TSessionHandle {\n // The subtype of an OperationHandle.\n enum TOperationType {\n   EXECUTE_STATEMENT,\n+  PROCEDURAL_SQL,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgyOTg0MQ==", "bodyText": "Good idea, moved it to the end. No, the existing hplsql tests still use the old way, most of them are running in offline mode I guess. But the newly added tests in TestHplSqlViaBeeLine use the new mode.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515829841", "createdAt": "2020-11-02T09:11:45Z", "author": {"login": "zeroflag"}, "path": "service-rpc/if/TCLIService.thrift", "diffHunk": "@@ -515,6 +515,7 @@ struct TSessionHandle {\n // The subtype of an OperationHandle.\n enum TOperationType {\n   EXECUTE_STATEMENT,\n+  PROCEDURAL_SQL,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwNzg1Ng=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODc5NTg3OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxODo1OTowNlrOHrcVJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwOToxMTo1OVrOHr7w0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxNDk4Mg==", "bodyText": "Minor: we can extract this if statement to a private method.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515314982", "createdAt": "2020-10-30T18:59:06Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgyOTk2OA==", "bodyText": "Done.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515829968", "createdAt": "2020-11-02T09:11:59Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxNDk4Mg=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODgxNTMyOnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxOTowNTozOVrOHrchKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwOToxMjowN1rOHr7xGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxODA1OA==", "bodyText": "runInBackground is not used", "url": "https://github.com/apache/hive/pull/1633#discussion_r515318058", "createdAt": "2020-10-30T19:05:39Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -36,6 +48,11 @@ public ExecuteStatementOperation(HiveSession parentSession, String statement,\n     this.statement = statement;\n   }\n \n+  public ExecuteStatementOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, boolean generateNewQueryId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgzMDA0Mg==", "bodyText": "Removed.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515830042", "createdAt": "2020-11-02T09:12:07Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -36,6 +48,11 @@ public ExecuteStatementOperation(HiveSession parentSession, String statement,\n     this.statement = statement;\n   }\n \n+  public ExecuteStatementOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, boolean generateNewQueryId) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxODA1OA=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODgyOTk3OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxOToxMDo0M1rOHrcp1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNzowMzo0OVrOHv4o3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng==", "bodyText": "HiveHplSqlSessionState does not hold any info which is not accessible in SessionState already. Why is that class needed?", "url": "https://github.com/apache/hive/pull/1633#discussion_r515320276", "createdAt": "2020-10-30T19:10:43Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgzMDEwMw==", "bodyText": "The session state is not available when the operation is running in the background.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515830103", "createdAt": "2020-11-02T09:12:11Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM2ODAwMQ==", "bodyText": "So this gets a reference to active SessionState. Then it is offloaded to another background thread to run. What if the next operation changes sessionState.currentDatabase? Then hpl operation might run on wrong database, no?", "url": "https://github.com/apache/hive/pull/1633#discussion_r516368001", "createdAt": "2020-11-03T00:45:54Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1OTU2Mg==", "bodyText": "Yes, that might be a problem, let me check that.", "url": "https://github.com/apache/hive/pull/1633#discussion_r516659562", "createdAt": "2020-11-03T13:19:43Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MzA4Nw==", "bodyText": "@mustafaiman,\nI added a unittest to verify it and looks like it still works this way. HiveHplSqlSessionState holds a reference to SessionState which changes when the the current db is modified. The reason why the HiveHplSqlSessionState is still needed is because the SessionState is in the ql project which cannot be referenced from hplsql without introducing circular dependency.", "url": "https://github.com/apache/hive/pull/1633#discussion_r519973087", "createdAt": "2020-11-09T17:03:49Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyOTA0MTU5OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlOperation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQyMDoxNDo1MVrOHret-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwOToxMjo0NFrOHr7yTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NDEwNg==", "bodyText": "I think this would not log e without a matching {}", "url": "https://github.com/apache/hive/pull/1633#discussion_r515354106", "createdAt": "2020-10-30T20:14:51Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlOperation.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.security.PrivilegedExceptionAction;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.apache.hadoop.hive.common.LogUtils;\n+import org.apache.hadoop.hive.ql.log.PerfLogger;\n+import org.apache.hadoop.hive.ql.metadata.Hive;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hadoop.hive.serde2.thrift.Type;\n+import org.apache.hadoop.hive.shims.ShimLoader;\n+import org.apache.hadoop.hive.shims.Utils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.ResultListener;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationState;\n+import org.apache.hive.service.cli.OperationType;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.RowSetFactory;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.operation.ExecuteStatementOperation;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.ThreadWithGarbageCleanup;\n+\n+public class HplSqlOperation extends ExecuteStatementOperation implements ResultListener {\n+  private final Exec exec;\n+  private final boolean runInBackground;\n+  private RowSet rowSet;\n+  private TableSchema schema;\n+\n+  public HplSqlOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, Exec exec) {\n+    super(parentSession, statement, confOverlay, runInBackground, false);\n+    this.exec = exec;\n+    this.runInBackground = runInBackground;\n+    exec.setResultListener(this);\n+  }\n+\n+  @Override\n+  protected void runInternal() throws HiveSQLException {\n+    setState(OperationState.PENDING);\n+    if (!runInBackground) {\n+      interpret();\n+    } else {\n+      Runnable work = new BackgroundWork(getCurrentUGI(), parentSession.getSessionHive(), SessionState.get());\n+      try {\n+        // This submit blocks if no background threads are available to run this operation\n+        Future<?> backgroundHandle = getParentSession().submitBackgroundOperation(work);\n+        setBackgroundHandle(backgroundHandle);\n+      } catch (RejectedExecutionException rejected) {\n+        setState(OperationState.ERROR);\n+        throw new HiveSQLException(\"The background threadpool cannot accept\" +\n+                \" new task for execution, please retry the operation\", rejected);\n+      }\n+    }\n+  }\n+\n+  private void interpret() throws HiveSQLException {\n+    try {\n+      OperationState opState = getStatus().getState();\n+      // Operation may have been cancelled by another thread\n+      if (opState.isTerminal()) {\n+        log.info(\"Not running the query. Operation is already in terminal state: \" + opState\n+                + \", perhaps cancelled due to query timeout or by another thread.\");\n+        return;\n+      }\n+      setState(OperationState.RUNNING);\n+      int code = exec.run(new String[]{\"-e\", statement});\n+      if (code != 0) {\n+        throw new HiveSQLException(\"HPL/SQL returned \" + code);\n+      }\n+      setState(OperationState.FINISHED);\n+    } catch (Throwable e) {\n+      if (getStatus().getState().isTerminal()) {\n+        log.warn(\"Ignore exception in terminal state: {}\", getStatus().getState(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgzMDM0OA==", "bodyText": "I tried it, and it still works this way. The same way is used at other places in the code.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515830348", "createdAt": "2020-11-02T09:12:44Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlOperation.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.security.PrivilegedExceptionAction;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.apache.hadoop.hive.common.LogUtils;\n+import org.apache.hadoop.hive.ql.log.PerfLogger;\n+import org.apache.hadoop.hive.ql.metadata.Hive;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hadoop.hive.serde2.thrift.Type;\n+import org.apache.hadoop.hive.shims.ShimLoader;\n+import org.apache.hadoop.hive.shims.Utils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.ResultListener;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationState;\n+import org.apache.hive.service.cli.OperationType;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.RowSetFactory;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.operation.ExecuteStatementOperation;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.ThreadWithGarbageCleanup;\n+\n+public class HplSqlOperation extends ExecuteStatementOperation implements ResultListener {\n+  private final Exec exec;\n+  private final boolean runInBackground;\n+  private RowSet rowSet;\n+  private TableSchema schema;\n+\n+  public HplSqlOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, Exec exec) {\n+    super(parentSession, statement, confOverlay, runInBackground, false);\n+    this.exec = exec;\n+    this.runInBackground = runInBackground;\n+    exec.setResultListener(this);\n+  }\n+\n+  @Override\n+  protected void runInternal() throws HiveSQLException {\n+    setState(OperationState.PENDING);\n+    if (!runInBackground) {\n+      interpret();\n+    } else {\n+      Runnable work = new BackgroundWork(getCurrentUGI(), parentSession.getSessionHive(), SessionState.get());\n+      try {\n+        // This submit blocks if no background threads are available to run this operation\n+        Future<?> backgroundHandle = getParentSession().submitBackgroundOperation(work);\n+        setBackgroundHandle(backgroundHandle);\n+      } catch (RejectedExecutionException rejected) {\n+        setState(OperationState.ERROR);\n+        throw new HiveSQLException(\"The background threadpool cannot accept\" +\n+                \" new task for execution, please retry the operation\", rejected);\n+      }\n+    }\n+  }\n+\n+  private void interpret() throws HiveSQLException {\n+    try {\n+      OperationState opState = getStatus().getState();\n+      // Operation may have been cancelled by another thread\n+      if (opState.isTerminal()) {\n+        log.info(\"Not running the query. Operation is already in terminal state: \" + opState\n+                + \", perhaps cancelled due to query timeout or by another thread.\");\n+        return;\n+      }\n+      setState(OperationState.RUNNING);\n+      int code = exec.run(new String[]{\"-e\", statement});\n+      if (code != 0) {\n+        throw new HiveSQLException(\"HPL/SQL returned \" + code);\n+      }\n+      setState(OperationState.FINISHED);\n+    } catch (Throwable e) {\n+      if (getStatus().getState().isTerminal()) {\n+        log.warn(\"Ignore exception in terminal state: {}\", getStatus().getState(), e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NDEwNg=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyOTA2NDY4OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQyMDoyNDowMFrOHre8gA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwOToxMjo0OFrOHr7yaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NzgyNA==", "bodyText": "Shouldn't this be configurable?", "url": "https://github.com/apache/hive/pull/1633#discussion_r515357824", "createdAt": "2020-10-30T20:24:00Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long defaultMaxRows = HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.defaultIntVal;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgzMDM3OQ==", "bodyText": "I made it configurable.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515830379", "createdAt": "2020-11-02T09:12:48Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long defaultMaxRows = HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.defaultIntVal;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NzgyNA=="}, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTk5OTMyOnYy", "diffSide": "RIGHT", "path": "ql/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoxMjozNlrOHxu3UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo1NDoxNlrOHx5fLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMDA5Nw==", "bodyText": "I think it would be better to avoid pulling in hplsql under ql - there is only a console class and some minor other stuff - I think this could be dodged with a few interfaces.", "url": "https://github.com/apache/hive/pull/1633#discussion_r521910097", "createdAt": "2020-11-12T08:12:36Z", "author": {"login": "kgyrtkirk"}, "path": "ql/pom.xml", "diffHunk": "@@ -863,6 +863,11 @@\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-hplsql</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA4NDE0MQ==", "bodyText": "I removed this dependency.", "url": "https://github.com/apache/hive/pull/1633#discussion_r522084141", "createdAt": "2020-11-12T12:54:16Z", "author": {"login": "zeroflag"}, "path": "ql/pom.xml", "diffHunk": "@@ -863,6 +863,11 @@\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-hplsql</artifactId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMDA5Nw=="}, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MjAwNTUxOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoxNDoxN1rOHxu67Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo1NToxOFrOHx5hog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMTAyMQ==", "bodyText": "I don't fully understand why we have this field \"here\" - we don't even use hplsql from ql.\nThis field is only used from the \"service\" module", "url": "https://github.com/apache/hive/pull/1633#discussion_r521911021", "createdAt": "2020-11-12T08:14:17Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java", "diffHunk": "@@ -270,6 +271,8 @@\n \n   private SparkSession sparkSession;\n \n+  private Exec hplsqlInterpreter;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA4NDc3MA==", "bodyText": "I made this dynamic.", "url": "https://github.com/apache/hive/pull/1633#discussion_r522084770", "createdAt": "2020-11-12T12:55:18Z", "author": {"login": "zeroflag"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java", "diffHunk": "@@ -270,6 +271,8 @@\n \n   private SparkSession sparkSession;\n \n+  private Exec hplsqlInterpreter;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMTAyMQ=="}, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MjAyNzkzOnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoxOToyNFrOHxvHxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToxMjoyMlrOHx_Ydw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNDMxMA==", "bodyText": "I think if I set fetchsize to 1 - and then I try to fetch a resultset of 10 rows with hplsql; I'll get 1 row back", "url": "https://github.com/apache/hive/pull/1633#discussion_r521914310", "createdAt": "2020-11-12T08:19:24Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long fetchSize;\n+\n+  public HplSqlQueryExecutor(HiveSession hiveSession) {\n+    this.fetchSize = hiveSession.getHiveConf().getIntVar(HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE);\n+    this.hiveSession = hiveSession;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    try {\n+      Map<String, String> confOverlay = new HashMap<>();\n+      confOverlay.put(QUERY_EXECUTOR, HPLSQL);\n+      OperationHandle operationHandle = hiveSession.executeStatement(sql, confOverlay);\n+      return new QueryResult(new OperationRowResult(operationHandle), () -> metadata(operationHandle), null);\n+    } catch (HiveSQLException e) {\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), e);\n+    }\n+  }\n+\n+  public Metadata metadata(OperationHandle operationHandle) {\n+    try {\n+      TableSchema meta = hiveSession.getResultSetMetadata(operationHandle);\n+      List<ColumnMeta> colMeta = new ArrayList<>();\n+      for (int i = 0; i < meta.getSize(); i++) {\n+        ColumnDescriptor col = meta.getColumnDescriptorAt(i);\n+        colMeta.add(new ColumnMeta(col.getName(), col.getTypeName(), col.getType().toJavaSQLType()));\n+      }\n+      return new Metadata(colMeta);\n+    } catch (HiveSQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private class OperationRowResult implements RowResult {\n+    private final OperationHandle handle;\n+    private RowSet rows;\n+    private Iterator<Object[]> iterator;\n+    private Object[] current;\n+\n+    private OperationRowResult(OperationHandle operationHandle) {\n+      this.handle = operationHandle;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      if (rows == null) {\n+        this.rows = fetch();\n+        this.iterator = rows.iterator();\n+      }\n+      if (iterator.hasNext()) {\n+        current = iterator.next();\n+        return true;\n+      } else {\n+        current = null;\n+        return false;\n+      }\n+    }\n+\n+    private RowSet fetch() {\n+      try {\n+        return hiveSession.fetchResults(\n+                handle, FetchOrientation.FETCH_NEXT, fetchSize, FetchType.QUERY_OUTPUT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4MDcyNw==", "bodyText": "Right. I think I fixed it by adding an extra condition.", "url": "https://github.com/apache/hive/pull/1633#discussion_r522180727", "createdAt": "2020-11-12T15:12:22Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long fetchSize;\n+\n+  public HplSqlQueryExecutor(HiveSession hiveSession) {\n+    this.fetchSize = hiveSession.getHiveConf().getIntVar(HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE);\n+    this.hiveSession = hiveSession;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    try {\n+      Map<String, String> confOverlay = new HashMap<>();\n+      confOverlay.put(QUERY_EXECUTOR, HPLSQL);\n+      OperationHandle operationHandle = hiveSession.executeStatement(sql, confOverlay);\n+      return new QueryResult(new OperationRowResult(operationHandle), () -> metadata(operationHandle), null);\n+    } catch (HiveSQLException e) {\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), e);\n+    }\n+  }\n+\n+  public Metadata metadata(OperationHandle operationHandle) {\n+    try {\n+      TableSchema meta = hiveSession.getResultSetMetadata(operationHandle);\n+      List<ColumnMeta> colMeta = new ArrayList<>();\n+      for (int i = 0; i < meta.getSize(); i++) {\n+        ColumnDescriptor col = meta.getColumnDescriptorAt(i);\n+        colMeta.add(new ColumnMeta(col.getName(), col.getTypeName(), col.getType().toJavaSQLType()));\n+      }\n+      return new Metadata(colMeta);\n+    } catch (HiveSQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private class OperationRowResult implements RowResult {\n+    private final OperationHandle handle;\n+    private RowSet rows;\n+    private Iterator<Object[]> iterator;\n+    private Object[] current;\n+\n+    private OperationRowResult(OperationHandle operationHandle) {\n+      this.handle = operationHandle;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      if (rows == null) {\n+        this.rows = fetch();\n+        this.iterator = rows.iterator();\n+      }\n+      if (iterator.hasNext()) {\n+        current = iterator.next();\n+        return true;\n+      } else {\n+        current = null;\n+        return false;\n+      }\n+    }\n+\n+    private RowSet fetch() {\n+      try {\n+        return hiveSession.fetchResults(\n+                handle, FetchOrientation.FETCH_NEXT, fetchSize, FetchType.QUERY_OUTPUT);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNDMxMA=="}, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MjA0NDE2OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/Udf.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoyMTo1NVrOHxvSbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo1NTozNlrOHx5iQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNzAzNg==", "bodyText": "this doesnt look right...\nwhy are we moviong a UDF into the service package? can't we avoid that?", "url": "https://github.com/apache/hive/pull/1633#discussion_r521917036", "createdAt": "2020-11-12T08:21:55Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/Udf.java", "diffHunk": "@@ -1,123 +1,125 @@\n /*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n  *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n  *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n  */\n \n-package org.apache.hive.hplsql;\n+package org.apache.hive.service.cli.operation.hplsql;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA4NDkzMA==", "bodyText": "I put it back to hplsql project.", "url": "https://github.com/apache/hive/pull/1633#discussion_r522084930", "createdAt": "2020-11-12T12:55:36Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/Udf.java", "diffHunk": "@@ -1,123 +1,125 @@\n /*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n  *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n  *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n  */\n \n-package org.apache.hive.hplsql;\n+package org.apache.hive.service.cli.operation.hplsql;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNzAzNg=="}, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzgxMzMzOnYy", "diffSide": "RIGHT", "path": "beeline/src/java/org/apache/hive/beeline/BeeLine.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOToyMjoxN1rOH3HimQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTozMjoyNlrOH4FPzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1NzI3Mw==", "bodyText": "I think it would be better if this would be mode=hplsql; that way we may add more \"mode\"-s later\nwhat do you think?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527557273", "createdAt": "2020-11-20T09:22:17Z", "author": {"login": "kgyrtkirk"}, "path": "beeline/src/java/org/apache/hive/beeline/BeeLine.java", "diffHunk": "@@ -892,8 +893,12 @@ private boolean connectUsingArgs(BeelineParser beelineParser, CommandLine cl) {\n     getOpts().setInitFiles(cl.getOptionValues(\"i\"));\n     getOpts().setScriptFile(cl.getOptionValue(\"f\"));\n \n-\n     if (url != null) {\n+      String hplSqlMode = Utils.parsePropertyFromUrl(url, Constants.HPLSQL_MODE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU2ODI2OQ==", "bodyText": "Ok, modified it.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528568269", "createdAt": "2020-11-23T09:32:26Z", "author": {"login": "zeroflag"}, "path": "beeline/src/java/org/apache/hive/beeline/BeeLine.java", "diffHunk": "@@ -892,8 +893,12 @@ private boolean connectUsingArgs(BeelineParser beelineParser, CommandLine cl) {\n     getOpts().setInitFiles(cl.getOptionValues(\"i\"));\n     getOpts().setScriptFile(cl.getOptionValue(\"f\"));\n \n-\n     if (url != null) {\n+      String hplSqlMode = Utils.parsePropertyFromUrl(url, Constants.HPLSQL_MODE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1NzI3Mw=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzgxNzcxOnYy", "diffSide": "RIGHT", "path": "hplsql/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOToyMzoyNlrOH3HlUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTozMjozMFrOH4FP-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1Nzk2OA==", "bodyText": "I think hive-exec already contains this transitively - is this dep really neccessary?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527557968", "createdAt": "2020-11-20T09:23:26Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/pom.xml", "diffHunk": "@@ -46,6 +46,11 @@\n       <artifactId>commons-io</artifactId>\n     </dependency>\n     <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-standalone-metastore-common</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU2ODMxNQ==", "bodyText": "Right, I removed it.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528568315", "createdAt": "2020-11-23T09:32:30Z", "author": {"login": "zeroflag"}, "path": "hplsql/pom.xml", "diffHunk": "@@ -46,6 +46,11 @@\n       <artifactId>commons-io</artifactId>\n     </dependency>\n     <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-standalone-metastore-common</artifactId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1Nzk2OA=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzg1NTE0OnYy", "diffSide": "RIGHT", "path": "hplsql/src/main/java/org/apache/hive/hplsql/Cmp.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTozMjo1NFrOH3H7_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoxODoyOFrOH4LBFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Mzc3NQ==", "bodyText": "(QR-indexes#1) there seems to be existing loops starting for idx \"1\"", "url": "https://github.com/apache/hive/pull/1633#discussion_r527563775", "createdAt": "2020-11-20T09:32:54Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Cmp.java", "diffHunk": "@@ -138,28 +147,26 @@ else if (query2.error()) {\n       exec.signal(query2);\n       return null;\n     }\n-    ResultSet rs1 = query1.getResultSet();\n-    ResultSet rs2 = query2.getResultSet();\n-    if (rs1 == null || rs2 == null) {\n+    if (query1 == null || query2 == null) {\n       exec.setSqlCode(-1);\n       return null;\n     }\n     boolean equal = true;\n     tests = 0;\n     failedTests = 0;\n     try {\n-      ResultSetMetaData rm1 = rs1.getMetaData();\n-      ResultSetMetaData rm2 = rs2.getMetaData();\n-      int cnt1 = rm1.getColumnCount();\n-      int cnt2 = rm2.getColumnCount();\n+      Metadata rm1 = query1.metadata();\n+      Metadata rm2 = query2.metadata();\n+      int cnt1 = rm1.columnCount();\n+      int cnt2 = rm2.columnCount();\n       tests = cnt1;\n-      while (rs1.next() && rs2.next()) {\n+      while (query1.next() && query2.next()) {\n         for (int i = 1; i <= tests; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2MjgwNQ==", "bodyText": "Yes, I missed this. It should have been 0 based. Fixed it. I also removed the 2 threads since Tez doesn't support concurrent queries within the same session.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528662805", "createdAt": "2020-11-23T12:18:28Z", "author": {"login": "zeroflag"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Cmp.java", "diffHunk": "@@ -138,28 +147,26 @@ else if (query2.error()) {\n       exec.signal(query2);\n       return null;\n     }\n-    ResultSet rs1 = query1.getResultSet();\n-    ResultSet rs2 = query2.getResultSet();\n-    if (rs1 == null || rs2 == null) {\n+    if (query1 == null || query2 == null) {\n       exec.setSqlCode(-1);\n       return null;\n     }\n     boolean equal = true;\n     tests = 0;\n     failedTests = 0;\n     try {\n-      ResultSetMetaData rm1 = rs1.getMetaData();\n-      ResultSetMetaData rm2 = rs2.getMetaData();\n-      int cnt1 = rm1.getColumnCount();\n-      int cnt2 = rm2.getColumnCount();\n+      Metadata rm1 = query1.metadata();\n+      Metadata rm2 = query2.metadata();\n+      int cnt1 = rm1.columnCount();\n+      int cnt2 = rm2.columnCount();\n       tests = cnt1;\n-      while (rs1.next() && rs2.next()) {\n+      while (query1.next() && query2.next()) {\n         for (int i = 1; i <= tests; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Mzc3NQ=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzg1NzExOnYy", "diffSide": "RIGHT", "path": "hplsql/src/main/java/org/apache/hive/hplsql/Copy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTozMzoyN1rOH3H9MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoxOTowOVrOH4LCsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NDA4MQ==", "bodyText": "(QR-indexes#2) and there are places where it changes to 0 indexed", "url": "https://github.com/apache/hive/pull/1633#discussion_r527564081", "createdAt": "2020-11-20T09:33:27Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Copy.java", "diffHunk": "@@ -233,16 +219,16 @@ void copyToFile(HplsqlParser.Copy_stmtContext ctx, Query query) throws Exception\n         sql = \"INSERT INTO \" + sqlInsertName + \" VALUES (\";\n         rowdel = \");\\n\".getBytes();\n       }\n-      while (rs.next()) {\n+      while (query.next()) {\n         if (sqlInsert) {\n           out.write(sql.getBytes());\n         }\n-        for (int i = 1; i <= cols; i++) {\n-          if (i > 1) {\n+        for (int i = 0; i < cols; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2MzIxNg==", "bodyText": "I supposed to be 0 based everywhere.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528663216", "createdAt": "2020-11-23T12:19:09Z", "author": {"login": "zeroflag"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Copy.java", "diffHunk": "@@ -233,16 +219,16 @@ void copyToFile(HplsqlParser.Copy_stmtContext ctx, Query query) throws Exception\n         sql = \"INSERT INTO \" + sqlInsertName + \" VALUES (\";\n         rowdel = \");\\n\".getBytes();\n       }\n-      while (rs.next()) {\n+      while (query.next()) {\n         if (sqlInsert) {\n           out.write(sql.getBytes());\n         }\n-        for (int i = 1; i <= cols; i++) {\n-          if (i > 1) {\n+        for (int i = 0; i < cols; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NDA4MQ=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzg2NDk3OnYy", "diffSide": "RIGHT", "path": "hplsql/src/main/java/org/apache/hive/hplsql/Var.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTozNTozMFrOH3IB3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTozMjo1M1rOH4FQ0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NTI3Ng==", "bodyText": "(QR-indexes#2) and there are places where it changes to 0 indexed\njdbc drivers usually start numbering from 1; but internal stuff tends to use 0.\nit would be helpfull to write this contract down in the QueryResult's apidoc\nwill the \"old\" approach still work after these changes?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527565276", "createdAt": "2020-11-20T09:35:30Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Var.java", "diffHunk": "@@ -258,44 +256,35 @@ public void setValue(Object value) {\n       this.value = value;\n \t  }\n   }\n-\t\n-\t/**\n-   * Set the new value from the result set\n-   */\n-  public Var setValue(ResultSet rs, ResultSetMetaData rsm, int idx) throws SQLException {\n-    int type = rsm.getColumnType(idx);\n+\n+  public Var setValue(QueryResult queryResult, int idx) {\n+    int type = queryResult.jdbcType(idx);\n     if (type == java.sql.Types.CHAR || type == java.sql.Types.VARCHAR) {\n-      cast(new Var(rs.getString(idx)));\n-    }\n-    else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n-        type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n-      cast(new Var(Long.valueOf(rs.getLong(idx))));\n-    }\n-    else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n-      cast(new Var(rs.getBigDecimal(idx)));\n-    }\n-    else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n-      cast(new Var(Double.valueOf(rs.getDouble(idx))));\n+      cast(new Var(queryResult.column(idx, String.class)));\n+    } else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n+            type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n+      cast(new Var(Long.valueOf(queryResult.column(idx, Long.class))));\n+    } else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n+      cast(new Var(queryResult.column(idx, BigDecimal.class)));\n+    } else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n+      cast(new Var(Double.valueOf(queryResult.column(idx, Double.class))));\n     }\n     return this;\n   }\n-  \n-  /**\n-   * Set ROW values from the result set\n-   */\n-  public Var setValues(ResultSet rs, ResultSetMetaData rsm) throws SQLException {\n+\n+  public Var setValues(QueryResult queryResult) {\n     Row row = (Row)this.value;\n-    int idx = 1;\n+    int idx = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU2ODUzMA==", "bodyText": "I added a javadoc explaining the difference.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528568530", "createdAt": "2020-11-23T09:32:53Z", "author": {"login": "zeroflag"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Var.java", "diffHunk": "@@ -258,44 +256,35 @@ public void setValue(Object value) {\n       this.value = value;\n \t  }\n   }\n-\t\n-\t/**\n-   * Set the new value from the result set\n-   */\n-  public Var setValue(ResultSet rs, ResultSetMetaData rsm, int idx) throws SQLException {\n-    int type = rsm.getColumnType(idx);\n+\n+  public Var setValue(QueryResult queryResult, int idx) {\n+    int type = queryResult.jdbcType(idx);\n     if (type == java.sql.Types.CHAR || type == java.sql.Types.VARCHAR) {\n-      cast(new Var(rs.getString(idx)));\n-    }\n-    else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n-        type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n-      cast(new Var(Long.valueOf(rs.getLong(idx))));\n-    }\n-    else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n-      cast(new Var(rs.getBigDecimal(idx)));\n-    }\n-    else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n-      cast(new Var(Double.valueOf(rs.getDouble(idx))));\n+      cast(new Var(queryResult.column(idx, String.class)));\n+    } else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n+            type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n+      cast(new Var(Long.valueOf(queryResult.column(idx, Long.class))));\n+    } else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n+      cast(new Var(queryResult.column(idx, BigDecimal.class)));\n+    } else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n+      cast(new Var(Double.valueOf(queryResult.column(idx, Double.class))));\n     }\n     return this;\n   }\n-  \n-  /**\n-   * Set ROW values from the result set\n-   */\n-  public Var setValues(ResultSet rs, ResultSetMetaData rsm) throws SQLException {\n+\n+  public Var setValues(QueryResult queryResult) {\n     Row row = (Row)this.value;\n-    int idx = 1;\n+    int idx = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NTI3Ng=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzg3NTY4OnYy", "diffSide": "RIGHT", "path": "hplsql/src/main/java/org/apache/hive/hplsql/executor/JdbcQueryExecutor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTozODoyMFrOH3IIXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoyMDoxNVrOH4LFLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Njk0MA==", "bodyText": "(QR-indexes#4) given the things I've seen so far:\nI think right now queryresult is 0 indexed; and this seems to be the jdbc adaptor so I would have expected a +/- 1 here", "url": "https://github.com/apache/hive/pull/1633#discussion_r527566940", "createdAt": "2020-11-20T09:38:20Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/executor/JdbcQueryExecutor.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.hplsql.executor;\n+\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.Query;\n+\n+public class JdbcQueryExecutor implements QueryExecutor {\n+  private final Exec exec;\n+\n+  public JdbcQueryExecutor(Exec exec) {\n+    this.exec = exec;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    String conn = exec.getStatementConnection();\n+    Query query = exec.executeQuery(ctx, new Query(sql), conn);\n+    ResultSet resultSet = query.getResultSet();\n+    if (resultSet == null) { // offline mode\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), query.getException());\n+    } else {\n+      return new QueryResult(new JdbcRowResult(resultSet), () -> metadata(resultSet), query.getException());\n+    }\n+  }\n+\n+  private static Metadata metadata(ResultSet resultSet) {\n+    try {\n+      ResultSetMetaData meta = resultSet.getMetaData();\n+      List<ColumnMeta> colMetas = new ArrayList<>();\n+      for (int i = 1; i <= meta.getColumnCount(); i++) {\n+        colMetas.add(new ColumnMeta(\n+                meta.getColumnName(i), meta.getColumnTypeName(i), meta.getColumnType(i)));\n+      }\n+      return new Metadata(colMetas);\n+    } catch (SQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private static class JdbcRowResult implements RowResult {\n+    private final ResultSet resultSet;\n+\n+    private JdbcRowResult(ResultSet resultSet) {\n+      this.resultSet = resultSet;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      try {\n+        return resultSet.next();\n+      } catch (SQLException e) {\n+        throw new QueryException(e);\n+      }\n+    }\n+\n+    @Override\n+    public <T> T get(int columnIndex, Class<T> type) {\n+      try {\n+        return resultSet.getObject(columnIndex, type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2Mzg1NQ==", "bodyText": "Right, this is off by one. the Jdbc adaptor was added for compatibility, I'm not sure for how long we'll want to support it but I fixed indexing.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528663855", "createdAt": "2020-11-23T12:20:15Z", "author": {"login": "zeroflag"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/executor/JdbcQueryExecutor.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.hplsql.executor;\n+\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.Query;\n+\n+public class JdbcQueryExecutor implements QueryExecutor {\n+  private final Exec exec;\n+\n+  public JdbcQueryExecutor(Exec exec) {\n+    this.exec = exec;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    String conn = exec.getStatementConnection();\n+    Query query = exec.executeQuery(ctx, new Query(sql), conn);\n+    ResultSet resultSet = query.getResultSet();\n+    if (resultSet == null) { // offline mode\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), query.getException());\n+    } else {\n+      return new QueryResult(new JdbcRowResult(resultSet), () -> metadata(resultSet), query.getException());\n+    }\n+  }\n+\n+  private static Metadata metadata(ResultSet resultSet) {\n+    try {\n+      ResultSetMetaData meta = resultSet.getMetaData();\n+      List<ColumnMeta> colMetas = new ArrayList<>();\n+      for (int i = 1; i <= meta.getColumnCount(); i++) {\n+        colMetas.add(new ColumnMeta(\n+                meta.getColumnName(i), meta.getColumnTypeName(i), meta.getColumnType(i)));\n+      }\n+      return new Metadata(colMetas);\n+    } catch (SQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private static class JdbcRowResult implements RowResult {\n+    private final ResultSet resultSet;\n+\n+    private JdbcRowResult(ResultSet resultSet) {\n+      this.resultSet = resultSet;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      try {\n+        return resultSet.next();\n+      } catch (SQLException e) {\n+        throw new QueryException(e);\n+      }\n+    }\n+\n+    @Override\n+    public <T> T get(int columnIndex, Class<T> type) {\n+      try {\n+        return resultSet.getObject(columnIndex, type);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Njk0MA=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzg5NTExOnYy", "diffSide": "RIGHT", "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTo0MzoyOFrOH3IT5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoyMDo1NFrOH4LGtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2OTg5NA==", "bodyText": "could you configure import order in your ide to not reorder imports \"this much\"?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527569894", "createdAt": "2020-11-20T09:43:28Z", "author": {"login": "kgyrtkirk"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -18,18 +18,67 @@\n \n package org.apache.hive.jdbc;\n \n-import com.google.common.annotations.VisibleForTesting;\n+import static org.apache.hadoop.hive.conf.Constants.HPLSQL_MODE;\n+import java.io.BufferedReader;\n+import java.io.DataInputStream;\n+import java.io.File;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NDI0NA==", "bodyText": "I'll try to do something about it.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528664244", "createdAt": "2020-11-23T12:20:54Z", "author": {"login": "zeroflag"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -18,18 +18,67 @@\n \n package org.apache.hive.jdbc;\n \n-import com.google.common.annotations.VisibleForTesting;\n+import static org.apache.hadoop.hive.conf.Constants.HPLSQL_MODE;\n+import java.io.BufferedReader;\n+import java.io.DataInputStream;\n+import java.io.File;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2OTg5NA=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzkyNDc0OnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOTo1MDoyN1rOH3Ilew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QwOTozMDoyN1rOH4FLEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3NDM5NQ==", "bodyText": "what does embedded mean here?\n\nembedded hiveserver2\nsome hplsql related stuff?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527574395", "createdAt": "2020-11-20T09:50:27Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -102,7 +109,7 @@ protected Operation(HiveSession parentSession,\n         MetricsConstant.COMPLETED_OPERATION_PREFIX, state);\n     queryState = new QueryState.Builder()\n                      .withConfOverlay(confOverlay)\n-                     .withGenerateNewQueryId(true)\n+                     .withGenerateNewQueryId(!embedded)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU2NzA1OQ==", "bodyText": "An hplsql script contains both declarative (for example select) and imperative statements (for example a for loop). The script is executed by an HplSqlOperation but this will start SQLOperations when it sees hive ql stuffs. So this flag indicates that one operation was started by an other operation.", "url": "https://github.com/apache/hive/pull/1633#discussion_r528567059", "createdAt": "2020-11-23T09:30:27Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -102,7 +109,7 @@ protected Operation(HiveSession parentSession,\n         MetricsConstant.COMPLETED_OPERATION_PREFIX, state);\n     queryState = new QueryState.Builder()\n                      .withConfOverlay(confOverlay)\n-                     .withGenerateNewQueryId(true)\n+                     .withGenerateNewQueryId(!embedded)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3NDM5NQ=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNzk3OTgwOnYy", "diffSide": "RIGHT", "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMDowMzo0MVrOH3JGMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMjoyNDozNlrOH4LOOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU4Mjc2OA==", "bodyText": "I don't see this or SqlOperation called with a true embedded parameter\nthis one way to create a multi statement query thing - I wonder if we could have that as a first class citizen - and implement the old one as a single-instruction operation. what do you think?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527582768", "createdAt": "2020-11-20T10:03:41Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -88,8 +89,14 @@ protected Operation(HiveSession parentSession, OperationType opType) {\n   }\n \n   protected Operation(HiveSession parentSession,\n-      Map<String, String> confOverlay, OperationType opType) {\n+                      Map<String, String> confOverlay, OperationType opType) {\n+    this(parentSession, confOverlay, opType, false);\n+  }\n+\n+  protected Operation(HiveSession parentSession,\n+      Map<String, String> confOverlay, OperationType opType, boolean embedded) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjE2OA==", "bodyText": "The SqlOperation is called with embedded=true when it is instantiated from a running hplsql script.\nnew SQLOperation(parentSession, statement, confOverlay, runAsync, queryTimeout, hplSqlMode());\n\nCould elaborate more on that idea of having it as a first class citizen?", "url": "https://github.com/apache/hive/pull/1633#discussion_r528666168", "createdAt": "2020-11-23T12:24:36Z", "author": {"login": "zeroflag"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -88,8 +89,14 @@ protected Operation(HiveSession parentSession, OperationType opType) {\n   }\n \n   protected Operation(HiveSession parentSession,\n-      Map<String, String> confOverlay, OperationType opType) {\n+                      Map<String, String> confOverlay, OperationType opType) {\n+    this(parentSession, confOverlay, opType, false);\n+  }\n+\n+  protected Operation(HiveSession parentSession,\n+      Map<String, String> confOverlay, OperationType opType, boolean embedded) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU4Mjc2OA=="}, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 211, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}