{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxNDg2OTYy", "number": 1791, "title": "[WIP] HIVE-24543: Support SAML 2.0 as an authentication mechanism", "bodyText": "What changes were proposed in this pull request?\nThis is a WIP patch to add support for SAML 2.0 based authention for HiveServer2 clients. Currently this would only support local desktop based JDBC clients. The JDBC Driver opens a browser and points to the SSO URL to complete the authentication flow.\nWhy are the changes needed?\nNew feature\nDoes this PR introduce any user-facing change?\nIt introduces new hive configurations to configure the SAML client.\nHow was this patch tested?\nAdded new unit tests to authenticate against a dockerized SAML 2.0 provider. Also, manually tested with Okta SAML 2.0 application.", "createdAt": "2020-12-16T22:53:20Z", "url": "https://github.com/apache/hive/pull/1791", "merged": true, "mergeCommit": {"oid": "6e8936fbb725450250271552c683f7b76bc38d93"}, "closed": true, "closedAt": "2021-03-10T22:10:55Z", "author": {"login": "vihangk1"}, "timelineItems": {"totalCount": 41, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdpDDqpgBqjQxNDUwNzQ3ODk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABeBgzmRABqjQ0MzAzNzUwODM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d2e760b51d7288066a2bb52c480b66c28a934c7", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/0d2e760b51d7288066a2bb52c480b66c28a934c7", "committedDate": "2020-12-22T00:14:28Z", "message": "Added additional configuration. SAML redirect happens when token is not present and port is present"}, "afterCommit": {"oid": "8a378458fda0a5fd05993a65aad77f625e72b9ff", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/8a378458fda0a5fd05993a65aad77f625e72b9ff", "committedDate": "2020-12-23T18:00:26Z", "message": "Added additional configuration. SAML redirect happens when token is not present and port is present"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8a378458fda0a5fd05993a65aad77f625e72b9ff", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/8a378458fda0a5fd05993a65aad77f625e72b9ff", "committedDate": "2020-12-23T18:00:26Z", "message": "Added additional configuration. SAML redirect happens when token is not present and port is present"}, "afterCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/2763d7f5e05bad6a15c503d49666db55e33e7f7a", "committedDate": "2021-01-04T23:08:44Z", "message": "revert back the surefire plugin version change"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxOTk2NDkz", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-561996493", "createdAt": "2021-01-05T17:41:50Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNzo0MTo1MFrOIOg0Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNzo0MTo1MFrOIOg0Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjA4ODYyNg==", "bodyText": "nit: SAML2 should be SAML to match the value in the set", "url": "https://github.com/apache/hive/pull/1791#discussion_r552088626", "createdAt": "2021-01-05T17:41:50Z", "author": {"login": "nrg4878"}, "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "diffHunk": "@@ -3871,15 +3870,16 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n \n     // HiveServer2 auth configuration\n     HIVE_SERVER2_AUTHENTICATION(\"hive.server2.authentication\", \"NONE\",\n-      new StringSet(\"NOSASL\", \"NONE\", \"LDAP\", \"KERBEROS\", \"PAM\", \"CUSTOM\"),\n+      new StringSet(\"NOSASL\", \"NONE\", \"LDAP\", \"KERBEROS\", \"PAM\", \"CUSTOM\", \"SAML\"),\n         \"Client authentication types.\\n\" +\n         \"  NONE: no authentication check\\n\" +\n         \"  LDAP: LDAP/AD based authentication\\n\" +\n         \"  KERBEROS: Kerberos/GSSAPI authentication\\n\" +\n         \"  CUSTOM: Custom authentication provider\\n\" +\n         \"          (Use with property hive.server2.custom.authentication.class)\\n\" +\n         \"  PAM: Pluggable authentication module\\n\" +\n-        \"  NOSASL:  Raw transport\"),\n+        \"  NOSASL:  Raw transport\\n\" +\n+        \"  SAML2: SAML 2.0 compliant authentication. This is only supported in http transport mode.\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDExNzc4", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562011778", "createdAt": "2021-01-05T18:02:49Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODowMjo0OVrOIOhiog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODowMjo0OVrOIOhiog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEwMDUxNA==", "bodyText": "TODO item", "url": "https://github.com/apache/hive/pull/1791#discussion_r552100514", "createdAt": "2021-01-05T18:02:49Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -301,10 +326,20 @@ public HiveConnection(String uri, Properties info) throws SQLException {\n     supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V9);\n     supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V10);\n \n+    if (isBrowserAuthMode()) {\n+      try {\n+        browserClient = browserClientFactory.create(connParams);\n+      } catch (HiveJdbcBrowserException e) {\n+        throw new SQLException(\"\");\n+      }\n+    } else {\n+      browserClient = null;\n+    }\n     if (isEmbeddedMode) {\n       client = EmbeddedCLIServicePortal.get(connParams.getHiveConfs());\n       connParams.getHiveConfs().clear();\n       // open client session\n+      // TODO(Vihang) need to throw here if saml auth?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 85}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDE0OTg4", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562014988", "createdAt": "2021-01-05T18:07:24Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODowNzoyNVrOIOhsMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODowNzoyNVrOIOhsMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEwMjk2MQ==", "bodyText": "I understand why this is done but feels odd that this throws a SQLException. Can we throw something else here and then wrap it in a SQLException in the calling method? Even a TTransportException would make sense over SQLException (though it is not thrown from thrift).", "url": "https://github.com/apache/hive/pull/1791#discussion_r552102961", "createdAt": "2021-01-05T18:07:25Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -476,12 +511,18 @@ private String getServerHttpUrl(boolean useSsl) {\n   private TTransport createHttpTransport() throws SQLException, TTransportException {\n     CloseableHttpClient httpClient;\n     boolean useSsl = isSslConnection();\n-    // Create an http client from the configs\n+    validateSslForBrowserMode();\n     httpClient = getHttpClient(useSsl);\n     transport = new THttpClient(getServerHttpUrl(useSsl), httpClient);\n     return transport;\n   }\n \n+  protected void validateSslForBrowserMode() throws SQLException {\n+    if (isBrowserAuthMode() && !isSslConnection()) {\n+      throw new SQLException(\"Browser mode is only supported with SSL is enabled\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 102}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDE3MDUy", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562017052", "createdAt": "2021-01-05T18:10:26Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoxMDoyN1rOIOhyuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoxMDoyN1rOIOhyuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEwNDYzMg==", "bodyText": "wouldn't httpClientBuilder be null if cookieAuth is disabled? We could use http transport with cookieAuth disabled right?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552104632", "createdAt": "2021-01-05T18:10:27Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -592,6 +638,10 @@ public boolean retryRequest(IOException exception, int executionCount, HttpConte\n       }\n     });\n \n+    if (isBrowserAuthMode()) {\n+      httpClientBuilder", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 140}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDE3NjMw", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562017630", "createdAt": "2021-01-05T18:11:15Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoxMToxNVrOIOh0Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoxMToxNVrOIOh0Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEwNTA0Mw==", "bodyText": "TODO: If nothing to do, should we remove your name from the comment?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552105043", "createdAt": "2021-01-05T18:11:15Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -896,39 +946,103 @@ private void openSession() throws SQLException {\n       openReq.setPassword(sessConfMap.get(JdbcConnectionParams.AUTH_PASSWD));\n     }\n \n+    //TODO(Vihang): This is a bit hacky. We piggy back on a dummy OpenSession call", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 150}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDI0MzQ1", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562024345", "createdAt": "2021-01-05T18:20:03Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoyMDowM1rOIOiJHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoyMDowM1rOIOiJHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjExMDM2NA==", "bodyText": "is this a known error code for failed auth?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552110364", "createdAt": "2021-01-05T18:20:03Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -896,39 +946,103 @@ private void openSession() throws SQLException {\n       openReq.setPassword(sessConfMap.get(JdbcConnectionParams.AUTH_PASSWD));\n     }\n \n+    //TODO(Vihang): This is a bit hacky. We piggy back on a dummy OpenSession call\n+    // to get the redirect response from the server. Instead its probably cleaner to\n+    // explicitly do a HTTP post request and get the response.\n+    int numRetry = isBrowserAuthMode() ? 2 : 1;\n+    for (int i=0; i<numRetry; i++) {\n+      try {\n+        openSession(openReq);\n+      } catch (TException e) {\n+        if (isSamlRedirect(e)) {\n+          boolean success = doBrowserSSO();\n+          if (!success) {\n+            String msg = browserClient.getServerResponse() == null\n+                || browserClient.getServerResponse().getMsg() == null ? \"\"\n+                : browserClient.getServerResponse().getMsg();\n+            throw new SQLException(\n+                \"Could not establish connection to \" + jdbcUriString + \": \"\n+                    + msg, \" 08S01\", e);\n+          }\n+        } else {\n+          throw new SQLException(\n+              \"Could not establish connection to \" + jdbcUriString + \": \" + e\n+                  .getMessage(), \" 08S01\", e);\n+        }\n+      }\n+    }\n+    isClosed = false;\n+  }\n+\n+  private boolean doBrowserSSO() throws SQLException {\n     try {\n-      TOpenSessionResp openResp = client.OpenSession(openReq);\n+      Preconditions.checkNotNull(browserClient);\n+      try (IJdbcBrowserClient bc = browserClient) {\n+        browserClient.doBrowserSSO();\n+        HiveJdbcBrowserServerResponse response = browserClient.getServerResponse();\n+        if (response != null) {\n+          return response.isSuccessful();\n+        }\n+        return false;\n+      }\n+    } catch (Exception ex) {\n+      throw new SQLException(\"Browser based SSO failed: \" + ex.getMessage(),\n+          \" 08S01\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 192}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDI1MDM5", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562025039", "createdAt": "2021-01-05T18:21:03Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoyMTowM1rOIOiK_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxODoyMTowM1rOIOiK_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjExMDg0Ng==", "bodyText": "is 08S01 a known error code for failed auth with SAML?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552110846", "createdAt": "2021-01-05T18:21:03Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -896,39 +946,103 @@ private void openSession() throws SQLException {\n       openReq.setPassword(sessConfMap.get(JdbcConnectionParams.AUTH_PASSWD));\n     }\n \n+    //TODO(Vihang): This is a bit hacky. We piggy back on a dummy OpenSession call\n+    // to get the redirect response from the server. Instead its probably cleaner to\n+    // explicitly do a HTTP post request and get the response.\n+    int numRetry = isBrowserAuthMode() ? 2 : 1;\n+    for (int i=0; i<numRetry; i++) {\n+      try {\n+        openSession(openReq);\n+      } catch (TException e) {\n+        if (isSamlRedirect(e)) {\n+          boolean success = doBrowserSSO();\n+          if (!success) {\n+            String msg = browserClient.getServerResponse() == null\n+                || browserClient.getServerResponse().getMsg() == null ? \"\"\n+                : browserClient.getServerResponse().getMsg();\n+            throw new SQLException(\n+                \"Could not establish connection to \" + jdbcUriString + \": \"\n+                    + msg, \" 08S01\", e);\n+          }\n+        } else {\n+          throw new SQLException(\n+              \"Could not establish connection to \" + jdbcUriString + \": \" + e\n+                  .getMessage(), \" 08S01\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 171}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDY0OTA4", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562064908", "createdAt": "2021-01-05T19:21:21Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxOToyMToyMVrOIOkEBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxOToyMToyMVrOIOkEBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjE0MTgyOA==", "bodyText": "its not clear what the change is here. The proposed code looks similar to the existing code in the OpenSession() method. What has changed?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552141828", "createdAt": "2021-01-05T19:21:21Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -896,39 +946,103 @@ private void openSession() throws SQLException {\n       openReq.setPassword(sessConfMap.get(JdbcConnectionParams.AUTH_PASSWD));\n     }\n \n+    //TODO(Vihang): This is a bit hacky. We piggy back on a dummy OpenSession call\n+    // to get the redirect response from the server. Instead its probably cleaner to\n+    // explicitly do a HTTP post request and get the response.\n+    int numRetry = isBrowserAuthMode() ? 2 : 1;\n+    for (int i=0; i<numRetry; i++) {\n+      try {\n+        openSession(openReq);\n+      } catch (TException e) {\n+        if (isSamlRedirect(e)) {\n+          boolean success = doBrowserSSO();\n+          if (!success) {\n+            String msg = browserClient.getServerResponse() == null\n+                || browserClient.getServerResponse().getMsg() == null ? \"\"\n+                : browserClient.getServerResponse().getMsg();\n+            throw new SQLException(\n+                \"Could not establish connection to \" + jdbcUriString + \": \"\n+                    + msg, \" 08S01\", e);\n+          }\n+        } else {\n+          throw new SQLException(\n+              \"Could not establish connection to \" + jdbcUriString + \": \" + e\n+                  .getMessage(), \" 08S01\", e);\n+        }\n+      }\n+    }\n+    isClosed = false;\n+  }\n+\n+  private boolean doBrowserSSO() throws SQLException {\n     try {\n-      TOpenSessionResp openResp = client.OpenSession(openReq);\n+      Preconditions.checkNotNull(browserClient);\n+      try (IJdbcBrowserClient bc = browserClient) {\n+        browserClient.doBrowserSSO();\n+        HiveJdbcBrowserServerResponse response = browserClient.getServerResponse();\n+        if (response != null) {\n+          return response.isSuccessful();\n+        }\n+        return false;\n+      }\n+    } catch (Exception ex) {\n+      throw new SQLException(\"Browser based SSO failed: \" + ex.getMessage(),\n+          \" 08S01\",\n+          ex);\n+    }\n+  }\n \n-      // Populate a given configuration from HS2 server HiveConf, only if that configuration\n-      // is not already present in Connection parameter HiveConf i.e., client side configuration\n-      // takes precedence over the server side configuration.\n-      Map<String, String> serverHiveConf = openResp.getConfiguration();\n+  @VisibleForTesting\n+  public IJdbcBrowserClient getBrowserClient() {\n+    return browserClient;\n+  }\n \n-      updateServerHiveConf(serverHiveConf, connParams);\n+  private void openSession(TOpenSessionReq openReq) throws TException, SQLException {\n+    TOpenSessionResp openResp = client.OpenSession(openReq);\n \n-      // validate connection\n-      Utils.verifySuccess(openResp.getStatus());\n-      if (!supportedProtocols.contains(openResp.getServerProtocolVersion())) {\n-        throw new TException(\"Unsupported Hive2 protocol\");\n-      }\n-      protocol = openResp.getServerProtocolVersion();\n-      sessHandle = openResp.getSessionHandle();\n-\n-      final String serverFetchSizeString =\n-          openResp.getConfiguration().get(ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname);\n-      if (serverFetchSizeString == null) {\n-        throw new IllegalStateException(\"Server returned a null default fetch size. Check that \"\n-            + ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname + \" is configured correctly.\");\n-      }\n+    // Populate a given configuration from HS2 server HiveConf, only if that configuration", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 224}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMDczNjAw", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562073600", "createdAt": "2021-01-05T19:34:12Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxOTozNDoxMlrOIOkgMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxOTozNDoxMlrOIOkgMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjE0OTA0MA==", "bodyText": "@vihangk1 Could you please add some comments to the method as to why we look for 302 and 303 in the error message. This will help remember the logic", "url": "https://github.com/apache/hive/pull/1791#discussion_r552149040", "createdAt": "2021-01-05T19:34:12Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -896,39 +946,103 @@ private void openSession() throws SQLException {\n       openReq.setPassword(sessConfMap.get(JdbcConnectionParams.AUTH_PASSWD));\n     }\n \n+    //TODO(Vihang): This is a bit hacky. We piggy back on a dummy OpenSession call\n+    // to get the redirect response from the server. Instead its probably cleaner to\n+    // explicitly do a HTTP post request and get the response.\n+    int numRetry = isBrowserAuthMode() ? 2 : 1;\n+    for (int i=0; i<numRetry; i++) {\n+      try {\n+        openSession(openReq);\n+      } catch (TException e) {\n+        if (isSamlRedirect(e)) {\n+          boolean success = doBrowserSSO();\n+          if (!success) {\n+            String msg = browserClient.getServerResponse() == null\n+                || browserClient.getServerResponse().getMsg() == null ? \"\"\n+                : browserClient.getServerResponse().getMsg();\n+            throw new SQLException(\n+                \"Could not establish connection to \" + jdbcUriString + \": \"\n+                    + msg, \" 08S01\", e);\n+          }\n+        } else {\n+          throw new SQLException(\n+              \"Could not establish connection to \" + jdbcUriString + \": \" + e\n+                  .getMessage(), \" 08S01\", e);\n+        }\n+      }\n+    }\n+    isClosed = false;\n+  }\n+\n+  private boolean doBrowserSSO() throws SQLException {\n     try {\n-      TOpenSessionResp openResp = client.OpenSession(openReq);\n+      Preconditions.checkNotNull(browserClient);\n+      try (IJdbcBrowserClient bc = browserClient) {\n+        browserClient.doBrowserSSO();\n+        HiveJdbcBrowserServerResponse response = browserClient.getServerResponse();\n+        if (response != null) {\n+          return response.isSuccessful();\n+        }\n+        return false;\n+      }\n+    } catch (Exception ex) {\n+      throw new SQLException(\"Browser based SSO failed: \" + ex.getMessage(),\n+          \" 08S01\",\n+          ex);\n+    }\n+  }\n \n-      // Populate a given configuration from HS2 server HiveConf, only if that configuration\n-      // is not already present in Connection parameter HiveConf i.e., client side configuration\n-      // takes precedence over the server side configuration.\n-      Map<String, String> serverHiveConf = openResp.getConfiguration();\n+  @VisibleForTesting\n+  public IJdbcBrowserClient getBrowserClient() {\n+    return browserClient;\n+  }\n \n-      updateServerHiveConf(serverHiveConf, connParams);\n+  private void openSession(TOpenSessionReq openReq) throws TException, SQLException {\n+    TOpenSessionResp openResp = client.OpenSession(openReq);\n \n-      // validate connection\n-      Utils.verifySuccess(openResp.getStatus());\n-      if (!supportedProtocols.contains(openResp.getServerProtocolVersion())) {\n-        throw new TException(\"Unsupported Hive2 protocol\");\n-      }\n-      protocol = openResp.getServerProtocolVersion();\n-      sessHandle = openResp.getSessionHandle();\n-\n-      final String serverFetchSizeString =\n-          openResp.getConfiguration().get(ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname);\n-      if (serverFetchSizeString == null) {\n-        throw new IllegalStateException(\"Server returned a null default fetch size. Check that \"\n-            + ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname + \" is configured correctly.\");\n-      }\n+    // Populate a given configuration from HS2 server HiveConf, only if that configuration\n+    // is not already present in Connection parameter HiveConf i.e., client side configuration\n+    // takes precedence over the server side configuration.\n+    Map<String, String> serverHiveConf = openResp.getConfiguration();\n+\n+    updateServerHiveConf(serverHiveConf, connParams);\n+\n+    // validate connection\n+    Utils.verifySuccess(openResp.getStatus());\n+    if (!supportedProtocols.contains(openResp.getServerProtocolVersion())) {\n+      throw new TException(\"Unsupported Hive2 protocol\");\n+    }\n+    protocol = openResp.getServerProtocolVersion();\n+    sessHandle = openResp.getSessionHandle();\n \n-      this.defaultFetchSize = Integer.parseInt(serverFetchSizeString);\n-      if (this.defaultFetchSize <= 0) {\n-        throw new IllegalStateException(\"Default fetch size must be greater than 0\");\n+    final String serverFetchSizeString =\n+        openResp.getConfiguration().get(ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname);\n+    if (serverFetchSizeString == null) {\n+      throw new IllegalStateException(\"Server returned a null default fetch size. Check that \"\n+          + ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.varname + \" is configured correctly.\");\n+    }\n+\n+    this.defaultFetchSize = Integer.parseInt(serverFetchSizeString);\n+    if (this.defaultFetchSize <= 0) {\n+      throw new IllegalStateException(\"Default fetch size must be greater than 0\");\n+    }\n+  }\n+\n+  private boolean isSamlRedirect(TException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 255}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMzA3ODE0", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562307814", "createdAt": "2021-01-06T03:46:40Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwMzo0Njo0MVrOIOw8tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwMzo0Njo0MVrOIOw8tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM1Mjk1MQ==", "bodyText": "should this account for serverSocket being null in case of an exception in getServerSocket() ?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552352951", "createdAt": "2021-01-06T03:46:41Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/saml/HiveJdbcBrowserClient.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.jdbc.saml;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import java.awt.Desktop;\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.PrintWriter;\n+import java.io.UnsupportedEncodingException;\n+import java.net.InetAddress;\n+import java.net.ServerSocket;\n+import java.net.Socket;\n+import java.net.SocketTimeoutException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLDecoder;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.hive.jdbc.Utils.JdbcConnectionParams;\n+import org.apache.hive.service.auth.saml.HiveSamlUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class is used to execute a browser based SSO workflow with the authentication mode\n+ * is browser.\n+ */\n+public class HiveJdbcBrowserClient implements IJdbcBrowserClient {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveJdbcBrowserClient.class);\n+  // error message when the socket times out.\n+  @VisibleForTesting\n+  public static final String TIMEOUT_ERROR_MSG = \"Timed out while waiting for server response\";\n+  private final ServerSocket serverSocket;\n+  private HiveJdbcBrowserServerResponse serverResponse;\n+  protected JdbcBrowserClientContext clientContext;\n+  // By default we wait for 2 min unless overridden by a JDBC connection param\n+  // browserResponseTimeout\n+  private static final int DEFAULT_SOCKET_TIMEOUT_SECS = 120;\n+  private final ExecutorService serverResponseThread = Executors.newSingleThreadExecutor(\n+      new ThreadFactoryBuilder().setNameFormat(\"Hive-Jdbc-Browser-Client-%d\")\n+          .setDaemon(true).build());\n+\n+  HiveJdbcBrowserClient(JdbcConnectionParams connectionParams)\n+      throws HiveJdbcBrowserException {\n+    serverSocket = getServerSocket(connectionParams.getSessionVars());\n+  }\n+\n+  private ServerSocket getServerSocket(Map<String, String> sessionConf)\n+      throws HiveJdbcBrowserException {\n+    final ServerSocket serverSocket;\n+    int port = Integer.parseInt(sessionConf\n+        .getOrDefault(JdbcConnectionParams.AUTH_BROWSER_RESPONSE_PORT, \"0\"));\n+    int timeout = Integer.parseInt(\n+        sessionConf.getOrDefault(JdbcConnectionParams.AUTH_BROWSER_RESPONSE_TIMEOUT_SECS,\n+            String.valueOf(DEFAULT_SOCKET_TIMEOUT_SECS)));\n+    try {\n+      serverSocket = new ServerSocket(port, 0,\n+          InetAddress.getByName(HiveSamlUtils.LOOP_BACK_INTERFACE));\n+      LOG.debug(\"Browser response timeout is set to {} seconds\", timeout);\n+      serverSocket.setSoTimeout(timeout * 1000);\n+    } catch (IOException e) {\n+      throw new HiveJdbcBrowserException(\"Unable to bind to the localhost\");\n+    }\n+    return serverSocket;\n+  }\n+\n+  public Integer getPort() {\n+    return serverSocket.getLocalPort();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMzA4MDM3", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562308037", "createdAt": "2021-01-06T03:47:37Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwMzo0NzozN1rOIOw9hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwMzo0NzozN1rOIOw9hQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM1MzE1Nw==", "bodyText": "looks like this needs some real validation code?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552353157", "createdAt": "2021-01-06T03:47:37Z", "author": {"login": "nrg4878"}, "path": "jdbc/src/java/org/apache/hive/jdbc/saml/HiveJdbcBrowserClient.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.jdbc.saml;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import java.awt.Desktop;\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.PrintWriter;\n+import java.io.UnsupportedEncodingException;\n+import java.net.InetAddress;\n+import java.net.ServerSocket;\n+import java.net.Socket;\n+import java.net.SocketTimeoutException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLDecoder;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.hive.jdbc.Utils.JdbcConnectionParams;\n+import org.apache.hive.service.auth.saml.HiveSamlUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class is used to execute a browser based SSO workflow with the authentication mode\n+ * is browser.\n+ */\n+public class HiveJdbcBrowserClient implements IJdbcBrowserClient {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveJdbcBrowserClient.class);\n+  // error message when the socket times out.\n+  @VisibleForTesting\n+  public static final String TIMEOUT_ERROR_MSG = \"Timed out while waiting for server response\";\n+  private final ServerSocket serverSocket;\n+  private HiveJdbcBrowserServerResponse serverResponse;\n+  protected JdbcBrowserClientContext clientContext;\n+  // By default we wait for 2 min unless overridden by a JDBC connection param\n+  // browserResponseTimeout\n+  private static final int DEFAULT_SOCKET_TIMEOUT_SECS = 120;\n+  private final ExecutorService serverResponseThread = Executors.newSingleThreadExecutor(\n+      new ThreadFactoryBuilder().setNameFormat(\"Hive-Jdbc-Browser-Client-%d\")\n+          .setDaemon(true).build());\n+\n+  HiveJdbcBrowserClient(JdbcConnectionParams connectionParams)\n+      throws HiveJdbcBrowserException {\n+    serverSocket = getServerSocket(connectionParams.getSessionVars());\n+  }\n+\n+  private ServerSocket getServerSocket(Map<String, String> sessionConf)\n+      throws HiveJdbcBrowserException {\n+    final ServerSocket serverSocket;\n+    int port = Integer.parseInt(sessionConf\n+        .getOrDefault(JdbcConnectionParams.AUTH_BROWSER_RESPONSE_PORT, \"0\"));\n+    int timeout = Integer.parseInt(\n+        sessionConf.getOrDefault(JdbcConnectionParams.AUTH_BROWSER_RESPONSE_TIMEOUT_SECS,\n+            String.valueOf(DEFAULT_SOCKET_TIMEOUT_SECS)));\n+    try {\n+      serverSocket = new ServerSocket(port, 0,\n+          InetAddress.getByName(HiveSamlUtils.LOOP_BACK_INTERFACE));\n+      LOG.debug(\"Browser response timeout is set to {} seconds\", timeout);\n+      serverSocket.setSoTimeout(timeout * 1000);\n+    } catch (IOException e) {\n+      throw new HiveJdbcBrowserException(\"Unable to bind to the localhost\");\n+    }\n+    return serverSocket;\n+  }\n+\n+  public Integer getPort() {\n+    return serverSocket.getLocalPort();\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (serverSocket != null) {\n+      serverSocket.close();\n+    }\n+  }\n+\n+  public void init(JdbcBrowserClientContext clientContext) {\n+    // everytime we set the sso URI we should clean up the previous state if its set.\n+    // this may be from the previous invalid connection attempt or if the token has\n+    // expired\n+    reset();\n+    this.clientContext = clientContext;\n+    LOG.trace(\"Initialized the JDBCBrowser client with URL {}\",\n+        clientContext.getSsoUri());\n+  }\n+\n+  private void reset() {\n+    serverResponse = null;\n+    clientContext = null;\n+  }\n+\n+  private boolean validateSSOUrl(URI ssoUrl) {\n+    //TODO(Vihang) add URL validation code here\n+    return true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMzExMzMz", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562311333", "createdAt": "2021-01-06T04:00:28Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwNDowMDoyOFrOIOxJZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwNDowMDoyOFrOIOxJZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM1NjE5Ng==", "bodyText": "should define the scope for this dependency. Might pull in transitive dependencies that might be undesirable.", "url": "https://github.com/apache/hive/pull/1791#discussion_r552356196", "createdAt": "2021-01-06T04:00:28Z", "author": {"login": "nrg4878"}, "path": "service/pom.xml", "diffHunk": "@@ -179,6 +179,37 @@\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.pac4j</groupId>\n+      <artifactId>pac4j-saml-opensamlv3</artifactId>\n+      <version>4.0.3</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMzE0MzIz", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-562314323", "createdAt": "2021-01-06T04:13:15Z", "commit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwNDoxMzoxNVrOIOxUWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNlQwNDoxMzoxNVrOIOxUWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM1OTAwMQ==", "bodyText": "not sure I understand how this works.\nWhen auth is set to SAML on server, is this provider even called?", "url": "https://github.com/apache/hive/pull/1791#discussion_r552359001", "createdAt": "2021-01-06T04:13:15Z", "author": {"login": "nrg4878"}, "path": "service/src/java/org/apache/hive/service/auth/AuthenticationProviderFactory.java", "diffHunk": "@@ -76,6 +77,9 @@ public static PasswdAuthenticationProvider getAuthenticationProvider(AuthMethods\n       return new CustomAuthenticationProviderImpl((conf == null) ? AuthMethods.CUSTOM.getConf() : conf);\n     } else if (authMethod == AuthMethods.NONE) {\n       return new AnonymousAuthenticationProviderImpl();\n+    } else if (authMethod == AuthMethods.SAML) {\n+      //TODO right thing to do?\n+      return new AnonymousAuthenticationProviderImpl();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2763d7f5e05bad6a15c503d49666db55e33e7f7a"}, "originalPosition": 16}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "743948f9a0b9902a0b1259a7ddeaefd6ff3f2303", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/743948f9a0b9902a0b1259a7ddeaefd6ff3f2303", "committedDate": "2021-01-12T03:21:25Z", "message": "Naveen's comments II"}, "afterCommit": {"oid": "ed8075658219180ff70b0a301886acbb24e7949d", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/ed8075658219180ff70b0a301886acbb24e7949d", "committedDate": "2021-01-12T17:58:33Z", "message": "Naveen's comments II"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "96423408f7b768c3faf8b6f81c242f86c5ea792a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/96423408f7b768c3faf8b6f81c242f86c5ea792a", "committedDate": "2021-02-03T23:35:13Z", "message": "Add a check for support for Browse action"}, "afterCommit": {"oid": "450b0917f1068b06973a174f9efa7e1cb13e4739", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/450b0917f1068b06973a174f9efa7e1cb13e4739", "committedDate": "2021-02-03T23:40:45Z", "message": "Add a check for support for Browse action"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "450b0917f1068b06973a174f9efa7e1cb13e4739", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/450b0917f1068b06973a174f9efa7e1cb13e4739", "committedDate": "2021-02-03T23:40:45Z", "message": "Add a check for support for Browse action"}, "afterCommit": {"oid": "bf899e97a3af471e9ab96a336de4febb8d8d354a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/bf899e97a3af471e9ab96a336de4febb8d8d354a", "committedDate": "2021-02-18T19:44:08Z", "message": "Fixed compilation issue after rebase"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bf899e97a3af471e9ab96a336de4febb8d8d354a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/bf899e97a3af471e9ab96a336de4febb8d8d354a", "committedDate": "2021-02-18T19:44:08Z", "message": "Fixed compilation issue after rebase"}, "afterCommit": {"oid": "87e4f3877657254967e720436088f7df59d35946", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/87e4f3877657254967e720436088f7df59d35946", "committedDate": "2021-02-22T23:18:29Z", "message": "updated TODO"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "87e4f3877657254967e720436088f7df59d35946", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/87e4f3877657254967e720436088f7df59d35946", "committedDate": "2021-02-22T23:18:29Z", "message": "updated TODO"}, "afterCommit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/b358b44038c5d47eeb70db29728e65f50727c7b1", "committedDate": "2021-02-24T21:13:58Z", "message": "updated TODO"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA3NzA3MzI0", "url": "https://github.com/apache/hive/pull/1791#pullrequestreview-607707324", "createdAt": "2021-03-09T18:02:56Z", "commit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wOVQxODowMjo1NlrOIzPTfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wOVQxODowMzoyOFrOIzPUzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MDU5OTAzNw==", "bodyText": "We should not be logging configured user and group filters to the logs regardless of the log levels. User's security configuration might be inadvertently logged to the files that are then distributed. Can you please create a follow up jira to review such statements.", "url": "https://github.com/apache/hive/pull/1791#discussion_r590599037", "createdAt": "2021-03-09T18:02:56Z", "author": {"login": "nrg4878"}, "path": "service/src/java/org/apache/hive/service/auth/saml/HiveSamlGroupNameFilter.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.auth.saml;\n+\n+import com.google.common.base.Predicate;\n+import com.google.common.base.Splitter;\n+import com.google.common.collect.ImmutableList;\n+import java.util.List;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.pac4j.saml.credentials.SAML2Credentials.SAMLAttribute;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class HiveSamlGroupNameFilter implements Predicate<SAMLAttribute> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(HiveSamlGroupNameFilter.class);\n+  private final List<String> groupNames;\n+  private static final Splitter COMMA_SPLITTER = Splitter.on(',').trimResults()\n+      .omitEmptyStrings();\n+  private final String attributeName;\n+\n+  public HiveSamlGroupNameFilter(HiveConf conf) {\n+    String groupNameStr = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_FILTER.varname);\n+    attributeName = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_ATTRIBUTE_NAME.varname, \"\");\n+    ImmutableList.Builder<String> builder = ImmutableList.builder();\n+    if (groupNameStr != null && !groupNameStr.isEmpty()) {\n+      builder\n+          .addAll(COMMA_SPLITTER.split(groupNameStr));\n+    }\n+    groupNames = builder.build();\n+    LOG.debug(\"Initialized allowed group names as {}\", groupNames);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MDU5OTE5Ng==", "bodyText": "ditto", "url": "https://github.com/apache/hive/pull/1791#discussion_r590599196", "createdAt": "2021-03-09T18:03:14Z", "author": {"login": "nrg4878"}, "path": "service/src/java/org/apache/hive/service/auth/saml/HiveSamlGroupNameFilter.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.auth.saml;\n+\n+import com.google.common.base.Predicate;\n+import com.google.common.base.Splitter;\n+import com.google.common.collect.ImmutableList;\n+import java.util.List;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.pac4j.saml.credentials.SAML2Credentials.SAMLAttribute;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class HiveSamlGroupNameFilter implements Predicate<SAMLAttribute> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(HiveSamlGroupNameFilter.class);\n+  private final List<String> groupNames;\n+  private static final Splitter COMMA_SPLITTER = Splitter.on(',').trimResults()\n+      .omitEmptyStrings();\n+  private final String attributeName;\n+\n+  public HiveSamlGroupNameFilter(HiveConf conf) {\n+    String groupNameStr = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_FILTER.varname);\n+    attributeName = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_ATTRIBUTE_NAME.varname, \"\");\n+    ImmutableList.Builder<String> builder = ImmutableList.builder();\n+    if (groupNameStr != null && !groupNameStr.isEmpty()) {\n+      builder\n+          .addAll(COMMA_SPLITTER.split(groupNameStr));\n+    }\n+    groupNames = builder.build();\n+    LOG.debug(\"Initialized allowed group names as {}\", groupNames);\n+  }\n+\n+  public boolean apply(List<SAMLAttribute> attributes) {\n+    if (attributeName.isEmpty() && attributes.size() == 0) {\n+      return true;\n+    }\n+    for (SAMLAttribute attribute : attributes) {\n+      if (apply(attribute)) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean apply(SAMLAttribute attribute) {\n+    if (attributeName.isEmpty()) {\n+      // if attributeName is not configured, then it means groups based\n+      // filtering is not enabled and we allow any authenticated user.\n+      return true;\n+    }\n+    if (attribute == null || attribute.getName() == null) {\n+      return false;\n+    }\n+    if (!attributeName.equals(attribute.getName())) {\n+      LOG.debug(\"Attribute name {} did not match with {}\", attribute.getName(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MDU5OTM3NA==", "bodyText": "ditto", "url": "https://github.com/apache/hive/pull/1791#discussion_r590599374", "createdAt": "2021-03-09T18:03:28Z", "author": {"login": "nrg4878"}, "path": "service/src/java/org/apache/hive/service/auth/saml/HiveSamlGroupNameFilter.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.service.auth.saml;\n+\n+import com.google.common.base.Predicate;\n+import com.google.common.base.Splitter;\n+import com.google.common.collect.ImmutableList;\n+import java.util.List;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.conf.HiveConf.ConfVars;\n+import org.pac4j.saml.credentials.SAML2Credentials.SAMLAttribute;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class HiveSamlGroupNameFilter implements Predicate<SAMLAttribute> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(HiveSamlGroupNameFilter.class);\n+  private final List<String> groupNames;\n+  private static final Splitter COMMA_SPLITTER = Splitter.on(',').trimResults()\n+      .omitEmptyStrings();\n+  private final String attributeName;\n+\n+  public HiveSamlGroupNameFilter(HiveConf conf) {\n+    String groupNameStr = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_FILTER.varname);\n+    attributeName = conf.get(ConfVars.HIVE_SERVER2_SAML_GROUP_ATTRIBUTE_NAME.varname, \"\");\n+    ImmutableList.Builder<String> builder = ImmutableList.builder();\n+    if (groupNameStr != null && !groupNameStr.isEmpty()) {\n+      builder\n+          .addAll(COMMA_SPLITTER.split(groupNameStr));\n+    }\n+    groupNames = builder.build();\n+    LOG.debug(\"Initialized allowed group names as {}\", groupNames);\n+  }\n+\n+  public boolean apply(List<SAMLAttribute> attributes) {\n+    if (attributeName.isEmpty() && attributes.size() == 0) {\n+      return true;\n+    }\n+    for (SAMLAttribute attribute : attributes) {\n+      if (apply(attribute)) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean apply(SAMLAttribute attribute) {\n+    if (attributeName.isEmpty()) {\n+      // if attributeName is not configured, then it means groups based\n+      // filtering is not enabled and we allow any authenticated user.\n+      return true;\n+    }\n+    if (attribute == null || attribute.getName() == null) {\n+      return false;\n+    }\n+    if (!attributeName.equals(attribute.getName())) {\n+      LOG.debug(\"Attribute name {} did not match with {}\", attribute.getName(),\n+          attributeName);\n+      return false;\n+    }\n+    for (String attrVal : attribute.getAttributeValues()) {\n+      LOG.debug(\"Evaluating group name {}\", attrVal);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1"}, "originalPosition": 80}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56f001cd10a71b77f19b021e208f7df2a8781aca", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/56f001cd10a71b77f19b021e208f7df2a8781aca", "committedDate": "2021-03-09T18:15:06Z", "message": "HIVE-24543: Support SAML 2.0 as an authentication mechanism"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45a8f828105adff42436e45595f136be07e3f1d7", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/45a8f828105adff42436e45595f136be07e3f1d7", "committedDate": "2021-03-09T18:15:06Z", "message": "fix ptest compile issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "301f823dc5dba39c9f323a0a1fc4afb5c7012c41", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/301f823dc5dba39c9f323a0a1fc4afb5c7012c41", "committedDate": "2021-03-09T18:15:06Z", "message": "renamed SAML2_0 to SAML"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f6c8f3f05ec0045c47c9c261dc06039dc13df83", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/7f6c8f3f05ec0045c47c9c261dc06039dc13df83", "committedDate": "2021-03-09T18:15:07Z", "message": "self-review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "230860c4673ab4813f30374ead3210bf20b1a413", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/230860c4673ab4813f30374ead3210bf20b1a413", "committedDate": "2021-03-09T18:15:07Z", "message": "Added additional configuration. SAML redirect happens when token is not present and port is present"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51b48da2bfcb765e12ec11a9c9b6f6ee674ea11b", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/51b48da2bfcb765e12ec11a9c9b6f6ee674ea11b", "committedDate": "2021-03-09T18:15:07Z", "message": "revert back the surefire plugin version change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "beae94af5981440b0417dc838815dc6b7e995b26", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/beae94af5981440b0417dc838815dc6b7e995b26", "committedDate": "2021-03-09T18:15:07Z", "message": "updated configuration description"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18d968b1db0280da101a4eed07ae1a32165cf1ed", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/18d968b1db0280da101a4eed07ae1a32165cf1ed", "committedDate": "2021-03-09T18:15:07Z", "message": "Naveen's review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d979cbc5df955ea8b7f8ebbd66ef4a0d40c2495", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/3d979cbc5df955ea8b7f8ebbd66ef4a0d40c2495", "committedDate": "2021-03-09T18:15:07Z", "message": "Naveen's comments II"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45f3913e13c70894fa80db53a6a0bdba16ccdc29", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/45f3913e13c70894fa80db53a6a0bdba16ccdc29", "committedDate": "2021-03-09T18:15:07Z", "message": "modified preconditions check to allow callback URLs without any port"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "277bd6fa4a0e04933d26da7fb4f25a018cdeb3aa", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/277bd6fa4a0e04933d26da7fb4f25a018cdeb3aa", "committedDate": "2021-03-09T18:15:07Z", "message": "Added a connection parameter to optionally disable SSL enforcement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1da6e7a2d06605b4e970a3e5bf55fd609d19b04f", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/1da6e7a2d06605b4e970a3e5bf55fd609d19b04f", "committedDate": "2021-03-09T18:15:07Z", "message": "reduced dependencies and fixed redirect code path"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "75b742399c8fce807ab4c85c41d9c9640f69a81e", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/75b742399c8fce807ab4c85c41d9c9640f69a81e", "committedDate": "2021-03-09T18:15:07Z", "message": "exclude unnecessary dependencies from lib"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "025cf4bf57bd77e87afee198120ab8a03a641061", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/025cf4bf57bd77e87afee198120ab8a03a641061", "committedDate": "2021-03-09T18:15:07Z", "message": "Add a check for support for Browse action"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a155fb8fe14e027bec9f03d23b2c8138cb3f7ead", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/a155fb8fe14e027bec9f03d23b2c8138cb3f7ead", "committedDate": "2021-03-09T18:15:07Z", "message": "Fixed compilation issue after rebase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e56ae4982e9958eef84c98fd15d5963dddd74e1", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/0e56ae4982e9958eef84c98fd15d5963dddd74e1", "committedDate": "2021-03-09T18:15:07Z", "message": "Fix for download artifact error for shibboleth dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df345030655ddf45466f0fbe846afb4703b2df1d", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/df345030655ddf45466f0fbe846afb4703b2df1d", "committedDate": "2021-03-09T18:15:07Z", "message": "Updated testcontainers library"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a10519626dac152d49a9860f8860d88959bccfe", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/5a10519626dac152d49a9860f8860d88959bccfe", "committedDate": "2021-03-09T18:15:07Z", "message": "updated TODO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a50b9148a3add789d267dd2a76a8e49cbb972a1a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/a50b9148a3add789d267dd2a76a8e49cbb972a1a", "committedDate": "2021-03-09T18:15:07Z", "message": "Naveen's comments regarding logging sensitive stuff"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b358b44038c5d47eeb70db29728e65f50727c7b1", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/b358b44038c5d47eeb70db29728e65f50727c7b1", "committedDate": "2021-02-24T21:13:58Z", "message": "updated TODO"}, "afterCommit": {"oid": "a50b9148a3add789d267dd2a76a8e49cbb972a1a", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/a50b9148a3add789d267dd2a76a8e49cbb972a1a", "committedDate": "2021-03-09T18:15:07Z", "message": "Naveen's comments regarding logging sensitive stuff"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2938, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}