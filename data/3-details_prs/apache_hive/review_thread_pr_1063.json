{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI4NDMwMjg1", "number": 1063, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzowMToxOFrOEDB5uQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxMTowMjoxNVrOEDZV8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNjEyMzQ1OnYy", "diffSide": "RIGHT", "path": "storage-api/src/java/org/apache/hive/common/util/SuppressFBWarnings.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzowMToxOFrOGf2Qwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzo1Nzo0NVrOGf4A-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng==", "bodyText": "Isn't there a SuppressFBWarnings annotation in findbugs package? Why do we need to introduce our own annotation?", "url": "https://github.com/apache/hive/pull/1063#discussion_r436048066", "createdAt": "2020-06-05T17:01:18Z", "author": {"login": "mustafaiman"}, "path": "storage-api/src/java/org/apache/hive/common/util/SuppressFBWarnings.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.apache.hive.common.util;\n+\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+\n+@Retention(RetentionPolicy.CLASS)\n+public @interface SuppressFBWarnings {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MzY3Nw==", "bodyText": "Hey @mustafaiman  -- in the main pom.xml we are only using the finbugs-maven-plugin and not the findbugs-annotation package (only hive-ql is using it as dependency and I would like to remove it eventually).\nIn order to avoid adding just another dependency (findbugs-annotation), I implemented the annotation as a separate class, Findbugs doesn't care in which package the annotation is, so it works pretty well -- we can also reuse it across hive packages.\nhttps://sourceforge.net/p/findbugs/feature-requests/298/#5e88", "url": "https://github.com/apache/hive/pull/1063#discussion_r436063677", "createdAt": "2020-06-05T17:32:49Z", "author": {"login": "pgaref"}, "path": "storage-api/src/java/org/apache/hive/common/util/SuppressFBWarnings.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.apache.hive.common.util;\n+\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+\n+@Retention(RetentionPolicy.CLASS)\n+public @interface SuppressFBWarnings {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng=="}, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3Njc5NQ==", "bodyText": "If we are defining our own annotation, I would like to put it in a common to prevent each module having their own copy of the same annotation. I thought hive-common would be a good candidate but storage-api does not depend on hive-common either. This looks like the only way then. Thanks for the link.", "url": "https://github.com/apache/hive/pull/1063#discussion_r436076795", "createdAt": "2020-06-05T17:57:45Z", "author": {"login": "mustafaiman"}, "path": "storage-api/src/java/org/apache/hive/common/util/SuppressFBWarnings.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.apache.hive.common.util;\n+\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+\n+@Retention(RetentionPolicy.CLASS)\n+public @interface SuppressFBWarnings {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng=="}, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNjU1MjcyOnYy", "diffSide": "RIGHT", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOToyMDoyNVrOGf6iQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOTo0MzozN1rOGf7H6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ==", "bodyText": "I think it's a little bit more than this.  There shouldn't be any \"+\" concatenation.  Should all be .append()\nI already proposed to addressed this issue (HIVE-23540), but happy to defer to this PR\nhttps://issues.apache.org/jira/browse/HIVE-23540", "url": "https://github.com/apache/hive/pull/1063#discussion_r436118081", "createdAt": "2020-06-05T19:20:25Z", "author": {"login": "belugabehr"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +78,13 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuffer bufStr = new StringBuffer();\n       if (cacheBuffers != null) {\n         for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNTQ5Ng==", "bodyText": "Hey @belugabehr  -- I see your point.\nSure, happy to integrate HIVE-23540 here.", "url": "https://github.com/apache/hive/pull/1063#discussion_r436125496", "createdAt": "2020-06-05T19:38:07Z", "author": {"login": "pgaref"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +78,13 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuffer bufStr = new StringBuffer();\n       if (cacheBuffers != null) {\n         for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ=="}, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNzcyMA==", "bodyText": "Updated", "url": "https://github.com/apache/hive/pull/1063#discussion_r436127720", "createdAt": "2020-06-05T19:43:37Z", "author": {"login": "pgaref"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +78,13 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuffer bufStr = new StringBuffer();\n       if (cacheBuffers != null) {\n         for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ=="}, "originalCommit": {"oid": "ed084759cc57675eaecc774ffbd5633099a2771e"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNjY2OTUwOnYy", "diffSide": "RIGHT", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOTo1Nzo0OFrOGf7qhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxMjoyNzowN1rOGgbSww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNjU4MQ==", "bodyText": "Will have to check this.  I think from my own patch experience, that this change might break a bunch of unit tests because they are checking the output of toString() which previously always adds a comma, even if it's not really needed.  I'm not 100%, but just FYI.", "url": "https://github.com/apache/hive/pull/1063#discussion_r436136581", "createdAt": "2020-06-05T19:57:48Z", "author": {"login": "belugabehr"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +79,21 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuilder sb = new StringBuilder();\n       if (cacheBuffers != null) {\n-        for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+        Iterator<MemoryBuffer> iter = cacheBuffers.iterator();\n+        while (iter.hasNext()) {\n+          MemoryBuffer mb = iter.next();\n+          sb.append(mb.getClass().getSimpleName());\n+          sb.append(\" with \");\n+          sb.append(mb.getByteBufferRaw().remaining());\n+          sb.append(\" bytes\");\n+          if (iter.hasNext()) {\n+            sb.append(\", \");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY1NDc4Nw==", "bodyText": "Tests passed so this change should be safe.", "url": "https://github.com/apache/hive/pull/1063#discussion_r436654787", "createdAt": "2020-06-08T12:27:07Z", "author": {"login": "pgaref"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +79,21 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuilder sb = new StringBuilder();\n       if (cacheBuffers != null) {\n-        for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+        Iterator<MemoryBuffer> iter = cacheBuffers.iterator();\n+        while (iter.hasNext()) {\n+          MemoryBuffer mb = iter.next();\n+          sb.append(mb.getClass().getSimpleName());\n+          sb.append(\" with \");\n+          sb.append(mb.getByteBufferRaw().remaining());\n+          sb.append(\" bytes\");\n+          if (iter.hasNext()) {\n+            sb.append(\", \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNjU4MQ=="}, "originalCommit": {"oid": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxOTk2NDAwOnYy", "diffSide": "RIGHT", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxMTowMjoxNVrOGgY54Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOFQxMjozMjoyNlrOGgbdlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjYxNTY0OQ==", "bodyText": "this equals doesn't care about next/prev fields", "url": "https://github.com/apache/hive/pull/1063#discussion_r436615649", "createdAt": "2020-06-08T11:02:15Z", "author": {"login": "kgyrtkirk"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java", "diffHunk": "@@ -228,6 +228,16 @@ public long getTotalLength() {\n     return result;\n   }\n \n+  @Override\n+  public int hashCode() {\n+    return super.hashCode();\n+  }\n+\n+  @Override\n+  public boolean equals(Object other) {\n+    return super.equals(other);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY1NzU1Nw==", "bodyText": "Addressed as part of 0e40c95\nAs discussed, let's make sure we update such methods across packages.", "url": "https://github.com/apache/hive/pull/1063#discussion_r436657557", "createdAt": "2020-06-08T12:32:26Z", "author": {"login": "pgaref"}, "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java", "diffHunk": "@@ -228,6 +228,16 @@ public long getTotalLength() {\n     return result;\n   }\n \n+  @Override\n+  public int hashCode() {\n+    return super.hashCode();\n+  }\n+\n+  @Override\n+  public boolean equals(Object other) {\n+    return super.equals(other);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjYxNTY0OQ=="}, "originalCommit": {"oid": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8"}, "originalPosition": 11}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 729, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}