{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY0NjY2ODM5", "number": 1380, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMToxNzo1NVrOEej31g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozNToxN1rOEekiLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDgwNDcwOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMToxNzo1NVrOHKR5mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMToxNzo1NVrOHKR5mQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU0MTA4MQ==", "bodyText": "Better follow the same pattern as the original function, return at the end.", "url": "https://github.com/apache/hive/pull/1380#discussion_r480541081", "createdAt": "2020-09-01T01:17:55Z", "author": {"login": "yongzhi"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -5695,8 +5695,16 @@ private void alter_table_core(String catName, String dbname, String name, Table\n       String[] parsedDbName = parseDbName(dbname, conf);\n       try {\n         ret = getMS().getTables(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], pattern);\n-        ret = FilterUtils.filterTableNamesIfEnabled(isServerFilterEnabled, filterHook,\n-            parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+        if(ret !=  null && !ret.isEmpty()) {\n+          List<Table> tableInfo = new ArrayList<>();\n+          tableInfo = getMS().getTableObjectsByName(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+          tableInfo = FilterUtils.filterTablesIfEnabled(isServerFilterEnabled, filterHook, tableInfo);\n+          List<String> result = new ArrayList<>(); // Cannot do ret.clear() because of query cannot be modified error in tests.\n+          for (Table tbl : tableInfo) {\n+            result.add(tbl.getTableName());\n+          }\n+          return result;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "078e37916a49268810b44d110d77632160e7faa5"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDg4MjcyOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozMDoxOFrOHKStjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozMDoxOFrOHKStjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU1NDM4Mw==", "bodyText": "Please add comments on why you pass-in tableInfo objects", "url": "https://github.com/apache/hive/pull/1380#discussion_r480554383", "createdAt": "2020-09-01T01:30:18Z", "author": {"login": "yongzhi"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -5695,8 +5695,16 @@ private void alter_table_core(String catName, String dbname, String name, Table\n       String[] parsedDbName = parseDbName(dbname, conf);\n       try {\n         ret = getMS().getTables(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], pattern);\n-        ret = FilterUtils.filterTableNamesIfEnabled(isServerFilterEnabled, filterHook,\n-            parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+        if(ret !=  null && !ret.isEmpty()) {\n+          List<Table> tableInfo = new ArrayList<>();\n+          tableInfo = getMS().getTableObjectsByName(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+          tableInfo = FilterUtils.filterTablesIfEnabled(isServerFilterEnabled, filterHook, tableInfo);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "078e37916a49268810b44d110d77632160e7faa5"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDkwNTAyOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozMzo1NVrOHKS9NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozMzo1NVrOHKS9NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU1ODM4OQ==", "bodyText": "Not quite understand the comment.  Maybe ret = new ArrayList<>();   good enough?", "url": "https://github.com/apache/hive/pull/1380#discussion_r480558389", "createdAt": "2020-09-01T01:33:55Z", "author": {"login": "yongzhi"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -5695,8 +5695,16 @@ private void alter_table_core(String catName, String dbname, String name, Table\n       String[] parsedDbName = parseDbName(dbname, conf);\n       try {\n         ret = getMS().getTables(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], pattern);\n-        ret = FilterUtils.filterTableNamesIfEnabled(isServerFilterEnabled, filterHook,\n-            parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+        if(ret !=  null && !ret.isEmpty()) {\n+          List<Table> tableInfo = new ArrayList<>();\n+          tableInfo = getMS().getTableObjectsByName(parsedDbName[CAT_NAME], parsedDbName[DB_NAME], ret);\n+          tableInfo = FilterUtils.filterTablesIfEnabled(isServerFilterEnabled, filterHook, tableInfo);\n+          List<String> result = new ArrayList<>(); // Cannot do ret.clear() because of query cannot be modified error in tests.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "078e37916a49268810b44d110d77632160e7faa5"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwNDkxMzEwOnYy", "diffSide": "RIGHT", "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMTozNToxN1rOHKTCxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjo0ODoxOVrOHb9Z_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU1OTgxMw==", "bodyText": "Is that possible also to assert on owner related values?", "url": "https://github.com/apache/hive/pull/1380#discussion_r480559813", "createdAt": "2020-09-01T01:35:17Z", "author": {"login": "yongzhi"}, "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java", "diffHunk": "@@ -600,6 +600,22 @@ public void testReplDump() throws Exception {\n     assertEquals(\"table name\", inDbTableName.toLowerCase(), dbObj.getObjectName());\n   }\n \n+  @Test\n+  public void showTablesInDB() throws Exception{\n+    final String tableName1 = \"table1\";\n+    driver.run(\"create table \" + dbName+\".\"+tableName1 + \"(eid int, yoj int)\");\n+    final String tableName2 = \"table2\";\n+    driver.run(\"create table \" + dbName+\".\"+tableName2 + \"(eid int, ecode int)\");\n+    reset(mockedAuthorizer);\n+\n+    int status = driver.compile(\"show tables in \"+dbName, true);\n+    assertEquals(0, status);\n+    Pair<List<HivePrivilegeObject>, List<HivePrivilegeObject>> io = getHivePrivilegeObjectInputs();\n+    List<HivePrivilegeObject> inputs = io.getLeft();\n+    HivePrivilegeObject dbObj = inputs.get(0);\n+    assertEquals(\"input type\", HivePrivilegeObjectType.DATABASE, dbObj.getType());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "078e37916a49268810b44d110d77632160e7faa5"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3OTY3Ng==", "bodyText": "I have added the assert on owner info.", "url": "https://github.com/apache/hive/pull/1380#discussion_r499079676", "createdAt": "2020-10-02T22:48:19Z", "author": {"login": "saihemanth-cloudera"}, "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/security/authorization/plugin/TestHiveAuthorizerCheckInvocation.java", "diffHunk": "@@ -600,6 +600,22 @@ public void testReplDump() throws Exception {\n     assertEquals(\"table name\", inDbTableName.toLowerCase(), dbObj.getObjectName());\n   }\n \n+  @Test\n+  public void showTablesInDB() throws Exception{\n+    final String tableName1 = \"table1\";\n+    driver.run(\"create table \" + dbName+\".\"+tableName1 + \"(eid int, yoj int)\");\n+    final String tableName2 = \"table2\";\n+    driver.run(\"create table \" + dbName+\".\"+tableName2 + \"(eid int, ecode int)\");\n+    reset(mockedAuthorizer);\n+\n+    int status = driver.compile(\"show tables in \"+dbName, true);\n+    assertEquals(0, status);\n+    Pair<List<HivePrivilegeObject>, List<HivePrivilegeObject>> io = getHivePrivilegeObjectInputs();\n+    List<HivePrivilegeObject> inputs = io.getLeft();\n+    HivePrivilegeObject dbObj = inputs.get(0);\n+    assertEquals(\"input type\", HivePrivilegeObjectType.DATABASE, dbObj.getType());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU1OTgxMw=="}, "originalCommit": {"oid": "078e37916a49268810b44d110d77632160e7faa5"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 504, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}