{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2NTg0MTQy", "number": 1544, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODowNzoxNVrOEtXZSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODowNzoxNVrOEtXZSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MDA0NjgyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODowNzoxNVrOHhHI2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQyMzowOToyMVrOIMDq5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ4MjAxMA==", "bodyText": "it seems like we have some inconsistency in GenericUDFMurmurHash which is registered as murmur_hash in the FunctionRegistry ; however in the UDF's annotation it only has hash - and here as well we use simply \"hash\".\na change like this will most likely cause a lot of q.out changes - could you file a follow-up ticket?", "url": "https://github.com/apache/hive/pull/1544#discussion_r504482010", "createdAt": "2020-10-14T08:07:15Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "diffHunk": "@@ -233,6 +235,23 @@ public static ExprNodeGenericFuncDesc and(List<ExprNodeDesc> exps) {\n     return new ExprNodeGenericFuncDesc(TypeInfoFactory.booleanTypeInfo, new GenericUDFOPAnd(), \"and\", flatExps);\n   }\n \n+  /**\n+   * Create an expression for computing a hash by recursively hashing given expressions by two:\n+   * <pre>\n+   * Input: HASH(A, B, C, D)\n+   * Output: HASH(HASH(HASH(A,B),C),D)\n+   * </pre>\n+   */\n+  public static ExprNodeGenericFuncDesc hash(List<ExprNodeDesc> exps) {\n+    assert exps.size() >= 2;\n+    ExprNodeDesc hashExp = exps.get(0);\n+    for (int i = 1; i < exps.size(); i++) {\n+      List<ExprNodeDesc> hArgs = Arrays.asList(hashExp, exps.get(i));\n+      hashExp = new ExprNodeGenericFuncDesc(TypeInfoFactory.intTypeInfo, new GenericUDFMurmurHash(), \"hash\", hArgs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5985e250350ed627c93dce1104506a16841010d4"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDYzODQ2MA==", "bodyText": "Good catch @kgyrtkirk ! I've never noticed that we have two different UDFs for hashing. Indeed having the same annotation can create quite some confusion and difficult to debug problems. I guess your suggestion is to change the annotation of GenericUDFMurmurHash to murmur_hash right?", "url": "https://github.com/apache/hive/pull/1544#discussion_r504638460", "createdAt": "2020-10-14T12:33:21Z", "author": {"login": "zabetak"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "diffHunk": "@@ -233,6 +235,23 @@ public static ExprNodeGenericFuncDesc and(List<ExprNodeDesc> exps) {\n     return new ExprNodeGenericFuncDesc(TypeInfoFactory.booleanTypeInfo, new GenericUDFOPAnd(), \"and\", flatExps);\n   }\n \n+  /**\n+   * Create an expression for computing a hash by recursively hashing given expressions by two:\n+   * <pre>\n+   * Input: HASH(A, B, C, D)\n+   * Output: HASH(HASH(HASH(A,B),C),D)\n+   * </pre>\n+   */\n+  public static ExprNodeGenericFuncDesc hash(List<ExprNodeDesc> exps) {\n+    assert exps.size() >= 2;\n+    ExprNodeDesc hashExp = exps.get(0);\n+    for (int i = 1; i < exps.size(); i++) {\n+      List<ExprNodeDesc> hArgs = Arrays.asList(hashExp, exps.get(i));\n+      hashExp = new ExprNodeGenericFuncDesc(TypeInfoFactory.intTypeInfo, new GenericUDFMurmurHash(), \"hash\", hArgs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ4MjAxMA=="}, "originalCommit": {"oid": "5985e250350ed627c93dce1104506a16841010d4"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjExMzE4Mg==", "bodyText": "yes; excatly", "url": "https://github.com/apache/hive/pull/1544#discussion_r542113182", "createdAt": "2020-12-14T05:02:01Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "diffHunk": "@@ -233,6 +235,23 @@ public static ExprNodeGenericFuncDesc and(List<ExprNodeDesc> exps) {\n     return new ExprNodeGenericFuncDesc(TypeInfoFactory.booleanTypeInfo, new GenericUDFOPAnd(), \"and\", flatExps);\n   }\n \n+  /**\n+   * Create an expression for computing a hash by recursively hashing given expressions by two:\n+   * <pre>\n+   * Input: HASH(A, B, C, D)\n+   * Output: HASH(HASH(HASH(A,B),C),D)\n+   * </pre>\n+   */\n+  public static ExprNodeGenericFuncDesc hash(List<ExprNodeDesc> exps) {\n+    assert exps.size() >= 2;\n+    ExprNodeDesc hashExp = exps.get(0);\n+    for (int i = 1; i < exps.size(); i++) {\n+      List<ExprNodeDesc> hArgs = Arrays.asList(hashExp, exps.get(i));\n+      hashExp = new ExprNodeGenericFuncDesc(TypeInfoFactory.intTypeInfo, new GenericUDFMurmurHash(), \"hash\", hArgs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ4MjAxMA=="}, "originalCommit": {"oid": "5985e250350ed627c93dce1104506a16841010d4"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUxMzk1OQ==", "bodyText": "Logged https://issues.apache.org/jira/browse/HIVE-24572 for this purpose.", "url": "https://github.com/apache/hive/pull/1544#discussion_r549513959", "createdAt": "2020-12-28T23:09:21Z", "author": {"login": "zabetak"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "diffHunk": "@@ -233,6 +235,23 @@ public static ExprNodeGenericFuncDesc and(List<ExprNodeDesc> exps) {\n     return new ExprNodeGenericFuncDesc(TypeInfoFactory.booleanTypeInfo, new GenericUDFOPAnd(), \"and\", flatExps);\n   }\n \n+  /**\n+   * Create an expression for computing a hash by recursively hashing given expressions by two:\n+   * <pre>\n+   * Input: HASH(A, B, C, D)\n+   * Output: HASH(HASH(HASH(A,B),C),D)\n+   * </pre>\n+   */\n+  public static ExprNodeGenericFuncDesc hash(List<ExprNodeDesc> exps) {\n+    assert exps.size() >= 2;\n+    ExprNodeDesc hashExp = exps.get(0);\n+    for (int i = 1; i < exps.size(); i++) {\n+      List<ExprNodeDesc> hArgs = Arrays.asList(hashExp, exps.get(i));\n+      hashExp = new ExprNodeGenericFuncDesc(TypeInfoFactory.intTypeInfo, new GenericUDFMurmurHash(), \"hash\", hArgs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ4MjAxMA=="}, "originalCommit": {"oid": "5985e250350ed627c93dce1104506a16841010d4"}, "originalPosition": 25}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 315, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}