{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzNjU4OTYx", "number": 1750, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMjozMDo0OFrOFDK5ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMzowODoxNlrOFDLr9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4ODY4NjE4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMjozMDo0OFrOICsgxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxMjoxMDo0NVrOIDGMvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY5NzM1MA==", "bodyText": "Needed?", "url": "https://github.com/apache/hive/pull/1750#discussion_r539697350", "createdAt": "2020-12-09T22:30:48Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -17,6 +17,7 @@\n  */\n package org.apache.hadoop.hive.ql.optimizer;\n \n+import java.io.File;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDExODIwNQ==", "bodyText": "yeah...I've some stuff which write out File-s for now...and I just remove it at the end of preparing the patch....\nit gives easier insights into what happened in the SWO.\nI would really like to build it into the system and expose it on the HS2 web interface - it would be very usefull...will get to that as well :)\nbut first I would like to finish this set of patches :)", "url": "https://github.com/apache/hive/pull/1750#discussion_r540118205", "createdAt": "2020-12-10T12:10:45Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -17,6 +17,7 @@\n  */\n package org.apache.hadoop.hive.ql.optimizer;\n \n+import java.io.File;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY5NzM1MA=="}, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM4ODgxNTI0OnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMzowODoxNlrOICtpUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMjo1NDozOVrOIDhBIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNTkyMw==", "bodyText": "Could merging these TS operators be effectively worse?\nFor instance, in this specific mock query, no partition will be pruned for the x1_store_sales table, while before partition pruning was kicking in. Thus, in this case, you are scanning the same data whether you have one or two TS operators (two partitions), however after merging the TS, the size of the data you are shuffling for the join doubles (data in both partitions twice)? Is that analysis correct?\nOff the top of my head, this could be beneficial if i) both TS only select a small subset of the partitions in the table, or ii) overlapping in the partition list for those two different TS is greater than a certain threshold. Should we work in that direction, i.e., introduce some config parameters for this?\n@rbalamohan , what is your take? It would be helpful to have a second opinion.", "url": "https://github.com/apache/hive/pull/1750#discussion_r539715923", "createdAt": "2020-12-09T23:08:16Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "diffHunk": "@@ -0,0 +1,291 @@\n+PREHOOK: query: drop table if exists x1_store_sales\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_store_sales\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_date_dim\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_date_dim\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_item\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_item\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_store_sales\n+POSTHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_store_sales\n+PREHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_date_dim\n+POSTHOOK: Lineage: x1_date_dim.d_date_sk SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_month_seq SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_moy SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_year SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=1).ss_item_sk SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=2).ss_item_sk SCRIPT []\n+PREHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+PREHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+PREHOOK: type: QUERY\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+POSTHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+Plan optimized by CBO.\n+\n+Vertex dependency in root stage\n+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Union 4 (CONTAINS)\n+Reducer 5 <- Union 4 (SIMPLE_EDGE)\n+Reducer 6 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 7 <- Reducer 6 (SIMPLE_EDGE), Union 4 (CONTAINS)\n+\n+Stage-0\n+  Fetch Operator\n+    limit:-1\n+    Stage-1\n+      Reducer 5 vectorized, llap\n+      File Output Operator [FS_89]\n+        Group By Operator [GBY_88] (rows=1 width=8)\n+          Output:[\"_col0\"],keys:KEY._col0\n+        <-Union 4 [SIMPLE_EDGE]\n+          <-Reducer 3 [CONTAINS] vectorized, llap\n+            Reduce Output Operator [RS_87]\n+              PartitionCols:_col0\n+              Group By Operator [GBY_86] (rows=1 width=8)\n+                Output:[\"_col0\"],keys:_col0\n+                Group By Operator [GBY_85] (rows=1 width=8)\n+                  Output:[\"_col0\"],aggregations:[\"count(VALUE._col0)\"]\n+                <-Reducer 2 [CUSTOM_SIMPLE_EDGE] llap\n+                  PARTITION_ONLY_SHUFFLE [RS_11]\n+                    Group By Operator [GBY_10] (rows=1 width=8)\n+                      Output:[\"_col0\"],aggregations:[\"count()\"]\n+                      Merge Join Operator [MERGEJOIN_51] (rows=1728398 width=8)\n+                        Conds:RS_71._col0=RS_77._col0(Inner)\n+                      <-Map 1 [SIMPLE_EDGE] vectorized, llap\n+                        SHUFFLE [RS_71]\n+                          PartitionCols:_col0\n+                          Select Operator [SEL_69] (rows=123457 width=4)\n+                            Output:[\"_col0\"]\n+                            Filter Operator [FIL_68]\n+                              predicate:ss_sold_date_sk is not null\n+                              TableScan [TS_0] (rows=123457 width=14)\n+                                default@x1_store_sales,s,Tbl:COMPLETE,Col:COMPLETE,Output:[\"ss_item_sk\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDExNjc2NA==", "bodyText": "I think right now we don't have a sanity check filter right before the TS to limit reduce shuffled data size to the previous amount; but reducing the number of scans is beneficial - IIRC in the q23 query the scanned partitions were the same; so the benefit was real.\nIf we make available these things the same way as we have the SJ filters - then we could for sure avoid shuffling more data.\nNote: I think it would enable some further opportunities if we would change the SJ data transmission method from RS to EVENTOP - that way we shouldn't have to worry about parallel edges anymore...", "url": "https://github.com/apache/hive/pull/1750#discussion_r540116764", "createdAt": "2020-12-10T12:08:19Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "diffHunk": "@@ -0,0 +1,291 @@\n+PREHOOK: query: drop table if exists x1_store_sales\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_store_sales\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_date_dim\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_date_dim\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_item\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_item\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_store_sales\n+POSTHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_store_sales\n+PREHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_date_dim\n+POSTHOOK: Lineage: x1_date_dim.d_date_sk SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_month_seq SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_moy SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_year SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=1).ss_item_sk SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=2).ss_item_sk SCRIPT []\n+PREHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+PREHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+PREHOOK: type: QUERY\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+POSTHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+Plan optimized by CBO.\n+\n+Vertex dependency in root stage\n+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Union 4 (CONTAINS)\n+Reducer 5 <- Union 4 (SIMPLE_EDGE)\n+Reducer 6 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 7 <- Reducer 6 (SIMPLE_EDGE), Union 4 (CONTAINS)\n+\n+Stage-0\n+  Fetch Operator\n+    limit:-1\n+    Stage-1\n+      Reducer 5 vectorized, llap\n+      File Output Operator [FS_89]\n+        Group By Operator [GBY_88] (rows=1 width=8)\n+          Output:[\"_col0\"],keys:KEY._col0\n+        <-Union 4 [SIMPLE_EDGE]\n+          <-Reducer 3 [CONTAINS] vectorized, llap\n+            Reduce Output Operator [RS_87]\n+              PartitionCols:_col0\n+              Group By Operator [GBY_86] (rows=1 width=8)\n+                Output:[\"_col0\"],keys:_col0\n+                Group By Operator [GBY_85] (rows=1 width=8)\n+                  Output:[\"_col0\"],aggregations:[\"count(VALUE._col0)\"]\n+                <-Reducer 2 [CUSTOM_SIMPLE_EDGE] llap\n+                  PARTITION_ONLY_SHUFFLE [RS_11]\n+                    Group By Operator [GBY_10] (rows=1 width=8)\n+                      Output:[\"_col0\"],aggregations:[\"count()\"]\n+                      Merge Join Operator [MERGEJOIN_51] (rows=1728398 width=8)\n+                        Conds:RS_71._col0=RS_77._col0(Inner)\n+                      <-Map 1 [SIMPLE_EDGE] vectorized, llap\n+                        SHUFFLE [RS_71]\n+                          PartitionCols:_col0\n+                          Select Operator [SEL_69] (rows=123457 width=4)\n+                            Output:[\"_col0\"]\n+                            Filter Operator [FIL_68]\n+                              predicate:ss_sold_date_sk is not null\n+                              TableScan [TS_0] (rows=123457 width=14)\n+                                default@x1_store_sales,s,Tbl:COMPLETE,Col:COMPLETE,Output:[\"ss_item_sk\"]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNTkyMw=="}, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDMwMzU0Ng==", "bodyText": "@jcamachor I've added a config knob to control event operator merge", "url": "https://github.com/apache/hive/pull/1750#discussion_r540303546", "createdAt": "2020-12-10T16:19:56Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "diffHunk": "@@ -0,0 +1,291 @@\n+PREHOOK: query: drop table if exists x1_store_sales\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_store_sales\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_date_dim\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_date_dim\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_item\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_item\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_store_sales\n+POSTHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_store_sales\n+PREHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_date_dim\n+POSTHOOK: Lineage: x1_date_dim.d_date_sk SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_month_seq SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_moy SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_year SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=1).ss_item_sk SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=2).ss_item_sk SCRIPT []\n+PREHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+PREHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+PREHOOK: type: QUERY\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+POSTHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+Plan optimized by CBO.\n+\n+Vertex dependency in root stage\n+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Union 4 (CONTAINS)\n+Reducer 5 <- Union 4 (SIMPLE_EDGE)\n+Reducer 6 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 7 <- Reducer 6 (SIMPLE_EDGE), Union 4 (CONTAINS)\n+\n+Stage-0\n+  Fetch Operator\n+    limit:-1\n+    Stage-1\n+      Reducer 5 vectorized, llap\n+      File Output Operator [FS_89]\n+        Group By Operator [GBY_88] (rows=1 width=8)\n+          Output:[\"_col0\"],keys:KEY._col0\n+        <-Union 4 [SIMPLE_EDGE]\n+          <-Reducer 3 [CONTAINS] vectorized, llap\n+            Reduce Output Operator [RS_87]\n+              PartitionCols:_col0\n+              Group By Operator [GBY_86] (rows=1 width=8)\n+                Output:[\"_col0\"],keys:_col0\n+                Group By Operator [GBY_85] (rows=1 width=8)\n+                  Output:[\"_col0\"],aggregations:[\"count(VALUE._col0)\"]\n+                <-Reducer 2 [CUSTOM_SIMPLE_EDGE] llap\n+                  PARTITION_ONLY_SHUFFLE [RS_11]\n+                    Group By Operator [GBY_10] (rows=1 width=8)\n+                      Output:[\"_col0\"],aggregations:[\"count()\"]\n+                      Merge Join Operator [MERGEJOIN_51] (rows=1728398 width=8)\n+                        Conds:RS_71._col0=RS_77._col0(Inner)\n+                      <-Map 1 [SIMPLE_EDGE] vectorized, llap\n+                        SHUFFLE [RS_71]\n+                          PartitionCols:_col0\n+                          Select Operator [SEL_69] (rows=123457 width=4)\n+                            Output:[\"_col0\"]\n+                            Filter Operator [FIL_68]\n+                              predicate:ss_sold_date_sk is not null\n+                              TableScan [TS_0] (rows=123457 width=14)\n+                                default@x1_store_sales,s,Tbl:COMPLETE,Col:COMPLETE,Output:[\"ss_item_sk\"]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNTkyMw=="}, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU1NzYwMA==", "bodyText": "however after merging the TS, the size of the data you are shuffling for the join doubles\n\n\nYes, this is possible with merging. +1 on adding an option for enabling it.\nThere is additional option to reduce number of group by operator evaluations (e.g Q65 computes group by operator twice) which can help in reducing runtime.", "url": "https://github.com/apache/hive/pull/1750#discussion_r540557600", "createdAt": "2020-12-10T22:54:39Z", "author": {"login": "rbalamohan"}, "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "diffHunk": "@@ -0,0 +1,291 @@\n+PREHOOK: query: drop table if exists x1_store_sales\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_store_sales\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_date_dim\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_date_dim\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_item\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_item\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_store_sales\n+POSTHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_store_sales\n+PREHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_date_dim\n+POSTHOOK: Lineage: x1_date_dim.d_date_sk SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_month_seq SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_moy SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_year SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=1).ss_item_sk SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=2).ss_item_sk SCRIPT []\n+PREHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+PREHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+PREHOOK: type: QUERY\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+POSTHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+Plan optimized by CBO.\n+\n+Vertex dependency in root stage\n+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Union 4 (CONTAINS)\n+Reducer 5 <- Union 4 (SIMPLE_EDGE)\n+Reducer 6 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 7 <- Reducer 6 (SIMPLE_EDGE), Union 4 (CONTAINS)\n+\n+Stage-0\n+  Fetch Operator\n+    limit:-1\n+    Stage-1\n+      Reducer 5 vectorized, llap\n+      File Output Operator [FS_89]\n+        Group By Operator [GBY_88] (rows=1 width=8)\n+          Output:[\"_col0\"],keys:KEY._col0\n+        <-Union 4 [SIMPLE_EDGE]\n+          <-Reducer 3 [CONTAINS] vectorized, llap\n+            Reduce Output Operator [RS_87]\n+              PartitionCols:_col0\n+              Group By Operator [GBY_86] (rows=1 width=8)\n+                Output:[\"_col0\"],keys:_col0\n+                Group By Operator [GBY_85] (rows=1 width=8)\n+                  Output:[\"_col0\"],aggregations:[\"count(VALUE._col0)\"]\n+                <-Reducer 2 [CUSTOM_SIMPLE_EDGE] llap\n+                  PARTITION_ONLY_SHUFFLE [RS_11]\n+                    Group By Operator [GBY_10] (rows=1 width=8)\n+                      Output:[\"_col0\"],aggregations:[\"count()\"]\n+                      Merge Join Operator [MERGEJOIN_51] (rows=1728398 width=8)\n+                        Conds:RS_71._col0=RS_77._col0(Inner)\n+                      <-Map 1 [SIMPLE_EDGE] vectorized, llap\n+                        SHUFFLE [RS_71]\n+                          PartitionCols:_col0\n+                          Select Operator [SEL_69] (rows=123457 width=4)\n+                            Output:[\"_col0\"]\n+                            Filter Operator [FIL_68]\n+                              predicate:ss_sold_date_sk is not null\n+                              TableScan [TS_0] (rows=123457 width=14)\n+                                default@x1_store_sales,s,Tbl:COMPLETE,Col:COMPLETE,Output:[\"ss_item_sk\"]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNTkyMw=="}, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 199}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 135, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}