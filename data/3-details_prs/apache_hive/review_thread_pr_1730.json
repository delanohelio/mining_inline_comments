{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxNjk1MzE0", "number": 1730, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjo1NTo1NlrOFAOnSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQxNjo0ODoxOFrOFBRNjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1NzgzNzU1OnYy", "diffSide": "RIGHT", "path": "ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFixAcidKeyIndex.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxMjo1NTo1NlrOH-aTNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDowMzoxOFrOH-dKdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw==", "bodyText": "Shouldn't this check if the index was actually corrected in the new file? It just checks the output of the tool.", "url": "https://github.com/apache/hive/pull/1730#discussion_r535204663", "createdAt": "2020-12-03T12:55:56Z", "author": {"login": "pvargacl"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFixAcidKeyIndex.java", "diffHunk": "@@ -243,6 +233,12 @@ public void testInvalidKeyIndex() throws Exception {\n     checkInvalidKeyIndex(testFilePath);\n     // Try fixing, this should result in new fixed file.\n     fixInvalidIndex(testFilePath);\n+\n+    // Multiple stripes\n+    createTestAcidFile(testFilePath, 12000, new FaultyKeyIndexBuilder());\n+    checkInvalidKeyIndex(testFilePath);\n+    // Try fixing, this should result in new fixed file.\n+    fixInvalidIndex(testFilePath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIyMzk0Ng==", "bodyText": "There is a validation in the tool itself after the recovery, so if the index was still invalid, the output would be different.\nhttps://github.com/asinkovits/hive/blob/HIVE-24475/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java#L265", "url": "https://github.com/apache/hive/pull/1730#discussion_r535223946", "createdAt": "2020-12-03T13:24:09Z", "author": {"login": "asinkovits"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFixAcidKeyIndex.java", "diffHunk": "@@ -243,6 +233,12 @@ public void testInvalidKeyIndex() throws Exception {\n     checkInvalidKeyIndex(testFilePath);\n     // Try fixing, this should result in new fixed file.\n     fixInvalidIndex(testFilePath);\n+\n+    // Multiple stripes\n+    createTestAcidFile(testFilePath, 12000, new FaultyKeyIndexBuilder());\n+    checkInvalidKeyIndex(testFilePath);\n+    // Try fixing, this should result in new fixed file.\n+    fixInvalidIndex(testFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw=="}, "originalCommit": {"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MTU3NA==", "bodyText": "Ah ok, missed that.", "url": "https://github.com/apache/hive/pull/1730#discussion_r535251574", "createdAt": "2020-12-03T14:03:18Z", "author": {"login": "pvargacl"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFixAcidKeyIndex.java", "diffHunk": "@@ -243,6 +233,12 @@ public void testInvalidKeyIndex() throws Exception {\n     checkInvalidKeyIndex(testFilePath);\n     // Try fixing, this should result in new fixed file.\n     fixInvalidIndex(testFilePath);\n+\n+    // Multiple stripes\n+    createTestAcidFile(testFilePath, 12000, new FaultyKeyIndexBuilder());\n+    checkInvalidKeyIndex(testFilePath);\n+    // Try fixing, this should result in new fixed file.\n+    fixInvalidIndex(testFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw=="}, "originalCommit": {"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2ODc0ODk1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQxNjo0ODoxOFrOH_89eQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNzowMzozMVrOIAw2kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjgyMTExMw==", "bodyText": "Can this be moved out of the loop ?", "url": "https://github.com/apache/hive/pull/1730#discussion_r536821113", "createdAt": "2020-12-05T16:48:18Z", "author": {"login": "maheshk114"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java", "diffHunk": "@@ -163,11 +144,52 @@ static void checkFile(Configuration conf, Path inputPath) throws IOException {\n       return;\n     }\n \n-    boolean validIndex = isAcidKeyIndexValid(reader);\n+    AcidKeyIndexValidationResult validationResult = validate(conf, inputPath);\n+    boolean validIndex = validationResult.isValid;\n     System.out.println(\"Checking \" + inputPath + \" - acid key index is \" +\n         (validIndex ? \"valid\" : \"invalid\"));\n   }\n \n+  public static AcidKeyIndexValidationResult validate(Configuration conf, Path inputPath) throws IOException {\n+    AcidKeyIndexValidationResult result = new AcidKeyIndexValidationResult();\n+    FileSystem fs = inputPath.getFileSystem(conf);\n+    Reader reader = OrcFile.createReader(fs, inputPath);\n+    List<StripeInformation> stripes = reader.getStripes();\n+    RecordIdentifier[] keyIndex = OrcRecordUpdater.parseKeyIndex(reader);\n+    StructObjectInspector soi = (StructObjectInspector) reader.getObjectInspector();\n+    // struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint\n+\n+    long rowsProcessed = 0;\n+    try (RecordReader rr = reader.rows()) {\n+      for(int i=0; i<stripes.size(); i++) {\n+        rowsProcessed += stripes.get(i).getNumberOfRows();\n+        rr.seekToRow(rowsProcessed-1);\n+        OrcStruct row = (OrcStruct) rr.next(null);\n+\n+        List<? extends StructField> structFields = soi.getAllStructFieldRefs();\n+\n+        StructField transactionField = structFields.get(1);\n+        StructField bucketField = structFields.get(2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY3MTMxMg==", "bodyText": "Fixed.", "url": "https://github.com/apache/hive/pull/1730#discussion_r537671312", "createdAt": "2020-12-07T17:03:31Z", "author": {"login": "asinkovits"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java", "diffHunk": "@@ -163,11 +144,52 @@ static void checkFile(Configuration conf, Path inputPath) throws IOException {\n       return;\n     }\n \n-    boolean validIndex = isAcidKeyIndexValid(reader);\n+    AcidKeyIndexValidationResult validationResult = validate(conf, inputPath);\n+    boolean validIndex = validationResult.isValid;\n     System.out.println(\"Checking \" + inputPath + \" - acid key index is \" +\n         (validIndex ? \"valid\" : \"invalid\"));\n   }\n \n+  public static AcidKeyIndexValidationResult validate(Configuration conf, Path inputPath) throws IOException {\n+    AcidKeyIndexValidationResult result = new AcidKeyIndexValidationResult();\n+    FileSystem fs = inputPath.getFileSystem(conf);\n+    Reader reader = OrcFile.createReader(fs, inputPath);\n+    List<StripeInformation> stripes = reader.getStripes();\n+    RecordIdentifier[] keyIndex = OrcRecordUpdater.parseKeyIndex(reader);\n+    StructObjectInspector soi = (StructObjectInspector) reader.getObjectInspector();\n+    // struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint\n+\n+    long rowsProcessed = 0;\n+    try (RecordReader rr = reader.rows()) {\n+      for(int i=0; i<stripes.size(); i++) {\n+        rowsProcessed += stripes.get(i).getNumberOfRows();\n+        rr.seekToRow(rowsProcessed-1);\n+        OrcStruct row = (OrcStruct) rr.next(null);\n+\n+        List<? extends StructField> structFields = soi.getAllStructFieldRefs();\n+\n+        StructField transactionField = structFields.get(1);\n+        StructField bucketField = structFields.get(2);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjgyMTExMw=="}, "originalCommit": {"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956"}, "originalPosition": 104}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 123, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}