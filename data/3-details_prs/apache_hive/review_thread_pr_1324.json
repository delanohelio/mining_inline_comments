{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU3Mjg0NTI0", "number": 1324, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMjoxMlrOETtLmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDo0MjoyOFrOETte0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDk4NjQ4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMjoxMlrOG5lv4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwODo1MjowNlrOG6BDxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDQ4MQ==", "bodyText": "Can we move the new call before the if(pctx.getConf().getBoolVar(ConfVars.HIVE_SHARED_WORK_REUSE_MAPJOIN_CACHE)) { block? It makes sense to trigger that block at the very end in case we continue adding phases.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040481", "createdAt": "2020-07-30T14:32:12Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4Nzk0Mg==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1324#discussion_r463487942", "createdAt": "2020-07-31T08:52:06Z", "author": {"login": "kasakrisz"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDQ4MQ=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDk4NzYzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMjoyOFrOG5lwkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwODo1MjozMFrOG6BEgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDY1OA==", "bodyText": "Can we put this additional step under a new flag (true by default)?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040658", "createdAt": "2020-07-30T14:32:28Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODEzMQ==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488131", "createdAt": "2020-07-31T08:52:30Z", "author": {"login": "kasakrisz"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDY1OA=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDk5MDYwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMzowOFrOG5lyZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwODo1MjozOFrOG6BE3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTEyNA==", "bodyText": "This is the same as After SharedWorkSJOptimizer, no need to print it again.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041124", "createdAt": "2020-07-30T14:33:08Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODIyMg==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488222", "createdAt": "2020-07-31T08:52:38Z", "author": {"login": "kasakrisz"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTEyNA=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDk5NDQyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMzo1OFrOG5l0yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwODo1Mjo1MFrOG6BFPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTczOA==", "bodyText": "After SharedWorkOptimizer merging TS schema?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041738", "createdAt": "2020-07-30T14:33:58Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(\n+        pctx, optimizerCache, tableNameToOps, sortedTables, false);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"After SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODMxOQ==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488319", "createdAt": "2020-07-31T08:52:50Z", "author": {"login": "kasakrisz"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(\n+        pctx, optimizerCache, tableNameToOps, sortedTables, false);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"After SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTczOA=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MDk5ODU4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozNDo0N1rOG5l3RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwODo1MzowMFrOG6BFlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MjM3Mw==", "bodyText": "Can we add a clarifying comment to the new internal classes with the difference between both of them?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463042373", "createdAt": "2020-07-30T14:34:47Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -273,258 +287,332 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n-  private static boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCache optimizerCache,\n-      ArrayListMultimap<String, TableScanOperator> tableNameToOps, List<Entry<String, Long>> sortedTables,\n-      boolean removeSemijoin) throws SemanticException {\n-    // Boolean to keep track of whether this method actually merged any TS operators\n-    boolean mergedExecuted = false;\n-\n-    Multimap<String, TableScanOperator> existingOps = ArrayListMultimap.create();\n-    Set<Operator<?>> removedOps = new HashSet<>();\n-    for (Entry<String, Long> tablePair : sortedTables) {\n-      String tableName = tablePair.getKey();\n-      for (TableScanOperator discardableTsOp : tableNameToOps.get(tableName)) {\n-        if (removedOps.contains(discardableTsOp)) {\n-          LOG.debug(\"Skip {} as it has already been removed\", discardableTsOp);\n-          continue;\n-        }\n-        Collection<TableScanOperator> prevTsOps = existingOps.get(tableName);\n-        for (TableScanOperator retainableTsOp : prevTsOps) {\n-          if (removedOps.contains(retainableTsOp)) {\n-            LOG.debug(\"Skip {} as it has already been removed\", retainableTsOp);\n+  private static class BaseSharedWorkOptimizer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODQwNA==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488404", "createdAt": "2020-07-31T08:53:00Z", "author": {"login": "kasakrisz"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -273,258 +287,332 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n-  private static boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCache optimizerCache,\n-      ArrayListMultimap<String, TableScanOperator> tableNameToOps, List<Entry<String, Long>> sortedTables,\n-      boolean removeSemijoin) throws SemanticException {\n-    // Boolean to keep track of whether this method actually merged any TS operators\n-    boolean mergedExecuted = false;\n-\n-    Multimap<String, TableScanOperator> existingOps = ArrayListMultimap.create();\n-    Set<Operator<?>> removedOps = new HashSet<>();\n-    for (Entry<String, Long> tablePair : sortedTables) {\n-      String tableName = tablePair.getKey();\n-      for (TableScanOperator discardableTsOp : tableNameToOps.get(tableName)) {\n-        if (removedOps.contains(discardableTsOp)) {\n-          LOG.debug(\"Skip {} as it has already been removed\", discardableTsOp);\n-          continue;\n-        }\n-        Collection<TableScanOperator> prevTsOps = existingOps.get(tableName);\n-        for (TableScanOperator retainableTsOp : prevTsOps) {\n-          if (removedOps.contains(retainableTsOp)) {\n-            LOG.debug(\"Skip {} as it has already been removed\", retainableTsOp);\n+  private static class BaseSharedWorkOptimizer {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MjM3Mw=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MTAxNjk4OnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/llap/annotate_stats_join_pkfk.q.out", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozODozMFrOG5mCdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwNTo0Mzo0NFrOG58qGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NTIzOA==", "bodyText": "I do not see projected columns, so it is difficult to confirm whether this is because of the schema. Is it?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463045238", "createdAt": "2020-07-30T14:38:30Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/annotate_stats_join_pkfk.q.out", "diffHunk": "@@ -1191,14 +1191,6 @@ STAGE PLANS:\n                         sort order: +\n                         Map-reduce partition columns: _col0 (type: int)\n                         Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE\n-            Execution mode: vectorized, llap", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQxNTgzNA==", "bodyText": "I checked this with the debugger:\nTS[6]\ndbName = \"default\"\ntableName = \"store_n0\"\nneededColumns = {ArrayList@24024}  size = 1\n 0 = \"s_store_sk\"\n\nTS[3]\ndbName = \"default\"\ntableName = \"store_n0\"\nneededColumns = {ArrayList@24053}  size = 2\n 0 = \"s_store_sk\"\n 1 = \"s_floor_space\"", "url": "https://github.com/apache/hive/pull/1324#discussion_r463415834", "createdAt": "2020-07-31T05:43:44Z", "author": {"login": "kasakrisz"}, "path": "ql/src/test/results/clientpositive/llap/annotate_stats_join_pkfk.q.out", "diffHunk": "@@ -1191,14 +1191,6 @@ STAGE PLANS:\n                         sort order: +\n                         Map-reduce partition columns: _col0 (type: int)\n                         Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE\n-            Execution mode: vectorized, llap", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NTIzOA=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg5MTAzNTY5OnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/llap/auto_join_reordering_values.q.out", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDo0MjoyOFrOG5mN9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQwNjozNjowNlrOG59lHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0ODE4Mg==", "bodyText": "Why is this projection changing? Is this correct? I do not see the branch with date column.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463048182", "createdAt": "2020-07-30T14:42:28Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/auto_join_reordering_values.q.out", "diffHunk": "@@ -144,122 +144,30 @@ STAGE PLANS:\n                         tag: 0\n                         value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)\n                         auto parallelism: true\n-            Execution mode: vectorized, llap\n-            LLAP IO: no inputs\n-            Path -> Alias:\n-#### A masked pattern was here ####\n-            Path -> Partition:\n-#### A masked pattern was here ####\n-                Partition\n-                  base file name: orderpayment_small\n-                  input format: org.apache.hadoop.mapred.TextInputFormat\n-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                  properties:\n-                    bucket_count -1\n-                    bucketing_version 2\n-                    column.name.delimiter ,\n-                    columns dealid,date,time,cityid,userid\n-                    columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                    name default.orderpayment_small\n-                    serialization.format 1\n-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                \n-                    input format: org.apache.hadoop.mapred.TextInputFormat\n-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                    properties:\n-                      bucketing_version 2\n-                      column.name.delimiter ,\n-                      columns dealid,date,time,cityid,userid\n-                      columns.comments \n-                      columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                      name default.orderpayment_small\n-                      serialization.format 1\n-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    name: default.orderpayment_small\n-                  name: default.orderpayment_small\n-            Truncated Path -> Alias:\n-              /orderpayment_small [orderpayment]\n-        Map 6 \n-            Map Operator Tree:\n-                TableScan\n-                  alias: dim_pay_date\n-                  filterExpr: date is not null (type: boolean)\n-                  Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n-                  GatherStats: false\n                   Filter Operator\n                     isSamplingPred: false\n-                    predicate: date is not null (type: boolean)\n-                    Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n+                    predicate: dealid is not null (type: boolean)\n+                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n                     Select Operator\n-                      expressions: date (type: string)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQzMDk0Mg==", "bodyText": "The TS pulls the column date only was not merged due to validPreConditions failed:\n2020-07-30T23:20:32,796 DEBUG [a51ac124-5fb2-43bc-a0fc-f27099762584 main] optimizer.SharedWorkOptimizer: After SharedWorkSJOptimizer:\nTS[0]-FIL[44]-SEL[2]-RS[15]-MERGEJOIN[89]-RS[18]-MERGEJOIN[90]-RS[21]-MERGEJOIN[91]-RS[24]-MERGEJOIN[92]-SEL[27]-LIM[28]-FS[29]\nTS[3]-FIL[45]-SEL[5]-RS[16]-MERGEJOIN[89]\nTS[6]-FIL[46]-SEL[8]-RS[19]-MERGEJOIN[90]\nTS[9]-FIL[47]-SEL[11]-RS[22]-MERGEJOIN[91]\nTS[12]-FIL[48]-SEL[14]-RS[25]-MERGEJOIN[92]\n\nBoth has the same output works:\nTS[0] \nalias = \"orderpayment\"\ndbName = \"default\"\ntableName = \"orderpayment_small\"\nneededColumns = {ArrayList@24085}  size = 4\n 0 = \"dealid\"\n 1 = \"date\"\n 2 = \"cityid\"\n 3 = \"userid\"\noutputWorksOps1 = {HashSet@24017}  size = 2\n 0 = {ReduceSinkOperator@24028} \"RS[18]\"\n 1 = {CommonMergeJoinOperator@24029} \"MERGEJOIN[89]\"\n\nTS[3]\nalias = \"dim_pay_date\"\ndbName = \"default\"\ntableName = \"orderpayment_small\"\nneededColumns = {ArrayList@23791}  size = 1\n 0 = \"date\"\noutputWorksOps2 = {HashSet@24022}  size = 2\n 0 = {ReduceSinkOperator@24028} \"RS[18]\"\n 1 = {CommonMergeJoinOperator@24029} \"MERGEJOIN[89]\"", "url": "https://github.com/apache/hive/pull/1324#discussion_r463430942", "createdAt": "2020-07-31T06:36:06Z", "author": {"login": "kasakrisz"}, "path": "ql/src/test/results/clientpositive/llap/auto_join_reordering_values.q.out", "diffHunk": "@@ -144,122 +144,30 @@ STAGE PLANS:\n                         tag: 0\n                         value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)\n                         auto parallelism: true\n-            Execution mode: vectorized, llap\n-            LLAP IO: no inputs\n-            Path -> Alias:\n-#### A masked pattern was here ####\n-            Path -> Partition:\n-#### A masked pattern was here ####\n-                Partition\n-                  base file name: orderpayment_small\n-                  input format: org.apache.hadoop.mapred.TextInputFormat\n-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                  properties:\n-                    bucket_count -1\n-                    bucketing_version 2\n-                    column.name.delimiter ,\n-                    columns dealid,date,time,cityid,userid\n-                    columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                    name default.orderpayment_small\n-                    serialization.format 1\n-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                \n-                    input format: org.apache.hadoop.mapred.TextInputFormat\n-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                    properties:\n-                      bucketing_version 2\n-                      column.name.delimiter ,\n-                      columns dealid,date,time,cityid,userid\n-                      columns.comments \n-                      columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                      name default.orderpayment_small\n-                      serialization.format 1\n-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    name: default.orderpayment_small\n-                  name: default.orderpayment_small\n-            Truncated Path -> Alias:\n-              /orderpayment_small [orderpayment]\n-        Map 6 \n-            Map Operator Tree:\n-                TableScan\n-                  alias: dim_pay_date\n-                  filterExpr: date is not null (type: boolean)\n-                  Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n-                  GatherStats: false\n                   Filter Operator\n                     isSamplingPred: false\n-                    predicate: date is not null (type: boolean)\n-                    Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n+                    predicate: dealid is not null (type: boolean)\n+                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n                     Select Operator\n-                      expressions: date (type: string)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0ODE4Mg=="}, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 78}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 456, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}