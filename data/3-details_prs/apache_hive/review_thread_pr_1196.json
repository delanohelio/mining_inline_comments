{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyNjU4Mzc2", "number": 1196, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxODo0OVrOEKk6ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjozMDo1NVrOEKlMRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTI2MDUxOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxODo0OVrOGrsu6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxODo0OVrOGrsu6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3NDg1OQ==", "bodyText": "There is a slight problem here, if we are on hdfs and the file listing with id is supported. Few lines below there is a check for dirsnapshot == null, that was running every time for this case, but now it won't run if you call getacidstate with nonnull dirsnapshot", "url": "https://github.com/apache/hive/pull/1196#discussion_r448474859", "createdAt": "2020-07-01T16:18:49Z", "author": {"login": "pvargacl"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "diffHunk": "@@ -1305,7 +1322,9 @@ public static Directory getAcidState(FileSystem fileSystem, Path candidateDirect\n             bestBase, ignoreEmptyFiles, abortedDirectories, fs, validTxnList);\n       }\n     } else {\n-      dirSnapshots = getHdfsDirSnapshots(fs, candidateDirectory);\n+      if (dirSnapshots == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85c5a8261e6866be17a382e3d2634764029dbd81"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTMwNTY1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjozMDo1NVrOGrtLCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNzo1NjowNlrOGrv7qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ4MjA1Nw==", "bodyText": "this might be out-of-scope for this change: but this static method in AcidUtils is trying to do all the work upfront...\nwhich might lead to:\n\nthat it does work which is not even needed\nit doesn't scan some location - and the map just returns null ; so it might be not noticable\n\nI think it would be better if this method would return a something (it could still be a map) which could fill in stuff from hdfs if its not cached already...", "url": "https://github.com/apache/hive/pull/1196#discussion_r448482057", "createdAt": "2020-07-01T16:30:55Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "diffHunk": "@@ -2614,28 +2633,25 @@ public static Path getVersionFilePath(Path deltaOrBase) {\n           + \" from \" + jc.get(ValidTxnWriteIdList.VALID_TABLES_WRITEIDS_KEY));\n       return null;\n     }\n-    Directory acidInfo = AcidUtils.getAcidState(fs, dir, jc, idList, null, false);\n+    if (fs == null) {\n+      fs = dir.getFileSystem(jc);\n+    }\n+    // Collect the all of the files/dirs\n+    Map<Path, HdfsDirSnapshot> hdfsDirSnapshots = AcidUtils.getHdfsDirSnapshots(fs, dir);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "85c5a8261e6866be17a382e3d2634764029dbd81"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUyNzI3NA==", "bodyText": "Ohh.. I think I get it now.\n\nYou are right that this will do stuff which is not really needed in this case - namely creating objects which are not needed at here (dirSnapshot.metaDataFile/dirSnapshot.acidFormatFile), also we might list and create objects which are not needed in this snapshot. On the other hand the costly part on S3 (and on HDFS as well) is the number of remote calls, which is reduced to a single listing instead of doing the listing for every directory 1-by-1.\nIt is not possible that it does not scan some location which needed. If this happens then this is a bug in AcidUtils.getAcidState, as it has to return every directory which is readable\n\nWhat I do not understand in your comment is \"this method would return a something (it could still be a map) which could fill in stuff from hdfs if its not cached already\" - the main thing we would like to avoid here is the need of reading the HDFS again and again. The only way to realize that something is missing is reading the directory again... or I miss something :)", "url": "https://github.com/apache/hive/pull/1196#discussion_r448527274", "createdAt": "2020-07-01T17:56:06Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "diffHunk": "@@ -2614,28 +2633,25 @@ public static Path getVersionFilePath(Path deltaOrBase) {\n           + \" from \" + jc.get(ValidTxnWriteIdList.VALID_TABLES_WRITEIDS_KEY));\n       return null;\n     }\n-    Directory acidInfo = AcidUtils.getAcidState(fs, dir, jc, idList, null, false);\n+    if (fs == null) {\n+      fs = dir.getFileSystem(jc);\n+    }\n+    // Collect the all of the files/dirs\n+    Map<Path, HdfsDirSnapshot> hdfsDirSnapshots = AcidUtils.getHdfsDirSnapshots(fs, dir);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ4MjA1Nw=="}, "originalCommit": {"oid": "85c5a8261e6866be17a382e3d2634764029dbd81"}, "originalPosition": 57}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 696, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}