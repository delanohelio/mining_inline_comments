{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0NDQzNzQ1", "number": 1109, "title": "HIVE-22015: Add table constraints in CachedStore", "bodyText": "", "createdAt": "2020-06-15T10:29:36Z", "url": "https://github.com/apache/hive/pull/1109", "merged": true, "mergeCommit": {"oid": "c93d7797329103d6c509bada68b6da7f907b3dee"}, "closed": true, "closedAt": "2020-07-13T10:28:59Z", "author": {"login": "adesh-rao"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcrjtptABqjM0NDUzNDM5NDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc0e1SZAFqTQ0NzEyNTkyNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a810753e7bcbe9bc564fd65d4f9af2273110b164", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/a810753e7bcbe9bc564fd65d4f9af2273110b164", "committedDate": "2020-06-15T10:28:31Z", "message": "renaming variables/reorganizing imports"}, "afterCommit": {"oid": "c6f370c129c3f977afb76740275841dabcc7ce34", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/c6f370c129c3f977afb76740275841dabcc7ce34", "committedDate": "2020-06-15T17:00:08Z", "message": "renaming variables/reorganizing imports"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c6f370c129c3f977afb76740275841dabcc7ce34", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/c6f370c129c3f977afb76740275841dabcc7ce34", "committedDate": "2020-06-15T17:00:08Z", "message": "renaming variables/reorganizing imports"}, "afterCommit": {"oid": "111bf3dffed83715334e1d6c029febffdda2e6e7", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/111bf3dffed83715334e1d6c029febffdda2e6e7", "committedDate": "2020-06-18T08:53:17Z", "message": "renaming variables/reorganizing imports"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3NTE4ODE0", "url": "https://github.com/apache/hive/pull/1109#pullrequestreview-437518814", "createdAt": "2020-06-25T13:55:55Z", "commit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxMzo1NTo1NlrOGo75RQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxODoyN1rOGpeu_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU3NzU0MQ==", "bodyText": "Should be 2 spaced indentation. Check other places too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r445577541", "createdAt": "2020-06-25T13:55:56Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -402,6 +385,32 @@ private static void updateStatsForAlterTable(RawStore rawStore, Table tblBefore,\n         sharedCache.removePartitionColStatsFromCache(catalogName, dbName, tableName, msgPart.getPartValues(),\n             msgPart.getColName());\n         break;\n+      case MessageBuilder.ADD_PRIMARYKEY_EVENT:\n+          AddPrimaryKeyMessage addPrimaryKeyMessage = deserializer.getAddPrimaryKeyMessage(message);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU5OTYzOA==", "bodyText": "It seems missed to assign the return values from these rawStore calls to the local variables.", "url": "https://github.com/apache/hive/pull/1109#discussion_r445599638", "createdAt": "2020-06-25T14:26:18Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw==", "bodyText": "Too many arguments. Can we have another class (TableCacheObjects) to store all these arguments using set methods?", "url": "https://github.com/apache/hive/pull/1109#discussion_r445603527", "createdAt": "2020-06-25T14:31:32Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getForeignKeys\");\n+              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getUniqueConstraints\");\n+              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getNotNullConstraints\");\n+              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+\n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwOTY5OA==", "bodyText": "Failure logs can have catName and dbName too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r445609698", "createdAt": "2020-06-25T14:39:33Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +902,73 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of table: \" + tblName, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDQ2MA==", "bodyText": "Arguments names can be uks and uk.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446104460", "createdAt": "2020-06-26T10:32:49Z", "author": {"login": "sankarh"}, "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java", "diffHunk": "@@ -295,6 +295,178 @@ public void testTableOpsForUpdateUsingEvents() throws Exception {\n     sharedCache.getSdCache().clear();\n   }\n \n+  @Test\n+  public void testConstraintsForUpdateUsingEvents() throws Exception {\n+    long lastEventId = -1;\n+    RawStore rawStore = hmsHandler.getMS();\n+\n+    // Prewarm CachedStore\n+    CachedStore.setCachePrewarmedState(false);\n+    CachedStore.prewarm(rawStore);\n+\n+    // Add a db via rawStore\n+    String dbName = \"test_table_ops\";\n+    String dbOwner = \"user1\";\n+    Database db = createTestDb(dbName, dbOwner);\n+    hmsHandler.create_database(db);\n+    db = rawStore.getDatabase(DEFAULT_CATALOG_NAME, dbName);\n+\n+    String foreignDbName = \"test_table_ops_foreign\";\n+    Database foreignDb = createTestDb(foreignDbName, dbOwner);\n+    hmsHandler.create_database(foreignDb);\n+    foreignDb = rawStore.getDatabase(DEFAULT_CATALOG_NAME, foreignDbName);\n+    // Add a table via rawStore\n+    String tblName = \"tbl\";\n+    String tblOwner = \"user1\";\n+    FieldSchema col1 = new FieldSchema(\"col1\", \"int\", \"integer column\");\n+    FieldSchema col2 = new FieldSchema(\"col2\", \"string\", \"string column\");\n+    List<FieldSchema> cols = new ArrayList<FieldSchema>();\n+    cols.add(col1);\n+    cols.add(col2);\n+    List<FieldSchema> ptnCols = new ArrayList<FieldSchema>();\n+    Table tbl = createTestTbl(dbName, tblName, tblOwner, cols, ptnCols);\n+    String foreignTblName = \"ftbl\";\n+    Table foreignTbl = createTestTbl(foreignDbName, foreignTblName, tblOwner, cols, ptnCols);\n+\n+    SQLPrimaryKey key = new SQLPrimaryKey(dbName, tblName, col1.getName(), 1, \"pk1\",\n+            false, false, false);\n+    SQLUniqueConstraint uC = new SQLUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), 2, \"uc1\", false, false, false);\n+    SQLNotNullConstraint nN = new SQLNotNullConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), \"nn1\", false, false, false);\n+    SQLForeignKey foreignKey = new SQLForeignKey(key.getTable_db(), key.getTable_name(), key.getColumn_name(),\n+            foreignDbName, foreignTblName, key.getColumn_name(), 2, 1,2,\n+            \"fk1\", key.getPk_name(), false, false, false);\n+\n+    hmsHandler.create_table_with_constraints(tbl,\n+            Arrays.asList(key), null, Arrays.asList(uC), Arrays.asList(nN), null, null);\n+    hmsHandler.create_table_with_constraints(foreignTbl, null, Arrays.asList(foreignKey),\n+            null, null, null, null);\n+\n+    tbl = rawStore.getTable(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    foreignTbl = rawStore.getTable(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+\n+    // Read database, table via CachedStore\n+    Database dbRead= sharedCache.getDatabaseFromCache(DEFAULT_CATALOG_NAME, dbName);\n+    Assert.assertEquals(db, dbRead);\n+    Table tblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    compareTables(tblRead, tbl);\n+\n+    Table foreignTblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+    compareTables(foreignTblRead, foreignTbl);\n+\n+    List<SQLPrimaryKey> keys = rawStore.getPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLPrimaryKey> keysRead = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keysRead, 1, 0, keys.get(0));\n+\n+    List<SQLNotNullConstraint> nNs = rawStore.getNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLNotNullConstraint> nNsRead = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNsRead, 1, 0, nNs.get(0));\n+\n+    List<SQLUniqueConstraint> uns = rawStore.getUniqueConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLUniqueConstraint> unsRead = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(unsRead, 1, 0, uns.get(0));\n+\n+    List<SQLForeignKey> fks = rawStore.getForeignKeys(DEFAULT_CATALOG_NAME, dbName, tblName, foreignDbName, foreignTblName);\n+    List<SQLForeignKey> fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName,\n+            foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, fks.get(0));\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            dbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, tblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            null, null);\n+    Assert.assertEquals(fksRead.size(), 1);\n+\n+    // Dropping the constraint\n+    DropConstraintRequest dropConstraintRequest = new DropConstraintRequest(foreignDbName, foreignTblName, foreignKey.getFk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, key.getPk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, nN.getNn_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, uC.getUk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    Assert.assertEquals(keys.size(), 0);\n+    Assert.assertEquals(nNs.size(), 0);\n+    Assert.assertEquals(uns.size(), 0);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    // Adding keys back\n+    AddPrimaryKeyRequest req = new AddPrimaryKeyRequest(Arrays.asList(key));\n+    hmsHandler.add_primary_key(req);\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keys, 1, 0, key);\n+\n+    AddUniqueConstraintRequest uniqueConstraintRequest = new AddUniqueConstraintRequest(Arrays.asList(uC));\n+    hmsHandler.add_unique_constraint(uniqueConstraintRequest);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(uns, 1, 0, uC);\n+\n+    AddNotNullConstraintRequest notNullConstraintRequest = new AddNotNullConstraintRequest(Arrays.asList(nN));\n+    hmsHandler.add_not_null_constraint(notNullConstraintRequest);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNs, 1, 0, nN);\n+\n+    AddForeignKeyRequest foreignKeyRequest = new AddForeignKeyRequest(Arrays.asList(foreignKey));\n+    hmsHandler.add_foreign_key(foreignKeyRequest);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, foreignKey);\n+\n+    sharedCache.getDatabaseCache().clear();\n+    sharedCache.clearTableCache();\n+    sharedCache.getSdCache().clear();\n+  }\n+\n+  private void assertsForPrimarkaryKey(List<SQLPrimaryKey> keys, int size, int ele, SQLPrimaryKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getColumn_name(), key.getColumn_name());\n+    Assert.assertEquals(keys.get(ele).getTable_name(), key.getTable_name());\n+    Assert.assertEquals(keys.get(ele).getTable_db(), key.getTable_db());\n+  }\n+\n+  private void assertsForForeignKey(List<SQLForeignKey> keys, int size, int ele, SQLForeignKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getFk_name(), key.getFk_name());\n+    Assert.assertEquals(keys.get(ele).getFktable_db(), key.getFktable_db());\n+    Assert.assertEquals(keys.get(ele).getFktable_name(), key.getFktable_name());\n+    Assert.assertEquals(keys.get(ele).getPktable_db(), key.getPktable_db());\n+    Assert.assertEquals(keys.get(ele).getPktable_name(), key.getPktable_name());\n+    Assert.assertEquals(keys.get(ele).getPkcolumn_name(), key.getPkcolumn_name());\n+    Assert.assertEquals(keys.get(ele).getFkcolumn_name(), key.getFkcolumn_name());\n+  }\n+\n+  private void assertsForNotNullConstraints(List<SQLNotNullConstraint> nns, int size, int ele, SQLNotNullConstraint nN) {\n+    Assert.assertEquals(nns.size(), size);\n+    Assert.assertEquals(nns.get(ele).getNn_name(), nN.getNn_name());\n+    Assert.assertEquals(nns.get(ele).getColumn_name(), nN.getColumn_name());\n+    Assert.assertEquals(nns.get(ele).getTable_name(), nN.getTable_name());\n+    Assert.assertEquals(nns.get(ele).getTable_db(), nN.getTable_db());\n+  }\n+\n+  private void assertsForUniqueConstraints(List<SQLUniqueConstraint> nns, int size, int ele, SQLUniqueConstraint nN) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA==", "bodyText": "Is it possible that table is cached but not the constraints?", "url": "https://github.com/apache/hive/pull/1109#discussion_r446106308", "createdAt": "2020-06-26T10:37:18Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwODU0NQ==", "bodyText": "If foreign db or table names are null, then we should just invoke rawStore apis instead of using empty string. It can cause issues.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446108545", "createdAt": "2020-06-26T10:42:48Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    catName = normalizeIdentifier(catName);\n+    foreignDbName = (foreignDbName == null) ? \"\" : normalizeIdentifier(foreignDbName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNTY5OQ==", "bodyText": "Indentation of \"case' statement is not matching with others.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446115699", "createdAt": "2020-06-26T11:00:57Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -410,6 +436,34 @@ private void updateMemberSize(MemberName mn, Integer size, SizeMode mode) {\n           aggrColStatsCacheSize = size;\n         }\n         break;\n+      case PRIMARY_KEY_CACHE:\n+        if (mode == SizeMode.Delta) {\n+          primaryKeyCacheSize += size;\n+        } else {\n+          primaryKeyCacheSize = size;\n+        }\n+        break;\n+        case FOREIGN_KEY_CACHE:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNzA4OA==", "bodyText": "Shall consolidate all these size variables into an array(say, memberObjectsSize) of size = (number of items in enum MemberName) and can refer to it using enum value as index. It reduces lot of code especially the switch cases.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446117088", "createdAt": "2020-06-26T11:04:29Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -265,6 +270,10 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionCacheSize;\n     private int partitionColStatsCacheSize;\n     private int aggrColStatsCacheSize;\n+    private int primaryKeyCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExODQ2MA==", "bodyText": "Same as size, even dirty check boolean also can be an array.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446118460", "createdAt": "2020-06-26T11:07:39Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -287,6 +296,18 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n     private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+    private AtomicBoolean isPrimaryKeyCacheDirty = new AtomicBoolean(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMjUxMQ==", "bodyText": "Why do we need to pass both member name and constraint class name. We can derive it from member name itself.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446122511", "createdAt": "2020-06-26T11:17:09Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNDk3MQ==", "bodyText": "Can be a switch-case.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446124971", "createdAt": "2020-06-26T11:22:45Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDgxMQ==", "bodyText": "Double assignment. Shall directly return from here and avoid local variable.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446140811", "createdAt": "2020-06-26T12:00:52Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {\n+            SQLPrimaryKey key = (SQLPrimaryKey) constraintsList.get(i);\n+            this.primaryKeyCache.put(key.getPk_name(), key);\n+          } else if (constraintClass == SQLForeignKey.class) {\n+            SQLForeignKey key = (SQLForeignKey) constraintsList.get(i);\n+            this.foreignKeyCache.put(key.getFk_name(), key);\n+          } else if (constraintClass == SQLNotNullConstraint.class) {\n+            SQLNotNullConstraint key = (SQLNotNullConstraint) constraintsList.get(i);\n+            this.notNullConstraintCache.put(key.getNn_name(), key);\n+          } else if (constraintClass == SQLUniqueConstraint.class) {\n+            SQLUniqueConstraint key = (SQLUniqueConstraint) constraintsList.get(i);\n+            this.uniqueConstraintCache.put(key.getUk_name(), key);\n+          }\n+          size += getObjectSize(constraintClass, constraintsList.get(i));\n+        }\n+\n+        if (!fromPrewarm) {\n+          dirtyConstaintVariable.set(true);\n+        }\n+\n+        updateMemberSize(mn, size, SizeMode.Delta);\n+        return true;\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public List<SQLPrimaryKey> getPrimaryKeys() {\n+      List<SQLPrimaryKey> keys = new ArrayList<>();\n+      try {\n+        tableLock.readLock().lock();\n+        keys = new ArrayList<>(this.primaryKeyCache.values());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzQyMQ==", "bodyText": "It can happen that for multi HMS instance case, table can be cached but not constraints right? If yes, then it can hit here.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446143421", "createdAt": "2020-06-26T12:06:51Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDUzNg==", "bodyText": "Shouldn't we use ConcurrentHashMap here?", "url": "https://github.com/apache/hive/pull/1109#discussion_r446144536", "createdAt": "2020-06-26T12:09:37Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjU1MQ==", "bodyText": "Shall use List.stream().filter() instead of loop and check.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446146551", "createdAt": "2020-06-26T12:14:20Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2247,125 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {\n+      List<SQLForeignKey> filteredKeys = new ArrayList<>();\n+      for (SQLForeignKey key : keys) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 508}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0ODM0OQ==", "bodyText": "Too many blank lines.", "url": "https://github.com/apache/hive/pull/1109#discussion_r446148349", "createdAt": "2020-06-26T12:18:27Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1507,6 +1490,305 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLPrimaryKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.refreshNotNullConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.refreshUniqueConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // List operation with different parent table\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"dummyDB\", \"dummyTable\");\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    // Refresh Operation\n+    SQLForeignKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setFkcolumn_name(\"col3\");\n+    modifiedKey.setFk_name(\"fk_modified\");\n+\n+    sharedCache.refreshForeignKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col3\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 287}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "committedDate": "2020-06-22T08:52:28Z", "message": "dummy commit to re-run the tests"}, "afterCommit": {"oid": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/628f0e7fa1891f05946b843bdb2a3463b43d3d08", "committedDate": "2020-06-29T10:53:15Z", "message": "address review comments part 2"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f7a7e0d79b5be5dc856591567daed4e825811757", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f7a7e0d79b5be5dc856591567daed4e825811757", "committedDate": "2020-06-30T04:26:48Z", "message": "Fix compilation issue"}, "afterCommit": {"oid": "f009640f85ff76ff1041ef75462b4e9058eae295", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f009640f85ff76ff1041ef75462b4e9058eae295", "committedDate": "2020-06-30T10:48:44Z", "message": "Fix compilation issue"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f009640f85ff76ff1041ef75462b4e9058eae295", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f009640f85ff76ff1041ef75462b4e9058eae295", "committedDate": "2020-06-30T10:48:44Z", "message": "Fix compilation issue"}, "afterCommit": {"oid": "22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "committedDate": "2020-07-01T10:52:57Z", "message": "Fix compilation issue"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "committedDate": "2020-07-01T10:52:57Z", "message": "Fix compilation issue"}, "afterCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "committedDate": "2020-07-02T07:23:04Z", "message": "Fix compilation issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5Njc2MTk5", "url": "https://github.com/apache/hive/pull/1109#pullrequestreview-439676199", "createdAt": "2020-06-30T05:16:56Z", "commit": {"oid": "f7a7e0d79b5be5dc856591567daed4e825811757"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQwNToxNjo1NlrOGqsCsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMzozODo1NFrOGsNS4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNDk2MA==", "bodyText": "We should take the same path if parentDbName or parentTblName is null.", "url": "https://github.com/apache/hive/pull/1109#discussion_r447414960", "createdAt": "2020-06-30T05:16:56Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f7a7e0d79b5be5dc856591567daed4e825811757"}, "originalPosition": 245}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTM2Mw==", "bodyText": "This flow is a candidate for improvement as it tries to fetch all foreignkeys of give parent table and vice-versa which is frequent operations. Pls create a follow-up JIRA to use CachedStore for this case too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r447415363", "createdAt": "2020-06-30T05:18:25Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {\n+      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f7a7e0d79b5be5dc856591567daed4e825811757"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwMzQyMA==", "bodyText": "I think, we can make this refactoring also here itself. It needs change only in this method and so less risky. Having another ticket for this is time consuming.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448903420", "createdAt": "2020-07-02T10:24:38Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getForeignKeys\");\n+              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getUniqueConstraints\");\n+              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getNotNullConstraints\");\n+              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+\n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw=="}, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDAwMw==", "bodyText": "Method is to \"update\" but the log msg says \"read\"", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904003", "createdAt": "2020-07-02T10:25:43Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDI2Mg==", "bodyText": "Shall limit the try-catch block only for rawStore calls.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904262", "createdAt": "2020-07-02T10:26:13Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNTU4Ng==", "bodyText": "I think, we should handle the case where table object is cached but constraints are not cached. Now, it seems, we just return empty key list to caller but ideally, we should invoke rawStore.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448905586", "createdAt": "2020-07-02T10:28:57Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}, "originalCommit": {"oid": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ==", "bodyText": "We need to check if the caller queries the foreign key constraints using parentDb and table as input. If yes, it make sense to map it against parent table object rather than foreign table.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448907251", "createdAt": "2020-07-02T10:32:16Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +557,30 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              cacheObjects.setPrimaryKeys(primaryKeys);\n+\n+              Deadline.startTimer(\"getForeignKeys\");\n+              foreignKeys = rawStore.getForeignKeys(catName, null, null, dbName, tblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkzNjQ4NA==", "bodyText": "We shall remove these variables for stats and partition too as we already have memberObjectsSize and memberCacheDirty.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448936484", "createdAt": "2020-07-02T11:32:59Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -266,6 +272,13 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionColStatsCacheSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2ODg5Mw==", "bodyText": "Shall do the following to avoid using variable i and get(i).\nconstraintsList.stream().forEach(constraint -> {\nswitch (mn) {\ncase PRIMARY_KEY_CACHE:\nSQLPrimaryKey pk = (SQLPrimaryKey) constraint;\nthis.primaryKeyCache.put(pk.getPk_name(), pk);\nsize += getObjectSize(SQLPrimaryKey.class, constraint);\nbreak;\n...\n}\n});", "url": "https://github.com/apache/hive/pull/1109#discussion_r448968893", "createdAt": "2020-07-02T12:36:09Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +510,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4NjczNA==", "bodyText": "Check if we need to normalize the case of \"name\" before using for search. it might be coming from user input.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448986734", "createdAt": "2020-07-02T13:05:40Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MjMxMA==", "bodyText": "memberCacheDirty.set is common code and can be moved outside if-else blocks.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992310", "createdAt": "2020-07-02T13:14:17Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5Mjc5OQ==", "bodyText": "Extra blank line.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992799", "createdAt": "2020-07-02T13:15:02Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 247}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NDAzMw==", "bodyText": "We can directly use MemberName.PRIMARY_KEY_CACHE if we assign 0 to first member in the enum.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448994033", "createdAt": "2020-07-02T13:16:54Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NzEyMA==", "bodyText": "What is the significance of this check? memberCacheDirty flag is confusing. Pls add a comment describing the meaning of this value and how read/write to cache behave for true or false. If true means, cache is already set, then pls rename it to give correct meaning. It sounds like true means invalid cache.", "url": "https://github.com/apache/hive/pull/1109#discussion_r448997120", "createdAt": "2020-07-02T13:21:42Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMDQ4NA==", "bodyText": "Add a debug log to mark the cache refresh is successful.", "url": "https://github.com/apache/hive/pull/1109#discussion_r449000484", "createdAt": "2020-07-02T13:26:51Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMjg2Mg==", "bodyText": "TableWrapper can have setMemberCacheDirty(MemberName, boolean) method to make it clean.", "url": "https://github.com/apache/hive/pull/1109#discussion_r449002862", "createdAt": "2020-07-02T13:30:29Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 359}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMzQzMg==", "bodyText": "Member name is incorrect. Check other places below.", "url": "https://github.com/apache/hive/pull/1109#discussion_r449003432", "createdAt": "2020-07-02T13:31:20Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+\n+    if (cacheObjects.getForeignKeys() != null) {\n+      if(!tblWrapper.cacheForeignKeys(cacheObjects.getForeignKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 366}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNDUwOA==", "bodyText": "We are writing in to cache. Check if we need read or write lock here? Looks like we take write lock on the table. Pls confirm if this is fine.", "url": "https://github.com/apache/hive/pull/1109#discussion_r449004508", "createdAt": "2020-07-02T13:32:59Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 391}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNzMxOQ==", "bodyText": "Shall move this if block under if (tblWrapper != null) block above.", "url": "https://github.com/apache/hive/pull/1109#discussion_r449007319", "createdAt": "2020-07-02T13:37:23Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2228,122 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 495}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODM1NA==", "bodyText": "Method name cacheNotNulConstraints missing one \"l\". :)", "url": "https://github.com/apache/hive/pull/1109#discussion_r449008354", "createdAt": "2020-07-02T13:38:54Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cachePrimaryKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addForeignKeysToCache(String catName, String dbName, String tblName, List<SQLForeignKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheForeignKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addUniqueConstraintsToCache(String catName, String dbName, String tblName, List<SQLUniqueConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheUniqueConstraints(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addNotNullConstraintsToCache(String catName, String dbName, String tblName, List<SQLNotNullConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheNotNulConstraints(keys, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f"}, "originalPosition": 434}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e330915a45143da819625bfa40aafed413558df6", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/e330915a45143da819625bfa40aafed413558df6", "committedDate": "2020-07-03T10:59:19Z", "message": "Review comments p3"}, "afterCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/6f5125dc6304cfa3d52aa39902df48b5605241f2", "committedDate": "2020-07-03T11:05:21Z", "message": "Review comments p3"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MzAyMzM3", "url": "https://github.com/apache/hive/pull/1109#pullrequestreview-446302337", "createdAt": "2020-07-10T10:40:21Z", "commit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxMDo0MDoyMVrOGvyrvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxMTowMTo1N1rOGvzPUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2NjY1NQ==", "bodyText": "Can we have a flag in TableWrapper in Cache to tell if it was set or not? Can be a follow-up jira.", "url": "https://github.com/apache/hive/pull/1109#discussion_r452766655", "createdAt": "2020-07-10T10:40:21Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2490,26 +2616,99 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+    if (keys == null || keys.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 272}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA==", "bodyText": "Can't we just use mn instead of mn.getValue()?", "url": "https://github.com/apache/hive/pull/1109#discussion_r452768398", "createdAt": "2020-07-10T10:44:26Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -261,44 +283,57 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, String> parameters;\n     private byte[] sdHash;\n     private int otherSize;\n-    private int tableColStatsCacheSize;\n-    private int partitionCacheSize;\n-    private int partitionColStatsCacheSize;\n-    private int aggrColStatsCacheSize;\n+\n+    // Arrays to hold the size/updated bit of cached objects.\n+    // These arrays are to be referenced using MemberName enum only.\n+    private int[] memberObjectsSize = new int[MemberName.values().length];\n+    private AtomicBoolean[] memberCacheUpdated = new AtomicBoolean[MemberName.values().length];\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n     // Key is column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> tableColStatsCache = new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isTableColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching partition objects\n     // Ket is partition values and the value is a wrapper around the partition object\n     private Map<String, PartitionWrapper> partitionCache = new ConcurrentHashMap<String, PartitionWrapper>();\n-    private AtomicBoolean isPartitionCacheDirty = new AtomicBoolean(false);\n     // For caching column stats for a partitioned table\n     // Key is aggregate of partition values, column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> partitionColStatsCache =\n         new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isPartitionColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching aggregate column stats for all and all minus default partition\n     // Key is column name and the value is a list of 2 col stat objects\n     // (all partitions and all but default)\n     private Map<String, List<ColumnStatisticsObj>> aggrColStatsCache =\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n-    private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n+\n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLForeignKey> foreignKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLNotNullConstraint> notNullConstraintCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLUniqueConstraint> uniqueConstraintCache = new ConcurrentHashMap<>();\n \n     TableWrapper(Table t, byte[] sdHash, String location, Map<String, String> parameters) {\n       this.t = t;\n       this.sdHash = sdHash;\n       this.location = location;\n       this.parameters = parameters;\n-      this.tableColStatsCacheSize = 0;\n-      this.partitionCacheSize = 0;\n-      this.partitionColStatsCacheSize = 0;\n-      this.aggrColStatsCacheSize = 0;\n+      for(MemberName mn : MemberName.values()) {\n+        this.memberObjectsSize[mn.getValue()] = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MDA2NQ==", "bodyText": "Why do we use int array if we just want to store one value? and why is it final?", "url": "https://github.com/apache/hive/pull/1109#discussion_r452770065", "createdAt": "2020-07-10T10:48:24Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +484,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNullConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        final int[] size = {0};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MTM5OQ==", "bodyText": "Shall add catalog, db and table names in the log msg otherwise this is no use. Same for other methods too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r452771399", "createdAt": "2020-07-10T10:51:19Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name().toLowerCase(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n+        LOG.debug(\"Primary keys refresh in cache was successful.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 357}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MjMwMA==", "bodyText": "The debug log msg is confusing. It says, primary keys is dirty and so skipping the update. I think, it should be \"Skipping the primary keys update for table:  as it was already refreshed.\"\nSame for other methods too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r452772300", "createdAt": "2020-07-10T10:53:25Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 348}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3NTc2MA==", "bodyText": "Can we add foreign keys for multiple parent db/tbl and get it from cache to verify if return correct fk?", "url": "https://github.com/apache/hive/pull/1109#discussion_r452775760", "createdAt": "2020-07-10T11:01:57Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1556,6 +1543,289 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLPrimaryKey modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2"}, "originalPosition": 229}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MzUzMjg0", "url": "https://github.com/apache/hive/pull/1109#pullrequestreview-446353284", "createdAt": "2020-07-10T12:16:33Z", "commit": {"oid": "fec5a1770f598b7f1d9c1d3c1dcd674e9a69d93c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxMjoxNjozM1rOGv1G6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxMjoxNjozM1rOGv1G6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgwNjM3OQ==", "bodyText": "Also validate if parent tbl name is proper too.", "url": "https://github.com/apache/hive/pull/1109#discussion_r452806379", "createdAt": "2020-07-10T12:16:33Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1754,6 +1760,16 @@ public void testForeignKeys() {\n     Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n     Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n \n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl1.getDbName(), tbl1.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk2\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col1\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fec5a1770f598b7f1d9c1d3c1dcd674e9a69d93c"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "73ad4f6db3ff0a4640347e88380a3055b9041880", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/73ad4f6db3ff0a4640347e88380a3055b9041880", "committedDate": "2020-07-12T03:56:25Z", "message": "First cut for adding constraints"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "committedDate": "2020-07-12T03:56:25Z", "message": "Add updation of cache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "005ea861cb6294d7dc41d5e92212d4596d5c502d", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/005ea861cb6294d7dc41d5e92212d4596d5c502d", "committedDate": "2020-07-12T03:56:25Z", "message": "Remove check/default constraints"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eccc6b05557e691449ecdb733db53a7d17e0dae9", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/eccc6b05557e691449ecdb733db53a7d17e0dae9", "committedDate": "2020-07-12T03:56:25Z", "message": "Add foreign keys caching"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8a0b062f67192d9725938afbc74dbc76ab0cb84", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f8a0b062f67192d9725938afbc74dbc76ab0cb84", "committedDate": "2020-07-12T03:56:25Z", "message": "Add UT for constraints"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29fb02300a3074fe2c42657573b9d5934c97167a", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/29fb02300a3074fe2c42657573b9d5934c97167a", "committedDate": "2020-07-12T03:56:25Z", "message": "Add test for foreign key constraints"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5e877da60fdb8d085476ea13678c88e826f0359", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f5e877da60fdb8d085476ea13678c88e826f0359", "committedDate": "2020-07-12T03:56:25Z", "message": "renaming variables/reorganizing imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "committedDate": "2020-07-12T03:56:25Z", "message": "dummy commit to re-run the tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8828383f824cf3f52572175e4173e72f0fab15b", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/c8828383f824cf3f52572175e4173e72f0fab15b", "committedDate": "2020-07-12T03:56:25Z", "message": "Fix review comment part 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "committedDate": "2020-07-12T03:56:25Z", "message": "address review comments part 2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "committedDate": "2020-07-12T03:56:25Z", "message": "Fix tests failure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0706fccc68e2660be42d8469d5d9a2d005ecc17", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/d0706fccc68e2660be42d8469d5d9a2d005ecc17", "committedDate": "2020-07-12T03:56:25Z", "message": "Fix compilation issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54b837f6c487d91071bb7dd14c0419507a61ecbd", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/54b837f6c487d91071bb7dd14c0419507a61ecbd", "committedDate": "2020-07-12T03:56:25Z", "message": "Review comments p3"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5dacc72f1dab8cf77d296998cc05cf271179c03", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f5dacc72f1dab8cf77d296998cc05cf271179c03", "committedDate": "2020-07-12T03:56:25Z", "message": "review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e980fd88bce3d98bef1216b08ab1e4b907c495b", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/3e980fd88bce3d98bef1216b08ab1e4b907c495b", "committedDate": "2020-07-12T03:56:25Z", "message": "Validate parent db/table too for fk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a9d425b708317de126943613d72228f94b502d1", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "committedDate": "2020-07-12T03:56:25Z", "message": "Fix enum accessor"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "796bc52ead33f006b219dd42a7b2a229dfba5a13", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/796bc52ead33f006b219dd42a7b2a229dfba5a13", "committedDate": "2020-07-10T12:47:47Z", "message": "Fix enum accessor"}, "afterCommit": {"oid": "7a9d425b708317de126943613d72228f94b502d1", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "committedDate": "2020-07-12T03:56:25Z", "message": "Fix enum accessor"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MTI1OTI3", "url": "https://github.com/apache/hive/pull/1109#pullrequestreview-447125927", "createdAt": "2020-07-13T10:25:30Z", "commit": {"oid": "7a9d425b708317de126943613d72228f94b502d1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3868, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}