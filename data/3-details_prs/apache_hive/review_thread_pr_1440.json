{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc0OTI3OTY3", "number": 1440, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNDoyOToyNlrOEdxdmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0OTozOFrOEd1nCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NjU0NTU0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveJoinConstraintsRule.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNDoyOToyNlrOHJIw8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzowNTo0N1rOHJOGqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTM0MjgzNQ==", "bodyText": "why do we skip all other kinds which are not EQUALS?\nI think instead there should be a return here instead of a continue", "url": "https://github.com/apache/hive/pull/1440#discussion_r479342835", "createdAt": "2020-08-28T14:29:26Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveJoinConstraintsRule.java", "diffHunk": "@@ -213,61 +218,137 @@ public void onMatch(RelOptRuleCall call) {\n \n     // 2) Check whether this join can be rewritten or removed\n     RewritablePKFKJoinInfo r = HiveRelOptUtil.isRewritablePKFKJoin(\n-        join, leftInput == fkInput, call.getMetadataQuery());\n+        join, fkInput,  nonFkInput, call.getMetadataQuery());\n \n     // 3) If it is the only condition, we can trigger the rewriting\n     if (r.rewritable) {\n-      List<RexNode> nullableNodes = r.nullableNodes;\n-      // If we reach here, we trigger the transform\n-      if (mode == Mode.REMOVE) {\n-        if (rightInputPotentialFK) {\n-          // First, if FK is the right input, we need to shift\n-          nullableNodes = nullableNodes.stream()\n-              .map(node -> RexUtil.shift(node, 0, -leftInput.getRowType().getFieldCount()))\n-              .collect(Collectors.toList());\n-          topProjExprs = topProjExprs.stream()\n-              .map(node -> RexUtil.shift(node, 0, -leftInput.getRowType().getFieldCount()))\n-              .collect(Collectors.toList());\n-        }\n-        // Fix nullability in references to the input node\n-        topProjExprs = HiveCalciteUtil.fixNullability(rexBuilder, topProjExprs, RelOptUtil.getFieldTypeList(fkInput.getRowType()));\n-        // Trigger transformation\n-        if (nullableNodes.isEmpty()) {\n-          call.transformTo(call.builder()\n-              .push(fkInput)\n-              .project(topProjExprs)\n-              .convert(project.getRowType(), false)\n-              .build());\n+      rewrite(mode, fkInput, nonFkInput, join, topProjExprs, call, project, r.nullableNodes);\n+    } else {\n+      // check if FK side could be removed instead\n+\n+      // Possibly this could be enhanced to take other join type into consideration.\n+      if (joinType != JoinRelType.INNER) {\n+        return;\n+      }\n+\n+      //first swap fk and non-fk input and see if we can rewrite them\n+      RewritablePKFKJoinInfo fkRemoval = HiveRelOptUtil.isRewritablePKFKJoin(\n+          join, nonFkInput, fkInput, call.getMetadataQuery());\n+\n+      if (fkRemoval.rewritable) {\n+        // we have established that nonFkInput is FK, and fkInput is PK\n+        // and there is no row filtering on FK side\n+\n+        // check that FK side join column is distinct (i.e. have a group by)\n+        ImmutableBitSet fkSideBitSet;\n+        if (nonFkInput == leftInput) {\n+          fkSideBitSet = leftBits;\n         } else {\n-          RexNode newFilterCond;\n-          if (nullableNodes.size() == 1) {\n-            newFilterCond = rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, nullableNodes.get(0));\n-          } else {\n-            List<RexNode> isNotNullConds = new ArrayList<>();\n-            for (RexNode nullableNode : nullableNodes) {\n-              isNotNullConds.add(rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, nullableNode));\n+          fkSideBitSet = rightBits;\n+        }\n+\n+        ImmutableBitSet.Builder fkJoinColBuilder = ImmutableBitSet.builder();\n+        for (RexNode conj : RelOptUtil.conjunctions(cond)) {\n+          if (!conj.isA(SqlKind.EQUALS)) {\n+            continue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "89377e579f398816ea23f914d55a76feede36929"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzMDMxNA==", "bodyText": "@kgyrtkirk If there is any other kind of predicate/condition isRewritablePKFKJoin will return false. But you are right that the code here should return instead of continue. I will update the code. Thanks for pointing it out.", "url": "https://github.com/apache/hive/pull/1440#discussion_r479430314", "createdAt": "2020-08-28T17:05:47Z", "author": {"login": "vineetgarg02"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveJoinConstraintsRule.java", "diffHunk": "@@ -213,61 +218,137 @@ public void onMatch(RelOptRuleCall call) {\n \n     // 2) Check whether this join can be rewritten or removed\n     RewritablePKFKJoinInfo r = HiveRelOptUtil.isRewritablePKFKJoin(\n-        join, leftInput == fkInput, call.getMetadataQuery());\n+        join, fkInput,  nonFkInput, call.getMetadataQuery());\n \n     // 3) If it is the only condition, we can trigger the rewriting\n     if (r.rewritable) {\n-      List<RexNode> nullableNodes = r.nullableNodes;\n-      // If we reach here, we trigger the transform\n-      if (mode == Mode.REMOVE) {\n-        if (rightInputPotentialFK) {\n-          // First, if FK is the right input, we need to shift\n-          nullableNodes = nullableNodes.stream()\n-              .map(node -> RexUtil.shift(node, 0, -leftInput.getRowType().getFieldCount()))\n-              .collect(Collectors.toList());\n-          topProjExprs = topProjExprs.stream()\n-              .map(node -> RexUtil.shift(node, 0, -leftInput.getRowType().getFieldCount()))\n-              .collect(Collectors.toList());\n-        }\n-        // Fix nullability in references to the input node\n-        topProjExprs = HiveCalciteUtil.fixNullability(rexBuilder, topProjExprs, RelOptUtil.getFieldTypeList(fkInput.getRowType()));\n-        // Trigger transformation\n-        if (nullableNodes.isEmpty()) {\n-          call.transformTo(call.builder()\n-              .push(fkInput)\n-              .project(topProjExprs)\n-              .convert(project.getRowType(), false)\n-              .build());\n+      rewrite(mode, fkInput, nonFkInput, join, topProjExprs, call, project, r.nullableNodes);\n+    } else {\n+      // check if FK side could be removed instead\n+\n+      // Possibly this could be enhanced to take other join type into consideration.\n+      if (joinType != JoinRelType.INNER) {\n+        return;\n+      }\n+\n+      //first swap fk and non-fk input and see if we can rewrite them\n+      RewritablePKFKJoinInfo fkRemoval = HiveRelOptUtil.isRewritablePKFKJoin(\n+          join, nonFkInput, fkInput, call.getMetadataQuery());\n+\n+      if (fkRemoval.rewritable) {\n+        // we have established that nonFkInput is FK, and fkInput is PK\n+        // and there is no row filtering on FK side\n+\n+        // check that FK side join column is distinct (i.e. have a group by)\n+        ImmutableBitSet fkSideBitSet;\n+        if (nonFkInput == leftInput) {\n+          fkSideBitSet = leftBits;\n         } else {\n-          RexNode newFilterCond;\n-          if (nullableNodes.size() == 1) {\n-            newFilterCond = rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, nullableNodes.get(0));\n-          } else {\n-            List<RexNode> isNotNullConds = new ArrayList<>();\n-            for (RexNode nullableNode : nullableNodes) {\n-              isNotNullConds.add(rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, nullableNode));\n+          fkSideBitSet = rightBits;\n+        }\n+\n+        ImmutableBitSet.Builder fkJoinColBuilder = ImmutableBitSet.builder();\n+        for (RexNode conj : RelOptUtil.conjunctions(cond)) {\n+          if (!conj.isA(SqlKind.EQUALS)) {\n+            continue;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTM0MjgzNQ=="}, "originalCommit": {"oid": "89377e579f398816ea23f914d55a76feede36929"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzIyNTA1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelOptUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0OTozOFrOHJPZKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0OTozOFrOHJPZKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1MTQzMg==", "bodyText": "nit. Use guava preconditions instead of Parquet.", "url": "https://github.com/apache/hive/pull/1440#discussion_r479451432", "createdAt": "2020-08-28T17:49:38Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelOptUtil.java", "diffHunk": "@@ -75,6 +75,7 @@\n import org.apache.hadoop.hive.ql.optimizer.calcite.translator.TypeConverter;\n import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils;\n+import org.apache.parquet.Preconditions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0befb9f4ee0691adc87850ff7ae9bddddf2904cc"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 398, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}