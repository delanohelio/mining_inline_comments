{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU3Mjg0NTI0", "number": 1324, "title": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans", "bodyText": "Testing done:\nmvn test -Dtest.output.overwrite -DskipSparkTests -Dtest=TestTezPerfCliDriver -Dqfile=query9.q -pl itests/qtest -Pitests\nmvn test -Dtest.output.overwrite -DskipSparkTests -Dtest=TestTezPerfConstraintsCliDriver -Dqfile=query9.q -pl itests/qtest -Pitests", "createdAt": "2020-07-27T16:55:14Z", "url": "https://github.com/apache/hive/pull/1324", "merged": true, "mergeCommit": {"oid": "933c023b7d6524451bc6121eaa7b2f98827d23fa"}, "closed": true, "closedAt": "2020-08-02T14:39:11Z", "author": {"login": "kasakrisz"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5rcG1gBqjM1OTkxNzU4NTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc6U8DTgFqTQ1OTIwOTMzNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dbb0ac20a8d5387521e537769b9cc27f1146a608", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/dbb0ac20a8d5387521e537769b9cc27f1146a608", "committedDate": "2020-07-27T16:54:10Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans"}, "afterCommit": {"oid": "53d0f2b8c3d38a458ff7a743246ac4df8c3861b2", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/53d0f2b8c3d38a458ff7a743246ac4df8c3861b2", "committedDate": "2020-07-29T13:56:07Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NDU5OTEy", "url": "https://github.com/apache/hive/pull/1324#pullrequestreview-458459912", "createdAt": "2020-07-30T14:32:12Z", "commit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozMjoxMlrOG5lv4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDo0MjoyOFrOG5mN9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDQ4MQ==", "bodyText": "Can we move the new call before the if(pctx.getConf().getBoolVar(ConfVars.HIVE_SHARED_WORK_REUSE_MAPJOIN_CACHE)) { block? It makes sense to trigger that block at the very end in case we continue adding phases.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040481", "createdAt": "2020-07-30T14:32:12Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDY1OA==", "bodyText": "Can we put this additional step under a new flag (true by default)?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040658", "createdAt": "2020-07-30T14:32:28Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTEyNA==", "bodyText": "This is the same as After SharedWorkSJOptimizer, no need to print it again.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041124", "createdAt": "2020-07-30T14:33:08Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTczOA==", "bodyText": "After SharedWorkOptimizer merging TS schema?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041738", "createdAt": "2020-07-30T14:33:58Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(\n+        pctx, optimizerCache, tableNameToOps, sortedTables, false);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"After SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MjM3Mw==", "bodyText": "Can we add a clarifying comment to the new internal classes with the difference between both of them?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463042373", "createdAt": "2020-07-30T14:34:47Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -273,258 +287,332 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n-  private static boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCache optimizerCache,\n-      ArrayListMultimap<String, TableScanOperator> tableNameToOps, List<Entry<String, Long>> sortedTables,\n-      boolean removeSemijoin) throws SemanticException {\n-    // Boolean to keep track of whether this method actually merged any TS operators\n-    boolean mergedExecuted = false;\n-\n-    Multimap<String, TableScanOperator> existingOps = ArrayListMultimap.create();\n-    Set<Operator<?>> removedOps = new HashSet<>();\n-    for (Entry<String, Long> tablePair : sortedTables) {\n-      String tableName = tablePair.getKey();\n-      for (TableScanOperator discardableTsOp : tableNameToOps.get(tableName)) {\n-        if (removedOps.contains(discardableTsOp)) {\n-          LOG.debug(\"Skip {} as it has already been removed\", discardableTsOp);\n-          continue;\n-        }\n-        Collection<TableScanOperator> prevTsOps = existingOps.get(tableName);\n-        for (TableScanOperator retainableTsOp : prevTsOps) {\n-          if (removedOps.contains(retainableTsOp)) {\n-            LOG.debug(\"Skip {} as it has already been removed\", retainableTsOp);\n+  private static class BaseSharedWorkOptimizer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NTIzOA==", "bodyText": "I do not see projected columns, so it is difficult to confirm whether this is because of the schema. Is it?", "url": "https://github.com/apache/hive/pull/1324#discussion_r463045238", "createdAt": "2020-07-30T14:38:30Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/annotate_stats_join_pkfk.q.out", "diffHunk": "@@ -1191,14 +1191,6 @@ STAGE PLANS:\n                         sort order: +\n                         Map-reduce partition columns: _col0 (type: int)\n                         Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE\n-            Execution mode: vectorized, llap", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0ODE4Mg==", "bodyText": "Why is this projection changing? Is this correct? I do not see the branch with date column.", "url": "https://github.com/apache/hive/pull/1324#discussion_r463048182", "createdAt": "2020-07-30T14:42:28Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/auto_join_reordering_values.q.out", "diffHunk": "@@ -144,122 +144,30 @@ STAGE PLANS:\n                         tag: 0\n                         value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)\n                         auto parallelism: true\n-            Execution mode: vectorized, llap\n-            LLAP IO: no inputs\n-            Path -> Alias:\n-#### A masked pattern was here ####\n-            Path -> Partition:\n-#### A masked pattern was here ####\n-                Partition\n-                  base file name: orderpayment_small\n-                  input format: org.apache.hadoop.mapred.TextInputFormat\n-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                  properties:\n-                    bucket_count -1\n-                    bucketing_version 2\n-                    column.name.delimiter ,\n-                    columns dealid,date,time,cityid,userid\n-                    columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                    name default.orderpayment_small\n-                    serialization.format 1\n-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                \n-                    input format: org.apache.hadoop.mapred.TextInputFormat\n-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                    properties:\n-                      bucketing_version 2\n-                      column.name.delimiter ,\n-                      columns dealid,date,time,cityid,userid\n-                      columns.comments \n-                      columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                      name default.orderpayment_small\n-                      serialization.format 1\n-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    name: default.orderpayment_small\n-                  name: default.orderpayment_small\n-            Truncated Path -> Alias:\n-              /orderpayment_small [orderpayment]\n-        Map 6 \n-            Map Operator Tree:\n-                TableScan\n-                  alias: dim_pay_date\n-                  filterExpr: date is not null (type: boolean)\n-                  Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n-                  GatherStats: false\n                   Filter Operator\n                     isSamplingPred: false\n-                    predicate: date is not null (type: boolean)\n-                    Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n+                    predicate: dealid is not null (type: boolean)\n+                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n                     Select Operator\n-                      expressions: date (type: string)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380"}, "originalPosition": 78}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f195a5435aef9bf7c13b4e68dbb0ee0664062a2d", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/f195a5435aef9bf7c13b4e68dbb0ee0664062a2d", "committedDate": "2020-07-31T04:02:01Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6602742be7ec984623d9dc35e1549414a393e03", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/d6602742be7ec984623d9dc35e1549414a393e03", "committedDate": "2020-07-31T04:02:01Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - update q9, q64 out"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9179b150a8519baf825c0b36150488af67f57ea5", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/9179b150a8519baf825c0b36150488af67f57ea5", "committedDate": "2020-07-31T07:23:35Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - address review comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "committedDate": "2020-07-30T06:35:08Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - update q9, q64 out"}, "afterCommit": {"oid": "9179b150a8519baf825c0b36150488af67f57ea5", "author": {"user": {"login": "kasakrisz", "name": "Krisztian Kasa"}}, "url": "https://github.com/apache/hive/commit/9179b150a8519baf825c0b36150488af67f57ea5", "committedDate": "2020-07-31T07:23:35Z", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - address review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5MjA5MzM1", "url": "https://github.com/apache/hive/pull/1324#pullrequestreview-459209335", "createdAt": "2020-07-31T14:17:23Z", "commit": {"oid": "9179b150a8519baf825c0b36150488af67f57ea5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3355, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}