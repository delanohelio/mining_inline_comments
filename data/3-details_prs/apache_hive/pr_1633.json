{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEzMDk4NzQz", "number": 1633, "title": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)", "bodyText": "See HIVE-24230 for more info.", "createdAt": "2020-10-30T15:47:50Z", "url": "https://github.com/apache/hive/pull/1633", "merged": true, "mergeCommit": {"oid": "91ab242841879ca8133c1231ad124b48df6fa05b"}, "closed": true, "closedAt": "2020-12-03T14:43:52Z", "author": {"login": "zeroflag"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXowNMgH2gAyNTEzMDk4NzQzOjU3MTg0YmRhMGJkMTA3YmViNDQ0NDNjM2Q2NWUyNDRkYjc5MWMzZWE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdijLk9gFqTU0Mzk1MjU3OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/57184bda0bd107beb44443c3d65e244db791c3ea", "committedDate": "2020-10-30T15:46:21Z", "message": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwOTQzNDg5", "url": "https://github.com/apache/hive/pull/1633#pullrequestreview-520943489", "createdAt": "2020-10-30T18:44:20Z", "commit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxODo0NDoyMFrOHrb5UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQyMDoyNDowMFrOHre8gA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwNzg1Ng==", "bodyText": "Minor: Can we move PROCEDURAL_SQL to the line just before UNKNOWN? That way all the message ids would not be shifted. I dont believe it makes a practical difference but leaves a nicer commit.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515307856", "createdAt": "2020-10-30T18:44:20Z", "author": {"login": "mustafaiman"}, "path": "service-rpc/if/TCLIService.thrift", "diffHunk": "@@ -515,6 +515,7 @@ struct TSessionHandle {\n // The subtype of an OperationHandle.\n enum TOperationType {\n   EXECUTE_STATEMENT,\n+  PROCEDURAL_SQL,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxNDk4Mg==", "bodyText": "Minor: we can extract this if statement to a private method.", "url": "https://github.com/apache/hive/pull/1633#discussion_r515314982", "createdAt": "2020-10-30T18:59:06Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxODA1OA==", "bodyText": "runInBackground is not used", "url": "https://github.com/apache/hive/pull/1633#discussion_r515318058", "createdAt": "2020-10-30T19:05:39Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -36,6 +48,11 @@ public ExecuteStatementOperation(HiveSession parentSession, String statement,\n     this.statement = statement;\n   }\n \n+  public ExecuteStatementOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, boolean generateNewQueryId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMDI3Ng==", "bodyText": "HiveHplSqlSessionState does not hold any info which is not accessible in SessionState already. Why is that class needed?", "url": "https://github.com/apache/hive/pull/1633#discussion_r515320276", "createdAt": "2020-10-30T19:10:43Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java", "diffHunk": "@@ -45,6 +62,21 @@ public static ExecuteStatementOperation newExecuteStatementOperation(HiveSession\n       throws HiveSQLException {\n \n     String cleanStatement = HiveStringUtils.removeComments(statement);\n+    if (!HPLSQL.equals(confOverlay.get(QUERY_EXECUTOR)) && hplSqlMode()) {\n+      if (SessionState.get().getHplsqlInterpreter() == null) {\n+        Exec interpreter = new Exec(\n+                new Conf(),\n+                new BeelineConsole(),\n+                ResultListener.NONE,\n+                new HplSqlQueryExecutor(parentSession),\n+                parentSession.getMetaStoreClient(),\n+                new HiveHplSqlSessionState(SessionState.get())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NDEwNg==", "bodyText": "I think this would not log e without a matching {}", "url": "https://github.com/apache/hive/pull/1633#discussion_r515354106", "createdAt": "2020-10-30T20:14:51Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlOperation.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.security.PrivilegedExceptionAction;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.apache.hadoop.hive.common.LogUtils;\n+import org.apache.hadoop.hive.ql.log.PerfLogger;\n+import org.apache.hadoop.hive.ql.metadata.Hive;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hadoop.hive.serde2.thrift.Type;\n+import org.apache.hadoop.hive.shims.ShimLoader;\n+import org.apache.hadoop.hive.shims.Utils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.ResultListener;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationState;\n+import org.apache.hive.service.cli.OperationType;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.RowSetFactory;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.operation.ExecuteStatementOperation;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.ThreadWithGarbageCleanup;\n+\n+public class HplSqlOperation extends ExecuteStatementOperation implements ResultListener {\n+  private final Exec exec;\n+  private final boolean runInBackground;\n+  private RowSet rowSet;\n+  private TableSchema schema;\n+\n+  public HplSqlOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay, boolean runInBackground, Exec exec) {\n+    super(parentSession, statement, confOverlay, runInBackground, false);\n+    this.exec = exec;\n+    this.runInBackground = runInBackground;\n+    exec.setResultListener(this);\n+  }\n+\n+  @Override\n+  protected void runInternal() throws HiveSQLException {\n+    setState(OperationState.PENDING);\n+    if (!runInBackground) {\n+      interpret();\n+    } else {\n+      Runnable work = new BackgroundWork(getCurrentUGI(), parentSession.getSessionHive(), SessionState.get());\n+      try {\n+        // This submit blocks if no background threads are available to run this operation\n+        Future<?> backgroundHandle = getParentSession().submitBackgroundOperation(work);\n+        setBackgroundHandle(backgroundHandle);\n+      } catch (RejectedExecutionException rejected) {\n+        setState(OperationState.ERROR);\n+        throw new HiveSQLException(\"The background threadpool cannot accept\" +\n+                \" new task for execution, please retry the operation\", rejected);\n+      }\n+    }\n+  }\n+\n+  private void interpret() throws HiveSQLException {\n+    try {\n+      OperationState opState = getStatus().getState();\n+      // Operation may have been cancelled by another thread\n+      if (opState.isTerminal()) {\n+        log.info(\"Not running the query. Operation is already in terminal state: \" + opState\n+                + \", perhaps cancelled due to query timeout or by another thread.\");\n+        return;\n+      }\n+      setState(OperationState.RUNNING);\n+      int code = exec.run(new String[]{\"-e\", statement});\n+      if (code != 0) {\n+        throw new HiveSQLException(\"HPL/SQL returned \" + code);\n+      }\n+      setState(OperationState.FINISHED);\n+    } catch (Throwable e) {\n+      if (getStatus().getState().isTerminal()) {\n+        log.warn(\"Ignore exception in terminal state: {}\", getStatus().getState(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM1NzgyNA==", "bodyText": "Shouldn't this be configurable?", "url": "https://github.com/apache/hive/pull/1633#discussion_r515357824", "createdAt": "2020-10-30T20:24:00Z", "author": {"login": "mustafaiman"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long defaultMaxRows = HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE.defaultIntVal;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57184bda0bd107beb44443c3d65e244db791c3ea"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7e24e0c53ae50c3ac5bf38b17eb9581cc60f9ba", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/f7e24e0c53ae50c3ac5bf38b17eb9581cc60f9ba", "committedDate": "2020-11-02T10:32:35Z", "message": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/e7eeafeb56170581e58c9e6d10478c6d1cdcd584", "committedDate": "2020-11-09T17:02:59Z", "message": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4ODM2MzI4", "url": "https://github.com/apache/hive/pull/1633#pullrequestreview-528836328", "createdAt": "2020-11-12T08:12:35Z", "commit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoxMjozNlrOHxu3UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwODoyMTo1NVrOHxvSbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMDA5Nw==", "bodyText": "I think it would be better to avoid pulling in hplsql under ql - there is only a console class and some minor other stuff - I think this could be dodged with a few interfaces.", "url": "https://github.com/apache/hive/pull/1633#discussion_r521910097", "createdAt": "2020-11-12T08:12:36Z", "author": {"login": "kgyrtkirk"}, "path": "ql/pom.xml", "diffHunk": "@@ -863,6 +863,11 @@\n         </exclusion>\n       </exclusions>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-hplsql</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxMTAyMQ==", "bodyText": "I don't fully understand why we have this field \"here\" - we don't even use hplsql from ql.\nThis field is only used from the \"service\" module", "url": "https://github.com/apache/hive/pull/1633#discussion_r521911021", "createdAt": "2020-11-12T08:14:17Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java", "diffHunk": "@@ -270,6 +271,8 @@\n \n   private SparkSession sparkSession;\n \n+  private Exec hplsqlInterpreter;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNDMxMA==", "bodyText": "I think if I set fetchsize to 1 - and then I try to fetch a resultset of 10 rows with hplsql; I'll get 1 row back", "url": "https://github.com/apache/hive/pull/1633#discussion_r521914310", "createdAt": "2020-11-12T08:19:24Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/HplSqlQueryExecutor.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.service.cli.operation.hplsql;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.hplsql.executor.ColumnMeta;\n+import org.apache.hive.hplsql.executor.Metadata;\n+import org.apache.hive.hplsql.executor.QueryException;\n+import org.apache.hive.hplsql.executor.QueryExecutor;\n+import org.apache.hive.hplsql.executor.QueryResult;\n+import org.apache.hive.hplsql.executor.RowResult;\n+import org.apache.hive.service.cli.ColumnDescriptor;\n+import org.apache.hive.service.cli.FetchOrientation;\n+import org.apache.hive.service.cli.FetchType;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.session.HiveSession;\n+\n+/**\n+ * Executing HiveQL from HPL/SQL directly, without JDBC or Thrift.\n+ */\n+public class HplSqlQueryExecutor implements QueryExecutor {\n+  public static final String QUERY_EXECUTOR = \"QUERY_EXECUTOR\";\n+  public static final String HPLSQL = \"HPLSQL\";\n+  private final HiveSession hiveSession;\n+  private long fetchSize;\n+\n+  public HplSqlQueryExecutor(HiveSession hiveSession) {\n+    this.fetchSize = hiveSession.getHiveConf().getIntVar(HiveConf.ConfVars.HIVE_SERVER2_THRIFT_RESULTSET_DEFAULT_FETCH_SIZE);\n+    this.hiveSession = hiveSession;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    try {\n+      Map<String, String> confOverlay = new HashMap<>();\n+      confOverlay.put(QUERY_EXECUTOR, HPLSQL);\n+      OperationHandle operationHandle = hiveSession.executeStatement(sql, confOverlay);\n+      return new QueryResult(new OperationRowResult(operationHandle), () -> metadata(operationHandle), null);\n+    } catch (HiveSQLException e) {\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), e);\n+    }\n+  }\n+\n+  public Metadata metadata(OperationHandle operationHandle) {\n+    try {\n+      TableSchema meta = hiveSession.getResultSetMetadata(operationHandle);\n+      List<ColumnMeta> colMeta = new ArrayList<>();\n+      for (int i = 0; i < meta.getSize(); i++) {\n+        ColumnDescriptor col = meta.getColumnDescriptorAt(i);\n+        colMeta.add(new ColumnMeta(col.getName(), col.getTypeName(), col.getType().toJavaSQLType()));\n+      }\n+      return new Metadata(colMeta);\n+    } catch (HiveSQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private class OperationRowResult implements RowResult {\n+    private final OperationHandle handle;\n+    private RowSet rows;\n+    private Iterator<Object[]> iterator;\n+    private Object[] current;\n+\n+    private OperationRowResult(OperationHandle operationHandle) {\n+      this.handle = operationHandle;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      if (rows == null) {\n+        this.rows = fetch();\n+        this.iterator = rows.iterator();\n+      }\n+      if (iterator.hasNext()) {\n+        current = iterator.next();\n+        return true;\n+      } else {\n+        current = null;\n+        return false;\n+      }\n+    }\n+\n+    private RowSet fetch() {\n+      try {\n+        return hiveSession.fetchResults(\n+                handle, FetchOrientation.FETCH_NEXT, fetchSize, FetchType.QUERY_OUTPUT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTkxNzAzNg==", "bodyText": "this doesnt look right...\nwhy are we moviong a UDF into the service package? can't we avoid that?", "url": "https://github.com/apache/hive/pull/1633#discussion_r521917036", "createdAt": "2020-11-12T08:21:55Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/hplsql/Udf.java", "diffHunk": "@@ -1,123 +1,125 @@\n /*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n  *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n  *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n  */\n \n-package org.apache.hive.hplsql;\n+package org.apache.hive.service.cli.operation.hplsql;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e7eeafeb56170581e58c9e6d10478c6d1cdcd584"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3764bff31a467a53dcf4fc7e49dd37cdcb428b2d", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/3764bff31a467a53dcf4fc7e49dd37cdcb428b2d", "committedDate": "2020-11-12T12:53:20Z", "message": " HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91be26a5852446768e2264613c987a73a87d8710", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/91be26a5852446768e2264613c987a73a87d8710", "committedDate": "2020-11-12T15:09:48Z", "message": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1MjU1NzU5", "url": "https://github.com/apache/hive/pull/1633#pullrequestreview-535255759", "createdAt": "2020-11-20T09:22:17Z", "commit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwOToyMjoxN1rOH3HimQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQxMDowMzo0MVrOH3JGMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1NzI3Mw==", "bodyText": "I think it would be better if this would be mode=hplsql; that way we may add more \"mode\"-s later\nwhat do you think?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527557273", "createdAt": "2020-11-20T09:22:17Z", "author": {"login": "kgyrtkirk"}, "path": "beeline/src/java/org/apache/hive/beeline/BeeLine.java", "diffHunk": "@@ -892,8 +893,12 @@ private boolean connectUsingArgs(BeelineParser beelineParser, CommandLine cl) {\n     getOpts().setInitFiles(cl.getOptionValues(\"i\"));\n     getOpts().setScriptFile(cl.getOptionValue(\"f\"));\n \n-\n     if (url != null) {\n+      String hplSqlMode = Utils.parsePropertyFromUrl(url, Constants.HPLSQL_MODE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU1Nzk2OA==", "bodyText": "I think hive-exec already contains this transitively - is this dep really neccessary?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527557968", "createdAt": "2020-11-20T09:23:26Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/pom.xml", "diffHunk": "@@ -46,6 +46,11 @@\n       <artifactId>commons-io</artifactId>\n     </dependency>\n     <dependency>\n+      <groupId>org.apache.hive</groupId>\n+      <artifactId>hive-standalone-metastore-common</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Mzc3NQ==", "bodyText": "(QR-indexes#1) there seems to be existing loops starting for idx \"1\"", "url": "https://github.com/apache/hive/pull/1633#discussion_r527563775", "createdAt": "2020-11-20T09:32:54Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Cmp.java", "diffHunk": "@@ -138,28 +147,26 @@ else if (query2.error()) {\n       exec.signal(query2);\n       return null;\n     }\n-    ResultSet rs1 = query1.getResultSet();\n-    ResultSet rs2 = query2.getResultSet();\n-    if (rs1 == null || rs2 == null) {\n+    if (query1 == null || query2 == null) {\n       exec.setSqlCode(-1);\n       return null;\n     }\n     boolean equal = true;\n     tests = 0;\n     failedTests = 0;\n     try {\n-      ResultSetMetaData rm1 = rs1.getMetaData();\n-      ResultSetMetaData rm2 = rs2.getMetaData();\n-      int cnt1 = rm1.getColumnCount();\n-      int cnt2 = rm2.getColumnCount();\n+      Metadata rm1 = query1.metadata();\n+      Metadata rm2 = query2.metadata();\n+      int cnt1 = rm1.columnCount();\n+      int cnt2 = rm2.columnCount();\n       tests = cnt1;\n-      while (rs1.next() && rs2.next()) {\n+      while (query1.next() && query2.next()) {\n         for (int i = 1; i <= tests; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NDA4MQ==", "bodyText": "(QR-indexes#2) and there are places where it changes to 0 indexed", "url": "https://github.com/apache/hive/pull/1633#discussion_r527564081", "createdAt": "2020-11-20T09:33:27Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Copy.java", "diffHunk": "@@ -233,16 +219,16 @@ void copyToFile(HplsqlParser.Copy_stmtContext ctx, Query query) throws Exception\n         sql = \"INSERT INTO \" + sqlInsertName + \" VALUES (\";\n         rowdel = \");\\n\".getBytes();\n       }\n-      while (rs.next()) {\n+      while (query.next()) {\n         if (sqlInsert) {\n           out.write(sql.getBytes());\n         }\n-        for (int i = 1; i <= cols; i++) {\n-          if (i > 1) {\n+        for (int i = 0; i < cols; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2NTI3Ng==", "bodyText": "(QR-indexes#2) and there are places where it changes to 0 indexed\njdbc drivers usually start numbering from 1; but internal stuff tends to use 0.\nit would be helpfull to write this contract down in the QueryResult's apidoc\nwill the \"old\" approach still work after these changes?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527565276", "createdAt": "2020-11-20T09:35:30Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/Var.java", "diffHunk": "@@ -258,44 +256,35 @@ public void setValue(Object value) {\n       this.value = value;\n \t  }\n   }\n-\t\n-\t/**\n-   * Set the new value from the result set\n-   */\n-  public Var setValue(ResultSet rs, ResultSetMetaData rsm, int idx) throws SQLException {\n-    int type = rsm.getColumnType(idx);\n+\n+  public Var setValue(QueryResult queryResult, int idx) {\n+    int type = queryResult.jdbcType(idx);\n     if (type == java.sql.Types.CHAR || type == java.sql.Types.VARCHAR) {\n-      cast(new Var(rs.getString(idx)));\n-    }\n-    else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n-        type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n-      cast(new Var(Long.valueOf(rs.getLong(idx))));\n-    }\n-    else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n-      cast(new Var(rs.getBigDecimal(idx)));\n-    }\n-    else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n-      cast(new Var(Double.valueOf(rs.getDouble(idx))));\n+      cast(new Var(queryResult.column(idx, String.class)));\n+    } else if (type == java.sql.Types.INTEGER || type == java.sql.Types.BIGINT ||\n+            type == java.sql.Types.SMALLINT || type == java.sql.Types.TINYINT) {\n+      cast(new Var(Long.valueOf(queryResult.column(idx, Long.class))));\n+    } else if (type == java.sql.Types.DECIMAL || type == java.sql.Types.NUMERIC) {\n+      cast(new Var(queryResult.column(idx, BigDecimal.class)));\n+    } else if (type == java.sql.Types.FLOAT || type == java.sql.Types.DOUBLE) {\n+      cast(new Var(Double.valueOf(queryResult.column(idx, Double.class))));\n     }\n     return this;\n   }\n-  \n-  /**\n-   * Set ROW values from the result set\n-   */\n-  public Var setValues(ResultSet rs, ResultSetMetaData rsm) throws SQLException {\n+\n+  public Var setValues(QueryResult queryResult) {\n     Row row = (Row)this.value;\n-    int idx = 1;\n+    int idx = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2Njk0MA==", "bodyText": "(QR-indexes#4) given the things I've seen so far:\nI think right now queryresult is 0 indexed; and this seems to be the jdbc adaptor so I would have expected a +/- 1 here", "url": "https://github.com/apache/hive/pull/1633#discussion_r527566940", "createdAt": "2020-11-20T09:38:20Z", "author": {"login": "kgyrtkirk"}, "path": "hplsql/src/main/java/org/apache/hive/hplsql/executor/JdbcQueryExecutor.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+package org.apache.hive.hplsql.executor;\n+\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.antlr.v4.runtime.ParserRuleContext;\n+import org.apache.hive.hplsql.Exec;\n+import org.apache.hive.hplsql.Query;\n+\n+public class JdbcQueryExecutor implements QueryExecutor {\n+  private final Exec exec;\n+\n+  public JdbcQueryExecutor(Exec exec) {\n+    this.exec = exec;\n+  }\n+\n+  @Override\n+  public QueryResult executeQuery(String sql, ParserRuleContext ctx) {\n+    String conn = exec.getStatementConnection();\n+    Query query = exec.executeQuery(ctx, new Query(sql), conn);\n+    ResultSet resultSet = query.getResultSet();\n+    if (resultSet == null) { // offline mode\n+      return new QueryResult(null, () -> new Metadata(Collections.emptyList()), query.getException());\n+    } else {\n+      return new QueryResult(new JdbcRowResult(resultSet), () -> metadata(resultSet), query.getException());\n+    }\n+  }\n+\n+  private static Metadata metadata(ResultSet resultSet) {\n+    try {\n+      ResultSetMetaData meta = resultSet.getMetaData();\n+      List<ColumnMeta> colMetas = new ArrayList<>();\n+      for (int i = 1; i <= meta.getColumnCount(); i++) {\n+        colMetas.add(new ColumnMeta(\n+                meta.getColumnName(i), meta.getColumnTypeName(i), meta.getColumnType(i)));\n+      }\n+      return new Metadata(colMetas);\n+    } catch (SQLException e) {\n+      throw new QueryException(e);\n+    }\n+  }\n+\n+  private static class JdbcRowResult implements RowResult {\n+    private final ResultSet resultSet;\n+\n+    private JdbcRowResult(ResultSet resultSet) {\n+      this.resultSet = resultSet;\n+    }\n+\n+    @Override\n+    public boolean next() {\n+      try {\n+        return resultSet.next();\n+      } catch (SQLException e) {\n+        throw new QueryException(e);\n+      }\n+    }\n+\n+    @Override\n+    public <T> T get(int columnIndex, Class<T> type) {\n+      try {\n+        return resultSet.getObject(columnIndex, type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU2OTg5NA==", "bodyText": "could you configure import order in your ide to not reorder imports \"this much\"?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527569894", "createdAt": "2020-11-20T09:43:28Z", "author": {"login": "kgyrtkirk"}, "path": "jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java", "diffHunk": "@@ -18,18 +18,67 @@\n \n package org.apache.hive.jdbc;\n \n-import com.google.common.annotations.VisibleForTesting;\n+import static org.apache.hadoop.hive.conf.Constants.HPLSQL_MODE;\n+import java.io.BufferedReader;\n+import java.io.DataInputStream;\n+import java.io.File;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3NDM5NQ==", "bodyText": "what does embedded mean here?\n\nembedded hiveserver2\nsome hplsql related stuff?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527574395", "createdAt": "2020-11-20T09:50:27Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -102,7 +109,7 @@ protected Operation(HiveSession parentSession,\n         MetricsConstant.COMPLETED_OPERATION_PREFIX, state);\n     queryState = new QueryState.Builder()\n                      .withConfOverlay(confOverlay)\n-                     .withGenerateNewQueryId(true)\n+                     .withGenerateNewQueryId(!embedded)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU4Mjc2OA==", "bodyText": "I don't see this or SqlOperation called with a true embedded parameter\nthis one way to create a multi statement query thing - I wonder if we could have that as a first class citizen - and implement the old one as a single-instruction operation. what do you think?", "url": "https://github.com/apache/hive/pull/1633#discussion_r527582768", "createdAt": "2020-11-20T10:03:41Z", "author": {"login": "kgyrtkirk"}, "path": "service/src/java/org/apache/hive/service/cli/operation/Operation.java", "diffHunk": "@@ -88,8 +89,14 @@ protected Operation(HiveSession parentSession, OperationType opType) {\n   }\n \n   protected Operation(HiveSession parentSession,\n-      Map<String, String> confOverlay, OperationType opType) {\n+                      Map<String, String> confOverlay, OperationType opType) {\n+    this(parentSession, confOverlay, opType, false);\n+  }\n+\n+  protected Operation(HiveSession parentSession,\n+      Map<String, String> confOverlay, OperationType opType, boolean embedded) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91be26a5852446768e2264613c987a73a87d8710"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aff6cfd7426aec1a45852783f5571e8803eef1dd", "author": {"user": {"login": "zeroflag", "name": "Attila Magyar"}}, "url": "https://github.com/apache/hive/commit/aff6cfd7426aec1a45852783f5571e8803eef1dd", "committedDate": "2020-11-23T12:29:26Z", "message": "HIVE-24230 Integrate HPL/SQL into HiveServer2 (amagyar)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzOTUyNTc5", "url": "https://github.com/apache/hive/pull/1633#pullrequestreview-543952579", "createdAt": "2020-12-03T13:29:59Z", "commit": {"oid": "aff6cfd7426aec1a45852783f5571e8803eef1dd"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2982, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}