{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI4NTgwODEz", "number": 1067, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzowNjowM1rOEDB_Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwODoyOToxN1rOEGP90g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNjEzNzU5OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzowNjowM1rOGf2ZzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxOTozMjo1MFrOGf62xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ==", "bodyText": "We were skipping string garbage for this, I think we can switch to the {} format", "url": "https://github.com/apache/hive/pull/1067#discussion_r436050381", "createdAt": "2020-06-05T17:06:03Z", "author": {"login": "t3rmin4t0r"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MTgzMQ==", "bodyText": "Thanks @t3rmin4t0r for the review!  I'm not sure the value of that.  Are there many instances where organizations are running with something higher than INFO?  If it's expected to run at INFO, better to just concat and print the message than to have to do the actions of parsing the string, looking for the anchor {}, replacing it, etc. etc.  I am happy to do it just for consistency, but from performance, better to simply concat and print.", "url": "https://github.com/apache/hive/pull/1067#discussion_r436051831", "createdAt": "2020-06-05T17:09:07Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ=="}, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3MjY2OQ==", "bodyText": "The problem is string concatenation does a lot of work without knowing if it is needed or not -- {} format does not!\nhttp://slf4j.org/faq.html#logging_performance", "url": "https://github.com/apache/hive/pull/1067#discussion_r436072669", "createdAt": "2020-06-05T17:49:58Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ=="}, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA5Mjk3OQ==", "bodyText": "Thanks for chiming in @pgaref\nI love that you're passionate about using the parameters.  I usually like to do this, but it's 50-50 on who likes to see it and who not.  My point is that using parameters:\n\ncan significantly boost logging performance for disabled logging statement.\n\nThe problem is that it adds overhead when there are enabled logging statements.  For an INFO level logging, it's almost certainly enabled in a production environment so using the anchor ({}) just adds needless overhead.\nThink about it, what is faster?\npublic static void main(String[] args) {\n   info1(\"foo: \", \"bar\");\n   info2(\"foo: {}\", \"bar\");\n}\n\nvoid info1(String s, String param) {\n  System.out.println(s.concat(param));\n}\n\nvoid info2(String s, String param) {\n   int index = s.lastIndexOf(\"{\");\n   if (index < 0) {\n     System.out.println(s);\n   } else {\n      if (s.lastIndexOf{\"}\") == (index + 1) {\n         String firstHalf= s.subString(0, index);\n         String secondHalf = s.subString(index + 2) s.length());\n        System.out.println(firstHalf + param + secondHalf);\n    } else {\n        System.out.println(s);\n    }\n}\n\nClearly the second option is going to be slower.  Info1 generates a string certainly, and Info2 does not.  However, if the application is almost always going to be running at the INFO level, it doesn't really make a lot of sense to have to always go down Info2.\nThat said, there is certainly value in having consistency (always using parameters), and I think messages are easier to read when formatted this way than when they are all piecemeal with the \"+\" signs, but if you want to understand the raw performance, then what is currently there is preferable in an environment where the log level is set to a minimum of INFO (which almost every environment I've worked on is).", "url": "https://github.com/apache/hive/pull/1067#discussion_r436092979", "createdAt": "2020-06-05T18:25:54Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ=="}, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA5OTA3MA==", "bodyText": "(see below for more)", "url": "https://github.com/apache/hive/pull/1067#discussion_r436099070", "createdAt": "2020-06-05T18:38:05Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ=="}, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyMzMzNA==", "bodyText": "Hey @belugabehr -- thanks for the detailed comment!\nTbh I was under the impression that the flush size message above was on debug mode -- we are on the same page on this!\nThere are several places in the project were we check if (LOG.isDebugEnabled()) before doing the logging, however, this is completely redundant (if we have less than 3 arguments as you pointed out correctly below).\nFor Log.info mode, as you said, it is more like a matter of consistency.", "url": "https://github.com/apache/hive/pull/1067#discussion_r436123334", "createdAt": "2020-06-05T19:32:50Z", "author": {"login": "pgaref"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -990,24 +955,17 @@ private void flushHashTable(boolean complete) throws HiveException {\n     // changed in the future\n \n     if (complete) {\n-      Iterator<Map.Entry<KeyWrapper, AggregationBuffer[]>> iter = hashAggregations\n-          .entrySet().iterator();\n-      while (iter.hasNext()) {\n-        Map.Entry<KeyWrapper, AggregationBuffer[]> m = iter.next();\n-        forward(m.getKey().getKeyArray(), m.getValue());\n+      for (Map.Entry<KeyWrapper, AggregationBuffer[]> entry : hashAggregations.entrySet()) {\n+        forward(entry.getKey().getKeyArray(), entry.getValue());\n       }\n-      hashAggregations.clear();\n       hashAggregations = null;\n-      if (LOG.isInfoEnabled()) {\n-        LOG.info(\"Hash Table completed flushed\");\n-      }\n+      LOG.info(\"Hash Table completed flushed\");\n       return;\n     }\n \n     int oldSize = hashAggregations.size();\n-    if (LOG.isInfoEnabled()) {\n-      LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);\n-    }\n+    LOG.info(\"Hash Tbl flush: #hash table = \" + oldSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1MDM4MQ=="}, "originalCommit": {"oid": "6b31fea4b6c319066e952d6bc5057ff14bcfb6b7"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxNzA1ODEwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQyMjo1NzozMFrOGf_e6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxMzoyNTozOFrOGh0rew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE5OTE0Ng==", "bodyText": "I assume that LinkedHashSet was chosen in order to retain the order of the elements and avoid calling contains on a List.\nHowever, I have the impression that we can avoid the call to List#contains rather easy since the way we populate the list is controlled.\nMoreover, I think that the order of inserting the elements does not really matter since what we are storing inside is a pointer to an aggregate and when it is used it is used with indirection. The same pointer that we are putting in this list we are putting also to the nonDistinctKeyAggrs and distinctKeyAggrs inside the sets, so it is another indicator that retaining the order is useless.\nSo instead of using the LinkedHashSet some other alternatives would be to  would be to keep the ArrayList with a small refactoring to avoid List#contains or use a plain HashSet.", "url": "https://github.com/apache/hive/pull/1067#discussion_r436199146", "createdAt": "2020-06-05T22:57:30Z", "author": {"login": "zabetak"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -90,13 +91,11 @@\n   // so aggregationIsDistinct is a boolean array instead of a single number.\n   private transient boolean[] aggregationIsDistinct;\n   // Map from integer tag to distinct aggrs\n-  private transient Map<Integer, Set<Integer>> distinctKeyAggrs =\n-    new HashMap<Integer, Set<Integer>>();\n+  private transient Map<Integer, Set<Integer>> distinctKeyAggrs = new HashMap<>();\n   // Map from integer tag to non-distinct aggrs with key parameters.\n-  private transient Map<Integer, Set<Integer>> nonDistinctKeyAggrs =\n-    new HashMap<Integer, Set<Integer>>();\n+  private transient Map<Integer, Set<Integer>> nonDistinctKeyAggrs = new HashMap<>();\n   // List of non-distinct aggrs.\n-  private transient List<Integer> nonDistinctAggrs = new ArrayList<Integer>();\n+  private transient Set<Integer> nonDistinctAggrs = new LinkedHashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36ba0a64ce1a0e6421e725313dff37fd582af64"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODExOTI5MQ==", "bodyText": "@zabetak Yes.  You are 100% correct about your assumptions about my motivations. Bravo.\nI will change to HashSet and let anyone else take a crack at more refactoring.", "url": "https://github.com/apache/hive/pull/1067#discussion_r438119291", "createdAt": "2020-06-10T13:25:38Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -90,13 +91,11 @@\n   // so aggregationIsDistinct is a boolean array instead of a single number.\n   private transient boolean[] aggregationIsDistinct;\n   // Map from integer tag to distinct aggrs\n-  private transient Map<Integer, Set<Integer>> distinctKeyAggrs =\n-    new HashMap<Integer, Set<Integer>>();\n+  private transient Map<Integer, Set<Integer>> distinctKeyAggrs = new HashMap<>();\n   // Map from integer tag to non-distinct aggrs with key parameters.\n-  private transient Map<Integer, Set<Integer>> nonDistinctKeyAggrs =\n-    new HashMap<Integer, Set<Integer>>();\n+  private transient Map<Integer, Set<Integer>> nonDistinctKeyAggrs = new HashMap<>();\n   // List of non-distinct aggrs.\n-  private transient List<Integer> nonDistinctAggrs = new ArrayList<Integer>();\n+  private transient Set<Integer> nonDistinctAggrs = new LinkedHashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE5OTE0Ng=="}, "originalCommit": {"oid": "d36ba0a64ce1a0e6421e725313dff37fd582af64"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0OTg4NDk4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwODoyOToxN1rOGk7TLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwODoyOToxN1rOGk7TLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM3MzQ4Ng==", "bodyText": "nit: missing space", "url": "https://github.com/apache/hive/pull/1067#discussion_r441373486", "createdAt": "2020-06-17T08:29:17Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java", "diffHunk": "@@ -899,12 +873,8 @@ private boolean shouldBeFlushed(KeyWrapper newKeys) {\n       // Assuming the used memory is equally divided among all executors.\n       usedMemory = isLlap ? usedMemory / numExecutors : usedMemory;\n       rate = (float) usedMemory / (float) maxMemory;\n-      if(rate > memoryThreshold){\n-        if (isTez && numEntriesHashTable == 0) {\n-          return false;\n-        } else {\n-          return true;\n-        }\n+      if (rate > memoryThreshold){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f0110b0c3c61d3a7220c1bcc7e8831713750ba82"}, "originalPosition": 108}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 734, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}