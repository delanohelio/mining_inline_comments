{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2NTI2NjE4", "number": 1231, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQwNDoyNzoyOVrOEOGJQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQwNDoyNzoyOVrOEOGJQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMjE2MTkzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQwNDoyNzoyOVrOGxDlmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQyMTowNjoxMFrOGxlVng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA5MjE4Ng==", "bodyText": "In which case would we have a RS with multiple children? I thought this would never happen. Can we leave a comment explaining it? Otherwise, we should add a Precondition with number of children 1.", "url": "https://github.com/apache/hive/pull/1231#discussion_r454092186", "createdAt": "2020-07-14T04:27:29Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "diffHunk": "@@ -409,26 +409,54 @@ private boolean removeRSInsertedByEnforceBucketing(FileSinkOperator fsOp) {\n       // and grand child\n       if (found) {\n         Operator<? extends OperatorDesc> rsParent = rsToRemove.getParentOperators().get(0);\n-        Operator<? extends OperatorDesc> rsChild = rsToRemove.getChildOperators().get(0);\n-        Operator<? extends OperatorDesc> rsGrandChild = rsChild.getChildOperators().get(0);\n-\n-        if (rsChild instanceof SelectOperator) {\n-          // if schema size cannot be matched, then it could be because of constant folding\n-          // converting partition column expression to constant expression. The constant\n-          // expression will then get pruned by column pruner since it will not reference to\n-          // any columns.\n-          if (rsParent.getSchema().getSignature().size() !=\n-              rsChild.getSchema().getSignature().size()) {\n+        List<Operator<? extends OperatorDesc>> rsChildren = rsToRemove.getChildOperators();\n+\n+        Operator<? extends OperatorDesc> rsChildToRemove = null;\n+\n+        for (Operator<? extends OperatorDesc> rsChild : rsChildren) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a030d50eebbf43c84528b2ec006cd39ef13cd1d5"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ2MjM4Mw==", "bodyText": "I assumed that this could be possibility and therefore accounted for it, but if this assumption is wrong I update the code.", "url": "https://github.com/apache/hive/pull/1231#discussion_r454462383", "createdAt": "2020-07-14T15:55:13Z", "author": {"login": "vineetgarg02"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "diffHunk": "@@ -409,26 +409,54 @@ private boolean removeRSInsertedByEnforceBucketing(FileSinkOperator fsOp) {\n       // and grand child\n       if (found) {\n         Operator<? extends OperatorDesc> rsParent = rsToRemove.getParentOperators().get(0);\n-        Operator<? extends OperatorDesc> rsChild = rsToRemove.getChildOperators().get(0);\n-        Operator<? extends OperatorDesc> rsGrandChild = rsChild.getChildOperators().get(0);\n-\n-        if (rsChild instanceof SelectOperator) {\n-          // if schema size cannot be matched, then it could be because of constant folding\n-          // converting partition column expression to constant expression. The constant\n-          // expression will then get pruned by column pruner since it will not reference to\n-          // any columns.\n-          if (rsParent.getSchema().getSignature().size() !=\n-              rsChild.getSchema().getSignature().size()) {\n+        List<Operator<? extends OperatorDesc>> rsChildren = rsToRemove.getChildOperators();\n+\n+        Operator<? extends OperatorDesc> rsChildToRemove = null;\n+\n+        for (Operator<? extends OperatorDesc> rsChild : rsChildren) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA5MjE4Ng=="}, "originalCommit": {"oid": "a030d50eebbf43c84528b2ec006cd39ef13cd1d5"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ2NDI5Ng==", "bodyText": "Yes, there should not be a RS with multiple children, we can simplify that code. You can even add an assert to the new code to make sure.", "url": "https://github.com/apache/hive/pull/1231#discussion_r454464296", "createdAt": "2020-07-14T15:57:57Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "diffHunk": "@@ -409,26 +409,54 @@ private boolean removeRSInsertedByEnforceBucketing(FileSinkOperator fsOp) {\n       // and grand child\n       if (found) {\n         Operator<? extends OperatorDesc> rsParent = rsToRemove.getParentOperators().get(0);\n-        Operator<? extends OperatorDesc> rsChild = rsToRemove.getChildOperators().get(0);\n-        Operator<? extends OperatorDesc> rsGrandChild = rsChild.getChildOperators().get(0);\n-\n-        if (rsChild instanceof SelectOperator) {\n-          // if schema size cannot be matched, then it could be because of constant folding\n-          // converting partition column expression to constant expression. The constant\n-          // expression will then get pruned by column pruner since it will not reference to\n-          // any columns.\n-          if (rsParent.getSchema().getSignature().size() !=\n-              rsChild.getSchema().getSignature().size()) {\n+        List<Operator<? extends OperatorDesc>> rsChildren = rsToRemove.getChildOperators();\n+\n+        Operator<? extends OperatorDesc> rsChildToRemove = null;\n+\n+        for (Operator<? extends OperatorDesc> rsChild : rsChildren) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA5MjE4Ng=="}, "originalCommit": {"oid": "a030d50eebbf43c84528b2ec006cd39ef13cd1d5"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUxMTQyOA==", "bodyText": "@jcamachor I have addressed in latest commit.", "url": "https://github.com/apache/hive/pull/1231#discussion_r454511428", "createdAt": "2020-07-14T17:10:43Z", "author": {"login": "vineetgarg02"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "diffHunk": "@@ -409,26 +409,54 @@ private boolean removeRSInsertedByEnforceBucketing(FileSinkOperator fsOp) {\n       // and grand child\n       if (found) {\n         Operator<? extends OperatorDesc> rsParent = rsToRemove.getParentOperators().get(0);\n-        Operator<? extends OperatorDesc> rsChild = rsToRemove.getChildOperators().get(0);\n-        Operator<? extends OperatorDesc> rsGrandChild = rsChild.getChildOperators().get(0);\n-\n-        if (rsChild instanceof SelectOperator) {\n-          // if schema size cannot be matched, then it could be because of constant folding\n-          // converting partition column expression to constant expression. The constant\n-          // expression will then get pruned by column pruner since it will not reference to\n-          // any columns.\n-          if (rsParent.getSchema().getSignature().size() !=\n-              rsChild.getSchema().getSignature().size()) {\n+        List<Operator<? extends OperatorDesc>> rsChildren = rsToRemove.getChildOperators();\n+\n+        Operator<? extends OperatorDesc> rsChildToRemove = null;\n+\n+        for (Operator<? extends OperatorDesc> rsChild : rsChildren) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA5MjE4Ng=="}, "originalCommit": {"oid": "a030d50eebbf43c84528b2ec006cd39ef13cd1d5"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY0NTE1MA==", "bodyText": "@jcamachor all tests passed.", "url": "https://github.com/apache/hive/pull/1231#discussion_r454645150", "createdAt": "2020-07-14T21:06:10Z", "author": {"login": "vineetgarg02"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java", "diffHunk": "@@ -409,26 +409,54 @@ private boolean removeRSInsertedByEnforceBucketing(FileSinkOperator fsOp) {\n       // and grand child\n       if (found) {\n         Operator<? extends OperatorDesc> rsParent = rsToRemove.getParentOperators().get(0);\n-        Operator<? extends OperatorDesc> rsChild = rsToRemove.getChildOperators().get(0);\n-        Operator<? extends OperatorDesc> rsGrandChild = rsChild.getChildOperators().get(0);\n-\n-        if (rsChild instanceof SelectOperator) {\n-          // if schema size cannot be matched, then it could be because of constant folding\n-          // converting partition column expression to constant expression. The constant\n-          // expression will then get pruned by column pruner since it will not reference to\n-          // any columns.\n-          if (rsParent.getSchema().getSignature().size() !=\n-              rsChild.getSchema().getSignature().size()) {\n+        List<Operator<? extends OperatorDesc>> rsChildren = rsToRemove.getChildOperators();\n+\n+        Operator<? extends OperatorDesc> rsChildToRemove = null;\n+\n+        for (Operator<? extends OperatorDesc> rsChild : rsChildren) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA5MjE4Ng=="}, "originalCommit": {"oid": "a030d50eebbf43c84528b2ec006cd39ef13cd1d5"}, "originalPosition": 58}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 553, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}