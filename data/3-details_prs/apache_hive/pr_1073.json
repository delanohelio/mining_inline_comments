{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxMDUwMzI1", "number": 1073, "title": "HIVE-22869: Add locking benchmark to metastore-tools/metastore-benchmarks", "bodyText": "", "createdAt": "2020-06-08T10:58:13Z", "url": "https://github.com/apache/hive/pull/1073", "merged": true, "mergeCommit": {"oid": "764e5ed20ab9a5a8bc5b8bd5947b231c14703eaa"}, "closed": true, "closedAt": "2020-07-20T08:04:23Z", "author": {"login": "zchovan"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcnUWaxgH2gAyNDMxMDUwMzI1Ojc2YzQxZDJmNDYzYmYwNGFjYzFhNDE4ZTMyODI1OGI2ZjBjMmU3ZWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc10-cMAFqTQ1MDcyMDc0NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "76c41d2f463bf04acc1a418e328258b6f0c2e7ed", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/76c41d2f463bf04acc1a418e328258b6f0c2e7ed", "committedDate": "2020-06-02T12:51:43Z", "message": "HIVE-22869 Add locking benchmark to metastore-tools/metastore-benchmarks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9fc7b16b58c0d282af216891a7fe87cc166bc6f", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/f9fc7b16b58c0d282af216891a7fe87cc166bc6f", "committedDate": "2020-06-02T12:51:43Z", "message": "HMS benchmarking modifications\n\nChange-Id: I641f7b094aff46b92cfa3d38e3049b221fa5abe6"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fdd6af13da002bac0c3a63f18a958325858275fe", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/fdd6af13da002bac0c3a63f18a958325858275fe", "committedDate": "2020-06-05T13:00:03Z", "message": "CDPD-11690\n\nChange-Id: Iea9f99870cfffc915b0574570cfb4b08827d5e3a"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6a7ea1bf3f8eb1a70337d0f827a72d997db2939", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/b6a7ea1bf3f8eb1a70337d0f827a72d997db2939", "committedDate": "2020-06-09T15:13:44Z", "message": "CDPD-11690\n\nChange-Id: Iea9f99870cfffc915b0574570cfb4b08827d5e3a"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/cd44b6227ea2c56386ab09970a3dfeb2016767d0", "committedDate": "2020-06-09T15:15:27Z", "message": "Merge branch 'HIVE-22869' of github.com:zchovan/hive into HIVE-22869\n\nChange-Id: I0b4ae360a4c2b2de49dd74620f19e38cf38a2021"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI5MDI3NjQ0", "url": "https://github.com/apache/hive/pull/1073#pullrequestreview-429027644", "createdAt": "2020-06-11T15:26:30Z", "commit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxNToyNjozMFrOGiib9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMVQxNTo0MzozOFrOGijahQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg2ODk4MQ==", "bodyText": "rename to doSetup as it's global and not iteration scoped", "url": "https://github.com/apache/hive/pull/1073#discussion_r438868981", "createdAt": "2020-06-11T15:26:30Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/metastore-benchmarks/src/main/java/org/apache/hadoop/hive/metastore/tools/ACIDBenchmarks.java", "diffHunk": "@@ -0,0 +1,247 @@\n+package org.apache.hadoop.hive.metastore.tools;\n+\n+import org.apache.hadoop.hive.metastore.api.DataOperationType;\n+import org.apache.hadoop.hive.metastore.api.LockComponent;\n+import org.apache.hadoop.hive.metastore.api.LockRequest;\n+import org.apache.logging.log4j.Level;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.core.LoggerContext;\n+import org.apache.logging.log4j.core.config.Configuration;\n+import org.apache.thrift.TException;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.tools.BenchmarkUtils.createManyTables;\n+import static org.apache.hadoop.hive.metastore.tools.BenchmarkUtils.dropManyTables;\n+import static org.apache.hadoop.hive.metastore.tools.Util.throwingSupplierWrapper;\n+\n+public class ACIDBenchmarks {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(CoreContext.class);\n+\n+  @State(Scope.Benchmark)\n+  public static class CoreContext {\n+    @Param(\"1\")\n+    protected int howMany;\n+\n+    @State(Scope.Thread)\n+    public static class ThreadState {\n+      HMSClient client;\n+\n+      @Setup\n+      public void doSetup() throws Exception {\n+        LOG.debug(\"Creating client\");\n+        client = HMSConfig.getInstance().newClient();\n+      }\n+\n+      @TearDown\n+      public void doTearDown() throws Exception {\n+        client.close();\n+        LOG.debug(\"Closed a connection to metastore.\");\n+      }\n+    }\n+\n+    @Setup\n+    public void setup() {\n+      LoggerContext ctx = (LoggerContext) LogManager.getContext(false);\n+      Configuration ctxConfig = ctx.getConfiguration();\n+      ctxConfig.getLoggerConfig(CoreContext.class.getName()).setLevel(Level.INFO);\n+      ctx.updateLoggers(ctxConfig);\n+    }\n+  }\n+\n+  @State(Scope.Benchmark)\n+  public static class TestOpenTxn extends CoreContext {\n+\n+    @State(Scope.Thread)\n+    public static class ThreadState extends CoreContext.ThreadState {\n+      List<Long> openTxns = new ArrayList<>();\n+\n+      @TearDown\n+      public void doTearDown() throws Exception {\n+        client.abortTxns(openTxns);\n+        LOG.debug(\"aborted all opened txns\");\n+      }\n+\n+      void addTxn(List<Long> openTxn) {\n+        openTxns.addAll(openTxn);\n+      }\n+    }\n+\n+    @Benchmark\n+    public void openTxn(TestOpenTxn.ThreadState state) throws TException {\n+      state.addTxn(state.client.openTxn(howMany));\n+      LOG.debug(\"opened txns, count=\", howMany);\n+    }\n+  }\n+\n+  @State(Scope.Benchmark)\n+  public static class TestLocking extends CoreContext {\n+    private int nTables;\n+\n+    @Param(\"0\")\n+    private int nPartitions;\n+\n+    private List<LockComponent> lockComponents;\n+\n+    @Setup\n+    public void setup() {\n+      this.nTables = (nPartitions != 0) ? howMany / nPartitions : howMany;\n+      createLockComponents();\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class ThreadState extends CoreContext.ThreadState {\n+      List<Long> openTxns = new ArrayList<>();\n+      long txnId;\n+\n+      @Setup(org.openjdk.jmh.annotations.Level.Invocation)\n+      public void iterSetup() {\n+        txnId = executeOpenTxnAndGetTxnId(client);\n+        LOG.debug(\"opened txn, id={}\", txnId);\n+        openTxns.add(txnId);\n+      }\n+\n+      @TearDown\n+      public void doTearDown() throws Exception {\n+        client.abortTxns(openTxns);\n+        if (BenchmarkUtils.checkTxnsCleaned(client, openTxns) == false) {\n+          LOG.error(\"Something went wrong with the cleanup of txns\");\n+        }\n+        LOG.debug(\"aborted all opened txns\");\n+      }\n+    }\n+\n+    @Benchmark\n+    public void lock(TestLocking.ThreadState state) {\n+      LOG.debug(\"sending lock request\");\n+      executeLock(state.client, state.txnId, lockComponents);\n+    }\n+\n+    private void createLockComponents() {\n+      lockComponents = new ArrayList<>();\n+\n+      for (int i = 0; i < nTables; i++) {\n+        for (int j = 0; j < nPartitions - (nPartitions > 1 ? 1 : 0); j++) {\n+          lockComponents.add(\n+            new Util.LockComponentBuilder()\n+              .setDbName(\"default\")\n+              .setTableName(String.format(\"tmp_table_%d\", i))\n+              .setPartitionName(\"p_\" + j)\n+              .setShared()\n+              .setOperationType(DataOperationType.SELECT)\n+              .build());\n+        }\n+        if (nPartitions != 1) {\n+          lockComponents.add(\n+            new Util.LockComponentBuilder()\n+              .setDbName(\"default\")\n+              .setTableName(String.format(\"tmp_table_%d\", i))\n+              .setShared()\n+              .setOperationType(DataOperationType.SELECT)\n+              .build());\n+        }\n+      }\n+    }\n+\n+    private static long executeOpenTxnAndGetTxnId(HMSClient client) {\n+      return throwingSupplierWrapper(() -> client.openTxn(1).get(0));\n+    }\n+\n+    private void executeLock(HMSClient client, long txnId, List<LockComponent> lockComponents) {\n+      LockRequest req = new LockRequest(lockComponents, \"hclient\", \"localhost\");\n+      req.setTxnid(txnId);\n+      throwingSupplierWrapper(() -> client.lock(req));\n+    }\n+  }\n+\n+  @State(Scope.Benchmark)\n+  public static class TestAllocateTableWriteIds extends CoreContext {\n+    String dbName = \"test_db\";\n+    String tblName = \"tmp_table\";\n+\n+    @State(Scope.Thread)\n+    public static class ThreadState extends CoreContext.ThreadState {\n+      List<Long> openTxns = new ArrayList<>();\n+      long txnId;\n+\n+      @Setup\n+      public void iterSetup() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg3MTc4OA==", "bodyText": "I would use switch here and go with ALL by default", "url": "https://github.com/apache/hive/pull/1073#discussion_r438871788", "createdAt": "2020-06-11T15:29:21Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/metastore-benchmarks/src/main/java/org/apache/hadoop/hive/metastore/tools/BenchmarkTool.java", "diffHunk": "@@ -141,12 +175,62 @@ private static void saveDataFile(String location, String name,\n     }\n   }\n \n-\n   @Override\n   public void run() {\n-    LOG.info(\"Using warmup \" + warmup +\n-        \" spin \" + spinCount + \" nparams \" + nParameters + \" threads \" + nThreads);\n+    LOG.info(\"Using warmup \" + warmup + \" spin \" + spinCount + \" nparams \" + Arrays.toString(nParameters) + \" threads \"\n+        + nThreads);\n+    HMSConfig.getInstance().init(host, port, confDir);\n+\n+    if (runMode == RunModes.ALL) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg3NTA4Mg==", "bodyText": "many new lines", "url": "https://github.com/apache/hive/pull/1073#discussion_r438875082", "createdAt": "2020-06-11T15:32:37Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/metastore-benchmarks/src/main/java/org/apache/hadoop/hive/metastore/tools/BenchmarkUtils.java", "diffHunk": "@@ -0,0 +1,72 @@\n+package org.apache.hadoop.hive.metastore.tools;\n+\n+import org.apache.hadoop.hive.metastore.TableType;\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.TxnInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.hadoop.hive.metastore.tools.Util.createSchema;\n+import static org.apache.hadoop.hive.metastore.tools.Util.throwingSupplierWrapper;\n+\n+public class BenchmarkUtils {\n+  private static final Logger LOG = LoggerFactory.getLogger(BenchmarkUtils.class);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg3NjM3NA==", "bodyText": "Arrays.asList returns ArrayList, why to pass it into constructor of another ArrayList?", "url": "https://github.com/apache/hive/pull/1073#discussion_r438876374", "createdAt": "2020-06-11T15:34:01Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/metastore-benchmarks/src/main/java/org/apache/hadoop/hive/metastore/tools/BenchmarkUtils.java", "diffHunk": "@@ -0,0 +1,72 @@\n+package org.apache.hadoop.hive.metastore.tools;\n+\n+import org.apache.hadoop.hive.metastore.TableType;\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.TxnInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.hadoop.hive.metastore.tools.Util.createSchema;\n+import static org.apache.hadoop.hive.metastore.tools.Util.throwingSupplierWrapper;\n+\n+public class BenchmarkUtils {\n+  private static final Logger LOG = LoggerFactory.getLogger(BenchmarkUtils.class);\n+\n+\n+  static void createManyTables(HMSClient client, int howMany, String dbName, String format) {\n+    List<FieldSchema> columns = createSchema(new ArrayList<>(Arrays.asList(\"name\", \"string\")));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg4MTYwMg==", "bodyText": "you can use txnInfos.stream().anyMatch(txnsOpenedByBenchmark::contains), change txnsOpenedByBenchmark to Set", "url": "https://github.com/apache/hive/pull/1073#discussion_r438881602", "createdAt": "2020-06-11T15:39:22Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/metastore-benchmarks/src/main/java/org/apache/hadoop/hive/metastore/tools/BenchmarkUtils.java", "diffHunk": "@@ -0,0 +1,72 @@\n+package org.apache.hadoop.hive.metastore.tools;\n+\n+import org.apache.hadoop.hive.metastore.TableType;\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.TxnInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.hadoop.hive.metastore.tools.Util.createSchema;\n+import static org.apache.hadoop.hive.metastore.tools.Util.throwingSupplierWrapper;\n+\n+public class BenchmarkUtils {\n+  private static final Logger LOG = LoggerFactory.getLogger(BenchmarkUtils.class);\n+\n+\n+  static void createManyTables(HMSClient client, int howMany, String dbName, String format) {\n+    List<FieldSchema> columns = createSchema(new ArrayList<>(Arrays.asList(\"name\", \"string\")));\n+    List<FieldSchema> partitions = createSchema(new ArrayList<>(Arrays.asList(\"date\", \"string\")));\n+    IntStream.range(0, howMany)\n+        .forEach(i ->\n+            throwingSupplierWrapper(() -> client.createTable(\n+                new Util.TableBuilder(dbName, String.format(format, i))\n+                    .withType(TableType.MANAGED_TABLE)\n+                    .withColumns(columns)\n+                    .withPartitionKeys(partitions)\n+                    .build())));\n+  }\n+\n+  static void dropManyTables(HMSClient client, int howMany, String dbName, String format) {\n+    IntStream.range(0, howMany)\n+        .forEach(i ->\n+            throwingSupplierWrapper(() -> client.dropTable(dbName, String.format(format, i))));\n+  }\n+\n+  // Create a simple table with a single column and single partition\n+  static void createPartitionedTable(HMSClient client, String dbName, String tableName) {\n+    throwingSupplierWrapper(() -> client.createTable(\n+        new Util.TableBuilder(dbName, tableName)\n+            .withType(TableType.MANAGED_TABLE)\n+            .withColumns(createSchema(Collections.singletonList(\"name:string\")))\n+            .withPartitionKeys(createSchema(Collections.singletonList(\"date\")))\n+            .build()));\n+  }\n+\n+  static boolean checkTxnsCleaned(HMSClient client, List<Long> txnsOpenedByBenchmark) throws InterruptedException {\n+    // let's wait the default cleaner run period\n+    Thread.sleep(100000);\n+    List<Long> notCleanedTxns = new ArrayList<>();\n+    throwingSupplierWrapper(() -> {\n+      List<TxnInfo> txnInfos = client.getOpenTxnsInfo();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg4NDk5Nw==", "bodyText": "I would expect this method to return list of validWriteIds, not just true. Should we change the name?", "url": "https://github.com/apache/hive/pull/1073#discussion_r438884997", "createdAt": "2020-06-11T15:43:38Z", "author": {"login": "deniskuzZ"}, "path": "standalone-metastore/metastore-tools/tools-common/src/main/java/org/apache/hadoop/hive/metastore/tools/HMSClient.java", "diffHunk": "@@ -345,21 +348,44 @@ boolean openTxn(int numTxns) throws TException {\n     return openTxns;\n   }\n \n+  List<TxnInfo> getOpenTxnsInfo() throws TException {\n+    return client.get_open_txns_info().getOpen_txns();\n+  }\n+\n   boolean commitTxn(long txnId) throws TException {\n     client.commit_txn(new CommitTxnRequest(txnId));\n     return true;\n   }\n \n-  boolean abortTxn(long txnId) throws TException {\n-    client.abort_txn(new AbortTxnRequest(txnId));\n+  boolean abortTxns(List<Long> txnIds) throws TException {\n+    client.abort_txns(new AbortTxnsRequest(txnIds));\n     return true;\n   }\n \n-  boolean abortTxns(List<Long> txnIds) throws TException {\n-    client.abort_txns(new AbortTxnsRequest(txnIds));\n+  boolean allocateTableWriteIds(String dbName, String tableName, List<Long> openTxns) throws TException {\n+    AllocateTableWriteIdsRequest awiRqst = new AllocateTableWriteIdsRequest(dbName, tableName);\n+    openTxns.forEach(t -> {\n+      awiRqst.addToTxnIds(t);\n+    });\n+\n+    client.allocate_table_write_ids(awiRqst);\n     return true;\n   }\n \n+  boolean getValidWriteIds(List<String> fullTableNames) throws TException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd44b6227ea2c56386ab09970a3dfeb2016767d0"}, "originalPosition": 83}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4621b3a481292602c00c1b7c97ad9765b62ef28", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/a4621b3a481292602c00c1b7c97ad9765b62ef28", "committedDate": "2020-07-16T13:19:39Z", "message": "HIVE-22869 Add locking benchmark to metastore-tools/metastore-benchmarks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "897703da07f7fe73a9a08e2993442952ec347b2b", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/897703da07f7fe73a9a08e2993442952ec347b2b", "committedDate": "2020-07-16T13:19:39Z", "message": "HMS benchmarking modifications\n\nChange-Id: I641f7b094aff46b92cfa3d38e3049b221fa5abe6"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0648a760b7f75658c9a29d0d7b9c9fc021463691", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/0648a760b7f75658c9a29d0d7b9c9fc021463691", "committedDate": "2020-07-16T13:19:39Z", "message": "CDPD-11690\n\nChange-Id: Iea9f99870cfffc915b0574570cfb4b08827d5e3a"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "765a65ccb3a87118ecc6c311799563359fab1636", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/765a65ccb3a87118ecc6c311799563359fab1636", "committedDate": "2020-07-16T13:37:44Z", "message": "CDPD-11690\n\nChange-Id: Iea9f99870cfffc915b0574570cfb4b08827d5e3a"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67f3f493ed191782150fca7c0f857d8a2dd504e0", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/67f3f493ed191782150fca7c0f857d8a2dd504e0", "committedDate": "2020-07-16T13:38:41Z", "message": "Merge branch 'HIVE-22869' of github.com:zchovan/hive into HIVE-22869\n\nChange-Id: I2a9393a7472730e74da6da3e6071f551a47aa4cd"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13e36fe69e210e76ab5142db47fc35318f0f8281", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/13e36fe69e210e76ab5142db47fc35318f0f8281", "committedDate": "2020-07-16T14:03:30Z", "message": "Merge branch 'HIVE-22869' of github.com:zchovan/hive into HIVE-22869\n\nChange-Id: I2a9393a7472730e74da6da3e6071f551a47aa4cd"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9bfa5ddbf03304164bd39d6e4eec1ee5a8d7d958", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/9bfa5ddbf03304164bd39d6e4eec1ee5a8d7d958", "committedDate": "2020-07-16T14:28:21Z", "message": "Merge branch 'HIVE-22869' of github.com:zchovan/hive into HIVE-22869\n\nChange-Id: I82ed3a001e453a701bc6f20448958adf10cd943d"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe8387e3c54bcb85b5d1b0447cceafa341e64912", "author": {"user": null}, "url": "https://github.com/apache/hive/commit/fe8387e3c54bcb85b5d1b0447cceafa341e64912", "committedDate": "2020-07-17T13:17:17Z", "message": "review modifications\n\nChange-Id: I2e890124a0e09df4b917b4899e1acb2b42ebbfdf"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwNzIwNzQ0", "url": "https://github.com/apache/hive/pull/1073#pullrequestreview-450720744", "createdAt": "2020-07-17T14:47:20Z", "commit": {"oid": "fe8387e3c54bcb85b5d1b0447cceafa341e64912"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3823, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}