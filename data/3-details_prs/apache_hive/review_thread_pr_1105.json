{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzOTc2NTU1", "number": 1105, "reviewThreads": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjoxMzozMVrOEMdZQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzoyNDoxNVrOEM5Kiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNDk5OTY5OnYy", "diffSide": "RIGHT", "path": "itests/src/test/resources/testconfiguration.properties", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjoxMzozMVrOGulHgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1MzoyNFrOGvL_kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ5NTgxMQ==", "bodyText": "is there a reason that we run this test with mr?", "url": "https://github.com/apache/hive/pull/1105#discussion_r451495811", "createdAt": "2020-07-08T12:13:31Z", "author": {"login": "kgyrtkirk"}, "path": "itests/src/test/resources/testconfiguration.properties", "diffHunk": "@@ -222,6 +222,7 @@ mr.query.files=\\\n   mapjoin_subquery2.q,\\\n   mapjoin_test_outer.q,\\\n   masking_5.q,\\\n+  msck_repair_filter.q,\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMjc1Mg==", "bodyText": "Not a requirement though. This was done before we moved our qtests to run on LLAP by default. It makes sense to move this to LLAP as well.\nFixed.", "url": "https://github.com/apache/hive/pull/1105#discussion_r452132752", "createdAt": "2020-07-09T10:53:24Z", "author": {"login": "shameersss1"}, "path": "itests/src/test/resources/testconfiguration.properties", "diffHunk": "@@ -222,6 +222,7 @@ mr.query.files=\\\n   mapjoin_subquery2.q,\\\n   mapjoin_test_outer.q,\\\n   masking_5.q,\\\n+  msck_repair_filter.q,\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ5NTgxMQ=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTAxMjI1OnYy", "diffSide": "RIGHT", "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjoxNTo0MlrOGulPQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1MzozOFrOGvL__Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ5Nzc5Mw==", "bodyText": "I know it was here before - but let's fix this up:\ninstead of separate add/drop/sync variable ...we could have opt=(KW_ADD|KW_DROP|KW_SYNC) ? that will make the other end more readable as well", "url": "https://github.com/apache/hive/pull/1105#discussion_r451497793", "createdAt": "2020-07-08T12:15:42Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "diffHunk": "@@ -1942,9 +1942,8 @@ metastoreCheck\n @after { popMsg(state); }\n     : KW_MSCK (repair=KW_REPAIR)?\n       (KW_TABLE tableName\n-        ((add=KW_ADD | drop=KW_DROP | sync=KW_SYNC) (parts=KW_PARTITIONS))? |\n-        (partitionSpec)?)\n-    -> ^(TOK_MSCK $repair? tableName? $add? $drop? $sync? (partitionSpec*)?)\n+        ((add=KW_ADD | drop=KW_DROP | sync=KW_SYNC) (parts=KW_PARTITIONS) (filterPartitionSpec)?)?)\n+    -> ^(TOK_MSCK $repair? tableName? $add? $drop? $sync? (filterPartitionSpec)?)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMjg2MQ==", "bodyText": "Yes It makes sense!. Fixed.", "url": "https://github.com/apache/hive/pull/1105#discussion_r452132861", "createdAt": "2020-07-09T10:53:38Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "diffHunk": "@@ -1942,9 +1942,8 @@ metastoreCheck\n @after { popMsg(state); }\n     : KW_MSCK (repair=KW_REPAIR)?\n       (KW_TABLE tableName\n-        ((add=KW_ADD | drop=KW_DROP | sync=KW_SYNC) (parts=KW_PARTITIONS))? |\n-        (partitionSpec)?)\n-    -> ^(TOK_MSCK $repair? tableName? $add? $drop? $sync? (partitionSpec*)?)\n+        ((add=KW_ADD | drop=KW_DROP | sync=KW_SYNC) (parts=KW_PARTITIONS) (filterPartitionSpec)?)?)\n+    -> ^(TOK_MSCK $repair? tableName? $add? $drop? $sync? (filterPartitionSpec)?)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ5Nzc5Mw=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA0MDM0OnYy", "diffSide": "RIGHT", "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjoyMTozM1rOGulgeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NDozNFrOGvMBuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMjIwMQ==", "bodyText": "old partitionSpec doesn't mandatorily required the constant\nidentifier (EQUAL constant)? \n\nwere there any use cases of that?", "url": "https://github.com/apache/hive/pull/1105#discussion_r451502201", "createdAt": "2020-07-08T12:21:33Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzMwNw==", "bodyText": "Based on the implementation, I don't think there was never such a use case. I guess we always except it to be contatant\nRefer:\nhttps://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java#L66\n\n  \n    \n      hive/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n    \n    \n         Line 1527\n      in\n      6f9c7bc\n    \n    \n    \n    \n\n        \n          \n           val = stripQuotes(child.getChild(1).getText()); \n        \n    \n  \n\n\n\n  \n    \n      hive/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n    \n    \n         Line 259\n      in\n      6f9c7bc\n    \n    \n    \n    \n\n        \n          \n           for (Map<String, String> map : partitions) {", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133307", "createdAt": "2020-07-09T10:54:34Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMjIwMQ=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA0OTE3OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjoyNDowNFrOGulmDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzowNjozNFrOGvQQPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA==", "bodyText": "I don't think this will work - this is the ql module ; while EXPRESSION_PROXY_CLASS is a metastore conf key; in a remote metastore setup this set will probably have no effect...\nhave you tried it?\nI think making a check and returning with an error that this feature is not available due to required conf change is fine", "url": "https://github.com/apache/hive/pull/1105#discussion_r451503630", "createdAt": "2020-07-08T12:24:04Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMjk2Mw==", "bodyText": "Yes, It won't work with remote metastore. Currently only planning for embedded metastore, Sure, we should bail out if conditions are not met. Currently i have added the bail out code in HiveMetaStoreChecker. But i feel bail out should have been much more earlier. I Couldn't think of a better spot. Any thoughts on this?", "url": "https://github.com/apache/hive/pull/1105#discussion_r452132963", "createdAt": "2020-07-09T10:53:52Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNzM0OA==", "bodyText": "I think it would be great to throw an exception here; I think you should throw the type SemanticException\nThrowing exceptions from in the Analyzer classes works nicely! :)", "url": "https://github.com/apache/hive/pull/1105#discussion_r452137348", "createdAt": "2020-07-09T11:02:57Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIwMjU1Nw==", "bodyText": "Done!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452202557", "createdAt": "2020-07-09T13:06:34Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA3NjI4OnYy", "diffSide": "RIGHT", "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjozMTozNlrOGul2rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzowNjozOFrOGvQQYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNzg4Ng==", "bodyText": "dropPartitionSpec seems to use almost the same construct ; I don't see any reason to duplicate it ...\nthe only difference I see right now is LIKE - are there any other differences?\nI think instead of duplicate we should use the same stuff...", "url": "https://github.com/apache/hive/pull/1105#discussion_r451507886", "createdAt": "2020-07-08T12:31:36Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)\n+    ;\n+\n+filterPartitionOperator\n+    :\n+    EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN | KW_LIKE", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzUxMA==", "bodyText": "There is one slight difference apart from the LIKE operator, dropPartitionSpec expects PARTITON keyword, But since in MSCK we already have a PARTITONS keyword in the syntax it will cause a problem.", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133510", "createdAt": "2020-07-09T10:54:59Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)\n+    ;\n+\n+filterPartitionOperator\n+    :\n+    EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN | KW_LIKE", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNzg4Ng=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjE0MDAzNQ==", "bodyText": "I may just blur the distinction between PARTITION/PARTITIONS :)", "url": "https://github.com/apache/hive/pull/1105#discussion_r452140035", "createdAt": "2020-07-09T11:08:25Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)\n+    ;\n+\n+filterPartitionOperator\n+    :\n+    EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN | KW_LIKE", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNzg4Ng=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIwMjU5Mg==", "bodyText": "Done!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452202592", "createdAt": "2020-07-09T13:06:38Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -734,6 +734,21 @@ dropPartitionOperator\n     EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN\n     ;\n \n+filterPartitionSpec\n+    :\n+    LPAREN filterPartitionVal (COMMA  filterPartitionVal )* RPAREN -> ^(TOK_PARTSPEC filterPartitionVal +)\n+    ;\n+\n+filterPartitionVal\n+    :\n+    identifier filterPartitionOperator constant -> ^(TOK_PARTVAL identifier filterPartitionOperator constant)\n+    ;\n+\n+filterPartitionOperator\n+    :\n+    EQUAL | NOTEQUAL | LESSTHANOREQUALTO | LESSTHAN | GREATERTHANOREQUALTO | GREATERTHAN | KW_LIKE", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNzg4Ng=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA4MDQ5OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjozMjo0NVrOGul5MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NToxMVrOGvMC-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwODUyOA==", "bodyText": "why this needs to be flattened into a byte[] ?", "url": "https://github.com/apache/hive/pull/1105#discussion_r451508528", "createdAt": "2020-07-08T12:32:45Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n+          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // fetch the first value of partitionSpecs map since it will always have one key, value pair\n+      filterExp = SerializationUtilities.serializeExpressionToKryo(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzYyNw==", "bodyText": "PartitionPruner and msc.listPartitionsByExpr() expects serialized byte array, Hence it is required to flatten out.", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133627", "createdAt": "2020-07-09T10:55:11Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n+          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // fetch the first value of partitionSpecs map since it will always have one key, value pair\n+      filterExp = SerializationUtilities.serializeExpressionToKryo(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwODUyOA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA5NjI0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjozNzowM1rOGumC7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NToxOFrOGvMDMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTAyMw==", "bodyText": "can we find a new home for these 2 static methods? :)\nql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java", "url": "https://github.com/apache/hive/pull/1105#discussion_r451511023", "createdAt": "2020-07-08T12:37:03Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java", "diffHunk": "@@ -837,6 +844,118 @@ public static void checkColumnName(String columnName) throws SemanticException {\n     return colList;\n   }\n \n+  /**\n+   * Get the partition specs from the tree. This stores the full specification\n+   * with the comparator operator into the output list.\n+   *\n+   * @return Map of partitions by prefix length. Most of the time prefix length will\n+   *         be the same for all partition specs, so we can just OR the expressions.\n+   */\n+  public static Map<Integer, List<ExprNodeGenericFuncDesc>> getFullPartitionSpecs(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzY4Mg==", "bodyText": "Fixed!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133682", "createdAt": "2020-07-09T10:55:18Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java", "diffHunk": "@@ -837,6 +844,118 @@ public static void checkColumnName(String columnName) throws SemanticException {\n     return colList;\n   }\n \n+  /**\n+   * Get the partition specs from the tree. This stores the full specification\n+   * with the comparator operator into the output list.\n+   *\n+   * @return Map of partitions by prefix length. Most of the time prefix length will\n+   *         be the same for all partition specs, so we can just OR the expressions.\n+   */\n+  public static Map<Integer, List<ExprNodeGenericFuncDesc>> getFullPartitionSpecs(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTAyMw=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTA5ODcxOnYy", "diffSide": "LEFT", "path": "ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveMetaStoreChecker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjozNzo1MlrOGumEmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NTo0NlrOGvMEJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTQ1MA==", "bodyText": "is there a successor of this test?", "url": "https://github.com/apache/hive/pull/1105#discussion_r451511450", "createdAt": "2020-07-08T12:37:52Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveMetaStoreChecker.java", "diffHunk": "@@ -330,17 +330,6 @@ public void testPartitionsCheck() throws HiveException,\n     assertEquals(partToRemove.getTable().getTableName(),\n         result.getPartitionsNotOnFs().iterator().next().getTableName());\n     assertEquals(Collections.<CheckResult.PartitionResult>emptySet(), result.getPartitionsNotInMs());\n-\n-    List<Map<String, String>> partsCopy = new ArrayList<Map<String, String>>();\n-    partsCopy.add(partitions.get(1).getSpec());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzkyNg==", "bodyText": "I think the qtests handles most of cases", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133926", "createdAt": "2020-07-09T10:55:46Z", "author": {"login": "shameersss1"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveMetaStoreChecker.java", "diffHunk": "@@ -330,17 +330,6 @@ public void testPartitionsCheck() throws HiveException,\n     assertEquals(partToRemove.getTable().getTableName(),\n         result.getPartitionsNotOnFs().iterator().next().getTableName());\n     assertEquals(Collections.<CheckResult.PartitionResult>emptySet(), result.getPartitionsNotInMs());\n-\n-    List<Map<String, String>> partsCopy = new ArrayList<Map<String, String>>();\n-    partsCopy.add(partitions.get(1).getSpec());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTQ1MA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTExMjU3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjo0MToyOVrOGumNNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMToxMDo1NVrOGvMgag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA==", "bodyText": "I wonder if there is a way to retain filterExp in a more natural way....it will be kryo-encoded almost all the time...but seems like the metastore interface method was designed to accept kryo stuff...", "url": "https://github.com/apache/hive/pull/1105#discussion_r451513654", "createdAt": "2020-07-08T12:41:29Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -240,40 +243,27 @@ void checkTable(String catName, String dbName, String tableName,\n     }\n \n     PartitionIterable parts;\n-    boolean findUnknownPartitions = true;\n \n     if (isPartitioned(table)) {\n-      if (partitions == null || partitions.isEmpty()) {\n+      if (filterExp != null) {\n+        List<Partition> results = new ArrayList<>();\n+        getPartitionListByFilterExp(getMsc(), table, filterExp,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNjIyMg==", "bodyText": "I though this initially but it becomes difficult to serialize filter exp once we move out of ql code, Hence did the kyro stuff in the initial stage", "url": "https://github.com/apache/hive/pull/1105#discussion_r452136222", "createdAt": "2020-07-09T11:00:31Z", "author": {"login": "shameersss1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -240,40 +243,27 @@ void checkTable(String catName, String dbName, String tableName,\n     }\n \n     PartitionIterable parts;\n-    boolean findUnknownPartitions = true;\n \n     if (isPartitioned(table)) {\n-      if (partitions == null || partitions.isEmpty()) {\n+      if (filterExp != null) {\n+        List<Partition> results = new ArrayList<>();\n+        getPartitionListByFilterExp(getMsc(), table, filterExp,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjE0MTE2Mg==", "bodyText": "yeah I understand...sometimes we have to cook from what we have :D", "url": "https://github.com/apache/hive/pull/1105#discussion_r452141162", "createdAt": "2020-07-09T11:10:55Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -240,40 +243,27 @@ void checkTable(String catName, String dbName, String tableName,\n     }\n \n     PartitionIterable parts;\n-    boolean findUnknownPartitions = true;\n \n     if (isPartitioned(table)) {\n-      if (partitions == null || partitions.isEmpty()) {\n+      if (filterExp != null) {\n+        List<Partition> results = new ArrayList<>();\n+        getPartitionListByFilterExp(getMsc(), table, filterExp,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTEzNjc0OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjo0ODowMFrOGumcVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1ODozM1rOGvMJTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNzUyNQ==", "bodyText": "this method accepts byte[] and if I'm not wrong this is like this since around 2013", "url": "https://github.com/apache/hive/pull/1105#discussion_r451517525", "createdAt": "2020-07-08T12:48:00Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java", "diffHunk": "@@ -1348,6 +1348,17 @@ public static Path getPath(Table table) {\n     }\n   }\n \n+  public static void getPartitionListByFilterExp(IMetaStoreClient msc, Table table, byte[] filterExp,\n+                                                 String defaultPartName, List<Partition> results)\n+      throws MetastoreException {\n+    try {\n+      msc.listPartitionsByExpr(table.getCatName(), table.getDbName(), table.getTableName(), filterExp,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNTI0NA==", "bodyText": "Yes, I think we also pass byte array", "url": "https://github.com/apache/hive/pull/1105#discussion_r452135244", "createdAt": "2020-07-09T10:58:33Z", "author": {"login": "shameersss1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java", "diffHunk": "@@ -1348,6 +1348,17 @@ public static Path getPath(Table table) {\n     }\n   }\n \n+  public static void getPartitionListByFilterExp(IMetaStoreClient msc, Table table, byte[] filterExp,\n+                                                 String defaultPartName, List<Partition> results)\n+      throws MetastoreException {\n+    try {\n+      msc.listPartitionsByExpr(table.getCatName(), table.getDbName(), table.getTableName(), filterExp,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNzUyNQ=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTE0NDUwOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjo1MDoxMFrOGumhVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NjowMVrOGvMEmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxODgwNg==", "bodyText": "move this variable inside the if", "url": "https://github.com/apache/hive/pull/1105#discussion_r451518806", "createdAt": "2020-07-08T12:50:10Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDA0Mg==", "bodyText": "Fixed", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134042", "createdAt": "2020-07-09T10:56:01Z", "author": {"login": "shameersss1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxODgwNg=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 183}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTE2NjkzOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjo1NTo0MFrOGumvGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NjowOFrOGvMEyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyMjMzMA==", "bodyText": "instead of concatenating with / use new Path(parentPath,child) - it's more portable", "url": "https://github.com/apache/hive/pull/1105#discussion_r451522330", "createdAt": "2020-07-08T12:55:40Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+      }\n+      // Remove all partition paths which does not matches the filter expression.\n+      expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n+          conf.get(MetastoreConf.ConfVars.DEFAULTPARTITIONNAME.getVarname()), paritions);\n+\n+      // now the partition list will contain all the paths that matches the filter expression.\n+      // add them back to partDirs.\n+      for (String path : paritions) {\n+        partDirs.add(new Path(tablePath.toString() + \"/\" + path));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDA5MA==", "bodyText": "Fixed!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134090", "createdAt": "2020-07-09T10:56:08Z", "author": {"login": "shameersss1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+      }\n+      // Remove all partition paths which does not matches the filter expression.\n+      expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n+          conf.get(MetastoreConf.ConfVars.DEFAULTPARTITIONNAME.getVarname()), paritions);\n+\n+      // now the partition list will contain all the paths that matches the filter expression.\n+      // add them back to partDirs.\n+      for (String path : paritions) {\n+        partDirs.add(new Path(tablePath.toString() + \"/\" + path));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyMjMzMA=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxNTE3ODA5OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxMjo1ODozNlrOGum2Rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMDo1NjozNlrOGvMFtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyNDE2Ng==", "bodyText": "I'm wondering if tablePath could end with a '/' or not; if it does, and checkPartitionDirs are removing double slashes this could eat up 1 extra char...", "url": "https://github.com/apache/hive/pull/1105#discussion_r451524166", "createdAt": "2020-07-08T12:58:36Z", "author": {"login": "kgyrtkirk"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDMyNQ==", "bodyText": "Fixed!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134325", "createdAt": "2020-07-09T10:56:36Z", "author": {"login": "shameersss1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyNDE2Ng=="}, "originalCommit": {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852"}, "originalPosition": 193}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxOTUzNTkwOnYy", "diffSide": "RIGHT", "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzoyMDo1MlrOGvQ0ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNTowNzowMFrOGvVgOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxMTg1MA==", "bodyText": "I think we are fighting with the complexity of the existing complexity :)\nright now this will mean that we may write TABLE t PARTITION PARTITION ...  :D\ndo one of the following:\n\neither push out the KW_PARTITION keyword from dropPartitionSpec to every site it's being used\nor...remove the (parts=KW_PARTITIONS)? from here and change the dropPartitionSpec to accept it optionally by using: (KW_PARTITION | KW_PARTITIONS)?\n\nI think we should also clean up a bit:\n\nrename the dropPartitionSpec to something which doesn't have drop in its name like partitionSelectorSpec", "url": "https://github.com/apache/hive/pull/1105#discussion_r452211850", "createdAt": "2020-07-09T13:20:52Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "diffHunk": "@@ -1942,8 +1942,8 @@ metastoreCheck\n @after { popMsg(state); }\n     : KW_MSCK (repair=KW_REPAIR)?\n       (KW_TABLE tableName\n-        (opt=(KW_ADD|KW_DROP|KW_SYNC) (parts=KW_PARTITIONS) (filterPartitionSpec)?)?)\n-    -> ^(TOK_MSCK $repair? tableName? $opt? (filterPartitionSpec)?)\n+        (opt=(KW_ADD|KW_DROP|KW_SYNC) (parts=KW_PARTITIONS)? (dropPartitionSpec)?)?)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjI4ODU2OQ==", "bodyText": "Option 2 looks good, Option 1 will change the current syntax.\nFixed.", "url": "https://github.com/apache/hive/pull/1105#discussion_r452288569", "createdAt": "2020-07-09T15:07:00Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g", "diffHunk": "@@ -1942,8 +1942,8 @@ metastoreCheck\n @after { popMsg(state); }\n     : KW_MSCK (repair=KW_REPAIR)?\n       (KW_TABLE tableName\n-        (opt=(KW_ADD|KW_DROP|KW_SYNC) (parts=KW_PARTITIONS) (filterPartitionSpec)?)?)\n-    -> ^(TOK_MSCK $repair? tableName? $opt? (filterPartitionSpec)?)\n+        (opt=(KW_ADD|KW_DROP|KW_SYNC) (parts=KW_PARTITIONS)? (dropPartitionSpec)?)?)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxMTg1MA=="}, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxOTU0MDY3OnYy", "diffSide": "RIGHT", "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzoyMTo1OVrOGvQ3pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNTowNzowMlrOGvVgWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxMjY0NQ==", "bodyText": "I think this should be (KW_PARTITION|KW_PARTITIONS)  ; because in it's current form it will\n\naccept PARTITION\nand PARTITIONS  (...)\nbut not  PARTITION (...)", "url": "https://github.com/apache/hive/pull/1105#discussion_r452212645", "createdAt": "2020-07-09T13:21:59Z", "author": {"login": "kgyrtkirk"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -720,7 +720,7 @@ partitionVal\n \n dropPartitionSpec\n     :\n-    KW_PARTITION\n+    KW_PARTITION | KW_PARTITIONS", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjI4ODYwMQ==", "bodyText": "As discussed above!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452288601", "createdAt": "2020-07-09T15:07:02Z", "author": {"login": "shameersss1"}, "path": "parser/src/java/org/apache/hadoop/hive/ql/parse/IdentifiersParser.g", "diffHunk": "@@ -720,7 +720,7 @@ partitionVal\n \n dropPartitionSpec\n     :\n-    KW_PARTITION\n+    KW_PARTITION | KW_PARTITIONS", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxMjY0NQ=="}, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxOTU0OTU1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxMzoyNDoxNVrOGvQ9aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQxNTowNzowNVrOGvVgeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxNDEyMA==", "bodyText": "you could avoid the null/empty check by using: !PartitionExpressionForMetastore.class.getCanonicalName()).equals(expressionProxyClass)", "url": "https://github.com/apache/hive/pull/1105#discussion_r452214120", "createdAt": "2020-07-09T13:24:15Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -71,10 +71,15 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = ParseUtils.getFullPartitionSpecs(root, table, conf, false);\n     byte[] filterExp = null;\n     if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n-      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // expression proxy class needs to be PartitionExpressionForMetastore since we intend to use the\n       // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n-      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n-          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // Bail out early if expressionProxyClass is not configured properly.\n+      String expressionProxyClass = conf.get(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname());\n+      if (expressionProxyClass == null || expressionProxyClass.isEmpty() ||\n+          !expressionProxyClass.equals(PartitionExpressionForMetastore.class.getCanonicalName())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjI4ODYzMw==", "bodyText": "Fixed!", "url": "https://github.com/apache/hive/pull/1105#discussion_r452288633", "createdAt": "2020-07-09T15:07:05Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -71,10 +71,15 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = ParseUtils.getFullPartitionSpecs(root, table, conf, false);\n     byte[] filterExp = null;\n     if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n-      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // expression proxy class needs to be PartitionExpressionForMetastore since we intend to use the\n       // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n-      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n-          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // Bail out early if expressionProxyClass is not configured properly.\n+      String expressionProxyClass = conf.get(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname());\n+      if (expressionProxyClass == null || expressionProxyClass.isEmpty() ||\n+          !expressionProxyClass.equals(PartitionExpressionForMetastore.class.getCanonicalName())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxNDEyMA=="}, "originalCommit": {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 772, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}