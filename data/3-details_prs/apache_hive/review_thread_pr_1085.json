{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMTIzNDgz", "number": 1085, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDoxNjo0NVrOEFAdlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1NDowOFrOEIQfpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjg1OTA4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDoxNjo0NVrOGi-xVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMTowODoxNlrOGnV2gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzMzIwNg==", "bodyText": "Why do we need this?", "url": "https://github.com/apache/hive/pull/1085#discussion_r439333206", "createdAt": "2020-06-12T10:16:45Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -282,6 +282,7 @@ private CompactionType checkForCompaction(final CompactionInfo ci,\n     }\n \n     if (runJobAsSelf(runAs)) {\n+      ci.runAs = runAs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNTY2Ng==", "bodyText": "without setting explicitly here, insert query find it null and skip the here", "url": "https://github.com/apache/hive/pull/1085#discussion_r443905666", "createdAt": "2020-06-23T01:08:16Z", "author": {"login": "rajkrrsingh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -282,6 +282,7 @@ private CompactionType checkForCompaction(final CompactionInfo ci,\n     }\n \n     if (runJobAsSelf(runAs)) {\n+      ci.runAs = runAs;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzMzIwNg=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjg3ODcwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDoyNDoxOVrOGi-94A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMTowODo1MlrOGnV3BQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzNjQxNg==", "bodyText": "Maybe use findAny() instead of count()?", "url": "https://github.com/apache/hive/pull/1085#discussion_r439336416", "createdAt": "2020-06-12T10:24:19Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -353,6 +354,16 @@ private CompactionType determineCompactionType(CompactionInfo ci, ValidWriteIdLi\n           HiveConf.getFloatVar(conf, HiveConf.ConfVars.HIVE_COMPACTOR_DELTA_PCT_THRESHOLD) :\n           Float.parseFloat(deltaPctProp);\n       boolean bigEnough =   (float)deltaSize/(float)baseSize > deltaPctThreshold;\n+      boolean multiBase = dir.getObsolete().stream()\n+              .filter(path -> path.getName().startsWith(AcidUtils.BASE_PREFIX)).count() >= 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNTc5Nw==", "bodyText": "incorporated the suggested change.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443905797", "createdAt": "2020-06-23T01:08:52Z", "author": {"login": "rajkrrsingh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -353,6 +354,16 @@ private CompactionType determineCompactionType(CompactionInfo ci, ValidWriteIdLi\n           HiveConf.getFloatVar(conf, HiveConf.ConfVars.HIVE_COMPACTOR_DELTA_PCT_THRESHOLD) :\n           Float.parseFloat(deltaPctProp);\n       boolean bigEnough =   (float)deltaSize/(float)baseSize > deltaPctThreshold;\n+      boolean multiBase = dir.getObsolete().stream()\n+              .filter(path -> path.getName().startsWith(AcidUtils.BASE_PREFIX)).count() >= 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzNjQxNg=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjg4MzQ3OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDoyNTo1N1rOGi_Ayg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMTowOTowM1rOGnV3NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzNzE2Mg==", "bodyText": "Unnecessary parenthesis and also I think dir.getObsolete().size() check is not needed, since multiBase is true", "url": "https://github.com/apache/hive/pull/1085#discussion_r439337162", "createdAt": "2020-06-12T10:25:57Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -353,6 +354,16 @@ private CompactionType determineCompactionType(CompactionInfo ci, ValidWriteIdLi\n           HiveConf.getFloatVar(conf, HiveConf.ConfVars.HIVE_COMPACTOR_DELTA_PCT_THRESHOLD) :\n           Float.parseFloat(deltaPctProp);\n       boolean bigEnough =   (float)deltaSize/(float)baseSize > deltaPctThreshold;\n+      boolean multiBase = dir.getObsolete().stream()\n+              .filter(path -> path.getName().startsWith(AcidUtils.BASE_PREFIX)).count() >= 1;\n+      if ((deltaSize == 0  && dir.getObsolete().size() > 0) && multiBase) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNTg0NQ==", "bodyText": "incorporated the suggested change.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443905845", "createdAt": "2020-06-23T01:09:03Z", "author": {"login": "rajkrrsingh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -353,6 +354,16 @@ private CompactionType determineCompactionType(CompactionInfo ci, ValidWriteIdLi\n           HiveConf.getFloatVar(conf, HiveConf.ConfVars.HIVE_COMPACTOR_DELTA_PCT_THRESHOLD) :\n           Float.parseFloat(deltaPctProp);\n       boolean bigEnough =   (float)deltaSize/(float)baseSize > deltaPctThreshold;\n+      boolean multiBase = dir.getObsolete().stream()\n+              .filter(path -> path.getName().startsWith(AcidUtils.BASE_PREFIX)).count() >= 1;\n+      if ((deltaSize == 0  && dir.getObsolete().size() > 0) && multiBase) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzNzE2Mg=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkwMDAwOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozMjo1NVrOGi_L0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMTowOToyN1rOGnV3ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzOTk4NQ==", "bodyText": "Meybe we should move this select out to a different method, since this is the copy of the one used in compact().\nAlso I would add state cleaning as well. We do not want 2 cleaners running parallel", "url": "https://github.com/apache/hive/pull/1085#discussion_r439339985", "createdAt": "2020-06-12T10:32:55Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTczMQ==", "bodyText": "Can we use preparedstatement here as well?", "url": "https://github.com/apache/hive/pull/1085#discussion_r439341731", "createdAt": "2020-06-12T10:36:58Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzOTk4NQ=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAzNDEzNw==", "bodyText": "Further clarified thoughts:\n\nIt would be good to have a single method inserting to the COMPACTION_QUEUE table\nWe should use a preparedstatement for this so JDBC execution could be faster\nTxnHandler.compact() should check for only INITIATED/WORKING status - it might still worth tho start a new compaction, even if the cleanup not finished yet\nTxnHandler.requestCleanup() should check for INITIATED/WORKING/READY_TO_CLEAN status (the first 2 should not be there anyway), so we do not queue multiple compactions for the same table/partition\n\nThanks,\nPeter", "url": "https://github.com/apache/hive/pull/1085#discussion_r442034137", "createdAt": "2020-06-18T07:49:44Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzOTk4NQ=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNTk1MA==", "bodyText": "incorporated the suggested change.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443905950", "createdAt": "2020-06-23T01:09:27Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMzOTk4NQ=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkwMzExOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozNDoxMFrOGi_N6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMTowOTo1OVrOGnV4Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MDUyMA==", "bodyText": "I think, we really want to ignore this, so we would like to return here.", "url": "https://github.com/apache/hive/pull/1085#discussion_r439340520", "createdAt": "2020-06-12T10:34:10Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNjA3MQ==", "bodyText": "moved this logline to debug and return from here.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443906071", "createdAt": "2020-06-23T01:09:59Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MDUyMA=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkwMzkyOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozNDozMlrOGi_OhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMToxMDoxM1rOGnV4UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MDY3Ng==", "bodyText": "Could we do this in a try with resource construct?", "url": "https://github.com/apache/hive/pull/1085#discussion_r439340676", "createdAt": "2020-06-12T10:34:32Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNjEyOA==", "bodyText": "incorporated the suggested change.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443906128", "createdAt": "2020-06-23T01:10:13Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MDY3Ng=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkwNjAxOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozNToyMVrOGi_P3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMToxMDoxNlrOGnV4Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTAyMg==", "bodyText": "Again this is very similar that we have in compact(), we might to create a new method for it and reuse.", "url": "https://github.com/apache/hive/pull/1085#discussion_r439341022", "createdAt": "2020-06-12T10:35:21Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTUxOA==", "bodyText": "Also using a prepared statement would be nice, I think", "url": "https://github.com/apache/hive/pull/1085#discussion_r439341518", "createdAt": "2020-06-12T10:36:32Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTAyMg=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNjEzNQ==", "bodyText": "incorporated the suggested change.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443906135", "createdAt": "2020-06-23T01:10:16Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTAyMg=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkxMTYzOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozNzozMVrOGi_Tfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMToxMTozOVrOGnV5sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTk1MQ==", "bodyText": "try with resource would be nice here too", "url": "https://github.com/apache/hive/pull/1085#discussion_r439341951", "createdAt": "2020-06-12T10:37:31Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;\n+        if (partName != null) {\n+          buf.append(\"cq_partition, \");\n+        }\n+        buf.append(\"cq_state, cq_type\");\n+        if (ci.properties != null) {\n+          buf.append(\", cq_tblproperties\");\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", cq_run_as\");\n+        }\n+        buf.append(\") values (\");\n+        buf.append(id);\n+        buf.append(\", ?\");\n+        buf.append(\", ?\");\n+        buf.append(\", \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if (partName != null) {\n+          buf.append(\"?, '\");\n+          params.add(partName);\n+        } else {\n+          buf.append(\"'\");\n+        }\n+        buf.append(READY_FOR_CLEANING);\n+        buf.append(\"', '\");\n+        buf.append(MAJOR_TYPE);\n+        buf.append(\"'\");\n+        if (ci.properties != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.properties);\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.runAs);\n+        }\n+        buf.append(\")\");\n+        String s = buf.toString();\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, s, params);\n+        LOG.debug(\"Going to execute update <\" + s + \">\");\n+        pst.executeUpdate();\n+        LOG.debug(\"Going to commit\");\n+        dbConn.commit();\n+      } catch (SQLException e) {\n+        LOG.debug(\"Going to rollback\");\n+        rollbackDBConn(dbConn);\n+        checkRetryable(dbConn, e, \"requestCleanup(\" + ci + \")\");\n+        throw new MetaException(\"Unable to select from transaction database \" +\n+                StringUtils.stringifyException(e));\n+      } finally {\n+        closeStmt(pst);\n+        closeStmt(stmt);\n+        closeDbConn(dbConn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNjQ4MQ==", "bodyText": "incorporated the suggested change for stmt and pst. try-resource with dbConn make code clumsy with so many nested try-catch so I skipped it.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443906481", "createdAt": "2020-06-23T01:11:39Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;\n+        if (partName != null) {\n+          buf.append(\"cq_partition, \");\n+        }\n+        buf.append(\"cq_state, cq_type\");\n+        if (ci.properties != null) {\n+          buf.append(\", cq_tblproperties\");\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", cq_run_as\");\n+        }\n+        buf.append(\") values (\");\n+        buf.append(id);\n+        buf.append(\", ?\");\n+        buf.append(\", ?\");\n+        buf.append(\", \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if (partName != null) {\n+          buf.append(\"?, '\");\n+          params.add(partName);\n+        } else {\n+          buf.append(\"'\");\n+        }\n+        buf.append(READY_FOR_CLEANING);\n+        buf.append(\"', '\");\n+        buf.append(MAJOR_TYPE);\n+        buf.append(\"'\");\n+        if (ci.properties != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.properties);\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.runAs);\n+        }\n+        buf.append(\")\");\n+        String s = buf.toString();\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, s, params);\n+        LOG.debug(\"Going to execute update <\" + s + \">\");\n+        pst.executeUpdate();\n+        LOG.debug(\"Going to commit\");\n+        dbConn.commit();\n+      } catch (SQLException e) {\n+        LOG.debug(\"Going to rollback\");\n+        rollbackDBConn(dbConn);\n+        checkRetryable(dbConn, e, \"requestCleanup(\" + ci + \")\");\n+        throw new MetaException(\"Unable to select from transaction database \" +\n+                StringUtils.stringifyException(e));\n+      } finally {\n+        closeStmt(pst);\n+        closeStmt(stmt);\n+        closeDbConn(dbConn);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MTk1MQ=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNjkxMzg0OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxMDozODoyNFrOGi_U9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QwMToxMzozMFrOGnV7Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MjMyNw==", "bodyText": "If there is some exception before in the finally, this unlockInternal will not be called. Isn't this a problem?", "url": "https://github.com/apache/hive/pull/1085#discussion_r439342327", "createdAt": "2020-06-12T10:38:24Z", "author": {"login": "pvary"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;\n+        if (partName != null) {\n+          buf.append(\"cq_partition, \");\n+        }\n+        buf.append(\"cq_state, cq_type\");\n+        if (ci.properties != null) {\n+          buf.append(\", cq_tblproperties\");\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", cq_run_as\");\n+        }\n+        buf.append(\") values (\");\n+        buf.append(id);\n+        buf.append(\", ?\");\n+        buf.append(\", ?\");\n+        buf.append(\", \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if (partName != null) {\n+          buf.append(\"?, '\");\n+          params.add(partName);\n+        } else {\n+          buf.append(\"'\");\n+        }\n+        buf.append(READY_FOR_CLEANING);\n+        buf.append(\"', '\");\n+        buf.append(MAJOR_TYPE);\n+        buf.append(\"'\");\n+        if (ci.properties != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.properties);\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.runAs);\n+        }\n+        buf.append(\")\");\n+        String s = buf.toString();\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, s, params);\n+        LOG.debug(\"Going to execute update <\" + s + \">\");\n+        pst.executeUpdate();\n+        LOG.debug(\"Going to commit\");\n+        dbConn.commit();\n+      } catch (SQLException e) {\n+        LOG.debug(\"Going to rollback\");\n+        rollbackDBConn(dbConn);\n+        checkRetryable(dbConn, e, \"requestCleanup(\" + ci + \")\");\n+        throw new MetaException(\"Unable to select from transaction database \" +\n+                StringUtils.stringifyException(e));\n+      } finally {\n+        closeStmt(pst);\n+        closeStmt(stmt);\n+        closeDbConn(dbConn);\n+        if(handle != null) {\n+          handle.releaseLocks();\n+        }\n+        unlockInternal();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkwNjkwNg==", "bodyText": "unlockInternal is mostly applicable for derby so I think it should not create the problem.", "url": "https://github.com/apache/hive/pull/1085#discussion_r443906906", "createdAt": "2020-06-23T01:13:30Z", "author": {"login": "rajkrrsingh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -5363,6 +5363,121 @@ private void acquireTxnLock(Statement stmt, boolean shared) throws SQLException,\n     LOG.debug(\"TXN lock locked by {} in mode {}\", quoteString(TxnHandler.hostname), shared);\n   }\n \n+\n+  @Override\n+  @RetrySemantics.Idempotent\n+  public void requestCleanup(CompactionInfo ci) throws MetaException {\n+    try {\n+      Connection dbConn = null;\n+      Statement stmt = null;\n+      PreparedStatement pst = null;\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      try {\n+        lockInternal();\n+        /**\n+         * MUTEX_KEY.CompactionScheduler lock ensures that there is only 1 entry in\n+         * Initiated/Working state for any resource.  This ensures that we don't run concurrent\n+         * compactions for any resource.\n+         */\n+        handle = getMutexAPI().acquireLock(MUTEX_KEY.CompactionScheduler.name());\n+        dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+        stmt = dbConn.createStatement();\n+\n+        long id = generateCompactionQueueId(stmt);\n+\n+        List<String> params = new ArrayList<>();\n+        StringBuilder sb = new StringBuilder(\"select cq_id, cq_state from COMPACTION_QUEUE where\").\n+                append(\" cq_state IN(\").append(quoteChar(INITIATED_STATE)).\n+                append(\",\").append(quoteChar(WORKING_STATE)).\n+                append(\") AND cq_database=?\").\n+                append(\" AND cq_table=?\").append(\" AND \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if(ci.partName == null) {\n+          sb.append(\"cq_partition is null\");\n+        } else {\n+          sb.append(\"cq_partition=?\");\n+          params.add(ci.partName);\n+        }\n+\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, sb.toString(), params);\n+        LOG.debug(\"Going to execute query <\" + sb.toString() + \">\");\n+        ResultSet rs = pst.executeQuery();\n+        if(rs.next()) {\n+          long enqueuedId = rs.getLong(1);\n+          String state = compactorStateToResponse(rs.getString(2).charAt(0));\n+          LOG.info(\"Ignoring request to clean up for \" + ci.dbname + \"/\" + ci.tableName +\n+                  \"/\" + ci.partName + \" since it is already \" + quoteString(state) +\n+                  \" with id=\" + enqueuedId);\n+        }\n+        close(rs);\n+        closeStmt(pst);\n+        params.clear();\n+        StringBuilder buf = new StringBuilder(\"insert into COMPACTION_QUEUE (cq_id, cq_database, \" +\n+                \"cq_table, \");\n+        String partName = ci.partName;\n+        if (partName != null) {\n+          buf.append(\"cq_partition, \");\n+        }\n+        buf.append(\"cq_state, cq_type\");\n+        if (ci.properties != null) {\n+          buf.append(\", cq_tblproperties\");\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", cq_run_as\");\n+        }\n+        buf.append(\") values (\");\n+        buf.append(id);\n+        buf.append(\", ?\");\n+        buf.append(\", ?\");\n+        buf.append(\", \");\n+        params.add(ci.dbname);\n+        params.add(ci.tableName);\n+        if (partName != null) {\n+          buf.append(\"?, '\");\n+          params.add(partName);\n+        } else {\n+          buf.append(\"'\");\n+        }\n+        buf.append(READY_FOR_CLEANING);\n+        buf.append(\"', '\");\n+        buf.append(MAJOR_TYPE);\n+        buf.append(\"'\");\n+        if (ci.properties != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.properties);\n+        }\n+        if (ci.runAs != null) {\n+          buf.append(\", ?\");\n+          params.add(ci.runAs);\n+        }\n+        buf.append(\")\");\n+        String s = buf.toString();\n+        pst = sqlGenerator.prepareStmtWithParameters(dbConn, s, params);\n+        LOG.debug(\"Going to execute update <\" + s + \">\");\n+        pst.executeUpdate();\n+        LOG.debug(\"Going to commit\");\n+        dbConn.commit();\n+      } catch (SQLException e) {\n+        LOG.debug(\"Going to rollback\");\n+        rollbackDBConn(dbConn);\n+        checkRetryable(dbConn, e, \"requestCleanup(\" + ci + \")\");\n+        throw new MetaException(\"Unable to select from transaction database \" +\n+                StringUtils.stringifyException(e));\n+      } finally {\n+        closeStmt(pst);\n+        closeStmt(stmt);\n+        closeDbConn(dbConn);\n+        if(handle != null) {\n+          handle.releaseLocks();\n+        }\n+        unlockInternal();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM0MjMyNw=="}, "originalCommit": {"oid": "91ad99ab38ec5149350a997c0b0b3beb66b1f922"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDkzNDIzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1MToxNVrOGoG6Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1MToxNVrOGoG6Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcwOTM5MA==", "bodyText": "Nit: I think this is misleading, and unnecessary since we have already logged the values of deltaSize and multiBase.", "url": "https://github.com/apache/hive/pull/1085#discussion_r444709390", "createdAt": "2020-06-24T07:51:15Z", "author": {"login": "klcopp"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -361,18 +361,25 @@ private CompactionType determineCompactionType(CompactionInfo ci, ValidWriteIdLi\n           HiveConf.getFloatVar(conf, HiveConf.ConfVars.HIVE_COMPACTOR_DELTA_PCT_THRESHOLD) :\n           Float.parseFloat(deltaPctProp);\n       boolean bigEnough =   (float)deltaSize/(float)baseSize > deltaPctThreshold;\n+      boolean multiBase = dir.getObsolete().stream()\n+              .filter(path -> path.getName().startsWith(AcidUtils.BASE_PREFIX)).findAny().isPresent();\n+\n       if (LOG.isDebugEnabled()) {\n         StringBuilder msg = new StringBuilder(\"delta size: \");\n         msg.append(deltaSize);\n         msg.append(\" base size: \");\n         msg.append(baseSize);\n+        msg.append(\" multiBase \");\n+        msg.append(multiBase);\n+        msg.append(\" deltaSize \");\n+        msg.append(deltaSize);\n         msg.append(\" threshold: \");\n         msg.append(deltaPctThreshold);\n         msg.append(\" will major compact: \");\n-        msg.append(bigEnough);\n+        msg.append(bigEnough || (deltaSize == 0  && multiBase));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "12a95f18239db835745c20445ed1763cc6549e07"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDk0MDk2OnYy", "diffSide": "RIGHT", "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestInitiator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1MzozMFrOGoG-gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1MzozMFrOGoG-gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxMDUzMQ==", "bodyText": "opportunity: add:\nstartWorker();\nAssert.assertEquals(\"ready for cleaning\",rsp.getCompacts().get(0).getState());", "url": "https://github.com/apache/hive/pull/1085#discussion_r444710531", "createdAt": "2020-06-24T07:53:30Z", "author": {"login": "klcopp"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestInitiator.java", "diffHunk": "@@ -1031,6 +1031,34 @@ private ShowCompactResponseElement generateElement(long id, String db, String ta\n     return element;\n   }\n \n+  @Test\n+  public void compactTableWithMultipleBase() throws Exception {\n+    Table t = newTable(\"default\", \"nctdpnhe\", false);\n+\n+    addBaseFile(t, null, 50L, 50);\n+    addBaseFile(t, null, 100L, 50);\n+\n+    burnThroughTransactions(\"default\", \"nctdpnhe\", 102);\n+\n+    long txnid = openTxn();\n+    LockComponent comp = new LockComponent(LockType.SHARED_WRITE, LockLevel.TABLE, \"default\");\n+    comp.setTablename(\"nctdpnhe\");\n+    comp.setOperationType(DataOperationType.UPDATE);\n+    List<LockComponent> components = new ArrayList<LockComponent>(1);\n+    components.add(comp);\n+    LockRequest req = new LockRequest(components, \"me\", \"localhost\");\n+    req.setTxnid(txnid);\n+    LockResponse res = txnHandler.lock(req);\n+    long writeid = allocateWriteId(\"default\", \"nctdpnhe\", txnid);\n+    txnHandler.commitTxn(new CommitTxnRequest(txnid));\n+\n+    startInitiator();\n+\n+    ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n+    Assert.assertEquals(1, rsp.getCompactsSize());\n+    Assert.assertEquals(\"initiated\",rsp.getCompacts().get(0).getState());\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "12a95f18239db835745c20445ed1763cc6549e07"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDk0MzA4OnYy", "diffSide": "RIGHT", "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestInitiator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1NDowOFrOGoG_6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzo1NDowOFrOGoG_6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxMDg5MA==", "bodyText": "nit: no newline at end of file", "url": "https://github.com/apache/hive/pull/1085#discussion_r444710890", "createdAt": "2020-06-24T07:54:08Z", "author": {"login": "klcopp"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestInitiator.java", "diffHunk": "@@ -1040,4 +1068,4 @@ boolean useHive130DeltaDirName() {\n   public void tearDown() throws Exception {\n     compactorTestCleanup();\n   }\n-}\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "12a95f18239db835745c20445ed1763cc6549e07"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 756, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}