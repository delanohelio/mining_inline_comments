{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyNzEyNzU1", "number": 1629, "title": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "bodyText": "What changes were proposed in this pull request?\nThe Driver class has some very long methods, they are now having a more manageable size. Also some minor checkstyle errors were fixed in some Driver associated classes\nWhy are the changes needed?\nTo make the Driver class more understandable.\nDoes this PR introduce any user-facing change?\nNo.\nHow was this patch tested?\nAll the tests are still running.", "createdAt": "2020-10-30T02:15:14Z", "url": "https://github.com/apache/hive/pull/1629", "merged": true, "mergeCommit": {"oid": "c309914f0f7e76aa74f1713ea7648c2d25c0409a"}, "closed": true, "closedAt": "2020-12-02T12:50:50Z", "author": {"login": "miklosgergely"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbLyT9AFqTUyNzM3MTQ3OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdhnYM0AFqTU0MTAzODczNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MzcxNDc5", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-527371479", "createdAt": "2020-11-10T16:17:06Z", "commit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjoxNzowNlrOHwkXEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjoxNzowNlrOHwkXEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4OTQyNA==", "bodyText": "This is nice because it has been moved outside the lock scope.  I was double-checking if this variable can safely be examined outside the scope of the lock, and I noted that driverContext can never be null.  It is defined as final and set in the constructor.  Please remove this check.", "url": "https://github.com/apache/hive/pull/1629#discussion_r520689424", "createdAt": "2020-11-10T16:17:06Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -149,207 +149,64 @@ private CommandProcessorResponse run(String command, boolean alreadyCompiled) th\n       runInternal(command, alreadyCompiled);\n       return new CommandProcessorResponse(getSchema(), null);\n     } catch (CommandProcessorException cpe) {\n-      SessionState ss = SessionState.get();\n-      if (ss == null) {\n-        throw cpe;\n-      }\n-      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-      if (!(mdf instanceof JsonMetaDataFormatter)) {\n-        throw cpe;\n-      }\n-      /*Here we want to encode the error in machine readable way (e.g. JSON)\n-       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n-       * In practice that is rarely the case, so the messy logic below tries to tease\n-       * out canonical error code if it can.  Exclude stack trace from output when\n-       * the error is a specific/expected one.\n-       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n-      try {\n-        if (cpe.getCause() == null) {\n-          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-          throw cpe;\n-        }\n-        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-          /*Some HiveExceptions (e.g. SemanticException) don't set\n-            canonical ErrorMsg explicitly, but there is logic\n-            (e.g. #compile()) to find an appropriate canonical error and\n-            return its code as error code. In this case we want to\n-            preserve it for downstream code to interpret*/\n-          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-          throw cpe;\n-        }\n-        if (cpe.getCause() instanceof HiveException) {\n-          HiveException rc = (HiveException)cpe.getCause();\n-          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-        } else {\n-          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-              StringUtils.stringifyException(cpe.getCause()));\n-        }\n-      } catch (HiveException ex) {\n-        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n-      }\n+      processRunException(cpe);\n       throw cpe;\n     }\n   }\n \n   private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     DriverState.setDriverState(driverState);\n \n-    driverState.lock();\n-    try {\n-      if (driverContext != null && driverContext.getPlan() != null\n-          && driverContext.getPlan().isPrepareQuery()\n-          && !driverContext.getPlan().isExplain()) {\n-        LOG.info(\"Skip running tasks for prepare plan\");\n-        return;\n-      }\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+    if (driverContext != null && driverContext.getPlan() != null &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3Mzg1MDcy", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-527385072", "createdAt": "2020-11-10T16:30:47Z", "commit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjozMDo0N1rOHwk_dQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjozMDo0N1rOHwk_dQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc2NQ==", "bodyText": "Since you are slicing and dicing things, you may want to look at breaking this out a bit.\nIt is bad form to throw and exception, and then handle it, within the same method.\nI think this should be moved out of this try block.\n      if (retryShapshotCount > maxRetrySnapshotCount) {\n        // Throw exception\n        HiveException e = new HiveException(\n            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n        DriverUtils.handleHiveException(driverContext, e, 14, null);\n      }\n  if (retryShapshotCount != 0) {\n        // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n        // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n        context.setHiveTxnManager(driverContext.getTxnManager());\n        return true;\n    }\n    return false;", "url": "https://github.com/apache/hive/pull/1629#discussion_r520699765", "createdAt": "2020-11-10T16:30:47Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -359,6 +216,101 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command\n     SessionState.getPerfLogger().cleanupPerfLogMetrics();\n   }\n \n+  /**\n+   * @return If the perfLogger should be reseted.\n+   */\n+  private boolean validateTxnList() throws CommandProcessorException {\n+    int retryShapshotCount = 0;\n+    int maxRetrySnapshotCount = HiveConf.getIntVar(driverContext.getConf(),\n+        HiveConf.ConfVars.HIVE_TXN_MAX_RETRYSNAPSHOT_COUNT);\n+\n+    try {\n+      do {\n+        driverContext.setOutdatedTxn(false);\n+        // Inserts will not invalidate the snapshot, that could cause duplicates.\n+        if (!driverTxnHandler.isValidTxnListState()) {\n+          LOG.info(\"Re-compiling after acquiring locks, attempt #\" + retryShapshotCount);\n+          // Snapshot was outdated when locks were acquired, hence regenerate context, txn list and retry.\n+          // TODO: Lock acquisition should be moved before analyze, this is a bit hackish.\n+          // Currently, we acquire a snapshot, compile the query with that snapshot, and then - acquire locks.\n+          // If snapshot is still valid, we continue as usual.\n+          // But if snapshot is not valid, we recompile the query.\n+          if (driverContext.isOutdatedTxn()) {\n+            // Later transaction invalidated the snapshot, a new transaction is required\n+            LOG.info(\"Snapshot is outdated, re-initiating transaction ...\");\n+            driverContext.getTxnManager().rollbackTxn();\n+\n+            String userFromUGI = DriverUtils.getUserFromUGI(driverContext);\n+            driverContext.getTxnManager().openTxn(context, userFromUGI, driverContext.getTxnType());\n+            lockAndRespond();\n+          }\n+          driverContext.setRetrial(true);\n+          driverContext.getBackupContext().addSubContext(context);\n+          driverContext.getBackupContext().setHiveLocks(context.getHiveLocks());\n+          context = driverContext.getBackupContext();\n+\n+          driverContext.getConf().set(ValidTxnList.VALID_TXNS_KEY,\n+              driverContext.getTxnManager().getValidTxns().toString());\n+\n+          if (driverContext.getPlan().hasAcidResourcesInQuery()) {\n+            compileInternal(context.getCmd(), true);\n+            driverTxnHandler.recordValidWriteIds();\n+            driverTxnHandler.setWriteIdForAcidFileSinks();\n+          }\n+          // Since we're reusing the compiled plan, we need to update its start time for current run\n+          driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n+        }\n+        // Re-check snapshot only in case we had to release locks and open a new transaction,\n+        // otherwise exclusive locks should protect output tables/partitions in snapshot from concurrent writes.\n+      } while (driverContext.isOutdatedTxn() && ++retryShapshotCount <= maxRetrySnapshotCount);\n+\n+      if (retryShapshotCount > maxRetrySnapshotCount) {\n+        // Throw exception\n+        HiveException e = new HiveException(\n+            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n+        DriverUtils.handleHiveException(driverContext, e, 14, null);\n+      } else if (retryShapshotCount != 0) {\n+        // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+        // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+        context.setHiveTxnManager(driverContext.getTxnManager());\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 285}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3Mzk2MTE2", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-527396116", "createdAt": "2020-11-10T16:42:13Z", "commit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0MjoxM1rOHwlfmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0MjoxM1rOHwlfmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwNzk5NQ==", "bodyText": "This is a little hard to follow.  Perhaps something like:\n    if (driverContext.getResStream() == null) {\n       // If the driver does not have a stream and neither does the context, return\n       Stream contextStream = context.getStream();\n       if (contextStream == null) {\n         return false;\n       }\n       driverContext.setResStream(contextStream);\n      }\n    }", "url": "https://github.com/apache/hive/pull/1629#discussion_r520707995", "createdAt": "2020-11-10T16:42:13Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -638,46 +654,28 @@ public boolean getResults(List results) throws IOException {\n     }\n \n     if (isFetchingTable()) {\n-      /**\n-       * If resultset serialization to thrift object is enabled, and if the destination table is\n-       * indeed written using ThriftJDBCBinarySerDe, read one row from the output sequence file,\n-       * since it is a blob of row batches.\n-       */\n-      if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n-        maxRows = 1;\n-      }\n-      driverContext.getFetchTask().setMaxRows(maxRows);\n-      return driverContext.getFetchTask().fetch(results);\n+      return getFetchingTableResults(results);\n     }\n \n     if (driverContext.getResStream() == null) {\n       driverContext.setResStream(context.getStream());\n-    }\n-    if (driverContext.getResStream() == null) {\n-      return false;\n+      if (driverContext.getResStream() == null) {\n+        return false;\n+      }\n     }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 433}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3Mzk5NDgx", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-527399481", "createdAt": "2020-11-10T16:45:50Z", "commit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0NTo1MFrOHwlp6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0NTo1MFrOHwlp6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMDYzMw==", "bodyText": "nit: Safer to make this final to ensure that there aren't multiple paths later if this code changes.", "url": "https://github.com/apache/hive/pull/1629#discussion_r520710633", "createdAt": "2020-11-10T16:45:50Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -687,13 +685,36 @@ public boolean getResults(List results) throws IOException {\n         return false;\n       }\n \n-      if (ss == Utilities.StreamStatus.EOF) {\n+      if (streamStatus == Utilities.StreamStatus.EOF) {\n         driverContext.setResStream(context.getStream());\n       }\n     }\n     return true;\n   }\n \n+  @SuppressWarnings(\"rawtypes\")\n+  private boolean getFetchingTableResults(List results) throws IOException {\n+    // If result set serialization to thrift object is enabled, and if the destination table is indeed written using\n+    // ThriftJDBCBinarySerDe, read one row from the output sequence file, since it is a blob of row batches.\n+    if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n+      maxRows = 1;\n+    }\n+    driverContext.getFetchTask().setMaxRows(maxRows);\n+    return driverContext.getFetchTask().fetch(results);\n+  }\n+\n+  private String getRow(ByteStream.Output bos, Utilities.StreamStatus streamStatus) {\n+    String row;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 486}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NDAyMjM1", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-527402235", "createdAt": "2020-11-10T16:48:44Z", "commit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0ODo0NFrOHwlyXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxNjo0ODo1MFrOHwlyqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjc5Nw==", "bodyText": "This is a good change, but please revert for this PR to keep it focused on the Driver classes.", "url": "https://github.com/apache/hive/pull/1629#discussion_r520712797", "createdAt": "2020-11-10T16:48:44Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java", "diffHunk": "@@ -73,7 +73,7 @@ private static IReExecutionPlugin buildReExecPlugin(String name) throws RuntimeE\n     if(\"reexecute_lost_am\".equals(name)) {\n       return new ReExecuteLostAMQueryPlugin();\n     }\n-    if (name.equals(\"dagsubmit\")) {\n+    if (\"dagsubmit\".equals(name)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjg3Mw==", "bodyText": "This is a good change, but please revert for this PR to keep it focused on the Driver classes.", "url": "https://github.com/apache/hive/pull/1629#discussion_r520712873", "createdAt": "2020-11-10T16:48:50Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java", "diffHunk": "@@ -67,7 +67,6 @@\n import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;\n import org.apache.hadoop.util.StringUtils;\n import org.apache.hive.common.util.ShutdownHookManager;\n-import org.apache.hive.common.util.TxnIdUtils;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/7316cc96b7042a6227e6507e4cd265f97d91c93d", "committedDate": "2020-10-30T02:10:48Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}, "afterCommit": {"oid": "8c33879faa9538712811b5057c7808b233d68a8e", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/8c33879faa9538712811b5057c7808b233d68a8e", "committedDate": "2020-11-10T18:16:32Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8c33879faa9538712811b5057c7808b233d68a8e", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/8c33879faa9538712811b5057c7808b233d68a8e", "committedDate": "2020-11-10T18:16:32Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}, "afterCommit": {"oid": "4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "committedDate": "2020-11-10T18:18:53Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "committedDate": "2020-11-26T11:53:01Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "committedDate": "2020-11-10T18:18:53Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}, "afterCommit": {"oid": "76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "author": {"user": {"login": "miklosgergely", "name": "Miklos Gergely"}}, "url": "https://github.com/apache/hive/commit/76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "committedDate": "2020-11-26T11:53:01Z", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxMDM4NzM2", "url": "https://github.com/apache/hive/pull/1629#pullrequestreview-541038736", "createdAt": "2020-11-30T15:49:28Z", "commit": {"oid": "76ce45dd0316f18f6329e7ff3d8069cfe2f7042c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2976, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}