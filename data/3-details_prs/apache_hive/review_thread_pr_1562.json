{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwMDA4MDYw", "number": 1562, "reviewThreads": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo1OTo1NVrOExvipw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNzoyM1rOEzn2Cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNTk0NTk5OnYy", "diffSide": "RIGHT", "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo1OTo1NVrOHoAOOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwMzo1OTo1NVrOHoAOOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwODczMA==", "bodyText": "nit. typo 'successfull'", "url": "https://github.com/apache/hive/pull/1562#discussion_r511708730", "createdAt": "2020-10-26T03:59:55Z", "author": {"login": "jcamachor"}, "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "diffHunk": "@@ -2595,6 +2595,8 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n     HIVE_SHARED_WORK_DPPUNION_OPTIMIZATION(\"hive.optimize.shared.work.dppunion\", true,\n         \"Enables dppops unioning. This optimization will enable to merge multiple tablescans with different \"\n             + \"dynamic filters into a single one (with a more complex filter)\"),\n+    HIVE_SHARED_WORK_DOWNSTREAM_MERGE(\"hive.optimize.shared.work.downstream.merge\", true,\n+        \"Analyzes and merges equiv downstream operators after a successfull shared work optimization step.\"),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjAwNzEzOnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query32.q.out", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNDo0Mzo1NFrOHoAvXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo0NTozOVrOHo1seQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxNzIxMw==", "bodyText": "SJ is gone. Is this expected?", "url": "https://github.com/apache/hive/pull/1562#discussion_r511717213", "createdAt": "2020-10-26T04:43:54Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query32.q.out", "diffHunk": "@@ -160,7 +160,7 @@ Stage-0\n                                     Select Operator [SEL_115] (rows=286549727 width=119)\n                                       Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                       Filter Operator [FIL_113] (rows=286549727 width=119)\n-                                        predicate:(cs_sold_date_sk is not null and cs_item_sk BETWEEN DynamicValue(RS_28_item_i_item_sk_min) AND DynamicValue(RS_28_item_i_item_sk_max) and in_bloom_filter(cs_item_sk, DynamicValue(RS_28_item_i_item_sk_bloom_filter)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU4NDgyNQ==", "bodyText": "conditional was not reconstructed properly during filter creation - fixed", "url": "https://github.com/apache/hive/pull/1562#discussion_r512584825", "createdAt": "2020-10-27T10:45:39Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query32.q.out", "diffHunk": "@@ -160,7 +160,7 @@ Stage-0\n                                     Select Operator [SEL_115] (rows=286549727 width=119)\n                                       Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                       Filter Operator [FIL_113] (rows=286549727 width=119)\n-                                        predicate:(cs_sold_date_sk is not null and cs_item_sk BETWEEN DynamicValue(RS_28_item_i_item_sk_min) AND DynamicValue(RS_28_item_i_item_sk_max) and in_bloom_filter(cs_item_sk, DynamicValue(RS_28_item_i_item_sk_bloom_filter)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxNzIxMw=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjA3MzkyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTozMDo0NFrOHoBUNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTozMDo0NFrOHoBUNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyNjY0Nw==", "bodyText": "I think you could use ExprNodeDescExprFactory.isANDFuncCallExpr or FunctionRegistry.isOpAnd(expr)?", "url": "https://github.com/apache/hive/pull/1562#discussion_r511726647", "createdAt": "2020-10-26T05:30:44Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeDescUtils.java", "diffHunk": "@@ -1136,4 +1173,30 @@ public static boolean isOr(ExprNodeDesc expr) {\n     return false;\n   }\n \n+  public static boolean isAnd(ExprNodeDesc expr) {\n+    if (expr instanceof ExprNodeGenericFuncDesc) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjA3OTQwOnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/llap/sharedwork_semi.q.out", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTozNDozN1rOHoBXZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwNDowNDowMVrOHqIjUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyNzQ2MA==", "bodyText": "Iirc we order the expressions intentionally in such a way that the rest of expressions are evaluated before the SJ expression, since the probe of the bloom filter is usually more expensive than evaluating other expressions (heuristic).", "url": "https://github.com/apache/hive/pull/1562#discussion_r511727460", "createdAt": "2020-10-26T05:34:37Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/sharedwork_semi.q.out", "diffHunk": "@@ -541,7 +541,7 @@ STAGE PLANS:\n             Map Operator Tree:\n                 TableScan\n                   alias: s\n-                  filterExpr: (ss_sold_date_sk is not null and ((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter))))) (type: boolean)\n+                  filterExpr: (((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter)))) and ss_sold_date_sk is not null) (type: boolean)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU4ODc1OQ==", "bodyText": "I've tried to retain the order - which have placed the bloom related checks at the end.\nI recall that there was a ticket about ordering conditionals - but I can't find the related ticket; do I remember incorrectly?", "url": "https://github.com/apache/hive/pull/1562#discussion_r512588759", "createdAt": "2020-10-27T10:51:14Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/llap/sharedwork_semi.q.out", "diffHunk": "@@ -541,7 +541,7 @@ STAGE PLANS:\n             Map Operator Tree:\n                 TableScan\n                   alias: s\n-                  filterExpr: (ss_sold_date_sk is not null and ((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter))))) (type: boolean)\n+                  filterExpr: (((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter)))) and ss_sold_date_sk is not null) (type: boolean)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyNzQ2MA=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk0MjM1NA==", "bodyText": "we see a case when NonBlockingOpDeDupProc merges FIL-FIL, the conditionals may be reorder.\n#1308", "url": "https://github.com/apache/hive/pull/1562#discussion_r513942354", "createdAt": "2020-10-29T04:04:01Z", "author": {"login": "dengzhhu653"}, "path": "ql/src/test/results/clientpositive/llap/sharedwork_semi.q.out", "diffHunk": "@@ -541,7 +541,7 @@ STAGE PLANS:\n             Map Operator Tree:\n                 TableScan\n                   alias: s\n-                  filterExpr: (ss_sold_date_sk is not null and ((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter))))) (type: boolean)\n+                  filterExpr: (((ss_sold_date_sk BETWEEN DynamicValue(RS_7_d_d_date_sk_min) AND DynamicValue(RS_7_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_7_d_d_date_sk_bloom_filter))) or (ss_sold_date_sk BETWEEN DynamicValue(RS_21_d_d_date_sk_min) AND DynamicValue(RS_21_d_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_21_d_d_date_sk_bloom_filter)))) and ss_sold_date_sk is not null) (type: boolean)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyNzQ2MA=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjA5Mzg5OnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query1b.q.out", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo0Mzo1OVrOHoBfmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo0Mzo1OVrOHoBfmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyOTU2Mw==", "bodyText": "Same as above. Filter exprs order", "url": "https://github.com/apache/hive/pull/1562#discussion_r511729563", "createdAt": "2020-10-26T05:43:59Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query1b.q.out", "diffHunk": "@@ -176,7 +176,7 @@ STAGE PLANS:\n             Map Operator Tree:\n                 TableScan\n                   alias: store_returns\n-                  filterExpr: (((sr_customer_sk is not null and sr_store_sk is not null and sr_returned_date_sk is not null) or (sr_store_sk is not null and sr_returned_date_sk is not null)) and sr_store_sk BETWEEN DynamicValue(RS_40_store_s_store_sk_min) AND DynamicValue(RS_40_store_s_store_sk_max) and in_bloom_filter(sr_store_sk, DynamicValue(RS_40_store_s_store_sk_bloom_filter))) (type: boolean)\n+                  filterExpr: (sr_store_sk BETWEEN DynamicValue(RS_40_store_s_store_sk_min) AND DynamicValue(RS_40_store_s_store_sk_max) and in_bloom_filter(sr_store_sk, DynamicValue(RS_40_store_s_store_sk_bloom_filter)) and ((sr_customer_sk is not null and sr_store_sk is not null and sr_returned_date_sk is not null) or (sr_store_sk is not null and sr_returned_date_sk is not null))) (type: boolean)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjA5NDU5OnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query1b.q.out", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo0NDoyN1rOHoBgBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo1MTo1N1rOHo1-Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyOTY2OQ==", "bodyText": "SJ went away? It is kept in the other branch (L182).", "url": "https://github.com/apache/hive/pull/1562#discussion_r511729669", "createdAt": "2020-10-26T05:44:27Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query1b.q.out", "diffHunk": "@@ -210,7 +210,7 @@ STAGE PLANS:\n                             Statistics: Num rows: 16855704 Data size: 2008197920 Basic stats: COMPLETE Column stats: COMPLETE\n                             value expressions: _col2 (type: decimal(17,2))\n                   Filter Operator\n-                    predicate: (sr_store_sk is not null and sr_returned_date_sk is not null and sr_store_sk BETWEEN DynamicValue(RS_40_store_s_store_sk_min) AND DynamicValue(RS_40_store_s_store_sk_max) and in_bloom_filter(sr_store_sk, DynamicValue(RS_40_store_s_store_sk_bloom_filter))) (type: boolean)\n+                    predicate: (sr_store_sk is not null and sr_returned_date_sk is not null) (type: boolean)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU4OTM5MA==", "bodyText": "changes are gone in this file", "url": "https://github.com/apache/hive/pull/1562#discussion_r512589390", "createdAt": "2020-10-27T10:51:57Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query1b.q.out", "diffHunk": "@@ -210,7 +210,7 @@ STAGE PLANS:\n                             Statistics: Num rows: 16855704 Data size: 2008197920 Basic stats: COMPLETE Column stats: COMPLETE\n                             value expressions: _col2 (type: decimal(17,2))\n                   Filter Operator\n-                    predicate: (sr_store_sk is not null and sr_returned_date_sk is not null and sr_store_sk BETWEEN DynamicValue(RS_40_store_s_store_sk_min) AND DynamicValue(RS_40_store_s_store_sk_max) and in_bloom_filter(sr_store_sk, DynamicValue(RS_40_store_s_store_sk_bloom_filter))) (type: boolean)\n+                    predicate: (sr_store_sk is not null and sr_returned_date_sk is not null) (type: boolean)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcyOTY2OQ=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjA5ODIzOnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query25.q.out", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo0Njo0N1rOHoBiFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxNToyOTozM1rOHrUQXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMDE5OQ==", "bodyText": "Are these new TS that are not reused anymore? For instance, it seems this one is the same that was reused in old L224.", "url": "https://github.com/apache/hive/pull/1562#discussion_r511730199", "createdAt": "2020-10-26T05:46:47Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query25.q.out", "diffHunk": "@@ -176,92 +176,88 @@ Stage-0\n                                   Merge Join Operator [MERGEJOIN_246] (rows=21091882 width=154)\n                                     Conds:RS_25._col2, _col1, _col4=RS_26._col2, _col1, _col3(Inner),Output:[\"_col1\",\"_col3\",\"_col5\",\"_col8\",\"_col9\",\"_col11\"]\n                                   <-Reducer 10 [SIMPLE_EDGE]\n+                                    SHUFFLE [RS_26]\n+                                      PartitionCols:_col2, _col1, _col3\n+                                      Merge Join Operator [MERGEJOIN_245] (rows=9402909 width=100)\n+                                        Conds:RS_270._col0=RS_256._col0(Inner),Output:[\"_col1\",\"_col2\",\"_col3\",\"_col4\"]\n+                                      <-Map 8 [SIMPLE_EDGE] vectorized\n+                                        PARTITION_ONLY_SHUFFLE [RS_256]\n+                                          PartitionCols:_col0\n+                                          Select Operator [SEL_252] (rows=351 width=4)\n+                                            Output:[\"_col0\"]\n+                                            Filter Operator [FIL_250] (rows=351 width=12)\n+                                              predicate:((d_year = 2000) and d_moy BETWEEN 4 AND 10)\n+                                              TableScan [TS_3] (rows=73049 width=12)\n+                                                default@date_dim,d3,Tbl:COMPLETE,Col:COMPLETE,Output:[\"d_date_sk\",\"d_year\",\"d_moy\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE4MjY4NQ==", "bodyText": "date_dim is only scanned once in the new plan as well - in this query the order of things have changed a bit\nso far it seems like the biggest change is that Reducer 10 is exchanged with Reducer 15", "url": "https://github.com/apache/hive/pull/1562#discussion_r515182685", "createdAt": "2020-10-30T15:29:33Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query25.q.out", "diffHunk": "@@ -176,92 +176,88 @@ Stage-0\n                                   Merge Join Operator [MERGEJOIN_246] (rows=21091882 width=154)\n                                     Conds:RS_25._col2, _col1, _col4=RS_26._col2, _col1, _col3(Inner),Output:[\"_col1\",\"_col3\",\"_col5\",\"_col8\",\"_col9\",\"_col11\"]\n                                   <-Reducer 10 [SIMPLE_EDGE]\n+                                    SHUFFLE [RS_26]\n+                                      PartitionCols:_col2, _col1, _col3\n+                                      Merge Join Operator [MERGEJOIN_245] (rows=9402909 width=100)\n+                                        Conds:RS_270._col0=RS_256._col0(Inner),Output:[\"_col1\",\"_col2\",\"_col3\",\"_col4\"]\n+                                      <-Map 8 [SIMPLE_EDGE] vectorized\n+                                        PARTITION_ONLY_SHUFFLE [RS_256]\n+                                          PartitionCols:_col0\n+                                          Select Operator [SEL_252] (rows=351 width=4)\n+                                            Output:[\"_col0\"]\n+                                            Filter Operator [FIL_250] (rows=351 width=12)\n+                                              predicate:((d_year = 2000) and d_moy BETWEEN 4 AND 10)\n+                                              TableScan [TS_3] (rows=73049 width=12)\n+                                                default@date_dim,d3,Tbl:COMPLETE,Col:COMPLETE,Output:[\"d_date_sk\",\"d_year\",\"d_moy\"]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMDE5OQ=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjEwMTc0OnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query54.q.out", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo0ODo1N1rOHoBkBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo1ODoxOVrOHo2RIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMDY5NA==", "bodyText": "Change of algorithm to SHUFFLE. Is this expected? It seems the same changed happened for multiple ops in the plan.", "url": "https://github.com/apache/hive/pull/1562#discussion_r511730694", "createdAt": "2020-10-26T05:48:57Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query54.q.out", "diffHunk": "@@ -202,156 +202,154 @@ Stage-0\n                                           predicate:(_col1 <= _col3)\n                                           Merge Join Operator [MERGEJOIN_294] (rows=15218525 width=12)\n                                             Conds:(Inner),Output:[\"_col0\",\"_col1\",\"_col3\"]\n-                                          <-Reducer 15 [CUSTOM_SIMPLE_EDGE]\n+                                          <-Reducer 20 [CUSTOM_SIMPLE_EDGE]\n                                             PARTITION_ONLY_SHUFFLE [RS_99]\n                                               Filter Operator [FIL_98] (rows=608741 width=12)\n                                                 predicate:(_col2 <= _col1)\n                                                 Merge Join Operator [MERGEJOIN_291] (rows=1826225 width=12)\n                                                   Conds:(Inner),Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                                 <-Map 9 [CUSTOM_SIMPLE_EDGE] vectorized\n-                                                  PARTITION_ONLY_SHUFFLE [RS_327]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NDIwOA==", "bodyText": "this is hightly unfortunate:\nthe jsonexplain api \"tells\" the vertex about the outgoing edge type by calling this method from here\nsince a single vertex can have multiple outgoing edges - setting the type of one-of-them is problematic - I think we may want to consider to simple remove this tagging of vertices\ninstead...we should consider renaming some of the edge types...like CUSTOM_SIMPLE_EDGE to PARTITION_ONLY", "url": "https://github.com/apache/hive/pull/1562#discussion_r512594208", "createdAt": "2020-10-27T10:58:19Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query54.q.out", "diffHunk": "@@ -202,156 +202,154 @@ Stage-0\n                                           predicate:(_col1 <= _col3)\n                                           Merge Join Operator [MERGEJOIN_294] (rows=15218525 width=12)\n                                             Conds:(Inner),Output:[\"_col0\",\"_col1\",\"_col3\"]\n-                                          <-Reducer 15 [CUSTOM_SIMPLE_EDGE]\n+                                          <-Reducer 20 [CUSTOM_SIMPLE_EDGE]\n                                             PARTITION_ONLY_SHUFFLE [RS_99]\n                                               Filter Operator [FIL_98] (rows=608741 width=12)\n                                                 predicate:(_col2 <= _col1)\n                                                 Merge Join Operator [MERGEJOIN_291] (rows=1826225 width=12)\n                                                   Conds:(Inner),Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                                 <-Map 9 [CUSTOM_SIMPLE_EDGE] vectorized\n-                                                  PARTITION_ONLY_SHUFFLE [RS_327]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMDY5NA=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIwNjEwODY1OnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query92.q.out", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNlQwNTo1MzowNlrOHoBn9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxMDo1ODo1OVrOHo2TFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMTcwMg==", "bodyText": "SJ got removed. Is this expected?", "url": "https://github.com/apache/hive/pull/1562#discussion_r511731702", "createdAt": "2020-10-26T05:53:06Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query92.q.out", "diffHunk": "@@ -164,7 +164,7 @@ Stage-0\n                                     Select Operator [SEL_115] (rows=143966864 width=119)\n                                       Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                       Filter Operator [FIL_113] (rows=143966864 width=119)\n-                                        predicate:(ws_sold_date_sk is not null and ws_item_sk BETWEEN DynamicValue(RS_28_item_i_item_sk_min) AND DynamicValue(RS_28_item_i_item_sk_max) and in_bloom_filter(ws_item_sk, DynamicValue(RS_28_item_i_item_sk_bloom_filter)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU5NDcxMA==", "bodyText": "changes are gone", "url": "https://github.com/apache/hive/pull/1562#discussion_r512594710", "createdAt": "2020-10-27T10:58:59Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query92.q.out", "diffHunk": "@@ -164,7 +164,7 @@ Stage-0\n                                     Select Operator [SEL_115] (rows=143966864 width=119)\n                                       Output:[\"_col0\",\"_col1\",\"_col2\"]\n                                       Filter Operator [FIL_113] (rows=143966864 width=119)\n-                                        predicate:(ws_sold_date_sk is not null and ws_item_sk BETWEEN DynamicValue(RS_28_item_i_item_sk_min) AND DynamicValue(RS_28_item_i_item_sk_max) and in_bloom_filter(ws_item_sk, DynamicValue(RS_28_item_i_item_sk_bloom_filter)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczMTcwMg=="}, "originalCommit": {"oid": "0d801e4f838909d80112d7067816a954fb937397"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODU3Nzg2OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODoyODoyMVrOHp4BZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwMzo1NjoxMlrOHq9N3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3MTUyNw==", "bodyText": "@jcamachor this is the checker class I was talking about - right now it builds on top of the basic digraph class I've introduce some time ago in PointLookupOptimizer", "url": "https://github.com/apache/hive/pull/1562#discussion_r513671527", "createdAt": "2020-10-28T18:28:21Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgwNTIxNQ==", "bodyText": "Looks good. Could we add comments so it is clear what it is being represented, e.g., what is a cluster, etc.", "url": "https://github.com/apache/hive/pull/1562#discussion_r514805215", "createdAt": "2020-10-30T03:56:12Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3MTUyNw=="}, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODU5NDk3OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODozMjo0M1rOHp4LzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMDo0MzozNFrOHt9dBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NDE4OQ==", "bodyText": "we can definetly roll our own graph representation; however sometimes I would feel that it would make things easier to have access to basic graph algorithms (for example to do a  topological order walk/etc) there is a small library called jgrapht (EPL 2.0 license - I think it will be okay) which could be utilized for these kind of things\n@jcamachor what do you think about pulling in the jgrapht lib and removing the makeshift digraph classes?", "url": "https://github.com/apache/hive/pull/1562#discussion_r513674189", "createdAt": "2020-10-28T18:32:43Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgwMjIwNg==", "bodyText": "Yes, I think it's a good idea to use an established graph library for this. I think we could create a follow-up for that and discuss the license too, to make sure there is no issue. Any advantage to using jgrapht over Guava graph implementation, given that guava is already a Hive dependency and quite widely used?", "url": "https://github.com/apache/hive/pull/1562#discussion_r514802206", "createdAt": "2020-10-30T03:53:11Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NDE4OQ=="}, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk1NDgyMA==", "bodyText": "jgrapht has quite a few graph algorithms as well - guava would be a viable candidate if we don't yet have a graph class; but I think it doesn't give much more than that.\nI've moved these classes around - let's see how far we can get with these!", "url": "https://github.com/apache/hive/pull/1562#discussion_r517954820", "createdAt": "2020-11-05T10:43:34Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NDE4OQ=="}, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODYwNDMyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODozNToxN1rOHp4RtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMDo1MTo1NVrOHt9xZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NTcwMA==", "bodyText": "this is not called from anywhere right now - but I've used it during debug to get a better understanding of the plan", "url": "https://github.com/apache/hive/pull/1562#discussion_r513675700", "createdAt": "2020-10-28T18:35:17Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {\n+\n+    static class DagNode<V, E> extends Node<V, E> {\n+      int dagIdx = 0;\n+      public DagNode(V v) {\n+        super(v);\n+      }\n+\n+      @Override\n+      public void addEdge(Edge<V, E> edge) {\n+        if (edge.s == this) {\n+          DagNode<V, E> t = (DagNode<V, E>) edge.t;\n+          ensureDagIdxAtLeast(t.dagIdx + 1);\n+          if (t.dagIdx > dagIdx) {\n+            throw new IllegalArgumentException(\"adding this edge would violate dag properties\");\n+          }\n+        }\n+        super.addEdge(edge);\n+      }\n+\n+      void ensureDagIdxAtLeast(int min) {\n+        if (dagIdx >= min) {\n+          return;\n+        }\n+        dagIdx = min;\n+        for (Edge<V, E> e : edges) {\n+          if(e.t == this) {\n+            DagNode<V, E> s = (DagNode<V, E>) e.s;\n+            s.ensureDagIdxAtLeast(min + 1);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Override\n+    protected Node<V, E> newNode(V s) {\n+      return new DagNode<V, E>(s);\n+    }\n+  }\n+\n+  DagGraph<Operator<?>, OpEdge> g;\n+\n+  enum EdgeType {\n+    FLOW, SEMIJOIN, DPP, TEST,\n+  }\n+\n+  static class OpEdge {\n+\n+    private final EdgeType et;\n+    private final int index;\n+\n+    public OpEdge(EdgeType et) {\n+      this(et, 0);\n+    }\n+\n+    public OpEdge(EdgeType et, int index) {\n+      this.et = et;\n+      this.index = index;\n+    }\n+\n+  }\n+\n+\n+  Map<Operator<?>, Cluster> nodeCluster = new HashMap<>();\n+\n+  public class Cluster {\n+\n+    Set<Operator<?>> members = new LinkedHashSet<>();\n+\n+    public void merge(Cluster o) {\n+      for (Operator<?> node : o.members) {\n+        add(node);\n+      }\n+      o.members.clear();\n+    }\n+\n+    public void add(Operator<?> curr) {\n+      nodeCluster.put(curr, this);\n+      members.add(curr);\n+    }\n+\n+  }\n+\n+\n+  public OperatorGraph(ParseContext pctx) {\n+    g = new DagGraph<Operator<?>, OperatorGraph.OpEdge>();\n+    Set<Operator<?>> visited = Sets.newIdentityHashSet();\n+    Set<Operator<?>> seen = Sets.newIdentityHashSet();\n+\n+    seen.addAll(pctx.getTopOps().values());\n+    while (!seen.isEmpty()) {\n+      Operator<?> curr = seen.iterator().next();\n+      seen.remove(curr);\n+      if (visited.contains(curr)) {\n+        continue;\n+      }\n+\n+      visited.add(curr);\n+\n+      Cluster currentCluster = nodeCluster.get(curr);\n+      if (currentCluster == null) {\n+        currentCluster=new Cluster();\n+        currentCluster.add(curr);\n+      }\n+      List<Operator<?>> parents = curr.getParentOperators();\n+      for (int i = 0; i < parents.size(); i++) {\n+        Operator<?> p = parents.get(i);\n+        g.putEdgeValue(p, curr, new OpEdge(EdgeType.FLOW, i));\n+        if (p instanceof ReduceSinkOperator) {\n+          // ignore cluster of parent RS\n+          continue;\n+        }\n+        Cluster cluster = nodeCluster.get(p);\n+        if (cluster != null) {\n+          currentCluster.merge(cluster);\n+        } else {\n+          currentCluster.add(p);\n+        }\n+      }\n+\n+      SemiJoinBranchInfo sji = pctx.getRsToSemiJoinBranchInfo().get(curr);\n+      if (sji != null) {\n+        g.putEdgeValue(curr, sji.getTsOp(), new OpEdge(EdgeType.SEMIJOIN));\n+        seen.add(sji.getTsOp());\n+      }\n+      if (curr instanceof AppMasterEventOperator) {\n+        DynamicPruningEventDesc dped = (DynamicPruningEventDesc) curr.getConf();\n+        TableScanOperator ts = dped.getTableScan();\n+        g.putEdgeValue(curr, ts, new OpEdge(EdgeType.DPP));\n+        seen.add(ts);\n+      }\n+\n+      List<Operator<?>> ccc = curr.getChildOperators();\n+      for (Operator<?> operator : ccc) {\n+        seen.add(operator);\n+      }\n+    }\n+  }\n+\n+  public void toDot(File outFile) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDc5NTgzOQ==", "bodyText": "Can we maybe move it to a utility class and add a comment? You could maybe move all these classes to optimizer.graph package", "url": "https://github.com/apache/hive/pull/1562#discussion_r514795839", "createdAt": "2020-10-30T03:46:06Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {\n+\n+    static class DagNode<V, E> extends Node<V, E> {\n+      int dagIdx = 0;\n+      public DagNode(V v) {\n+        super(v);\n+      }\n+\n+      @Override\n+      public void addEdge(Edge<V, E> edge) {\n+        if (edge.s == this) {\n+          DagNode<V, E> t = (DagNode<V, E>) edge.t;\n+          ensureDagIdxAtLeast(t.dagIdx + 1);\n+          if (t.dagIdx > dagIdx) {\n+            throw new IllegalArgumentException(\"adding this edge would violate dag properties\");\n+          }\n+        }\n+        super.addEdge(edge);\n+      }\n+\n+      void ensureDagIdxAtLeast(int min) {\n+        if (dagIdx >= min) {\n+          return;\n+        }\n+        dagIdx = min;\n+        for (Edge<V, E> e : edges) {\n+          if(e.t == this) {\n+            DagNode<V, E> s = (DagNode<V, E>) e.s;\n+            s.ensureDagIdxAtLeast(min + 1);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Override\n+    protected Node<V, E> newNode(V s) {\n+      return new DagNode<V, E>(s);\n+    }\n+  }\n+\n+  DagGraph<Operator<?>, OpEdge> g;\n+\n+  enum EdgeType {\n+    FLOW, SEMIJOIN, DPP, TEST,\n+  }\n+\n+  static class OpEdge {\n+\n+    private final EdgeType et;\n+    private final int index;\n+\n+    public OpEdge(EdgeType et) {\n+      this(et, 0);\n+    }\n+\n+    public OpEdge(EdgeType et, int index) {\n+      this.et = et;\n+      this.index = index;\n+    }\n+\n+  }\n+\n+\n+  Map<Operator<?>, Cluster> nodeCluster = new HashMap<>();\n+\n+  public class Cluster {\n+\n+    Set<Operator<?>> members = new LinkedHashSet<>();\n+\n+    public void merge(Cluster o) {\n+      for (Operator<?> node : o.members) {\n+        add(node);\n+      }\n+      o.members.clear();\n+    }\n+\n+    public void add(Operator<?> curr) {\n+      nodeCluster.put(curr, this);\n+      members.add(curr);\n+    }\n+\n+  }\n+\n+\n+  public OperatorGraph(ParseContext pctx) {\n+    g = new DagGraph<Operator<?>, OperatorGraph.OpEdge>();\n+    Set<Operator<?>> visited = Sets.newIdentityHashSet();\n+    Set<Operator<?>> seen = Sets.newIdentityHashSet();\n+\n+    seen.addAll(pctx.getTopOps().values());\n+    while (!seen.isEmpty()) {\n+      Operator<?> curr = seen.iterator().next();\n+      seen.remove(curr);\n+      if (visited.contains(curr)) {\n+        continue;\n+      }\n+\n+      visited.add(curr);\n+\n+      Cluster currentCluster = nodeCluster.get(curr);\n+      if (currentCluster == null) {\n+        currentCluster=new Cluster();\n+        currentCluster.add(curr);\n+      }\n+      List<Operator<?>> parents = curr.getParentOperators();\n+      for (int i = 0; i < parents.size(); i++) {\n+        Operator<?> p = parents.get(i);\n+        g.putEdgeValue(p, curr, new OpEdge(EdgeType.FLOW, i));\n+        if (p instanceof ReduceSinkOperator) {\n+          // ignore cluster of parent RS\n+          continue;\n+        }\n+        Cluster cluster = nodeCluster.get(p);\n+        if (cluster != null) {\n+          currentCluster.merge(cluster);\n+        } else {\n+          currentCluster.add(p);\n+        }\n+      }\n+\n+      SemiJoinBranchInfo sji = pctx.getRsToSemiJoinBranchInfo().get(curr);\n+      if (sji != null) {\n+        g.putEdgeValue(curr, sji.getTsOp(), new OpEdge(EdgeType.SEMIJOIN));\n+        seen.add(sji.getTsOp());\n+      }\n+      if (curr instanceof AppMasterEventOperator) {\n+        DynamicPruningEventDesc dped = (DynamicPruningEventDesc) curr.getConf();\n+        TableScanOperator ts = dped.getTableScan();\n+        g.putEdgeValue(curr, ts, new OpEdge(EdgeType.DPP));\n+        seen.add(ts);\n+      }\n+\n+      List<Operator<?>> ccc = curr.getChildOperators();\n+      for (Operator<?> operator : ccc) {\n+        seen.add(operator);\n+      }\n+    }\n+  }\n+\n+  public void toDot(File outFile) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NTcwMA=="}, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2MDAzNg==", "bodyText": "yes; I've moved these classes - I use these methods during development; and they are very usefull; I needed to see the join tree - and I was able to extract a simple tree after a few minutes.\nI plan to expose this kind of information on the hs2 web interface in some way.", "url": "https://github.com/apache/hive/pull/1562#discussion_r517960036", "createdAt": "2020-11-05T10:51:55Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {\n+\n+    static class DagNode<V, E> extends Node<V, E> {\n+      int dagIdx = 0;\n+      public DagNode(V v) {\n+        super(v);\n+      }\n+\n+      @Override\n+      public void addEdge(Edge<V, E> edge) {\n+        if (edge.s == this) {\n+          DagNode<V, E> t = (DagNode<V, E>) edge.t;\n+          ensureDagIdxAtLeast(t.dagIdx + 1);\n+          if (t.dagIdx > dagIdx) {\n+            throw new IllegalArgumentException(\"adding this edge would violate dag properties\");\n+          }\n+        }\n+        super.addEdge(edge);\n+      }\n+\n+      void ensureDagIdxAtLeast(int min) {\n+        if (dagIdx >= min) {\n+          return;\n+        }\n+        dagIdx = min;\n+        for (Edge<V, E> e : edges) {\n+          if(e.t == this) {\n+            DagNode<V, E> s = (DagNode<V, E>) e.s;\n+            s.ensureDagIdxAtLeast(min + 1);\n+          }\n+        }\n+      }\n+    }\n+\n+    @Override\n+    protected Node<V, E> newNode(V s) {\n+      return new DagNode<V, E>(s);\n+    }\n+  }\n+\n+  DagGraph<Operator<?>, OpEdge> g;\n+\n+  enum EdgeType {\n+    FLOW, SEMIJOIN, DPP, TEST,\n+  }\n+\n+  static class OpEdge {\n+\n+    private final EdgeType et;\n+    private final int index;\n+\n+    public OpEdge(EdgeType et) {\n+      this(et, 0);\n+    }\n+\n+    public OpEdge(EdgeType et, int index) {\n+      this.et = et;\n+      this.index = index;\n+    }\n+\n+  }\n+\n+\n+  Map<Operator<?>, Cluster> nodeCluster = new HashMap<>();\n+\n+  public class Cluster {\n+\n+    Set<Operator<?>> members = new LinkedHashSet<>();\n+\n+    public void merge(Cluster o) {\n+      for (Operator<?> node : o.members) {\n+        add(node);\n+      }\n+      o.members.clear();\n+    }\n+\n+    public void add(Operator<?> curr) {\n+      nodeCluster.put(curr, this);\n+      members.add(curr);\n+    }\n+\n+  }\n+\n+\n+  public OperatorGraph(ParseContext pctx) {\n+    g = new DagGraph<Operator<?>, OperatorGraph.OpEdge>();\n+    Set<Operator<?>> visited = Sets.newIdentityHashSet();\n+    Set<Operator<?>> seen = Sets.newIdentityHashSet();\n+\n+    seen.addAll(pctx.getTopOps().values());\n+    while (!seen.isEmpty()) {\n+      Operator<?> curr = seen.iterator().next();\n+      seen.remove(curr);\n+      if (visited.contains(curr)) {\n+        continue;\n+      }\n+\n+      visited.add(curr);\n+\n+      Cluster currentCluster = nodeCluster.get(curr);\n+      if (currentCluster == null) {\n+        currentCluster=new Cluster();\n+        currentCluster.add(curr);\n+      }\n+      List<Operator<?>> parents = curr.getParentOperators();\n+      for (int i = 0; i < parents.size(); i++) {\n+        Operator<?> p = parents.get(i);\n+        g.putEdgeValue(p, curr, new OpEdge(EdgeType.FLOW, i));\n+        if (p instanceof ReduceSinkOperator) {\n+          // ignore cluster of parent RS\n+          continue;\n+        }\n+        Cluster cluster = nodeCluster.get(p);\n+        if (cluster != null) {\n+          currentCluster.merge(cluster);\n+        } else {\n+          currentCluster.add(p);\n+        }\n+      }\n+\n+      SemiJoinBranchInfo sji = pctx.getRsToSemiJoinBranchInfo().get(curr);\n+      if (sji != null) {\n+        g.putEdgeValue(curr, sji.getTsOp(), new OpEdge(EdgeType.SEMIJOIN));\n+        seen.add(sji.getTsOp());\n+      }\n+      if (curr instanceof AppMasterEventOperator) {\n+        DynamicPruningEventDesc dped = (DynamicPruningEventDesc) curr.getConf();\n+        TableScanOperator ts = dped.getTableScan();\n+        g.putEdgeValue(curr, ts, new OpEdge(EdgeType.DPP));\n+        seen.add(ts);\n+      }\n+\n+      List<Operator<?>> ccc = curr.getChildOperators();\n+      for (Operator<?> operator : ccc) {\n+        seen.add(operator);\n+      }\n+    }\n+  }\n+\n+  public void toDot(File outFile) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY3NTcwMA=="}, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTU4NjE0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwMzo1NDozMFrOHq9HHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwMzo1NDozMFrOHq9HHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgwMzQ4Nw==", "bodyText": "In the meantime, maybe DiGraph could be made a top class.", "url": "https://github.com/apache/hive/pull/1562#discussion_r514803487", "createdAt": "2020-10-30T03:54:30Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/OperatorGraph.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.optimizer;\n+\n+import java.io.File;\n+import java.io.PrintWriter;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.AppMasterEventOperator;\n+import org.apache.hadoop.hive.ql.exec.Operator;\n+import org.apache.hadoop.hive.ql.exec.ReduceSinkOperator;\n+import org.apache.hadoop.hive.ql.exec.TableScanOperator;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.rules.HivePointLookupOptimizerRule.DiGraph;\n+import org.apache.hadoop.hive.ql.parse.ParseContext;\n+import org.apache.hadoop.hive.ql.parse.SemiJoinBranchInfo;\n+import org.apache.hadoop.hive.ql.plan.DynamicPruningEventDesc;\n+\n+import com.google.common.collect.Sets;\n+\n+public class OperatorGraph {\n+\n+  /**\n+   * A directed graph extended with support to check dag property.\n+   */\n+  static class DagGraph<V, E> extends DiGraph<V, E> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTYxNDkxOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HivePointLookupOptimizerRule.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowMDowOVrOHq9bgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowMDowOVrOHq9bgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgwODcwNQ==", "bodyText": "Left the comment in other class but I was thinking that it may be a good idea to promote this to top class (at least until we replace it by any other library version as we were discussing).", "url": "https://github.com/apache/hive/pull/1562#discussion_r514808705", "createdAt": "2020-10-30T04:00:09Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HivePointLookupOptimizerRule.java", "diffHunk": "@@ -189,115 +189,121 @@ public RexNode analyzeRexNode(RexBuilder rexBuilder, RexNode condition) {\n     return newCondition;\n   }\n \n-  /**\n-   * Transforms inequality candidates into [NOT] BETWEEN calls.\n-   *\n-   */\n-  protected static class RexTransformIntoBetween extends RexShuttle {\n-    private final RexBuilder rexBuilder;\n+  public static class DiGraph<V, E> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTYzMzk4OnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/llap/dynamic_partition_pruning.q.out", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowMzo0MFrOHq9pZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowMzo0MFrOHq9pZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgxMjI2MQ==", "bodyText": "Note that the filter operator is removed. We need to be careful here because not all input formats guarantee that the filter expression is being applied / does not return false positives. I would expect the Filter remains but only a single time?", "url": "https://github.com/apache/hive/pull/1562#discussion_r514812261", "createdAt": "2020-10-30T04:03:40Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/dynamic_partition_pruning.q.out", "diffHunk": "@@ -4277,37 +4277,21 @@ STAGE PLANS:\n                   alias: srcpart\n                   filterExpr: ds is not null (type: boolean)\n                   Statistics: Num rows: 2000 Data size: 389248 Basic stats: COMPLETE Column stats: COMPLETE\n-                  Filter Operator\n-                    predicate: ds is not null (type: boolean)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTY0MDAwOnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/llap/dynamic_partition_pruning.q.out", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNDo0NFrOHq9t-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNDo0NFrOHq9t-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgxMzQzMw==", "bodyText": "Any idea why this is happening?", "url": "https://github.com/apache/hive/pull/1562#discussion_r514813433", "createdAt": "2020-10-30T04:04:44Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/dynamic_partition_pruning.q.out", "diffHunk": "@@ -4317,7 +4301,7 @@ STAGE PLANS:\n                     outputColumnNames: ds\n                     Statistics: Num rows: 2000 Data size: 389248 Basic stats: COMPLETE Column stats: COMPLETE\n                     Group By Operator\n-                      aggregations: max(ds)\n+                      aggregations: min(ds)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTY0MzEzOnYy", "diffSide": "LEFT", "path": "ql/src/test/results/clientpositive/llap/vectorized_dynamic_partition_pruning.q.out", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNToxMlrOHq9wJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNToxMlrOHq9wJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgxMzk4OQ==", "bodyText": "Filter (same as mentioned previously).", "url": "https://github.com/apache/hive/pull/1562#discussion_r514813989", "createdAt": "2020-10-30T04:05:12Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/vectorized_dynamic_partition_pruning.q.out", "diffHunk": "@@ -4816,34 +4816,18 @@ STAGE PLANS:\n                   alias: srcpart\n                   filterExpr: ds is not null (type: boolean)\n                   Statistics: Num rows: 2000 Data size: 389248 Basic stats: COMPLETE Column stats: COMPLETE\n-                  Filter Operator\n-                    predicate: ds is not null (type: boolean)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTY0ODkyOnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query61.q.out", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNjowOFrOHq90dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNjowOFrOHq90dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgxNTA5NQ==", "bodyText": "new SJ?", "url": "https://github.com/apache/hive/pull/1562#discussion_r514815095", "createdAt": "2020-10-30T04:06:08Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/constraints/query61.q.out", "diffHunk": "@@ -273,6 +273,6 @@ Stage-0\n                                     Select Operator [SEL_273] (rows=501694138 width=122)\n                                       Output:[\"_col0\",\"_col1\",\"_col2\",\"_col3\",\"_col4\"]\n                                       Filter Operator [FIL_271] (rows=501694138 width=122)\n-                                        predicate:(ss_sold_date_sk is not null and ss_customer_sk is not null and ss_store_sk is not null)\n+                                        predicate:(ss_sold_date_sk is not null and ss_customer_sk is not null and ss_store_sk is not null and ss_sold_date_sk BETWEEN DynamicValue(RS_64_date_dim_d_date_sk_min) AND DynamicValue(RS_64_date_dim_d_date_sk_max) and in_bloom_filter(ss_sold_date_sk, DynamicValue(RS_64_date_dim_d_date_sk_bloom_filter)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyNTY1NjQyOnYy", "diffSide": "RIGHT", "path": "ql/src/test/results/clientpositive/perf/tez/query95.q.out", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNzoyM1rOHq959Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNDowNzoyM1rOHq959Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgxNjUwMQ==", "bodyText": "good!", "url": "https://github.com/apache/hive/pull/1562#discussion_r514816501", "createdAt": "2020-10-30T04:07:23Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/perf/tez/query95.q.out", "diffHunk": "@@ -128,7 +128,7 @@ Stage-0\n                                   Select Operator [SEL_235] (rows=144002668 width=7)\n                                     Output:[\"_col0\",\"_col1\"]\n                                     Filter Operator [FIL_234] (rows=144002668 width=7)\n-                                      predicate:(ws_order_number is not null and (ws_order_number is not null or ws_order_number is not null))\n+                                      predicate:ws_order_number is not null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14e001e3d08db27da0b4b4a6a3a65dacccbfacbc"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 336, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}