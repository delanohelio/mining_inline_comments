{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE4NzQyMTkw", "number": 1660, "title": "HIVE-23410: ACID: Improve the delete and update operations to avoid t\u2026", "bodyText": "\u2026he move step\n\nWhat changes were proposed in this pull request?\n\nWhy are the changes needed?\n\nDoes this PR introduce any user-facing change?\n\nHow was this patch tested?", "createdAt": "2020-11-10T20:21:23Z", "url": "https://github.com/apache/hive/pull/1660", "merged": true, "mergeCommit": {"oid": "f6ac13a0aadf8817958056d578883a9eb852e8dd"}, "closed": true, "closedAt": "2020-12-08T23:08:15Z", "author": {"login": "kuczoram"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbOzSigH2gAyNTE4NzQyMTkwOjFjNzJhZDg5Mzg1NjU3OWM2ZjYzZDY0YmI0MWU4OTVjZGNlNDcxZWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkPJv8AH2gAyNTE4NzQyMTkwOjNiYjhlNWIwYTZjODNjZjQ3YTdlNzVkYWFmNmE1ZWRhYTlmN2MyOTA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1c72ad893856579c6f63d64bb41e895cdce471eb", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/1c72ad893856579c6f63d64bb41e895cdce471eb", "committedDate": "2020-11-10T19:47:53Z", "message": "HIVE-23410: ACID: Improve the delete and update operations to avoid the move step"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0037a9c4df24076bb1ce2d2e90085aad1d782be", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/f0037a9c4df24076bb1ce2d2e90085aad1d782be", "committedDate": "2020-11-13T14:57:34Z", "message": "Fixed the MoveTask assignment for merge statements with multiple statements with the same ACID operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c7d7d570931cc1cc81953aee50156886e058f3d", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/7c7d7d570931cc1cc81953aee50156886e058f3d", "committedDate": "2020-11-23T18:29:27Z", "message": "Fix the MoveTask assignment if the query contains multiple statements with the same ACID operation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f32b88649c6a4b2e2a3659ccc053fa616f6ba02", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/7f32b88649c6a4b2e2a3659ccc053fa616f6ba02", "committedDate": "2020-11-24T19:17:04Z", "message": "Fix the file listings in MoveTasks for insert overwrite for mm tables"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f6edc428c7f47bc4c22ffe47d2dae3b82719d3c", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/1f6edc428c7f47bc4c22ffe47d2dae3b82719d3c", "committedDate": "2020-11-30T18:36:45Z", "message": "Fix the file listing for union all queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0720b3809a9776b3983b68a3c993fe4790a83ea4", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/0720b3809a9776b3983b68a3c993fe4790a83ea4", "committedDate": "2020-12-01T11:59:19Z", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23410-1110"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98a29c50395d50a7fcaa670c7c9ed2a69077b75f", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/98a29c50395d50a7fcaa670c7c9ed2a69077b75f", "committedDate": "2020-12-02T17:46:54Z", "message": "Fixing the acidSink sorting and some test outputs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/6f9cfcd37341fe990b4411d56ad3a4d050ec2bca", "committedDate": "2020-12-03T13:02:23Z", "message": "Fix the acidSink sorting and add ordering to the q test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MDk3MjY4", "url": "https://github.com/apache/hive/pull/1660#pullrequestreview-546097268", "createdAt": "2020-12-07T12:22:35Z", "commit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxMjoyMjozNVrOIAkPsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxMjoyMjozNVrOIAkPsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ2NDc1Mw==", "bodyText": "Is this change expected? What are these records?", "url": "https://github.com/apache/hive/pull/1660#discussion_r537464753", "createdAt": "2020-12-07T12:22:35Z", "author": {"login": "pvargacl"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/lockmgr/TestDbTxnManager2.java", "diffHunk": "@@ -1747,15 +1747,15 @@ public void testMultiInsertOnDynamicallyPartitionedMmTable() throws Exception {\n     final String completedTxnComponentsContents =\n         TxnDbUtil.queryToString(conf, \"select * from \\\"COMPLETED_TXN_COMPONENTS\\\"\");\n     Assert.assertEquals(completedTxnComponentsContents,\n-        2, TxnDbUtil.countQueryAgent(conf, \"select count(*) from \\\"COMPLETED_TXN_COMPONENTS\\\"\"));\n+        4, TxnDbUtil.countQueryAgent(conf, \"select count(*) from \\\"COMPLETED_TXN_COMPONENTS\\\"\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MjE1MTAw", "url": "https://github.com/apache/hive/pull/1660#pullrequestreview-546215100", "createdAt": "2020-12-07T14:43:37Z", "commit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "state": "APPROVED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNDo0MzozN1rOIAqGOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNTo0MjoyMFrOIAs8qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2MDYzMw==", "bodyText": "Could we start it from 0?", "url": "https://github.com/apache/hive/pull/1660#discussion_r537560633", "createdAt": "2020-12-07T14:43:37Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/Context.java", "diffHunk": "@@ -105,6 +105,7 @@\n \n   private Configuration conf;\n   protected int pathid = 10000;\n+  private int moveTaskId = 100;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2NjQxMg==", "bodyText": "Maybe javadoc instead of a comment?", "url": "https://github.com/apache/hive/pull/1660#discussion_r537566412", "createdAt": "2020-12-07T14:50:51Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java", "diffHunk": "@@ -189,6 +191,49 @@ public WriteEntity getAcidAnalyzeTable() {\n     return acidSinks;\n   }\n \n+  public Integer getStatementIdForAcidWriteType(long writeId, String moveTaskId, AcidUtils.Operation acidOperation, Path path) {\n+    FileSinkDesc result = null;\n+    for (FileSinkDesc acidSink : acidSinks) {\n+      if (acidOperation.equals(acidSink.getAcidOperation()) && path.equals(acidSink.getDestPath())\n+          && acidSink.getTableWriteId() == writeId\n+          && (moveTaskId == null || acidSink.getMoveTaskId() == null || moveTaskId.equals(acidSink.getMoveTaskId()))) {\n+        // There is a problem with the union all optimisation. In this case, there will be multiple FileSinkOperators", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2NzEzMQ==", "bodyText": "Javadoc", "url": "https://github.com/apache/hive/pull/1660#discussion_r537567131", "createdAt": "2020-12-07T14:51:42Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/QueryPlan.java", "diffHunk": "@@ -189,6 +191,49 @@ public WriteEntity getAcidAnalyzeTable() {\n     return acidSinks;\n   }\n \n+  public Integer getStatementIdForAcidWriteType(long writeId, String moveTaskId, AcidUtils.Operation acidOperation, Path path) {\n+    FileSinkDesc result = null;\n+    for (FileSinkDesc acidSink : acidSinks) {\n+      if (acidOperation.equals(acidSink.getAcidOperation()) && path.equals(acidSink.getDestPath())\n+          && acidSink.getTableWriteId() == writeId\n+          && (moveTaskId == null || acidSink.getMoveTaskId() == null || moveTaskId.equals(acidSink.getMoveTaskId()))) {\n+        // There is a problem with the union all optimisation. In this case, there will be multiple FileSinkOperators\n+        // with the same operation, writeId and moveTaskId. But one of these FSOs doesn't write data and its statementId\n+        // is not valid, so if this FSO is selected and its statementId is returned, the file listing will find nothing.\n+        // So check the acidSinks and if two of them have the same writeId, path and moveTaskId, then return -1 as statementId.\n+        // Like this, the file listing will find all partitions and files correctly.\n+        if (result != null) {\n+          return -1;\n+        }\n+        result = acidSink;\n+      }\n+    }\n+    if (result != null) {\n+      return result.getStatementId();\n+    } else {\n+      return -1;\n+    }\n+  }\n+\n+  public Set<String> getDynamicPartitionSpecs(long writeId, String moveTaskId, AcidUtils.Operation acidOperation, Path path) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU3MjM0Mw==", "bodyText": "Could we do something like a switch?", "url": "https://github.com/apache/hive/pull/1660#discussion_r537572343", "createdAt": "2020-12-07T14:57:50Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java", "diffHunk": "@@ -232,9 +236,25 @@ public void closeWriters(boolean abort) throws HiveException {\n       for (int i = 0; i < updaters.length; i++) {\n         if (updaters[i] != null) {\n           SerDeStats stats = updaters[i].getStats();\n-          // Ignore 0 row files except in case of insert overwrite\n-          if (isDirectInsert && (stats.getRowCount() > 0 || isInsertOverwrite)) {\n-            outPathsCommitted[i] = updaters[i].getUpdatedFilePath();\n+          // Ignore 0 row files except in case of insert overwrite or delete or update\n+          if (isDirectInsert\n+              && (stats.getRowCount() > 0 || isInsertOverwrite || AcidUtils.Operation.DELETE.equals(acidOperation)\n+                  || AcidUtils.Operation.UPDATE.equals(acidOperation))) {\n+            // In case of delete operation, the deleteFilePath has to be used, not the updatedFilePath\n+            // In case of update operation, we need both paths. The updateFilePath will be added\n+            // to the outPathsCommitted array and the deleteFilePath will be collected in a separate list.\n+            OrcRecordUpdater recordUpdater = (OrcRecordUpdater) updaters[i];\n+            outPathsCommitted[i] = recordUpdater.getUpdatedFilePath();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU3NjA2Ng==", "bodyText": "Think through 1 more time. I can accept that this is the best solution, but this is UGLY \ud83d\ude04", "url": "https://github.com/apache/hive/pull/1660#discussion_r537576066", "createdAt": "2020-12-07T15:02:39Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java", "diffHunk": "@@ -251,7 +271,7 @@ public void closeWriters(boolean abort) throws HiveException {\n       }\n     }\n \n-    private void commit(FileSystem fs, List<Path> commitPaths) throws HiveException {\n+    private void commit(FileSystem fs, List<Path> commitPaths, List<Path> deleteDeltas) throws HiveException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU4ODEyMw==", "bodyText": "Javadoc please", "url": "https://github.com/apache/hive/pull/1660#discussion_r537588123", "createdAt": "2020-12-07T15:17:52Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java", "diffHunk": "@@ -563,6 +564,21 @@ else if (filename.startsWith(BUCKET_PREFIX)) {\n     return result;\n   }\n \n+  public static Map<String, Integer> getDeltaToAttemptIdMap(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU5MzUwNw==", "bodyText": "Too long line", "url": "https://github.com/apache/hive/pull/1660#discussion_r537593507", "createdAt": "2020-12-07T15:24:45Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2694,7 +2699,7 @@ private void constructOneLBLocationMap(FileStatus fSta,\n    */\n   private Set<Path> getValidPartitionsInPath(\n       int numDP, int numLB, Path loadPath, Long writeId, int stmtId,\n-      boolean isMmTable, boolean isInsertOverwrite, boolean isDirectInsert) throws HiveException {\n+      boolean isMmTable, boolean isInsertOverwrite, boolean isDirectInsert, AcidUtils.Operation operation, Set<String> dynamiPartitionSpecs) throws HiveException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU5NzA3Nw==", "bodyText": "Double check if this is needed", "url": "https://github.com/apache/hive/pull/1660#discussion_r537597077", "createdAt": "2020-12-07T15:29:09Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java", "diffHunk": "@@ -1895,7 +1901,20 @@ public static boolean isSkewedStoredAsDirs(FileSinkDesc fsInputDesc) {\n       }\n \n       if ((srcDir != null) && srcDir.equals(fsopFinalDir)) {\n-        return mvTsk;\n+        if (isDirectInsert || isMmFsop) {\n+          if (moveTaskId != null && fsoMoveTaskId != null && moveTaskId.equals(fsoMoveTaskId)) {\n+            // If the ACID direct insert is on, the MoveTasks cannot be identified by the srcDir as\n+            // in this case the srcDir is always the root directory of the table.\n+            // We need to consider the ACID write type to identify the MoveTasks.\n+            return mvTsk;\n+          }\n+          if ((moveTaskId == null || fsoMoveTaskId == null) && moveTaskWriteType != null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwMTYxNw==", "bodyText": "Remove", "url": "https://github.com/apache/hive/pull/1660#discussion_r537601617", "createdAt": "2020-12-07T15:34:56Z", "author": {"login": "pvary"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/io/TestAcidInputFormat.java", "diffHunk": "@@ -52,6 +52,8 @@\n   @Mock\n   private DataInput mockDataInput;\n \n+  // IRJUNK IDE TESZTET!!!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwNjgwOA==", "bodyText": "Please file a jira", "url": "https://github.com/apache/hive/pull/1660#discussion_r537606808", "createdAt": "2020-12-07T15:41:42Z", "author": {"login": "pvary"}, "path": "ql/src/test/queries/clientpositive/materialized_view_create_rewrite_4.q", "diffHunk": "@@ -3,6 +3,7 @@ set hive.support.concurrency=true;\n set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;\n set hive.strict.checks.cartesian.product=false;\n set hive.materializedview.rewriting=true;\n+set hive.acid.direct.insert.enabled=false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwNzMzOQ==", "bodyText": "Can we sort the result file instead?", "url": "https://github.com/apache/hive/pull/1660#discussion_r537607339", "createdAt": "2020-12-07T15:42:20Z", "author": {"login": "pvary"}, "path": "ql/src/test/queries/clientpositive/sort_acid.q", "diffHunk": "@@ -16,7 +16,7 @@ explain cbo\n update acidtlb set b=777;\n update acidtlb set b=777;\n \n-select * from acidtlb;\n+select * from acidtlb order by a;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f9cfcd37341fe990b4411d56ad3a4d050ec2bca"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bb8e5b0a6c83cf47a7e75daaf6a5edaa9f7c290", "author": {"user": {"login": "kuczoram", "name": null}}, "url": "https://github.com/apache/hive/commit/3bb8e5b0a6c83cf47a7e75daaf6a5edaa9f7c290", "committedDate": "2020-12-08T19:17:44Z", "message": "Address review findings"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3025, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}