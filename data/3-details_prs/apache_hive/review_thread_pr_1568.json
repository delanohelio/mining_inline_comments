{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwODU3NDgw", "number": 1568, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzo0NzoyNlrOEs0IqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzo0NzoyNlrOEs0IqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1NDI2OTg0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzo0NzoyNlrOHgQmig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDoyODowM1rOHgRctQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU4ODQ5MA==", "bodyText": "Can we move this check to just after getting TableScanOperator i.e. line 94/95? We will avoid un-necessary checkQBpForGlobalLimit and findOperators.", "url": "https://github.com/apache/hive/pull/1568#discussion_r503588490", "createdAt": "2020-10-12T23:47:26Z", "author": {"login": "vineetgarg02"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java", "diffHunk": "@@ -99,27 +99,31 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n         LimitDesc tempGlobalLimitDesc = tempGlobalLimit.getConf();\n         Table tab = ts.getConf().getTableMetadata();\n         Set<FilterOperator> filterOps = OperatorUtils.findOperators(ts, FilterOperator.class);\n-\n-        if (!tab.isPartitioned()) {\n-          if (filterOps.size() == 0) {\n-            Integer tempOffset = tempGlobalLimitDesc.getOffset();\n-            globalLimitCtx.enableOpt(tempGlobalLimitDesc.getLimit(),\n-                (tempOffset == null) ? 0 : tempOffset);\n-          }\n-        } else {\n-          // check if the pruner only contains partition columns\n-          if (onlyContainsPartnCols(tab, filterOps)) {\n-\n-            String alias = (String) topOps.keySet().toArray()[0];\n-            PrunedPartitionList partsList = pctx.getPrunedPartitions(alias, ts);\n-\n-            // If there is any unknown partition, create a map-reduce job for\n-            // the filter to prune correctly\n-            if (!partsList.hasUnknownPartitions()) {\n+        // StorageHandlers will always have empty tablePath.\n+        // GenMapRedUtils.setMapWork removes empty tablePath from input dir with select-Limit\n+        // InputFormat.getSplits wont be called if no input path & TS Vertex will have 0 task parallelism\n+        if (tab.getStorageHandler() == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f4627086307828b82a557099b855e792dc8891ad"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjM1Nw==", "bodyText": "Handled in the new commit Vineet. Thanks for review.", "url": "https://github.com/apache/hive/pull/1568#discussion_r503602357", "createdAt": "2020-10-13T00:28:03Z", "author": {"login": "nareshpr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/GlobalLimitOptimizer.java", "diffHunk": "@@ -99,27 +99,31 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n         LimitDesc tempGlobalLimitDesc = tempGlobalLimit.getConf();\n         Table tab = ts.getConf().getTableMetadata();\n         Set<FilterOperator> filterOps = OperatorUtils.findOperators(ts, FilterOperator.class);\n-\n-        if (!tab.isPartitioned()) {\n-          if (filterOps.size() == 0) {\n-            Integer tempOffset = tempGlobalLimitDesc.getOffset();\n-            globalLimitCtx.enableOpt(tempGlobalLimitDesc.getLimit(),\n-                (tempOffset == null) ? 0 : tempOffset);\n-          }\n-        } else {\n-          // check if the pruner only contains partition columns\n-          if (onlyContainsPartnCols(tab, filterOps)) {\n-\n-            String alias = (String) topOps.keySet().toArray()[0];\n-            PrunedPartitionList partsList = pctx.getPrunedPartitions(alias, ts);\n-\n-            // If there is any unknown partition, create a map-reduce job for\n-            // the filter to prune correctly\n-            if (!partsList.hasUnknownPartitions()) {\n+        // StorageHandlers will always have empty tablePath.\n+        // GenMapRedUtils.setMapWork removes empty tablePath from input dir with select-Limit\n+        // InputFormat.getSplits wont be called if no input path & TS Vertex will have 0 task parallelism\n+        if (tab.getStorageHandler() == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU4ODQ5MA=="}, "originalCommit": {"oid": "f4627086307828b82a557099b855e792dc8891ad"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 339, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}