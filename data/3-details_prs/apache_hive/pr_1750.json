{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMzNjU4OTYx", "number": 1750, "title": "HIVE-24388: Enhance swo optimizations to merge EventOperators", "bodyText": "What changes were proposed in this pull request?\n\nWhy are the changes needed?\n\nDoes this PR introduce any user-facing change?\n\nHow was this patch tested?", "createdAt": "2020-12-07T13:10:15Z", "url": "https://github.com/apache/hive/pull/1750", "merged": true, "mergeCommit": {"oid": "19324b0194b9d60fd2f06a33bf37042c0dee4432"}, "closed": true, "closedAt": "2020-12-11T03:22:19Z", "author": {"login": "kgyrtkirk"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddE0noAH2gAyNTMzNjU4OTYxOjdmM2QxMGI5NzRlOWQ1ODExMjkxMWYxMjAyZWExMDM1MDg2N2VmZTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdk8klDAFqTU0OTcxMTUwMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7f3d10b974e9d58112911f1202ea10350867efe9", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/7f3d10b974e9d58112911f1202ea10350867efe9", "committedDate": "2020-11-16T13:18:08Z", "message": "add test\n\n(cherry picked from commit fbfe28081700d701ea5e99463d3761bdae259d15)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37e75a40232e3ff6cf4db1f9b274c4c0751c04f4", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/37e75a40232e3ff6cf4db1f9b274c4c0751c04f4", "committedDate": "2020-11-16T15:04:01Z", "message": "add debug; q.out"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebfcba96ca147156c9c3abc8fde4f5bbad1587cf", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/ebfcba96ca147156c9c3abc8fde4f5bbad1587cf", "committedDate": "2020-11-16T16:02:22Z", "message": "en"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "644f16fbada79af45ddecf66ef6987972afab26c", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/644f16fbada79af45ddecf66ef6987972afab26c", "committedDate": "2020-11-17T14:53:41Z", "message": "accept"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "751ad448d1a1891dedb75b073e3a20b3e5a1d717", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/751ad448d1a1891dedb75b073e3a20b3e5a1d717", "committedDate": "2020-11-19T11:40:17Z", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24388-event-merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5576d77bfae7f1c6b9222f2de865c4aa2be7ff91", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/5576d77bfae7f1c6b9222f2de865c4aa2be7ff91", "committedDate": "2020-11-19T11:41:05Z", "message": "(X) HIVE-23965: Improve plan regression tests using TPCDS30TB metastore dump and custom configs\n\ncommit 7ad4c9d6af0e840213ad5da41f1b42ff3e83bfeb\nAuthor: Stamatis Zampetakis <zabetak@gmail.com>\nDate:   Mon Jun 15 21:09:14 2020 +0200\n\n    HIVE-23965: Improve plan regression tests using TPCDS30TB metastore dump and custom configs\n\n    1. Add new perf driver, TestTezTPCDS30TBCliDriver, relying on a dockerized metastore.\n    2. Use Dockerized postgres metastore with TPC-DS 30TB dump\n    3. Remove old drivers (with and without constraints), related classes\n    (e.g., MetastoreDumpUtility), and resources.\n\n    After discussion in the JIRA we decided that keeping the old drivers\n    is most likely useless.\n\n    4. Use Hive config properties obtained and curated from real-life usages\n    5. Allow AbstractCliConfig to override metastore DB type\n    6. Rework CorePerfCliDriver to allow pre-initialized metastores\n\n    Remove system property settings in the initialization of the driver and\n    leave in the configuration to set it up if needed. This is necessary to\n    be able to use the driver with a preinitialised metastore.\n\n    Remove redundant logs in System.err. Logging and throwing an exception\n    is an anti-pattern.\n\n    Replace assertions with exceptions and improve the messages.\n\n    7. Upgrade postgres JDBC driver to version 42.2.14 to be compatible\n    with the docker image used\n    8. Update path to new postgres version in TestBeelineArgParsing\n    9. Display plans using hive.explain.user set to false which seems\n    to be preferrable for performing a diff and checking regressions\n\n    10. Disable queries 14 (HIVE-24167), 30 (HIVE-23964)\n    11. Re-enable CBO plan tests for queries 44, 45, 67, 70, 86\n\n    The queries were disabled as part of HIVE-20718. They were supposed to\n    be fixed in Calcite 1.18.0 and currently Hive is in 1.21.0 so it is not\n    surprising that they pass.\n\n    12. Add missing queries: cbo_query41, cbo_query62, query62\n\ncommit 4ee53365d94f127131332f3e552c8cac3ce9938e\nAuthor: Stamatis Zampetakis <zabetak@gmail.com>\nDate:   Tue Nov 17 11:13:22 2020 +0100\n\n    HIVE-24395: Intermittent failures to initialize dockerized Postgres metastore in tests\n\n    Ensure the Postgres init process is complete the database port is open\n    and accepting connections before declaring the container ready.\n\ncommit a2815c2bf6152e7fd35612450f370fe5a5b10b8d\nAuthor: Stamatis Zampetakis <zabetak@gmail.com>\nDate:   Tue Jun 16 22:17:10 2020 +0200\n\n    HIVE-23742: Remove unintentional execution of TPC-DS query39 in qtests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e100138eb48108d853ec0b30cb9a0dcd6cf1231f", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/e100138eb48108d853ec0b30cb9a0dcd6cf1231f", "committedDate": "2020-12-04T13:11:34Z", "message": "Revert \"(X) HIVE-23965: Improve plan regression tests using TPCDS30TB metastore dump and custom configs\"\n\nThis reverts commit 5576d77bfae7f1c6b9222f2de865c4aa2be7ff91."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7df746bf5055a89a7fec678340340f02d312f00b", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/7df746bf5055a89a7fec678340340f02d312f00b", "committedDate": "2020-12-04T13:11:38Z", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24388-event-merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb66915b6a89b8a77f610062022374c078c6eeb2", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/cb66915b6a89b8a77f610062022374c078c6eeb2", "committedDate": "2020-12-04T15:30:00Z", "message": "accept qouts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80fa406b1a330bbbc297974128d0300bc0572475", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/80fa406b1a330bbbc297974128d0300bc0572475", "committedDate": "2020-12-07T09:34:41Z", "message": "dont traverse event operators during valiudation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d74bb58db59b58f89a70a35aba0001ecd1cd10f", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/3d74bb58db59b58f89a70a35aba0001ecd1cd10f", "committedDate": "2020-12-07T10:03:02Z", "message": "doesnt count eventop in parent/child relationg; optree vill filter out inbvalid cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d0dd60f225aaeec8852d34c5bb8fe89d30a35d6", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/9d0dd60f225aaeec8852d34c5bb8fe89d30a35d6", "committedDate": "2020-12-07T10:13:19Z", "message": "Revert \"doesnt count eventop in parent/child relationg; optree vill filter out inbvalid cases\"\n\nThis reverts commit 3d74bb58db59b58f89a70a35aba0001ecd1cd10f."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bfaba51305e4f533f2571d58b8579ad9aeac3873", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/bfaba51305e4f533f2571d58b8579ad9aeac3873", "committedDate": "2020-12-07T11:18:28Z", "message": "add mayRemoveInputs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f74c516cad84c89310b4f1be1c04e28405089e7a", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/f74c516cad84c89310b4f1be1c04e28405089e7a", "committedDate": "2020-12-07T11:19:50Z", "message": "Revert \"Revert \"doesnt count eventop in parent/child relationg; optree vill filter out inbvalid cases\"\"\n\nThis reverts commit 9d0dd60f225aaeec8852d34c5bb8fe89d30a35d6."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2966843a31d895bd9a407e33cec90b0221516069", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/2966843a31d895bd9a407e33cec90b0221516069", "committedDate": "2020-12-07T11:20:00Z", "message": "Revert \"dont traverse event operators during valiudation\"\n\nThis reverts commit 80fa406b1a330bbbc297974128d0300bc0572475."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea312679dbb3abe915c86a9bc74e666f461941ff", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/ea312679dbb3abe915c86a9bc74e666f461941ff", "committedDate": "2020-12-07T11:59:34Z", "message": "re-patch/etc;"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eda0089e21f5f81833b4f020cfebe72774aa3c83", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/eda0089e21f5f81833b4f020cfebe72774aa3c83", "committedDate": "2020-12-07T13:09:31Z", "message": "accept q2 - removed parallel edge!"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "472b7e62535f72c5d56db812914a951dca57431d", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/472b7e62535f72c5d56db812914a951dca57431d", "committedDate": "2020-12-07T15:04:30Z", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24388-event-merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6c44d152f729cb4d3ae4697e20ce7ffb2a4d3d9", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/e6c44d152f729cb4d3ae4697e20ce7ffb2a4d3d9", "committedDate": "2020-12-07T15:45:20Z", "message": "fixup q75"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/fd8cc61dc2b047585392cdf2aa2a829c11cc3caf", "committedDate": "2020-12-07T15:46:04Z", "message": "remove file writes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NjY4NTUy", "url": "https://github.com/apache/hive/pull/1750#pullrequestreview-548668552", "createdAt": "2020-12-09T22:30:48Z", "commit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMjozMDo0OFrOICsgxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQyMzowODoxNlrOICtpUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY5NzM1MA==", "bodyText": "Needed?", "url": "https://github.com/apache/hive/pull/1750#discussion_r539697350", "createdAt": "2020-12-09T22:30:48Z", "author": {"login": "jcamachor"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -17,6 +17,7 @@\n  */\n package org.apache.hadoop.hive.ql.optimizer;\n \n+import java.io.File;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNTkyMw==", "bodyText": "Could merging these TS operators be effectively worse?\nFor instance, in this specific mock query, no partition will be pruned for the x1_store_sales table, while before partition pruning was kicking in. Thus, in this case, you are scanning the same data whether you have one or two TS operators (two partitions), however after merging the TS, the size of the data you are shuffling for the join doubles (data in both partitions twice)? Is that analysis correct?\nOff the top of my head, this could be beneficial if i) both TS only select a small subset of the partitions in the table, or ii) overlapping in the partition list for those two different TS is greater than a certain threshold. Should we work in that direction, i.e., introduce some config parameters for this?\n@rbalamohan , what is your take? It would be helpful to have a second opinion.", "url": "https://github.com/apache/hive/pull/1750#discussion_r539715923", "createdAt": "2020-12-09T23:08:16Z", "author": {"login": "jcamachor"}, "path": "ql/src/test/results/clientpositive/llap/swo_event_merge.q.out", "diffHunk": "@@ -0,0 +1,291 @@\n+PREHOOK: query: drop table if exists x1_store_sales\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_store_sales\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_date_dim\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_date_dim\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: drop table if exists x1_item\n+PREHOOK: type: DROPTABLE\n+POSTHOOK: query: drop table if exists x1_item\n+POSTHOOK: type: DROPTABLE\n+PREHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_store_sales\n+POSTHOOK: query: create table x1_store_sales \n+(\n+\tss_item_sk\tint\n+)\n+partitioned by (ss_sold_date_sk int)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_store_sales\n+PREHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+PREHOOK: type: CREATETABLE\n+PREHOOK: Output: database:default\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: create table x1_date_dim\n+(\n+\td_date_sk\tint,\n+\td_month_seq\tint,\n+\td_year\t\tint,\n+\td_moy\t\tint\n+)\n+stored as orc\n+POSTHOOK: type: CREATETABLE\n+POSTHOOK: Output: database:default\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: insert into x1_date_dim values\t(1,1,2000,2),\n+\t\t\t\t(2,2,2001,2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_date_dim\n+POSTHOOK: Lineage: x1_date_dim.d_date_sk SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_month_seq SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_moy SCRIPT []\n+POSTHOOK: Lineage: x1_date_dim.d_year SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=1) values (1)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=1).ss_item_sk SCRIPT []\n+PREHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+PREHOOK: type: QUERY\n+PREHOOK: Input: _dummy_database@_dummy_table\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: query: insert into x1_store_sales partition (ss_sold_date_sk=2) values (2)\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: _dummy_database@_dummy_table\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=2\n+POSTHOOK: Lineage: x1_store_sales PARTITION(ss_sold_date_sk=2).ss_item_sk SCRIPT []\n+PREHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+PREHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: query: alter table x1_store_sales partition (ss_sold_date_sk=1) update statistics set(\n+'numRows'='123456',\n+'rawDataSize'='1234567')\n+POSTHOOK: type: ALTERTABLE_UPDATEPARTSTATS\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Output: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+PREHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Output: default@x1_date_dim\n+POSTHOOK: query: alter table x1_date_dim update statistics set(\n+'numRows'='56',\n+'rawDataSize'='81449')\n+POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Output: default@x1_date_dim\n+PREHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+PREHOOK: type: QUERY\n+PREHOOK: Input: default@x1_date_dim\n+PREHOOK: Input: default@x1_store_sales\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+PREHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+POSTHOOK: query: explain \n+select   count(*) cnt\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2000\n+union\n+select   s.ss_item_sk*d_date_sk\n+ from\n+     x1_store_sales s\n+     ,x1_date_dim d\n+ where  \n+\t1=1\n+\tand s.ss_sold_date_sk = d.d_date_sk\n+\tand d.d_year=2001\n+\tgroup by s.ss_item_sk*d_date_sk\n+POSTHOOK: type: QUERY\n+POSTHOOK: Input: default@x1_date_dim\n+POSTHOOK: Input: default@x1_store_sales\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=1\n+POSTHOOK: Input: default@x1_store_sales@ss_sold_date_sk=2\n+#### A masked pattern was here ####\n+Plan optimized by CBO.\n+\n+Vertex dependency in root stage\n+Reducer 2 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE), Union 4 (CONTAINS)\n+Reducer 5 <- Union 4 (SIMPLE_EDGE)\n+Reducer 6 <- Map 1 (SIMPLE_EDGE), Map 8 (SIMPLE_EDGE)\n+Reducer 7 <- Reducer 6 (SIMPLE_EDGE), Union 4 (CONTAINS)\n+\n+Stage-0\n+  Fetch Operator\n+    limit:-1\n+    Stage-1\n+      Reducer 5 vectorized, llap\n+      File Output Operator [FS_89]\n+        Group By Operator [GBY_88] (rows=1 width=8)\n+          Output:[\"_col0\"],keys:KEY._col0\n+        <-Union 4 [SIMPLE_EDGE]\n+          <-Reducer 3 [CONTAINS] vectorized, llap\n+            Reduce Output Operator [RS_87]\n+              PartitionCols:_col0\n+              Group By Operator [GBY_86] (rows=1 width=8)\n+                Output:[\"_col0\"],keys:_col0\n+                Group By Operator [GBY_85] (rows=1 width=8)\n+                  Output:[\"_col0\"],aggregations:[\"count(VALUE._col0)\"]\n+                <-Reducer 2 [CUSTOM_SIMPLE_EDGE] llap\n+                  PARTITION_ONLY_SHUFFLE [RS_11]\n+                    Group By Operator [GBY_10] (rows=1 width=8)\n+                      Output:[\"_col0\"],aggregations:[\"count()\"]\n+                      Merge Join Operator [MERGEJOIN_51] (rows=1728398 width=8)\n+                        Conds:RS_71._col0=RS_77._col0(Inner)\n+                      <-Map 1 [SIMPLE_EDGE] vectorized, llap\n+                        SHUFFLE [RS_71]\n+                          PartitionCols:_col0\n+                          Select Operator [SEL_69] (rows=123457 width=4)\n+                            Output:[\"_col0\"]\n+                            Filter Operator [FIL_68]\n+                              predicate:ss_sold_date_sk is not null\n+                              TableScan [TS_0] (rows=123457 width=14)\n+                                default@x1_store_sales,s,Tbl:COMPLETE,Col:COMPLETE,Output:[\"ss_item_sk\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fd8cc61dc2b047585392cdf2aa2a829c11cc3caf"}, "originalPosition": 199}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb1d52d71f71628bb0d7e338c889c679e662c8c6", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/eb1d52d71f71628bb0d7e338c889c679e662c8c6", "committedDate": "2020-12-10T16:20:35Z", "message": "remove import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1af5bb83b5749295eb1ecfe9843338d30dc80ac7", "author": {"user": {"login": "kgyrtkirk", "name": "Zoltan Haindrich"}}, "url": "https://github.com/apache/hive/commit/1af5bb83b5749295eb1ecfe9843338d30dc80ac7", "committedDate": "2020-12-10T16:24:49Z", "message": "add config knob"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NzExNTAz", "url": "https://github.com/apache/hive/pull/1750#pullrequestreview-549711503", "createdAt": "2020-12-11T00:12:46Z", "commit": {"oid": "1af5bb83b5749295eb1ecfe9843338d30dc80ac7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2877, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}