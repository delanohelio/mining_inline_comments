{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3MjI2Njg0", "number": 1400, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMjoxMTozMFrOEdsrSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxMTo0NTozN1rOEzQrig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTc2MTM5OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMjoxMTozMFrOHJAyNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxMTo0NDoxNlrOHqYBKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxMjA4Nw==", "bodyText": "I think we should be merging the child into the parent inside this \"if\" - and we have 2  specific conditionals which are handled - so I think an else false here would be needed - to close down unhandled future cases", "url": "https://github.com/apache/hive/pull/1400#discussion_r479212087", "createdAt": "2020-08-28T12:11:30Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {\n+        ArrayList<String> keyColNames = Lists.newArrayList();\n+        for (ExprNodeDesc keyCol : pRS.getConf().getKeyCols()) {\n+          String keyColName = keyCol.getExprString();\n+          keyColNames.add(keyColName);\n+        }\n+        List<FieldSchema> fields = PlanUtils.getFieldSchemasFromColumnList(pRS.getConf().getKeyCols(),\n+            keyColNames, 0, \"\");\n+        TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(fields, pRS.getConf().getOrder(),\n+            pRS.getConf().getNullOrder());\n+        ArrayList<String> outputKeyCols = Lists.newArrayList();\n+        for (int i = 0; i < fields.size(); i++) {\n+          outputKeyCols.add(fields.get(i).getName());\n+        }\n+        pRS.getConf().setOutputKeyColumnNames(outputKeyCols);\n+        pRS.getConf().setKeySerializeInfo(keyTable);\n+        pRS.getConf().setNumDistributionKeys(cRS.getConf().getNumDistributionKeys());\n       }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTg5NDEyOA==", "bodyText": "Such case would arise only when both pRS keyCol is not empty and cRS keyCol is empty, In such cases wouldn't it be correct to return to true and go with the pRS values. I mean by the time the program pointer reaches here there would have been some merging of cRS to pRS would have happened upstream.", "url": "https://github.com/apache/hive/pull/1400#discussion_r479894128", "createdAt": "2020-08-31T05:24:31Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {\n+        ArrayList<String> keyColNames = Lists.newArrayList();\n+        for (ExprNodeDesc keyCol : pRS.getConf().getKeyCols()) {\n+          String keyColName = keyCol.getExprString();\n+          keyColNames.add(keyColName);\n+        }\n+        List<FieldSchema> fields = PlanUtils.getFieldSchemasFromColumnList(pRS.getConf().getKeyCols(),\n+            keyColNames, 0, \"\");\n+        TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(fields, pRS.getConf().getOrder(),\n+            pRS.getConf().getNullOrder());\n+        ArrayList<String> outputKeyCols = Lists.newArrayList();\n+        for (int i = 0; i < fields.size(); i++) {\n+          outputKeyCols.add(fields.get(i).getName());\n+        }\n+        pRS.getConf().setOutputKeyColumnNames(outputKeyCols);\n+        pRS.getConf().setKeySerializeInfo(keyTable);\n+        pRS.getConf().setNumDistributionKeys(cRS.getConf().getNumDistributionKeys());\n       }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxMjA4Nw=="}, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTcxOTY3NA==", "bodyText": "Just to add more context here, Number of distribution keys of cRS is chosen only when numDistKeys of pRS is 0 or less. In all other cases, distribution of the keys is based on the pRS which is more generic than cRS. We will enter this \"if\" condition only in two cases\n\npRS keyCol is empty and cRS keyCol is empty\npRS keyCol is empty and cRS keyCol is not empty\n\nSo in case I we would like to keep the pRS properties intact since pRS is more generic. In case (2) we want to go with cRS properties hence i think returning false is not required.\nDoes this make sense? Or am i missing any thing?", "url": "https://github.com/apache/hive/pull/1400#discussion_r495719674", "createdAt": "2020-09-28T06:43:45Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {\n+        ArrayList<String> keyColNames = Lists.newArrayList();\n+        for (ExprNodeDesc keyCol : pRS.getConf().getKeyCols()) {\n+          String keyColName = keyCol.getExprString();\n+          keyColNames.add(keyColName);\n+        }\n+        List<FieldSchema> fields = PlanUtils.getFieldSchemasFromColumnList(pRS.getConf().getKeyCols(),\n+            keyColNames, 0, \"\");\n+        TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(fields, pRS.getConf().getOrder(),\n+            pRS.getConf().getNullOrder());\n+        ArrayList<String> outputKeyCols = Lists.newArrayList();\n+        for (int i = 0; i < fields.size(); i++) {\n+          outputKeyCols.add(fields.get(i).getName());\n+        }\n+        pRS.getConf().setOutputKeyColumnNames(outputKeyCols);\n+        pRS.getConf().setKeySerializeInfo(keyTable);\n+        pRS.getConf().setNumDistributionKeys(cRS.getConf().getNumDistributionKeys());\n       }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxMjA4Nw=="}, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDE5NTc1NQ==", "bodyText": "yes; you are correct", "url": "https://github.com/apache/hive/pull/1400#discussion_r514195755", "createdAt": "2020-10-29T11:44:16Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {\n+        ArrayList<String> keyColNames = Lists.newArrayList();\n+        for (ExprNodeDesc keyCol : pRS.getConf().getKeyCols()) {\n+          String keyColName = keyCol.getExprString();\n+          keyColNames.add(keyColName);\n+        }\n+        List<FieldSchema> fields = PlanUtils.getFieldSchemasFromColumnList(pRS.getConf().getKeyCols(),\n+            keyColNames, 0, \"\");\n+        TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(fields, pRS.getConf().getOrder(),\n+            pRS.getConf().getNullOrder());\n+        ArrayList<String> outputKeyCols = Lists.newArrayList();\n+        for (int i = 0; i < fields.size(); i++) {\n+          outputKeyCols.add(fields.get(i).getName());\n+        }\n+        pRS.getConf().setOutputKeyColumnNames(outputKeyCols);\n+        pRS.getConf().setKeySerializeInfo(keyTable);\n+        pRS.getConf().setNumDistributionKeys(cRS.getConf().getNumDistributionKeys());\n       }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxMjA4Nw=="}, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTc4OTkwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMjoxNTo1MFrOHJBFFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQwNDozOTo0MFrOHJpyWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxNjkxNw==", "bodyText": "don't we need any conditional on pRS here?", "url": "https://github.com/apache/hive/pull/1400#discussion_r479216917", "createdAt": "2020-08-28T12:15:50Z", "author": {"login": "kgyrtkirk"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTg4Mzg2Ng==", "bodyText": "setNumDistributionKeys is a subset of keycols, We enters this conditions only when NumDistributionKeys of pRS is null or <= 0. Hence checking for pRS doesn't make sense here since we anyhow want to go with cRS.", "url": "https://github.com/apache/hive/pull/1400#discussion_r479883866", "createdAt": "2020-08-31T04:39:40Z", "author": {"login": "shameersss1"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplicationUtils.java", "diffHunk": "@@ -181,6 +183,23 @@ public static boolean merge(HiveConf hiveConf, ReduceSinkOperator cRS, ReduceSin\n         TableDesc keyTable = PlanUtils.getReduceKeyTableDesc(new ArrayList<FieldSchema>(), pRS\n             .getConf().getOrder(), pRS.getConf().getNullOrder());\n         pRS.getConf().setKeySerializeInfo(keyTable);\n+      } else if (cRS.getConf().getKeyCols() != null && cRS.getConf().getKeyCols().size() > 0) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIxNjkxNw=="}, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyMTg2MTIyOnYy", "diffSide": "RIGHT", "path": "itests/src/test/resources/testconfiguration.properties", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxMTo0NTozOFrOHqYD4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQwNToxODozNFrOHrBX7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDE5NjQ1MQ==", "bodyText": "do we need to run this test with minitez - or it may run with minillaplocal?", "url": "https://github.com/apache/hive/pull/1400#discussion_r514196451", "createdAt": "2020-10-29T11:45:38Z", "author": {"login": "kgyrtkirk"}, "path": "itests/src/test/resources/testconfiguration.properties", "diffHunk": "@@ -6,6 +6,7 @@ minimr.query.files=\\\n \n # Queries ran by both MiniLlapLocal and MiniTez\n minitez.query.files.shared=\\\n+  dynpart_sort_optimization_distribute_by.q,\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg3MzMyNw==", "bodyText": "For some reason, The issue is not reproducible with LLAP, Hence running this with mini tez", "url": "https://github.com/apache/hive/pull/1400#discussion_r514873327", "createdAt": "2020-10-30T05:18:34Z", "author": {"login": "shameersss1"}, "path": "itests/src/test/resources/testconfiguration.properties", "diffHunk": "@@ -6,6 +6,7 @@ minimr.query.files=\\\n \n # Queries ran by both MiniLlapLocal and MiniTez\n minitez.query.files.shared=\\\n+  dynpart_sort_optimization_distribute_by.q,\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDE5NjQ1MQ=="}, "originalCommit": {"oid": "1ac7b0f70e07faa87ce75669d65040f983027a6e"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 518, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}