{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyMTEwODQ1", "number": 1419, "reviewThreads": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNToyMzoyMVrOEcarlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNToxMDoyMVrOEi4gQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4MjMyNzI3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNToyMzoyMVrOHG8RNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNTozMTozNVrOHG8bSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0MDk1MQ==", "bodyText": "Let's have a followup jira to have overall one db call to fetch all constraints instead of having one for each type of constraint.", "url": "https://github.com/apache/hive/pull/1419#discussion_r477040951", "createdAt": "2020-08-26T05:23:21Z", "author": {"login": "adesh-rao"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java", "diffHunk": "@@ -11286,6 +11287,20 @@ private String getPrimaryKeyConstraintName(String catName, String dbName, String\n     return notNullConstraints;\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)\n+      throws MetaException {\n+    debugLog(\"Get all table constraints for the table - \" + catName + \".\"+ db_name+\".\"+tbl_name + \" in class ObjectStore.java\");\n+    SQLAllTableConstraints sqlAllTableConstraints = new SQLAllTableConstraints();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cca559a7655bf1468262d64f180b51f51dfa89b7"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0MzUzMA==", "bodyText": "https://issues.apache.org/jira/browse/HIVE-24062", "url": "https://github.com/apache/hive/pull/1419#discussion_r477043530", "createdAt": "2020-08-26T05:31:35Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java", "diffHunk": "@@ -11286,6 +11287,20 @@ private String getPrimaryKeyConstraintName(String catName, String dbName, String\n     return notNullConstraints;\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)\n+      throws MetaException {\n+    debugLog(\"Get all table constraints for the table - \" + catName + \".\"+ db_name+\".\"+tbl_name + \" in class ObjectStore.java\");\n+    SQLAllTableConstraints sqlAllTableConstraints = new SQLAllTableConstraints();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0MDk1MQ=="}, "originalCommit": {"oid": "cca559a7655bf1468262d64f180b51f51dfa89b7"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4MjMzNjA4OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNToyNzo1M1rOHG8Wow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwNzo1NToxMlrOHHAPZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0MjMzOQ==", "bodyText": "Also add tests for\n\nall non-empty constraints\nfew constraints are present\nmore than 1 constraints are present of a single type on one table.\nhaving multiple tables and then fetching the constraints", "url": "https://github.com/apache/hive/pull/1419#discussion_r477042339", "createdAt": "2020-08-26T05:27:53Z", "author": {"login": "adesh-rao"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)\n+public class TestGetAllTableConstraints extends MetaStoreClientTest {\n+  private static final String OTHER_DATABASE = \"test_constraints_other_database\";\n+  private static final String OTHER_CATALOG = \"test_constraints_other_catalog\";\n+  private static final String DATABASE_IN_OTHER_CATALOG = \"test_constraints_database_in_other_catalog\";\n+  private final AbstractMetaStoreService metaStore;\n+  private IMetaStoreClient client;\n+  private Table[] testTables = new Table[3];\n+  private Database inOtherCatalog;\n+\n+  public TestGetAllTableConstraints(String name, AbstractMetaStoreService metaStore) throws Exception {\n+    this.metaStore = metaStore;\n+  }\n+  @Before\n+  public void setUp() throws Exception {\n+    // Get new client\n+    client = metaStore.getClient();\n+\n+    // Clean up the database\n+    client.dropDatabase(OTHER_DATABASE, true, true, true);\n+    // Drop every table in the default database\n+    for(String tableName : client.getAllTables(DEFAULT_DATABASE_NAME)) {\n+      client.dropTable(DEFAULT_DATABASE_NAME, tableName, true, true, true);\n+    }\n+\n+    client.dropDatabase(OTHER_CATALOG, DATABASE_IN_OTHER_CATALOG, true, true, true);\n+    try {\n+      client.dropCatalog(OTHER_CATALOG);\n+    } catch (NoSuchObjectException e) {\n+      // NOP\n+    }\n+\n+    // Clean up trash\n+    metaStore.cleanWarehouseDirs();\n+\n+    new DatabaseBuilder().setName(OTHER_DATABASE).create(client, metaStore.getConf());\n+\n+    Catalog cat = new CatalogBuilder()\n+        .setName(OTHER_CATALOG)\n+        .setLocation(MetaStoreTestUtils.getTestWarehouseDir(OTHER_CATALOG))\n+        .build();\n+    client.createCatalog(cat);\n+\n+    // For this one don't specify a location to make sure it gets put in the catalog directory\n+    inOtherCatalog = new DatabaseBuilder()\n+        .setName(DATABASE_IN_OTHER_CATALOG)\n+        .setCatalogName(OTHER_CATALOG)\n+        .create(client, metaStore.getConf());\n+\n+    testTables[0] =\n+        new TableBuilder()\n+            .setTableName(\"test_table_1\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    testTables[1] =\n+        new TableBuilder()\n+            .setDbName(OTHER_DATABASE)\n+            .setTableName(\"test_table_2\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    testTables[2] =\n+        new TableBuilder()\n+            .inDb(inOtherCatalog)\n+            .setTableName(\"test_table_3\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    // Reload tables from the MetaStore\n+    for(int i=0; i < testTables.length; i++) {\n+      testTables[i] = client.getTable(testTables[i].getCatName(), testTables[i].getDbName(),\n+          testTables[i].getTableName());\n+    }\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (client != null) {\n+        try {\n+          client.close();\n+        } catch (Exception e) {\n+          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira\n+        }\n+      }\n+    } finally {\n+      client = null;\n+    }\n+  }\n+\n+\n+  @Test\n+  public void NoConstraints() throws TException{\n+    Table table = testTables[0];\n+\n+    // Make sure get on a table with no key returns empty list\n+    PrimaryKeysRequest rqst =\n+        new PrimaryKeysRequest(table.getDbName(), table.getTableName());\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(),table.getTableName());\n+\n+    request.setCatName(table.getCatName());\n+    rqst.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+    Assert.assertTrue(fetched.getDefaultConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getNotNullConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getPrimaryKeys().isEmpty());\n+    Assert.assertTrue(fetched.getUniqueConstraints().isEmpty());\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cca559a7655bf1468262d64f180b51f51dfa89b7"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzEwNjAyMA==", "bodyText": "Test added", "url": "https://github.com/apache/hive/pull/1419#discussion_r477106020", "createdAt": "2020-08-26T07:55:12Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)\n+public class TestGetAllTableConstraints extends MetaStoreClientTest {\n+  private static final String OTHER_DATABASE = \"test_constraints_other_database\";\n+  private static final String OTHER_CATALOG = \"test_constraints_other_catalog\";\n+  private static final String DATABASE_IN_OTHER_CATALOG = \"test_constraints_database_in_other_catalog\";\n+  private final AbstractMetaStoreService metaStore;\n+  private IMetaStoreClient client;\n+  private Table[] testTables = new Table[3];\n+  private Database inOtherCatalog;\n+\n+  public TestGetAllTableConstraints(String name, AbstractMetaStoreService metaStore) throws Exception {\n+    this.metaStore = metaStore;\n+  }\n+  @Before\n+  public void setUp() throws Exception {\n+    // Get new client\n+    client = metaStore.getClient();\n+\n+    // Clean up the database\n+    client.dropDatabase(OTHER_DATABASE, true, true, true);\n+    // Drop every table in the default database\n+    for(String tableName : client.getAllTables(DEFAULT_DATABASE_NAME)) {\n+      client.dropTable(DEFAULT_DATABASE_NAME, tableName, true, true, true);\n+    }\n+\n+    client.dropDatabase(OTHER_CATALOG, DATABASE_IN_OTHER_CATALOG, true, true, true);\n+    try {\n+      client.dropCatalog(OTHER_CATALOG);\n+    } catch (NoSuchObjectException e) {\n+      // NOP\n+    }\n+\n+    // Clean up trash\n+    metaStore.cleanWarehouseDirs();\n+\n+    new DatabaseBuilder().setName(OTHER_DATABASE).create(client, metaStore.getConf());\n+\n+    Catalog cat = new CatalogBuilder()\n+        .setName(OTHER_CATALOG)\n+        .setLocation(MetaStoreTestUtils.getTestWarehouseDir(OTHER_CATALOG))\n+        .build();\n+    client.createCatalog(cat);\n+\n+    // For this one don't specify a location to make sure it gets put in the catalog directory\n+    inOtherCatalog = new DatabaseBuilder()\n+        .setName(DATABASE_IN_OTHER_CATALOG)\n+        .setCatalogName(OTHER_CATALOG)\n+        .create(client, metaStore.getConf());\n+\n+    testTables[0] =\n+        new TableBuilder()\n+            .setTableName(\"test_table_1\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    testTables[1] =\n+        new TableBuilder()\n+            .setDbName(OTHER_DATABASE)\n+            .setTableName(\"test_table_2\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    testTables[2] =\n+        new TableBuilder()\n+            .inDb(inOtherCatalog)\n+            .setTableName(\"test_table_3\")\n+            .addCol(\"col1\", \"int\")\n+            .addCol(\"col2\", \"varchar(32)\")\n+            .create(client, metaStore.getConf());\n+\n+    // Reload tables from the MetaStore\n+    for(int i=0; i < testTables.length; i++) {\n+      testTables[i] = client.getTable(testTables[i].getCatName(), testTables[i].getDbName(),\n+          testTables[i].getTableName());\n+    }\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (client != null) {\n+        try {\n+          client.close();\n+        } catch (Exception e) {\n+          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira\n+        }\n+      }\n+    } finally {\n+      client = null;\n+    }\n+  }\n+\n+\n+  @Test\n+  public void NoConstraints() throws TException{\n+    Table table = testTables[0];\n+\n+    // Make sure get on a table with no key returns empty list\n+    PrimaryKeysRequest rqst =\n+        new PrimaryKeysRequest(table.getDbName(), table.getTableName());\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(),table.getTableName());\n+\n+    request.setCatName(table.getCatName());\n+    rqst.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+    Assert.assertTrue(fetched.getDefaultConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getNotNullConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getPrimaryKeys().isEmpty());\n+    Assert.assertTrue(fetched.getUniqueConstraints().isEmpty());\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0MjMzOQ=="}, "originalCommit": {"oid": "cca559a7655bf1468262d64f180b51f51dfa89b7"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzE3NTg1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzozMjoyM1rOHJO52g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyMzoyOFrOHQzCBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0MzQxOA==", "bodyText": "Nit: Annotation and api signature can be in separate lines.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479443418", "createdAt": "2020-08-28T17:32:23Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java", "diffHunk": "@@ -1014,6 +1015,11 @@ public FileMetadataHandler getFileMetadataHandler(FileMetadataExprType type) {\n     return null;\n   }\n \n+  @Override public SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTM2Nw==", "bodyText": "Done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375367", "createdAt": "2020-09-12T06:23:28Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/DummyRawStoreForJdoConnection.java", "diffHunk": "@@ -1014,6 +1015,11 @@ public FileMetadataHandler getFileMetadataHandler(FileMetadataExprType type) {\n     return null;\n   }\n \n+  @Override public SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0MzQxOA=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzE4MDUyOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzozNDowMlrOHJO88A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyMzozNVrOHQzCDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0NDIwOA==", "bodyText": "Follow uniform naming style for arguments.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479444208", "createdAt": "2020-08-28T17:34:02Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java", "diffHunk": "@@ -1485,6 +1485,16 @@ void getFileMetadataByExpr(List<Long> fileIds, FileMetadataExprType type, byte[]\n   List<SQLCheckConstraint> getCheckConstraints(String catName, String db_name,\n                                                    String tbl_name) throws MetaException;\n \n+  /**\n+   *  Get all constraints of the table\n+   * @param catName catalog name\n+   * @param db_name database name\n+   * @param tbl_name table name\n+   * @return all constraints for this table\n+   * @throws MetaException error accessing the RDBMS\n+   */\n+  SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTM3Mg==", "bodyText": "Done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375372", "createdAt": "2020-09-12T06:23:35Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/RawStore.java", "diffHunk": "@@ -1485,6 +1485,16 @@ void getFileMetadataByExpr(List<Long> fileIds, FileMetadataExprType type, byte[]\n   List<SQLCheckConstraint> getCheckConstraints(String catName, String db_name,\n                                                    String tbl_name) throws MetaException;\n \n+  /**\n+   *  Get all constraints of the table\n+   * @param catName catalog name\n+   * @param db_name database name\n+   * @param tbl_name table name\n+   * @return all constraints for this table\n+   * @throws MetaException error accessing the RDBMS\n+   */\n+  SQLAllTableConstraints getAllTableConstraints(String catName, String db_name, String tbl_name)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0NDIwOA=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzIyNTY3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0OTo1MFrOHJPZjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyMzo0M1rOHQzCEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1MTUzMw==", "bodyText": "I think, it is redundant as HMS also logs the time taken by get_all_table_constraints api.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479451533", "createdAt": "2020-08-28T17:49:50Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)\n+      throws MetaException, NoSuchObjectException, TException {\n+    long t1 = System.currentTimeMillis();\n+\n+    try {\n+      if (!req.isSetCatName()) {\n+        req.setCatName(getDefaultCatalog(conf));\n+      }\n+\n+      return client.get_all_table_constraints(req).getAllTableConstraints();\n+    } finally {\n+      long diff = System.currentTimeMillis() - t1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTM3Nw==", "bodyText": "done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375377", "createdAt": "2020-09-12T06:23:43Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)\n+      throws MetaException, NoSuchObjectException, TException {\n+    long t1 = System.currentTimeMillis();\n+\n+    try {\n+      if (!req.isSetCatName()) {\n+        req.setCatName(getDefaultCatalog(conf));\n+      }\n+\n+      return client.get_all_table_constraints(req).getAllTableConstraints();\n+    } finally {\n+      long diff = System.currentTimeMillis() - t1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1MTUzMw=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI0NDU4OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1NjowNlrOHJPlQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyNDoxMFrOHQzCPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDUyOQ==", "bodyText": "Nit: Naming can be dbName, tblName and catName.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479454529", "createdAt": "2020-08-28T17:56:06Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -720,6 +729,15 @@ struct CheckConstraintsResponse {\n   1: required list<SQLCheckConstraint> checkConstraints\n }\n \n+struct AllTableConstraintsRequest {\n+  1: required string db_name,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTQyMA==", "bodyText": "set all variable to camel casing", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375420", "createdAt": "2020-09-12T06:24:10Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -720,6 +729,15 @@ struct CheckConstraintsResponse {\n   1: required list<SQLCheckConstraint> checkConstraints\n }\n \n+struct AllTableConstraintsRequest {\n+  1: required string db_name,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDUyOQ=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI0ODk3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1NzozM1rOHJPoAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyNDoxOVrOHQzCTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NTIzMg==", "bodyText": "HMS api handles this default catalog name flow. Shall remove it here.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479455232", "createdAt": "2020-08-28T17:57:33Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)\n+      throws MetaException, NoSuchObjectException, TException {\n+    long t1 = System.currentTimeMillis();\n+\n+    try {\n+      if (!req.isSetCatName()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTQzOA==", "bodyText": "removed", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375438", "createdAt": "2020-09-12T06:24:19Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)\n+      throws MetaException, NoSuchObjectException, TException {\n+    long t1 = System.currentTimeMillis();\n+\n+    try {\n+      if (!req.isSetCatName()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NTIzMg=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI1MDg5OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1ODoxNVrOHJPpRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1ODoxNVrOHJPpRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NTU1Ng==", "bodyText": "This can be kept under isDebugEnabled flag.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479455556", "createdAt": "2020-08-28T17:58:15Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)\n+      throws MetaException, NoSuchObjectException, TException {\n+    long t1 = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI4ODkxOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoxMTo1M1rOHJQBcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQwOTo1MzowMlrOHJacVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2MTc0Ng==", "bodyText": "Will these tests run in our PR build pipeline?", "url": "https://github.com/apache/hive/pull/1419#discussion_r479461746", "createdAt": "2020-08-28T18:11:53Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,382 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLDefaultConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLNotNullConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLCheckConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLDefaultConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLForeignKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLNotNullConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLPrimaryKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLUniqueConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTYzMjQ2OQ==", "bodyText": "Yes", "url": "https://github.com/apache/hive/pull/1419#discussion_r479632469", "createdAt": "2020-08-29T09:53:02Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,382 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLDefaultConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLNotNullConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLCheckConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLDefaultConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLForeignKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLNotNullConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLPrimaryKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLUniqueConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2MTc0Ng=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI5OTA3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoxNToxOFrOHJQHrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyNDoyOVrOHQzCUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2MzM0Mg==", "bodyText": "Remove comma \",\" in last column.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479463342", "createdAt": "2020-08-28T18:15:18Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -122,6 +122,15 @@ struct SQLCheckConstraint {\n   9: bool rely_cstr      // Rely/No Rely\n }\n \n+struct SQLAllTableConstraints {\n+  1: optional list<SQLPrimaryKey> primaryKeys,\n+  2: optional list<SQLForeignKey> foreignKeys,\n+  3: optional list<SQLUniqueConstraint> uniqueConstraints,\n+  4: optional list<SQLNotNullConstraint> notNullConstraints,\n+  5: optional list<SQLDefaultConstraint> defaultConstraints,\n+  6: optional list<SQLCheckConstraint> checkConstraints,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTQ0Mw==", "bodyText": "removed", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375443", "createdAt": "2020-09-12T06:24:29Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -122,6 +122,15 @@ struct SQLCheckConstraint {\n   9: bool rely_cstr      // Rely/No Rely\n }\n \n+struct SQLAllTableConstraints {\n+  1: optional list<SQLPrimaryKey> primaryKeys,\n+  2: optional list<SQLForeignKey> foreignKeys,\n+  3: optional list<SQLUniqueConstraint> uniqueConstraints,\n+  4: optional list<SQLNotNullConstraint> notNullConstraints,\n+  5: optional list<SQLDefaultConstraint> defaultConstraints,\n+  6: optional list<SQLCheckConstraint> checkConstraints,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2MzM0Mg=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzMwNDY1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoxNzowOFrOHJQLBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQwOTo1Mjo1MlrOHJacRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2NDE5OA==", "bodyText": "Use this api in query planner instead of multiple calls.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479464198", "createdAt": "2020-08-28T18:17:08Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTYzMjQ1Mg==", "bodyText": "https://issues.apache.org/jira/browse/HIVE-24091", "url": "https://github.com/apache/hive/pull/1419#discussion_r479632452", "createdAt": "2020-08-29T09:52:52Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java", "diffHunk": "@@ -2811,6 +2811,26 @@ public GetFieldsResponse getFieldsRequest(GetFieldsRequest req)\n     return client.get_check_constraints(req).getCheckConstraints();\n   }\n \n+  @Override\n+  public SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest req)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2NDE5OA=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzMxNzM1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoyMToyMlrOHJQSlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQxODo1MzoxNVrOHJdRsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2NjEzMw==", "bodyText": "Add a negative scenario where db invalid or table invalid etc and check if we get NoSuchObjectException.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479466133", "createdAt": "2020-08-28T18:21:22Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,382 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLDefaultConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLNotNullConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLCheckConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLDefaultConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLForeignKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLNotNullConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLPrimaryKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLUniqueConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)\n+public class TestGetAllTableConstraints\n+    extends MetaStoreClientTest {\n+  private static final String OTHER_DATABASE = \"test_constraints_other_database\";\n+  private static final String OTHER_CATALOG = \"test_constraints_other_catalog\";\n+  private static final String DATABASE_IN_OTHER_CATALOG = \"test_constraints_database_in_other_catalog\";\n+  private final AbstractMetaStoreService metaStore;\n+  private IMetaStoreClient client;\n+  private Table[] testTables = new Table[3];\n+  private Database inOtherCatalog;\n+\n+  public TestGetAllTableConstraints(String name, AbstractMetaStoreService metaStore) throws Exception {\n+    this.metaStore = metaStore;\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    // Get new client\n+    client = metaStore.getClient();\n+\n+    // Clean up the database\n+    client.dropDatabase(OTHER_DATABASE, true, true, true);\n+    // Drop every table in the default database\n+    for (String tableName : client.getAllTables(DEFAULT_DATABASE_NAME)) {\n+      client.dropTable(DEFAULT_DATABASE_NAME, tableName, true, true, true);\n+    }\n+\n+    client.dropDatabase(OTHER_CATALOG, DATABASE_IN_OTHER_CATALOG, true, true, true);\n+    try {\n+      client.dropCatalog(OTHER_CATALOG);\n+    } catch (NoSuchObjectException e) {\n+      // NOP\n+    }\n+\n+    // Clean up trash\n+    metaStore.cleanWarehouseDirs();\n+\n+    new DatabaseBuilder().setName(OTHER_DATABASE).create(client, metaStore.getConf());\n+\n+    Catalog cat =\n+        new CatalogBuilder().setName(OTHER_CATALOG).setLocation(MetaStoreTestUtils.getTestWarehouseDir(OTHER_CATALOG))\n+            .build();\n+    client.createCatalog(cat);\n+\n+    // For this one don't specify a location to make sure it gets put in the catalog directory\n+    inOtherCatalog = new DatabaseBuilder().setName(DATABASE_IN_OTHER_CATALOG).setCatalogName(OTHER_CATALOG)\n+        .create(client, metaStore.getConf());\n+\n+    testTables[0] = new TableBuilder().setTableName(\"test_table_1\").addCol(\"col1\", \"int\").addCol(\"col2\", \"int\")\n+        .addCol(\"col3\", \"boolean\").addCol(\"col4\", \"int\").addCol(\"col5\", \"varchar(32)\")\n+        .create(client, metaStore.getConf());\n+\n+    testTables[1] = new TableBuilder().setDbName(OTHER_DATABASE).setTableName(\"test_table_2\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    testTables[2] = new TableBuilder().inDb(inOtherCatalog).setTableName(\"test_table_3\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    // Reload tables from the MetaStore\n+    for (int i = 0; i < testTables.length; i++) {\n+      testTables[i] =\n+          client.getTable(testTables[i].getCatName(), testTables[i].getDbName(), testTables[i].getTableName());\n+    }\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (client != null) {\n+        try {\n+          client.close();\n+        } catch (Exception e) {\n+          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira\n+        }\n+      }\n+    } finally {\n+      client = null;\n+    }\n+  }\n+\n+  @Test\n+  public void noConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+    Assert.assertTrue(fetched.getDefaultConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getNotNullConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getPrimaryKeys().isEmpty());\n+    Assert.assertTrue(fetched.getUniqueConstraints().isEmpty());\n+  }\n+\n+  @Test\n+  public void fewPresentWithMultipleConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col2 with not null constraint in default catalog and database;\n+    String nnCol2ConstraintName = \"col2_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(nnCol2ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol3 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol3);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint\n+    Assert.assertEquals(1, fetched.getPrimaryKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getPrimaryKeys().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getPrimaryKeys().get(0).getTable_name());\n+    Assert.assertEquals(\"col1\", fetched.getPrimaryKeys().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getPrimaryKeys().get(0).getKey_seq());\n+    Assert.assertEquals(pkConstraintName, fetched.getPrimaryKeys().get(0).getPk_name());\n+    Assert.assertTrue(fetched.getPrimaryKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getPrimaryKeys().get(0).getCatName());\n+\n+    // Assert unique constraint\n+    Assert.assertEquals(1, fetched.getUniqueConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getUniqueConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getUniqueConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getUniqueConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getUniqueConstraints().get(0).getKey_seq());\n+    Assert.assertEquals(uniqueConstraintName, fetched.getUniqueConstraints().get(0).getUk_name());\n+    Assert.assertTrue(fetched.getUniqueConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getUniqueConstraints().get(0).getCatName());\n+\n+    // Assert Default constraint\n+    Assert.assertEquals(1, fetched.getDefaultConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getDefaultConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getDefaultConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getDefaultConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"false\", fetched.getDefaultConstraints().get(0).getDefault_value());\n+    Assert.assertEquals(defaultConstraintName, fetched.getDefaultConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getDefaultConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getDefaultConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint\n+    Assert.assertEquals(2, fetched.getNotNullConstraintsSize());\n+\n+    // Assert Not Null constraint for col2\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getNotNullConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(nnCol2ConstraintName, fetched.getNotNullConstraints().get(0).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint for col3\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(1).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(1).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getNotNullConstraints().get(1).getColumn_name());\n+    Assert.assertEquals(nnCol3ConstraintName, fetched.getNotNullConstraints().get(1).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(1).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(1).getCatName());\n+\n+    // Check constraints which is not present in table\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+\n+  }\n+\n+  @Test\n+  public void allConstraintsPresent() throws TException {\n+    Table table = testTables[0];\n+    Table parentTable = testTables[1];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col2 with not check constraint in default catalog and database;\n+    String ccCol2ConstraintName = \"col2_check\";\n+    List<SQLCheckConstraint> cc =\n+        new SQLCheckConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(ccCol2ConstraintName)\n+            .setCheckExpression(\"= 5\").build(metaStore.getConf());\n+    client.addCheckConstraint(cc);\n+\n+    // Set col1 of parent table to PK and Set Col4 of table to FK\n+    String parentPkConstraintName = \"parentpk\";\n+    List<SQLPrimaryKey> parentPk =\n+        new SQLPrimaryKeyBuilder().onTable(parentTable).addColumn(\"col1\").setConstraintName(parentPkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(parentPk);\n+    String fkConstraintName = \"fk\";\n+    List<SQLForeignKey> fk =\n+        new SQLForeignKeyBuilder().fromPrimaryKey(parentPk).onTable(table).setConstraintName(fkConstraintName)\n+            .addColumn(\"col4\").build(metaStore.getConf());\n+    client.addForeignKey(fk);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint\n+    Assert.assertEquals(1, fetched.getPrimaryKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getPrimaryKeys().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getPrimaryKeys().get(0).getTable_name());\n+    Assert.assertEquals(\"col1\", fetched.getPrimaryKeys().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getPrimaryKeys().get(0).getKey_seq());\n+    Assert.assertEquals(pkConstraintName, fetched.getPrimaryKeys().get(0).getPk_name());\n+    Assert.assertTrue(fetched.getPrimaryKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getPrimaryKeys().get(0).getCatName());\n+\n+    // Assert unique constraint\n+    Assert.assertEquals(1, fetched.getUniqueConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getUniqueConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getUniqueConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getUniqueConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getUniqueConstraints().get(0).getKey_seq());\n+    Assert.assertEquals(uniqueConstraintName, fetched.getUniqueConstraints().get(0).getUk_name());\n+    Assert.assertTrue(fetched.getUniqueConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getUniqueConstraints().get(0).getCatName());\n+\n+    // Assert Default constraint\n+    Assert.assertEquals(1, fetched.getDefaultConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getDefaultConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getDefaultConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getDefaultConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"false\", fetched.getDefaultConstraints().get(0).getDefault_value());\n+    Assert.assertEquals(defaultConstraintName, fetched.getDefaultConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getDefaultConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getDefaultConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint\n+    Assert.assertEquals(1, fetched.getNotNullConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getNotNullConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(nnCol3ConstraintName, fetched.getNotNullConstraints().get(0).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(0).getCatName());\n+\n+    // Assert check constraint\n+    Assert.assertEquals(1, fetched.getNotNullConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getCheckConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getCheckConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getCheckConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"= 5\", fetched.getCheckConstraints().get(0).getCheck_expression());\n+    Assert.assertEquals(ccCol2ConstraintName, fetched.getCheckConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getCheckConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getCheckConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getCheckConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getCheckConstraints().get(0).getCatName());\n+\n+    // Assert foreign key\n+    Assert.assertEquals(1, fetched.getForeignKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getForeignKeys().get(0).getFktable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getForeignKeys().get(0).getFktable_name());\n+    Assert.assertEquals(\"col4\", fetched.getForeignKeys().get(0).getFkcolumn_name());\n+    Assert.assertEquals(parentTable.getDbName(), fetched.getForeignKeys().get(0).getPktable_db());\n+    Assert.assertEquals(parentTable.getTableName(), fetched.getForeignKeys().get(0).getPktable_name());\n+    Assert.assertEquals(\"col1\", fetched.getForeignKeys().get(0).getPkcolumn_name());\n+    Assert.assertEquals(1, fetched.getForeignKeys().get(0).getKey_seq());\n+    Assert.assertEquals(parentPkConstraintName, fetched.getForeignKeys().get(0).getPk_name());\n+    Assert.assertEquals(fkConstraintName, fetched.getForeignKeys().get(0).getFk_name());\n+    Assert.assertTrue(fetched.getForeignKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getForeignKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getForeignKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getForeignKeys().get(0).getCatName());\n+\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 380}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTY3ODg5OQ==", "bodyText": "We will not get NoSuchObjectException because in the code follow NoSuchObjectException is replaced by MetaException", "url": "https://github.com/apache/hive/pull/1419#discussion_r479678899", "createdAt": "2020-08-29T18:53:15Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,382 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLDefaultConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLNotNullConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLCheckConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLDefaultConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLForeignKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLNotNullConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLPrimaryKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLUniqueConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)\n+public class TestGetAllTableConstraints\n+    extends MetaStoreClientTest {\n+  private static final String OTHER_DATABASE = \"test_constraints_other_database\";\n+  private static final String OTHER_CATALOG = \"test_constraints_other_catalog\";\n+  private static final String DATABASE_IN_OTHER_CATALOG = \"test_constraints_database_in_other_catalog\";\n+  private final AbstractMetaStoreService metaStore;\n+  private IMetaStoreClient client;\n+  private Table[] testTables = new Table[3];\n+  private Database inOtherCatalog;\n+\n+  public TestGetAllTableConstraints(String name, AbstractMetaStoreService metaStore) throws Exception {\n+    this.metaStore = metaStore;\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    // Get new client\n+    client = metaStore.getClient();\n+\n+    // Clean up the database\n+    client.dropDatabase(OTHER_DATABASE, true, true, true);\n+    // Drop every table in the default database\n+    for (String tableName : client.getAllTables(DEFAULT_DATABASE_NAME)) {\n+      client.dropTable(DEFAULT_DATABASE_NAME, tableName, true, true, true);\n+    }\n+\n+    client.dropDatabase(OTHER_CATALOG, DATABASE_IN_OTHER_CATALOG, true, true, true);\n+    try {\n+      client.dropCatalog(OTHER_CATALOG);\n+    } catch (NoSuchObjectException e) {\n+      // NOP\n+    }\n+\n+    // Clean up trash\n+    metaStore.cleanWarehouseDirs();\n+\n+    new DatabaseBuilder().setName(OTHER_DATABASE).create(client, metaStore.getConf());\n+\n+    Catalog cat =\n+        new CatalogBuilder().setName(OTHER_CATALOG).setLocation(MetaStoreTestUtils.getTestWarehouseDir(OTHER_CATALOG))\n+            .build();\n+    client.createCatalog(cat);\n+\n+    // For this one don't specify a location to make sure it gets put in the catalog directory\n+    inOtherCatalog = new DatabaseBuilder().setName(DATABASE_IN_OTHER_CATALOG).setCatalogName(OTHER_CATALOG)\n+        .create(client, metaStore.getConf());\n+\n+    testTables[0] = new TableBuilder().setTableName(\"test_table_1\").addCol(\"col1\", \"int\").addCol(\"col2\", \"int\")\n+        .addCol(\"col3\", \"boolean\").addCol(\"col4\", \"int\").addCol(\"col5\", \"varchar(32)\")\n+        .create(client, metaStore.getConf());\n+\n+    testTables[1] = new TableBuilder().setDbName(OTHER_DATABASE).setTableName(\"test_table_2\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    testTables[2] = new TableBuilder().inDb(inOtherCatalog).setTableName(\"test_table_3\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    // Reload tables from the MetaStore\n+    for (int i = 0; i < testTables.length; i++) {\n+      testTables[i] =\n+          client.getTable(testTables[i].getCatName(), testTables[i].getDbName(), testTables[i].getTableName());\n+    }\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (client != null) {\n+        try {\n+          client.close();\n+        } catch (Exception e) {\n+          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira\n+        }\n+      }\n+    } finally {\n+      client = null;\n+    }\n+  }\n+\n+  @Test\n+  public void noConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+    Assert.assertTrue(fetched.getDefaultConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getNotNullConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getPrimaryKeys().isEmpty());\n+    Assert.assertTrue(fetched.getUniqueConstraints().isEmpty());\n+  }\n+\n+  @Test\n+  public void fewPresentWithMultipleConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col2 with not null constraint in default catalog and database;\n+    String nnCol2ConstraintName = \"col2_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(nnCol2ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol3 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol3);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint\n+    Assert.assertEquals(1, fetched.getPrimaryKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getPrimaryKeys().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getPrimaryKeys().get(0).getTable_name());\n+    Assert.assertEquals(\"col1\", fetched.getPrimaryKeys().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getPrimaryKeys().get(0).getKey_seq());\n+    Assert.assertEquals(pkConstraintName, fetched.getPrimaryKeys().get(0).getPk_name());\n+    Assert.assertTrue(fetched.getPrimaryKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getPrimaryKeys().get(0).getCatName());\n+\n+    // Assert unique constraint\n+    Assert.assertEquals(1, fetched.getUniqueConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getUniqueConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getUniqueConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getUniqueConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getUniqueConstraints().get(0).getKey_seq());\n+    Assert.assertEquals(uniqueConstraintName, fetched.getUniqueConstraints().get(0).getUk_name());\n+    Assert.assertTrue(fetched.getUniqueConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getUniqueConstraints().get(0).getCatName());\n+\n+    // Assert Default constraint\n+    Assert.assertEquals(1, fetched.getDefaultConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getDefaultConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getDefaultConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getDefaultConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"false\", fetched.getDefaultConstraints().get(0).getDefault_value());\n+    Assert.assertEquals(defaultConstraintName, fetched.getDefaultConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getDefaultConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getDefaultConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint\n+    Assert.assertEquals(2, fetched.getNotNullConstraintsSize());\n+\n+    // Assert Not Null constraint for col2\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getNotNullConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(nnCol2ConstraintName, fetched.getNotNullConstraints().get(0).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint for col3\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(1).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(1).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getNotNullConstraints().get(1).getColumn_name());\n+    Assert.assertEquals(nnCol3ConstraintName, fetched.getNotNullConstraints().get(1).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(1).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(1).getCatName());\n+\n+    // Check constraints which is not present in table\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+\n+  }\n+\n+  @Test\n+  public void allConstraintsPresent() throws TException {\n+    Table table = testTables[0];\n+    Table parentTable = testTables[1];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col2 with not check constraint in default catalog and database;\n+    String ccCol2ConstraintName = \"col2_check\";\n+    List<SQLCheckConstraint> cc =\n+        new SQLCheckConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(ccCol2ConstraintName)\n+            .setCheckExpression(\"= 5\").build(metaStore.getConf());\n+    client.addCheckConstraint(cc);\n+\n+    // Set col1 of parent table to PK and Set Col4 of table to FK\n+    String parentPkConstraintName = \"parentpk\";\n+    List<SQLPrimaryKey> parentPk =\n+        new SQLPrimaryKeyBuilder().onTable(parentTable).addColumn(\"col1\").setConstraintName(parentPkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(parentPk);\n+    String fkConstraintName = \"fk\";\n+    List<SQLForeignKey> fk =\n+        new SQLForeignKeyBuilder().fromPrimaryKey(parentPk).onTable(table).setConstraintName(fkConstraintName)\n+            .addColumn(\"col4\").build(metaStore.getConf());\n+    client.addForeignKey(fk);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint\n+    Assert.assertEquals(1, fetched.getPrimaryKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getPrimaryKeys().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getPrimaryKeys().get(0).getTable_name());\n+    Assert.assertEquals(\"col1\", fetched.getPrimaryKeys().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getPrimaryKeys().get(0).getKey_seq());\n+    Assert.assertEquals(pkConstraintName, fetched.getPrimaryKeys().get(0).getPk_name());\n+    Assert.assertTrue(fetched.getPrimaryKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getPrimaryKeys().get(0).getCatName());\n+\n+    // Assert unique constraint\n+    Assert.assertEquals(1, fetched.getUniqueConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getUniqueConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getUniqueConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getUniqueConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getUniqueConstraints().get(0).getKey_seq());\n+    Assert.assertEquals(uniqueConstraintName, fetched.getUniqueConstraints().get(0).getUk_name());\n+    Assert.assertTrue(fetched.getUniqueConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getUniqueConstraints().get(0).getCatName());\n+\n+    // Assert Default constraint\n+    Assert.assertEquals(1, fetched.getDefaultConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getDefaultConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getDefaultConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getDefaultConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"false\", fetched.getDefaultConstraints().get(0).getDefault_value());\n+    Assert.assertEquals(defaultConstraintName, fetched.getDefaultConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getDefaultConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getDefaultConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint\n+    Assert.assertEquals(1, fetched.getNotNullConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getNotNullConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(nnCol3ConstraintName, fetched.getNotNullConstraints().get(0).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(0).getCatName());\n+\n+    // Assert check constraint\n+    Assert.assertEquals(1, fetched.getNotNullConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getCheckConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getCheckConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getCheckConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"= 5\", fetched.getCheckConstraints().get(0).getCheck_expression());\n+    Assert.assertEquals(ccCol2ConstraintName, fetched.getCheckConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getCheckConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getCheckConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getCheckConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getCheckConstraints().get(0).getCatName());\n+\n+    // Assert foreign key\n+    Assert.assertEquals(1, fetched.getForeignKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getForeignKeys().get(0).getFktable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getForeignKeys().get(0).getFktable_name());\n+    Assert.assertEquals(\"col4\", fetched.getForeignKeys().get(0).getFkcolumn_name());\n+    Assert.assertEquals(parentTable.getDbName(), fetched.getForeignKeys().get(0).getPktable_db());\n+    Assert.assertEquals(parentTable.getTableName(), fetched.getForeignKeys().get(0).getPktable_name());\n+    Assert.assertEquals(\"col1\", fetched.getForeignKeys().get(0).getPkcolumn_name());\n+    Assert.assertEquals(1, fetched.getForeignKeys().get(0).getKey_seq());\n+    Assert.assertEquals(parentPkConstraintName, fetched.getForeignKeys().get(0).getPk_name());\n+    Assert.assertEquals(fkConstraintName, fetched.getForeignKeys().get(0).getFk_name());\n+    Assert.assertTrue(fetched.getForeignKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getForeignKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getForeignKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getForeignKeys().get(0).getCatName());\n+\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2NjEzMw=="}, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 380}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzMyMDgyOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoyMjozN1rOHJQUyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxODoyMjozN1rOHJQUyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ2NjY5OA==", "bodyText": "Too much of duplicate code. Can write common methods for the asserts and use it in all tests.", "url": "https://github.com/apache/hive/pull/1419#discussion_r479466698", "createdAt": "2020-08-28T18:22:37Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetAllTableConstraints.java", "diffHunk": "@@ -0,0 +1,382 @@\n+package org.apache.hadoop.hive.metastore.client;\n+\n+import org.apache.hadoop.hive.metastore.IMetaStoreClient;\n+import org.apache.hadoop.hive.metastore.MetaStoreTestUtils;\n+import org.apache.hadoop.hive.metastore.annotation.MetastoreCheckinTest;\n+import org.apache.hadoop.hive.metastore.api.AllTableConstraintsRequest;\n+import org.apache.hadoop.hive.metastore.api.Catalog;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.PrimaryKeysRequest;\n+import org.apache.hadoop.hive.metastore.api.SQLAllTableConstraints;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLDefaultConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLNotNullConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.hadoop.hive.metastore.client.builder.CatalogBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.DatabaseBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLCheckConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLDefaultConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLForeignKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLNotNullConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLPrimaryKeyBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.SQLUniqueConstraintBuilder;\n+import org.apache.hadoop.hive.metastore.client.builder.TableBuilder;\n+import org.apache.hadoop.hive.metastore.minihms.AbstractMetaStoreService;\n+import org.apache.thrift.TException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.util.List;\n+\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+\n+@RunWith(Parameterized.class)\n+@Category(MetastoreCheckinTest.class)\n+public class TestGetAllTableConstraints\n+    extends MetaStoreClientTest {\n+  private static final String OTHER_DATABASE = \"test_constraints_other_database\";\n+  private static final String OTHER_CATALOG = \"test_constraints_other_catalog\";\n+  private static final String DATABASE_IN_OTHER_CATALOG = \"test_constraints_database_in_other_catalog\";\n+  private final AbstractMetaStoreService metaStore;\n+  private IMetaStoreClient client;\n+  private Table[] testTables = new Table[3];\n+  private Database inOtherCatalog;\n+\n+  public TestGetAllTableConstraints(String name, AbstractMetaStoreService metaStore) throws Exception {\n+    this.metaStore = metaStore;\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    // Get new client\n+    client = metaStore.getClient();\n+\n+    // Clean up the database\n+    client.dropDatabase(OTHER_DATABASE, true, true, true);\n+    // Drop every table in the default database\n+    for (String tableName : client.getAllTables(DEFAULT_DATABASE_NAME)) {\n+      client.dropTable(DEFAULT_DATABASE_NAME, tableName, true, true, true);\n+    }\n+\n+    client.dropDatabase(OTHER_CATALOG, DATABASE_IN_OTHER_CATALOG, true, true, true);\n+    try {\n+      client.dropCatalog(OTHER_CATALOG);\n+    } catch (NoSuchObjectException e) {\n+      // NOP\n+    }\n+\n+    // Clean up trash\n+    metaStore.cleanWarehouseDirs();\n+\n+    new DatabaseBuilder().setName(OTHER_DATABASE).create(client, metaStore.getConf());\n+\n+    Catalog cat =\n+        new CatalogBuilder().setName(OTHER_CATALOG).setLocation(MetaStoreTestUtils.getTestWarehouseDir(OTHER_CATALOG))\n+            .build();\n+    client.createCatalog(cat);\n+\n+    // For this one don't specify a location to make sure it gets put in the catalog directory\n+    inOtherCatalog = new DatabaseBuilder().setName(DATABASE_IN_OTHER_CATALOG).setCatalogName(OTHER_CATALOG)\n+        .create(client, metaStore.getConf());\n+\n+    testTables[0] = new TableBuilder().setTableName(\"test_table_1\").addCol(\"col1\", \"int\").addCol(\"col2\", \"int\")\n+        .addCol(\"col3\", \"boolean\").addCol(\"col4\", \"int\").addCol(\"col5\", \"varchar(32)\")\n+        .create(client, metaStore.getConf());\n+\n+    testTables[1] = new TableBuilder().setDbName(OTHER_DATABASE).setTableName(\"test_table_2\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    testTables[2] = new TableBuilder().inDb(inOtherCatalog).setTableName(\"test_table_3\").addCol(\"col1\", \"int\")\n+        .addCol(\"col2\", \"varchar(32)\").create(client, metaStore.getConf());\n+\n+    // Reload tables from the MetaStore\n+    for (int i = 0; i < testTables.length; i++) {\n+      testTables[i] =\n+          client.getTable(testTables[i].getCatName(), testTables[i].getDbName(), testTables[i].getTableName());\n+    }\n+  }\n+\n+  @After\n+  public void tearDown() throws Exception {\n+    try {\n+      if (client != null) {\n+        try {\n+          client.close();\n+        } catch (Exception e) {\n+          // HIVE-19729: Shallow the exceptions based on the discussion in the Jira\n+        }\n+      }\n+    } finally {\n+      client = null;\n+    }\n+  }\n+\n+  @Test\n+  public void noConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+    Assert.assertTrue(fetched.getDefaultConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getNotNullConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getPrimaryKeys().isEmpty());\n+    Assert.assertTrue(fetched.getUniqueConstraints().isEmpty());\n+  }\n+\n+  @Test\n+  public void fewPresentWithMultipleConstraints() throws TException {\n+    Table table = testTables[0];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col2 with not null constraint in default catalog and database;\n+    String nnCol2ConstraintName = \"col2_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(nnCol2ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol3 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol3);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint\n+    Assert.assertEquals(1, fetched.getPrimaryKeysSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getPrimaryKeys().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getPrimaryKeys().get(0).getTable_name());\n+    Assert.assertEquals(\"col1\", fetched.getPrimaryKeys().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getPrimaryKeys().get(0).getKey_seq());\n+    Assert.assertEquals(pkConstraintName, fetched.getPrimaryKeys().get(0).getPk_name());\n+    Assert.assertTrue(fetched.getPrimaryKeys().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getPrimaryKeys().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getPrimaryKeys().get(0).getCatName());\n+\n+    // Assert unique constraint\n+    Assert.assertEquals(1, fetched.getUniqueConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getUniqueConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getUniqueConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getUniqueConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(1, fetched.getUniqueConstraints().get(0).getKey_seq());\n+    Assert.assertEquals(uniqueConstraintName, fetched.getUniqueConstraints().get(0).getUk_name());\n+    Assert.assertTrue(fetched.getUniqueConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getUniqueConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getUniqueConstraints().get(0).getCatName());\n+\n+    // Assert Default constraint\n+    Assert.assertEquals(1, fetched.getDefaultConstraintsSize());\n+    Assert.assertEquals(table.getDbName(), fetched.getDefaultConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getDefaultConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getDefaultConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(\"false\", fetched.getDefaultConstraints().get(0).getDefault_value());\n+    Assert.assertEquals(defaultConstraintName, fetched.getDefaultConstraints().get(0).getDc_name());\n+    Assert.assertTrue(fetched.getDefaultConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getDefaultConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getDefaultConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint\n+    Assert.assertEquals(2, fetched.getNotNullConstraintsSize());\n+\n+    // Assert Not Null constraint for col2\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(0).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(0).getTable_name());\n+    Assert.assertEquals(\"col2\", fetched.getNotNullConstraints().get(0).getColumn_name());\n+    Assert.assertEquals(nnCol2ConstraintName, fetched.getNotNullConstraints().get(0).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(0).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(0).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(0).getCatName());\n+\n+    // Assert Not Null constraint for col3\n+    Assert.assertEquals(table.getDbName(), fetched.getNotNullConstraints().get(1).getTable_db());\n+    Assert.assertEquals(table.getTableName(), fetched.getNotNullConstraints().get(1).getTable_name());\n+    Assert.assertEquals(\"col3\", fetched.getNotNullConstraints().get(1).getColumn_name());\n+    Assert.assertEquals(nnCol3ConstraintName, fetched.getNotNullConstraints().get(1).getNn_name());\n+    Assert.assertTrue(fetched.getNotNullConstraints().get(1).isEnable_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isValidate_cstr());\n+    Assert.assertFalse(fetched.getNotNullConstraints().get(1).isRely_cstr());\n+    Assert.assertEquals(table.getCatName(), fetched.getNotNullConstraints().get(1).getCatName());\n+\n+    // Check constraints which is not present in table\n+    Assert.assertTrue(fetched.getCheckConstraints().isEmpty());\n+    Assert.assertTrue(fetched.getForeignKeys().isEmpty());\n+\n+  }\n+\n+  @Test\n+  public void allConstraintsPresent() throws TException {\n+    Table table = testTables[0];\n+    Table parentTable = testTables[1];\n+\n+    // Set col1 as primary key Constraint in default catalog and database\n+    String pkConstraintName = \"col1_pk\";\n+    List<SQLPrimaryKey> pk =\n+        new SQLPrimaryKeyBuilder().onTable(table).addColumn(\"col1\").setConstraintName(pkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(pk);\n+\n+    // Set col2 with Unique Constraint in default catalog and database\n+    String uniqueConstraintName = \"col2_unique\";\n+    List<SQLUniqueConstraint> uc =\n+        new SQLUniqueConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(uniqueConstraintName)\n+            .build(metaStore.getConf());\n+    client.addUniqueConstraint(uc);\n+\n+    // Set col3 with default Constraint in default catalog and database\n+    String defaultConstraintName = \"col3_default\";\n+    List<SQLDefaultConstraint> dv =\n+        new SQLDefaultConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(defaultConstraintName)\n+            .setDefaultVal(false).build(metaStore.getConf());\n+    client.addDefaultConstraint(dv);\n+\n+    // Set col3 with not null constraint in default catalog and database;\n+    String nnCol3ConstraintName = \"col3_not_null\";\n+    List<SQLNotNullConstraint> nnCol2 =\n+        new SQLNotNullConstraintBuilder().onTable(table).addColumn(\"col3\").setConstraintName(nnCol3ConstraintName)\n+            .build(metaStore.getConf());\n+    client.addNotNullConstraint(nnCol2);\n+\n+    // Set col2 with not check constraint in default catalog and database;\n+    String ccCol2ConstraintName = \"col2_check\";\n+    List<SQLCheckConstraint> cc =\n+        new SQLCheckConstraintBuilder().onTable(table).addColumn(\"col2\").setConstraintName(ccCol2ConstraintName)\n+            .setCheckExpression(\"= 5\").build(metaStore.getConf());\n+    client.addCheckConstraint(cc);\n+\n+    // Set col1 of parent table to PK and Set Col4 of table to FK\n+    String parentPkConstraintName = \"parentpk\";\n+    List<SQLPrimaryKey> parentPk =\n+        new SQLPrimaryKeyBuilder().onTable(parentTable).addColumn(\"col1\").setConstraintName(parentPkConstraintName)\n+            .build(metaStore.getConf());\n+    client.addPrimaryKey(parentPk);\n+    String fkConstraintName = \"fk\";\n+    List<SQLForeignKey> fk =\n+        new SQLForeignKeyBuilder().fromPrimaryKey(parentPk).onTable(table).setConstraintName(fkConstraintName)\n+            .addColumn(\"col4\").build(metaStore.getConf());\n+    client.addForeignKey(fk);\n+\n+    // Fetch all constraints for the table in default catalog and database\n+    AllTableConstraintsRequest request = new AllTableConstraintsRequest(table.getDbName(), table.getTableName());\n+    request.setCatName(table.getCatName());\n+    SQLAllTableConstraints fetched = client.getAllTableConstraints(request);\n+\n+    // Assert primary key constraint", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bcf739c59daf283657efe7152c6b724a33765729"}, "originalPosition": 305}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjEzNTU5OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMToxNDozM1rOHQaueg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNDozMzoyMlrOHQyfOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk3NzE0Ng==", "bodyText": "nit: Add space after comma between arguments.", "url": "https://github.com/apache/hive/pull/1419#discussion_r486977146", "createdAt": "2020-09-11T11:14:33Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "diffHunk": "@@ -1155,22 +1150,19 @@ void dumpConstraintMetadata(String dbName, String tblName, Path dbRoot, Hive hiv\n       Path constraintsRoot = new Path(dbRoot, ReplUtils.CONSTRAINTS_ROOT_DIR_NAME);\n       Path commonConstraintsFile = new Path(constraintsRoot, ConstraintFileType.COMMON.getPrefix() + tblName);\n       Path fkConstraintsFile = new Path(constraintsRoot, ConstraintFileType.FOREIGNKEY.getPrefix() + tblName);\n-      List<SQLPrimaryKey> pks = hiveDb.getPrimaryKeyList(dbName, tblName);\n-      List<SQLForeignKey> fks = hiveDb.getForeignKeyList(dbName, tblName);\n-      List<SQLUniqueConstraint> uks = hiveDb.getUniqueConstraintList(dbName, tblName);\n-      List<SQLNotNullConstraint> nns = hiveDb.getNotNullConstraintList(dbName, tblName);\n-      if ((pks != null && !pks.isEmpty()) || (uks != null && !uks.isEmpty())\n-          || (nns != null && !nns.isEmpty())) {\n+      SQLAllTableConstraints tableConstraints = hiveDb.getTableConstraints(dbName,tblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2NjQ1Ng==", "bodyText": "Done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487366456", "createdAt": "2020-09-12T04:33:22Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "diffHunk": "@@ -1155,22 +1150,19 @@ void dumpConstraintMetadata(String dbName, String tblName, Path dbRoot, Hive hiv\n       Path constraintsRoot = new Path(dbRoot, ReplUtils.CONSTRAINTS_ROOT_DIR_NAME);\n       Path commonConstraintsFile = new Path(constraintsRoot, ConstraintFileType.COMMON.getPrefix() + tblName);\n       Path fkConstraintsFile = new Path(constraintsRoot, ConstraintFileType.FOREIGNKEY.getPrefix() + tblName);\n-      List<SQLPrimaryKey> pks = hiveDb.getPrimaryKeyList(dbName, tblName);\n-      List<SQLForeignKey> fks = hiveDb.getForeignKeyList(dbName, tblName);\n-      List<SQLUniqueConstraint> uks = hiveDb.getUniqueConstraintList(dbName, tblName);\n-      List<SQLNotNullConstraint> nns = hiveDb.getNotNullConstraintList(dbName, tblName);\n-      if ((pks != null && !pks.isEmpty()) || (uks != null && !uks.isEmpty())\n-          || (nns != null && !nns.isEmpty())) {\n+      SQLAllTableConstraints tableConstraints = hiveDb.getTableConstraints(dbName,tblName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk3NzE0Ng=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjE0NjIyOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMToxODoyMVrOHQa0-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNDozOToxNVrOHQyhGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk3ODgxMA==", "bodyText": "Can add utility method to check for null and empty of given list. Used multiple times. Also use local variables to reduce the code.", "url": "https://github.com/apache/hive/pull/1419#discussion_r486978810", "createdAt": "2020-09-11T11:18:21Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "diffHunk": "@@ -1155,22 +1150,19 @@ void dumpConstraintMetadata(String dbName, String tblName, Path dbRoot, Hive hiv\n       Path constraintsRoot = new Path(dbRoot, ReplUtils.CONSTRAINTS_ROOT_DIR_NAME);\n       Path commonConstraintsFile = new Path(constraintsRoot, ConstraintFileType.COMMON.getPrefix() + tblName);\n       Path fkConstraintsFile = new Path(constraintsRoot, ConstraintFileType.FOREIGNKEY.getPrefix() + tblName);\n-      List<SQLPrimaryKey> pks = hiveDb.getPrimaryKeyList(dbName, tblName);\n-      List<SQLForeignKey> fks = hiveDb.getForeignKeyList(dbName, tblName);\n-      List<SQLUniqueConstraint> uks = hiveDb.getUniqueConstraintList(dbName, tblName);\n-      List<SQLNotNullConstraint> nns = hiveDb.getNotNullConstraintList(dbName, tblName);\n-      if ((pks != null && !pks.isEmpty()) || (uks != null && !uks.isEmpty())\n-          || (nns != null && !nns.isEmpty())) {\n+      SQLAllTableConstraints tableConstraints = hiveDb.getTableConstraints(dbName,tblName);\n+      if ((tableConstraints.getPrimaryKeys() != null && !tableConstraints.getPrimaryKeys().isEmpty()) || (tableConstraints.getUniqueConstraints() != null && !tableConstraints.getUniqueConstraints().isEmpty())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2NjkzOQ==", "bodyText": "Yes, code is very redundant. I have replaced it with CollectionsUtils.isNotEmpty() which does the same check i.e not null and isEmpty()", "url": "https://github.com/apache/hive/pull/1419#discussion_r487366939", "createdAt": "2020-09-12T04:39:15Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java", "diffHunk": "@@ -1155,22 +1150,19 @@ void dumpConstraintMetadata(String dbName, String tblName, Path dbRoot, Hive hiv\n       Path constraintsRoot = new Path(dbRoot, ReplUtils.CONSTRAINTS_ROOT_DIR_NAME);\n       Path commonConstraintsFile = new Path(constraintsRoot, ConstraintFileType.COMMON.getPrefix() + tblName);\n       Path fkConstraintsFile = new Path(constraintsRoot, ConstraintFileType.FOREIGNKEY.getPrefix() + tblName);\n-      List<SQLPrimaryKey> pks = hiveDb.getPrimaryKeyList(dbName, tblName);\n-      List<SQLForeignKey> fks = hiveDb.getForeignKeyList(dbName, tblName);\n-      List<SQLUniqueConstraint> uks = hiveDb.getUniqueConstraintList(dbName, tblName);\n-      List<SQLNotNullConstraint> nns = hiveDb.getNotNullConstraintList(dbName, tblName);\n-      if ((pks != null && !pks.isEmpty()) || (uks != null && !uks.isEmpty())\n-          || (nns != null && !nns.isEmpty())) {\n+      SQLAllTableConstraints tableConstraints = hiveDb.getTableConstraints(dbName,tblName);\n+      if ((tableConstraints.getPrimaryKeys() != null && !tableConstraints.getPrimaryKeys().isEmpty()) || (tableConstraints.getUniqueConstraints() != null && !tableConstraints.getUniqueConstraints().isEmpty())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk3ODgxMA=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjIzNjM1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMTo0ODo1NlrOHQbqZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNDozOTo0NVrOHQyhVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5MjQ4Ng==", "bodyText": "nit: Use \"fetchReliable\" and \"fetchEnabled\" instead of \"reliable\" and \"enable\" as it sound like flag to enable something.", "url": "https://github.com/apache/hive/pull/1419#discussion_r486992486", "createdAt": "2020-09-11T11:48:56Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, true, true);\n   }\n \n-  /**\n-   * Get primary key columns associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getReliablePrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, true);\n-  }\n-\n-  private PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName, boolean onlyReliable)\n+  private TableConstraintsInfo getTableConstraints(String dbName, String tblName, boolean reliable, boolean enable)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2Njk5Ng==", "bodyText": "Update the variable name.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487366996", "createdAt": "2020-09-12T04:39:45Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, true, true);\n   }\n \n-  /**\n-   * Get primary key columns associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getReliablePrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, true);\n-  }\n-\n-  private PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName, boolean onlyReliable)\n+  private TableConstraintsInfo getTableConstraints(String dbName, String tblName, boolean reliable, boolean enable)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5MjQ4Ng=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjI1NzYzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMTo1NTo1N1rOHQb2pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNDo1Mjo0OVrOHQ9Big==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5NTYyMw==", "bodyText": "Other constraints also needs to be filtered based on \"enable\" flag, right?", "url": "https://github.com/apache/hive/pull/1419#discussion_r486995623", "createdAt": "2020-09-11T11:55:57Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, true, true);\n   }\n \n-  /**\n-   * Get primary key columns associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getReliablePrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, true);\n-  }\n-\n-  private PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName, boolean onlyReliable)\n+  private TableConstraintsInfo getTableConstraints(String dbName, String tblName, boolean reliable, boolean enable)\n       throws HiveException {\n     PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_PK);\n-    try {\n-      List<SQLPrimaryKey> primaryKeys = getMSC().getPrimaryKeys(new PrimaryKeysRequest(dbName, tblName));\n-      if (onlyReliable && primaryKeys != null && !primaryKeys.isEmpty()) {\n-        primaryKeys = primaryKeys.stream()\n-          .filter(pk -> pk.isRely_cstr())\n-          .collect(Collectors.toList());\n-      }\n-\n-      return new PrimaryKeyInfo(primaryKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_PK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all foreign keys associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get foreign keys associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getReliableForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, true);\n-  }\n-\n-  private ForeignKeyInfo getForeignKeys(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_FK);\n-    try {\n-      List<SQLForeignKey> foreignKeys = getMSC().getForeignKeys(new ForeignKeysRequest(null, null, dbName, tblName));\n-      if (onlyReliable && foreignKeys != null && !foreignKeys.isEmpty()) {\n-        foreignKeys = foreignKeys.stream()\n-          .filter(fk -> fk.isRely_cstr())\n-          .collect(Collectors.toList());\n+    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_TABLE_CONSTRAINTS);\n+    try {\n+      SQLAllTableConstraints tableConstraints =\n+          getMSC().getAllTableConstraints(new AllTableConstraintsRequest(dbName, tblName));\n+      if (reliable && tableConstraints != null) {\n+        if (tableConstraints.getPrimaryKeys() != null && !tableConstraints.getPrimaryKeys().isEmpty()) {\n+          tableConstraints.setPrimaryKeys(\n+              tableConstraints.getPrimaryKeys().stream().filter(primaryKey -> primaryKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getForeignKeys() != null && !tableConstraints.getForeignKeys().isEmpty()) {\n+          tableConstraints.setForeignKeys(\n+              tableConstraints.getForeignKeys().stream().filter(foreignKey -> foreignKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getUniqueConstraints() != null && !tableConstraints.getUniqueConstraints().isEmpty()) {\n+          tableConstraints.setUniqueConstraints(tableConstraints.getUniqueConstraints().stream()\n+              .filter(uniqueConstraint -> uniqueConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getNotNullConstraints() != null && !tableConstraints.getNotNullConstraints().isEmpty()) {\n+          tableConstraints.setNotNullConstraints(tableConstraints.getNotNullConstraints().stream()\n+              .filter(notNullConstraint -> notNullConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n       }\n \n-      return new ForeignKeyInfo(foreignKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_FK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all unique constraints associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get unique constraints associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getReliableUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, true);\n-  }\n-\n-  private UniqueConstraint getUniqueConstraints(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_UNIQ_CONSTRAINT);\n-    try {\n-      List<SQLUniqueConstraint> uniqueConstraints = getMSC().getUniqueConstraints(\n-              new UniqueConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n-      if (onlyReliable && uniqueConstraints != null && !uniqueConstraints.isEmpty()) {\n-        uniqueConstraints = uniqueConstraints.stream()\n-          .filter(uk -> uk.isRely_cstr())\n-          .collect(Collectors.toList());\n+      if (enable && tableConstraints != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2NzQ4Ng==", "bodyText": "Yes, Ideally we can fetch all constraint on rely,enable and validate. But in table.java we have chooses to pk,fk,unique and notnull as fetch based on rely. Default and check constraints are fetch based on enable. this method is tightly couple with Hive.java class that's why i have put everything is one method as tableConstraints is single object. But yes we can have separate function for both of them", "url": "https://github.com/apache/hive/pull/1419#discussion_r487367486", "createdAt": "2020-09-12T04:45:27Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, true, true);\n   }\n \n-  /**\n-   * Get primary key columns associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getReliablePrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, true);\n-  }\n-\n-  private PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName, boolean onlyReliable)\n+  private TableConstraintsInfo getTableConstraints(String dbName, String tblName, boolean reliable, boolean enable)\n       throws HiveException {\n     PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_PK);\n-    try {\n-      List<SQLPrimaryKey> primaryKeys = getMSC().getPrimaryKeys(new PrimaryKeysRequest(dbName, tblName));\n-      if (onlyReliable && primaryKeys != null && !primaryKeys.isEmpty()) {\n-        primaryKeys = primaryKeys.stream()\n-          .filter(pk -> pk.isRely_cstr())\n-          .collect(Collectors.toList());\n-      }\n-\n-      return new PrimaryKeyInfo(primaryKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_PK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all foreign keys associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get foreign keys associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getReliableForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, true);\n-  }\n-\n-  private ForeignKeyInfo getForeignKeys(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_FK);\n-    try {\n-      List<SQLForeignKey> foreignKeys = getMSC().getForeignKeys(new ForeignKeysRequest(null, null, dbName, tblName));\n-      if (onlyReliable && foreignKeys != null && !foreignKeys.isEmpty()) {\n-        foreignKeys = foreignKeys.stream()\n-          .filter(fk -> fk.isRely_cstr())\n-          .collect(Collectors.toList());\n+    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_TABLE_CONSTRAINTS);\n+    try {\n+      SQLAllTableConstraints tableConstraints =\n+          getMSC().getAllTableConstraints(new AllTableConstraintsRequest(dbName, tblName));\n+      if (reliable && tableConstraints != null) {\n+        if (tableConstraints.getPrimaryKeys() != null && !tableConstraints.getPrimaryKeys().isEmpty()) {\n+          tableConstraints.setPrimaryKeys(\n+              tableConstraints.getPrimaryKeys().stream().filter(primaryKey -> primaryKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getForeignKeys() != null && !tableConstraints.getForeignKeys().isEmpty()) {\n+          tableConstraints.setForeignKeys(\n+              tableConstraints.getForeignKeys().stream().filter(foreignKey -> foreignKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getUniqueConstraints() != null && !tableConstraints.getUniqueConstraints().isEmpty()) {\n+          tableConstraints.setUniqueConstraints(tableConstraints.getUniqueConstraints().stream()\n+              .filter(uniqueConstraint -> uniqueConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getNotNullConstraints() != null && !tableConstraints.getNotNullConstraints().isEmpty()) {\n+          tableConstraints.setNotNullConstraints(tableConstraints.getNotNullConstraints().stream()\n+              .filter(notNullConstraint -> notNullConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n       }\n \n-      return new ForeignKeyInfo(foreignKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_FK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all unique constraints associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get unique constraints associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getReliableUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, true);\n-  }\n-\n-  private UniqueConstraint getUniqueConstraints(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_UNIQ_CONSTRAINT);\n-    try {\n-      List<SQLUniqueConstraint> uniqueConstraints = getMSC().getUniqueConstraints(\n-              new UniqueConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n-      if (onlyReliable && uniqueConstraints != null && !uniqueConstraints.isEmpty()) {\n-        uniqueConstraints = uniqueConstraints.stream()\n-          .filter(uk -> uk.isRely_cstr())\n-          .collect(Collectors.toList());\n+      if (enable && tableConstraints != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5NTYyMw=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzOTA4Mg==", "bodyText": "ok", "url": "https://github.com/apache/hive/pull/1419#discussion_r487539082", "createdAt": "2020-09-13T14:52:49Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, true, true);\n   }\n \n-  /**\n-   * Get primary key columns associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getReliablePrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, true);\n-  }\n-\n-  private PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName, boolean onlyReliable)\n+  private TableConstraintsInfo getTableConstraints(String dbName, String tblName, boolean reliable, boolean enable)\n       throws HiveException {\n     PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_PK);\n-    try {\n-      List<SQLPrimaryKey> primaryKeys = getMSC().getPrimaryKeys(new PrimaryKeysRequest(dbName, tblName));\n-      if (onlyReliable && primaryKeys != null && !primaryKeys.isEmpty()) {\n-        primaryKeys = primaryKeys.stream()\n-          .filter(pk -> pk.isRely_cstr())\n-          .collect(Collectors.toList());\n-      }\n-\n-      return new PrimaryKeyInfo(primaryKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_PK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all foreign keys associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get foreign keys associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Foreign keys associated with the table.\n-   * @throws HiveException\n-   */\n-  public ForeignKeyInfo getReliableForeignKeys(String dbName, String tblName) throws HiveException {\n-    return getForeignKeys(dbName, tblName, true);\n-  }\n-\n-  private ForeignKeyInfo getForeignKeys(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_FK);\n-    try {\n-      List<SQLForeignKey> foreignKeys = getMSC().getForeignKeys(new ForeignKeysRequest(null, null, dbName, tblName));\n-      if (onlyReliable && foreignKeys != null && !foreignKeys.isEmpty()) {\n-        foreignKeys = foreignKeys.stream()\n-          .filter(fk -> fk.isRely_cstr())\n-          .collect(Collectors.toList());\n+    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_TABLE_CONSTRAINTS);\n+    try {\n+      SQLAllTableConstraints tableConstraints =\n+          getMSC().getAllTableConstraints(new AllTableConstraintsRequest(dbName, tblName));\n+      if (reliable && tableConstraints != null) {\n+        if (tableConstraints.getPrimaryKeys() != null && !tableConstraints.getPrimaryKeys().isEmpty()) {\n+          tableConstraints.setPrimaryKeys(\n+              tableConstraints.getPrimaryKeys().stream().filter(primaryKey -> primaryKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getForeignKeys() != null && !tableConstraints.getForeignKeys().isEmpty()) {\n+          tableConstraints.setForeignKeys(\n+              tableConstraints.getForeignKeys().stream().filter(foreignKey -> foreignKey.isRely_cstr())\n+                  .collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getUniqueConstraints() != null && !tableConstraints.getUniqueConstraints().isEmpty()) {\n+          tableConstraints.setUniqueConstraints(tableConstraints.getUniqueConstraints().stream()\n+              .filter(uniqueConstraint -> uniqueConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n+        if (tableConstraints.getNotNullConstraints() != null && !tableConstraints.getNotNullConstraints().isEmpty()) {\n+          tableConstraints.setNotNullConstraints(tableConstraints.getNotNullConstraints().stream()\n+              .filter(notNullConstraint -> notNullConstraint.isRely_cstr()).collect(Collectors.toList()));\n+        }\n       }\n \n-      return new ForeignKeyInfo(foreignKeys, tblName, dbName);\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    } finally {\n-      perfLogger.perfLogEnd(CLASS_NAME, PerfLogger.HIVE_GET_FK, \"HS2-cache\");\n-    }\n-  }\n-\n-  /**\n-   * Get all unique constraints associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, false);\n-  }\n-\n-  /**\n-   * Get unique constraints associated with the table that are available for optimization.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Unique constraints associated with the table.\n-   * @throws HiveException\n-   */\n-  public UniqueConstraint getReliableUniqueConstraints(String dbName, String tblName) throws HiveException {\n-    return getUniqueConstraints(dbName, tblName, true);\n-  }\n-\n-  private UniqueConstraint getUniqueConstraints(String dbName, String tblName, boolean onlyReliable)\n-      throws HiveException {\n-    PerfLogger perfLogger = SessionState.getPerfLogger();\n-    perfLogger.perfLogBegin(CLASS_NAME, PerfLogger.HIVE_GET_UNIQ_CONSTRAINT);\n-    try {\n-      List<SQLUniqueConstraint> uniqueConstraints = getMSC().getUniqueConstraints(\n-              new UniqueConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n-      if (onlyReliable && uniqueConstraints != null && !uniqueConstraints.isEmpty()) {\n-        uniqueConstraints = uniqueConstraints.stream()\n-          .filter(uk -> uk.isRely_cstr())\n-          .collect(Collectors.toList());\n+      if (enable && tableConstraints != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5NTYyMw=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjI3MDI4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjowMDowOVrOHQb-XQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNDo0NjoxNlrOHQyjhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5NzU5Nw==", "bodyText": "getReliableAndEnableTableConstraints() method name is confusing. It is used in only one place and hence, just expose getTableConstraints() itself.", "url": "https://github.com/apache/hive/pull/1419#discussion_r486997597", "createdAt": "2020-09-11T12:00:09Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2NzU1Nw==", "bodyText": "Agreed, Removed this wrapper function", "url": "https://github.com/apache/hive/pull/1419#discussion_r487367557", "createdAt": "2020-09-12T04:46:16Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5663,79 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n+      AllTableConstraintsRequest tableConstraintsRequest = new AllTableConstraintsRequest();\n+      tableConstraintsRequest.setDbName(dbName);\n+      tableConstraintsRequest.setTblName(tblName);\n+      tableConstraintsRequest.setCatName(getDefaultCatalog(conf));\n+      return getMSC().getAllTableConstraints(tableConstraintsRequest);\n     } catch (NoSuchObjectException e) {\n       throw e;\n     } catch (Exception e) {\n       throw new HiveException(e);\n     }\n   }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n+  public TableConstraintsInfo getAllTableConstraints(String dbName, String tblName) throws HiveException {\n+    return getTableConstraints(dbName, tblName, false, false);\n   }\n \n-  /**\n-   * Get all primary key columns associated with the table.\n-   *\n-   * @param dbName Database Name\n-   * @param tblName Table Name\n-   * @return Primary Key associated with the table.\n-   * @throws HiveException\n-   */\n-  public PrimaryKeyInfo getPrimaryKeys(String dbName, String tblName) throws HiveException {\n-    return getPrimaryKeys(dbName, tblName, false);\n+  public TableConstraintsInfo getReliableAndEnableTableConstraints(String dbName, String tblName) throws HiveException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5NzU5Nw=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjI3MjkxOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjowMTowNVrOHQcAAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNzo1NDoxMlrOHQzeEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODAxNg==", "bodyText": "nit: Add space before and after \"=\".", "url": "https://github.com/apache/hive/pull/1419#discussion_r486998016", "createdAt": "2020-09-11T12:01:05Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched=false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM4MjU0NQ==", "bodyText": "done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487382545", "createdAt": "2020-09-12T07:54:12Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched=false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODAxNg=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjI3NDkzOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjowMTo0NVrOHQcBOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNzo1NDozM1rOHQzeKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODMyOA==", "bodyText": "Log dbName.tblName.", "url": "https://github.com/apache/hive/pull/1419#discussion_r486998328", "createdAt": "2020-09-11T12:01:45Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM4MjU2OA==", "bodyText": "replaced with complete name", "url": "https://github.com/apache/hive/pull/1419#discussion_r487382568", "createdAt": "2020-09-12T07:54:33Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODMyOA=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjI3NzQ4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjowMjozOFrOHQcCxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNzo1NjowMlrOHQzewA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODcyNQ==", "bodyText": "Do we need an extra flag? Can't we just check null for tableConstraintsInfo?", "url": "https://github.com/apache/hive/pull/1419#discussion_r486998725", "createdAt": "2020-09-11T12:02:38Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched=false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM4MjcyMA==", "bodyText": "Since we have wrapper in place. Now we don't require extra flag to track the object is fetched or not. We can have if condition to check wrapper is null or not", "url": "https://github.com/apache/hive/pull/1419#discussion_r487382720", "createdAt": "2020-09-12T07:56:02Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched=false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk5ODcyNQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjMwNjU5OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjoxMTo1MlrOHQcUHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNjo1MDoyNFrOHQ9yRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzE2NQ==", "bodyText": "Just add a note that we don't make copy of constraints we just refer to same input constraints object.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487003165", "createdAt": "2020-09-11T12:11:52Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);\n       }\n     }\n-    return pki;\n+    return tableConstraintsInfo;\n   }\n \n-  public void setPrimaryKeyInfo(PrimaryKeyInfo pki) {\n-    this.pki = pki;\n-    this.isPKFetched = true;\n+  /**\n+   * TableConstraintsInfo setter\n+   * @param tableConstraintsInfo\n+   */\n+  public void setTableConstraintsInfo(TableConstraintsInfo tableConstraintsInfo) {\n+    this.tableConstraintsInfo = tableConstraintsInfo;\n+    this.isTableConstraintsFetched = true;\n   }\n \n-  /* This only return FK constraints which are created with RELY */\n-  public ForeignKeyInfo getForeignKeyInfo() {\n-    if(!isFKFetched) {\n-      try {\n-        fki = Hive.get().getReliableForeignKeys(this.getDbName(), this.getTableName());\n-        this.isFKFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve FK info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+  /**\n+   * This only return PK which are created with RELY\n+   * @return primary key constraint list\n+   */\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    if (!this.isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return fki;\n+    return tableConstraintsInfo.getPrimaryKeyInfo();\n   }\n \n-  public void setForeignKeyInfo(ForeignKeyInfo fki) {\n-    this.fki = fki;\n-    this.isFKFetched = true;\n+  /**\n+   * This only return FK constraints which are created with RELY\n+   * @return foreign key constraint list\n+   */\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n+    }\n+    return tableConstraintsInfo.getForeignKeyInfo();\n   }\n \n-  /* This only return UNIQUE constraint defined with RELY */\n+  /**\n+   * This only return UNIQUE constraint defined with RELY\n+   * @return unique constraint list\n+   */\n   public UniqueConstraint getUniqueKeyInfo() {\n-    if(!isUniqueFetched) {\n-      try {\n-        uki = Hive.get().getReliableUniqueConstraints(this.getDbName(), this.getTableName());\n-        this.isUniqueFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve Unique Key info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return uki;\n-  }\n-\n-  public void setUniqueKeyInfo(UniqueConstraint uki) {\n-    this.uki = uki;\n-    this.isUniqueFetched = true;\n+    return tableConstraintsInfo.getUniqueConstraint();\n   }\n \n-  /* This only return NOT NULL constraint defined with RELY */\n+  /**\n+   * This only return NOT NULL constraint defined with RELY\n+   * @return not null constraint list\n+   */\n   public NotNullConstraint getNotNullConstraint() {\n-    if(!isNotNullFetched) {\n-      try {\n-        nnc = Hive.get().getReliableNotNullConstraints(this.getDbName(), this.getTableName());\n-        this.isNotNullFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Not Null constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return nnc;\n-  }\n-\n-  public void setNotNullConstraint(NotNullConstraint nnc) {\n-    this.nnc = nnc;\n-    this.isNotNullFetched = true;\n+    return tableConstraintsInfo.getNotNullConstraint();\n   }\n \n-  /* This only return DEFAULT constraint defined with ENABLE */\n+  /**\n+   * This only return DEFAULT constraint defined with ENABLE\n+   * @return default constraint list\n+   */\n   public DefaultConstraint getDefaultConstraint() {\n-    if(!isDefaultFetched) {\n-      try {\n-        dc = Hive.get().getEnabledDefaultConstraints(this.getDbName(), this.getTableName());\n-        this.isDefaultFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Default constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return dc;\n+    return tableConstraintsInfo.getDefaultConstraint();\n   }\n \n-  public void setDefaultConstraint(DefaultConstraint dc) {\n-    this.dc = dc;\n-    this.isDefaultFetched = true;\n-  }\n-\n-  /* This only return CHECK constraint defined with ENABLE */\n+  /**\n+   * This only return CHECK constraint defined with ENABLE\n+   * @return check constraint list\n+   */\n   public CheckConstraint getCheckConstraint() {\n-    if(!isCheckFetched) {\n-      try{\n-        cc = Hive.get().getEnabledCheckConstraints(this.getDbName(), this.getTableName());\n-        this.isCheckFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Check constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return cc;\n-  }\n-\n-  public void setCheckConstraint(CheckConstraint cc) {\n-    this.cc = cc;\n-    this.isCheckFetched = true;\n+    return tableConstraintsInfo.getCheckConstraint();\n   }\n \n   /** This shouldn't use get apis because those api call metastore\n    * to fetch constraints.\n    * getMetaData only need to make a copy of existing constraints, even if those are not fetched\n    */\n   public void copyConstraints(final Table tbl) {\n-    this.pki = tbl.pki;\n-    this.isPKFetched = tbl.isPKFetched;\n-\n-    this.fki = tbl.fki;\n-    this.isFKFetched = tbl.isFKFetched;\n-\n-    this.uki = tbl.uki;\n-    this.isUniqueFetched = tbl.isUniqueFetched;\n-\n-    this.nnc = tbl.nnc;\n-    this.isNotNullFetched = tbl.isNotNullFetched;\n-\n-    this.dc = tbl.dc;\n-    this.isDefaultFetched = tbl.isDefaultFetched;\n-\n-    this.cc = tbl.cc;\n-    this.isCheckFetched = tbl.isCheckFetched;\n+    this.tableConstraintsInfo = tbl.tableConstraintsInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTQ3MQ==", "bodyText": "Since the legacy way is to just copy the reference. Shouldn't I create a deep copy instead of reference?", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375471", "createdAt": "2020-09-12T06:24:46Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);\n       }\n     }\n-    return pki;\n+    return tableConstraintsInfo;\n   }\n \n-  public void setPrimaryKeyInfo(PrimaryKeyInfo pki) {\n-    this.pki = pki;\n-    this.isPKFetched = true;\n+  /**\n+   * TableConstraintsInfo setter\n+   * @param tableConstraintsInfo\n+   */\n+  public void setTableConstraintsInfo(TableConstraintsInfo tableConstraintsInfo) {\n+    this.tableConstraintsInfo = tableConstraintsInfo;\n+    this.isTableConstraintsFetched = true;\n   }\n \n-  /* This only return FK constraints which are created with RELY */\n-  public ForeignKeyInfo getForeignKeyInfo() {\n-    if(!isFKFetched) {\n-      try {\n-        fki = Hive.get().getReliableForeignKeys(this.getDbName(), this.getTableName());\n-        this.isFKFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve FK info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+  /**\n+   * This only return PK which are created with RELY\n+   * @return primary key constraint list\n+   */\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    if (!this.isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return fki;\n+    return tableConstraintsInfo.getPrimaryKeyInfo();\n   }\n \n-  public void setForeignKeyInfo(ForeignKeyInfo fki) {\n-    this.fki = fki;\n-    this.isFKFetched = true;\n+  /**\n+   * This only return FK constraints which are created with RELY\n+   * @return foreign key constraint list\n+   */\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n+    }\n+    return tableConstraintsInfo.getForeignKeyInfo();\n   }\n \n-  /* This only return UNIQUE constraint defined with RELY */\n+  /**\n+   * This only return UNIQUE constraint defined with RELY\n+   * @return unique constraint list\n+   */\n   public UniqueConstraint getUniqueKeyInfo() {\n-    if(!isUniqueFetched) {\n-      try {\n-        uki = Hive.get().getReliableUniqueConstraints(this.getDbName(), this.getTableName());\n-        this.isUniqueFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve Unique Key info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return uki;\n-  }\n-\n-  public void setUniqueKeyInfo(UniqueConstraint uki) {\n-    this.uki = uki;\n-    this.isUniqueFetched = true;\n+    return tableConstraintsInfo.getUniqueConstraint();\n   }\n \n-  /* This only return NOT NULL constraint defined with RELY */\n+  /**\n+   * This only return NOT NULL constraint defined with RELY\n+   * @return not null constraint list\n+   */\n   public NotNullConstraint getNotNullConstraint() {\n-    if(!isNotNullFetched) {\n-      try {\n-        nnc = Hive.get().getReliableNotNullConstraints(this.getDbName(), this.getTableName());\n-        this.isNotNullFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Not Null constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return nnc;\n-  }\n-\n-  public void setNotNullConstraint(NotNullConstraint nnc) {\n-    this.nnc = nnc;\n-    this.isNotNullFetched = true;\n+    return tableConstraintsInfo.getNotNullConstraint();\n   }\n \n-  /* This only return DEFAULT constraint defined with ENABLE */\n+  /**\n+   * This only return DEFAULT constraint defined with ENABLE\n+   * @return default constraint list\n+   */\n   public DefaultConstraint getDefaultConstraint() {\n-    if(!isDefaultFetched) {\n-      try {\n-        dc = Hive.get().getEnabledDefaultConstraints(this.getDbName(), this.getTableName());\n-        this.isDefaultFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Default constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return dc;\n+    return tableConstraintsInfo.getDefaultConstraint();\n   }\n \n-  public void setDefaultConstraint(DefaultConstraint dc) {\n-    this.dc = dc;\n-    this.isDefaultFetched = true;\n-  }\n-\n-  /* This only return CHECK constraint defined with ENABLE */\n+  /**\n+   * This only return CHECK constraint defined with ENABLE\n+   * @return check constraint list\n+   */\n   public CheckConstraint getCheckConstraint() {\n-    if(!isCheckFetched) {\n-      try{\n-        cc = Hive.get().getEnabledCheckConstraints(this.getDbName(), this.getTableName());\n-        this.isCheckFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Check constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return cc;\n-  }\n-\n-  public void setCheckConstraint(CheckConstraint cc) {\n-    this.cc = cc;\n-    this.isCheckFetched = true;\n+    return tableConstraintsInfo.getCheckConstraint();\n   }\n \n   /** This shouldn't use get apis because those api call metastore\n    * to fetch constraints.\n    * getMetaData only need to make a copy of existing constraints, even if those are not fetched\n    */\n   public void copyConstraints(final Table tbl) {\n-    this.pki = tbl.pki;\n-    this.isPKFetched = tbl.isPKFetched;\n-\n-    this.fki = tbl.fki;\n-    this.isFKFetched = tbl.isFKFetched;\n-\n-    this.uki = tbl.uki;\n-    this.isUniqueFetched = tbl.isUniqueFetched;\n-\n-    this.nnc = tbl.nnc;\n-    this.isNotNullFetched = tbl.isNotNullFetched;\n-\n-    this.dc = tbl.dc;\n-    this.isDefaultFetched = tbl.isDefaultFetched;\n-\n-    this.cc = tbl.cc;\n-    this.isCheckFetched = tbl.isCheckFetched;\n+    this.tableConstraintsInfo = tbl.tableConstraintsInfo;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzE2NQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzOTY3Mg==", "bodyText": "Need to understand from the caller on the usage and add appropriate comment to mark this behavior. Deep-copy would add additional overhead.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487539672", "createdAt": "2020-09-13T14:58:07Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);\n       }\n     }\n-    return pki;\n+    return tableConstraintsInfo;\n   }\n \n-  public void setPrimaryKeyInfo(PrimaryKeyInfo pki) {\n-    this.pki = pki;\n-    this.isPKFetched = true;\n+  /**\n+   * TableConstraintsInfo setter\n+   * @param tableConstraintsInfo\n+   */\n+  public void setTableConstraintsInfo(TableConstraintsInfo tableConstraintsInfo) {\n+    this.tableConstraintsInfo = tableConstraintsInfo;\n+    this.isTableConstraintsFetched = true;\n   }\n \n-  /* This only return FK constraints which are created with RELY */\n-  public ForeignKeyInfo getForeignKeyInfo() {\n-    if(!isFKFetched) {\n-      try {\n-        fki = Hive.get().getReliableForeignKeys(this.getDbName(), this.getTableName());\n-        this.isFKFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve FK info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+  /**\n+   * This only return PK which are created with RELY\n+   * @return primary key constraint list\n+   */\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    if (!this.isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return fki;\n+    return tableConstraintsInfo.getPrimaryKeyInfo();\n   }\n \n-  public void setForeignKeyInfo(ForeignKeyInfo fki) {\n-    this.fki = fki;\n-    this.isFKFetched = true;\n+  /**\n+   * This only return FK constraints which are created with RELY\n+   * @return foreign key constraint list\n+   */\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n+    }\n+    return tableConstraintsInfo.getForeignKeyInfo();\n   }\n \n-  /* This only return UNIQUE constraint defined with RELY */\n+  /**\n+   * This only return UNIQUE constraint defined with RELY\n+   * @return unique constraint list\n+   */\n   public UniqueConstraint getUniqueKeyInfo() {\n-    if(!isUniqueFetched) {\n-      try {\n-        uki = Hive.get().getReliableUniqueConstraints(this.getDbName(), this.getTableName());\n-        this.isUniqueFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve Unique Key info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return uki;\n-  }\n-\n-  public void setUniqueKeyInfo(UniqueConstraint uki) {\n-    this.uki = uki;\n-    this.isUniqueFetched = true;\n+    return tableConstraintsInfo.getUniqueConstraint();\n   }\n \n-  /* This only return NOT NULL constraint defined with RELY */\n+  /**\n+   * This only return NOT NULL constraint defined with RELY\n+   * @return not null constraint list\n+   */\n   public NotNullConstraint getNotNullConstraint() {\n-    if(!isNotNullFetched) {\n-      try {\n-        nnc = Hive.get().getReliableNotNullConstraints(this.getDbName(), this.getTableName());\n-        this.isNotNullFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Not Null constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return nnc;\n-  }\n-\n-  public void setNotNullConstraint(NotNullConstraint nnc) {\n-    this.nnc = nnc;\n-    this.isNotNullFetched = true;\n+    return tableConstraintsInfo.getNotNullConstraint();\n   }\n \n-  /* This only return DEFAULT constraint defined with ENABLE */\n+  /**\n+   * This only return DEFAULT constraint defined with ENABLE\n+   * @return default constraint list\n+   */\n   public DefaultConstraint getDefaultConstraint() {\n-    if(!isDefaultFetched) {\n-      try {\n-        dc = Hive.get().getEnabledDefaultConstraints(this.getDbName(), this.getTableName());\n-        this.isDefaultFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Default constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return dc;\n+    return tableConstraintsInfo.getDefaultConstraint();\n   }\n \n-  public void setDefaultConstraint(DefaultConstraint dc) {\n-    this.dc = dc;\n-    this.isDefaultFetched = true;\n-  }\n-\n-  /* This only return CHECK constraint defined with ENABLE */\n+  /**\n+   * This only return CHECK constraint defined with ENABLE\n+   * @return check constraint list\n+   */\n   public CheckConstraint getCheckConstraint() {\n-    if(!isCheckFetched) {\n-      try{\n-        cc = Hive.get().getEnabledCheckConstraints(this.getDbName(), this.getTableName());\n-        this.isCheckFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Check constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return cc;\n-  }\n-\n-  public void setCheckConstraint(CheckConstraint cc) {\n-    this.cc = cc;\n-    this.isCheckFetched = true;\n+    return tableConstraintsInfo.getCheckConstraint();\n   }\n \n   /** This shouldn't use get apis because those api call metastore\n    * to fetch constraints.\n    * getMetaData only need to make a copy of existing constraints, even if those are not fetched\n    */\n   public void copyConstraints(final Table tbl) {\n-    this.pki = tbl.pki;\n-    this.isPKFetched = tbl.isPKFetched;\n-\n-    this.fki = tbl.fki;\n-    this.isFKFetched = tbl.isFKFetched;\n-\n-    this.uki = tbl.uki;\n-    this.isUniqueFetched = tbl.isUniqueFetched;\n-\n-    this.nnc = tbl.nnc;\n-    this.isNotNullFetched = tbl.isNotNullFetched;\n-\n-    this.dc = tbl.dc;\n-    this.isDefaultFetched = tbl.isDefaultFetched;\n-\n-    this.cc = tbl.cc;\n-    this.isCheckFetched = tbl.isCheckFetched;\n+    this.tableConstraintsInfo = tbl.tableConstraintsInfo;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzE2NQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU1MTU1OQ==", "bodyText": "It is only called when copy/snapshot of the table is taken in semantic analyser.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487551559", "createdAt": "2020-09-13T16:50:24Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getReliableAndEnableTableConstraints(this.getDbName(), this.getTableName());\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(\n+            \"Cannot retrieve table constraints info for table : \" + this.getTableName() + \" ignoring exception: \" + e);\n       }\n     }\n-    return pki;\n+    return tableConstraintsInfo;\n   }\n \n-  public void setPrimaryKeyInfo(PrimaryKeyInfo pki) {\n-    this.pki = pki;\n-    this.isPKFetched = true;\n+  /**\n+   * TableConstraintsInfo setter\n+   * @param tableConstraintsInfo\n+   */\n+  public void setTableConstraintsInfo(TableConstraintsInfo tableConstraintsInfo) {\n+    this.tableConstraintsInfo = tableConstraintsInfo;\n+    this.isTableConstraintsFetched = true;\n   }\n \n-  /* This only return FK constraints which are created with RELY */\n-  public ForeignKeyInfo getForeignKeyInfo() {\n-    if(!isFKFetched) {\n-      try {\n-        fki = Hive.get().getReliableForeignKeys(this.getDbName(), this.getTableName());\n-        this.isFKFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve FK info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+  /**\n+   * This only return PK which are created with RELY\n+   * @return primary key constraint list\n+   */\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    if (!this.isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return fki;\n+    return tableConstraintsInfo.getPrimaryKeyInfo();\n   }\n \n-  public void setForeignKeyInfo(ForeignKeyInfo fki) {\n-    this.fki = fki;\n-    this.isFKFetched = true;\n+  /**\n+   * This only return FK constraints which are created with RELY\n+   * @return foreign key constraint list\n+   */\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n+    }\n+    return tableConstraintsInfo.getForeignKeyInfo();\n   }\n \n-  /* This only return UNIQUE constraint defined with RELY */\n+  /**\n+   * This only return UNIQUE constraint defined with RELY\n+   * @return unique constraint list\n+   */\n   public UniqueConstraint getUniqueKeyInfo() {\n-    if(!isUniqueFetched) {\n-      try {\n-        uki = Hive.get().getReliableUniqueConstraints(this.getDbName(), this.getTableName());\n-        this.isUniqueFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\n-            \"Cannot retrieve Unique Key info for table : \" + this.getTableName()\n-                + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return uki;\n-  }\n-\n-  public void setUniqueKeyInfo(UniqueConstraint uki) {\n-    this.uki = uki;\n-    this.isUniqueFetched = true;\n+    return tableConstraintsInfo.getUniqueConstraint();\n   }\n \n-  /* This only return NOT NULL constraint defined with RELY */\n+  /**\n+   * This only return NOT NULL constraint defined with RELY\n+   * @return not null constraint list\n+   */\n   public NotNullConstraint getNotNullConstraint() {\n-    if(!isNotNullFetched) {\n-      try {\n-        nnc = Hive.get().getReliableNotNullConstraints(this.getDbName(), this.getTableName());\n-        this.isNotNullFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Not Null constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return nnc;\n-  }\n-\n-  public void setNotNullConstraint(NotNullConstraint nnc) {\n-    this.nnc = nnc;\n-    this.isNotNullFetched = true;\n+    return tableConstraintsInfo.getNotNullConstraint();\n   }\n \n-  /* This only return DEFAULT constraint defined with ENABLE */\n+  /**\n+   * This only return DEFAULT constraint defined with ENABLE\n+   * @return default constraint list\n+   */\n   public DefaultConstraint getDefaultConstraint() {\n-    if(!isDefaultFetched) {\n-      try {\n-        dc = Hive.get().getEnabledDefaultConstraints(this.getDbName(), this.getTableName());\n-        this.isDefaultFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Default constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return dc;\n+    return tableConstraintsInfo.getDefaultConstraint();\n   }\n \n-  public void setDefaultConstraint(DefaultConstraint dc) {\n-    this.dc = dc;\n-    this.isDefaultFetched = true;\n-  }\n-\n-  /* This only return CHECK constraint defined with ENABLE */\n+  /**\n+   * This only return CHECK constraint defined with ENABLE\n+   * @return check constraint list\n+   */\n   public CheckConstraint getCheckConstraint() {\n-    if(!isCheckFetched) {\n-      try{\n-        cc = Hive.get().getEnabledCheckConstraints(this.getDbName(), this.getTableName());\n-        this.isCheckFetched = true;\n-      } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve Check constraint info for table : \"\n-            + this.getTableName() + \" ignoring exception: \" + e);\n-      }\n+    if (!isTableConstraintsFetched) {\n+      getTableConstraintsInfo();\n     }\n-    return cc;\n-  }\n-\n-  public void setCheckConstraint(CheckConstraint cc) {\n-    this.cc = cc;\n-    this.isCheckFetched = true;\n+    return tableConstraintsInfo.getCheckConstraint();\n   }\n \n   /** This shouldn't use get apis because those api call metastore\n    * to fetch constraints.\n    * getMetaData only need to make a copy of existing constraints, even if those are not fetched\n    */\n   public void copyConstraints(final Table tbl) {\n-    this.pki = tbl.pki;\n-    this.isPKFetched = tbl.isPKFetched;\n-\n-    this.fki = tbl.fki;\n-    this.isFKFetched = tbl.isFKFetched;\n-\n-    this.uki = tbl.uki;\n-    this.isUniqueFetched = tbl.isUniqueFetched;\n-\n-    this.nnc = tbl.nnc;\n-    this.isNotNullFetched = tbl.isNotNullFetched;\n-\n-    this.dc = tbl.dc;\n-    this.isDefaultFetched = tbl.isDefaultFetched;\n-\n-    this.cc = tbl.cc;\n-    this.isCheckFetched = tbl.isCheckFetched;\n+    this.tableConstraintsInfo = tbl.tableConstraintsInfo;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzE2NQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 227}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjMwOTY1OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjoxMjo1N1rOHQcV3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNDo0NjozMVrOHQyjnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzYxNQ==", "bodyText": "Shall make all members private as we have get and set methods.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487003615", "createdAt": "2020-09-11T12:12:57Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.metadata;\n+\n+public class TableConstraintsInfo {\n+  PrimaryKeyInfo primaryKeyInfo;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM2NzU4Mw==", "bodyText": "Done", "url": "https://github.com/apache/hive/pull/1419#discussion_r487367583", "createdAt": "2020-09-12T04:46:31Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.metadata;\n+\n+public class TableConstraintsInfo {\n+  PrimaryKeyInfo primaryKeyInfo;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwMzYxNQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjMxODk0OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjoxNTo0MFrOHQcbLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyNjo0MVrOHQzDLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwNDk3Mg==", "bodyText": "Why is it static method? In both the callers, we pass tbl.getTableConstraintsInfo(). This can be a public method without arguments inside \"Table\" class.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487004972", "createdAt": "2020-09-11T12:15:40Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.metadata;\n+\n+public class TableConstraintsInfo {\n+  PrimaryKeyInfo primaryKeyInfo;\n+  ForeignKeyInfo foreignKeyInfo;\n+  UniqueConstraint uniqueConstraint;\n+  DefaultConstraint defaultConstraint;\n+  CheckConstraint checkConstraint;\n+  NotNullConstraint notNullConstraint;\n+\n+  public TableConstraintsInfo() {\n+  }\n+\n+  public TableConstraintsInfo(PrimaryKeyInfo primaryKeyInfo, ForeignKeyInfo foreignKeyInfo,\n+      UniqueConstraint uniqueConstraint, DefaultConstraint defaultConstraint, CheckConstraint checkConstraint,\n+      NotNullConstraint notNullConstraint) {\n+    this.primaryKeyInfo = primaryKeyInfo;\n+    this.foreignKeyInfo = foreignKeyInfo;\n+    this.uniqueConstraint = uniqueConstraint;\n+    this.defaultConstraint = defaultConstraint;\n+    this.checkConstraint = checkConstraint;\n+    this.notNullConstraint = notNullConstraint;\n+  }\n+\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    return primaryKeyInfo;\n+  }\n+\n+  public void setPrimaryKeyInfo(PrimaryKeyInfo primaryKeyInfo) {\n+    this.primaryKeyInfo = primaryKeyInfo;\n+  }\n+\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    return foreignKeyInfo;\n+  }\n+\n+  public void setForeignKeyInfo(ForeignKeyInfo foreignKeyInfo) {\n+    this.foreignKeyInfo = foreignKeyInfo;\n+  }\n+\n+  public UniqueConstraint getUniqueConstraint() {\n+    return uniqueConstraint;\n+  }\n+\n+  public void setUniqueConstraint(UniqueConstraint uniqueConstraint) {\n+    this.uniqueConstraint = uniqueConstraint;\n+  }\n+\n+  public DefaultConstraint getDefaultConstraint() {\n+    return defaultConstraint;\n+  }\n+\n+  public void setDefaultConstraint(DefaultConstraint defaultConstraint) {\n+    this.defaultConstraint = defaultConstraint;\n+  }\n+\n+  public CheckConstraint getCheckConstraint() {\n+    return checkConstraint;\n+  }\n+\n+  public void setCheckConstraint(CheckConstraint checkConstraint) {\n+    this.checkConstraint = checkConstraint;\n+  }\n+\n+  public NotNullConstraint getNotNullConstraint() {\n+    return notNullConstraint;\n+  }\n+\n+  public void setNotNullConstraint(NotNullConstraint notNullConstraint) {\n+    this.notNullConstraint = notNullConstraint;\n+  }\n+\n+  public static boolean isTableConstraintsInfoNotEmpty(TableConstraintsInfo info) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTY2MA==", "bodyText": "i was trying to maintain the code uniformity. But since we have a wrapper class in places we can remove all static method and follow OOD para-dime", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375660", "createdAt": "2020-09-12T06:26:41Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/TableConstraintsInfo.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.metadata;\n+\n+public class TableConstraintsInfo {\n+  PrimaryKeyInfo primaryKeyInfo;\n+  ForeignKeyInfo foreignKeyInfo;\n+  UniqueConstraint uniqueConstraint;\n+  DefaultConstraint defaultConstraint;\n+  CheckConstraint checkConstraint;\n+  NotNullConstraint notNullConstraint;\n+\n+  public TableConstraintsInfo() {\n+  }\n+\n+  public TableConstraintsInfo(PrimaryKeyInfo primaryKeyInfo, ForeignKeyInfo foreignKeyInfo,\n+      UniqueConstraint uniqueConstraint, DefaultConstraint defaultConstraint, CheckConstraint checkConstraint,\n+      NotNullConstraint notNullConstraint) {\n+    this.primaryKeyInfo = primaryKeyInfo;\n+    this.foreignKeyInfo = foreignKeyInfo;\n+    this.uniqueConstraint = uniqueConstraint;\n+    this.defaultConstraint = defaultConstraint;\n+    this.checkConstraint = checkConstraint;\n+    this.notNullConstraint = notNullConstraint;\n+  }\n+\n+  public PrimaryKeyInfo getPrimaryKeyInfo() {\n+    return primaryKeyInfo;\n+  }\n+\n+  public void setPrimaryKeyInfo(PrimaryKeyInfo primaryKeyInfo) {\n+    this.primaryKeyInfo = primaryKeyInfo;\n+  }\n+\n+  public ForeignKeyInfo getForeignKeyInfo() {\n+    return foreignKeyInfo;\n+  }\n+\n+  public void setForeignKeyInfo(ForeignKeyInfo foreignKeyInfo) {\n+    this.foreignKeyInfo = foreignKeyInfo;\n+  }\n+\n+  public UniqueConstraint getUniqueConstraint() {\n+    return uniqueConstraint;\n+  }\n+\n+  public void setUniqueConstraint(UniqueConstraint uniqueConstraint) {\n+    this.uniqueConstraint = uniqueConstraint;\n+  }\n+\n+  public DefaultConstraint getDefaultConstraint() {\n+    return defaultConstraint;\n+  }\n+\n+  public void setDefaultConstraint(DefaultConstraint defaultConstraint) {\n+    this.defaultConstraint = defaultConstraint;\n+  }\n+\n+  public CheckConstraint getCheckConstraint() {\n+    return checkConstraint;\n+  }\n+\n+  public void setCheckConstraint(CheckConstraint checkConstraint) {\n+    this.checkConstraint = checkConstraint;\n+  }\n+\n+  public NotNullConstraint getNotNullConstraint() {\n+    return notNullConstraint;\n+  }\n+\n+  public void setNotNullConstraint(NotNullConstraint notNullConstraint) {\n+    this.notNullConstraint = notNullConstraint;\n+  }\n+\n+  public static boolean isTableConstraintsInfoNotEmpty(TableConstraintsInfo info) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAwNDk3Mg=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjM1MjA1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjoyNjoxNFrOHQcvKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMlQwNjoyNjo1M1rOHQzDOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAxMDA5MQ==", "bodyText": "nit: Add space after comma.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487010091", "createdAt": "2020-09-11T12:26:14Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -9200,6 +9200,31 @@ public CheckConstraintsResponse get_check_constraints(CheckConstraintsRequest re\n       return new CheckConstraintsResponse(ret);\n     }\n \n+    /**\n+     * Api to fetch all table constraints at once\n+     * @param request it consist of catalog name, database name and table name to identify the table in metastore\n+     * @return all cnstraint attached to given table\n+     * @throws TException\n+     */\n+    @Override\n+    public AllTableConstraintsResponse get_all_table_constraints(AllTableConstraintsRequest request) throws TException {\n+      String catName = request.isSetCatName() ? request.getCatName() : getDefaultCatalog(conf);\n+      String dbName = request.getDbName();\n+      String tblName = request.getTblName();\n+      startTableFunction(\"get_all_table_constraints\", catName, dbName, tblName);\n+      SQLAllTableConstraints ret = null;\n+      Exception ex = null;\n+      try {\n+        ret = getMS().getAllTableConstraints(catName,dbName,tblName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTY3NQ==", "bodyText": "fixed", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375675", "createdAt": "2020-09-12T06:26:53Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -9200,6 +9200,31 @@ public CheckConstraintsResponse get_check_constraints(CheckConstraintsRequest re\n       return new CheckConstraintsResponse(ret);\n     }\n \n+    /**\n+     * Api to fetch all table constraints at once\n+     * @param request it consist of catalog name, database name and table name to identify the table in metastore\n+     * @return all cnstraint attached to given table\n+     * @throws TException\n+     */\n+    @Override\n+    public AllTableConstraintsResponse get_all_table_constraints(AllTableConstraintsRequest request) throws TException {\n+      String catName = request.isSetCatName() ? request.getCatName() : getDefaultCatalog(conf);\n+      String dbName = request.getDbName();\n+      String tblName = request.getTblName();\n+      startTableFunction(\"get_all_table_constraints\", catName, dbName, tblName);\n+      SQLAllTableConstraints ret = null;\n+      Exception ex = null;\n+      try {\n+        ret = getMS().getAllTableConstraints(catName,dbName,tblName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAxMDA5MQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NjM2NzQ1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxMjozMDo1NVrOHQc4XQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNTowNzoyN1rOHQ9IQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAxMjQ0NQ==", "bodyText": "Method won't return NoSuchObjectException. Shall remove it here and from all implementations.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487012445", "createdAt": "2020-09-11T12:30:55Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java", "diffHunk": "@@ -3631,6 +3631,17 @@ boolean cacheFileMetadata(String dbName, String tableName, String partName,\n   List<SQLCheckConstraint> getCheckConstraints(CheckConstraintsRequest request) throws MetaException,\n       NoSuchObjectException, TException;\n \n+  /**\n+   * Get all constraints of given table\n+   * @param request Request info\n+   * @return all constraints of this table\n+   * @throws MetaException\n+   * @throws NoSuchObjectException\n+   * @throws TException\n+   */\n+  SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest request)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM3NTY5Mg==", "bodyText": "removed", "url": "https://github.com/apache/hive/pull/1419#discussion_r487375692", "createdAt": "2020-09-12T06:27:06Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java", "diffHunk": "@@ -3631,6 +3631,17 @@ boolean cacheFileMetadata(String dbName, String tableName, String partName,\n   List<SQLCheckConstraint> getCheckConstraints(CheckConstraintsRequest request) throws MetaException,\n       NoSuchObjectException, TException;\n \n+  /**\n+   * Get all constraints of given table\n+   * @param request Request info\n+   * @return all constraints of this table\n+   * @throws MetaException\n+   * @throws NoSuchObjectException\n+   * @throws TException\n+   */\n+  SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest request)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAxMjQ0NQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDgwMA==", "bodyText": "I can still see it here.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487540800", "createdAt": "2020-09-13T15:07:27Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/java/org/apache/hadoop/hive/metastore/IMetaStoreClient.java", "diffHunk": "@@ -3631,6 +3631,17 @@ boolean cacheFileMetadata(String dbName, String tableName, String partName,\n   List<SQLCheckConstraint> getCheckConstraints(CheckConstraintsRequest request) throws MetaException,\n       NoSuchObjectException, TException;\n \n+  /**\n+   * Get all constraints of given table\n+   * @param request Request info\n+   * @return all constraints of this table\n+   * @throws MetaException\n+   * @throws NoSuchObjectException\n+   * @throws TException\n+   */\n+  SQLAllTableConstraints getAllTableConstraints(AllTableConstraintsRequest request)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAxMjQ0NQ=="}, "originalCommit": {"oid": "5fb0873735beec39ae42f05d2dd27356c20a9063"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDEwODE4OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNDo0ODo0OFrOHQ8_7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxNzoyOTozNlrOHYMf8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzODY3MQ==", "bodyText": "Will NoSuchObjectException comes here? From the interface, it sounds not. Remove the handling here too.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487538671", "createdAt": "2020-09-13T14:48:48Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5664,69 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n-  }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName)\n+      throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n+      return getMSC().getAllTableConstraints(new AllTableConstraintsRequest(dbName, tblName, getDefaultCatalog(conf)));\n     } catch (NoSuchObjectException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEzMjY1Ng==", "bodyText": "I have added NoSuchObjectException in getAllTableConstraints() So we need to handle this here.", "url": "https://github.com/apache/hive/pull/1419#discussion_r495132656", "createdAt": "2020-09-25T17:29:36Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -5661,184 +5664,69 @@ public void dropConstraint(String dbName, String tableName, String constraintNam\n     }\n   }\n \n-  public List<SQLDefaultConstraint> getDefaultConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n-    try {\n-      return getMSC().getDefaultConstraints(new DefaultConstraintsRequest(getDefaultCatalog(conf), dbName, tblName));\n-    } catch (NoSuchObjectException e) {\n-      throw e;\n-    } catch (Exception e) {\n-      throw new HiveException(e);\n-    }\n-  }\n-\n-  public List<SQLCheckConstraint> getCheckConstraintList(String dbName, String tblName) throws HiveException, NoSuchObjectException {\n+  public SQLAllTableConstraints getTableConstraints(String dbName, String tblName)\n+      throws HiveException, NoSuchObjectException {\n     try {\n-      return getMSC().getCheckConstraints(new CheckConstraintsRequest(getDefaultCatalog(conf),\n-          dbName, tblName));\n+      return getMSC().getAllTableConstraints(new AllTableConstraintsRequest(dbName, tblName, getDefaultCatalog(conf)));\n     } catch (NoSuchObjectException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzODY3MQ=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDExNDk2OnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNDo1NjoxNFrOHQ9DLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNjo0Njo0OVrOHQ9wxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzOTUwMw==", "bodyText": "Shall remove this flag as we can check tableConstraintsInfo != null instead. Btw, we need this flag if we use default constructor in exception flow of getTableConstraintsInfo() method.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487539503", "createdAt": "2020-09-13T14:56:14Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU1MTE3NQ==", "bodyText": "Currently we don't any implementation where we are calling the default constructor. But in order to have a parameterised constructor we need need a default constructor also. As a result of which in future it might possible that some implementation use. the default constructor. So its better to move back to flag based verification.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487551175", "createdAt": "2020-09-13T16:46:49Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -116,22 +116,12 @@\n   private transient Boolean outdatedForRewritingMaterializedView;\n \n   /** Constraint related objects */\n-  private transient PrimaryKeyInfo pki;\n-  private transient ForeignKeyInfo fki;\n-  private transient UniqueConstraint uki;\n-  private transient NotNullConstraint nnc;\n-  private transient DefaultConstraint dc;\n-  private transient CheckConstraint cc;\n+  private transient TableConstraintsInfo tableConstraintsInfo;\n \n   /** Constraint related flags\n    *  This is to track if constraints are retrieved from metastore or not\n    */\n-  private transient boolean isPKFetched=false;\n-  private transient boolean isFKFetched=false;\n-  private transient boolean isUniqueFetched=false;\n-  private transient boolean isNotNullFetched=false;\n-  private transient boolean isDefaultFetched=false;\n-  private transient boolean isCheckFetched=false;\n+  private transient boolean isTableConstraintsFetched = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzUzOTUwMw=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDEyMTkxOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNTowMzo1N1rOHQ9GiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxODo0NTozMlrOHYOyCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDM2MA==", "bodyText": "Callers are assuming tableConstraintsInfo won't be null after invoking this method but it is not if there is an exception.\nCan initialize it with default constructor in this flow.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487540360", "createdAt": "2020-09-13T15:03:57Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getTableConstraints(this.getDbName(), this.getTableName(), true, true);\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE3MDA1OA==", "bodyText": "If exception generated then fall back to default constructor. As all the constraint will set to null which was the previous contract.", "url": "https://github.com/apache/hive/pull/1419#discussion_r495170058", "createdAt": "2020-09-25T18:45:32Z", "author": {"login": "ashish-kumar-sharma"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java", "diffHunk": "@@ -1176,145 +1166,101 @@ public void setStatsStateLikeNewTable() {\n    *  Note that set apis are used by DESCRIBE only, although get apis return RELY or ENABLE\n    *  constraints DESCRIBE could set all type of constraints\n    * */\n-\n-  /* This only return PK which are created with RELY */\n-  public PrimaryKeyInfo getPrimaryKeyInfo() {\n-    if(!this.isPKFetched) {\n+  public TableConstraintsInfo getTableConstraintsInfo() {\n+    if (!this.isTableConstraintsFetched) {\n       try {\n-        pki = Hive.get().getReliablePrimaryKeys(this.getDbName(), this.getTableName());\n-        this.isPKFetched = true;\n+        tableConstraintsInfo = Hive.get().getTableConstraints(this.getDbName(), this.getTableName(), true, true);\n+        this.isTableConstraintsFetched = true;\n       } catch (HiveException e) {\n-        LOG.warn(\"Cannot retrieve PK info for table : \" + this.getTableName()\n-            + \" ignoring exception: \" + e);\n+        LOG.warn(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDM2MA=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDEyNTk0OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNTowODowNlrOHQ9Idw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxNzoxOTo0NlrOHYMMIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDg1NQ==", "bodyText": "catName can be optional.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487540855", "createdAt": "2020-09-13T15:08:06Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -720,6 +729,15 @@ struct CheckConstraintsResponse {\n   1: required list<SQLCheckConstraint> checkConstraints\n }\n \n+struct AllTableConstraintsRequest {\n+  1: required string dbName,\n+  2: required string tblName,\n+  3: required string catName", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEyNzU4Nw==", "bodyText": "3 of the 6 constraint has catName required hence I have to make it required. We can open new jira to make a consistent behaviour across all the constraints.", "url": "https://github.com/apache/hive/pull/1419#discussion_r495127587", "createdAt": "2020-09-25T17:19:46Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -720,6 +729,15 @@ struct CheckConstraintsResponse {\n   1: required list<SQLCheckConstraint> checkConstraints\n }\n \n+struct AllTableConstraintsRequest {\n+  1: required string dbName,\n+  2: required string tblName,\n+  3: required string catName", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDg1NQ=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDEyNjc5OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNTowOToyMFrOHQ9I5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxNzoxODowM1rOHYMIxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDk2NA==", "bodyText": "This method also throws MetaException.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487540964", "createdAt": "2020-09-13T15:09:20Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -9330,6 +9330,31 @@ public CheckConstraintsResponse get_check_constraints(CheckConstraintsRequest re\n       return new CheckConstraintsResponse(ret);\n     }\n \n+    /**\n+     * Api to fetch all table constraints at once\n+     * @param request it consist of catalog name, database name and table name to identify the table in metastore\n+     * @return all constraints attached to given table\n+     * @throws TException\n+     */\n+    @Override\n+    public AllTableConstraintsResponse get_all_table_constraints(AllTableConstraintsRequest request) throws TException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEyNjcyNw==", "bodyText": "Added NoSuchObjectException", "url": "https://github.com/apache/hive/pull/1419#discussion_r495126727", "createdAt": "2020-09-25T17:18:03Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -9330,6 +9330,31 @@ public CheckConstraintsResponse get_check_constraints(CheckConstraintsRequest re\n       return new CheckConstraintsResponse(ret);\n     }\n \n+    /**\n+     * Api to fetch all table constraints at once\n+     * @param request it consist of catalog name, database name and table name to identify the table in metastore\n+     * @return all constraints attached to given table\n+     * @throws TException\n+     */\n+    @Override\n+    public AllTableConstraintsResponse get_all_table_constraints(AllTableConstraintsRequest request) throws TException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MDk2NA=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1MDEyODAzOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QxNToxMDoyMVrOHQ9Jdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQxNzoxNzo0NFrOHYMIOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MTExMQ==", "bodyText": "Here it shows, this method returns NoSuchObjectException but actually not. I think, the implementation should return this exception and handle in HMS client as well.", "url": "https://github.com/apache/hive/pull/1419#discussion_r487541111", "createdAt": "2020-09-13T15:10:21Z", "author": {"login": "sankarh"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -2502,6 +2520,9 @@ PartitionsResponse get_partitions_req(1:PartitionsRequest req)\n                        throws(1:MetaException o1, 2:NoSuchObjectException o2)\n   CheckConstraintsResponse get_check_constraints(1:CheckConstraintsRequest request)\n                        throws(1:MetaException o1, 2:NoSuchObjectException o2)\n+  // All table constrains\n+  AllTableConstraintsResponse get_all_table_constraints(1:AllTableConstraintsRequest request)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTEyNjU4NA==", "bodyText": "I have add the NoSuchObjectException in get_all_table_constraints.", "url": "https://github.com/apache/hive/pull/1419#discussion_r495126584", "createdAt": "2020-09-25T17:17:44Z", "author": {"login": "ashish-kumar-sharma"}, "path": "standalone-metastore/metastore-common/src/main/thrift/hive_metastore.thrift", "diffHunk": "@@ -2502,6 +2520,9 @@ PartitionsResponse get_partitions_req(1:PartitionsRequest req)\n                        throws(1:MetaException o1, 2:NoSuchObjectException o2)\n   CheckConstraintsResponse get_check_constraints(1:CheckConstraintsRequest request)\n                        throws(1:MetaException o1, 2:NoSuchObjectException o2)\n+  // All table constrains\n+  AllTableConstraintsResponse get_all_table_constraints(1:AllTableConstraintsRequest request)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU0MTExMQ=="}, "originalCommit": {"oid": "0feaa63fbbf588c43ca96dacf452187e750449cb"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 374, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}