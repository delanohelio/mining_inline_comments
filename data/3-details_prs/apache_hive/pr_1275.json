{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUxMjgxNTkx", "number": 1275, "title": "HIVE-23324: Parallelise compaction directory cleaning process", "bodyText": "NOTICE\nPlease create an issue in ASF JIRA before opening a pull request,\nand you need to set the title of the pull request which starts with\nthe corresponding JIRA issue number. (e.g. HIVE-XXXXX: Fix a typo in YYY)\nFor more details, please see https://cwiki.apache.org/confluence/display/Hive/HowToContribute", "createdAt": "2020-07-17T17:09:09Z", "url": "https://github.com/apache/hive/pull/1275", "merged": true, "mergeCommit": {"oid": "a206833639ebf69fa4c7d821f2ffca027c2f2ae5"}, "closed": true, "closedAt": "2020-07-31T18:04:31Z", "author": {"login": "adesh-rao"}, "timelineItems": {"totalCount": 44, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3DBDdgFqTQ1MjI5NDM5NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc57XNfgFqTQ1ODE5MTk3Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMjk0Mzk1", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-452294395", "createdAt": "2020-07-21T09:42:46Z", "commit": {"oid": "a94d0aacdf61a220514850b414ba0c126ef99f7e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOTo0Mjo0N1rOG0wUBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOTo0Mjo0N1rOG0wUBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA==", "bodyText": "I think it would be a good idea to shut down the executor when we finished the run loop.\nWhat do you think?", "url": "https://github.com/apache/hive/pull/1275#discussion_r457970694", "createdAt": "2020-07-21T09:42:47Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -64,13 +67,15 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n+  private Executor cleanerExecutor;\n \n   private ReplChangeManager replChangeManager;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    cleanerExecutor = Executors.newFixedThreadPool(conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a94d0aacdf61a220514850b414ba0c126ef99f7e"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMzAzNDE1", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-452303415", "createdAt": "2020-07-21T09:55:07Z", "commit": {"oid": "a94d0aacdf61a220514850b414ba0c126ef99f7e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOTo1NTowN1rOG0wvbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOTo1NTowN1rOG0wvbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3NzcwOQ==", "bodyText": "What happens if one of the futures throws the exception?\nAre the others continue to execute? Will we wait until all of the tasks are finished one way or another?\nWe do not want multiple Cleaning tasks running concurrently on the same partition.\nSeeing this the same problem might arise with the Initiator too. What do you think @deniskuzZ ?", "url": "https://github.com/apache/hive/pull/1275#discussion_r457977709", "createdAt": "2020-07-21T09:55:07Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,9 +94,12 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n+            clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a94d0aacdf61a220514850b414ba0c126ef99f7e"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNTA5Njg1", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-452509685", "createdAt": "2020-07-21T14:23:13Z", "commit": {"oid": "ce1780f8f5e5e502a9c4e220df424b89fa3ab7bc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDoyMzoxM1rOG06cXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDoyMzoxM1rOG06cXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNjY3MA==", "bodyText": "Why not just declare cleanerExecutor as and ExecutorService to start?", "url": "https://github.com/apache/hive/pull/1275#discussion_r458136670", "createdAt": "2020-07-21T14:23:13Z", "author": {"login": "belugabehr"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -113,6 +122,8 @@ public void run() {\n         }\n       }\n     } while (!stop.get());\n+\n+    ((ExecutorService)cleanerExecutor).shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce1780f8f5e5e502a9c4e220df424b89fa3ab7bc"}, "originalPosition": 46}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce1780f8f5e5e502a9c4e220df424b89fa3ab7bc", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/ce1780f8f5e5e502a9c4e220df424b89fa3ab7bc", "committedDate": "2020-07-21T10:59:34Z", "message": "Address review coment and fix configuration description"}, "afterCommit": {"oid": "82276808dc1bca746f77d4e31ff33adfc8ee0832", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/82276808dc1bca746f77d4e31ff33adfc8ee0832", "committedDate": "2020-07-21T17:04:34Z", "message": "Use named threads for initiator/cleaner parallelised threads"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMDg1Mjcz", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453085273", "createdAt": "2020-07-22T08:03:21Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowMzoyMVrOG1XUFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowMzoyMVrOG1XUFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYwOTY4NQ==", "bodyText": "Minimally log the error on info level?", "url": "https://github.com/apache/hive/pull/1275#discussion_r458609685", "createdAt": "2020-07-22T08:03:21Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 84}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMDg1NjQz", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453085643", "createdAt": "2020-07-22T08:03:52Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowMzo1MlrOG1XVIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowMzo1MlrOG1XVIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYwOTk1NA==", "bodyText": "nit of the nit: formatting:\nfor (int i = 0; i < count; i++) {", "url": "https://github.com/apache/hive/pull/1275#discussion_r458609954", "createdAt": "2020-07-22T08:03:52Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMDg2NzI3", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453086727", "createdAt": "2020-07-22T08:05:23Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowNToyM1rOG1XYew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowNToyM1rOG1XYew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMDgxMQ==", "bodyText": "Shall we move this to the run method too? It would make it easier to understand the code IMHO", "url": "https://github.com/apache/hive/pull/1275#discussion_r458610811", "createdAt": "2020-07-22T08:05:23Z", "author": {"login": "pvary"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -64,13 +72,23 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n+  private ExecutorService cleanerExecutor;\n+  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    ThreadFactory threadFactory = new ThreadFactoryBuilder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMDg3NjYw", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453087660", "createdAt": "2020-07-22T08:06:44Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODowNjo0NFrOG1XbXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODoyNzo0NlrOG1YMGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMTU1MQ==", "bodyText": "What's the reasoning behind this change?", "url": "https://github.com/apache/hive/pull/1275#discussion_r458611551", "createdAt": "2020-07-22T08:06:44Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -149,17 +156,25 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              compactionList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n+              completionService.submit(() -> {\n+                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n+                return null;\n+              });\n+              count++;\n             } catch (Throwable t) {\n               LOG.error(\"Caught exception while trying to determine if we should compact {}. \" +\n                   \"Marking failed to avoid repeated failures, {}\", ci, t);\n               ci.errorMessage = t.getMessage();\n               txnHandler.markFailed(ci);\n             }\n           }\n-          CompletableFuture.allOf(compactionList.toArray(new CompletableFuture[0]))\n-            .join();\n+          for(int i=0; i<count; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyNDAyNg==", "bodyText": "what's the reasoning behind this? if you want to call it, do it before releasing the lock!!", "url": "https://github.com/apache/hive/pull/1275#discussion_r458624026", "createdAt": "2020-07-22T08:27:46Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -182,6 +197,10 @@ public void run() {\n     } catch (Throwable t) {\n       LOG.error(\"Caught an exception in the main loop of compactor initiator, exiting \" +\n           StringUtils.stringifyException(t));\n+    } finally {\n+      if (compactionExecutor != null) {\n+        compactionExecutor.shutdownNow();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTA5NjI5", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453109629", "createdAt": "2020-07-22T08:36:14Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODozNjoxNFrOG1YgGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwODozNjoxNFrOG1YgGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyOTE0NA==", "bodyText": "what's the reasoning behind this change? returning some null doesn't add more code readability", "url": "https://github.com/apache/hive/pull/1275#discussion_r458629144", "createdAt": "2020-07-22T08:36:14Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -149,17 +156,25 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              compactionList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n+              completionService.submit(() -> {\n+                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n+                return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 49}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTM0ODc1", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453134875", "createdAt": "2020-07-22T09:09:44Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOTowOTo0NFrOG1ZvqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOTowOTo0NFrOG1ZvqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY0OTUxMw==", "bodyText": "CompletableFuture is a better choice", "url": "https://github.com/apache/hive/pull/1275#discussion_r458649513", "createdAt": "2020-07-22T09:09:44Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTM3ODkx", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453137891", "createdAt": "2020-07-22T09:13:43Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOToxMzo0M1rOG1Z4xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOToxMzo0M1rOG1Z4xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MTg0Nw==", "bodyText": "shutdown should be called here, otherwise you can terminate threads from 2nd iteration", "url": "https://github.com/apache/hive/pull/1275#discussion_r458651847", "createdAt": "2020-07-22T09:13:43Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?\n+            }\n+          }\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTQwODc0", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453140874", "createdAt": "2020-07-22T09:17:41Z", "commit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOToxNzo0MVrOG1aB4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOToxNzo0MVrOG1aB4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NDE3OQ==", "bodyText": "could we refactor this block by negating if condition and removing continue part?", "url": "https://github.com/apache/hive/pull/1275#discussion_r458654179", "createdAt": "2020-07-22T09:17:41Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?\n+            }\n+          }\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n-        try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime >= cleanerCheckInterval || stop.get())  {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTcyNDg2", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453172486", "createdAt": "2020-07-22T10:00:23Z", "commit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDowMDoyNFrOG1bj6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDowMDoyNFrOG1bj6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3OTI3Mw==", "bodyText": "Could you please move this to constants", "url": "https://github.com/apache/hive/pull/1275#discussion_r458679273", "createdAt": "2020-07-22T10:00:24Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -79,7 +81,9 @@ public void run() {\n       cleanerCheckInterval = conf.getTimeVar(\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n-\n+    String threadNameFormat = \"Cleaner-executor-thread-%d\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMjAyMDE2", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453202016", "createdAt": "2020-07-22T10:45:25Z", "commit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo0NToyNVrOG1c_gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo0NToyNVrOG1c_gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw==", "bodyText": "what's the purpose of executor service shutdown? it would be needed only when Cleaner thread terminates", "url": "https://github.com/apache/hive/pull/1275#discussion_r458702723", "createdAt": "2020-07-22T10:45:25Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,23 +93,28 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n       } catch (Throwable t) {\n         LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n+                StringUtils.stringifyException(t));\n+        if (cleanerExecutor != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMjA0MDU3", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453204057", "createdAt": "2020-07-22T10:48:41Z", "commit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo0ODo0MVrOG1dF0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo0ODo0MVrOG1dF0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNDMzOQ==", "bodyText": "could you move negation inside: elapsedTime < cleanerCheckInterval && !stop.get()", "url": "https://github.com/apache/hive/pull/1275#discussion_r458704339", "createdAt": "2020-07-22T10:48:41Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,23 +93,28 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n       } catch (Throwable t) {\n         LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n+                StringUtils.stringifyException(t));\n+        if (cleanerExecutor != null) {\n+          cleanerExecutor.shutdownNow();\n+          cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+                  conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n+        }\n+      } finally {\n         if (handle != null) {\n           handle.releaseLocks();\n         }\n       }\n       // Now, go back to bed until it's time to do this again\n       long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+      if (!(elapsedTime >= cleanerCheckInterval || stop.get())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMjA1NDE3", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453205417", "createdAt": "2020-07-22T10:50:51Z", "commit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1MDo1MVrOG1dKMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1MDo1MVrOG1dKMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNTQ1OQ==", "bodyText": "same as above, what's the purpose of executor service shutdown? it would be needed only when Initiator thread terminates", "url": "https://github.com/apache/hive/pull/1275#discussion_r458705459", "createdAt": "2020-07-22T10:50:51Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -166,6 +167,11 @@ public void run() {\n         } catch (Throwable t) {\n           LOG.error(\"Initiator loop caught unexpected exception this time through the loop: \" +\n               StringUtils.stringifyException(t));\n+          if (compactionExecutor != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMjA2NjY4", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453206668", "createdAt": "2020-07-22T10:52:52Z", "commit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1Mjo1M1rOG1dN7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1Mjo1M1rOG1dN7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNjQxNA==", "bodyText": "should it be ThreadUtil?", "url": "https://github.com/apache/hive/pull/1275#discussion_r458706414", "createdAt": "2020-07-22T10:52:53Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.txn.compactor;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class CompactorUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36b661a6f02c0584bdbad59785ab1d5d38da07c"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNTUxNjcx", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453551671", "createdAt": "2020-07-22T17:52:41Z", "commit": {"oid": "f1029d56a3867daa29035c67e8eca3fcec9080f7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzo1Mjo0MVrOG1tsZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzo1Mjo0MVrOG1tsZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3NjM1OA==", "bodyText": "move this under init, including cleanerCheckInterval initialization", "url": "https://github.com/apache/hive/pull/1275#discussion_r458976358", "createdAt": "2020-07-22T17:52:41Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -79,7 +82,9 @@ public void run() {\n       cleanerCheckInterval = conf.getTimeVar(\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n-\n+    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1029d56a3867daa29035c67e8eca3fcec9080f7"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNTUzNzEw", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-453553710", "createdAt": "2020-07-22T17:55:26Z", "commit": {"oid": "f1029d56a3867daa29035c67e8eca3fcec9080f7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzo1NToyNlrOG1tzQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNzo1NToyNlrOG1tzQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3ODExNQ==", "bodyText": "move this under init", "url": "https://github.com/apache/hive/pull/1275#discussion_r458978115", "createdAt": "2020-07-22T17:55:26Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -87,6 +87,9 @@\n   public void run() {\n     // Make sure nothing escapes this run method and kills the metastore at large,\n     // so wrap it in a big catch Throwable statement.\n+    ExecutorService compactionExecutor = CompactorUtil.createExecutorWithThreadFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1029d56a3867daa29035c67e8eca3fcec9080f7"}, "originalPosition": 29}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0MTEwMTMw", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-454110130", "createdAt": "2020-07-23T13:05:31Z", "commit": {"oid": "001595fed553b5eec519e244c74e75d071f3ddf4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMzowNTozMVrOG2JkdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMzowNTozMVrOG2JkdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzMzA3Nw==", "bodyText": "@deniskuzZ This condition is modified. The previous comment is there on the outdated code.", "url": "https://github.com/apache/hive/pull/1275#discussion_r459433077", "createdAt": "2020-07-23T13:05:31Z", "author": {"login": "adesh-rao"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n-        }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+  @Override\n+  public void run() {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n+        }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "001595fed553b5eec519e244c74e75d071f3ddf4"}, "originalPosition": 94}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "001595fed553b5eec519e244c74e75d071f3ddf4", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/001595fed553b5eec519e244c74e75d071f3ddf4", "committedDate": "2020-07-23T13:03:59Z", "message": "Add executor shutdown"}, "afterCommit": {"oid": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/22df6f60e678119c89dc9e3a592d79a09d65a55b", "committedDate": "2020-07-23T16:54:34Z", "message": "Add executor shutdown"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/22df6f60e678119c89dc9e3a592d79a09d65a55b", "committedDate": "2020-07-23T16:54:34Z", "message": "Add executor shutdown"}, "afterCommit": {"oid": "87414359c1ac92562e9d5de4249b6b68a9ab402a", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/87414359c1ac92562e9d5de4249b6b68a9ab402a", "committedDate": "2020-07-24T09:46:46Z", "message": "Add executor shutdown"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "87414359c1ac92562e9d5de4249b6b68a9ab402a", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/87414359c1ac92562e9d5de4249b6b68a9ab402a", "committedDate": "2020-07-24T09:46:46Z", "message": "Add executor shutdown"}, "afterCommit": {"oid": "2c0798db8730e422a9a4bbf00dd81472ee5e9825", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/2c0798db8730e422a9a4bbf00dd81472ee5e9825", "committedDate": "2020-07-24T12:02:24Z", "message": "Add executor shutdown"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1NTQ5NzI3", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-455549727", "createdAt": "2020-07-27T07:48:43Z", "commit": {"oid": "2c0798db8730e422a9a4bbf00dd81472ee5e9825"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QwNzo0ODo0M1rOG3XSoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QwNzo0ODo0M1rOG3XSoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDcwNjQ2NQ==", "bodyText": "i think, this if check is redundant.", "url": "https://github.com/apache/hive/pull/1275#discussion_r460706465", "createdAt": "2020-07-27T07:48:43Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2c0798db8730e422a9a4bbf00dd81472ee5e9825"}, "originalPosition": 27}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2c0798db8730e422a9a4bbf00dd81472ee5e9825", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/2c0798db8730e422a9a4bbf00dd81472ee5e9825", "committedDate": "2020-07-24T12:02:24Z", "message": "Add executor shutdown"}, "afterCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/c6ef5ddca2ea3009ceb99140079a6d694c642c17", "committedDate": "2020-07-27T14:59:12Z", "message": "Remove redundant check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2MzEyNTQ2", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-456312546", "createdAt": "2020-07-28T05:29:33Z", "commit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2MzE0NTMy", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-456314532", "createdAt": "2020-07-28T05:35:30Z", "commit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTozNTozMFrOG39TJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwNTozNTozMFrOG39TJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ==", "bodyText": "InterruptedException catch redundant as well (see Initiator)", "url": "https://github.com/apache/hive/pull/1275#discussion_r461329189", "createdAt": "2020-07-28T05:35:30Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,60 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    cleanerCheckInterval = conf.getTimeVar(\n+            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n-        }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "originalPosition": 95}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca5addc861df51983a91f709bf5294ac05fc24ae", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/ca5addc861df51983a91f709bf5294ac05fc24ae", "committedDate": "2020-07-28T12:32:44Z", "message": "Parallelise compaction directory cleaning process"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "506103475d1088dcc86d2ef17c78acb15a1b5b39", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/506103475d1088dcc86d2ef17c78acb15a1b5b39", "committedDate": "2020-07-28T12:32:44Z", "message": "Address review coment and fix configuration description"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87b57be2533ae49c5e390ef792bdbd8e53a52e98", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/87b57be2533ae49c5e390ef792bdbd8e53a52e98", "committedDate": "2020-07-28T12:32:44Z", "message": "Use named threads for initiator/cleaner parallelised threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d5dc57a1925b811507e63d7d6397e38bbf07859f", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/d5dc57a1925b811507e63d7d6397e38bbf07859f", "committedDate": "2020-07-28T12:32:44Z", "message": "Use completion service to wait for executor completion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fb5a35a9c305413b92631f820e88a372df2bd59", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/8fb5a35a9c305413b92631f820e88a372df2bd59", "committedDate": "2020-07-28T12:32:44Z", "message": "Revert \"Use completion service to wait for executor completion\"\n\nThis reverts commit b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9510700d0a26e35789a0bcdd543371ad9139146f", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/9510700d0a26e35789a0bcdd543371ad9139146f", "committedDate": "2020-07-28T12:32:44Z", "message": "Use utility to create executor and fix executor shutdown"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a505763f2c3e325083af7463dd7de4b6388ed99", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/6a505763f2c3e325083af7463dd7de4b6388ed99", "committedDate": "2020-07-28T12:32:44Z", "message": "add constant and fix if condition"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38ac6cd48cb9d24f1dc684de4172ebcda5c2aafe", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/38ac6cd48cb9d24f1dc684de4172ebcda5c2aafe", "committedDate": "2020-07-28T12:32:44Z", "message": "do not reinitialize executor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6039bbffba51682f9cbfb073837e490994ca0106", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/6039bbffba51682f9cbfb073837e490994ca0106", "committedDate": "2020-07-28T12:32:44Z", "message": "Add executor shutdown"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/5f16fd20aafe062e5c70cfacc22a944591210f68", "committedDate": "2020-07-28T12:32:44Z", "message": "Remove redundant check"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/c6ef5ddca2ea3009ceb99140079a6d694c642c17", "committedDate": "2020-07-27T14:59:12Z", "message": "Remove redundant check"}, "afterCommit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/5f16fd20aafe062e5c70cfacc22a944591210f68", "committedDate": "2020-07-28T12:32:44Z", "message": "Remove redundant check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MjI4MTQ4", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-457228148", "createdAt": "2020-07-29T06:28:31Z", "commit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNjoyODozMVrOG4qV1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwNjoyODozMVrOG4qV1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA2NzE1Nw==", "bodyText": "@adesh-rao, it should behave same way as in Initiator. if you interrupt the thread - it should be cleanly interrupted. To be honest i don't see the difference. try-catch in Cleaner covers main do-while loop in Thread.run. Am I missing something here?", "url": "https://github.com/apache/hive/pull/1275#discussion_r462067157", "createdAt": "2020-07-29T06:28:31Z", "author": {"login": "deniskuzZ"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,60 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    cleanerCheckInterval = conf.getTimeVar(\n+            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n-        }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, "originalCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "originalPosition": 95}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NDE4MzA3", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-456418307", "createdAt": "2020-07-28T08:34:39Z", "commit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQwODozNDo0MFrOG4CYAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwODoxNzozNlrOG4tsdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjM1Mg==", "bodyText": "nit: Make it 2 space tabs.", "url": "https://github.com/apache/hive/pull/1275#discussion_r461412352", "createdAt": "2020-07-28T08:34:40Z", "author": {"login": "sankarh"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.txn.compactor;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class CompactorUtil {\n+    public interface ThrowingRunnable<E extends Exception> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyMTEwMQ==", "bodyText": "The config name can be relevant. It actually represent how many threads that we use for parallelly run the cleaner. But, the name sounds like Queue name. Can we change it to \"HIVE_COMPACTOR_CLEANER_THREADS_NUM\"?", "url": "https://github.com/apache/hive/pull/1275#discussion_r461421101", "createdAt": "2020-07-28T08:49:06Z", "author": {"login": "sankarh"}, "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "diffHunk": "@@ -3028,6 +3028,9 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n \n     HIVE_COMPACTOR_CLEANER_RUN_INTERVAL(\"hive.compactor.cleaner.run.interval\", \"5000ms\",\n         new TimeValidator(TimeUnit.MILLISECONDS), \"Time between runs of the cleaner thread\"),\n+    HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE(\"hive.compactor.cleaner.request.queue\", 1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMDE3Nw==", "bodyText": "nit: Make it \"for (int i = 0; i < 10; i++)\". Check other places in this patch.", "url": "https://github.com/apache/hive/pull/1275#discussion_r462120177", "createdAt": "2020-07-29T08:14:37Z", "author": {"login": "sankarh"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMTMyMw==", "bodyText": "nit: Need a blank line after closing braces,", "url": "https://github.com/apache/hive/pull/1275#discussion_r462121323", "createdAt": "2020-07-29T08:16:25Z", "author": {"login": "sankarh"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {\n+      p = newPartition(t, \"today\" + i);\n+\n+      addBaseFile(t, p, 20L, 20);\n+      addDeltaFile(t, p, 21L, 22L, 2);\n+      addDeltaFile(t, p, 23L, 24L, 2);\n+      addDeltaFile(t, p, 21L, 24L, 4);\n+      partitions.add(p);\n+    }\n+    burnThroughTransactions(\"default\", \"camipc\", 25);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMjEwMA==", "bodyText": "nit: Keep the code block of \"if\", \"else if\" and \"else\" in new line with a tab space.", "url": "https://github.com/apache/hive/pull/1275#discussion_r462122100", "createdAt": "2020-07-29T08:17:36Z", "author": {"login": "sankarh"}, "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {\n+      p = newPartition(t, \"today\" + i);\n+\n+      addBaseFile(t, p, 20L, 20);\n+      addDeltaFile(t, p, 21L, 22L, 2);\n+      addDeltaFile(t, p, 23L, 24L, 2);\n+      addDeltaFile(t, p, 21L, 24L, 4);\n+      partitions.add(p);\n+    }\n+    burnThroughTransactions(\"default\", \"camipc\", 25);\n+    for(int i=0; i<10; i++) {\n+      CompactionRequest rqst = new CompactionRequest(\"default\", \"camipc\", CompactionType.MINOR);\n+      rqst.setPartitionname(\"ds=today\"+i);\n+      txnHandler.compact(rqst);\n+      CompactionInfo ci = txnHandler.findNextToCompact(\"fred\");\n+      ci.runAs = System.getProperty(\"user.name\");\n+      txnHandler.updateCompactorState(ci, openTxn());\n+      txnHandler.markCompacted(ci);\n+    }\n+\n+    conf.setIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE, 3);\n+    startCleaner();\n+\n+    // Check there are no compactions requests left.\n+    ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n+    Assert.assertEquals(10, rsp.getCompactsSize());\n+    Assert.assertTrue(TxnStore.SUCCEEDED_RESPONSE.equals(rsp.getCompacts().get(0).getState()));\n+\n+    // Check that the files are removed\n+    for (Partition pa : partitions) {\n+      List<Path> paths = getDirectories(conf, t, pa);\n+      Assert.assertEquals(2, paths.size());\n+      boolean sawBase = false, sawDelta = false;\n+      for (Path path : paths) {\n+        if (path.getName().equals(\"base_20\")) sawBase = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68"}, "originalPosition": 74}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3d1dc37bfa5bfbda075f84b181a3884c49c0e59", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/f3d1dc37bfa5bfbda075f84b181a3884c49c0e59", "committedDate": "2020-07-29T08:33:58Z", "message": "Log exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "423fa2adb7631540c2d3f56af47429659814cb5f", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/423fa2adb7631540c2d3f56af47429659814cb5f", "committedDate": "2020-07-29T08:42:04Z", "message": "fix review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b61fa6003cec9d1c4716cb8957edc779d93fc76", "author": {"user": {"login": "adesh-rao", "name": "Adesh Kumar Rao"}}, "url": "https://github.com/apache/hive/commit/0b61fa6003cec9d1c4716cb8957edc779d93fc76", "committedDate": "2020-07-29T19:06:25Z", "message": "Exit if cleaner thread got interrupted"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4MTkxOTc2", "url": "https://github.com/apache/hive/pull/1275#pullrequestreview-458191976", "createdAt": "2020-07-30T08:29:31Z", "commit": {"oid": "0b61fa6003cec9d1c4716cb8957edc779d93fc76"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3575, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}