{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5NjEwOTQy", "number": 1258, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxOTo1MDozNFrOEO1ZWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxOTo1MDozNFrOEO1ZWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTkwMzYzOnYy", "diffSide": "RIGHT", "path": "parser/bin/fixHiveParser.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxOTo1MDozNFrOGyNc0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMToxNDoyN1rOGyQhow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMwMjM1Mg==", "bodyText": "Looks like AWK reinvented in bash", "url": "https://github.com/apache/hive/pull/1258#discussion_r455302352", "createdAt": "2020-07-15T19:50:34Z", "author": {"login": "t3rmin4t0r"}, "path": "parser/bin/fixHiveParser.sh", "diffHunk": "@@ -0,0 +1,44 @@\n+#!/bin/bash\n+\n+# This is a temporary solution for the issue of the \"code too large\" problem related to HiveParser.java\n+# We got to a point where adding anything to the antlr files lead to an issue about having a HiveParser.java that can not be compiled due to the compiled code size limitation in java (maximum 65536 bytes), so to avoid it we temorarly add this script to remove the huge tokenNames array into a separate file.\n+# The real solution would be to switch to antlr 4\n+\n+tokenFile=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParserTokens.java\"\n+input=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java\"\n+output=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java-fixed\"\n+\n+rm $tokenFile > /dev/null 2>&1\n+rm $output > /dev/null 2>&1\n+\n+echo \"package org.apache.hadoop.hive.ql.parse;\" >> $tokenFile\n+echo \"\" >> $tokenFile\n+echo \"public class HiveParserTokens {\" >> $tokenFile\n+\n+state=\"STAY\"\n+while IFS= read -r line", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a63015cef2ade3318b08ae2675702b74cd58ab5"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTM1MjczOQ==", "bodyText": "Thank you @t3rmin4t0r, I've modified the patch using awk.", "url": "https://github.com/apache/hive/pull/1258#discussion_r455352739", "createdAt": "2020-07-15T21:14:27Z", "author": {"login": "miklosgergely"}, "path": "parser/bin/fixHiveParser.sh", "diffHunk": "@@ -0,0 +1,44 @@\n+#!/bin/bash\n+\n+# This is a temporary solution for the issue of the \"code too large\" problem related to HiveParser.java\n+# We got to a point where adding anything to the antlr files lead to an issue about having a HiveParser.java that can not be compiled due to the compiled code size limitation in java (maximum 65536 bytes), so to avoid it we temorarly add this script to remove the huge tokenNames array into a separate file.\n+# The real solution would be to switch to antlr 4\n+\n+tokenFile=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParserTokens.java\"\n+input=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java\"\n+output=\"target/generated-sources/antlr3/org/apache/hadoop/hive/ql/parse/HiveParser.java-fixed\"\n+\n+rm $tokenFile > /dev/null 2>&1\n+rm $output > /dev/null 2>&1\n+\n+echo \"package org.apache.hadoop.hive.ql.parse;\" >> $tokenFile\n+echo \"\" >> $tokenFile\n+echo \"public class HiveParserTokens {\" >> $tokenFile\n+\n+state=\"STAY\"\n+while IFS= read -r line", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMwMjM1Mg=="}, "originalCommit": {"oid": "4a63015cef2ade3318b08ae2675702b74cd58ab5"}, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 584, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}