{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQwODI4MjA5", "number": 1787, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOToyNTowNVrOFH6AnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxOTozNToyMFrOFPWuTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODM0NzgwOnYy", "diffSide": "RIGHT", "path": "ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOToyNTowNVrOIJjXEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODozODoyMlrOIJy3Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4NzQ0MA==", "bodyText": "You can remove Constants just like in the previous patch. Same is true for other classes where you've removed unused imports in the previous patch, but not in this one for some reason.", "url": "https://github.com/apache/hive/pull/1787#discussion_r546887440", "createdAt": "2020-12-21T19:25:05Z", "author": {"login": "miklosgergely"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java", "diffHunk": "@@ -28,7 +28,7 @@\n import javax.security.auth.login.LoginException;\n \n import org.apache.hadoop.hive.conf.Constants;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTQ1MA==", "bodyText": "Removed", "url": "https://github.com/apache/hive/pull/1787#discussion_r547141450", "createdAt": "2020-12-22T08:38:22Z", "author": {"login": "dataproc-metastore"}, "path": "ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java", "diffHunk": "@@ -28,7 +28,7 @@\n import javax.security.auth.login.LoginException;\n \n import org.apache.hadoop.hive.conf.Constants;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4NzQ0MA=="}, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODM2MzY1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOTozMDozOFrOIJjgEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNTozMTozMFrOIJ_LVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4OTc0NQ==", "bodyText": "Please fix the indentation. There are a lot of other indentation issues introduced since the last version (also some fixed). Please run a checkstyle check (mvn checkstyle:checkstyle) on the metastore-server project, and fix at least the indentation issues in the HMSHandler class (preferably all the other issues too in this class).", "url": "https://github.com/apache/hive/pull/1787#discussion_r546889745", "createdAt": "2020-12-21T19:30:38Z", "author": {"login": "miklosgergely"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitCompactionEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage.EventType;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {\n+  public static final Logger LOG = LoggerFactory.getLogger(HMSHandler.class);\n+  private final Configuration conf; // stores datastore (jpox) properties,\n+                                   // right now they come from jpox.properties\n+\n+  // Flag to control that always threads are initialized only once\n+  // instead of multiple times\n+  private final static AtomicBoolean alwaysThreadsInitialized =\n+      new AtomicBoolean(false);\n+\n+  private static String currentUrl;\n+  private FileMetadataManager fileMetadataManager;\n+  private PartitionExpressionProxy expressionProxy;\n+  private StorageSchemaReader storageSchemaReader;\n+  private IMetaStoreMetadataTransformer transformer;\n+\n+  // Variables for metrics\n+  // Package visible so that HMSMetricsListener can see them.\n+  static AtomicInteger databaseCount, tableCount, partCount;\n+\n+  public static final String PARTITION_NUMBER_EXCEED_LIMIT_MSG =\n+      \"Number of partitions scanned (=%d) on table '%s' exceeds limit (=%d). This is controlled on the metastore server by %s.\";\n+\n+  // Used for testing to simulate method timeout.\n+  @VisibleForTesting\n+  static boolean TEST_TIMEOUT_ENABLED = false;\n+  @VisibleForTesting\n+  static long TEST_TIMEOUT_VALUE = -1;\n+\n+  public static final String ADMIN = \"admin\";\n+  public static final String PUBLIC = \"public\";\n+\n+  static final String NO_FILTER_STRING = \"\";\n+  static final int UNLIMITED_MAX_PARTITIONS = -1;\n+\n+  private Warehouse wh; // hdfs warehouse\n+  private static final ThreadLocal<RawStore> threadLocalMS =\n+      new ThreadLocal<RawStore>() {\n+        @Override\n+        protected RawStore initialValue() {\n+          return null;\n+        }\n+      };\n+\n+  private static final ThreadLocal<TxnStore> threadLocalTxn = new ThreadLocal<TxnStore>() {\n+    @Override\n+    protected TxnStore initialValue() {\n+      return null;\n+    }\n+  };\n+\n+  private static final ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>> timerContexts =\n+      new ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>>() {\n+    @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE5MjMyNQ==", "bodyText": "Fixed the indentation in HMSHandler and HiveMetaStore. Some of the issues in HMSHandler stem from mismatch of Thrift method names and checkstyle rules, I don't think they are touchable. I fixed many others, WDYT now?", "url": "https://github.com/apache/hive/pull/1787#discussion_r547192325", "createdAt": "2020-12-22T10:20:02Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitCompactionEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage.EventType;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {\n+  public static final Logger LOG = LoggerFactory.getLogger(HMSHandler.class);\n+  private final Configuration conf; // stores datastore (jpox) properties,\n+                                   // right now they come from jpox.properties\n+\n+  // Flag to control that always threads are initialized only once\n+  // instead of multiple times\n+  private final static AtomicBoolean alwaysThreadsInitialized =\n+      new AtomicBoolean(false);\n+\n+  private static String currentUrl;\n+  private FileMetadataManager fileMetadataManager;\n+  private PartitionExpressionProxy expressionProxy;\n+  private StorageSchemaReader storageSchemaReader;\n+  private IMetaStoreMetadataTransformer transformer;\n+\n+  // Variables for metrics\n+  // Package visible so that HMSMetricsListener can see them.\n+  static AtomicInteger databaseCount, tableCount, partCount;\n+\n+  public static final String PARTITION_NUMBER_EXCEED_LIMIT_MSG =\n+      \"Number of partitions scanned (=%d) on table '%s' exceeds limit (=%d). This is controlled on the metastore server by %s.\";\n+\n+  // Used for testing to simulate method timeout.\n+  @VisibleForTesting\n+  static boolean TEST_TIMEOUT_ENABLED = false;\n+  @VisibleForTesting\n+  static long TEST_TIMEOUT_VALUE = -1;\n+\n+  public static final String ADMIN = \"admin\";\n+  public static final String PUBLIC = \"public\";\n+\n+  static final String NO_FILTER_STRING = \"\";\n+  static final int UNLIMITED_MAX_PARTITIONS = -1;\n+\n+  private Warehouse wh; // hdfs warehouse\n+  private static final ThreadLocal<RawStore> threadLocalMS =\n+      new ThreadLocal<RawStore>() {\n+        @Override\n+        protected RawStore initialValue() {\n+          return null;\n+        }\n+      };\n+\n+  private static final ThreadLocal<TxnStore> threadLocalTxn = new ThreadLocal<TxnStore>() {\n+    @Override\n+    protected TxnStore initialValue() {\n+      return null;\n+    }\n+  };\n+\n+  private static final ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>> timerContexts =\n+      new ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>>() {\n+    @Override", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4OTc0NQ=="}, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 235}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM0MzE5MQ==", "bodyText": "Sure, no need to fix those. Thanks!", "url": "https://github.com/apache/hive/pull/1787#discussion_r547343191", "createdAt": "2020-12-22T15:31:30Z", "author": {"login": "miklosgergely"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitCompactionEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage.EventType;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {\n+  public static final Logger LOG = LoggerFactory.getLogger(HMSHandler.class);\n+  private final Configuration conf; // stores datastore (jpox) properties,\n+                                   // right now they come from jpox.properties\n+\n+  // Flag to control that always threads are initialized only once\n+  // instead of multiple times\n+  private final static AtomicBoolean alwaysThreadsInitialized =\n+      new AtomicBoolean(false);\n+\n+  private static String currentUrl;\n+  private FileMetadataManager fileMetadataManager;\n+  private PartitionExpressionProxy expressionProxy;\n+  private StorageSchemaReader storageSchemaReader;\n+  private IMetaStoreMetadataTransformer transformer;\n+\n+  // Variables for metrics\n+  // Package visible so that HMSMetricsListener can see them.\n+  static AtomicInteger databaseCount, tableCount, partCount;\n+\n+  public static final String PARTITION_NUMBER_EXCEED_LIMIT_MSG =\n+      \"Number of partitions scanned (=%d) on table '%s' exceeds limit (=%d). This is controlled on the metastore server by %s.\";\n+\n+  // Used for testing to simulate method timeout.\n+  @VisibleForTesting\n+  static boolean TEST_TIMEOUT_ENABLED = false;\n+  @VisibleForTesting\n+  static long TEST_TIMEOUT_VALUE = -1;\n+\n+  public static final String ADMIN = \"admin\";\n+  public static final String PUBLIC = \"public\";\n+\n+  static final String NO_FILTER_STRING = \"\";\n+  static final int UNLIMITED_MAX_PARTITIONS = -1;\n+\n+  private Warehouse wh; // hdfs warehouse\n+  private static final ThreadLocal<RawStore> threadLocalMS =\n+      new ThreadLocal<RawStore>() {\n+        @Override\n+        protected RawStore initialValue() {\n+          return null;\n+        }\n+      };\n+\n+  private static final ThreadLocal<TxnStore> threadLocalTxn = new ThreadLocal<TxnStore>() {\n+    @Override\n+    protected TxnStore initialValue() {\n+      return null;\n+    }\n+  };\n+\n+  private static final ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>> timerContexts =\n+      new ThreadLocal<Map<String, com.codahale.metrics.Timer.Context>>() {\n+    @Override", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg4OTc0NQ=="}, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 235}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODQzMTE1OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/TSetIpAddressProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOTo1Mjo0MlrOIJkIGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODozODowMlrOIJy2jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg5OTk5Mg==", "bodyText": "Unnecessary import.", "url": "https://github.com/apache/hive/pull/1787#discussion_r546899992", "createdAt": "2020-12-21T19:52:42Z", "author": {"login": "miklosgergely"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/TSetIpAddressProcessor.java", "diffHunk": "@@ -21,7 +21,7 @@\n import java.lang.reflect.InvocationTargetException;\n import java.net.Socket;\n \n-import org.apache.hadoop.hive.metastore.HiveMetaStore.HMSHandler;\n+import org.apache.hadoop.hive.metastore.HMSHandler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTI2MA==", "bodyText": "Fixed, thanks!", "url": "https://github.com/apache/hive/pull/1787#discussion_r547141260", "createdAt": "2020-12-22T08:38:02Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/TSetIpAddressProcessor.java", "diffHunk": "@@ -21,7 +21,7 @@\n import java.lang.reflect.InvocationTargetException;\n import java.net.Socket;\n \n-import org.apache.hadoop.hive.metastore.HiveMetaStore.HMSHandler;\n+import org.apache.hadoop.hive.metastore.HMSHandler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg5OTk5Mg=="}, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODQzNzEzOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/IpAddressListener.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOTo1NTowM1rOIJkL3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQwODozODowN1rOIJy2wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwMDk1OA==", "bodyText": "Unnecessary import.", "url": "https://github.com/apache/hive/pull/1787#discussion_r546900958", "createdAt": "2020-12-21T19:55:03Z", "author": {"login": "miklosgergely"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/IpAddressListener.java", "diffHunk": "@@ -22,7 +22,7 @@\n import java.net.UnknownHostException;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hive.metastore.HiveMetaStore.HMSHandler;\n+import org.apache.hadoop.hive.metastore.HMSHandler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTMxNA==", "bodyText": "Fixed!", "url": "https://github.com/apache/hive/pull/1787#discussion_r547141314", "createdAt": "2020-12-22T08:38:07Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/IpAddressListener.java", "diffHunk": "@@ -22,7 +22,7 @@\n import java.net.UnknownHostException;\n \n import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.hive.metastore.HiveMetaStore.HMSHandler;\n+import org.apache.hadoop.hive.metastore.HMSHandler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwMDk1OA=="}, "originalCommit": {"oid": "090a3956de518599cefac468953d1a09eb71137a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNjQ0MDY3OnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxOTozMTo1MVrOIUrE6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QxNDozNDowMlrOIVSQLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU0ODIwMQ==", "bodyText": "Since this is top level class, can you add a class level comment here on what is the main purpose of this class and any additional useful details to know for someone who is not familiar with code?", "url": "https://github.com/apache/hive/pull/1787#discussion_r558548201", "createdAt": "2021-01-15T19:31:51Z", "author": {"login": "vihangk1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTE5MDA2MQ==", "bodyText": "Sure, will do.", "url": "https://github.com/apache/hive/pull/1787#discussion_r559190061", "createdAt": "2021-01-17T14:34:02Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU0ODIwMQ=="}, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNjQ0NTYwOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxOTozMjo1MFrOIUrIKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QxNDoyOToyN1rOIVSONw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU0OTAzNQ==", "bodyText": "Is this a copy of the nested class or did you have to make any changes to it? If yes, can you please describe the changes so that it is easier to review?", "url": "https://github.com/apache/hive/pull/1787#discussion_r558549035", "createdAt": "2021-01-15T19:32:50Z", "author": {"login": "vihangk1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTE4OTU1OQ==", "bodyText": "I changed only some access modifiers that were necessary for HiveMetaStore to work. Other than that, it's a 1:1 copy.", "url": "https://github.com/apache/hive/pull/1787#discussion_r559189559", "createdAt": "2021-01-17T14:29:27Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java", "diffHunk": "@@ -0,0 +1,10155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.metastore;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Timer;\n+import com.facebook.fb303.FacebookBase;\n+import com.facebook.fb303.fb_status;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Supplier;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.Lists;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.commons.collections.CollectionUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.common.AcidConstants;\n+import org.apache.hadoop.hive.common.AcidMetaDataFile;\n+import org.apache.hadoop.hive.common.StatsSetupConst;\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.common.ValidReaderWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.common.repl.ReplConst;\n+import org.apache.hadoop.hive.metastore.api.*;\n+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;\n+import org.apache.hadoop.hive.metastore.events.AbortTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.AcidWriteEvent;\n+import org.apache.hadoop.hive.metastore.events.AddCheckConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddDefaultConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddForeignKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddNotNullConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddPrimaryKeyEvent;\n+import org.apache.hadoop.hive.metastore.events.AddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AddUniqueConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.AllocWriteIdEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.AlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.CommitTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.ConfigChangeEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.CreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.DeletePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DeleteTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.DropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.DropConstraintEvent;\n+import org.apache.hadoop.hive.metastore.events.DropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.DropFunctionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.DropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.DropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.InsertEvent;\n+import org.apache.hadoop.hive.metastore.events.LoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.OpenTxnEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAddSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAlterTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreAuthorizationCallEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreCreateTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropPartitionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.PreDropTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreEventContext;\n+import org.apache.hadoop.hive.metastore.events.PreLoadPartitionDoneEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadCatalogEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadDatabaseEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadISchemaEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadTableEvent;\n+import org.apache.hadoop.hive.metastore.events.PreReadhSchemaVersionEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdatePartitionColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.events.UpdateTableColumnStatEvent;\n+import org.apache.hadoop.hive.metastore.messaging.EventMessage;\n+import org.apache.hadoop.hive.metastore.metrics.Metrics;\n+import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;\n+import org.apache.hadoop.hive.metastore.metrics.PerfLogger;\n+import org.apache.hadoop.hive.metastore.partition.spec.PartitionSpecProxy;\n+import org.apache.hadoop.hive.metastore.txn.CompactionInfo;\n+import org.apache.hadoop.hive.metastore.txn.TxnStore;\n+import org.apache.hadoop.hive.metastore.txn.TxnUtils;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.metastore.utils.FilterUtils;\n+import org.apache.hadoop.hive.metastore.utils.HdfsUtils;\n+import org.apache.hadoop.hive.metastore.utils.JavaUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetaStoreUtils;\n+import org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo;\n+import org.apache.hadoop.hive.metastore.utils.SecurityUtils;\n+import org.apache.hadoop.security.UserGroupInformation;\n+import org.apache.hadoop.util.ReflectionUtils;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.jdo.JDOException;\n+import java.io.IOException;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.UndeclaredThrowableException;\n+import java.nio.ByteBuffer;\n+import java.security.PrivilegedExceptionAction;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.BitSet;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+import static org.apache.commons.lang3.StringUtils.isBlank;\n+import static org.apache.commons.lang3.StringUtils.join;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_CATALOG_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_COMMENT;\n+import static org.apache.hadoop.hive.metastore.Warehouse.DEFAULT_DATABASE_NAME;\n+import static org.apache.hadoop.hive.metastore.Warehouse.getCatalogQualifiedTableName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.CAT_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.DB_NAME;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.getDefaultCatalog;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.parseDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependCatalogToDbName;\n+import static org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.prependNotNullCatToDbName;\n+\n+public class HMSHandler extends FacebookBase implements IHMSHandler {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU0OTAzNQ=="}, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNjQ1MjYwOnYy", "diffSide": "RIGHT", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxOTozNToyMFrOIUrMkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QxNDoyOTozMFrOIVSOOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU1MDE2Mw==", "bodyText": "This method is exclusively doing all the operations in HMSHandler. Does it make sense to have this method here?", "url": "https://github.com/apache/hive/pull/1787#discussion_r558550163", "createdAt": "2021-01-15T19:35:20Z", "author": {"login": "vihangk1"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -10740,7 +10740,7 @@ private static String getServerHostName() throws Exception {\n     }\n   }\n \n-  private static void cleanupRawStore() {\n+  static void cleanupRawStore() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTE4OTU2Mg==", "bodyText": "I'm not sure, I'll move it to HMSHandler. Thanks!", "url": "https://github.com/apache/hive/pull/1787#discussion_r559189562", "createdAt": "2021-01-17T14:29:30Z", "author": {"login": "dataproc-metastore"}, "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java", "diffHunk": "@@ -10740,7 +10740,7 @@ private static String getServerHostName() throws Exception {\n     }\n   }\n \n-  private static void cleanupRawStore() {\n+  static void cleanupRawStore() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU1MDE2Mw=="}, "originalCommit": {"oid": "948f06762577c5be35d34ee95149b7493685396a"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 172, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}