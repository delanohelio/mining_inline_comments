{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE3NjA1MjY0", "number": 530, "reviewThreads": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMTo0MjozMVrOE4XXwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNToyNjoxMVrOFFCfug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTM4NjI0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMTo0MjozMVrOHyPddw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNDoyNDoxNVrOID69_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0NDE1MQ==", "bodyText": "Is this based on some euristic/rule?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r522444151", "createdAt": "2020-11-12T21:42:31Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "diffHunk": "@@ -27,7 +27,7 @@\n  */\n class SampleWeighter {\n \n-    private static final double SIGMA = 0.75;\n+    private static final double SIGMA = 0.675;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk4Mjc4MA==", "bodyText": "this softens the proximity function \"strictness\", some of the changes in this PR are somewhat correlated as we have improved the locality of the generated samples (in Type.NUMBER), so that the algo benefits from having less strict proximity function (here the width controls how strict the similarity between two vectors is) and similarity threshold (the CLUSTER_THRESHOLD in Type.NUMBER).", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540982780", "createdAt": "2020-12-11T14:24:15Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "diffHunk": "@@ -27,7 +27,7 @@\n  */\n class SampleWeighter {\n \n-    private static final double SIGMA = 0.75;\n+    private static final double SIGMA = 0.675;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0NDE1MQ=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NDA3MzM4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxNzo1OTowNlrOH1CI5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNToxMDoxMVrOID869Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA==", "bodyText": "Can you add a test to cover this branch?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r525371620", "createdAt": "2020-11-17T17:59:06Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -162,7 +162,7 @@ static Feature doubleToFeature(double d) {\n                 perturbationSize = lowerBound;\n             }\n             else if (upperBound > lowerBound) {\n-                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, upperBound).findFirst().orElse(1);\n+                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, 1 + upperBound).findFirst().orElse(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk1MTQ2MA==", "bodyText": "ok", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540951460", "createdAt": "2020-12-11T13:36:50Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -162,7 +162,7 @@ static Feature doubleToFeature(double d) {\n                 perturbationSize = lowerBound;\n             }\n             else if (upperBound > lowerBound) {\n-                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, upperBound).findFirst().orElse(1);\n+                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, 1 + upperBound).findFirst().orElse(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTAxNDc3Mw==", "bodyText": "actually this is already covered in DataUtils#testPerturbDropNumericTwo and DataUtils#testPerturbDropNumericThree.\nwe can't control the actual number being generated unless we induce the generation with a custom Random test-impl (e.g. the FakeRandom class we had).", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541014773", "createdAt": "2020-12-11T15:10:11Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -162,7 +162,7 @@ static Feature doubleToFeature(double d) {\n                 perturbationSize = lowerBound;\n             }\n             else if (upperBound > lowerBound) {\n-                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, upperBound).findFirst().orElse(1);\n+                perturbationSize = perturbationContext.getRandom().ints(1, lowerBound, 1 + upperBound).findFirst().orElse(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MTYyMA=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDY1OTk0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMjowOVrOH2pBFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxMzozNjozMFrOID5Cqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzE3NA==", "bodyText": "Why are you adding originalValue to feature scaling? Can you please clarify?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r527057174", "createdAt": "2020-11-19T17:12:09Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk1MTIxMA==", "bodyText": "as per issue description:\n\nincluded the original feature value in min / max scaling (which is performed during sparse encoding), this fixes cases where the original value doesn't fall in the value range of the sampled perturbed values (which is rare but can still happen)", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540951210", "createdAt": "2020-12-11T13:36:30Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzE3NA=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNDY2MjIxOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMjo0M1rOH2pCcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQxNzoxMjo0M1rOH2pCcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA1NzUyMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        int i = 0;\n          \n          \n            \n                        int valueIndex = 0;", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r527057520", "createdAt": "2020-11-19T17:12:43Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNTI1OTY5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMTowNzowNVrOH4IrUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTo0NTozNFrOH4TYDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ==", "bodyText": "do we need finalK?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528624465", "createdAt": "2020-11-23T11:07:05Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODcyOTEyNA==", "bodyText": "it seems so, as we use k in the stream, but k value changes across iterations for (k=0; k < ...", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528729124", "createdAt": "2020-11-23T14:10:49Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5OTc1OA==", "bodyText": "Sorry, I did not see it was used in the lambda", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528799758", "createdAt": "2020-11-23T15:45:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYyNDQ2NQ=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNTI5NTIyOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMToxNzoyNVrOH4JBBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNDozMDo1OFrOH4P74g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMDAyMg==", "bodyText": "If I've got it properly this can be replaced by something like\nMap.Entry maxEntry = Collections.max(collect.entrySet(), Map.Entry.comparingByValue());", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528630022", "createdAt": "2020-11-23T11:17:25Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);\n+        return saliencies;\n+    }\n+\n+    private static Map<List<String>, Long> getTopKFeaturesFrequency(List<Saliency> saliencies, Function<Saliency, List<FeatureImportance>> saliencyListFunction) {\n+        return saliencies.stream().map(saliencyListFunction)\n+                .map(l -> l.stream().map(f -> f.getFeature().getName())\n+                        .collect(Collectors.toList()))\n+                .collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+    }\n+\n+    private static Pair<List<String>, Long> getMostFrequent(Map<List<String>, Long> collect) {\n+        long max = 0L;\n+        Pair<List<String>, Long> topK = Pair.of(Collections.emptyList(), 0L);\n+        for (Map.Entry<List<String>, Long> entry : collect.entrySet()) {\n+            if (entry.getValue() >= max) {\n+                topK = Pair.of(entry.getKey(), entry.getValue());\n+                max = entry.getValue();\n+            }\n+        }\n+        return topK;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc0MzM5NA==", "bodyText": "much better, thanks!", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528743394", "createdAt": "2020-11-23T14:30:58Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);\n+        return saliencies;\n+    }\n+\n+    private static Map<List<String>, Long> getTopKFeaturesFrequency(List<Saliency> saliencies, Function<Saliency, List<FeatureImportance>> saliencyListFunction) {\n+        return saliencies.stream().map(saliencyListFunction)\n+                .map(l -> l.stream().map(f -> f.getFeature().getName())\n+                        .collect(Collectors.toList()))\n+                .collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+    }\n+\n+    private static Pair<List<String>, Long> getMostFrequent(Map<List<String>, Long> collect) {\n+        long max = 0L;\n+        Pair<List<String>, Long> topK = Pair.of(Collections.emptyList(), 0L);\n+        for (Map.Entry<List<String>, Long> entry : collect.entrySet()) {\n+            if (entry.getValue() >= max) {\n+                topK = Pair.of(entry.getKey(), entry.getValue());\n+                max = entry.getValue();\n+            }\n+        }\n+        return topK;\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMDAyMg=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNTMxMzE5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LocalSaliencyStability.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMToyMjozM1rOH4JLqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwNzoyMjoxN1rOH4u8vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMjc0Ng==", "bodyText": "Do we need public or can we keep it internal?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528632746", "createdAt": "2020-11-23T11:22:33Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LocalSaliencyStability.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Local {@code Saliency} stability evaluation result.\n+ */\n+public class LocalSaliencyStability {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI1MTUxNw==", "bodyText": "same reasoning as ExplainabilityMetrics#getLocalSaliencyStability, being this the result of the evaluation, it should be public for evaluators to consume it.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r529251517", "createdAt": "2020-11-24T07:22:17Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LocalSaliencyStability.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * Local {@code Saliency} stability evaluation result.\n+ */\n+public class LocalSaliencyStability {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzMjc0Ng=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNTM2MDgzOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMTozNjowM1rOH4JnzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwNzozMjowNlrOH4vO2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzOTk0OA==", "bodyText": "I have some questions around the getPositiveStabilityScore and getNegativeStabilityScore, what do they represent? Since they are rates how can they be both greater than 0.5?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528639948", "createdAt": "2020-11-23T11:36:03Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);\n+            assertFalse(predictionOutputs.isEmpty());\n+            PredictionOutput output = predictionOutputs.get(0);\n+            assertNotNull(output);\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n                 assertNotNull(saliency);\n-                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getPositiveFeatures(2));\n+                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertEquals(1d, v);\n             }\n+            int topK = 1;\n+            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+            for (int i = 1; i <= topK; i++) {\n+                for (String decision : stability.getDecisions()) {\n+                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI1NjE1NQ==", "bodyText": "data about positive and negative stability are kept separate because we want to separately check that the top k negative features are always the same as well as the top k positive features are always the same; it can happen that the negatives are stable whereas this is not true for the positive features.\nHowever I think rate is wrong here, ratio is more accurate (it's basically the number of times the most frequent positive/negative features appear divided by the number of explanations drawn for that decision).", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r529256155", "createdAt": "2020-11-24T07:32:06Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);\n+            assertFalse(predictionOutputs.isEmpty());\n+            PredictionOutput output = predictionOutputs.get(0);\n+            assertNotNull(output);\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n                 assertNotNull(saliency);\n-                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getPositiveFeatures(2));\n+                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertEquals(1d, v);\n             }\n+            int topK = 1;\n+            LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+            for (int i = 1; i <= topK; i++) {\n+                for (String decision : stability.getDecisions()) {\n+                    double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                    double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                    assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                    assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzOTk0OA=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNTM2ODE0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxMTozODoxNVrOH4JsCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTo1Mzo0NlrOH4Tv2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ==", "bodyText": "Do we need public or can we keep it internal?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528641035", "createdAt": "2020-11-23T11:38:15Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc0NDc3NA==", "bodyText": "being a metric, I supposed it would have made sense to keep it public, however at this stage it's not \"used\" by other components, so we can do both.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528744774", "createdAt": "2020-11-23T14:32:51Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwNTg1MQ==", "bodyText": "np, if it was intented to be a public api let's keep it as it is. Just wanted to be sure it was not just for our internal testing", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528805851", "createdAt": "2020-11-23T15:53:46Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,109 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY0MTAzNQ=="}, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjMwNzI4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyOToyOVrOH4SmLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyOToyOVrOH4SmLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4Njk4OQ==", "bodyText": "I think it would be good to use assertj also here. It provides much better messages when test fails.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528786989", "createdAt": "2020-11-23T15:29:29Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjMwOTI5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyOTo0N1rOH4SnUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyOTo0N1rOH4SnUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4NzI4MQ==", "bodyText": "Please use assertj.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528787281", "createdAt": "2020-11-23T15:29:47Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -86,17 +89,30 @@ void testPMMLRegression() throws Exception {\n                 }\n                 return outputs;\n             });\n-            PredictionOutput output = model.predictAsync(List.of(input))\n-                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                    .get(0);\n+            List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            assertNotNull(predictionOutputs);\n+            assertFalse(predictionOutputs.isEmpty());\n+            PredictionOutput output = predictionOutputs.get(0);\n+            assertNotNull(output);\n             Prediction prediction = new Prediction(input, output);\n             Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (Saliency saliency : saliencyMap.values()) {\n                 assertNotNull(saliency);\n-                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getPositiveFeatures(2));\n+                double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n                 assertEquals(1d, v);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjMxMjEyOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTozMDoxOFrOH4SpBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNTozMDoxOFrOH4SpBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4NzcxNw==", "bodyText": "Please use assertj also here.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r528787717", "createdAt": "2020-11-23T15:30:18Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/TypeTest.java", "diffHunk": "@@ -294,6 +294,27 @@ void testEncode(Type type) {\n         }\n     }\n \n+    @Test\n+    void testEncodeNumericSymmetric() {\n+        for (int seed = 0; seed < 5; seed++) {\n+            Random random = new Random();\n+            random.setSeed(seed);\n+            PerturbationContext perturbationContext = new PerturbationContext(random, random.nextInt());\n+            Value<?> target = Type.NUMBER.randomValue(perturbationContext);\n+            Value<?>[] values = new Value<?>[6];\n+            for (int i = 0; i < values.length / 2; i++) {\n+                values[i] = new Value<>(target.asNumber() + target.asNumber() * (1 + i) / 100d);\n+                values[values.length - 1 - i] = new Value<>(target.asNumber() - target.asNumber() * (1 + i) / 100d);\n+            }\n+            List<double[]> vectors = Type.NUMBER.encode(target, values);\n+            assertNotNull(vectors);\n+            assertEquals(values.length, vectors.size());\n+            for (int i = 0; i < vectors.size() / 2; i++) {\n+                assertEquals(vectors.get(i)[0], vectors.get(vectors.size() - 1 - i)[0]);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7db39c4c33c84eca961e21a8c1a0a24628d379e2"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM1ODUyNDg4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNDo1OToxNFrOH-gfbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNDoyNzowN1rOID7F5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMwNjA5NQ==", "bodyText": "Magic number?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r535306095", "createdAt": "2020-12-03T14:59:14Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -130,7 +130,7 @@\n     },\n \n     NUMBER(\"number\") {\n-        private static final double CLUSTER_THRESHOLD = 1e-3;\n+        private static final double CLUSTER_THRESHOLD = 1e-1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk4NDgwNw==", "bodyText": "see comment above for SampleWeighter.SIGMA", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540984807", "createdAt": "2020-12-11T14:27:07Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -130,7 +130,7 @@\n     },\n \n     NUMBER(\"number\") {\n-        private static final double CLUSTER_THRESHOLD = 1e-3;\n+        private static final double CLUSTER_THRESHOLD = 1e-1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMwNjA5NQ=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2MjUwNjI0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwODowMDozNFrOH_FDoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNjozOTozNlrOIEAvkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA==", "bodyText": "I see the same \"pattern\" in all the tests (not only PMML but all the others too) with only number of samples, topK and positive/negative stability score as difference.\nDoes it make sense to move it to a common method?\nAre all of them magic numbers? Like why 300/500 samples? Why the last assertion is >= 0.5/0.8?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r535905184", "createdAt": "2020-12-04T08:00:34Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -131,16 +144,29 @@ void testPMMLRegressionCategorical() throws Exception {\n             }\n             return outputs;\n         });\n-        PredictionOutput output = model.predictAsync(List.of(input))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                .get(0);\n+        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        assertThat(predictionOutputs).isNotNull();\n+        assertThat(predictionOutputs).isNotEmpty();\n+        PredictionOutput output = predictionOutputs.get(0);\n+        assertThat(output).isNotNull();\n         Prediction prediction = new Prediction(input, output);\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(1));\n-            assertEquals(1d, v);\n+            assertThat(saliency).isNotNull();\n+            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n+            assertThat(v).isEqualTo(1d);\n+        }\n+        int topK = 1;\n+        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+        for (int i = 1; i <= topK; i++) {\n+            for (String decision : stability.getDecisions()) {\n+                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5MjM4NQ==", "bodyText": "Sure it makes sense to have a common method in TestUtils, I'll do that.\nFor the specific settings: I've set a minimum expected stability rate to 0.5 for the models having more than 5 features (when linearized) including ones of Type.NUMBER since they're harder.\nI've set a high minimum (0.8) for OpenNLP ITs since the input only consists of 4 words that can only be set to empty String when perturbed, resulting in a low no. of possible perturbed inputs and hence an higher stability.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540992385", "createdAt": "2020-12-11T14:37:16Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -131,16 +144,29 @@ void testPMMLRegressionCategorical() throws Exception {\n             }\n             return outputs;\n         });\n-        PredictionOutput output = model.predictAsync(List.of(input))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                .get(0);\n+        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        assertThat(predictionOutputs).isNotNull();\n+        assertThat(predictionOutputs).isNotEmpty();\n+        PredictionOutput output = predictionOutputs.get(0);\n+        assertThat(output).isNotNull();\n         Prediction prediction = new Prediction(input, output);\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(1));\n-            assertEquals(1d, v);\n+            assertThat(saliency).isNotNull();\n+            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n+            assertThat(v).isEqualTo(1d);\n+        }\n+        int topK = 1;\n+        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+        for (int i = 1; i <= topK; i++) {\n+            for (String decision : stability.getDecisions()) {\n+                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTAzNTcxOQ==", "bodyText": "a practical problem with such a test method is that we need to inject a test classified version of explainability-core into the IT modules, which I think it's a bit overkill given the fact that we just need a few lines of code to check the expected stability scores.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541035719", "createdAt": "2020-12-11T15:38:57Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -131,16 +144,29 @@ void testPMMLRegressionCategorical() throws Exception {\n             }\n             return outputs;\n         });\n-        PredictionOutput output = model.predictAsync(List.of(input))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                .get(0);\n+        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        assertThat(predictionOutputs).isNotNull();\n+        assertThat(predictionOutputs).isNotEmpty();\n+        PredictionOutput output = predictionOutputs.get(0);\n+        assertThat(output).isNotNull();\n         Prediction prediction = new Prediction(input, output);\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(1));\n-            assertEquals(1d, v);\n+            assertThat(saliency).isNotNull();\n+            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n+            assertThat(v).isEqualTo(1d);\n+        }\n+        int topK = 1;\n+        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+        for (int i = 1; i <= topK; i++) {\n+            for (String decision : stability.getDecisions()) {\n+                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTA3NzM5Mw==", "bodyText": "I've moved the boilerplate to validate local saliency stability in a ValidationUtils#validateLocalSaliencyStability method so that it can be re-used easily in ITs as well.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r541077393", "createdAt": "2020-12-11T16:39:36Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-pmml/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/pmml/PmmlLimeExplainerTest.java", "diffHunk": "@@ -131,16 +144,29 @@ void testPMMLRegressionCategorical() throws Exception {\n             }\n             return outputs;\n         });\n-        PredictionOutput output = model.predictAsync(List.of(input))\n-                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n-                .get(0);\n+        List<PredictionOutput> predictionOutputs = model.predictAsync(List.of(input))\n+                .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        assertThat(predictionOutputs).isNotNull();\n+        assertThat(predictionOutputs).isNotEmpty();\n+        PredictionOutput output = predictionOutputs.get(0);\n+        assertThat(output).isNotNull();\n         Prediction prediction = new Prediction(input, output);\n         Map<String, Saliency> saliencyMap = limeExplainer.explainAsync(prediction, model)\n                 .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n         for (Saliency saliency : saliencyMap.values()) {\n-            assertNotNull(saliency);\n-            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(1));\n-            assertEquals(1d, v);\n+            assertThat(saliency).isNotNull();\n+            double v = ExplainabilityMetrics.impactScore(model, prediction, saliency.getTopFeatures(2));\n+            assertThat(v).isEqualTo(1d);\n+        }\n+        int topK = 1;\n+        LocalSaliencyStability stability = ExplainabilityMetrics.getLocalSaliencyStability(model, prediction, limeExplainer, topK, 10);\n+        for (int i = 1; i <= topK; i++) {\n+            for (String decision : stability.getDecisions()) {\n+                double positiveStabilityScore = stability.getPositiveStabilityScore(decision, i);\n+                double negativeStabilityScore = stability.getNegativeStabilityScore(decision, i);\n+                assertThat(positiveStabilityScore).isGreaterThanOrEqualTo(0.5);\n+                assertThat(negativeStabilityScore).isGreaterThanOrEqualTo(0.5);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTkwNTE4NA=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5NzIwMzM4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxMzoyMTo0OVrOID4gFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNDo0ODo1NlrOID8BNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0MjM1OA==", "bodyText": "Why fixed value?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540942358", "createdAt": "2020-12-11T13:21:49Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5OTk4OQ==", "bodyText": "this has not changed, previously the gaussian filter was centered in 0 with a stdDev of 1, now its centered around the original value with the same stdDev (as per PR description).\nthis way the encoding mechanism sets to 1 those scaled numbers that fall close to the center of the gaussian (= the original feature value).", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540999989", "createdAt": "2020-12-11T14:48:56Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n+            double[] doubles = new double[values.length + 1];\n             int i = 0;\n             for (Value<?> v : values) {\n                 doubles[i] = v.asNumber();\n                 i++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[i] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(i); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0MjM1OA=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5NzIxNDM3OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxMzoyNDozM1rOID4mWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNDozNzo0OVrOID7k3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0Mzk2MA==", "bodyText": "What about make both of them warn or debug?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540943960", "createdAt": "2020-12-11T13:24:33Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,102 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk5MjczNQ==", "bodyText": "ok", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r540992735", "createdAt": "2020-12-11T14:37:49Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -132,4 +139,102 @@ public static double classificationFidelity(List<Pair<Saliency, Prediction>> pai\n         }\n         return evals == 0 ? 0 : acc / evals;\n     }\n+\n+    /**\n+     * Evaluate stability of a local explainer generating {@code Saliencies}.\n+     * Such an evaluation is intended to measure how stable the explanations are in terms of \"are the top k most important\n+     * positive/negative features always the same for a single prediction?\".\n+     *\n+     * @param model                  a model to explain\n+     * @param prediction             the prediction on which explanation stability will be evaluated\n+     * @param saliencyLocalExplainer a local saliency explainer\n+     * @param topK                   no. of top k positive/negative features for which stability report will be generated\n+     * @return a report about stability of all the decisions/predictions (and for each {@code k < topK})\n+     */\n+    public static LocalSaliencyStability getLocalSaliencyStability(PredictionProvider model, Prediction prediction,\n+                                                                   LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                   int topK, int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = getMultipleSaliencies(model, prediction, saliencyLocalExplainer, runs);\n+\n+        LocalSaliencyStability saliencyStability = new LocalSaliencyStability(saliencies.keySet());\n+        // for each decision, calculate the stability rate for the top k important feature set, for each k < topK\n+        for (Map.Entry<String, List<Saliency>> entry : saliencies.entrySet()) {\n+            for (int k = 1; k <= topK; k++) {\n+                String decision = entry.getKey();\n+                List<Saliency> perDecisionSaliencies = entry.getValue();\n+\n+                int finalK = k;\n+                // get the top k positive features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKPositive = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getPositiveFeatures(finalK));\n+                // get the most frequent list of positive features\n+                Pair<List<String>, Long> positiveMostFrequent = getMostFrequent(topKPositive);\n+                double positiveFrequencyRate = (double) positiveMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // get the top k negative features list from each saliency and count the frequency of each such list across all saliencies\n+                Map<List<String>, Long> topKNegative = getTopKFeaturesFrequency(perDecisionSaliencies, s -> s.getNegativeFeatures(finalK));\n+                // get the most frequent list of negative features\n+                Pair<List<String>, Long> negativeMostFrequent = getMostFrequent(topKNegative);\n+                double negativeFrequencyRate = (double) negativeMostFrequent.getValue() / (double) perDecisionSaliencies.size();\n+\n+                // decision stability at k\n+                List<String> positiveFeatureNames = positiveMostFrequent.getKey();\n+                List<String> negativeFeatureNames = negativeMostFrequent.getKey();\n+                saliencyStability.add(decision, k, positiveFeatureNames, positiveFrequencyRate, negativeFeatureNames, negativeFrequencyRate);\n+            }\n+        }\n+        return saliencyStability;\n+    }\n+\n+    /**\n+     * Get multiple saliencies, aggregated by decision name.\n+     *\n+     * @param model                  the model used to perform predictions\n+     * @param prediction             the prediction to explain\n+     * @param saliencyLocalExplainer a local explainer that generates saliences\n+     * @param runs                   the no. of explanations to be generated\n+     * @return the generated saliencies, aggregated by decision name, across the different runs\n+     */\n+    private static Map<String, List<Saliency>> getMultipleSaliencies(PredictionProvider model, Prediction prediction,\n+                                                                     LocalExplainer<Map<String, Saliency>> saliencyLocalExplainer,\n+                                                                     int runs)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<String, List<Saliency>> saliencies = new HashMap<>();\n+        int skipped = 0;\n+        for (int i = 0; i < runs; i++) {\n+            Map<String, Saliency> saliencyMap = saliencyLocalExplainer.explainAsync(prediction, model)\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            for (Map.Entry<String, Saliency> saliencyEntry : saliencyMap.entrySet()) {\n+                // aggregate saliencies by output name\n+                List<FeatureImportance> topFeatures = saliencyEntry.getValue().getTopFeatures(1);\n+                if (!topFeatures.isEmpty() && topFeatures.get(0).getScore() != 0) { // skip empty or 0 valued saliencies\n+                    if (saliencies.containsKey(saliencyEntry.getKey())) {\n+                        List<Saliency> localSaliencies = saliencies.get(saliencyEntry.getKey());\n+                        List<Saliency> updatedSaliencies = new ArrayList<>(localSaliencies);\n+                        updatedSaliencies.add(saliencyEntry.getValue());\n+                        saliencies.put(saliencyEntry.getKey(), updatedSaliencies);\n+                    } else {\n+                        saliencies.put(saliencyEntry.getKey(), List.of(saliencyEntry.getValue()));\n+                    }\n+                } else {\n+                    LOGGER.warn(\"skipping empty / zero saliency for {}\", saliencyEntry.getKey());\n+                    skipped++;\n+                }\n+            }\n+        }\n+        LOGGER.debug(\"skipped {} useless saliencies\", skipped);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDk0Mzk2MA=="}, "originalCommit": {"oid": "3580d487a5dd0f45d40be5a8886a4ee68a30c10e"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNzU5NTI0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMzowODowMVrOIFPliQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNDozNzoyMVrOIFTffw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ==", "bodyText": "Would it be possible make \"0.01\" a constant and move it somewhere up to be more visible. I think it is better to have constants visible rather than hidden inside mothods etc.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542369161", "createdAt": "2020-12-14T13:08:01Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMDgwMA==", "bodyText": "I am thinking of placing all those parameters inside LimeConfig so that they are centralized, configurable and visible frome one place. I will make a new PR for that.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542430800", "createdAt": "2020-12-14T14:34:11Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMzE1MQ==", "bodyText": "here's the Jira issue: https://issues.redhat.com/browse/FAI-342", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542433151", "createdAt": "2020-12-14T14:37:21Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM2OTE2MQ=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNzYwNTYwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMzoxMDozMlrOIFPrsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNDozNzo0OVrOIFTgyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3MDczNw==", "bodyText": "Same here. Can we make \"1d\" a constant and move it to more visible place?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542370737", "createdAt": "2020-12-14T13:10:32Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value\n+                normalDistributionSample = normalDistributionSample * originalFeatureValue + stDev;\n             }\n             if (intValue) {\n                 normalDistributionSample = (int) normalDistributionSample;\n                 if (normalDistributionSample == originalFeatureValue) {\n-                    normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    normalDistributionSample = (int) normalDistributionSample + 1d;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQzMzQ4MA==", "bodyText": "I'd resolve this also as part of https://issues.redhat.com/browse/FAI-342", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542433480", "createdAt": "2020-12-14T14:37:49Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -150,12 +150,13 @@\n             // sample from a standard normal distribution and center around feature value\n             double normalDistributionSample = perturbationContext.getRandom().nextGaussian();\n             if (originalFeatureValue != 0d) {\n-                normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                double stDev = originalFeatureValue * 0.01; // set std dev at 1% of feature value\n+                normalDistributionSample = normalDistributionSample * originalFeatureValue + stDev;\n             }\n             if (intValue) {\n                 normalDistributionSample = (int) normalDistributionSample;\n                 if (normalDistributionSample == originalFeatureValue) {\n-                    normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    normalDistributionSample = (int) normalDistributionSample + 1d;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3MDczNw=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwNzYxMTQ3OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-opennlp/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMzoxMTo1M1rOIFPvHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxMzoxMTo1M1rOIFPvHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3MTYxNQ==", "bodyText": "+1 for using assertj instead of junit asserts.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542371615", "createdAt": "2020-12-14T13:11:53Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-opennlp/pom.xml", "diffHunk": "@@ -25,6 +25,11 @@\n       <artifactId>quarkus-junit5</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwODI2MTE1OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNToyMjozM1rOIFVrPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNjo1Mjo1N1rOIFaG3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ2ODkyNA==", "bodyText": "just wondering.. if Double.isNan(d) is true the previous call at line 180\n            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n\nshould have crashed right?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542468924", "createdAt": "2020-12-14T15:22:33Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n-            int i = 0;\n+            double[] doubles = new double[values.length + 1];\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;\n+            double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n+            List<Double> clusteredValues = scaledValues.stream()\n+                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjU0MTUzMg==", "bodyText": "good catch, it doesn't actually catch but the fact that there's a NaN makes all the values become NaN too in the feature scaling.\nI've fixed it and added a test to cover this case.", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542541532", "createdAt": "2020-12-14T16:52:57Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -164,20 +165,28 @@\n         @Override\n         public List<double[]> encode(Value<?> target, Value<?>... values) {\n             // find maximum and minimum values\n-            double[] doubles = new double[values.length];\n-            int i = 0;\n+            double[] doubles = new double[values.length + 1];\n+            int valueIndex = 0;\n             for (Value<?> v : values) {\n-                doubles[i] = v.asNumber();\n-                i++;\n+                doubles[valueIndex] = v.asNumber();\n+                valueIndex++;\n             }\n             double originalValue = target.asNumber();\n+            doubles[valueIndex] = originalValue; // include target number in feature scaling\n             double min = DoubleStream.of(doubles).min().orElse(Double.MIN_VALUE);\n             double max = DoubleStream.of(doubles).max().orElse(Double.MAX_VALUE);\n-            // feature scaling + kernel based clustering\n-            double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min), 0, 1);\n-            List<Double> encodedValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n-                    .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(d -> DataUtils.gaussianKernel(d, 0, 1))\n-                    .map(d -> (d - threshold < CLUSTER_THRESHOLD) ? 1d : 0d).collect(Collectors.toList());\n+\n+            // feature scaling\n+            List<Double> scaledValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min)).boxed().collect(Collectors.toList());\n+            double scaledOriginalValue = scaledValues.remove(valueIndex); // extract the scaled original value (it must not appear in encoded values)\n+\n+            // kernel based clustering\n+            double sigma = 1;\n+            double threshold = DataUtils.gaussianKernel(scaledOriginalValue, scaledOriginalValue, sigma);\n+            List<Double> clusteredValues = scaledValues.stream()\n+                    .map(d -> Double.isNaN(d) ? 0 : d).map(d -> DataUtils.gaussianKernel(d, scaledOriginalValue, sigma)).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ2ODkyNA=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQwODI4MDkwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNToyNjoxMVrOIFV2-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQxNjoxODowOFrOIFYanQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {\n          \n          \n            \n                void testPrequalificationDMNExplanation() throws ExecutionException, InterruptedException, TimeoutException {", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542471931", "createdAt": "2020-12-14T15:26:11Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n+\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n+import org.junit.jupiter.api.Test;\n+import org.kie.dmn.api.core.DMNRuntime;\n+import org.kie.kogito.decision.DecisionModel;\n+import org.kie.kogito.dmn.DMNKogito;\n+import org.kie.kogito.dmn.DmnDecisionModel;\n+import org.kie.kogito.explainability.Config;\n+import org.kie.kogito.explainability.local.lime.LimeConfig;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.PerturbationContext;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+import org.kie.kogito.explainability.utils.ValidationUtils;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PrequalificationDmnLimeExplainerTest {\n+\n+    @Test\n+    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MzQyMQ==", "bodyText": "And rename Prequalification-1 file?", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542473421", "createdAt": "2020-12-14T15:27:46Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n+\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n+import org.junit.jupiter.api.Test;\n+import org.kie.dmn.api.core.DMNRuntime;\n+import org.kie.kogito.decision.DecisionModel;\n+import org.kie.kogito.dmn.DMNKogito;\n+import org.kie.kogito.dmn.DmnDecisionModel;\n+import org.kie.kogito.explainability.Config;\n+import org.kie.kogito.explainability.local.lime.LimeConfig;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.PerturbationContext;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+import org.kie.kogito.explainability.utils.ValidationUtils;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PrequalificationDmnLimeExplainerTest {\n+\n+    @Test\n+    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjUxMzgyMQ==", "bodyText": "sure, thanks :)", "url": "https://github.com/kiegroup/kogito-apps/pull/530#discussion_r542513821", "createdAt": "2020-12-14T16:18:08Z", "author": {"login": "tteofili"}, "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/PrequalificationDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n+\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n+import org.junit.jupiter.api.Test;\n+import org.kie.dmn.api.core.DMNRuntime;\n+import org.kie.kogito.decision.DecisionModel;\n+import org.kie.kogito.dmn.DMNKogito;\n+import org.kie.kogito.dmn.DmnDecisionModel;\n+import org.kie.kogito.explainability.Config;\n+import org.kie.kogito.explainability.local.lime.LimeConfig;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.PerturbationContext;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+import org.kie.kogito.explainability.utils.ValidationUtils;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PrequalificationDmnLimeExplainerTest {\n+\n+    @Test\n+    void testPrequalificationDMNExplanation1() throws ExecutionException, InterruptedException, TimeoutException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTkzMQ=="}, "originalCommit": {"oid": "4a42ffb10648bb781ec9fd7f0b74b1e80b5fcfe2"}, "originalPosition": 55}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1202, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}