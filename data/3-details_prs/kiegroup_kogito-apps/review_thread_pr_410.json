{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyNjYxNjg4", "number": 410, "reviewThreads": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo0MzoxNVrOEbsnOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMTo1MjozMlrOEdr5uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDc3OTQ1OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo0MzoxNVrOHFxypA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQwODo0NzoxNFrOHHCOOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA==", "bodyText": "I think the URL should not be in the dto (at least for the scenarios we will support in this first release). The URL to be used is going to be injected by the operator with an enviroment variable. wdyt?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475820708", "createdAt": "2020-08-24T18:43:15Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjMxMjkyMQ==", "bodyText": "In general it is not correct to have this value injected by the operator because explainable-service (like job-service) needs to know who to call and this is not (or should not be) hard-coded.\nI'm fine to have a fallback value provisioned by the operator but we cannot get rid of this parameter.", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476312921", "createdAt": "2020-08-25T09:31:56Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzEzMjE3Mg==", "bodyText": "Hi @danielezonca @kostola , following this architecture, who, where and how this serviceUrl should be set?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477132172", "createdAt": "2020-08-26T08:37:16Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzEzODQ4OA==", "bodyText": "This value contains KogitoApp host, it is injected inside ConfigBean ( template ) by the operator  ( link ).\nThe flow is:\n\nKogito has its own URL\nTraceEvent contains this value\nThis value is send to Expl-service\nExpl-service interact with Kogito using it", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477138488", "createdAt": "2020-08-26T08:47:14Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDc4NDI4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo0NDo0MFrOHFx1uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxOTo0Mzo1M1rOHGnISg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng==", "bodyText": "Create a dedicated object for this to avoid Map<Map<>> that is not very informative? imo it's better to encapsulate it in a separated object in general since it will be easier to add properties in the future", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475821496", "createdAt": "2020-08-24T18:44:40Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "diffHunk": "@@ -16,23 +16,33 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityResultDto {\n+\n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    // TODO: add properties\n+    @JsonProperty(\"saliency\")\n+    private Map<String, Map<String, Double>> saliency;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjMxMzU3OQ==", "bodyText": "Yes @kostola is already working on this \ud83d\udc4d\nLet's keep this comment opened until the change is pushed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476313579", "createdAt": "2020-08-25T09:33:03Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "diffHunk": "@@ -16,23 +16,33 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityResultDto {\n+\n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    // TODO: add properties\n+    @JsonProperty(\"saliency\")\n+    private Map<String, Map<String, Double>> saliency;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NDYwMg==", "bodyText": "Introduced SaliencyDto", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476694602", "createdAt": "2020-08-25T19:43:53Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "diffHunk": "@@ -16,23 +16,33 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityResultDto {\n+\n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    // TODO: add properties\n+    @JsonProperty(\"saliency\")\n+    private Map<String, Map<String, Double>> saliency;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDgyODg0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo1Nzo0MFrOHFyROw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODozMDoyMFrOHIF7wQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODUzOQ==", "bodyText": "I'm not sure about this reaction to these exceptions. Let's assume that something bad happens and we catch the exception, we would anyway produce an (kind of empty?) explaination and display it right? If something bad happens, I think we should make it transparent to the user somehow (or even leave the explaination as \"not available\" or something) and not showing him wrong information", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475828539", "createdAt": "2020-08-24T18:57:40Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -75,17 +77,23 @@ public static double impactScore(PredictionProvider model, Prediction prediction\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput)).get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            predictionOutputs = Collections.emptyList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI0Nzg3Mw==", "bodyText": "Done, now the error is propagated", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478247873", "createdAt": "2020-08-27T08:30:20Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -75,17 +77,23 @@ public static double impactScore(PredictionProvider model, Prediction prediction\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput)).get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            predictionOutputs = Collections.emptyList();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODUzOQ=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDgzODA5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowMDoyN1rOHFyW6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo1NToxOVrOHIG23Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyOTk5Mg==", "bodyText": "move to TOP_FEATURE_THRESHOLD constant or something?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475829992", "createdAt": "2020-08-24T19:00:27Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -53,41 +55,53 @@ private void assertStable(PredictionProvider model, List<Feature> featureList) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(featureList);\n-            List<PredictionOutput> predictionOutputs = model.predict(List.of(input));\n-            Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n-            List<Saliency> saliencies = new LinkedList<>();\n-            for (int i = 0; i < 100; i++) {\n-                Map<String, Saliency> saliencyMap = limeExplainer.explain(prediction, model);\n-                saliencies.addAll(saliencyMap.values());\n+            List<PredictionOutput> predictionOutputs;\n+            try {\n+                predictionOutputs = model.predict(List.of(input)).get();\n+            } catch (InterruptedException | ExecutionException e) {\n+                predictionOutputs = Collections.emptyList();\n             }\n-            // check that the topmost important feature is stable\n-            List<String> names = new LinkedList<>();\n-            saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n-            Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n-            boolean topFeature = false;\n-            for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n-                if (entry.getValue() >= 0.9) {\n-                    topFeature = true;\n-                    break;\n+            for (PredictionOutput predictionOutput : predictionOutputs) {\n+                Prediction prediction = new Prediction(input, predictionOutput);\n+                List<Saliency> saliencies = new LinkedList<>();\n+                for (int i = 0; i < 100; i++) {\n+                    Map<String, Saliency> saliencyMap = null;\n+                    try {\n+                        saliencyMap = limeExplainer.explain(prediction, model).get();\n+                    } catch (InterruptedException | ExecutionException e) {\n+                        saliencyMap = Collections.emptyMap();\n+                    }\n+                    saliencies.addAll(saliencyMap.values());\n                 }\n-            }\n-            assertTrue(topFeature);\n+                // check that the topmost important feature is stable\n+                List<String> names = new LinkedList<>();\n+                saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+                Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+                boolean topFeature = false;\n+                for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+                    if (entry.getValue() >= 0.9) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2MzAwNQ==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478263005", "createdAt": "2020-08-27T08:55:19Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -53,41 +55,53 @@ private void assertStable(PredictionProvider model, List<Feature> featureList) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(featureList);\n-            List<PredictionOutput> predictionOutputs = model.predict(List.of(input));\n-            Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n-            List<Saliency> saliencies = new LinkedList<>();\n-            for (int i = 0; i < 100; i++) {\n-                Map<String, Saliency> saliencyMap = limeExplainer.explain(prediction, model);\n-                saliencies.addAll(saliencyMap.values());\n+            List<PredictionOutput> predictionOutputs;\n+            try {\n+                predictionOutputs = model.predict(List.of(input)).get();\n+            } catch (InterruptedException | ExecutionException e) {\n+                predictionOutputs = Collections.emptyList();\n             }\n-            // check that the topmost important feature is stable\n-            List<String> names = new LinkedList<>();\n-            saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n-            Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n-            boolean topFeature = false;\n-            for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n-                if (entry.getValue() >= 0.9) {\n-                    topFeature = true;\n-                    break;\n+            for (PredictionOutput predictionOutput : predictionOutputs) {\n+                Prediction prediction = new Prediction(input, predictionOutput);\n+                List<Saliency> saliencies = new LinkedList<>();\n+                for (int i = 0; i < 100; i++) {\n+                    Map<String, Saliency> saliencyMap = null;\n+                    try {\n+                        saliencyMap = limeExplainer.explain(prediction, model).get();\n+                    } catch (InterruptedException | ExecutionException e) {\n+                        saliencyMap = Collections.emptyMap();\n+                    }\n+                    saliencies.addAll(saliencyMap.values());\n                 }\n-            }\n-            assertTrue(topFeature);\n+                // check that the topmost important feature is stable\n+                List<String> names = new LinkedList<>();\n+                saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+                Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+                boolean topFeature = false;\n+                for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+                    if (entry.getValue() >= 0.9) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyOTk5Mg=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDgzOTU2OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowMDo1M1rOHFyX1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODozMDozNlrOHIF8Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDIzMA==", "bodyText": "disable the test instead of commenting?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475830230", "createdAt": "2020-08-24T19:00:53Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java", "diffHunk": "@@ -38,41 +38,41 @@ void testSamplingEmptyDataset() {\n         SampleWeighter.getSampleWeights(targetInput, trainingSet);\n     }\n \n-    @Test\n-    void testSamplingNonEmptyDataset() {\n-        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n-        List<Feature> features = new LinkedList<>();\n-        for (int i = 0; i < 5; i++) {\n-            features.add(TestUtils.getMockedNumericFeature());\n-        }\n-        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n-        for (int i = 0; i < 10; i++) {\n-            int finalI = i;\n-            Pair<double[], Double> doubles = new Pair<>() {\n-                @Override\n-                public double[] getLeft() {\n-                    double[] vector = new double[features.size()];\n-                    Arrays.fill(vector, 1d / (1d + finalI));\n-                    return vector;\n-                }\n-\n-                @Override\n-                public Double getRight() {\n-                    return 0d;\n-                }\n-\n-                @Override\n-                public Double setValue(Double aDouble) {\n-                    return 0d;\n-                }\n-            };\n-            trainingSet.add(doubles);\n-        }\n-        PredictionInput targetInput = new PredictionInput(features);\n-        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n-        // check that weights decrease with the distance from the 1 vector (the target instance)\n-        for (int i = 0; i < weights.length - 1; i++) {\n-            assertTrue(weights[i] > weights[i + 1]);\n-        }\n-    }\n+//    @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI0ODAzOQ==", "bodyText": "Restored", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478248039", "createdAt": "2020-08-27T08:30:36Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java", "diffHunk": "@@ -38,41 +38,41 @@ void testSamplingEmptyDataset() {\n         SampleWeighter.getSampleWeights(targetInput, trainingSet);\n     }\n \n-    @Test\n-    void testSamplingNonEmptyDataset() {\n-        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n-        List<Feature> features = new LinkedList<>();\n-        for (int i = 0; i < 5; i++) {\n-            features.add(TestUtils.getMockedNumericFeature());\n-        }\n-        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n-        for (int i = 0; i < 10; i++) {\n-            int finalI = i;\n-            Pair<double[], Double> doubles = new Pair<>() {\n-                @Override\n-                public double[] getLeft() {\n-                    double[] vector = new double[features.size()];\n-                    Arrays.fill(vector, 1d / (1d + finalI));\n-                    return vector;\n-                }\n-\n-                @Override\n-                public Double getRight() {\n-                    return 0d;\n-                }\n-\n-                @Override\n-                public Double setValue(Double aDouble) {\n-                    return 0d;\n-                }\n-            };\n-            trainingSet.add(doubles);\n-        }\n-        PredictionInput targetInput = new PredictionInput(features);\n-        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n-        // check that weights decrease with the distance from the 1 vector (the target instance)\n-        for (int i = 0; i < weights.length - 1; i++) {\n-            assertTrue(weights[i] > weights[i + 1]);\n-        }\n-    }\n+//    @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDIzMA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg0NjA3OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowMzowN1rOHFycRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo1NToxM1rOHIG2og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTM2Ng==", "bodyText": "remove this log or make it more informative like processing explainability for execution id xyz?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475831366", "createdAt": "2020-08-24T19:03:07Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2Mjk0Ng==", "bodyText": "Fixed :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478262946", "createdAt": "2020-08-27T08:55:13Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTM2Ng=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg1MTIwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowNDo1NFrOHFyfrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0MjoyOVrOHIGYPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjIzNg==", "bodyText": "should't this call the expl lib?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475832236", "createdAt": "2020-08-24T19:04:54Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1NTE2Nw==", "bodyText": "It was a WIP, fixed :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478255167", "createdAt": "2020-08-27T08:42:29Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjIzNg=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg1NzQyOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowNjo0OFrOHFyjew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxOTo0NjowNVrOHGnNMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzIxMQ==", "bodyText": "why check isDone?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833211", "createdAt": "2020-08-24T19:06:48Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NTg1Ng==", "bodyText": "This check was wrong, code changed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476695856", "createdAt": "2020-08-25T19:46:05Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzIxMQ=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg1OTA4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowNzoxNVrOHFykfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxOTo0Njo0MVrOHGnOhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzQ2OQ==", "bodyText": "Not sure this is the expected explaination result in case of an exception", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833469", "createdAt": "2020-08-24T19:07:15Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NjE5OQ==", "bodyText": "This code was wrong, now has changed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476696199", "createdAt": "2020-08-25T19:46:41Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzQ2OQ=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg2MTQzOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOTowNzo1MFrOHFyl2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo0MzowMVrOHIGZhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzgxNw==", "bodyText": "debug?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833817", "createdAt": "2020-08-24T19:07:50Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());\n+        }\n+        try {\n+            Map<String, Map<String, Double>> saliency = inputFuture.get().entrySet().stream().collect(Collectors.toMap(\n+                    Map.Entry::getKey,\n+                    e -> e.getValue().getPerFeatureImportance().stream().collect(Collectors.toMap(\n+                            v -> v.getFeature().getName(),\n+                            FeatureImportance::getScore\n+                    ))\n+            ));\n+            return new ExplainabilityResultDto(executionId, saliency);\n+        } catch (ExecutionException | InterruptedException e) {\n+            LOG.error(\"Exception on createResultDto\", e);\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static Prediction getPrediction(Map<String, TypedValue> inputs, Map<String, TypedValue> outputs) {\n+        PredictionInput input = getPredictionInput(inputs);\n+        PredictionOutput output = getPredictionOutput(outputs);\n+        return new Prediction(input, output);\n+    }\n+\n+    private static PredictionInput getPredictionInput(Map<String, TypedValue> inputs) {\n+        // TODO : convert inputs to a PredictionInput\n+        LOG.info(\"** getPredictionInput called with \" + inputs.size() + \" inputs ***\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1NTQ5NA==", "bodyText": "It was a WIP, removed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478255494", "createdAt": "2020-08-27T08:43:01Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());\n+        }\n+        try {\n+            Map<String, Map<String, Double>> saliency = inputFuture.get().entrySet().stream().collect(Collectors.toMap(\n+                    Map.Entry::getKey,\n+                    e -> e.getValue().getPerFeatureImportance().stream().collect(Collectors.toMap(\n+                            v -> v.getFeature().getName(),\n+                            FeatureImportance::getScore\n+                    ))\n+            ));\n+            return new ExplainabilityResultDto(executionId, saliency);\n+        } catch (ExecutionException | InterruptedException e) {\n+            LOG.error(\"Exception on createResultDto\", e);\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static Prediction getPrediction(Map<String, TypedValue> inputs, Map<String, TypedValue> outputs) {\n+        PredictionInput input = getPredictionInput(inputs);\n+        PredictionOutput output = getPredictionOutput(outputs);\n+        return new Prediction(input, output);\n+    }\n+\n+    private static PredictionInput getPredictionInput(Map<String, TypedValue> inputs) {\n+        // TODO : convert inputs to a PredictionInput\n+        LOG.info(\"** getPredictionInput called with \" + inputs.size() + \" inputs ***\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzgxNw=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg4MjQ0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToxNDoyMVrOHFyywA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNlQxNToxNDo0MVrOHHQ-aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzEyMA==", "bodyText": "Maybe it's not really related to this PR, but why the score in the Output is set to 1? what's that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837120", "createdAt": "2020-08-24T19:14:21Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM4MDIwMw==", "bodyText": "That number is the confidence of output value. We don't have this concept with Kogito so it is always 1 (aka confidence 100%). You can find some usage with OpenNLP tests ( link )", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477380203", "createdAt": "2020-08-26T15:14:41Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzEyMA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg4Nzk4OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToxNTo1NFrOHFy2CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwODo1NTowN1rOHIG2YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzk2MQ==", "bodyText": "Is this going to work if there are more than 2 levels of nesting for structures? a test for that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837961", "createdAt": "2020-08-24T19:15:54Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);\n+            outputs.add(output);\n+        }\n+        return new PredictionOutput(outputs);\n+    }\n+\n+    private List<PredictionOutput> addElement(List<PredictionOutput> l1, PredictionOutput elem) {\n+        List<PredictionOutput> result = new ArrayList<>(l1);\n+        result.add(elem);\n+        return result;\n+    }\n+\n+    private List<PredictionOutput> merge(List<PredictionOutput> l1, List<PredictionOutput> l2) {\n+        List<PredictionOutput> result = new ArrayList<>();\n+        result.addAll(l1);\n+        result.addAll(l2);\n+        return result;\n+    }\n+\n+    private CompletableFuture<PredictionOutput> sendPredictRequest(PredictionInput input, String[] namespaceAndName) {\n+        HttpRequest<Buffer> post = client.post(\"/predict\");\n+        Map<String, Object> map = toMap(input.getFeatures());\n+        PredictInput pi = new PredictInput();\n+        pi.setRequest(map);\n+        pi.setModelIdentifier(new ModelIdentifier(namespaceAndName[0], namespaceAndName[1]));\n+        return threadContext.withContextCapture(post.sendJson(pi).subscribeAsCompletionStage())\n+                .thenApply(r -> toPredictionOutput(r.bodyAsJsonObject()));\n+    }\n+\n+    private String[] extractNamespaceAndName(String resourceId) {\n+        int index = resourceId.lastIndexOf(ModelIdentifier.RESOURCE_ID_SEPARATOR);\n+        if (index < 0 || index == resourceId.length()) {\n+            throw new IllegalArgumentException(\"Malformed resourceId \" + resourceId);\n+        }\n+        return new String[]{resourceId.substring(0, index), resourceId.substring(index + 1)};\n+    }\n+\n+    private Map<String, Object> toMap(List<Feature> features) {\n+        Map<String, Object> map = new HashMap<>();\n+        for (Feature f : features) {\n+            if (Type.COMPOSITE.equals(f.getType())) {\n+                List<Feature> compositeFeatures = (List<Feature>) f.getValue().getUnderlyingObject();\n+                Map<String, Object> maps = new HashMap<>();\n+                for (Feature cf : compositeFeatures) {\n+                    Map<String, Object> compositeFeatureMap = toMap(List.of(cf));\n+                    maps.putAll(compositeFeatureMap);\n+                }\n+                map.put(f.getName(), maps);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2Mjg4MA==", "bodyText": "Done, added a test for this scenario", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478262880", "createdAt": "2020-08-27T08:55:07Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);\n+            outputs.add(output);\n+        }\n+        return new PredictionOutput(outputs);\n+    }\n+\n+    private List<PredictionOutput> addElement(List<PredictionOutput> l1, PredictionOutput elem) {\n+        List<PredictionOutput> result = new ArrayList<>(l1);\n+        result.add(elem);\n+        return result;\n+    }\n+\n+    private List<PredictionOutput> merge(List<PredictionOutput> l1, List<PredictionOutput> l2) {\n+        List<PredictionOutput> result = new ArrayList<>();\n+        result.addAll(l1);\n+        result.addAll(l2);\n+        return result;\n+    }\n+\n+    private CompletableFuture<PredictionOutput> sendPredictRequest(PredictionInput input, String[] namespaceAndName) {\n+        HttpRequest<Buffer> post = client.post(\"/predict\");\n+        Map<String, Object> map = toMap(input.getFeatures());\n+        PredictInput pi = new PredictInput();\n+        pi.setRequest(map);\n+        pi.setModelIdentifier(new ModelIdentifier(namespaceAndName[0], namespaceAndName[1]));\n+        return threadContext.withContextCapture(post.sendJson(pi).subscribeAsCompletionStage())\n+                .thenApply(r -> toPredictionOutput(r.bodyAsJsonObject()));\n+    }\n+\n+    private String[] extractNamespaceAndName(String resourceId) {\n+        int index = resourceId.lastIndexOf(ModelIdentifier.RESOURCE_ID_SEPARATOR);\n+        if (index < 0 || index == resourceId.length()) {\n+            throw new IllegalArgumentException(\"Malformed resourceId \" + resourceId);\n+        }\n+        return new String[]{resourceId.substring(0, index), resourceId.substring(index + 1)};\n+    }\n+\n+    private Map<String, Object> toMap(List<Feature> features) {\n+        Map<String, Object> map = new HashMap<>();\n+        for (Feature f : features) {\n+            if (Type.COMPOSITE.equals(f.getType())) {\n+                List<Feature> compositeFeatures = (List<Feature>) f.getValue().getUnderlyingObject();\n+                Map<String, Object> maps = new HashMap<>();\n+                for (Feature cf : compositeFeatures) {\n+                    Map<String, Object> compositeFeatureMap = toMap(List.of(cf));\n+                    maps.putAll(compositeFeatureMap);\n+                }\n+                map.put(f.getName(), maps);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzk2MQ=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDg5OTc4OnYy", "diffSide": "RIGHT", "path": "trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToxOToyOFrOHFy9HQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxOTo0OTo1M1rOHGnVEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTc3Mw==", "bodyText": "Still to be done? Link to ticket?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475839773", "createdAt": "2020-08-24T19:19:28Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import java.util.List;\n+\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+\n+import org.eclipse.microprofile.openapi.annotations.Operation;\n+import org.eclipse.microprofile.openapi.annotations.enums.SchemaType;\n+import org.eclipse.microprofile.openapi.annotations.media.Content;\n+import org.eclipse.microprofile.openapi.annotations.media.Schema;\n+import org.eclipse.microprofile.openapi.annotations.parameters.Parameter;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponse;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponses;\n+import org.jboss.resteasy.annotations.jaxrs.PathParam;\n+import org.kie.kogito.trusty.service.responses.DecisionStructuredInputsResponse;\n+import org.kie.kogito.trusty.service.responses.FeatureImportanceResponse;\n+import org.kie.kogito.trusty.service.responses.FeaturesImportanceResponse;\n+\n+@Path(\"executions/decisions\")\n+public class ExplainabilityApiV1 {\n+\n+    @GET\n+    @Path(\"/{executionId}/featureImportance\")\n+    @APIResponses(value = {\n+            @APIResponse(description = \"Gets the local explanation of a decision.\", responseCode = \"200\", content = @Content(mediaType = MediaType.APPLICATION_JSON, schema = @Schema(type = SchemaType.OBJECT, implementation = DecisionStructuredInputsResponse.class))),\n+            @APIResponse(description = \"Bad Request\", responseCode = \"400\", content = @Content(mediaType = MediaType.TEXT_PLAIN))\n+    }\n+    )\n+    @Operation(\n+            summary = \"Returns the feature importance for a decision.\",\n+            description = \"Returns the feature importance for a particular decision calculated using the lime algorithm.\"\n+    )\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public Response getStructuredInputs(\n+            @Parameter(\n+                    name = \"executionId\",\n+                    description = \"The execution ID.\",\n+                    required = true,\n+                    schema = @Schema(implementation = String.class)\n+            ) @PathParam(\"executionId\") String executionId) {\n+        // TODO: implement this\n+        return Response.ok(new FeaturesImportanceResponse(List.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5Nzg3Mw==", "bodyText": "Now it is implemented", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476697873", "createdAt": "2020-08-25T19:49:53Z", "author": {"login": "danielezonca"}, "path": "trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import java.util.List;\n+\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+\n+import org.eclipse.microprofile.openapi.annotations.Operation;\n+import org.eclipse.microprofile.openapi.annotations.enums.SchemaType;\n+import org.eclipse.microprofile.openapi.annotations.media.Content;\n+import org.eclipse.microprofile.openapi.annotations.media.Schema;\n+import org.eclipse.microprofile.openapi.annotations.parameters.Parameter;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponse;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponses;\n+import org.jboss.resteasy.annotations.jaxrs.PathParam;\n+import org.kie.kogito.trusty.service.responses.DecisionStructuredInputsResponse;\n+import org.kie.kogito.trusty.service.responses.FeatureImportanceResponse;\n+import org.kie.kogito.trusty.service.responses.FeaturesImportanceResponse;\n+\n+@Path(\"executions/decisions\")\n+public class ExplainabilityApiV1 {\n+\n+    @GET\n+    @Path(\"/{executionId}/featureImportance\")\n+    @APIResponses(value = {\n+            @APIResponse(description = \"Gets the local explanation of a decision.\", responseCode = \"200\", content = @Content(mediaType = MediaType.APPLICATION_JSON, schema = @Schema(type = SchemaType.OBJECT, implementation = DecisionStructuredInputsResponse.class))),\n+            @APIResponse(description = \"Bad Request\", responseCode = \"400\", content = @Content(mediaType = MediaType.TEXT_PLAIN))\n+    }\n+    )\n+    @Operation(\n+            summary = \"Returns the feature importance for a decision.\",\n+            description = \"Returns the feature importance for a particular decision calculated using the lime algorithm.\"\n+    )\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public Response getStructuredInputs(\n+            @Parameter(\n+                    name = \"executionId\",\n+                    description = \"The execution ID.\",\n+                    required = true,\n+                    schema = @Schema(implementation = String.class)\n+            ) @PathParam(\"executionId\") String executionId) {\n+        // TODO: implement this\n+        return Response.ok(new FeaturesImportanceResponse(List.of(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTc3Mw=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDkwNDY0OnYy", "diffSide": "RIGHT", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMTowMFrOHFzAEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOToxNDo0MVrOHIHjfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDUyOA==", "bodyText": "still to be done?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475840528", "createdAt": "2020-08-24T19:21:00Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.filter.log.ResponseLoggingFilter;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.restassured.RestAssured.given;\n+\n+@QuarkusTest\n+public class ExplainabilityApiV1IT {\n+\n+    @Test\n+    void testFeatureImportance() {\n+        // TODO: implement this\n+        given().filter(new ResponseLoggingFilter())\n+                .when().get(\"/executions/decisions/ID/featureImportance\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI3NDQzMQ==", "bodyText": "Done now", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478274431", "createdAt": "2020-08-27T09:14:41Z", "author": {"login": "kostola"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.filter.log.ResponseLoggingFilter;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.restassured.RestAssured.given;\n+\n+@QuarkusTest\n+public class ExplainabilityApiV1IT {\n+\n+    @Test\n+    void testFeatureImportance() {\n+        // TODO: implement this\n+        given().filter(new ResponseLoggingFilter())\n+                .when().get(\"/executions/decisions/ID/featureImportance\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDUyOA=="}, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTkwNzAxOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTozMzowNlrOHIIOaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMTowMjo0NFrOHILLPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTQxNw==", "bodyText": "since we throw the same checked exception, isnt't better to log on the consumer side of the method?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285417", "createdAt": "2020-08-27T09:33:06Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -108,8 +111,15 @@ public PartialDependencePlotExplainer() {\n                         predictionInputs.add(input);\n                     }\n \n+                    List<PredictionOutput> predictionOutputs;\n+                    try {\n+                        predictionOutputs = model.predict(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+                    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+                        LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMzc1OA==", "bodyText": "I prefer to have the log here instead of add a similar code every time this method is invoked. Then the caller can decide to mute or propagate again the exception but the log will be preserved", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478333758", "createdAt": "2020-08-27T11:02:44Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -108,8 +111,15 @@ public PartialDependencePlotExplainer() {\n                         predictionInputs.add(input);\n                     }\n \n+                    List<PredictionOutput> predictionOutputs;\n+                    try {\n+                        predictionOutputs = model.predict(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+                    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+                        LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTQxNw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTkwODU5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTozMzozMFrOHIIPYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMTowMjo1MlrOHILLig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTY2Ng==", "bodyText": "same here", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285666", "createdAt": "2020-08-27T09:33:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMzgzNA==", "bodyText": "Same as above :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478333834", "createdAt": "2020-08-27T11:02:52Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTY2Ng=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTkxMjYxOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTozNDozN1rOHIIR0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMzoyNjo0MFrOHIQTLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ==", "bodyText": "is this a random unit test?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478286291", "createdAt": "2020-08-27T09:34:37Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQwMDQyMA==", "bodyText": "Please use at least static seed.", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478400420", "createdAt": "2020-08-27T13:00:45Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQwNzAxNA==", "bodyText": "This test generates a random set of data because it just tests the cardinality of the result and not the specific value", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478407014", "createdAt": "2020-08-27T13:10:55Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQxNzcxMA==", "bodyText": "Btw random removed :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478417710", "createdAt": "2020-08-27T13:26:40Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTkxODEwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTozNjowM1rOHIIVHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0Mzo1N1rOHJPO0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw==", "bodyText": "what is the expectation of this test? Should this call raise a LocalExplanationException or should it run without exceptions?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478287133", "createdAt": "2020-08-27T09:36:03Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMjg0MQ==", "bodyText": "LocalExplainationException is expected, the previous code was using assertThrows but SonarCloud complained that this code\nlimeExplainer.explainAsync(prediction, model)\n      .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\ncan throws multiple exceptions so I changed it to explicitly catch the only expected exception and let the test fails otherwise", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478332841", "createdAt": "2020-08-27T11:00:47Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjE1Mw==", "bodyText": "@danielezonca\nThrowable throwable = catchThrowable(() -> limeExplainer.explainAsync(prediction, model)\n                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit()));\nassertThat(throwable).isInstanceOf(LocalExplanationException.class)\n\n?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478662153", "createdAt": "2020-08-27T19:59:16Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODc4Nw==", "bodyText": "My bad, the exception is thrown directly by explainAsync without the need of the additional get. I have updated the test with the original assertThrows and it should be SonarCloud friendly too :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448787", "createdAt": "2020-08-28T17:43:57Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTkzMzQ5OnYy", "diffSide": "LEFT", "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTo0MDowNVrOHIIeTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMjo1NDozNlrOHIO_hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4OTQ4Ng==", "bodyText": "don't we want to use vertx executors?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478289486", "createdAt": "2020-08-27T09:40:05Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -78,8 +73,7 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n             }\n \n             CloudEventImpl<ExplainabilityRequestDto> cloudEvent = cloudEventOpt.get();\n-            return CompletableFuture\n-                    .supplyAsync(() -> handleCloudEvent(cloudEvent), executor)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM5NjI5NQ==", "bodyText": "I did a quick review of the usage of CompletableFuture.*Async in some classes because I think we should use it only when it is really needed (aka long running/blocking tasks): every time we use that code, a new task is scheduled on Vert.x task list for the next loop and this has a cost. We should use it when we start a long task or when we compose an existing one with another long task.\nIn this case the full execution flow is:\n\nexplanationService.explainAsync -> this is the starting point and it already uses (in RemotePredictionProvider) Vert.x WebClient to dispatch the REST call as async task\nsendEvent -> this should not be blocking because it builds cloud event and then just schedule it with onNext\nmessage.ack -> this is a terminal operation that complete the CompletableFuture so it is not blocking\n\nBtw we can easily re-introduce it if needed :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478396295", "createdAt": "2020-08-27T12:54:36Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -78,8 +73,7 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n             }\n \n             CloudEventImpl<ExplainabilityRequestDto> cloudEvent = cloudEventOpt.get();\n-            return CompletableFuture\n-                    .supplyAsync(() -> handleCloudEvent(cloudEvent), executor)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4OTQ4Ng=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTk0MTk3OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTo0MjowOVrOHIIjPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMTo0ODoxOFrOHIMkjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MDc1MQ==", "bodyText": "why do we create a new instance at every event?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478290751", "createdAt": "2020-08-27T09:42:09Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -107,15 +101,16 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n \n         LOGGER.info(\"Received CloudEvent with id {} from {}\", attributes.getId(), attributes.getSource());\n \n-        ExplainabilityRequestDto explainabilityResult = optData.get();\n+        ExplainabilityRequest request = ExplainabilityRequest.from(optData.get());\n+        PredictionProvider provider = predictionProviderFactory.createPredictionProvider(request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM1NjYyMw==", "bodyText": "Prediction provider is tied to request information: for now it is only using serviceUrl but in the future I expect we will support multiple predictionProviders and based on the request it will produce the proper one.", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478356623", "createdAt": "2020-08-27T11:48:18Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -107,15 +101,16 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n \n         LOGGER.info(\"Received CloudEvent with id {} from {}\", attributes.getId(), attributes.getSource());\n \n-        ExplainabilityRequestDto explainabilityResult = optData.get();\n+        ExplainabilityRequest request = ExplainabilityRequest.from(optData.get());\n+        PredictionProvider provider = predictionProviderFactory.createPredictionProvider(request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MDc1MQ=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk4OTk1ODAwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/PredictionProviderFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTo0NTo1OFrOHIIslw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMTo0Njo0OFrOHIMhQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MzE0Mw==", "bodyText": "Why a test class is renamed/moved to the src folder?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478293143", "createdAt": "2020-08-27T09:45:58Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/PredictionProviderFactory.java", "diffHunk": "@@ -16,6 +16,10 @@\n \n package org.kie.kogito.explainability;\n \n-public class ExplanationServiceTest {\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n \n+public interface PredictionProviderFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM1NTc3OA==", "bodyText": "The original class was empty so probably I moved it and reused, no real reason :)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478355778", "createdAt": "2020-08-27T11:46:48Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/PredictionProviderFactory.java", "diffHunk": "@@ -16,6 +16,10 @@\n \n package org.kie.kogito.explainability;\n \n-public class ExplanationServiceTest {\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n \n+public interface PredictionProviderFactory {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MzE0Mw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjAzOTU2OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo0MjowMlrOHIcwMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODowODo1MVrOHIu70w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMTc0NQ==", "bodyText": "refactor import java.util.*; ;)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478621745", "createdAt": "2020-08-27T18:42:02Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -43,6 +34,14 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.security.SecureRandom;\n+import java.util.*;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.stream.Collectors;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkxOTYzNQ==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478919635", "createdAt": "2020-08-28T08:08:51Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -43,6 +34,14 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.security.SecureRandom;\n+import java.util.*;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.stream.Collectors;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMTc0NQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjA0NDk0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo0MzozN1rOHIczdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzowOToyNFrOHIsHBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMjU4Mg==", "bodyText": "why protected?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478622582", "createdAt": "2020-08-27T18:43:37Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg3MzM1MA==", "bodyText": "No specific reason, it is the \"core\" method so I prefer to keep it protected to allow override if needed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478873350", "createdAt": "2020-08-28T07:09:24Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMjU4Mg=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 164}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjA2MjUwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo0ODo0OVrOHIc-FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzozNDo0NVrOHItFAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNTMwMA==", "bodyText": "shouldn't model.predict be an async task as well? Use vertx executors?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478625300", "createdAt": "2020-08-27T18:48:49Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4OTIxNw==", "bodyText": "I prefer to let the implementation of PredictionProvider to decide how to provide the result: if it is heavy computation do it on a new thread or just return the value if not. In case of RemotePredictionProvider is already async ( link )", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478889217", "createdAt": "2020-08-28T07:34:45Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNTMwMA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 174}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjA3MTkxOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo1MToyOVrOHIdDug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNjo0NzoxN1rOHJNh1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNjc0Ng==", "bodyText": "if this condition is false we are going to return a kind of empty explaination without any additional information, is this correct from a user perspective?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478626746", "createdAt": "2020-08-27T18:51:29Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)\n+                .thenCompose(predictionOutputs -> {\n+                    try {\n+                        List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n+                        return completedFuture(getSaliencies(targetInput, linearizedTargetInputFeatures, actualOutputs, limeInputsList));\n+                    } catch (DatasetNotSeparableException e) {\n+                        if (noOfRetries > 0) {\n+                            return explainRetryCycle(model, originalInput, targetInput, linearizedTargetInputFeatures, actualOutputs, noOfRetries - 1);\n                         }\n+                        throw e;\n+                    }\n+                });\n+    }\n \n-                        Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+    private List<LimeInputs> getLimeInputs(List<Feature> linearizedTargetInputFeatures,\n+                                           List<Output> actualOutputs,\n+                                           List<PredictionInput> perturbedInputs,\n+                                           List<PredictionOutput> predictionOutputs) {\n+        List<LimeInputs> limeInputsList = new LinkedList<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            Output currentOutput = actualOutputs.get(o);\n+            LimeInputs limeInputs = prepareInputs(perturbedInputs, predictionOutputs, linearizedTargetInputFeatures,\n+                    o, currentOutput);\n+            limeInputsList.add(limeInputs);\n+        }\n+        return limeInputsList;\n+    }\n \n-                        // encode the training data so that it can be fed into the linear model\n-                        DatasetEncoder datasetEncoder = new DatasetEncoder(trainingInputs, predictedOutputs, targetInput, originalOutput);\n-                        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+    private Map<String, Saliency> getSaliencies(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, List<Output> actualOutputs, List<LimeInputs> limeInputsList) {\n+        Map<String, Saliency> result = new HashMap<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            LimeInputs limeInputs = limeInputsList.get(o);\n+            Output originalOutput = actualOutputs.get(o);\n \n-                        // weight the training samples based on the proximity to the target input to explain\n-                        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+            getSaliency(targetInput, linearizedTargetInputFeatures, result, limeInputs, originalOutput);\n+            LOGGER.debug(\"weights set for output {}\", originalOutput);\n+        }\n+        return result;\n+    }\n \n-                        // fit the linear model\n-                        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n-                        double loss = linearModel.fit(trainingSet, sampleWeights);\n+    private void getSaliency(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, Map<String, Saliency> result, LimeInputs limeInputs, Output originalOutput) {\n+        List<FeatureImportance> featureImportanceList = new LinkedList<>();\n+\n+        // encode the training data so that it can be fed into the linear model\n+        DatasetEncoder datasetEncoder = new DatasetEncoder(limeInputs.getPerturbedInputs(),\n+                limeInputs.getPerturbedOutputs(),\n+                targetInput, originalOutput);\n+        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+        // weight the training samples based on the proximity to the target input to explain\n+        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), limeInputs.isClassification());\n+        double loss = linearModel.fit(trainingSet, sampleWeights);\n+        if (!Double.isNaN(loss)) {\n+            // create the output saliency\n+            int i = 0;\n+            for (Feature linearizedFeature : linearizedTargetInputFeatures) {\n+                FeatureImportance featureImportance = new FeatureImportance(linearizedFeature, linearModel.getWeights()[i]);\n+                featureImportanceList.add(featureImportance);\n+                i++;\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQyMDg4NA==", "bodyText": "Ticket created https://issues.redhat.com/browse/KOGITO-3213", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479420884", "createdAt": "2020-08-28T16:47:17Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)\n+                .thenCompose(predictionOutputs -> {\n+                    try {\n+                        List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n+                        return completedFuture(getSaliencies(targetInput, linearizedTargetInputFeatures, actualOutputs, limeInputsList));\n+                    } catch (DatasetNotSeparableException e) {\n+                        if (noOfRetries > 0) {\n+                            return explainRetryCycle(model, originalInput, targetInput, linearizedTargetInputFeatures, actualOutputs, noOfRetries - 1);\n                         }\n+                        throw e;\n+                    }\n+                });\n+    }\n \n-                        Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+    private List<LimeInputs> getLimeInputs(List<Feature> linearizedTargetInputFeatures,\n+                                           List<Output> actualOutputs,\n+                                           List<PredictionInput> perturbedInputs,\n+                                           List<PredictionOutput> predictionOutputs) {\n+        List<LimeInputs> limeInputsList = new LinkedList<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            Output currentOutput = actualOutputs.get(o);\n+            LimeInputs limeInputs = prepareInputs(perturbedInputs, predictionOutputs, linearizedTargetInputFeatures,\n+                    o, currentOutput);\n+            limeInputsList.add(limeInputs);\n+        }\n+        return limeInputsList;\n+    }\n \n-                        // encode the training data so that it can be fed into the linear model\n-                        DatasetEncoder datasetEncoder = new DatasetEncoder(trainingInputs, predictedOutputs, targetInput, originalOutput);\n-                        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+    private Map<String, Saliency> getSaliencies(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, List<Output> actualOutputs, List<LimeInputs> limeInputsList) {\n+        Map<String, Saliency> result = new HashMap<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            LimeInputs limeInputs = limeInputsList.get(o);\n+            Output originalOutput = actualOutputs.get(o);\n \n-                        // weight the training samples based on the proximity to the target input to explain\n-                        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+            getSaliency(targetInput, linearizedTargetInputFeatures, result, limeInputs, originalOutput);\n+            LOGGER.debug(\"weights set for output {}\", originalOutput);\n+        }\n+        return result;\n+    }\n \n-                        // fit the linear model\n-                        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n-                        double loss = linearModel.fit(trainingSet, sampleWeights);\n+    private void getSaliency(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, Map<String, Saliency> result, LimeInputs limeInputs, Output originalOutput) {\n+        List<FeatureImportance> featureImportanceList = new LinkedList<>();\n+\n+        // encode the training data so that it can be fed into the linear model\n+        DatasetEncoder datasetEncoder = new DatasetEncoder(limeInputs.getPerturbedInputs(),\n+                limeInputs.getPerturbedOutputs(),\n+                targetInput, originalOutput);\n+        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+        // weight the training samples based on the proximity to the target input to explain\n+        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), limeInputs.isClassification());\n+        double loss = linearModel.fit(trainingSet, sampleWeights);\n+        if (!Double.isNaN(loss)) {\n+            // create the output saliency\n+            int i = 0;\n+            for (Feature linearizedFeature : linearizedTargetInputFeatures) {\n+                FeatureImportance featureImportance = new FeatureImportance(linearizedFeature, linearModel.getWeights()[i]);\n+                featureImportanceList.add(featureImportance);\n+                i++;\n+            }\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNjc0Ng=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 244}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjA4NTg3OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo1NTozNFrOHIdMNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODowOToxNlrOHIu9WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyODkxNg==", "bodyText": "predictAsync?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478628916", "createdAt": "2020-08-27T18:55:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "diffHunk": "@@ -16,18 +16,19 @@\n package org.kie.kogito.explainability.model;\n \n import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n \n /**\n  * A provider of predictions.\n  * This can be any model, service or function, like (local / remote) DMN, PMML services or any other ML model.\n  */\n+@FunctionalInterface\n public interface PredictionProvider {\n \n     /**\n      * Perform a batch of predictions, given a batch of inputs.\n      * @param inputs the input batch\n      * @return a batch of prediction outputs\n      */\n-    List<PredictionOutput> predict(List<PredictionInput> inputs);\n-\n+    CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDAyNQ==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920025", "createdAt": "2020-08-28T08:09:16Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "diffHunk": "@@ -16,18 +16,19 @@\n package org.kie.kogito.explainability.model;\n \n import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n \n /**\n  * A provider of predictions.\n  * This can be any model, service or function, like (local / remote) DMN, PMML services or any other ML model.\n  */\n+@FunctionalInterface\n public interface PredictionProvider {\n \n     /**\n      * Perform a batch of predictions, given a batch of inputs.\n      * @param inputs the input batch\n      * @return a batch of prediction outputs\n      */\n-    List<PredictionOutput> predict(List<PredictionInput> inputs);\n-\n+    CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyODkxNg=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjEyNTQzOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTowNzoxNFrOHIdkjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODowOToyMlrOHIu9wQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTE1MA==", "bodyText": "throws Exception?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478635150", "createdAt": "2020-08-27T19:07:14Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDEyOQ==", "bodyText": "Fixed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920129", "createdAt": "2020-08-28T08:09:22Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTE1MA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjE0NjQxOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxMzozMFrOHIdxHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzozMjo1NlrOHIs_ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzODM2NQ==", "bodyText": "I have mixed feelings about this test in general, but isnt't generating only 1s? Not sure this is really representative data, if this is actually meaningful for the test itself..", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478638365", "createdAt": "2020-08-27T19:13:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4Nzc4MQ==", "bodyText": "I agree that this test is not really meaningful so I have created this ticket to improve it\nhttps://issues.redhat.com/browse/FAI-249", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478887781", "createdAt": "2020-08-28T07:32:56Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzODM2NQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjE1Mjk2OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxNToyM1rOHId1PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzoyOToxNFrOHIszLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTQyMQ==", "bodyText": "why score is set to 0?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478639421", "createdAt": "2020-08-27T19:15:23Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());\n+        }\n \n-            @Override\n-            public PredictionInput getInputShape() {\n-                List<Feature> features = new LinkedList<>();\n-                features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n-                return new PredictionInput(features);\n-            }\n+        @Override\n+        public PredictionInput getInputShape() {\n+            List<Feature> features = new LinkedList<>();\n+            features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n+            return new PredictionInput(features);\n+        }\n+\n+        @Override\n+        public PredictionOutput getOutputShape() {\n+            List<Output> outputs = new LinkedList<>();\n+            outputs.add(new Output(\"spam\", Type.BOOLEAN, new Value<>(null), 0d));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4NDY1Mg==", "bodyText": "This value is not important in this test so it is mocked", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478884652", "createdAt": "2020-08-28T07:29:14Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());\n+        }\n \n-            @Override\n-            public PredictionInput getInputShape() {\n-                List<Feature> features = new LinkedList<>();\n-                features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n-                return new PredictionInput(features);\n-            }\n+        @Override\n+        public PredictionInput getInputShape() {\n+            List<Feature> features = new LinkedList<>();\n+            features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n+            return new PredictionInput(features);\n+        }\n+\n+        @Override\n+        public PredictionOutput getOutputShape() {\n+            List<Output> outputs = new LinkedList<>();\n+            outputs.add(new Output(\"spam\", Type.BOOLEAN, new Value<>(null), 0d));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTQyMQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjE2ODIyOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToxOTo1M1rOHId-hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQwODo0Mjo1N1rOHJv5-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw==", "bodyText": "why moving the division inside the sum?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478641797", "createdAt": "2020-08-27T19:19:53Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzMzc5Ng==", "bodyText": "The previous code was considering only one PredictionOutput to calculate the impact while now it consider all of them (excluding the top one on purpose). Adding this additional for required to move the division inside the loop.", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479433796", "createdAt": "2020-08-28T17:12:47Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk1MTg2NQ==", "bodyText": "Understood, but then I have the doubt that now the method is doing something different: in this method  model.predictAsync is used with just one request, predictionOutputs should a list of just 1 element as before right?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479951865", "createdAt": "2020-08-31T07:38:46Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk4NDEyMA==", "bodyText": "It was a bug not shown by the test: the test is providing 2 features, 1 is removed (top feature) and the other 1 was used for the calculus so the old value was correct (aka equivalent to the new one)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479984120", "createdAt": "2020-08-31T08:42:57Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjE5ODUzOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOToyOToxOVrOHIeRbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzozNjoxOFrOHItKcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjYzOA==", "bodyText": "is this used?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478646638", "createdAt": "2020-08-27T19:29:19Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability.rest;\n+\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+\n+public class PredictionProviderMock implements PredictionProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg5MDYwOA==", "bodyText": "Yes it is used by this mock", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478890608", "createdAt": "2020-08-28T07:36:18Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability.rest;\n+\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+\n+public class PredictionProviderMock implements PredictionProvider {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjYzOA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIwODk4OnYy", "diffSide": "LEFT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTozMjoyOVrOHIeX3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwNzozOToxOVrOHItTqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODI4NQ==", "bodyText": "Don't we use vertx?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648285", "createdAt": "2020-08-27T19:32:29Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg5Mjk3MQ==", "bodyText": "We are using context propagation abstraction to decouple from the specific executor impl ( see Quarkus doc and MP doc )", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478892971", "createdAt": "2020-08-28T07:39:19Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODI4NQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIxMjE2OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTozMzozMFrOHIeZ9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODowNTo0MVrOHIuwHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODgyMA==", "bodyText": "why protected?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648820", "createdAt": "2020-08-27T19:33:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+    }\n+\n+    protected static ExplainabilityResultDto createResultDto(Map<String, Saliency> saliencies, String executionId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkxNjYzOQ==", "bodyText": "Why not? :)\nIt is a pure static function so it could be even public :)\nJoking aside, the reason is because it is possible to reuse it if (when?) ExplainableServiceImpl will be extended", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478916639", "createdAt": "2020-08-28T08:05:41Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+    }\n+\n+    protected static ExplainabilityResultDto createResultDto(Map<String, Saliency> saliencies, String executionId) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODgyMA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIxNzA5OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTozNTowMlrOHIedCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMzozMDozM1rOHJFnmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTYwOQ==", "bodyText": "Can we avoid returning an empty map as result? What about adding a property in the DTO with the success information and eventually the reason why there is no result?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649609", "createdAt": "2020-08-27T19:35:02Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTI5MTI5MQ==", "bodyText": "Ticket created https://issues.redhat.com/browse/KOGITO-3213", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479291291", "createdAt": "2020-08-28T13:30:33Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTYwOQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIxODk1OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTozNTozNlrOHIeeHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODowOTozNFrOHIu-vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTg4NA==", "bodyText": "move at top?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649884", "createdAt": "2020-08-27T19:35:36Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import org.eclipse.microprofile.config.inject.ConfigProperty;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import java.util.Map;\n+\n+@ApplicationScoped\n+public class LimeExplainerProducer {\n+\n+    private final Integer numberOfSamples;\n+    private final Integer numberOfPerturbations;\n+\n+    @Inject\n+    public LimeExplainerProducer(\n+            @ConfigProperty(name = \"trusty.explainability.numberOfSamples\", defaultValue = \"100\") Integer numberOfSamples,\n+            @ConfigProperty(name = \"trusty.explainability.numberOfPerturbations\", defaultValue = \"1\") Integer numberOfPerturbations) {\n+        this.numberOfSamples = numberOfSamples;\n+        this.numberOfPerturbations = numberOfPerturbations;\n+    }\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(LimeExplainerProducer.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDM4Mg==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920382", "createdAt": "2020-08-28T08:09:34Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import org.eclipse.microprofile.config.inject.ConfigProperty;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import java.util.Map;\n+\n+@ApplicationScoped\n+public class LimeExplainerProducer {\n+\n+    private final Integer numberOfSamples;\n+    private final Integer numberOfPerturbations;\n+\n+    @Inject\n+    public LimeExplainerProducer(\n+            @ConfigProperty(name = \"trusty.explainability.numberOfSamples\", defaultValue = \"100\") Integer numberOfSamples,\n+            @ConfigProperty(name = \"trusty.explainability.numberOfPerturbations\", defaultValue = \"1\") Integer numberOfPerturbations) {\n+        this.numberOfSamples = numberOfSamples;\n+        this.numberOfPerturbations = numberOfPerturbations;\n+    }\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(LimeExplainerProducer.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTg4NA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjIzNDU2OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0MDozNFrOHIenxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODoxMDowNlrOHIvA-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjM1OQ==", "bodyText": "remove wildcard?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478652359", "createdAt": "2020-08-27T19:40:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDk1Mw==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920953", "createdAt": "2020-08-28T08:10:06Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjM1OQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI1Nzc4OnYy", "diffSide": "RIGHT", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0NzoyOFrOHIe2HQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQwODoxMDoxMlrOHIvBUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjAyOQ==", "bodyText": "Remove these assignments ;)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656029", "createdAt": "2020-08-27T19:47:28Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -61,7 +82,7 @@ void givenADecisionWhenStoreDecisionIsCalledThenNoExceptionsAreThrown() {\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void givenADecisionWhenADecisionIsStoredAndRetrievedThenTheOriginalObjectIsReturned() {\n-        String executionId = \"executionId\";\n+        String executionId = TEST_EXECUTION_ID;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMTA0MQ==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478921041", "createdAt": "2020-08-28T08:10:12Z", "author": {"login": "danielezonca"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -61,7 +82,7 @@ void givenADecisionWhenStoreDecisionIsCalledThenNoExceptionsAreThrown() {\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void givenADecisionWhenADecisionIsStoredAndRetrievedThenTheOriginalObjectIsReturned() {\n-        String executionId = \"executionId\";\n+        String executionId = TEST_EXECUTION_ID;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjAyOQ=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI2MzUyOnYy", "diffSide": "RIGHT", "path": "trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo0OToxM1rOHIe5og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0MzoyNVrOHJPN7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjkzMA==", "bodyText": "move to another file?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656930", "createdAt": "2020-08-27T19:49:13Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan;\n+\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.trusty.storage.api.model.ExplainabilityResult;\n+import org.kie.kogito.trusty.storage.api.model.Saliency;\n+\n+public class ExplainabilityResultItemMarshaller extends AbstractModelMarshaller<ExplainabilityResultItem> {\n+\n+    public ExplainabilityResultItemMarshaller(ObjectMapper mapper) {\n+        super(mapper, ExplainabilityResultItem.class);\n+    }\n+\n+    @Override\n+    public ExplainabilityResultItem readFrom(ProtoStreamReader reader) throws IOException {\n+        return new ExplainabilityResultItem(\n+                reader.readString(ExplainabilityResultItem.ID_FIELD),\n+                reader.readObject(ExplainabilityResultItem.SALIENCY_FIELD, Saliency.class)\n+        );\n+    }\n+\n+    @Override\n+    public void writeTo(ProtoStreamWriter writer, ExplainabilityResultItem input) throws IOException {\n+        writer.writeString(ExplainabilityResultItem.ID_FIELD, input.getId());\n+        writer.writeObject(ExplainabilityResultItem.SALIENCY_FIELD, input.getSaliency(), Saliency.class);\n+    }\n+\n+    @Override\n+    public String getTypeName() {\n+        return String.format(\"%s.%s\", ExplainabilityResult.class.getPackageName(), ExplainabilityResultItem.class.getSimpleName());\n+    }\n+}\n+\n+class ExplainabilityResultItem {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODU1OQ==", "bodyText": "In general I am no a fan of not public inner classes but I think it makes sense in this case: this is an utility class used only to properly serialize and de-serialize a Map with proto. We can create a new file but it is not supposed to be used and it could be even dangerous to have it: someone might see this class and modify it for other reason while this should never happen.\nI added a javadoc to clarify", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448559", "createdAt": "2020-08-28T17:43:25Z", "author": {"login": "danielezonca"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan;\n+\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.trusty.storage.api.model.ExplainabilityResult;\n+import org.kie.kogito.trusty.storage.api.model.Saliency;\n+\n+public class ExplainabilityResultItemMarshaller extends AbstractModelMarshaller<ExplainabilityResultItem> {\n+\n+    public ExplainabilityResultItemMarshaller(ObjectMapper mapper) {\n+        super(mapper, ExplainabilityResultItem.class);\n+    }\n+\n+    @Override\n+    public ExplainabilityResultItem readFrom(ProtoStreamReader reader) throws IOException {\n+        return new ExplainabilityResultItem(\n+                reader.readString(ExplainabilityResultItem.ID_FIELD),\n+                reader.readObject(ExplainabilityResultItem.SALIENCY_FIELD, Saliency.class)\n+        );\n+    }\n+\n+    @Override\n+    public void writeTo(ProtoStreamWriter writer, ExplainabilityResultItem input) throws IOException {\n+        writer.writeString(ExplainabilityResultItem.ID_FIELD, input.getId());\n+        writer.writeObject(ExplainabilityResultItem.SALIENCY_FIELD, input.getSaliency(), Saliency.class);\n+    }\n+\n+    @Override\n+    public String getTypeName() {\n+        return String.format(\"%s.%s\", ExplainabilityResult.class.getPackageName(), ExplainabilityResultItem.class.getSimpleName());\n+    }\n+}\n+\n+class ExplainabilityResultItem {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjkzMA=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI3MzU2OnYy", "diffSide": "RIGHT", "path": "trusty/trusty-storage/trusty-storage-infinispan/src/test/java/org/kie/kogito/trusty/storage/infinispan/testfield/MapToListTestField.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo1MjoyMVrOHIe_-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNjo1MjowN1rOHJNrUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1ODU1Mw==", "bodyText": "what's that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478658553", "createdAt": "2020-08-27T19:52:21Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/test/java/org/kie/kogito/trusty/storage/infinispan/testfield/MapToListTestField.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan.testfield;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+\n+public class MapToListTestField<M, K, V, L> extends ListTestField<M, L> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQyMzMxNQ==", "bodyText": "It is an utility test class to handle map and reuse MarshallerTestTemplate mechanism", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479423315", "createdAt": "2020-08-28T16:52:07Z", "author": {"login": "danielezonca"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/test/java/org/kie/kogito/trusty/storage/infinispan/testfield/MapToListTestField.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan.testfield;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+\n+public class MapToListTestField<M, K, V, L> extends ListTestField<M, L> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1ODU1Mw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MjI3OTgwOnYy", "diffSide": "RIGHT", "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo1NDoxMlrOHIfDiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0MzoxOFrOHJPNsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw==", "bodyText": "everything with capital letters?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478659467", "createdAt": "2020-08-27T19:54:12Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg1Mzc1NQ==", "bodyText": "why? \ud83e\udd14", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478853755", "createdAt": "2020-08-28T06:19:36Z", "author": {"login": "kostola"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4NjYyNg==", "bodyText": "because they are constants https://www.oracle.com/java/technologies/javase/codeconventions-namingconventions.html", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478886626", "createdAt": "2020-08-28T07:31:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODQ5Nw==", "bodyText": "Done", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448497", "createdAt": "2020-08-28T17:43:18Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTU2MTg0OnYy", "diffSide": "RIGHT", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMTo0MTo1NFrOHI-tdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0MTozNlrOHJPKqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE3ODEwMw==", "bodyText": "Can we add some description here?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479178103", "createdAt": "2020-08-28T11:41:54Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -74,4 +81,25 @@ public PredictionOutput getOutputShape() {\n         }\n     }\n \n+    @Test\n+    void testBrokenPredict() {\n+        Config.INSTANCE.setAsyncTimeout(1);\n+        Config.INSTANCE.setAsyncTimeUnit(TimeUnit.MILLISECONDS);\n+\n+        PredictionProvider brokenProvider = inputs -> supplyAsync(\n+                () -> {\n+                    try {\n+                        Thread.sleep(1000);\n+                        return Collections.emptyList();\n+                    } catch (InterruptedException e) {\n+                        throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0NzcyMQ==", "bodyText": "I just wanted to simulated a long call to check the timeout. Improved the message", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479447721", "createdAt": "2020-08-28T17:41:36Z", "author": {"login": "danielezonca"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -74,4 +81,25 @@ public PredictionOutput getOutputShape() {\n         }\n     }\n \n+    @Test\n+    void testBrokenPredict() {\n+        Config.INSTANCE.setAsyncTimeout(1);\n+        Config.INSTANCE.setAsyncTimeUnit(TimeUnit.MILLISECONDS);\n+\n+        PredictionProvider brokenProvider = inputs -> supplyAsync(\n+                () -> {\n+                    try {\n+                        Thread.sleep(1000);\n+                        return Collections.emptyList();\n+                    } catch (InterruptedException e) {\n+                        throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE3ODEwMw=="}, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NTYzNDQ4OnYy", "diffSide": "RIGHT", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMTo1MjozMlrOHI_dfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo0MzoxMFrOHJPNeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE5MDM5OQ==", "bodyText": "Is this correct behaviour? Shouldn't we throw an exception instead?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479190399", "createdAt": "2020-08-28T11:52:32Z", "author": {"login": "jiripetrlik"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -205,12 +284,68 @@ void givenAModelWhenAModelIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturne\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void whenAModelIsNotStoredAndRetrievedByIdThenExceptionIsThrown() {\n-        String modelId = \"name:namespace\";\n+        String modelId = TEST_MODEL_ID;\n         Storage storageMock = mock(Storage.class);\n \n         when(storageMock.containsKey(modelId)).thenReturn(false);\n         when(trustyStorageServiceMock.getModelStorage()).thenReturn(storageMock);\n \n-        Assertions.assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledThenNoExceptionsAreThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        Assertions.assertDoesNotThrow(() -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledMoreThanOnceForSameModelThenExceptionIsThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(true);\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    void givenAnExplainabilityResultWhenAnExplainabilityResultIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturned() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = new StorageImplMock<>(String.class);\n+\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result);\n+\n+        Assertions.assertEquals(result, trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultNotStoredWhenRetrievedByIdThenExceptionIsThrown() {\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(false);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    private static JsonNode toJsonNode(String jsonString) {\n+        try {\n+            return MAPPER.reader().readTree(jsonString);\n+        } catch (JsonProcessingException e) {\n+            return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 272}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODQ0Mg==", "bodyText": "Fixed", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448442", "createdAt": "2020-08-28T17:43:10Z", "author": {"login": "danielezonca"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -205,12 +284,68 @@ void givenAModelWhenAModelIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturne\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void whenAModelIsNotStoredAndRetrievedByIdThenExceptionIsThrown() {\n-        String modelId = \"name:namespace\";\n+        String modelId = TEST_MODEL_ID;\n         Storage storageMock = mock(Storage.class);\n \n         when(storageMock.containsKey(modelId)).thenReturn(false);\n         when(trustyStorageServiceMock.getModelStorage()).thenReturn(storageMock);\n \n-        Assertions.assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledThenNoExceptionsAreThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        Assertions.assertDoesNotThrow(() -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledMoreThanOnceForSameModelThenExceptionIsThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(true);\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    void givenAnExplainabilityResultWhenAnExplainabilityResultIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturned() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = new StorageImplMock<>(String.class);\n+\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result);\n+\n+        Assertions.assertEquals(result, trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultNotStoredWhenRetrievedByIdThenExceptionIsThrown() {\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(false);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    private static JsonNode toJsonNode(String jsonString) {\n+        try {\n+            return MAPPER.reader().readTree(jsonString);\n+        } catch (JsonProcessingException e) {\n+            return null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE5MDM5OQ=="}, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 272}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 648, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}