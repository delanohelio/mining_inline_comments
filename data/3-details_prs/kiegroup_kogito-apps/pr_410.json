{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyNjYxNjg4", "number": 410, "title": "KOGITO-2914: connect Trusty service and Explainability service", "bodyText": "General description\nThis PR includes multiple tickets because the are all correlated to close the end to end loop ([involved component]):\n\nKOGITO-3086: implement a remote PredictionProvider that uses /predict API to calculate explainability. To do that, refactor explainability-core to support not blocking execution [explainability-addon][explainability-core]\nKOGITO-2944: implement explainability DTOs for input and output and connect them to explainability-core [trusty-service][explainbility-service]\nKOGITO-2945: store and read explainability result inside trusty-service [trusty-service]\nKOGITO-2914: expose explainability information as REST featureImportance endpoint [trusty-service]\n\nDescription of this PR\nThis PR involves trusty-service and explainability-service.\n\nImplementation of ExplainabilityRequestDto and ExplainabilityResultDto with all data needed for explainabiltiy\nBig explainability-core refactor to make explain method async (now explainAsync) using CompletableFuture. The most important changes are inside LimeExplainer. NOTE: test suite is still the same so the behavior has not changed (a part from API changes of course)\nImplementation of RemotePredictionProvider\nExplainableServiceImpl is no more mocked and now is properly connected with explainability-core library\ntrusty-service now properly store ExplainabilityResultDto\ntrusty-service now expose explainability values via ExplainabilityApiV1\n\nNOTE: SonarCloud test coverage is not considering IT as part of the coverage so most of endpoint classes seem untested but they are\nList of PRs\n\nkiegroup/kogito-runtimes#720\n#410", "createdAt": "2020-08-24T17:26:33Z", "url": "https://github.com/kiegroup/kogito-apps/pull/410", "merged": true, "mergeCommit": {"oid": "c97df5efbc38a6defaf8336d6253cad27797e0fa"}, "closed": true, "closedAt": "2020-08-31T09:27:14Z", "author": {"login": "kostola"}, "timelineItems": {"totalCount": 67, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdAzAQAAH2gAyNDcyNjYxNjg4OmNjYTEwN2JjNzU3ODRmMDZhNmNiODM4ZmEwYmI2MGQzZDlmOGU4MTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdEPWvkgFqTQ3ODQ1NTI4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "cca107bc75784f06a6cb838fa0bb60d3d9f8e816", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/cca107bc75784f06a6cb838fa0bb60d3d9f8e816", "committedDate": "2020-08-20T16:42:40Z", "message": "KOGITO-2914: first stub of explainability DTOs with properties"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ad286e23ab5584214aebb8cadc5c34b44cad276", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/7ad286e23ab5584214aebb8cadc5c34b44cad276", "committedDate": "2020-08-21T12:43:35Z", "message": "KOGITO-2914: use tracing-typedvalue-api and improve explainability DTOs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e99f8c422a1063bb17c3075874ead3e6940e2ecd", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/e99f8c422a1063bb17c3075874ead3e6940e2ecd", "committedDate": "2020-08-24T08:34:50Z", "message": "KOGITO-2914: use typedvalue-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4a0f887fc1b31aafac212ab740738e403fc6cb6", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/a4a0f887fc1b31aafac212ab740738e403fc6cb6", "committedDate": "2020-08-24T08:35:55Z", "message": "KOGITO-3086 - kogito remote prediction provider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5effbf4915fdfec39fbd7acc00ca5c1798b20b3", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/b5effbf4915fdfec39fbd7acc00ca5c1798b20b3", "committedDate": "2020-08-24T08:35:55Z", "message": "KOGITO-3086 - added predict API model objects"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c4b324d38ea9a1cf6a9829fa7d558260897b34d", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/2c4b324d38ea9a1cf6a9829fa7d558260897b34d", "committedDate": "2020-08-24T08:35:55Z", "message": "KOGITO-3086 - added missing vertx dep in POM"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ff62c2396592496e6ab4d4e509a41193ee2413d", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/8ff62c2396592496e6ab4d4e509a41193ee2413d", "committedDate": "2020-08-24T08:35:55Z", "message": "KOGITO-3086 - make LimeExplainer API async"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "517b5b0b1066557550815a12fef8841617938e1a", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/517b5b0b1066557550815a12fef8841617938e1a", "committedDate": "2020-08-24T08:35:56Z", "message": "KOGITO-3086 - fail in case of empty (linearized) features"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbd84821b388394567f9c3e181e664f7acc68399", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/dbd84821b388394567f9c3e181e664f7acc68399", "committedDate": "2020-08-24T08:36:36Z", "message": "KOGITO-3086 - plugging dto/request with expl-service impl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24598be536c08a027e00d64535fb08cf55713d50", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/24598be536c08a027e00d64535fb08cf55713d50", "committedDate": "2020-08-24T08:36:36Z", "message": "KOGITO-3086 - in RKPP get the service url from the request"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41380ec06feed7a0c47dff769a86877b83eeecea", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/41380ec06feed7a0c47dff769a86877b83eeecea", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-2914: first stub of explainability DTOs with properties"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12a79d04e7bbec4d7b7b37d51a4b908647873017", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/12a79d04e7bbec4d7b7b37d51a4b908647873017", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-2914: use tracing-typedvalue-api and improve explainability DTOs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a349ab4edfa27d0e1ffd229cd38476d253a04069", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/a349ab4edfa27d0e1ffd229cd38476d253a04069", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-2914: use typedvalue-api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e913f408ff344fca93353c37d66f6ee600d4b014", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/e913f408ff344fca93353c37d66f6ee600d4b014", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - kogito remote prediction provider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ae3783034db7d50af53dddfc52177a97a7f4c76", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5ae3783034db7d50af53dddfc52177a97a7f4c76", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - added predict API model objects"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "317933b97a601e26874a16a0d74a578820400c04", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/317933b97a601e26874a16a0d74a578820400c04", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - added missing vertx dep in POM"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87b32ce63137803ce4dfb85b80db03594d813a69", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/87b32ce63137803ce4dfb85b80db03594d813a69", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - make LimeExplainer API async"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25cc6585d2ff2880b018faceb6da9cae5c80935f", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/25cc6585d2ff2880b018faceb6da9cae5c80935f", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - fail in case of empty (linearized) features"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "127da32a58068a22c554e7b7c4a84623249c9588", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/127da32a58068a22c554e7b7c4a84623249c9588", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - plugging dto/request with expl-service impl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5690e8fd14a9b1d040dd2e601b368a12b8129c07", "author": {"user": {"login": "tteofili", "name": "Tommaso Teofili"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5690e8fd14a9b1d040dd2e601b368a12b8129c07", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-3086 - in RKPP get the service url from the request"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44079831610e9e985b211935d3275e2efa8648a7", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/44079831610e9e985b211935d3275e2efa8648a7", "committedDate": "2020-08-24T15:04:31Z", "message": "KOGITO-2914: add DecisionInput to persistence models"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "564aea31e111e63044a126b5b47caf71f4641acf", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/564aea31e111e63044a126b5b47caf71f4641acf", "committedDate": "2020-08-24T15:57:33Z", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5041a4994ddecfb6f2d5da83853c32c577de2eba", "committedDate": "2020-08-24T17:23:38Z", "message": "KOGITO-2914: working loop between trusty and explainability services (some stubbed parts yet)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fa703c099a80579a271ce579e69e935a560f5ca", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5fa703c099a80579a271ce579e69e935a560f5ca", "committedDate": "2020-08-24T17:48:14Z", "message": "[KOGITO-2914] missing license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "538a5e3069b771f60fdf5245486d5a0bd5d06c15", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/538a5e3069b771f60fdf5245486d5a0bd5d06c15", "committedDate": "2020-08-24T17:48:23Z", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNzY0Mjg4", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-473764288", "createdAt": "2020-08-24T18:43:15Z", "commit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODo0MzoxNVrOHFxypA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMTowMFrOHFzAEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA==", "bodyText": "I think the URL should not be in the dto (at least for the scenarios we will support in this first release). The URL to be used is going to be injected by the operator with an enviroment variable. wdyt?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475820708", "createdAt": "2020-08-24T18:43:15Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng==", "bodyText": "Create a dedicated object for this to avoid Map<Map<>> that is not very informative? imo it's better to encapsulate it in a separated object in general since it will be easier to add properties in the future", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475821496", "createdAt": "2020-08-24T18:44:40Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "diffHunk": "@@ -16,23 +16,33 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityResultDto {\n+\n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    // TODO: add properties\n+    @JsonProperty(\"saliency\")\n+    private Map<String, Map<String, Double>> saliency;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODUzOQ==", "bodyText": "I'm not sure about this reaction to these exceptions. Let's assume that something bad happens and we catch the exception, we would anyway produce an (kind of empty?) explaination and display it right? If something bad happens, I think we should make it transparent to the user somehow (or even leave the explaination as \"not available\" or something) and not showing him wrong information", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475828539", "createdAt": "2020-08-24T18:57:40Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -75,17 +77,23 @@ public static double impactScore(PredictionProvider model, Prediction prediction\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput)).get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            predictionOutputs = Collections.emptyList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyOTk5Mg==", "bodyText": "move to TOP_FEATURE_THRESHOLD constant or something?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475829992", "createdAt": "2020-08-24T19:00:27Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -53,41 +55,53 @@ private void assertStable(PredictionProvider model, List<Feature> featureList) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(featureList);\n-            List<PredictionOutput> predictionOutputs = model.predict(List.of(input));\n-            Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n-            List<Saliency> saliencies = new LinkedList<>();\n-            for (int i = 0; i < 100; i++) {\n-                Map<String, Saliency> saliencyMap = limeExplainer.explain(prediction, model);\n-                saliencies.addAll(saliencyMap.values());\n+            List<PredictionOutput> predictionOutputs;\n+            try {\n+                predictionOutputs = model.predict(List.of(input)).get();\n+            } catch (InterruptedException | ExecutionException e) {\n+                predictionOutputs = Collections.emptyList();\n             }\n-            // check that the topmost important feature is stable\n-            List<String> names = new LinkedList<>();\n-            saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n-            Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n-            boolean topFeature = false;\n-            for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n-                if (entry.getValue() >= 0.9) {\n-                    topFeature = true;\n-                    break;\n+            for (PredictionOutput predictionOutput : predictionOutputs) {\n+                Prediction prediction = new Prediction(input, predictionOutput);\n+                List<Saliency> saliencies = new LinkedList<>();\n+                for (int i = 0; i < 100; i++) {\n+                    Map<String, Saliency> saliencyMap = null;\n+                    try {\n+                        saliencyMap = limeExplainer.explain(prediction, model).get();\n+                    } catch (InterruptedException | ExecutionException e) {\n+                        saliencyMap = Collections.emptyMap();\n+                    }\n+                    saliencies.addAll(saliencyMap.values());\n                 }\n-            }\n-            assertTrue(topFeature);\n+                // check that the topmost important feature is stable\n+                List<String> names = new LinkedList<>();\n+                saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+                Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+                boolean topFeature = false;\n+                for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+                    if (entry.getValue() >= 0.9) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDIzMA==", "bodyText": "disable the test instead of commenting?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475830230", "createdAt": "2020-08-24T19:00:53Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java", "diffHunk": "@@ -38,41 +38,41 @@ void testSamplingEmptyDataset() {\n         SampleWeighter.getSampleWeights(targetInput, trainingSet);\n     }\n \n-    @Test\n-    void testSamplingNonEmptyDataset() {\n-        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n-        List<Feature> features = new LinkedList<>();\n-        for (int i = 0; i < 5; i++) {\n-            features.add(TestUtils.getMockedNumericFeature());\n-        }\n-        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n-        for (int i = 0; i < 10; i++) {\n-            int finalI = i;\n-            Pair<double[], Double> doubles = new Pair<>() {\n-                @Override\n-                public double[] getLeft() {\n-                    double[] vector = new double[features.size()];\n-                    Arrays.fill(vector, 1d / (1d + finalI));\n-                    return vector;\n-                }\n-\n-                @Override\n-                public Double getRight() {\n-                    return 0d;\n-                }\n-\n-                @Override\n-                public Double setValue(Double aDouble) {\n-                    return 0d;\n-                }\n-            };\n-            trainingSet.add(doubles);\n-        }\n-        PredictionInput targetInput = new PredictionInput(features);\n-        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n-        // check that weights decrease with the distance from the 1 vector (the target instance)\n-        for (int i = 0; i < weights.length - 1; i++) {\n-            assertTrue(weights[i] > weights[i + 1]);\n-        }\n-    }\n+//    @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTM2Ng==", "bodyText": "remove this log or make it more informative like processing explainability for execution id xyz?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475831366", "createdAt": "2020-08-24T19:03:07Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjIzNg==", "bodyText": "should't this call the expl lib?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475832236", "createdAt": "2020-08-24T19:04:54Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzIxMQ==", "bodyText": "why check isDone?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833211", "createdAt": "2020-08-24T19:06:48Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzQ2OQ==", "bodyText": "Not sure this is the expected explaination result in case of an exception", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833469", "createdAt": "2020-08-24T19:07:15Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzgxNw==", "bodyText": "debug?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833817", "createdAt": "2020-08-24T19:07:50Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());\n+        }\n+        try {\n+            Map<String, Map<String, Double>> saliency = inputFuture.get().entrySet().stream().collect(Collectors.toMap(\n+                    Map.Entry::getKey,\n+                    e -> e.getValue().getPerFeatureImportance().stream().collect(Collectors.toMap(\n+                            v -> v.getFeature().getName(),\n+                            FeatureImportance::getScore\n+                    ))\n+            ));\n+            return new ExplainabilityResultDto(executionId, saliency);\n+        } catch (ExecutionException | InterruptedException e) {\n+            LOG.error(\"Exception on createResultDto\", e);\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static Prediction getPrediction(Map<String, TypedValue> inputs, Map<String, TypedValue> outputs) {\n+        PredictionInput input = getPredictionInput(inputs);\n+        PredictionOutput output = getPredictionOutput(outputs);\n+        return new Prediction(input, output);\n+    }\n+\n+    private static PredictionInput getPredictionInput(Map<String, TypedValue> inputs) {\n+        // TODO : convert inputs to a PredictionInput\n+        LOG.info(\"** getPredictionInput called with \" + inputs.size() + \" inputs ***\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzEyMA==", "bodyText": "Maybe it's not really related to this PR, but why the score in the Output is set to 1? what's that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837120", "createdAt": "2020-08-24T19:14:21Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzk2MQ==", "bodyText": "Is this going to work if there are more than 2 levels of nesting for structures? a test for that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837961", "createdAt": "2020-08-24T19:15:54Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);\n+            outputs.add(output);\n+        }\n+        return new PredictionOutput(outputs);\n+    }\n+\n+    private List<PredictionOutput> addElement(List<PredictionOutput> l1, PredictionOutput elem) {\n+        List<PredictionOutput> result = new ArrayList<>(l1);\n+        result.add(elem);\n+        return result;\n+    }\n+\n+    private List<PredictionOutput> merge(List<PredictionOutput> l1, List<PredictionOutput> l2) {\n+        List<PredictionOutput> result = new ArrayList<>();\n+        result.addAll(l1);\n+        result.addAll(l2);\n+        return result;\n+    }\n+\n+    private CompletableFuture<PredictionOutput> sendPredictRequest(PredictionInput input, String[] namespaceAndName) {\n+        HttpRequest<Buffer> post = client.post(\"/predict\");\n+        Map<String, Object> map = toMap(input.getFeatures());\n+        PredictInput pi = new PredictInput();\n+        pi.setRequest(map);\n+        pi.setModelIdentifier(new ModelIdentifier(namespaceAndName[0], namespaceAndName[1]));\n+        return threadContext.withContextCapture(post.sendJson(pi).subscribeAsCompletionStage())\n+                .thenApply(r -> toPredictionOutput(r.bodyAsJsonObject()));\n+    }\n+\n+    private String[] extractNamespaceAndName(String resourceId) {\n+        int index = resourceId.lastIndexOf(ModelIdentifier.RESOURCE_ID_SEPARATOR);\n+        if (index < 0 || index == resourceId.length()) {\n+            throw new IllegalArgumentException(\"Malformed resourceId \" + resourceId);\n+        }\n+        return new String[]{resourceId.substring(0, index), resourceId.substring(index + 1)};\n+    }\n+\n+    private Map<String, Object> toMap(List<Feature> features) {\n+        Map<String, Object> map = new HashMap<>();\n+        for (Feature f : features) {\n+            if (Type.COMPOSITE.equals(f.getType())) {\n+                List<Feature> compositeFeatures = (List<Feature>) f.getValue().getUnderlyingObject();\n+                Map<String, Object> maps = new HashMap<>();\n+                for (Feature cf : compositeFeatures) {\n+                    Map<String, Object> compositeFeatureMap = toMap(List.of(cf));\n+                    maps.putAll(compositeFeatureMap);\n+                }\n+                map.put(f.getName(), maps);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTc3Mw==", "bodyText": "Still to be done? Link to ticket?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475839773", "createdAt": "2020-08-24T19:19:28Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import java.util.List;\n+\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+\n+import org.eclipse.microprofile.openapi.annotations.Operation;\n+import org.eclipse.microprofile.openapi.annotations.enums.SchemaType;\n+import org.eclipse.microprofile.openapi.annotations.media.Content;\n+import org.eclipse.microprofile.openapi.annotations.media.Schema;\n+import org.eclipse.microprofile.openapi.annotations.parameters.Parameter;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponse;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponses;\n+import org.jboss.resteasy.annotations.jaxrs.PathParam;\n+import org.kie.kogito.trusty.service.responses.DecisionStructuredInputsResponse;\n+import org.kie.kogito.trusty.service.responses.FeatureImportanceResponse;\n+import org.kie.kogito.trusty.service.responses.FeaturesImportanceResponse;\n+\n+@Path(\"executions/decisions\")\n+public class ExplainabilityApiV1 {\n+\n+    @GET\n+    @Path(\"/{executionId}/featureImportance\")\n+    @APIResponses(value = {\n+            @APIResponse(description = \"Gets the local explanation of a decision.\", responseCode = \"200\", content = @Content(mediaType = MediaType.APPLICATION_JSON, schema = @Schema(type = SchemaType.OBJECT, implementation = DecisionStructuredInputsResponse.class))),\n+            @APIResponse(description = \"Bad Request\", responseCode = \"400\", content = @Content(mediaType = MediaType.TEXT_PLAIN))\n+    }\n+    )\n+    @Operation(\n+            summary = \"Returns the feature importance for a decision.\",\n+            description = \"Returns the feature importance for a particular decision calculated using the lime algorithm.\"\n+    )\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public Response getStructuredInputs(\n+            @Parameter(\n+                    name = \"executionId\",\n+                    description = \"The execution ID.\",\n+                    required = true,\n+                    schema = @Schema(implementation = String.class)\n+            ) @PathParam(\"executionId\") String executionId) {\n+        // TODO: implement this\n+        return Response.ok(new FeaturesImportanceResponse(List.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDUyOA==", "bodyText": "still to be done?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475840528", "createdAt": "2020-08-24T19:21:00Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.filter.log.ResponseLoggingFilter;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.restassured.RestAssured.given;\n+\n+@QuarkusTest\n+public class ExplainabilityApiV1IT {\n+\n+    @Test\n+    void testFeatureImportance() {\n+        // TODO: implement this\n+        given().filter(new ResponseLoggingFilter())\n+                .when().get(\"/executions/decisions/ID/featureImportance\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba"}, "originalPosition": 16}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97188aa0a726be6c427428bcc952738a97e563c0", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/97188aa0a726be6c427428bcc952738a97e563c0", "committedDate": "2020-08-25T08:01:20Z", "message": "Merge branch 'master' into 'KOGITO-2914'"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "committedDate": "2020-08-25T10:30:59Z", "message": "KOGITO-2914: implement persistence of ExplainabilityResult"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1453d2364fe66960068cd4a9eb2245d6178553c", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/f1453d2364fe66960068cd4a9eb2245d6178553c", "committedDate": "2020-08-25T11:33:21Z", "message": "KOGITO-2914: implement ExplainabilityApiV1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2217030d4f8e8febeadd8720185df80a1da8088", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/c2217030d4f8e8febeadd8720185df80a1da8088", "committedDate": "2020-08-25T12:31:52Z", "message": "[KOGITO-2914] Review CompletableFuture usages in expl-core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "committedDate": "2020-08-25T16:46:41Z", "message": "KOGITO-2914: fix call from explainability service to predict endpoint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bc7ce079e81d8f26984846a5b0ddf10393101ef", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/3bc7ce079e81d8f26984846a5b0ddf10393101ef", "committedDate": "2020-08-25T19:41:07Z", "message": "[KOGITO-2914] Review DTO to use ModelIdentifier + Fix jandex index + RemoteKogitoPredictionProvider now sends all the inputs together"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe3fb4c5cbf2a3db4d60f727f738fc35820362a2", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/fe3fb4c5cbf2a3db4d60f727f738fc35820362a2", "committedDate": "2020-08-26T09:22:09Z", "message": "KOGITO-2914: improve input/output parsing in explainability service"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "baee3426acbd1e3cdef7a9f384ecb839d0a2d441", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/baee3426acbd1e3cdef7a9f384ecb839d0a2d441", "committedDate": "2020-08-26T10:22:37Z", "message": "KOGITO-2914: add comment in RemoteKogitoPredictionProvider to explain a particular behavior"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b9972dadf8e865f035dfdb219b5056520cb0e9b", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/7b9972dadf8e865f035dfdb219b5056520cb0e9b", "committedDate": "2020-08-26T13:59:18Z", "message": "[KOGITO-2914] Fix rety mechanism in case of not separable dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d39fe0cb5e89309db8fbf3585a32df77dc7a3d2", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/7d39fe0cb5e89309db8fbf3585a32df77dc7a3d2", "committedDate": "2020-08-26T13:59:32Z", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "438aa5bda5553df0eb10b903cac43df4d5585c21", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/438aa5bda5553df0eb10b903cac43df4d5585c21", "committedDate": "2020-08-26T14:12:30Z", "message": "[KOGITO-2914] Fix rety mechanism in case of not separable dataset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "75bd0e34ab27cd9bcafe03aa4b2e64a497aaa086", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/75bd0e34ab27cd9bcafe03aa4b2e64a497aaa086", "committedDate": "2020-08-26T15:53:08Z", "message": "KOGITO-2914: improve coverage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de1d89b35d77e657d62f0fab17d7af67d394ef3d", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/de1d89b35d77e657d62f0fab17d7af67d394ef3d", "committedDate": "2020-08-26T22:09:56Z", "message": "[KOGITO-2914] explainability-service refactoring to make it testable + test coverage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c4000afce63d022f732a8dbef06b05c5cc2b58c", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/1c4000afce63d022f732a8dbef06b05c5cc2b58c", "committedDate": "2020-08-27T07:04:05Z", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "013ea031450abd9d28e848412e49645d5b2b0e9e", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/013ea031450abd9d28e848412e49645d5b2b0e9e", "committedDate": "2020-08-27T07:05:04Z", "message": "KOGITO-2914: improve trusty-service coverage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d105d13d1607fece46c0248b1f005747a59d20d", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/1d105d13d1607fece46c0248b1f005747a59d20d", "committedDate": "2020-08-27T07:05:12Z", "message": "Merge branch 'master' into 'KOGITO-2914'"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29af97856bd7f07e5c96ec6fba9c7c95fed7c944", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/29af97856bd7f07e5c96ec6fba9c7c95fed7c944", "committedDate": "2020-08-27T07:08:27Z", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell (removed duplicated class)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a6da048283f548cbcfaff46ecdc80809f2cb8c9", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/8a6da048283f548cbcfaff46ecdc80809f2cb8c9", "committedDate": "2020-08-27T07:29:06Z", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e2af340ebb00c44a28e756dbfa1299922d5a752", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/1e2af340ebb00c44a28e756dbfa1299922d5a752", "committedDate": "2020-08-27T07:31:06Z", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2acfadf15ebdc0b148c05eb65053be3ddc29062", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/e2acfadf15ebdc0b148c05eb65053be3ddc29062", "committedDate": "2020-08-27T08:22:47Z", "message": "[KOGITO-2914] Improve test coverage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e78a977dad88620eedbdfdda17717db025a4d1f", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/2e78a977dad88620eedbdfdda17717db025a4d1f", "committedDate": "2020-08-27T08:54:43Z", "message": "[KOGITO-2914] Changes based on PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f9f94981e066dc495b56f3f8d7dff5950a70ad8", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/5f9f94981e066dc495b56f3f8d7dff5950a70ad8", "committedDate": "2020-08-27T09:01:35Z", "message": "KOGITO-2914: improve coverage of trusty-service"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8b4287fe92ec8e8c650fde990ca2f22fee5f49e", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/a8b4287fe92ec8e8c650fde990ca2f22fee5f49e", "committedDate": "2020-08-27T09:01:38Z", "message": "Merge branch 'KOGITO-2914' of kostola/kogito-apps into 'KOGITO-2914'"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dda6ade677296eb1f82a6a34979d9de8d7e5305a", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/dda6ade677296eb1f82a6a34979d9de8d7e5305a", "committedDate": "2020-08-27T09:23:21Z", "message": "[KOGITO-2914] Improve coverage + codesmell"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/64d149a68d9f91edaede7dea4655886f3e0f06e1", "committedDate": "2020-08-27T09:23:28Z", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2NTQ3NDgx", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-476547481", "createdAt": "2020-08-27T09:33:06Z", "commit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTozMzowNlrOHIIOaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QwOTo0NTo1OFrOHIIslw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTQxNw==", "bodyText": "since we throw the same checked exception, isnt't better to log on the consumer side of the method?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285417", "createdAt": "2020-08-27T09:33:06Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -108,8 +111,15 @@ public PartialDependencePlotExplainer() {\n                         predictionInputs.add(input);\n                     }\n \n+                    List<PredictionOutput> predictionOutputs;\n+                    try {\n+                        predictionOutputs = model.predict(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+                    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+                        LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTY2Ng==", "bodyText": "same here", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285666", "createdAt": "2020-08-27T09:33:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ==", "bodyText": "is this a random unit test?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478286291", "createdAt": "2020-08-27T09:34:37Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw==", "bodyText": "what is the expectation of this test? Should this call raise a LocalExplanationException or should it run without exceptions?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478287133", "createdAt": "2020-08-27T09:36:03Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4OTQ4Ng==", "bodyText": "don't we want to use vertx executors?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478289486", "createdAt": "2020-08-27T09:40:05Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -78,8 +73,7 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n             }\n \n             CloudEventImpl<ExplainabilityRequestDto> cloudEvent = cloudEventOpt.get();\n-            return CompletableFuture\n-                    .supplyAsync(() -> handleCloudEvent(cloudEvent), executor)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MDc1MQ==", "bodyText": "why do we create a new instance at every event?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478290751", "createdAt": "2020-08-27T09:42:09Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -107,15 +101,16 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n \n         LOGGER.info(\"Received CloudEvent with id {} from {}\", attributes.getId(), attributes.getSource());\n \n-        ExplainabilityRequestDto explainabilityResult = optData.get();\n+        ExplainabilityRequest request = ExplainabilityRequest.from(optData.get());\n+        PredictionProvider provider = predictionProviderFactory.createPredictionProvider(request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MzE0Mw==", "bodyText": "Why a test class is renamed/moved to the src folder?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478293143", "createdAt": "2020-08-27T09:45:58Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/PredictionProviderFactory.java", "diffHunk": "@@ -16,6 +16,10 @@\n \n package org.kie.kogito.explainability;\n \n-public class ExplanationServiceTest {\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n \n+public interface PredictionProviderFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72c5a84c7362efe2259ed4916d5d2a49f7e1a3bf", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/72c5a84c7362efe2259ed4916d5d2a49f7e1a3bf", "committedDate": "2020-08-27T10:26:16Z", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914\n\n# Conflicts:\n#\ttrusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d33ed5ae54e37af02eacae5e94fd9d176636caf", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/9d33ed5ae54e37af02eacae5e94fd9d176636caf", "committedDate": "2020-08-27T11:08:18Z", "message": "[KOGITO-2914] Post merge fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3543c15505d5cb6154f07f7000959fb7c0090d3", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/c3543c15505d5cb6154f07f7000959fb7c0090d3", "committedDate": "2020-08-27T12:17:40Z", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08d0146452e4a4aff7e549468d9dfbb9fef18b7a", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/08d0146452e4a4aff7e549468d9dfbb9fef18b7a", "committedDate": "2020-08-27T12:18:41Z", "message": "[KOGITO-2914] Minor changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6d943f45041ce233977a2db707c677321bc15a2", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/a6d943f45041ce233977a2db707c677321bc15a2", "committedDate": "2020-08-27T13:26:01Z", "message": "[KOGITO-2914] Create FakeRandom for testing purpose"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "author": {"user": {"login": "kostola", "name": "Alessandro Costa"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "committedDate": "2020-08-27T13:31:15Z", "message": "KOGITO-2914: remove TODO line that was done previously"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2OTg2Nzk5", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-476986799", "createdAt": "2020-08-27T18:42:02Z", "commit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "state": "COMMENTED", "comments": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxODo0MjowMlrOHIcwMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxOTo1OToxNlrOHIfOCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMTc0NQ==", "bodyText": "refactor import java.util.*; ;)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478621745", "createdAt": "2020-08-27T18:42:02Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -43,6 +34,14 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.security.SecureRandom;\n+import java.util.*;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.stream.Collectors;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMjU4Mg==", "bodyText": "why protected?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478622582", "createdAt": "2020-08-27T18:43:37Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNTMwMA==", "bodyText": "shouldn't model.predict be an async task as well? Use vertx executors?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478625300", "createdAt": "2020-08-27T18:48:49Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNjc0Ng==", "bodyText": "if this condition is false we are going to return a kind of empty explaination without any additional information, is this correct from a user perspective?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478626746", "createdAt": "2020-08-27T18:51:29Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)\n+                .thenCompose(predictionOutputs -> {\n+                    try {\n+                        List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n+                        return completedFuture(getSaliencies(targetInput, linearizedTargetInputFeatures, actualOutputs, limeInputsList));\n+                    } catch (DatasetNotSeparableException e) {\n+                        if (noOfRetries > 0) {\n+                            return explainRetryCycle(model, originalInput, targetInput, linearizedTargetInputFeatures, actualOutputs, noOfRetries - 1);\n                         }\n+                        throw e;\n+                    }\n+                });\n+    }\n \n-                        Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+    private List<LimeInputs> getLimeInputs(List<Feature> linearizedTargetInputFeatures,\n+                                           List<Output> actualOutputs,\n+                                           List<PredictionInput> perturbedInputs,\n+                                           List<PredictionOutput> predictionOutputs) {\n+        List<LimeInputs> limeInputsList = new LinkedList<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            Output currentOutput = actualOutputs.get(o);\n+            LimeInputs limeInputs = prepareInputs(perturbedInputs, predictionOutputs, linearizedTargetInputFeatures,\n+                    o, currentOutput);\n+            limeInputsList.add(limeInputs);\n+        }\n+        return limeInputsList;\n+    }\n \n-                        // encode the training data so that it can be fed into the linear model\n-                        DatasetEncoder datasetEncoder = new DatasetEncoder(trainingInputs, predictedOutputs, targetInput, originalOutput);\n-                        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+    private Map<String, Saliency> getSaliencies(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, List<Output> actualOutputs, List<LimeInputs> limeInputsList) {\n+        Map<String, Saliency> result = new HashMap<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            LimeInputs limeInputs = limeInputsList.get(o);\n+            Output originalOutput = actualOutputs.get(o);\n \n-                        // weight the training samples based on the proximity to the target input to explain\n-                        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+            getSaliency(targetInput, linearizedTargetInputFeatures, result, limeInputs, originalOutput);\n+            LOGGER.debug(\"weights set for output {}\", originalOutput);\n+        }\n+        return result;\n+    }\n \n-                        // fit the linear model\n-                        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n-                        double loss = linearModel.fit(trainingSet, sampleWeights);\n+    private void getSaliency(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, Map<String, Saliency> result, LimeInputs limeInputs, Output originalOutput) {\n+        List<FeatureImportance> featureImportanceList = new LinkedList<>();\n+\n+        // encode the training data so that it can be fed into the linear model\n+        DatasetEncoder datasetEncoder = new DatasetEncoder(limeInputs.getPerturbedInputs(),\n+                limeInputs.getPerturbedOutputs(),\n+                targetInput, originalOutput);\n+        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+        // weight the training samples based on the proximity to the target input to explain\n+        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), limeInputs.isClassification());\n+        double loss = linearModel.fit(trainingSet, sampleWeights);\n+        if (!Double.isNaN(loss)) {\n+            // create the output saliency\n+            int i = 0;\n+            for (Feature linearizedFeature : linearizedTargetInputFeatures) {\n+                FeatureImportance featureImportance = new FeatureImportance(linearizedFeature, linearModel.getWeights()[i]);\n+                featureImportanceList.add(featureImportance);\n+                i++;\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyODkxNg==", "bodyText": "predictAsync?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478628916", "createdAt": "2020-08-27T18:55:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "diffHunk": "@@ -16,18 +16,19 @@\n package org.kie.kogito.explainability.model;\n \n import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n \n /**\n  * A provider of predictions.\n  * This can be any model, service or function, like (local / remote) DMN, PMML services or any other ML model.\n  */\n+@FunctionalInterface\n public interface PredictionProvider {\n \n     /**\n      * Perform a batch of predictions, given a batch of inputs.\n      * @param inputs the input batch\n      * @return a batch of prediction outputs\n      */\n-    List<PredictionOutput> predict(List<PredictionInput> inputs);\n-\n+    CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTE1MA==", "bodyText": "throws Exception?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478635150", "createdAt": "2020-08-27T19:07:14Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzODM2NQ==", "bodyText": "I have mixed feelings about this test in general, but isnt't generating only 1s? Not sure this is really representative data, if this is actually meaningful for the test itself..", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478638365", "createdAt": "2020-08-27T19:13:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTQyMQ==", "bodyText": "why score is set to 0?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478639421", "createdAt": "2020-08-27T19:15:23Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());\n+        }\n \n-            @Override\n-            public PredictionInput getInputShape() {\n-                List<Feature> features = new LinkedList<>();\n-                features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n-                return new PredictionInput(features);\n-            }\n+        @Override\n+        public PredictionInput getInputShape() {\n+            List<Feature> features = new LinkedList<>();\n+            features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n+            return new PredictionInput(features);\n+        }\n+\n+        @Override\n+        public PredictionOutput getOutputShape() {\n+            List<Output> outputs = new LinkedList<>();\n+            outputs.add(new Output(\"spam\", Type.BOOLEAN, new Value<>(null), 0d));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw==", "bodyText": "why moving the division inside the sum?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478641797", "createdAt": "2020-08-27T19:19:53Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjYzOA==", "bodyText": "is this used?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478646638", "createdAt": "2020-08-27T19:29:19Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability.rest;\n+\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+\n+public class PredictionProviderMock implements PredictionProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODI4NQ==", "bodyText": "Don't we use vertx?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648285", "createdAt": "2020-08-27T19:32:29Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODgyMA==", "bodyText": "why protected?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648820", "createdAt": "2020-08-27T19:33:30Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+    }\n+\n+    protected static ExplainabilityResultDto createResultDto(Map<String, Saliency> saliencies, String executionId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTYwOQ==", "bodyText": "Can we avoid returning an empty map as result? What about adding a property in the DTO with the success information and eventually the reason why there is no result?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649609", "createdAt": "2020-08-27T19:35:02Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTg4NA==", "bodyText": "move at top?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649884", "createdAt": "2020-08-27T19:35:36Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import org.eclipse.microprofile.config.inject.ConfigProperty;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import java.util.Map;\n+\n+@ApplicationScoped\n+public class LimeExplainerProducer {\n+\n+    private final Integer numberOfSamples;\n+    private final Integer numberOfPerturbations;\n+\n+    @Inject\n+    public LimeExplainerProducer(\n+            @ConfigProperty(name = \"trusty.explainability.numberOfSamples\", defaultValue = \"100\") Integer numberOfSamples,\n+            @ConfigProperty(name = \"trusty.explainability.numberOfPerturbations\", defaultValue = \"1\") Integer numberOfPerturbations) {\n+        this.numberOfSamples = numberOfSamples;\n+        this.numberOfPerturbations = numberOfPerturbations;\n+    }\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(LimeExplainerProducer.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjM1OQ==", "bodyText": "remove wildcard?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478652359", "createdAt": "2020-08-27T19:40:34Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjAyOQ==", "bodyText": "Remove these assignments ;)", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656029", "createdAt": "2020-08-27T19:47:28Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -61,7 +82,7 @@ void givenADecisionWhenStoreDecisionIsCalledThenNoExceptionsAreThrown() {\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void givenADecisionWhenADecisionIsStoredAndRetrievedThenTheOriginalObjectIsReturned() {\n-        String executionId = \"executionId\";\n+        String executionId = TEST_EXECUTION_ID;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjkzMA==", "bodyText": "move to another file?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656930", "createdAt": "2020-08-27T19:49:13Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan;\n+\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.trusty.storage.api.model.ExplainabilityResult;\n+import org.kie.kogito.trusty.storage.api.model.Saliency;\n+\n+public class ExplainabilityResultItemMarshaller extends AbstractModelMarshaller<ExplainabilityResultItem> {\n+\n+    public ExplainabilityResultItemMarshaller(ObjectMapper mapper) {\n+        super(mapper, ExplainabilityResultItem.class);\n+    }\n+\n+    @Override\n+    public ExplainabilityResultItem readFrom(ProtoStreamReader reader) throws IOException {\n+        return new ExplainabilityResultItem(\n+                reader.readString(ExplainabilityResultItem.ID_FIELD),\n+                reader.readObject(ExplainabilityResultItem.SALIENCY_FIELD, Saliency.class)\n+        );\n+    }\n+\n+    @Override\n+    public void writeTo(ProtoStreamWriter writer, ExplainabilityResultItem input) throws IOException {\n+        writer.writeString(ExplainabilityResultItem.ID_FIELD, input.getId());\n+        writer.writeObject(ExplainabilityResultItem.SALIENCY_FIELD, input.getSaliency(), Saliency.class);\n+    }\n+\n+    @Override\n+    public String getTypeName() {\n+        return String.format(\"%s.%s\", ExplainabilityResult.class.getPackageName(), ExplainabilityResultItem.class.getSimpleName());\n+    }\n+}\n+\n+class ExplainabilityResultItem {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1ODU1Mw==", "bodyText": "what's that?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478658553", "createdAt": "2020-08-27T19:52:21Z", "author": {"login": "r00ta"}, "path": "trusty/trusty-storage/trusty-storage-infinispan/src/test/java/org/kie/kogito/trusty/storage/infinispan/testfield/MapToListTestField.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan.testfield;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+\n+public class MapToListTestField<M, K, V, L> extends ListTestField<M, L> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw==", "bodyText": "everything with capital letters?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478659467", "createdAt": "2020-08-27T19:54:12Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjE1Mw==", "bodyText": "@danielezonca\nThrowable throwable = catchThrowable(() -> limeExplainer.explainAsync(prediction, model)\n                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit()));\nassertThat(throwable).isInstanceOf(LocalExplanationException.class)\n\n?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478662153", "createdAt": "2020-08-27T19:59:16Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 55}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98389345bd3c8aa3985e74dd0e65eb36405932cf", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/98389345bd3c8aa3985e74dd0e65eb36405932cf", "committedDate": "2020-08-28T07:06:08Z", "message": "[KOGITO-2914] Update imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8050f6eb00c8902273c656bbda15309fa095ddee", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/8050f6eb00c8902273c656bbda15309fa095ddee", "committedDate": "2020-08-28T08:08:36Z", "message": "[KOGITO-2914] PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/beeaeb4b50343bad73de57f5393da730ef3a4ea7", "committedDate": "2020-08-28T08:08:58Z", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2NjkyNDc2", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-476692476", "createdAt": "2020-08-27T12:57:36Z", "commit": {"oid": "08d0146452e4a4aff7e549468d9dfbb9fef18b7a"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxMzowMDo0NVrOHIPPpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMTo1MjozMlrOHI_dfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQwMDQyMA==", "bodyText": "Please use at least static seed.", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478400420", "createdAt": "2020-08-27T13:00:45Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, "originalCommit": {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE3ODEwMw==", "bodyText": "Can we add some description here?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479178103", "createdAt": "2020-08-28T11:41:54Z", "author": {"login": "jiripetrlik"}, "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -74,4 +81,25 @@ public PredictionOutput getOutputShape() {\n         }\n     }\n \n+    @Test\n+    void testBrokenPredict() {\n+        Config.INSTANCE.setAsyncTimeout(1);\n+        Config.INSTANCE.setAsyncTimeUnit(TimeUnit.MILLISECONDS);\n+\n+        PredictionProvider brokenProvider = inputs -> supplyAsync(\n+                () -> {\n+                    try {\n+                        Thread.sleep(1000);\n+                        return Collections.emptyList();\n+                    } catch (InterruptedException e) {\n+                        throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE5MDM5OQ==", "bodyText": "Is this correct behaviour? Shouldn't we throw an exception instead?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479190399", "createdAt": "2020-08-28T11:52:32Z", "author": {"login": "jiripetrlik"}, "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -205,12 +284,68 @@ void givenAModelWhenAModelIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturne\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void whenAModelIsNotStoredAndRetrievedByIdThenExceptionIsThrown() {\n-        String modelId = \"name:namespace\";\n+        String modelId = TEST_MODEL_ID;\n         Storage storageMock = mock(Storage.class);\n \n         when(storageMock.containsKey(modelId)).thenReturn(false);\n         when(trustyStorageServiceMock.getModelStorage()).thenReturn(storageMock);\n \n-        Assertions.assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledThenNoExceptionsAreThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        Assertions.assertDoesNotThrow(() -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledMoreThanOnceForSameModelThenExceptionIsThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(true);\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    void givenAnExplainabilityResultWhenAnExplainabilityResultIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturned() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = new StorageImplMock<>(String.class);\n+\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result);\n+\n+        Assertions.assertEquals(result, trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultNotStoredWhenRetrievedByIdThenExceptionIsThrown() {\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(false);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    private static JsonNode toJsonNode(String jsonString) {\n+        try {\n+            return MAPPER.reader().readTree(jsonString);\n+        } catch (JsonProcessingException e) {\n+            return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7"}, "originalPosition": 272}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e326e678ee96baab70addbc3355833da8aea0f94", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/e326e678ee96baab70addbc3355833da8aea0f94", "committedDate": "2020-08-28T16:31:44Z", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4d7e110f74131ec144d4eb254999855a8ee13ab", "author": {"user": {"login": "danielezonca", "name": "Daniele Zonca"}}, "url": "https://github.com/kiegroup/kogito-apps/commit/d4d7e110f74131ec144d4eb254999855a8ee13ab", "committedDate": "2020-08-28T17:48:48Z", "message": "[KOGITO-2914] PR comments + test coverage"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4Mzg2ODc1", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-478386875", "createdAt": "2020-08-31T07:38:46Z", "commit": {"oid": "d4d7e110f74131ec144d4eb254999855a8ee13ab"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQwNzozODo0NlrOHJt7-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQwNzozODo0NlrOHJt7-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk1MTg2NQ==", "bodyText": "Understood, but then I have the doubt that now the method is doing something different: in this method  model.predictAsync is used with just one request, predictionOutputs should a list of just 1 element as before right?", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479951865", "createdAt": "2020-08-31T07:38:46Z", "author": {"login": "r00ta"}, "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, "originalCommit": {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4NDU1Mjg4", "url": "https://github.com/kiegroup/kogito-apps/pull/410#pullrequestreview-478455288", "createdAt": "2020-08-31T09:26:21Z", "commit": {"oid": "d4d7e110f74131ec144d4eb254999855a8ee13ab"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4713, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}