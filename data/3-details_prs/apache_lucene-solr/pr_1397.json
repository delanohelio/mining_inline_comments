{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk3Nzk2ODM4", "number": 1397, "title": "LUCENE-9304: Refactor DWPTPool to pool DWPT directly", "bodyText": "This change removes the ThreadState indirection from DWPTPool and pools DWPT directly. The tracking information and locking semantics are mostly moved to DWPT directly and the pool semantics have changed slightly such that DWPT need to be checked-out in the pool once they need to be flushed or aborted. This automatically grows and shrinks the number of DWPT in the system when number of threads grow or shrink.  Access of pooled DWPTs is more straight forward and doesn't require ordinal. Instead consumers can just iterate over the elements in the pool.\nThis allowed for removal of indirections in DWPTFlushControl like BlockedFlush, the removal of DWPTPool setter and getter in IndexWriterConfig and the addition of stronger assertions in DWPT and DW.", "createdAt": "2020-04-02T20:25:43Z", "url": "https://github.com/apache/lucene-solr/pull/1397", "merged": true, "mergeCommit": {"oid": "2602269f3ec856f55a08a0c5a32a1364fd9c25ea"}, "closed": true, "closedAt": "2020-04-11T10:23:47Z", "author": {"login": "s1monw"}, "timelineItems": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcRgC_AgH2gAyMzk3Nzk2ODM4OjdhMzFlZWUzY2U4NjAxNzA4NzY1ZjE1NzU2NzUyNTg3ZWMyNzk3OWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcWixazAH2gAyMzk3Nzk2ODM4OjU4ODhkYjQ2MWRmMDIyMmE5NzE1MmMyZjM5NzMxMzdhNmNhZjgyMzI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "7a31eee3ce8601708765f15756752587ec27979d", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/7a31eee3ce8601708765f15756752587ec27979d", "committedDate": "2020-03-26T18:03:01Z", "message": "first cut"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "154f585d4b12b77554ae1ac4e0654adcc1de4fa7", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/154f585d4b12b77554ae1ac4e0654adcc1de4fa7", "committedDate": "2020-03-26T19:24:06Z", "message": "roll back to LIFO picking of DWPT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3238801920166f1b71b6ef69173261c99db2b67b", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/3238801920166f1b71b6ef69173261c99db2b67b", "committedDate": "2020-04-01T21:59:59Z", "message": "second step"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66e4bac3b080fdd520bd695381306d5152427ff3", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/66e4bac3b080fdd520bd695381306d5152427ff3", "committedDate": "2020-04-02T10:42:13Z", "message": "more cleanups"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da33df7efee1c59754f5e785f0d9210979f8db25", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/da33df7efee1c59754f5e785f0d9210979f8db25", "committedDate": "2020-04-02T14:57:44Z", "message": "cleanups"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3caaee6dda0baca38961034602e8f6b90351b57b", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/3caaee6dda0baca38961034602e8f6b90351b57b", "committedDate": "2020-04-02T18:30:22Z", "message": "Merge branch 'master' into pick_smallest_dwpt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/bd82f3193542de94f4c49726c3054c1fbe97e6c3", "committedDate": "2020-04-02T20:11:03Z", "message": "minor changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg2NzY2ODcw", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-386766870", "createdAt": "2020-04-02T20:26:26Z", "commit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQyMDoyNjoyN1rOF_8E3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQyMDoyNjoyN1rOF_8E3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU4ODg5Mw==", "bodyText": "@mikemccand can you take a look at this please", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r402588893", "createdAt": "2020-04-02T20:26:27Z", "author": {"login": "s1monw"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -322,35 +316,27 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortThreadState(final ThreadState perThread) throws IOException {\n+  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n-    if (perThread.isInitialized()) { \n-      try {\n-        int abortedDocCount = perThread.dwpt.getNumDocsInRAM();\n-        subtractFlushedNumDocs(abortedDocCount);\n-        perThread.dwpt.abort();\n-        return abortedDocCount;\n-      } finally {\n-        flushControl.doOnAbort(perThread);\n-      }\n-    } else {\n+    try {\n+      int abortedDocCount = perThread.getNumDocsInRAM();\n+      subtractFlushedNumDocs(abortedDocCount);\n+      perThread.abort();\n+      return abortedDocCount;\n+    } finally {\n       flushControl.doOnAbort(perThread);\n-      // This DWPT was never initialized so it has no indexed documents:\n-      return 0;\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n   public long getMaxCompletedSequenceNumber() {\n-    long value = lastSeqNo;\n-    int limit = perThreadPool.getMaxThreadStates();\n-    for(int i = 0; i < limit; i++) {\n-      ThreadState perThread = perThreadPool.getThreadState(i);\n-      value = Math.max(value, perThread.lastSeqNo);\n-    }\n-    return value;\n+    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 230}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3ODE4NjEy", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-387818612", "createdAt": "2020-04-05T13:24:08Z", "commit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxMzoyNDowOFrOGA_-6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQxMzo1MTo1OVrOGBAMDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTQ4Mw==", "bodyText": "s/event/even?", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701483", "createdAt": "2020-04-05T13:24:08Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -59,21 +58,25 @@\n  * Threads:\n  *\n  * Multiple threads are allowed into addDocument at once.\n- * There is an initial synchronized call to getThreadState\n- * which allocates a ThreadState for this thread.  The same\n- * thread will get the same ThreadState over time (thread\n- * affinity) so that if there are consistent patterns (for\n- * example each thread is indexing a different content\n- * source) then we make better use of RAM.  Then\n- * processDocument is called on that ThreadState without\n+ * There is an initial synchronized call to\n+ * {@link DocumentsWriterFlushControl#obtainAndLock()}\n+ * which allocates a DWPT for this indexing thread. The same\n+ * thread will not necessarily get the same DWPT over time.\n+ * Then updateDocuments is called on that DWPT without\n  * synchronization (most of the \"heavy lifting\" is in this\n- * call).  Finally the synchronized \"finishDocument\" is\n- * called to flush changes to the directory.\n+ * call). Once a DWPT fills up enough RAM or hold enough\n+ * documents in memory the DWPT is checked out for flush\n+ * and all changes are written to the directory. Each DWPT\n+ * corresponds to one segment being written.\n  *\n- * When flush is called by IndexWriter we forcefully idle\n- * all threads and flush only once they are all idle.  This\n- * means you can call flush with a given thread even while\n- * other threads are actively adding/deleting documents.\n+ * When flush is called by IndexWriter we check out all DWPTs\n+ * that are associated with the current {@link DocumentsWriterDeleteQueue}\n+ * out of the {@link DocumentsWriterPerThreadPool} and write\n+ * them to disk. The flush process can piggy-back on incoming\n+ * indexing threads or event block them from adding documents", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTY5OQ==", "bodyText": "Isn't writer still an empty list here?  Oh I see, we are creating a lambda and only using it below, after we've added things to writer, OK.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701699", "createdAt": "2020-04-05T13:26:04Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -273,33 +269,31 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n         pendingNumDocs.addAndGet(-ticket.getFlushedSegment().segmentInfo.info.maxDoc());\n       }\n     });\n-    List<ThreadState> threadStates = new ArrayList<>();\n+    List<DocumentsWriterPerThread> writer = new ArrayList<>();\n     AtomicBoolean released = new AtomicBoolean(false);\n     final Closeable release = () -> {\n       if (released.compareAndSet(false, true)) { // only once\n         if (infoStream.isEnabled(\"DW\")) {\n           infoStream.message(\"DW\", \"unlockAllAbortedThread\");\n         }\n-        perThreadPool.unlockNewThreadStates();\n-        for (ThreadState state : threadStates) {\n+        perThreadPool.unlockNewWriters();\n+        for (DocumentsWriterPerThread state : writer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTk1NA==", "bodyText": "I left a (non-review) comment on the single commit about this.\nI think it's a good tradeoff?  Instead of making each indexing op compute max to save lastSeqNo, we are making caller of this API do the legwork.  I think it's a fair tradeoff since likely this API is very rarely called, but indexing ops are very often called.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701954", "createdAt": "2020-04-05T13:28:36Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -322,35 +316,27 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortThreadState(final ThreadState perThread) throws IOException {\n+  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n-    if (perThread.isInitialized()) { \n-      try {\n-        int abortedDocCount = perThread.dwpt.getNumDocsInRAM();\n-        subtractFlushedNumDocs(abortedDocCount);\n-        perThread.dwpt.abort();\n-        return abortedDocCount;\n-      } finally {\n-        flushControl.doOnAbort(perThread);\n-      }\n-    } else {\n+    try {\n+      int abortedDocCount = perThread.getNumDocsInRAM();\n+      subtractFlushedNumDocs(abortedDocCount);\n+      perThread.abort();\n+      return abortedDocCount;\n+    } finally {\n       flushControl.doOnAbort(perThread);\n-      // This DWPT was never initialized so it has no indexed documents:\n-      return 0;\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n   public long getMaxCompletedSequenceNumber() {\n-    long value = lastSeqNo;\n-    int limit = perThreadPool.getMaxThreadStates();\n-    for(int i = 0; i < limit; i++) {\n-      ThreadState perThread = perThreadPool.getThreadState(i);\n-      value = Math.max(value, perThread.lastSeqNo);\n-    }\n-    return value;\n+    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/\n+    // Returning the last seqNum is as good as the way we had before IMO. I tried to figure out why this is better but\n+    // failed.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjY5Mw==", "bodyText": "Is it intentional that we are unlocking next even after returning it from checkOutForFlush(next)?  Shouldn't it remain locked until flush finishes?", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702693", "createdAt": "2020-04-05T13:34:18Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -380,52 +368,35 @@ DocumentsWriterPerThread nextPendingFlush() {\n       fullFlush = this.fullFlush;\n       numPending = this.numPending;\n     }\n-    if (numPending > 0 && !fullFlush) { // don't check if we are doing a full flush\n-      final int limit = perThreadPool.getActiveThreadStateCount();\n-      for (int i = 0; i < limit && numPending > 0; i++) {\n-        final ThreadState next = perThreadPool.getThreadState(i);\n-        if (next.flushPending) {\n-          final DocumentsWriterPerThread dwpt = tryCheckoutForFlush(next);\n-          if (dwpt != null) {\n-            return dwpt;\n+    if (numPending > 0 && fullFlush == false) { // don't check if we are doing a full flush\n+      for (final DocumentsWriterPerThread next : perThreadPool) {\n+        if (next.isFlushPending()) {\n+          if (next.tryLock()) {\n+            try {\n+              if (perThreadPool.isRegistered(next)) {\n+                return checkOutForFlush(next);\n+              }\n+            } finally {\n+              next.unlock();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjg0Ng==", "bodyText": "Woohoo!", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702846", "createdAt": "2020-04-05T13:35:40Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -543,59 +506,53 @@ long markForFullFlush() {\n   }\n   \n   private boolean assertActiveDeleteQueue(DocumentsWriterDeleteQueue queue) {\n-    final int limit = perThreadPool.getActiveThreadStateCount();\n-    for (int i = 0; i < limit; i++) {\n-      final ThreadState next = perThreadPool.getThreadState(i);\n-      next.lock();\n-      try {\n-        assert !next.isInitialized() || next.dwpt.deleteQueue == queue : \"isInitialized: \" + next.isInitialized() + \" numDocs: \" + (next.isInitialized() ? next.dwpt.getNumDocsInRAM() : 0) ;\n-      } finally {\n-        next.unlock();\n-      }\n+    for (final DocumentsWriterPerThread next : perThreadPool) {\n+        assert next.deleteQueue == queue : \"numDocs: \" + next.getNumDocsInRAM();\n     }\n     return true;\n   }\n \n   private final List<DocumentsWriterPerThread> fullFlushBuffer = new ArrayList<>();\n \n-  void addFlushableState(ThreadState perThread) {\n+  void addFlushableDWPT(DocumentsWriterPerThread dwpt) {\n     if (infoStream.isEnabled(\"DWFC\")) {\n-      infoStream.message(\"DWFC\", \"addFlushableState \" + perThread.dwpt);\n+      infoStream.message(\"DWFC\", \"addFlushableDWPT \" + dwpt);\n     }\n-    final DocumentsWriterPerThread dwpt = perThread.dwpt;\n-    assert perThread.isHeldByCurrentThread();\n-    assert perThread.isInitialized();\n+    assert dwpt.isHeldByCurrentThread();\n     assert fullFlush;\n     assert dwpt.deleteQueue != documentsWriter.deleteQueue;\n+    assert perThreadPool.isRegistered(dwpt);\n     if (dwpt.getNumDocsInRAM() > 0) {\n       synchronized(this) {\n-        if (!perThread.flushPending) {\n-          setFlushPending(perThread);\n+        if (dwpt.isFlushPending() == false) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 484}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjk4Ng==", "bodyText": "Hmm why would we ever have nextRam > 0 but next.getNumDocsInRAM() == ?", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702986", "createdAt": "2020-04-05T13:37:06Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -717,51 +664,49 @@ public InfoStream getInfoStream() {\n     return infoStream;\n   }\n \n-  synchronized ThreadState findLargestNonPendingWriter() {\n-    ThreadState maxRamUsingThreadState = null;\n+  synchronized DocumentsWriterPerThread findLargestNonPendingWriter() {\n+    DocumentsWriterPerThread maxRamUsingWriter = null;\n     long maxRamSoFar = 0;\n-    Iterator<ThreadState> activePerThreadsIterator = allActiveThreadStates();\n+    Iterator<DocumentsWriterPerThread> activePerThreadsIterator = perThreadPool.iterator();\n     int count = 0;\n     while (activePerThreadsIterator.hasNext()) {\n-      ThreadState next = activePerThreadsIterator.next();\n-      if (!next.flushPending) {\n-        final long nextRam = next.bytesUsed;\n-        if (nextRam > 0 && next.dwpt.getNumDocsInRAM() > 0) {\n+      DocumentsWriterPerThread next = activePerThreadsIterator.next();\n+      if (!next.isFlushPending()) {\n+        final long nextRam = next.bytesUsed();\n+        if (nextRam > 0 && next.getNumDocsInRAM() > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 594}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzY4OA==", "bodyText": "s/DWPTs/DPWT's", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703688", "createdAt": "2020-04-05T13:42:43Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzcxOA==", "bodyText": "s/DWPTs/DWPT's", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703718", "createdAt": "2020-04-05T13:42:57Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * of invocation.\n+   * @return true if the lock was acquired.\n+   * @see ReentrantLock#tryLock()\n+   */\n+  boolean tryLock() {\n+    return lock.tryLock();\n+  }\n+\n+  /**\n+   * Returns true if the DWPTs lock is held by the current thread", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzczMA==", "bodyText": "Here too.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703730", "createdAt": "2020-04-05T13:43:06Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * of invocation.\n+   * @return true if the lock was acquired.\n+   * @see ReentrantLock#tryLock()\n+   */\n+  boolean tryLock() {\n+    return lock.tryLock();\n+  }\n+\n+  /**\n+   * Returns true if the DWPTs lock is held by the current thread\n+   * @see ReentrantLock#isHeldByCurrentThread()\n+   */\n+  boolean isHeldByCurrentThread() {\n+    return lock.isHeldByCurrentThread();\n+  }\n+\n+  /**\n+   * Unlocks the DWPTs lock", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzg3MQ==", "bodyText": "Woo hoo!  I always thought it was kinda spooky that we were subclassing ReentrantLock instead of \"hasa\" that this change is switching to!", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703871", "createdAt": "2020-04-05T13:44:02Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNDY1NQ==", "bodyText": "= 0 isn't needed -- it's Java's default already.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403704655", "createdAt": "2020-04-05T13:50:29Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -156,6 +158,9 @@ void abort() throws IOException{\n   final BufferedUpdates pendingUpdates;\n   final SegmentInfo segmentInfo;     // Current segment we are working on\n   private boolean aborted = false;   // True if we aborted\n+  private SetOnce<Boolean> flushPending = new SetOnce<>();\n+  private volatile long lastCommittedBytesUsed = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNDg0Ng==", "bodyText": "s/sine/since", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403704846", "createdAt": "2020-04-05T13:51:59Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -458,74 +429,66 @@ public void setApplyAllDeletes() {\n     flushDeletes.set(true);\n   }\n   \n-  ThreadState obtainAndLock() {\n-    final ThreadState perThread = perThreadPool.getAndLock();\n-    boolean success = false;\n-    try {\n-      if (perThread.isInitialized() && perThread.dwpt.deleteQueue != documentsWriter.deleteQueue) {\n-        // There is a flush-all in process and this DWPT is\n-        // now stale -- enroll it for flush and try for\n-        // another DWPT:\n-        addFlushableState(perThread);\n-      }\n-      success = true;\n-      // simply return the ThreadState even in a flush all case sine we already hold the lock\n-      return perThread;\n-    } finally {\n-      if (!success) { // make sure we unlock if this fails\n-        perThreadPool.release(perThread);\n+  DocumentsWriterPerThread obtainAndLock() throws IOException {\n+    do {\n+      final DocumentsWriterPerThread perThread = perThreadPool.getAndLock();\n+      boolean unlock = true;\n+      try {\n+        if (perThread.deleteQueue != documentsWriter.deleteQueue) {\n+          // There is a flush-all in process and this DWPT is\n+          // now stale -- enroll it for flush and try for\n+          // another DWPT:\n+          addFlushableDWPT(perThread);\n+        } else {\n+          unlock = false;\n+          // simply return the DWPT even in a flush all case sine we already hold the lock", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 366}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg3ODU2NzEw", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-387856710", "createdAt": "2020-04-05T20:16:35Z", "commit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNVQyMDoxNjozNVrOGBDCaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwMzo0MToxMlrOGBG3NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzc1MTUyOQ==", "bodyText": "unrelated change?", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403751529", "createdAt": "2020-04-05T20:16:35Z", "author": {"login": "dnhatn"}, "path": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java", "diffHunk": "@@ -3774,6 +3768,9 @@ public void testRefreshAndRollbackConcurrently() throws Exception {\n       stopped.set(true);\n       indexer.join();\n       refresher.join();\n+      if (w.getTragicException() != null) {\n+        w.getTragicException().printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzgxMjE5OQ==", "bodyText": "state -> dwpt or perThread?", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403812199", "createdAt": "2020-04-06T03:31:10Z", "author": {"login": "dnhatn"}, "path": "lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java", "diffHunk": "@@ -52,38 +50,38 @@\n \n   /**\n    * Called for each delete term. If this is a delete triggered due to an update\n-   * the given {@link ThreadState} is non-null.\n+   * the given {@link DocumentsWriterPerThread} is non-null.\n    * <p>\n    * Note: This method is called synchronized on the given\n    * {@link DocumentsWriterFlushControl} and it is guaranteed that the calling\n-   * thread holds the lock on the given {@link ThreadState}\n+   * thread holds the lock on the given {@link DocumentsWriterPerThread}\n    */\n   public abstract void onDelete(DocumentsWriterFlushControl control,\n-      ThreadState state);\n+                                DocumentsWriterPerThread state);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzgxNDE5Ng==", "bodyText": "It might be less confusing if we reassign the release inside the try clause after acquiring DWPTs. Also nits: writer -> writers and state -> writer.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403814196", "createdAt": "2020-04-06T03:41:12Z", "author": {"login": "dnhatn"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -273,33 +269,31 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n         pendingNumDocs.addAndGet(-ticket.getFlushedSegment().segmentInfo.info.maxDoc());\n       }\n     });\n-    List<ThreadState> threadStates = new ArrayList<>();\n+    List<DocumentsWriterPerThread> writer = new ArrayList<>();\n     AtomicBoolean released = new AtomicBoolean(false);\n     final Closeable release = () -> {\n       if (released.compareAndSet(false, true)) { // only once\n         if (infoStream.isEnabled(\"DW\")) {\n           infoStream.message(\"DW\", \"unlockAllAbortedThread\");\n         }\n-        perThreadPool.unlockNewThreadStates();\n-        for (ThreadState state : threadStates) {\n+        perThreadPool.unlockNewWriters();\n+        for (DocumentsWriterPerThread state : writer) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTY5OQ=="}, "originalCommit": {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3"}, "originalPosition": 164}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "committedDate": "2020-04-06T12:58:01Z", "message": "address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06e746931bad2e0a17c4291786d264813116d643", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/06e746931bad2e0a17c4291786d264813116d643", "committedDate": "2020-04-06T13:06:44Z", "message": "remove nocommit"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4MjQ0OTk4", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-388244998", "createdAt": "2020-04-06T13:25:25Z", "commit": {"oid": "06e746931bad2e0a17c4291786d264813116d643"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b64ceabded6e9cab2bde69b4de196eff482c6ed", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/3b64ceabded6e9cab2bde69b4de196eff482c6ed", "committedDate": "2020-04-06T19:08:57Z", "message": "Merge branch 'master' into pick_smallest_dwpt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "committedDate": "2020-04-06T20:05:55Z", "message": "more cleanups and documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41acaa33990faaea6a52d1f0cec08c8cf2fbad03", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/41acaa33990faaea6a52d1f0cec08c8cf2fbad03", "committedDate": "2020-04-06T21:42:44Z", "message": "simplify obtainAndLock logic"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4Nzc5MDU3", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-388779057", "createdAt": "2020-04-07T04:42:08Z", "commit": {"oid": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNDo0MjoxMFrOGBynwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNDo0MjoxMFrOGBynwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDUzMTEzOA==", "bodyText": "nit: teh -> the", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404531138", "createdAt": "2020-04-07T04:42:10Z", "author": {"login": "dnhatn"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -52,12 +52,19 @@\n   private int numDocsSinceStalled = 0; // only with assert\n   final AtomicBoolean flushDeletes = new AtomicBoolean(false);\n   private boolean fullFlush = false;\n+  private boolean fullFlushMarkDone = false; // only for assertion that we don't get stale DWPTs from the pool\n+  // The flushQueue is used to concurrently distribute DWPTs that are ready to be flushed ie. when a full flush is in\n+  // progress. This might be triggered by a commit or NRT refresh. The trigger will only walk all eligible DWPTs and\n+  // mark them as flushable putting them in the flushQueue ready for other threads (ie. indexing threads) to help flushing\n   private final Queue<DocumentsWriterPerThread> flushQueue = new LinkedList<>();\n   // only for safety reasons if a DWPT is close to the RAM limit\n   private final Queue<DocumentsWriterPerThread> blockedFlushes = new LinkedList<>();\n+  // flushingWriters holds all currently flushing writers. There might be writers in this list that\n+  // are also in the flushQueue which means that writers in teh flushingWriters list are not necessarily", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bead669ed83297edbe342181db294df76bd04b7", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/0bead669ed83297edbe342181db294df76bd04b7", "committedDate": "2020-04-07T06:56:27Z", "message": "fix typo"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4ODcyMjcw", "url": "https://github.com/apache/lucene-solr/pull/1397#pullrequestreview-388872270", "createdAt": "2020-04-07T07:57:45Z", "commit": {"oid": "0bead669ed83297edbe342181db294df76bd04b7"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNzo1Nzo0NVrOGB3e1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QwNzo1ODoyMVrOGB3gUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMDc3Mw==", "bodyText": "Just an idea: Maybe use Deque<DocumentsWriterPerThread> freeList = new ArrayDeque<>(); here, as it allows to iterate in both directions (it has descendingIterator()). To me this also looks better, because the whole thing is mostly used as a deque (LIFO).", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404610773", "createdAt": "2020-04-07T07:57:45Z", "author": {"login": "uschindler"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {\n-    DocumentsWriterPerThread dwpt;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    volatile boolean flushPending = false;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    long bytesUsed = 0;\n-\n-    // set by DocumentsWriter after each indexing op finishes\n-    volatile long lastSeqNo;\n-\n-    ThreadState(DocumentsWriterPerThread dpwt) {\n-      this.dwpt = dpwt;\n-    }\n-    \n-    private void reset() {\n-      assert this.isHeldByCurrentThread();\n-      this.dwpt = null;\n-      this.bytesUsed = 0;\n-      this.flushPending = false;\n-    }\n-    \n-    boolean isInitialized() {\n-      assert this.isHeldByCurrentThread();\n-      return dwpt != null;\n-    }\n-    \n-    /**\n-     * Returns the number of currently active bytes in this ThreadState's\n-     * {@link DocumentsWriterPerThread}\n-     */\n-    public long getBytesUsedPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return bytesUsed;\n-    }\n-    \n-    /**\n-     * Returns this {@link ThreadState}s {@link DocumentsWriterPerThread}\n-     */\n-    public DocumentsWriterPerThread getDocumentsWriterPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return dwpt;\n-    }\n-    \n-    /**\n-     * Returns <code>true</code> iff this {@link ThreadState} is marked as flush\n-     * pending otherwise <code>false</code>\n-     */\n-    public boolean isFlushPending() {\n-      return flushPending;\n-    }\n-  }\n+final class DocumentsWriterPerThreadPool implements Iterable<DocumentsWriterPerThread>, Closeable {\n \n-  private final List<ThreadState> threadStates = new ArrayList<>();\n+  private final Set<DocumentsWriterPerThread> dwpts = Collections.newSetFromMap(new IdentityHashMap<>());\n+  private final List<DocumentsWriterPerThread> freeList = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bead669ed83297edbe342181db294df76bd04b7"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMTE1Mw==", "bodyText": "Here you could use the descendingIterator() and iterate while just calling remove() on the iterator.", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404611153", "createdAt": "2020-04-07T07:58:21Z", "author": {"login": "uschindler"}, "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {\n-    DocumentsWriterPerThread dwpt;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    volatile boolean flushPending = false;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    long bytesUsed = 0;\n-\n-    // set by DocumentsWriter after each indexing op finishes\n-    volatile long lastSeqNo;\n-\n-    ThreadState(DocumentsWriterPerThread dpwt) {\n-      this.dwpt = dpwt;\n-    }\n-    \n-    private void reset() {\n-      assert this.isHeldByCurrentThread();\n-      this.dwpt = null;\n-      this.bytesUsed = 0;\n-      this.flushPending = false;\n-    }\n-    \n-    boolean isInitialized() {\n-      assert this.isHeldByCurrentThread();\n-      return dwpt != null;\n-    }\n-    \n-    /**\n-     * Returns the number of currently active bytes in this ThreadState's\n-     * {@link DocumentsWriterPerThread}\n-     */\n-    public long getBytesUsedPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return bytesUsed;\n-    }\n-    \n-    /**\n-     * Returns this {@link ThreadState}s {@link DocumentsWriterPerThread}\n-     */\n-    public DocumentsWriterPerThread getDocumentsWriterPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return dwpt;\n-    }\n-    \n-    /**\n-     * Returns <code>true</code> iff this {@link ThreadState} is marked as flush\n-     * pending otherwise <code>false</code>\n-     */\n-    public boolean isFlushPending() {\n-      return flushPending;\n-    }\n-  }\n+final class DocumentsWriterPerThreadPool implements Iterable<DocumentsWriterPerThread>, Closeable {\n \n-  private final List<ThreadState> threadStates = new ArrayList<>();\n+  private final Set<DocumentsWriterPerThread> dwpts = Collections.newSetFromMap(new IdentityHashMap<>());\n+  private final List<DocumentsWriterPerThread> freeList = new ArrayList<>();\n+  private final IOSupplier<DocumentsWriterPerThread> dwptFactory;\n+  private int takenWriterPermits = 0;\n+  private boolean closed;\n \n-  private final List<ThreadState> freeList = new ArrayList<>();\n \n-  private int takenThreadStatePermits = 0;\n+  DocumentsWriterPerThreadPool(IOSupplier<DocumentsWriterPerThread> dwptFactory) {\n+    this.dwptFactory = dwptFactory;\n+  }\n \n   /**\n-   * Returns the active number of {@link ThreadState} instances.\n+   * Returns the active number of {@link DocumentsWriterPerThread} instances.\n    */\n-  synchronized int getActiveThreadStateCount() {\n-    return threadStates.size();\n+  synchronized int size() {\n+    return dwpts.size();\n   }\n \n-  synchronized void lockNewThreadStates() {\n-    // this is similar to a semaphore - we need to acquire all permits ie. takenThreadStatePermits must be == 0\n-    // any call to lockNewThreadStates() must be followed by unlockNewThreadStates() otherwise we will deadlock at some\n+  synchronized void lockNewWriters() {\n+    // this is similar to a semaphore - we need to acquire all permits ie. takenWriterPermits must be == 0\n+    // any call to lockNewWriters() must be followed by unlockNewWriters() otherwise we will deadlock at some\n     // point\n-    assert takenThreadStatePermits >= 0;\n-    takenThreadStatePermits++;\n+    assert takenWriterPermits >= 0;\n+    takenWriterPermits++;\n   }\n \n-  synchronized void unlockNewThreadStates() {\n-    assert takenThreadStatePermits > 0;\n-    takenThreadStatePermits--;\n-    if (takenThreadStatePermits == 0) {\n+  synchronized void unlockNewWriters() {\n+    assert takenWriterPermits > 0;\n+    takenWriterPermits--;\n+    if (takenWriterPermits == 0) {\n       notifyAll();\n     }\n   }\n+\n   /**\n-   * Returns a new {@link ThreadState} iff any new state is available otherwise\n-   * <code>null</code>.\n-   * <p>\n-   * NOTE: the returned {@link ThreadState} is already locked iff non-\n-   * <code>null</code>.\n-   * \n-   * @return a new {@link ThreadState} iff any new state is available otherwise\n-   *         <code>null</code>\n+   * Returns a new already locked {@link DocumentsWriterPerThread}\n+   *\n+   * @return a new {@link DocumentsWriterPerThread}\n    */\n-  private synchronized ThreadState newThreadState() {\n-    assert takenThreadStatePermits >= 0;\n-    while (takenThreadStatePermits > 0) {\n-      // we can't create new thread-states while not all permits are available\n+  private synchronized DocumentsWriterPerThread newWriter() throws IOException {\n+    assert takenWriterPermits >= 0;\n+    while (takenWriterPermits > 0) {\n+      // we can't create new DWPTs while not all permits are available\n       try {\n         wait();\n       } catch (InterruptedException ie) {\n         throw new ThreadInterruptedException(ie);\n       }\n     }\n-    ThreadState threadState = new ThreadState(null);\n-    threadState.lock(); // lock so nobody else will get this ThreadState\n-    threadStates.add(threadState);\n-    return threadState;\n-}\n-\n-  DocumentsWriterPerThread reset(ThreadState threadState) {\n-    assert threadState.isHeldByCurrentThread();\n-    final DocumentsWriterPerThread dwpt = threadState.dwpt;\n-    threadState.reset();\n+    DocumentsWriterPerThread dwpt = dwptFactory.get();\n+    dwpt.lock(); // lock so nobody else will get this DWPT\n+    dwpts.add(dwpt);\n     return dwpt;\n   }\n-  \n-  void recycle(DocumentsWriterPerThread dwpt) {\n-    // don't recycle DWPT by default\n-  }\n \n   // TODO: maybe we should try to do load leveling here: we want roughly even numbers\n   // of items (docs, deletes, DV updates) to most take advantage of concurrency while flushing\n \n-  /** This method is used by DocumentsWriter/FlushControl to obtain a ThreadState to do an indexing operation (add/updateDocument). */\n-  ThreadState getAndLock() {\n-    ThreadState threadState = null;\n+  /** This method is used by DocumentsWriter/FlushControl to obtain a DWPT to do an indexing operation (add/updateDocument). */\n+  DocumentsWriterPerThread getAndLock() throws IOException {\n     synchronized (this) {\n-      if (freeList.isEmpty()) {\n-        // ThreadState is already locked before return by this method:\n-        return newThreadState();\n-      } else {\n-        // Important that we are LIFO here! This way if number of concurrent indexing threads was once high, but has now reduced, we only use a\n-        // limited number of thread states:\n-        threadState = freeList.remove(freeList.size()-1);\n-\n-        if (threadState.dwpt == null) {\n-          // This thread-state is not initialized, e.g. it\n-          // was just flushed. See if we can instead find\n-          // another free thread state that already has docs\n-          // indexed. This way if incoming thread concurrency\n-          // has decreased, we don't leave docs\n-          // indefinitely buffered, tying up RAM.  This\n-          // will instead get those thread states flushed,\n-          // freeing up RAM for larger segment flushes:\n-          for(int i=0;i<freeList.size();i++) {\n-            ThreadState ts = freeList.get(i);\n-            if (ts.dwpt != null) {\n-              // Use this one instead, and swap it with\n-              // the un-initialized one:\n-              freeList.set(i, threadState);\n-              threadState = ts;\n-              break;\n-            }\n-          }\n+      if (closed) {\n+        throw new AlreadyClosedException(\"DWPTPool is already closed\");\n+      }\n+      // Important that we are LIFO here! This way if number of concurrent indexing threads was once high,\n+      // but has now reduced, we only use a limited number of DWPTs. This also guarantees that if we have suddenly\n+      // a single thread indexing\n+      for (int i = freeList.size()-1; i >= 0; i--) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bead669ed83297edbe342181db294df76bd04b7"}, "originalPosition": 251}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81bd46e212359bcacd99fdcef09ffd9140776a00", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/81bd46e212359bcacd99fdcef09ffd9140776a00", "committedDate": "2020-04-07T08:36:08Z", "message": "apply feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6621f103bab3f89fe8b0e847a4dbe3f8cc995bc1", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/6621f103bab3f89fe8b0e847a4dbe3f8cc995bc1", "committedDate": "2020-04-07T08:40:49Z", "message": "fix removal and assertion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "163a839ca134326ae268735b3549fab7c1bcf417", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/163a839ca134326ae268735b3549fab7c1bcf417", "committedDate": "2020-04-08T07:50:12Z", "message": "fix remaining review comments to be more clear"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03be7ab0ef2e129a3bb5eeff82c866ca27eba4ae", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/03be7ab0ef2e129a3bb5eeff82c866ca27eba4ae", "committedDate": "2020-04-08T19:21:54Z", "message": "Merge branch 'master' into pick_smallest_dwpt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07d2883d0e1f12e4c36c480473965e15f27c6730", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/07d2883d0e1f12e4c36c480473965e15f27c6730", "committedDate": "2020-04-10T11:25:49Z", "message": "Merge branch 'master' into pick_smallest_dwpt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26aaf40e6e3ada05eacbcd4acc834a2a73a1ed1d", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/26aaf40e6e3ada05eacbcd4acc834a2a73a1ed1d", "committedDate": "2020-04-11T09:59:35Z", "message": "Merge branch 'master' into pick_smallest_dwpt"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5888db461df0222a97152c2f3973137a6caf8232", "author": {"user": {"login": "s1monw", "name": "Simon Willnauer"}}, "url": "https://github.com/apache/lucene-solr/commit/5888db461df0222a97152c2f3973137a6caf8232", "committedDate": "2020-04-11T10:03:10Z", "message": "add changes"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2078, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}