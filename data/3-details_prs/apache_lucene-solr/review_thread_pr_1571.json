{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzMjY4NjY3", "number": 1571, "reviewThreads": {"totalCount": 36, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNzoxMjo1NVrOETWSHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyMToyOVrOE4ZbYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzIzNDg0OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNzoxMjo1NVrOG5CIIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxODozNjozMVrOHtk2wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA==", "bodyText": "The model name originalRanking is being given a special meaning here. I wonder if perhaps the differences between models could be transferred to the parameter names somehow (e.g. a new original_model parameter name alongside the existing model parameter name)? Then users could choose any model name they like, including for \"original ranking\" purposes.\n#1705 proposes to factor out a LTRQParserPlugin.newLTRScoringQuery method (but I haven't yet explored fully w.r.t. how that might connect up here w.r.t. additional parameter names).\nWhat do you think?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r462456864", "createdAt": "2020-07-29T17:12:55Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjIyNTI0Ng==", "bodyText": "Hi @cpoerschke , I think you are right, it is probably better to have a separate param to activate the interleaving with the original ranking.\nI have just made the change and updated the tests.\nThey are green locally, I'll just wait for them to be green remotely as well", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r496225246", "createdAt": "2020-09-28T20:52:32Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI0NDE5MQ==", "bodyText": "Thinking a little bit more about it, even if we solve the \"originalRanking\" request through a special param, when returning the results, the [interleaving] transformer will need to present for the search results coming from the original ranking a value :\n{\n\"id\":\"GB18030TEST\",\n\"score\":1.0005897,\n\"[interleaving]\":\"OriginalRanking\"},\n{\n\"id\":\"UTF8TEST\",\n\"score\":0.79656565,\n\"[interleaving]\":\"myModel\"}]\n}\nThis must follow the same format ( I wouldn't add a special field name different from [interleaing], this would complicate evaluators behaviours.\nThis means that in the end I guess we need to keep a special name to indicate the original ranking, and this name can't be used by the admin for any other model.\nGiven that, do you think is still beneficial to have a separate parameter?\nOr just using the original approach, with the documented exclusivity of a special name, would look cleaner?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r496244191", "createdAt": "2020-09-28T21:31:07Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk0ODAxOA==", "bodyText": "Ah, good point about the special \"OriginalRanking\" also appearing in the \"[interleaving]\" transformer!\nWhen using interleaving there's always at least two models to be interleaved, right?\nThe models could all be actual models or one of them could be the \"OriginalRanking\" pseudo-model.\nI wonder if class inheritance might help us e.g.\nclass InterleavingLTRQParserPlugin extends LTRQParserPlugin\n\nand (say)\n<queryParser name=\"ltr\" class=\"org.apache.solr.ltr.search.LTRQParserPlugin\"/>\n<queryParser name=\"iltr\" class=\"org.apache.solr.ltr.search.InterleavingLTRQParserPlugin\"/>\n\nwhere\nrq={!iltr model=myModelXYZ}\n\ncan be a convenience equivalent to\nrq={!iltr model=OriginalRanking model=myModelXYZ}\n\ni.e. if only one model is supplied then it is implied that the second model is the original ranking.\nAnd if the special \"OriginalRanking\" name doesn't suit someone (either because they already have a real model that happens to be called \"OriginalRanking\" or because they would prefer a different descriptor in the \"[interleaving]\" transformer output) then something like\nrq={!iltr originalRankingModel=noModel model=noModel model=someModel}\n\nwould allow them to call the \"OriginalRanking\" something else e.g. \"noModel\" instead.\nWe could even reject any \"OriginalRanking\" models that are actual models via something like\nfinal String originalRankingModelName = localParams.get(\"originalRankingModel\", \"OriginalRanking\" /* default */);\nif (null != mr.getModel(originalRankingModelName)) {\n  throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n                          \"Found an actual '\" + originalRankingModelName + \"' model, please ...\n}\n\n\nHowever, the \"[interleaving]\" transformer still needs to know about the special name, hmm.\nAt the moment we have\npublic static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n  return rerankingQuery.getScoringModel() == null;\n}\n\nin LTRQParserPlugin and in LTRInterleavingTransformerFactory\nif (isOriginalRanking(rerankingQuery)) {\n  doc.addField(name, ORIGINAL_RANKING);\n} else {\n  doc.addField(name, rerankingQuery.getScoringModel().getName());\n}\n\nand if we gave LTRScoringQuery a getScoringModelName method\npublic String getScoringModelName() {\n  return ltrScoringModel.getName();\n}\n\nthen in LTRInterleavingTransformerFactory we could have\ndoc.addField(name, rerankingQuery.getScoringModelName());\n\nif the\nnew LTRScoringQuery(null);\n\nin LTRQParserPlugin becomes\nnew LTRScoringQuery(null) {\n  @Override\n  public String getScoringModelName() {\n    return originalRankingModelName;\n  }\n};\n\nbut that wouldn't displace any other isOriginalRanking(rerankingQuery) calls, though if we had something like\nfinal class OriginalRankingLTRScoringQuery extends LTRScoringQuery {\n  private final String originalRankingModelName;\n  public OriginalRankingLTRScoringQuery(String originalRankingModelName) {\n    super(null /* LTRScoringModel */);\n    this.originalRankingModelName = originalRankingModelName;\n  }\n  @Override\n  public String getScoringModelName() {\n    return this.originalRankingModelName;\n  }\n}\n\nthen (rerankingQuery instanceof OriginalRankingLTRScoringQuery) could replace isOriginalRanking(rerankingQuery) conceptually.\n\nJust thinking out aloud here, haven't yet tried to turn any of the above into code.\nCould you see inheritance (for LTRQParserPlugin and/or LTRScoringQuery) work potentially?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r498948018", "createdAt": "2020-10-02T17:15:05Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDk1Njg3MA==", "bodyText": "So @cpoerschke , I made a step back with the latest commit, let me explain,\nFirst of all, the approach you detailed can definitely work,\nI don't want to undervalue your effort and contribution, I am actually quite grateful for the time you dedicated in reviewing my proposal, so I really appreciate that.\nBut let's aim to a Keep It Simple Stupid approach here (KISS) and avoid over-complication in a first release, if possible:\n\nApache Solr makes use of \"special names\" in various places :\n\n\nDEFAULT to indicate the default feature/model store\nversion to indicate a meta-field used for versioning/optimistic concurrency\nect\nI notice the prefix and suffix '_' is used for them.\nSo let's use it  : \"OriginalRanking\" could be a fair name to identify the Apache Solr ranking pre-re-ranking.\nI named it after the \"OriginalScore\" feature, already in place, happy to use a different name, but wouldn't spend to much time on it.\nMy proposal would be to use \"OriginalRanking\" or potentially \"OriginalScoreRanking\" if more readable\n\n\n\nthe user interact with the !ltr query parser as usual, and if he/she wants to use interleaving, he/she just passes a second model (yes, we are supporting only 2 interleaved model right now):\nmodel=A model=B\nIf he/she wants to interleave with the original ranking:\nmodel=A model=OriginalRanking\nI think this is quite intuitive and easy to be used, quite explicit and following current Apache Solr nomenclature for special named items\n\n\nwhat happens if a user had/wants to use \"OriginalRanking\" for one of his/her models?\nIn this unlikely event, a Jira issue can be raised and we design a possible solution at that time.\nA possible simple approach could be to make the original ranking name parametric, so the user can specify the name in the solrconfig.xml\nBut I would delay this reasoning only if we get requests for that functionality from users\n\n\nWhat do you think?\nIf we find a good compromise here, we could move the review to the re-scoring part, that is more delicate and we can make sure no mistake happened there (I definitely don't want to slow down normal re-ranking and I definitely want the interleaved re-ranking to be as fast as possible)\nYou find the latest changes in the latest commits, I will update the related documentation as well today.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r500956870", "createdAt": "2020-10-07T12:05:19Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwMjY3OA==", "bodyText": "Hi @alessandrobenedetti! Apologies for not returning to here sooner.\nGood point about Apache Solr already using \"special names\" in various places, sure, let's go with \"OriginalRanking\" as the special name then. Hmm, the UI treats underscore special here, so \"_OriginalRanking_\" is what's in the code currently.\n\n... we could move the review to the re-scoring part, that is more delicate ...\n\n\"delicate\" is an excellent word choice, thank you, I spent some pleasant time today continuing to learn more about the re-scoring part. Took a sort of outside-to-inside approach i.e. starting at LTRQParserPlugin and then looking at what changed and how the bits fit together.\nIf it's okay with you I'll push a branch to my fork and add comments/questions sometimes with commit links here, not quite sure if that might work, let's try?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517502678", "createdAt": "2020-11-04T17:14:14Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU1MTgxMA==", "bodyText": "Thanks @cpoerschke ! Tomorrow I'll address all your comments and think about them!\nMy intent is to merge within a few days, so hopefully, we can close this soon!\nThank you again for your time and contribution, much appreciated!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517551810", "createdAt": "2020-11-04T18:36:31Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njg2NA=="}, "originalCommit": {"oid": "79722402210371b8ff2422e945ba1b8f8eb29c15"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEwNjY5ODI2OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQyMjoxMDowN1rOHZRkbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQyMjoxMDowN1rOHZRkbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI2NDMwMw==", "bodyText": "NULL_DEREFERENCE:  object scorer last assigned on line 172 could be null and is dereferenced by call to scoreSingleHit(...) at line 189.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r496264303", "createdAt": "2020-09-28T22:10:07Z", "author": {"login": "sonatype-lift"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer.java", "diffHunk": "@@ -166,64 +186,77 @@ public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n         docBase = readerContext.docBase;\n         scorer = modelWeight.scorer(readerContext);\n       }\n-      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n-      // call score\n-      // even if no feature scorers match, since a model might use that info to\n-      // return a\n-      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n-      // past the target\n-      // doc since the model algorithm still needs to compute a potentially\n-      // non-zero score from blank features.\n-      assert (scorer != null);\n-      final int targetDoc = docID - docBase;\n-      scorer.docID();\n-      scorer.iterator().advance(targetDoc);\n-\n-      scorer.getDocInfo().setOriginalDocScore(hit.score);\n-      hit.score = scorer.score();\n-      if (hitUpto < topN) {\n-        reranked[hitUpto] = hit;\n-        // if the heap is not full, maybe I want to log the features for this\n-        // document\n+      scoreSingleHit(indexSearcher, topN, modelWeight, docBase, hitUpto, hit, docID, scoringQuery, scorer, reranked);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "921d7ef5ccf07b9af916410909d39fd61754908e"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEwNjY5ODQ2OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQyMjoxMDoxMFrOHZRkhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOFQyMjoxMDoxMFrOHZRkhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI2NDMyNQ==", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r496264325", "createdAt": "2020-09-28T22:10:10Z", "author": {"login": "sonatype-lift"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");\n+    if (seed == null) {\n+      RANDOM = new Random();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "921d7ef5ccf07b9af916410909d39fd61754908e"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzQ5NjYyOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzoyNDo0NFrOHtiRKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTozMzowNVrOHuI3Pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwOTQxNw==", "bodyText": "1/n Instead of having a static isOriginalRanking(LTRScoringQuery rerankingQuery) utility method here we could have a OriginalRankingLTRScoringQuery extends LTRScoringQuery class and replace LTRQParserPlugin.isOriginalRanking(query) calls with query instanceof OriginalRankingLTRScoringQuery expressions.\ncpoerschke@6204ead explores that.\nIn isolation the change appears to be somewhat stylistic only but it would later  (2/n and 4/n) allow for other possibilities too.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517509417", "createdAt": "2020-11-04T17:24:44Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE0MTc1OQ==", "bodyText": "makes sense to me! I resolve this and continue", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518141759", "createdAt": "2020-11-05T15:33:05Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwOTQxNw=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzUwNzg1OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRInterleavingTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzoyNzozNlrOHtiYOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTozNjo1MlrOHuJHFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxMTIyNw==", "bodyText": "2/n cpoerschke@be20b3a explores making LTRQParserPlugin.ORIGINAL_RANKING private. A stylistic thing to some extent though it would in future also make it easier to pass in their own alternative to the special \"_OriginalRanking_\" value as a parameter.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517511227", "createdAt": "2020-11-04T17:27:36Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRInterleavingTransformerFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr.response.transform;\n+\n+import java.io.IOException;\n+import org.apache.solr.common.SolrDocument;\n+import org.apache.solr.common.params.SolrParams;\n+import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.ltr.LTRScoringQuery;\n+import org.apache.solr.ltr.SolrQueryRequestContextUtils;\n+import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.response.ResultContext;\n+import org.apache.solr.response.transform.DocTransformer;\n+import org.apache.solr.response.transform.TransformerFactory;\n+import org.apache.solr.util.SolrPluginUtils;\n+\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.ORIGINAL_RANKING;\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.isOriginalRanking;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE0NTgxMw==", "bodyText": "Good idea!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518145813", "createdAt": "2020-11-05T15:36:52Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRInterleavingTransformerFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr.response.transform;\n+\n+import java.io.IOException;\n+import org.apache.solr.common.SolrDocument;\n+import org.apache.solr.common.params.SolrParams;\n+import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.ltr.LTRScoringQuery;\n+import org.apache.solr.ltr.SolrQueryRequestContextUtils;\n+import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.response.ResultContext;\n+import org.apache.solr.response.transform.DocTransformer;\n+import org.apache.solr.response.transform.TransformerFactory;\n+import org.apache.solr.util.SolrPluginUtils;\n+\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.ORIGINAL_RANKING;\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.isOriginalRanking;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxMTIyNw=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzUxOTU1OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/SolrQueryRequestContextUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzozMDo0OVrOHtifvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTozODo1NFrOHuJPQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxMzE0OQ==", "bodyText": "3/n getScoringQuery already is renamed to getScoringQueries to reflect the changed signature, how about renaming setScoringQuery to setScoringQueries also?  cpoerschke@2579aee does that plus SCORING_QUERY to SCORING_QUERIES too.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517513149", "createdAt": "2020-11-04T17:30:49Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/SolrQueryRequestContextUtils.java", "diffHunk": "@@ -47,12 +47,12 @@ public static FeatureLogger getFeatureLogger(SolrQueryRequest req) {\n \n   /** scoring query accessors **/\n \n-  public static void setScoringQuery(SolrQueryRequest req, LTRScoringQuery scoringQuery) {\n-    req.getContext().put(SCORING_QUERY, scoringQuery);\n+  public static void setScoringQuery(SolrQueryRequest req, LTRScoringQuery[] scoringQueries) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE0NzkwNQ==", "bodyText": "absolutely reasonable!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518147905", "createdAt": "2020-11-05T15:38:54Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/SolrQueryRequestContextUtils.java", "diffHunk": "@@ -47,12 +47,12 @@ public static FeatureLogger getFeatureLogger(SolrQueryRequest req) {\n \n   /** scoring query accessors **/\n \n-  public static void setScoringQuery(SolrQueryRequest req, LTRScoringQuery scoringQuery) {\n-    req.getContext().put(SCORING_QUERY, scoringQuery);\n+  public static void setScoringQuery(SolrQueryRequest req, LTRScoringQuery[] scoringQueries) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxMzE0OQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzUzMDUzOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRScoringQuery.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzozMzo1MFrOHtimlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzozMzo1MFrOHtimlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNDkwMA==", "bodyText": "4.1/n The addition of a new member here which is only sometimes applicable got me wondering about possibly having LTRInterleavingScoringQuery extends LTRScoringQuery inheritance.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517514900", "createdAt": "2020-11-04T17:33:50Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRScoringQuery.java", "diffHunk": "@@ -73,6 +74,8 @@\n   final private Map<String,String[]> efi;\n   // Original solr query used to fetch matching documents\n   private Query originalQuery;\n+  // Model was picked for this Docs\n+  private Set<Integer> pickedInterleavingDocIds;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzU0MDQ2OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzozNjoyNVrOHtisuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMzowMToyMVrOHutJqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNjQ3NQ==", "bodyText": "4.2/n The differentation of behaviour here based on which constructor variant was called got me wondering about possibly having LTRInterleavingQuery extends LTRQuery inheritance.\ncpoerschke@ff2cfe7 explores factoring out of LTRInterleaving[Scoring]Query classes.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517516475", "createdAt": "2020-11-04T17:36:25Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }\n \n   /**\n    * A learning to rank Query, will incapsulate a learning to rank model, and delegate to it the rescoring\n    * of the documents.\n    **/\n   public class LTRQuery extends AbstractReRankQuery {\n-    private final LTRScoringQuery scoringQuery;\n+    private final LTRScoringQuery[] rerankingQueries;\n \n-    public LTRQuery(LTRScoringQuery scoringQuery, int reRankDocs) {\n-      super(defaultQuery, reRankDocs, new LTRRescorer(scoringQuery));\n-      this.scoringQuery = scoringQuery;\n+    public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+      this.rerankingQueries = rerankingQueries;\n+    }\n+\n+    public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n+      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI5MDMxMg==", "bodyText": "I have some doubts about this commit, it's not a strong opinion though, your considerations about implementing two subclasses are fair.\nThe additional property and method added to LTR Query is just: private Set pickedInterleavingDocIds; and its getter/setters.\nOn the other hand with the creation of the subclass there is a little bit of code we are adding around,  I am not sure if it's worth in regarding to readability/maintenance.\nI am just wondering if we get substantial benefits from this piece of refactor, if not we may stick with the original code,\nwhat do you think?\nCan you elaborate a bit more the expected benefits you were thinking?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518290312", "createdAt": "2020-11-05T19:00:46Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }\n \n   /**\n    * A learning to rank Query, will incapsulate a learning to rank model, and delegate to it the rescoring\n    * of the documents.\n    **/\n   public class LTRQuery extends AbstractReRankQuery {\n-    private final LTRScoringQuery scoringQuery;\n+    private final LTRScoringQuery[] rerankingQueries;\n \n-    public LTRQuery(LTRScoringQuery scoringQuery, int reRankDocs) {\n-      super(defaultQuery, reRankDocs, new LTRRescorer(scoringQuery));\n-      this.scoringQuery = scoringQuery;\n+    public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+      this.rerankingQueries = rerankingQueries;\n+    }\n+\n+    public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n+      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNjQ3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM2NDE1OQ==", "bodyText": "That's a fair question.\nApart from the subclass considerations already annotated I see sort of \"structural extensibility\" type benefits, not sure if that's a good description, let me try to illustrate with two examples:\n\nexample 1: beyond TeamDraftInterleaving: An interleaving algorithm other than TeamDraftInterleaving could be supported like I alluded to in 11.1/n though of course with the existing class structure that would also be possible.\n\n- public LTRInterleavingQuery(LTRInterleavingScoringQuery[] rerankingQueries, int rerankDocs) {\n-     super(null /* scoringQuery */, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+ public LTRInterleavingQuery(LTRInterleavingScoringQuery[] rerankingQueries, int rerankDocs, Interleaving interleavingAlgorithm) {\n+     super(null /* scoringQuery */, rerankDocs, new LTRInterleavingRescorer(rerankingQueries, interleavingAlgorithm));\n\nvs.\n- public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n-     super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+ public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs, Interleaving interleavingAlgorithm) {\n+     super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries, interleavingAlgorithm));\n      this.rerankingQueries = rerankingQueries;\n  }\n\n  public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};\n  }\n\nYou'd know better than me what other interleaving algorithms exist and might be interesting for LTR and what sort of parameters they might need from LTRQParserPlugin. One variant of the current TeamDraftInterleaving that I (naively) could see is for the two models to interleave not with the current 50:50 ratio but with (say) a 80:20 ratio.\n\nexample 2: beyond Interleaving: we've got one model, we've got interleaving of two models, might there be other ways of combining models or of rescoring? I don't know what these might be: choose a document only if both models had picked it? choose a document only if at least 2 of 3 models picked it? hmm, maybe those are variants of interleaving. could one model rescore the documents already scored by another model?\n\nanyhow, whatever the shiny new thing is, there'd be an existing LTRQuery/LTRScoringQuery/LTRRescorer + LTRInterleavingQuery/LTRInterleavingScoringQuery/LTRInterleavingRescorer pattern that might be repeated then as LTRShinyNewQuery/LTRShinyNewScoringQuery/LTRShinyNewRescorer and whilst LTRInterleaving* required only the pickedInterleavingDocIds as state within LTR[Interleaving]ScoringQuery perhaps LTRShinyNew* would require something more complex.\n\nWhen you say \"there is a little bit of code we are adding around\" I agree, yes, there's all the methods twice though slightly different then.\n\nIs your concern about the repetition as such and/or about the increase in the LTRQParserPlugin class in which the LTR[Interleaving]Query classes are inner classes?\nIt appears that the inner classes are not but could be static inner classes and therefore it should also be possible to promote them to not be inner classes of LTRQParserPlugin but classes in their own right and that would make LTRQParserPlugin shorter.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518364159", "createdAt": "2020-11-05T21:05:53Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }\n \n   /**\n    * A learning to rank Query, will incapsulate a learning to rank model, and delegate to it the rescoring\n    * of the documents.\n    **/\n   public class LTRQuery extends AbstractReRankQuery {\n-    private final LTRScoringQuery scoringQuery;\n+    private final LTRScoringQuery[] rerankingQueries;\n \n-    public LTRQuery(LTRScoringQuery scoringQuery, int reRankDocs) {\n-      super(defaultQuery, reRankDocs, new LTRRescorer(scoringQuery));\n-      this.scoringQuery = scoringQuery;\n+    public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+      this.rerankingQueries = rerankingQueries;\n+    }\n+\n+    public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n+      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNjQ3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5NjY4OA==", "bodyText": "I didn't like much the bit in the  LTRFeatureLoggerTransformerFactory.java\nLTRInterleavingTransformerFactory.java, but thinking more about it, I don't think is that much of a problem, ad your observations are fair. I am finishing the other comments and I may extract  the two classes", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518696688", "createdAt": "2020-11-06T11:37:59Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }\n \n   /**\n    * A learning to rank Query, will incapsulate a learning to rank model, and delegate to it the rescoring\n    * of the documents.\n    **/\n   public class LTRQuery extends AbstractReRankQuery {\n-    private final LTRScoringQuery scoringQuery;\n+    private final LTRScoringQuery[] rerankingQueries;\n \n-    public LTRQuery(LTRScoringQuery scoringQuery, int reRankDocs) {\n-      super(defaultQuery, reRankDocs, new LTRRescorer(scoringQuery));\n-      this.scoringQuery = scoringQuery;\n+    public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+      this.rerankingQueries = rerankingQueries;\n+    }\n+\n+    public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n+      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNjQ3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczNjI5Nw==", "bodyText": "So I have done that in my latest commit, I brought back the original implementation for the transformers, it may be less readable but are we reducing the number of contains call?\nGiven that we support just interleaving for 2 ranked list, if a document is not assigned to modelB is by default assigned to modelA and no need of checking the  getPickedInterleavingDocIds?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518736297", "createdAt": "2020-11-06T13:01:21Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }\n+          rerankingQuery = new LTRScoringQuery(ltrScoringModel,\n+              extractEFIParams(localParams),\n+              featuresRequestedFromSameStore, threadManager);\n+\n+          // Enable the feature vector caching if we are extracting features, and the features\n+          // we requested are the same ones we are reranking with\n+          if (featuresRequestedFromSameStore) {\n+            rerankingQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+          }\n+        }else{\n+          rerankingQuery = new LTRScoringQuery(null);\n+        }\n+\n+        // External features\n+        rerankingQuery.setRequest(req);\n+        rerankingQueries[i] = rerankingQuery;\n       }\n-      SolrQueryRequestContextUtils.setScoringQuery(req, scoringQuery);\n \n+      SolrQueryRequestContextUtils.setScoringQuery(req, rerankingQueries);\n       int reRankDocs = localParams.getInt(RERANK_DOCS, DEFAULT_RERANK_DOCS);\n       if (reRankDocs <= 0) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-          \"Must rerank at least 1 document\");\n+            \"Must rerank at least 1 document\");\n+      }\n+      if (rerankingQueries.length == 1) {\n+        return new LTRQuery(rerankingQueries[0], reRankDocs);\n+      } else {\n+        return new LTRQuery(rerankingQueries, reRankDocs);\n       }\n-\n-      // External features\n-      scoringQuery.setRequest(req);\n-\n-      return new LTRQuery(scoringQuery, reRankDocs);\n     }\n   }\n+  \n+  public static boolean isOriginalRanking(LTRScoringQuery rerankingQuery){\n+    return rerankingQuery.getScoringModel() == null;\n+  }\n \n   /**\n    * A learning to rank Query, will incapsulate a learning to rank model, and delegate to it the rescoring\n    * of the documents.\n    **/\n   public class LTRQuery extends AbstractReRankQuery {\n-    private final LTRScoringQuery scoringQuery;\n+    private final LTRScoringQuery[] rerankingQueries;\n \n-    public LTRQuery(LTRScoringQuery scoringQuery, int reRankDocs) {\n-      super(defaultQuery, reRankDocs, new LTRRescorer(scoringQuery));\n-      this.scoringQuery = scoringQuery;\n+    public LTRQuery(LTRScoringQuery[] rerankingQueries, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRInterleavingRescorer(rerankingQueries));\n+      this.rerankingQueries = rerankingQueries;\n+    }\n+\n+    public LTRQuery(LTRScoringQuery rerankingQuery, int rerankDocs) {\n+      super(defaultQuery, rerankDocs, new LTRRescorer(rerankingQuery));\n+      this.rerankingQueries = new LTRScoringQuery[]{rerankingQuery};", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUxNjQ3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzU3MDg5OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzo0NDoxN1rOHti_uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxOTowMzoyNVrOHuSBXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyMTMzOQ==", "bodyText": "5/n When doing the 4/n stuff a question occurred to me here: rerankingQueries[0] and modelWeights[0] are the initial values. If the query is changed to rerankingQueries[1] then should the weight also be changed to modelWeights[1]? (Open question, haven't analysed it further yet nor tried it out.)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517521339", "createdAt": "2020-11-04T17:44:17Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -271,17 +287,23 @@ public void transform(SolrDocument doc, int docid)\n \n     private void implTransform(SolrDocument doc, int docid, Float score)\n         throws IOException {\n-      Object fv = featureLogger.getFeatureVector(docid, scoringQuery, searcher);\n-      if (fv == null) { // FV for this document was not in the cache\n-        fv = featureLogger.makeFeatureVector(\n-            LTRRescorer.extractFeaturesInfo(\n-                modelWeight,\n-                docid,\n-                (docsWereNotReranked ? score : null),\n-                leafContexts));\n+      LTRScoringQuery rerankingQuery = rerankingQueries[0];\n+      LTRScoringQuery.ModelWeight rerankingModelWeight = modelWeights[0];\n+      if (rerankingQueries.length > 1 && rerankingQueries[1].getPickedInterleavingDocIds().contains(docid)) {\n+        rerankingQuery = rerankingQueries[1];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI5MTgwNQ==", "bodyText": "Yes, I agree, I'll change that and resolve this later", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518291805", "createdAt": "2020-11-05T19:03:25Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -271,17 +287,23 @@ public void transform(SolrDocument doc, int docid)\n \n     private void implTransform(SolrDocument doc, int docid, Float score)\n         throws IOException {\n-      Object fv = featureLogger.getFeatureVector(docid, scoringQuery, searcher);\n-      if (fv == null) { // FV for this document was not in the cache\n-        fv = featureLogger.makeFeatureVector(\n-            LTRRescorer.extractFeaturesInfo(\n-                modelWeight,\n-                docid,\n-                (docsWereNotReranked ? score : null),\n-                leafContexts));\n+      LTRScoringQuery rerankingQuery = rerankingQueries[0];\n+      LTRScoringQuery.ModelWeight rerankingModelWeight = modelWeights[0];\n+      if (rerankingQueries.length > 1 && rerankingQueries[1].getPickedInterleavingDocIds().contains(docid)) {\n+        rerankingQuery = rerankingQueries[1];", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyMTMzOQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 141}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MzU4ODY3OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzo0OTowNlrOHtjK-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxNzo0OTowNlrOHtjK-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyNDIxNw==", "bodyText": "6/n Also as part of 4/n noticed that here this if-then-set likely need not be inside the for-loop? The loop runs only once or twice so efficiency wise no concerns but from code reading perspective it not being inside the loop would be clearer.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517524217", "createdAt": "2020-11-04T17:49:06Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {\n       // ReRanking Model\n-      final String modelName = localParams.get(LTRQParserPlugin.MODEL);\n-      if ((modelName == null) || modelName.isEmpty()) {\n+      final String[] modelNames = localParams.getParams(LTRQParserPlugin.MODEL);\n+      if ((modelNames == null) || modelNames.length==0 || modelNames[0].isEmpty()) {\n         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n             \"Must provide model in the request\");\n       }\n-\n-      final LTRScoringModel ltrScoringModel = mr.getModel(modelName);\n-      if (ltrScoringModel == null) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-            \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelName);\n-      }\n-\n-      final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n-      final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n-      final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      // Check if features are requested and if the model feature store and feature-transform feature store are the same\n-      final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures:false;\n-      if (threadManager != null) {\n-        threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n-      }\n-      final LTRScoringQuery scoringQuery = new LTRScoringQuery(ltrScoringModel,\n-          extractEFIParams(localParams),\n-          featuresRequestedFromSameStore, threadManager);\n-\n-      // Enable the feature vector caching if we are extracting features, and the features\n-      // we requested are the same ones we are reranking with\n-      if (featuresRequestedFromSameStore) {\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+     \n+      LTRScoringQuery[] rerankingQueries = new LTRScoringQuery[modelNames.length];\n+      for (int i = 0; i < modelNames.length; i++) {\n+        final LTRScoringQuery rerankingQuery;\n+        if (!ORIGINAL_RANKING.equals(modelNames[i])) {\n+          final LTRScoringModel ltrScoringModel = mr.getModel(modelNames[i]);\n+          if (ltrScoringModel == null) {\n+            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+                \"cannot find \" + LTRQParserPlugin.MODEL + \" \" + modelNames[i]);\n+          }\n+          final String modelFeatureStoreName = ltrScoringModel.getFeatureStoreName();\n+          final boolean extractFeatures = SolrQueryRequestContextUtils.isExtractingFeatures(req);\n+          final String fvStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);        // Check if features are requested and if the model feature store and feature-transform feature store are the same\n+          final boolean featuresRequestedFromSameStore = (modelFeatureStoreName.equals(fvStoreName) || fvStoreName == null) ? extractFeatures : false;\n+          if (threadManager != null) {\n+            threadManager.setExecutor(req.getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NTk2Mzg5OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwOTowMDoyNVrOHt5clw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMDoxNzowM1rOHuoGMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg4OTE3NQ==", "bodyText": "7/n minor comments:\n\ntechnically not just modelNames[0] but all the model names could be isEmpty checked\nthreadManager.setExecutor (already mentioned in 6/n) need not be inside the loop, likewise extractFeatures and fvStoreName and extractEFIParams(localParams) could move out.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517889175", "createdAt": "2020-11-05T09:00:25Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1MzQ5MA==", "bodyText": "as you will see in my next commit, I added the empty check in the loop and a couple of tests for it, I leave this open, feel free to resolve this once you take a look.\nIf we don't check for empty, we will get an exception anyway saying:\n\"cannot find model\"\nIt's up to us if we want to help more the user with the empty message.\nI think is fine, telling explicitly in an exception the model is empty could save time for developers/integrators not understanding why a model cannot be found", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518653490", "createdAt": "2020-11-06T10:17:03Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/search/LTRQParserPlugin.java", "diffHunk": "@@ -146,93 +149,114 @@ public LTRQParser(String qstr, SolrParams localParams, SolrParams params,\n     @Override\n     public Query parse() throws SyntaxError {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg4OTE3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NTk4NzgyOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwOTowNjo0OVrOHt5r1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNzoxNToxNVrOHv5IUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg5MzA3OA==", "bodyText": "8/n suggestions:\n\nclass level javadocs re: the interleaving algorithm\ncomments or javadocs re: any assumptions e.g.\n\nmust rerankedA.length and rerankedB.length match?\ncan rerankedA and rerankedB contain the same docs?\ncan rerankedA contain the same doc more than once?\ncan rerankedB contain the same doc more than once?\n\n\nconsider guarding against array-index-out-of-bounds exceptions (even if they shouldn't happen if all assumptions are met)\n\nindexA = updateIndex(interleavedResults,indexA,rerankedA);\nif (indexA < rerankedA.length) {\n  interleavedResults.add(rerankedA[indexA]);\n  teamA.add(rerankedA[indexA].doc);\n  indexA++;\n}", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517893078", "createdAt": "2020-11-05T09:06:49Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY2NTg4Ng==", "bodyText": "update the java docs, in regards to the index out of bounds, I think we should raise the exception instead of adding the condition:\nif the assumptions are not met, there is a bug to be fixed, so we need interleaving to fail instead of silently operates wrong, am I missing anything?\nPlease take a look to my new commit, especially for the comments", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518665886", "createdAt": "2020-11-06T10:39:51Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg5MzA3OA=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4MTEzNg==", "bodyText": "Very nice java docs and comments, thanks!\n\n... I think we should raise the exception ...\n\nYes, you're right, an exception that will lead to a bug being identified and fixed rather than silent failure or (confusing for the user) \"array out of bounds exception\" would be better.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519981136", "createdAt": "2020-11-09T17:15:15Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg5MzA3OA=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NjQxMjUwOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMDo1MjozOFrOHt9y_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxODoyNDo0MVrOHuQo_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2MDQ0Nw==", "bodyText": "9/n observation and suggestions:\n\nvery elegant factoring out of methods for use by LTRInterleavingRescorer\nthe rerank method already takes a searcher and so it could determine its own leaves from that\nthis.scoringQuery being passed to the scoreSingleHit method as an argument (rather than it using the this.scoringQuery directly) is very subtle. it is of course present as an argument because LTRInterleavingRescorer will passing rerankingQueries[i] for that argument. the subtlety could be removed by making scoreSingleHit a static method.\n\ncpoerschke@16512db", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r517960447", "createdAt": "2020-11-05T10:52:38Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer.java", "diffHunk": "@@ -166,64 +186,77 @@ public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n         docBase = readerContext.docBase;\n         scorer = modelWeight.scorer(readerContext);\n       }\n-      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n-      // call score\n-      // even if no feature scorers match, since a model might use that info to\n-      // return a\n-      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n-      // past the target\n-      // doc since the model algorithm still needs to compute a potentially\n-      // non-zero score from blank features.\n-      assert (scorer != null);\n-      final int targetDoc = docID - docBase;\n-      scorer.docID();\n-      scorer.iterator().advance(targetDoc);\n-\n-      scorer.getDocInfo().setOriginalDocScore(hit.score);\n-      hit.score = scorer.score();\n-      if (hitUpto < topN) {\n-        reranked[hitUpto] = hit;\n-        // if the heap is not full, maybe I want to log the features for this\n-        // document\n+      scoreSingleHit(indexSearcher, topN, modelWeight, docBase, hitUpto, hit, docID, scoringQuery, scorer, reranked);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2OTE4Mg==", "bodyText": "Brilliant observation!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518269182", "createdAt": "2020-11-05T18:24:41Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRRescorer.java", "diffHunk": "@@ -166,64 +186,77 @@ public void scoreFeatures(IndexSearcher indexSearcher, TopDocs firstPassTopDocs,\n         docBase = readerContext.docBase;\n         scorer = modelWeight.scorer(readerContext);\n       }\n-      // Scorer for a LTRScoringQuery.ModelWeight should never be null since we always have to\n-      // call score\n-      // even if no feature scorers match, since a model might use that info to\n-      // return a\n-      // non-zero score. Same applies for the case of advancing a LTRScoringQuery.ModelWeight.ModelScorer\n-      // past the target\n-      // doc since the model algorithm still needs to compute a potentially\n-      // non-zero score from blank features.\n-      assert (scorer != null);\n-      final int targetDoc = docID - docBase;\n-      scorer.docID();\n-      scorer.iterator().advance(targetDoc);\n-\n-      scorer.getDocInfo().setOriginalDocScore(hit.score);\n-      hit.score = scorer.score();\n-      if (hitUpto < topN) {\n-        reranked[hitUpto] = hit;\n-        // if the heap is not full, maybe I want to log the features for this\n-        // document\n+      scoreSingleHit(indexSearcher, topN, modelWeight, docBase, hitUpto, hit, docID, scoringQuery, scorer, reranked);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk2MDQ0Nw=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0Njg5MTY4OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxMzowNjowMVrOHuCYEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxOTowNDo1NVrOHuSEsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzNTQ3NQ==", "bodyText": "10/n suggestions:\n\ncalculate originalRankingIndex in the constructor\nuse originalRankingIndex to minimise \"rerankingQueries[i] is not original ranking\" checks\nuse originalRankingIndex to remove the \"original ranking query is always the last query\" assumption\nthe 'rerank' method already takes a searcher and so it could determine its own leaves from that\n\ncpoerschke@002c31c", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518035475", "createdAt": "2020-11-05T13:06:01Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Set;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.solr.ltr.interleaving.Interleaving;\n+import org.apache.solr.ltr.interleaving.InterleavingResult;\n+import org.apache.solr.ltr.interleaving.TeamDraftInterleaving;\n+\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.isOriginalRanking;\n+\n+/**\n+ * Implements the rescoring logic. The top documents returned by solr with their\n+ * original scores, will be processed by a {@link LTRScoringQuery} that will assign a\n+ * new score to each document. The top documents will be resorted based on the\n+ * new score.\n+ * */\n+public class LTRInterleavingRescorer extends LTRRescorer {\n+  \n+  LTRScoringQuery[] rerankingQueries;\n+  Interleaving interleavingAlgorithm = new TeamDraftInterleaving();\n+  \n+  public LTRInterleavingRescorer(LTRScoringQuery[] rerankingQueries) {\n+    this.rerankingQueries = rerankingQueries;\n+  }\n+\n+  /**\n+   * rescores the documents:\n+   *\n+   * @param searcher\n+   *          current IndexSearcher\n+   * @param firstPassTopDocs\n+   *          documents to rerank;\n+   * @param topN\n+   *          documents to return;\n+   */\n+  @Override\n+  public TopDocs rescore(IndexSearcher searcher, TopDocs firstPassTopDocs,\n+      int topN) throws IOException {\n+    if ((topN == 0) || (firstPassTopDocs.scoreDocs.length == 0)) {\n+      return firstPassTopDocs;\n+    }\n+    \n+    int originalRankingIndex = -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI5MjY1OQ==", "bodyText": "Perfectly splendid! I am just waiting to finalise the decision about the subclasses yes/no, and I'll proceed with this commit", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518292659", "createdAt": "2020-11-05T19:04:55Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Set;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.solr.ltr.interleaving.Interleaving;\n+import org.apache.solr.ltr.interleaving.InterleavingResult;\n+import org.apache.solr.ltr.interleaving.TeamDraftInterleaving;\n+\n+import static org.apache.solr.ltr.search.LTRQParserPlugin.isOriginalRanking;\n+\n+/**\n+ * Implements the rescoring logic. The top documents returned by solr with their\n+ * original scores, will be processed by a {@link LTRScoringQuery} that will assign a\n+ * new score to each document. The top documents will be resorted based on the\n+ * new score.\n+ * */\n+public class LTRInterleavingRescorer extends LTRRescorer {\n+  \n+  LTRScoringQuery[] rerankingQueries;\n+  Interleaving interleavingAlgorithm = new TeamDraftInterleaving();\n+  \n+  public LTRInterleavingRescorer(LTRScoringQuery[] rerankingQueries) {\n+    this.rerankingQueries = rerankingQueries;\n+  }\n+\n+  /**\n+   * rescores the documents:\n+   *\n+   * @param searcher\n+   *          current IndexSearcher\n+   * @param firstPassTopDocs\n+   *          documents to rerank;\n+   * @param topN\n+   *          documents to return;\n+   */\n+  @Override\n+  public TopDocs rescore(IndexSearcher searcher, TopDocs firstPassTopDocs,\n+      int topN) throws IOException {\n+    if ((topN == 0) || (firstPassTopDocs.scoreDocs.length == 0)) {\n+      return firstPassTopDocs;\n+    }\n+    \n+    int originalRankingIndex = -1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzNTQ3NQ=="}, "originalCommit": {"oid": "7f35b8f8f0f330852fb7eda4589c3d2e3a58342c"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NzY0OTE0OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTo0OTozN1rOHuJwPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoxOTo1OVrOHur7qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1NjM0OA==", "bodyText": "11.1/n If we go with 4/n then LTRQParserPlugin.LTRQParser could pass a Interleaving interleavingAlgorithm argument to the LTRInterleavingQuery constructor which could pass it to the LTRInterleavingRescorer constructor. For now TeamDraftInterleaving would be the only supported algorithm but in future other algorithms could then easily be added e.g. based on an additional ltr parameter. What do you think? An easy change to make now or something better left for later?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518156348", "createdAt": "2020-11-05T15:49:37Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Set;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.solr.ltr.interleaving.Interleaving;\n+import org.apache.solr.ltr.interleaving.InterleavingResult;\n+import org.apache.solr.ltr.interleaving.TeamDraftInterleaving;\n+\n+/**\n+ * Implements the rescoring logic. The top documents returned by solr with their\n+ * original scores, will be processed by a {@link LTRScoringQuery} that will assign a\n+ * new score to each document. The top documents will be resorted based on the\n+ * new score.\n+ * */\n+public class LTRInterleavingRescorer extends LTRRescorer {\n+  \n+  LTRScoringQuery[] rerankingQueries;\n+  Interleaving interleavingAlgorithm = new TeamDraftInterleaving();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNjMzMQ==", "bodyText": "I added this bit, I think is easy enough and not much invasive to prepare the structure now.\nAdding new algorithm would be as easy as :\n\nfetching the param from the request\nadd the algorithm name in the switch clause\nimplement the new algorithm\n\nTake a look if you like it", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518716331", "createdAt": "2020-11-06T12:19:59Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRInterleavingRescorer.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Set;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Explanation;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.solr.ltr.interleaving.Interleaving;\n+import org.apache.solr.ltr.interleaving.InterleavingResult;\n+import org.apache.solr.ltr.interleaving.TeamDraftInterleaving;\n+\n+/**\n+ * Implements the rescoring logic. The top documents returned by solr with their\n+ * original scores, will be processed by a {@link LTRScoringQuery} that will assign a\n+ * new score to each document. The top documents will be resorted based on the\n+ * new score.\n+ * */\n+public class LTRInterleavingRescorer extends LTRRescorer {\n+  \n+  LTRScoringQuery[] rerankingQueries;\n+  Interleaving interleavingAlgorithm = new TeamDraftInterleaving();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1NjM0OA=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NzY3MDY5OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNTo1NDoxNFrOHuJ-Ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjowMDo1MlrOHv1p9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ==", "bodyText": "11.2/n LTRQParserPlugin.LTRQParser also has access to the SolrQueryRequest and its SolrCore object. For some reason I thought that within that some 'official' source of random-ness might be available which could be passed to a TeamDraftInterleaving(Random) constructor. And I imagined that our test harnesses would use seeds to make tests reproducible w.r.t. that 'official' source of random-ness. There however doesn't appear to be such a source of non-test official random-ness? System.getProperty(\"tests.seed\"); being used/available to non-test code seems potentially tricky.\n@dweiss would you perhaps have any insights around non-test sources of randomness?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518159891", "createdAt": "2020-11-05T15:54:14Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI5MzYyOQ==", "bodyText": "I spent quite a lot of time on this, to make it compatible with the tests, if anyone else has some better solution I would be more than happy to change it, I was not super happy of what I ended with, but it was the only solution I found to be working at the time.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518293629", "createdAt": "2020-11-05T19:06:40Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1OTQzMw==", "bodyText": "Yes, predictable randomness in tests can be tricky! I had an (unplanned) idea around this at breakfast this morning, trying it out now: cpoerschke@5fc9989 is part 1 of 2 (and is independent technically speaking).", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518659433", "createdAt": "2020-11-06T10:28:11Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcyNTE2Ng==", "bodyText": "cpoerschke@63a190b is part 2 of 2: it removes the tests.seed System property use in TeamDraftInterleaving by passing a Random object into TeamDraftInterleaving. instead the tests.seed System property use is in a test class (LTRQParserTestPlugin) and tests continue to make their setRANDOM calls but instead of TeamDraftInterleaving.setRANDOM it's now LTRQParserTestPlugin.setRANDOM then.\nTwo problems with this though:\n\na forbidden apis check fails (saying that RandomizedRunner's random() should be used instead but i'm unclear still on how that might be done)\nthe tests no longer pass, which baffles me though haven't looked at details yet; speculations:\n\nwas the randomness in the tests predictable before and now it's predictable also but the number sequence has changed and test expectations need to be adjusted to match?\nsomething to do with order of system property setting and non-test/test class loading perhaps and perhaps use of the RandomizedRunner's random would solve it somehow?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518725166", "createdAt": "2020-11-06T12:38:42Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg2OTg5NQ==", "bodyText": "Now I remember, I worked on this a lot and I ended up with the current solution even if including the test seed get property.\nI have not introduced that approach on my own, but I took inspiration from other areas of Solr code:\nsuch as:\norg/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java:174\norg/apache/solr/core/BlobRepository.java:73\norg/apache/solr/servlet/HttpSolrCall.java:152\norg/apache/solr/util/tracing/GlobalTracer.java:35\nSo it is already used quite widely across Solr production code.\nUnless you have stronger concerns we can probably leave it as it is and resolve the conversation here :)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518869895", "createdAt": "2020-11-06T16:39:45Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTkyNDIxNA==", "bodyText": "Ah, precedent and existing use already, good to know, thanks for sharing!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519924214", "createdAt": "2020-11-09T16:00:52Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE1OTg5MQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODAzNDYxOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNzoxMjo1OVrOHuNgGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzo1NjoyMVrOHyT2WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ==", "bodyText": "12/n observations/thoughts/questions:\nMost tricky to articulate, hence left until last.\nPrior to interleaving the existing logic is that if feature vectors are requested and there is no model (or the model is for a different feature store) then a logging model is created.\nSo now then if we have two models:\n\nif both models are for the requested feature store then that's great and each document would have been picked by one of the models and so we use the feature vector already previously calculated by whatever model had picked the document.\nif neither model is for the requested feature store then we need to create a logging model, is one logging model sufficient or do we need two? intuitively to me one would seem to be sufficient but that's based on partial analysis only so far.\nif one of the two models (modelA) is for the requested feature store then for the documents picked by modelA we can use the feature vector already previously calculated by modelA. what about documents picked by modelB? it could be that modelA actually has the feature vector for that document but that modelB simply managed to pick the document first. or if modelA does not have the feature vector then we could calculate it for modelA. would a logging model help in this scenario? intuitively to me it would seem that calculating the missing feature vector via modelA or via the logging model would both be equally efficient and hence no logging model would be needed but again that's only based on partial analysis so far.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518217755", "createdAt": "2020-11-05T17:12:59Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE2MjY4MA==", "bodyText": "Spent a lot of time on this, I will continue on Monday, some considerations so far:\n\nin interleaving the logging model scoring query keeps also the interleaving picks (currently as a subclass of the scoring query), so we would need 2 logging models, by the way, I had various problems due to class cast exceptions and array around, so I will think a bit more about the subclass implementation to understand if it's actually an headache or full benefit,\nI think the solution will be to implement only one model, 2 different scoringQuery (that contain the picks) and change the feature vector cache to key on: private static int fvCacheKey(LTRScoringQuery scoringQuery, int docid) {\nreturn  scoringQuery.getScoringModel().hashCode() + (31 * docid);\n}\nI keep you posted on monday", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519162680", "createdAt": "2020-11-07T10:31:07Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzODMyNA==", "bodyText": "So I just committed my changes on this, I spent quite a while thinking about the various scenarios, adjusting the code and adding the related tests.\nFrom your observations:\n\nif both models are for the requested feature store then that's great and each document would have been picked by one of the models and so we use the feature vector already previously calculated by whatever model had picked the document. [OK]\nif neither model is for the requested feature store then we need to create a logging model, is one logging model sufficient or do we need two? intuitively to me one would seem to be sufficient but that's based on partial analysis only so far.\n[One is sufficient, and my latest changes do that, anyway I just realized that the loggingModel is not heavy to create and when getting the featureVector, the cache is accessed, the key for that cache doesn't look to the instance but to the content of classes, so two identical logging models would have matched in the feature vector cache, the change was probably not vital, but not harmful either]\nin the third scenario we still need the logging model, because when specifying a featureStore in the featureVector transformer we aim to extract all the features of that store, from efi passed to the transformer, so when explicitly mentioned, we need a logger for both the model again (also for the one that aligns)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520038324", "createdAt": "2020-11-09T18:48:38Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA1NTM0Ng==", "bodyText": "Actually taking a deeper look to the third point, the original implementation was not extracting all the features, but if the explicit featureStore was matching the model featureStore, it was using the model one (no logger).\nSo I agree with you, in our case, we want to use the model already existent and no logger at all.\nI am going to clean up that bit and do a new commit tomorrow", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520055346", "createdAt": "2020-11-09T19:10:45Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwOTkzMw==", "bodyText": "Ok, I have done an extensive refactor of this bit, following your scenarios guideline, I believe the code is much more readable now.\ufffd\nI added few tests as well.\nThank you very much for the insight, now that part is extremely clear.\nBefore resolving  this discussion, working on this, another consideration sparkled:\nCurrently when we use the feature logger transformer, all features are extracted (even the ones not used by the reranking model, if any).\nAre we sure we want this behavior ?\nWe could re-use the extracted feature vector  cached also for logging if we just log the features actually used by the model.\nI am just wondering why I would be interested in logging for a document, all the features in a featureStore, including potentially features just used by other models.\nThis could actually lead to confusion.\nIf you agree I create a separate Jira for that and I'll implement a solution soon, to avoid to forget and context switch.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520509933", "createdAt": "2020-11-10T12:02:01Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNjA1Ng==", "bodyText": "... I believe the code is much more readable now ... now that part is extremely clear.\n\nYes, I agree, very nice.\n\n... another consideration sparkled: ... a separate Jira for that ...\n\nInteresting points, will need to think about them a bit (next week). I agree it's unrelated i.e. not a blocker for this pull request here.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522516056", "createdAt": "2020-11-12T23:56:21Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -210,50 +216,59 @@ public void setContext(ResultContext context) {\n       }\n       \n       // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n-\n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n-\n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n-\n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n-\n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+      docsWereNotReranked = (rerankingQueries == null || rerankingQueries.length == 0);\n+      if (docsWereNotReranked) {\n+        rerankingQueries = new LTRScoringQuery[]{null};\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+      modelWeights = new LTRScoringQuery.ModelWeight[rerankingQueries.length];\n+      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+        if ((scoringQuery == null || !(scoringQuery instanceof OriginalRankingLTRScoringQuery)) && (docsWereNotReranked || (featureStoreName != null && !featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxNzc1NQ=="}, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0ODA0NzA2OnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNzoxNjowNlrOHuNoFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQxNzoxNjowNlrOHuNoFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIxOTc5OA==", "bodyText": "13/n minor: interleaveOriginalRanking=true --> model=_OriginalRanking_ assuming we're going with that special value", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518219798", "createdAt": "2020-11-05T17:16:06Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score,[interleaving]\n+\n+The output XML will include the model picked for each search result, resembling the output shown here:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":0,\n+    \"params\":{\n+      \"q\":\"test\",\n+      \"fl\":\"id,score,[interleaving]\",\n+      \"rq\":\"{!ltr model=myModelA model=myModelB reRankDocs=100}\"}},\n+  \"response\":{\"numFound\":2,\"start\":0,\"maxScore\":1.0005897,\"docs\":[\n+      {\n+        \"id\":\"GB18030TEST\",\n+        \"score\":1.0005897,\n+        \"[interleaving]\":\"myModelB\"},\n+      {\n+        \"id\":\"UTF8TEST\",\n+        \"score\":0.79656565,\n+        \"[interleaving]\":\"myModelA\"}]\n+  }}\n+----\n+\n+=== Running a Rerank Query Interleaving a model with the original ranking\n+When approaching Search Quality Evaluation with interleaving it may be useful to compare a model with the original ranking. \n+To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, with a model in input and activating the original ranking interleaving, for example:\n+\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModel interleaveOriginalRanking=true reRankDocs=100}&fl=id,score", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66139921ea61c15dc2884de80dff6d41a7e5aa"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MTI1MjU2OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRInterleavingTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoxNTozMlrOHurzrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMjoxNTozMlrOHurzrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNDI4NQ==", "bodyText": "NULL_DEREFERENCE:  object rerankingQuery last assigned on line 106 could be null and is dereferenced at line 117.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r518714285", "createdAt": "2020-11-06T12:15:32Z", "author": {"login": "sonatype-lift"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRInterleavingTransformerFactory.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.ltr.response.transform;\n+\n+import java.io.IOException;\n+import org.apache.solr.common.SolrDocument;\n+import org.apache.solr.common.params.SolrParams;\n+import org.apache.solr.common.util.NamedList;\n+import org.apache.solr.ltr.LTRInterleavingScoringQuery;\n+import org.apache.solr.ltr.LTRScoringQuery;\n+import org.apache.solr.ltr.SolrQueryRequestContextUtils;\n+import org.apache.solr.request.SolrQueryRequest;\n+import org.apache.solr.response.ResultContext;\n+import org.apache.solr.response.transform.DocTransformer;\n+import org.apache.solr.response.transform.TransformerFactory;\n+import org.apache.solr.util.SolrPluginUtils;\n+\n+public class LTRInterleavingTransformerFactory extends TransformerFactory {\n+  \n+  @Override\n+  @SuppressWarnings({\"unchecked\"})\n+  public void init(@SuppressWarnings(\"rawtypes\") NamedList args) {\n+    super.init(args);\n+    SolrPluginUtils.invokeSetters(this, args);\n+  }\n+\n+  @Override\n+  public DocTransformer create(String name, SolrParams localparams,\n+      SolrQueryRequest req) {\n+    return new InterleavingTransformer(name, req);\n+  }\n+  \n+  class InterleavingTransformer extends DocTransformer {\n+\n+    final private String name;\n+    final private SolrQueryRequest req;\n+    \n+    private LTRScoringQuery[] rerankingQueries;\n+\n+    /**\n+     * @param name\n+     *          Name of the field to be added in a document representing the\n+     *          model picked by the interleaving process\n+     */\n+    public InterleavingTransformer(String name,\n+        SolrQueryRequest req) {\n+      this.name = name;\n+      this.req = req;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+\n+    @Override\n+    public void setContext(ResultContext context) {\n+      super.setContext(context);\n+      if (context == null) {\n+        return;\n+      }\n+      if (context.getRequest() == null) {\n+        return;\n+      }\n+      rerankingQueries = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      for (int i = 0; i < rerankingQueries.length; i++) {\n+        LTRScoringQuery scoringQuery = rerankingQueries[i];\n+\n+        if (scoringQuery.getOriginalQuery() == null) {\n+          scoringQuery.setOriginalQuery(context.getQuery());\n+        }\n+        if (scoringQuery.getFeatureLogger() == null) {\n+          scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n+        }\n+        scoringQuery.setRequest(req);\n+      }\n+    }\n+\n+    @Override\n+    public void transform(SolrDocument doc, int docid, float score)\n+        throws IOException {\n+      implTransform(doc, docid);\n+    }\n+\n+    @Override\n+    public void transform(SolrDocument doc, int docid)\n+        throws IOException {\n+      implTransform(doc, docid);\n+    }\n+\n+    private void implTransform(SolrDocument doc, int docid) {\n+      LTRScoringQuery rerankingQuery = null;\n+      if (rerankingQueries.length == 1) {\n+        rerankingQuery = rerankingQueries[0];\n+      } else {\n+        for (LTRScoringQuery query : rerankingQueries) {\n+          if (((LTRInterleavingScoringQuery)query).getPickedInterleavingDocIds().contains(docid)) {\n+            rerankingQuery = query;\n+            break;\n+          }\n+        }\n+      }\n+      doc.addField(name, rerankingQuery.getScoringModelName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ba44e372222679cb1ef802263ab522476b8719a"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTM4MTcxOnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjoxMjowOFrOHv2Jog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjoxMjowOFrOHv2Jog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTkzMjMyMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, with a model in input and activating the original ranking interleaving, for example:\n          \n          \n            \n            To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, passing the special inbuilt `_OriginalRanking_` model identifier as one model and your comparison model as the other model, for example:", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519932322", "createdAt": "2020-11-09T16:12:08Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score,[interleaving]\n+\n+The output XML will include the model picked for each search result, resembling the output shown here:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":0,\n+    \"params\":{\n+      \"q\":\"test\",\n+      \"fl\":\"id,score,[interleaving]\",\n+      \"rq\":\"{!ltr model=myModelA model=myModelB reRankDocs=100}\"}},\n+  \"response\":{\"numFound\":2,\"start\":0,\"maxScore\":1.0005897,\"docs\":[\n+      {\n+        \"id\":\"GB18030TEST\",\n+        \"score\":1.0005897,\n+        \"[interleaving]\":\"myModelB\"},\n+      {\n+        \"id\":\"UTF8TEST\",\n+        \"score\":0.79656565,\n+        \"[interleaving]\":\"myModelA\"}]\n+  }}\n+----\n+\n+=== Running a Rerank Query Interleaving a model with the original ranking\n+When approaching Search Quality Evaluation with interleaving it may be useful to compare a model with the original ranking. \n+To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, with a model in input and activating the original ranking interleaving, for example:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTM5ODg4OnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjoxNTo1OVrOHv2UWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjowOTowM1rOHwZoRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTkzNTA2NA==", "bodyText": "subjective: might model=_OriginalRanking_ model=myModel be more intuitive i.e. the 'from' baseline model on the left and the 'to' alternative model on the right? (i recall that the code had an \"original ranking last\" assumption before but if that's gone there's a possibility here to swap the order)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519935064", "createdAt": "2020-11-09T16:15:59Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score,[interleaving]\n+\n+The output XML will include the model picked for each search result, resembling the output shown here:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":0,\n+    \"params\":{\n+      \"q\":\"test\",\n+      \"fl\":\"id,score,[interleaving]\",\n+      \"rq\":\"{!ltr model=myModelA model=myModelB reRankDocs=100}\"}},\n+  \"response\":{\"numFound\":2,\"start\":0,\"maxScore\":1.0005897,\"docs\":[\n+      {\n+        \"id\":\"GB18030TEST\",\n+        \"score\":1.0005897,\n+        \"[interleaving]\":\"myModelB\"},\n+      {\n+        \"id\":\"UTF8TEST\",\n+        \"score\":0.79656565,\n+        \"[interleaving]\":\"myModelA\"}]\n+  }}\n+----\n+\n+=== Running a Rerank Query Interleaving a model with the original ranking\n+When approaching Search Quality Evaluation with interleaving it may be useful to compare a model with the original ranking. \n+To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, with a model in input and activating the original ranking interleaving, for example:\n+\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModel model=_OriginalRanking_ reRankDocs=100}&fl=id,score", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUxMzYwNA==", "bodyText": "Just fixed that, it's not critical as the order is not important, but if it's more readable, let's go for it!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520513604", "createdAt": "2020-11-10T12:09:03Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score,[interleaving]\n+\n+The output XML will include the model picked for each search result, resembling the output shown here:\n+\n+[source,json]\n+----\n+{\n+  \"responseHeader\":{\n+    \"status\":0,\n+    \"QTime\":0,\n+    \"params\":{\n+      \"q\":\"test\",\n+      \"fl\":\"id,score,[interleaving]\",\n+      \"rq\":\"{!ltr model=myModelA model=myModelB reRankDocs=100}\"}},\n+  \"response\":{\"numFound\":2,\"start\":0,\"maxScore\":1.0005897,\"docs\":[\n+      {\n+        \"id\":\"GB18030TEST\",\n+        \"score\":1.0005897,\n+        \"[interleaving]\":\"myModelB\"},\n+      {\n+        \"id\":\"UTF8TEST\",\n+        \"score\":0.79656565,\n+        \"[interleaving]\":\"myModelA\"}]\n+  }}\n+----\n+\n+=== Running a Rerank Query Interleaving a model with the original ranking\n+When approaching Search Quality Evaluation with interleaving it may be useful to compare a model with the original ranking. \n+To rerank the results of a query, interleaving a model with the original ranking, add the `rq` parameter to your search, with a model in input and activating the original ranking interleaving, for example:\n+\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModel model=_OriginalRanking_ reRankDocs=100}&fl=id,score", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTkzNTA2NA=="}, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTQ1ODcyOnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjoyODo0NFrOHv25Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjoxMjozMVrOHwZwDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk0NDQ2Mg==", "bodyText": "question: if myModelA had [ doc1, doc2, doc3 ] document order and myModelB had [ doc1, doc3, doc2 ] document order i.e. there was agreement between the models re: the first document, will [interleaving] return (1) randomly myModelA or myModelB depending on how the picking actually happened or will it return (2) something else e.g. myModelA,myModelB (if myModelA actually picked and myModelB agreed) or myModelB,myModelA (if myModelB actually picked and myModelA agreed) or will it return (3) neither since in a way neither of them picked the document since they both agreed on it?\nanswer-ish: from recalling the implementation the answer is (1) i think though from a user's perspective perhaps it might be nice here to clarify here somehow around that? a subtle aspect being (if i understand things right) that [features] and [interleaving] could both be requested in the fl and whilst myModelA and myModelB might have agreed that doc1 should be the first document they might have used very different features to arrived at that conclusion and their score value could also differ.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519944462", "createdAt": "2020-11-09T16:28:44Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUxNTU5Ng==", "bodyText": "1 is what is currently implemented and it aligns with the TeamDraft Interleaving papers and evaluation methods.\nYour observation is interesting though, but to implement that we should invent a new type of Interleaving algorithm that will do that when interleaving the results and will evaluate the user clicks accordingly later on.\nYour observation on the features to log applies as well.\nSo far  no change is needed in this regard in my opinion.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520515596", "createdAt": "2020-11-10T12:12:31Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -247,6 +254,81 @@ The output XML will include feature values as a comma-separated list, resembling\n   }}\n ----\n \n+=== Running a Rerank Query Interleaving Two Models\n+\n+To rerank the results of a query, interleaving two models (myModelA, myModelB) add the `rq` parameter to your search, passing two models in input, for example:\n+\n+[source,text]\n+http://localhost:8983/solr/techproducts/query?q=test&rq={!ltr model=myModelA model=myModelB reRankDocs=100}&fl=id,score\n+\n+To obtain the model that interleaving picked for a search result, computed during reranking, add `[interleaving]` to the `fl` parameter, for example:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk0NDQ2Mg=="}, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTQ2NjE5OnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjozMDoxOVrOHv29nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjozMDoxOVrOHv29nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk0NTYyOQ==", "bodyText": "minor/subjective: could shorten since there's no parameters\n<transformer name=\"interleaving\" class=\"org.apache.solr.ltr.response.transform.LTRInterleavingTransformerFactory\"/>", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519945629", "createdAt": "2020-11-09T16:30:19Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -418,6 +500,14 @@ Learning-To-Rank is a contrib module and therefore its plugins must be configure\n </transformer>\n ----\n \n+* Declaration of the `[interleaving]` transformer.\n++\n+[source,xml]\n+----\n+<transformer name=\"interleaving\" class=\"org.apache.solr.ltr.response.transform.LTRInterleavingTransformerFactory\">\n+</transformer>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTQ5NjMyOnYy", "diffSide": "RIGHT", "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjozNzowM1rOHv3QCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjozNzowM1rOHv3QCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk1MDM0NQ==", "bodyText": "We've got \"... Contributions for further models, features and normalizers are welcome. ...\" above, any thoughts on adding \"interleaving algorithms\" to that list?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519950345", "createdAt": "2020-11-09T16:37:03Z", "author": {"login": "cpoerschke"}, "path": "solr/solr-ref-guide/src/learning-to-rank.adoc", "diffHunk": "@@ -779,3 +869,7 @@ The feature store and the model store are both <<managed-resources.adoc#managed-\n * \"Learning to Rank in Solr\" presentation at Lucene/Solr Revolution 2015 in Austin:\n ** Slides: http://www.slideshare.net/lucidworks/learning-to-rank-in-solr-presented-by-michael-nilsson-diego-ceccarelli-bloomberg-lp\n ** Video: https://www.youtube.com/watch?v=M7BKwJoh96s\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTU3NDU0OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjo1MToxMFrOHv4BXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjo1MToxMFrOHv4BXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk2Mjk3Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * Here the authors implement a method similar to the way in which captains select their players in team-matches.\n          \n          \n            \n             * Team Draft Interleaving implements a method similar to the way in which captains select their players in team-matches.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519962972", "createdAt": "2020-11-09T16:51:10Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Here the authors implement a method similar to the way in which captains select their players in team-matches.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTYwMDc4OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjo1NTo0MlrOHv4SUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNjo1NTo0MlrOHv4SUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk2NzMxNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * It has also proved to overcome an issue of the previous implemented approach, Balanced interleaving, in determining the winning model[4].\n          \n          \n            \n             * \"Team draft interleaving\" has also proved to overcome an issue of the \"Balanced interleaving\" approach, in determining the winning model[4].\n          \n      \n    \n    \n  \n\nSuggest to avoid the \"previous implemented approach\" wording since it could be misinterpreted to mean that Solr previously had a BalancedInterleaving class.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519967315", "createdAt": "2020-11-09T16:55:42Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Here the authors implement a method similar to the way in which captains select their players in team-matches.\n+ * Team Draft Interleaving produces a fair distribution of ranking models\u2019 elements in the final interleaved list.\n+ * It has also proved to overcome an issue of the previous implemented approach, Balanced interleaving, in determining the winning model[4].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1OTY0MzM3OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNzowNDo1OVrOHv4sGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzo1NToyM1rOHyT1Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MzkxNA==", "bodyText": "Wondering re: interleaved.contains(elementToCheck) vs. interleaved.contains(elementToCheck).doc here. I note that the new ScoreDoc.equals method considers doc and shardIndex but not score which makes sense in the context here but for ScoreDoc alone is perhaps less obvious. The interleavingPicks use doc only (i.e. not doc+shardIndex). I haven't fully thought it through but intuitively if doc+shardIndex is required here then would it not also be required for the interleaving picks to avoid a strange edge case when potentially modelA picks \"doc 1 from shard 1\" and modelB picks \"doc 1 from shard 2\"?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r519973914", "createdAt": "2020-11-09T17:04:59Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Here the authors implement a method similar to the way in which captains select their players in team-matches.\n+ * Team Draft Interleaving produces a fair distribution of ranking models\u2019 elements in the final interleaved list.\n+ * It has also proved to overcome an issue of the previous implemented approach, Balanced interleaving, in determining the winning model[4].\n+ * <p>\n+ * [1] T. Joachims. Optimizing search engines using clickthrough data. KDD (2002)\n+ * [2] T.Joachims.Evaluatingretrievalperformanceusingclickthroughdata.InJ.Franke, G. Nakhaeizadeh, and I. Renz, editors,\n+ * Text Mining, pages 79\u201396. Physica/Springer (2003)\n+ * [3] F. Radlinski, M. Kurup, and T. Joachims. How does clickthrough data reflect re-\n+ * trieval quality? In CIKM, pages 43\u201352. ACM Press (2008)\n+ * [4] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+ * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+ */\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");\n+    if (seed == null) {\n+      RANDOM = new Random();\n+    } else {\n+      RANDOM = new Random(seed.hashCode());\n+    }\n+  }\n+\n+  /**\n+   * Team Draft Interleaving considers two ranking models: modelA and modelB.\n+   * For a given query, each model returns its ranked list of documents La = (a1,a2,...) and Lb = (b1, b2, ...).\n+   * The algorithm creates a unique ranked list I = (i1, i2, ...).\n+   * This list is created by interleaving elements from the two lists la and lb as described by Chapelle et al.[1].\n+   * Each element Ij is labelled TeamA if it is selected from La and TeamB if it is selected from Lb.\n+   * <p>\n+   * [1] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+   * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+   * <p>\n+   * Assumptions:\n+   * - rerankedA and rerankedB has the same length.\n+   * They contains the same search results, ranked differently by two ranking models\n+   * - each reranked list can not contain the same search result more than once.\n+   *\n+   * @param rerankedA a ranked list of search results produced by a ranking model A\n+   * @param rerankedB a ranked list of search results produced by a ranking model B\n+   * @return the interleaved ranking list\n+   */\n+  public InterleavingResult interleave(ScoreDoc[] rerankedA, ScoreDoc[] rerankedB) {\n+    LinkedHashSet<ScoreDoc> interleavedResults = new LinkedHashSet<>();\n+    ScoreDoc[] interleavedResultArray = new ScoreDoc[rerankedA.length];\n+    ArrayList<Set<Integer>> interleavingPicks = new ArrayList<>(2);\n+    Set<Integer> teamA = new HashSet<>();\n+    Set<Integer> teamB = new HashSet<>();\n+    int topN = rerankedA.length;\n+    int indexA = 0, indexB = 0;\n+\n+    while (interleavedResults.size() < topN && indexA < rerankedA.length && indexB < rerankedB.length) {\n+      if(teamA.size()<teamB.size() || (teamA.size()==teamB.size() && !RANDOM.nextBoolean())){\n+        indexA = updateIndex(interleavedResults,indexA,rerankedA);\n+        interleavedResults.add(rerankedA[indexA]);\n+        teamA.add(rerankedA[indexA].doc);\n+        indexA++;\n+      } else{\n+        indexB = updateIndex(interleavedResults,indexB,rerankedB);\n+        interleavedResults.add(rerankedB[indexB]);\n+        teamB.add(rerankedB[indexB].doc);\n+        indexB++;\n+      }\n+    }\n+    interleavingPicks.add(teamA);\n+    interleavingPicks.add(teamB);\n+    interleavedResultArray = interleavedResults.toArray(interleavedResultArray);\n+\n+    return new InterleavingResult(interleavedResultArray,interleavingPicks);\n+  }\n+\n+  private int updateIndex(LinkedHashSet<ScoreDoc> interleaved, int index, ScoreDoc[] reranked) {\n+    boolean foundElementToAdd = false;\n+    while (index < reranked.length && !foundElementToAdd) {\n+      ScoreDoc elementToCheck = reranked[index];\n+      if (interleaved.contains(elementToCheck)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc1NjE1Mw==", "bodyText": "You are right, ScoreDoc.equals alone may be less obvious.\nThe reason I originally did that was to support sharding, but to be honest, currently Interleaving doesn't support sharding anyway (and adding the support is an extremely difficult topic that would require some serious thinking).\nSo I rolled back the ScoreDoc, and added an additional data structure on the doc Id, to do the contains.\nLet me know if it is better!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520756153", "createdAt": "2020-11-10T17:51:19Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Here the authors implement a method similar to the way in which captains select their players in team-matches.\n+ * Team Draft Interleaving produces a fair distribution of ranking models\u2019 elements in the final interleaved list.\n+ * It has also proved to overcome an issue of the previous implemented approach, Balanced interleaving, in determining the winning model[4].\n+ * <p>\n+ * [1] T. Joachims. Optimizing search engines using clickthrough data. KDD (2002)\n+ * [2] T.Joachims.Evaluatingretrievalperformanceusingclickthroughdata.InJ.Franke, G. Nakhaeizadeh, and I. Renz, editors,\n+ * Text Mining, pages 79\u201396. Physica/Springer (2003)\n+ * [3] F. Radlinski, M. Kurup, and T. Joachims. How does clickthrough data reflect re-\n+ * trieval quality? In CIKM, pages 43\u201352. ACM Press (2008)\n+ * [4] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+ * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+ */\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");\n+    if (seed == null) {\n+      RANDOM = new Random();\n+    } else {\n+      RANDOM = new Random(seed.hashCode());\n+    }\n+  }\n+\n+  /**\n+   * Team Draft Interleaving considers two ranking models: modelA and modelB.\n+   * For a given query, each model returns its ranked list of documents La = (a1,a2,...) and Lb = (b1, b2, ...).\n+   * The algorithm creates a unique ranked list I = (i1, i2, ...).\n+   * This list is created by interleaving elements from the two lists la and lb as described by Chapelle et al.[1].\n+   * Each element Ij is labelled TeamA if it is selected from La and TeamB if it is selected from Lb.\n+   * <p>\n+   * [1] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+   * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+   * <p>\n+   * Assumptions:\n+   * - rerankedA and rerankedB has the same length.\n+   * They contains the same search results, ranked differently by two ranking models\n+   * - each reranked list can not contain the same search result more than once.\n+   *\n+   * @param rerankedA a ranked list of search results produced by a ranking model A\n+   * @param rerankedB a ranked list of search results produced by a ranking model B\n+   * @return the interleaved ranking list\n+   */\n+  public InterleavingResult interleave(ScoreDoc[] rerankedA, ScoreDoc[] rerankedB) {\n+    LinkedHashSet<ScoreDoc> interleavedResults = new LinkedHashSet<>();\n+    ScoreDoc[] interleavedResultArray = new ScoreDoc[rerankedA.length];\n+    ArrayList<Set<Integer>> interleavingPicks = new ArrayList<>(2);\n+    Set<Integer> teamA = new HashSet<>();\n+    Set<Integer> teamB = new HashSet<>();\n+    int topN = rerankedA.length;\n+    int indexA = 0, indexB = 0;\n+\n+    while (interleavedResults.size() < topN && indexA < rerankedA.length && indexB < rerankedB.length) {\n+      if(teamA.size()<teamB.size() || (teamA.size()==teamB.size() && !RANDOM.nextBoolean())){\n+        indexA = updateIndex(interleavedResults,indexA,rerankedA);\n+        interleavedResults.add(rerankedA[indexA]);\n+        teamA.add(rerankedA[indexA].doc);\n+        indexA++;\n+      } else{\n+        indexB = updateIndex(interleavedResults,indexB,rerankedB);\n+        interleavedResults.add(rerankedB[indexB]);\n+        teamB.add(rerankedB[indexB].doc);\n+        indexB++;\n+      }\n+    }\n+    interleavingPicks.add(teamA);\n+    interleavingPicks.add(teamB);\n+    interleavedResultArray = interleavedResults.toArray(interleavedResultArray);\n+\n+    return new InterleavingResult(interleavedResultArray,interleavingPicks);\n+  }\n+\n+  private int updateIndex(LinkedHashSet<ScoreDoc> interleaved, int index, ScoreDoc[] reranked) {\n+    boolean foundElementToAdd = false;\n+    while (index < reranked.length && !foundElementToAdd) {\n+      ScoreDoc elementToCheck = reranked[index];\n+      if (interleaved.contains(elementToCheck)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MzkxNA=="}, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNTc0Mw==", "bodyText": "... currently Interleaving doesn't support sharding ...\n\nLet's include that in the documentation somehow, e.g. cpoerschke@7edd600 say.\n\n... So I rolled back the ScoreDoc ... Let me know if it is better!\n\nYes it is, thanks!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522515743", "createdAt": "2020-11-12T23:55:23Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Here the authors implement a method similar to the way in which captains select their players in team-matches.\n+ * Team Draft Interleaving produces a fair distribution of ranking models\u2019 elements in the final interleaved list.\n+ * It has also proved to overcome an issue of the previous implemented approach, Balanced interleaving, in determining the winning model[4].\n+ * <p>\n+ * [1] T. Joachims. Optimizing search engines using clickthrough data. KDD (2002)\n+ * [2] T.Joachims.Evaluatingretrievalperformanceusingclickthroughdata.InJ.Franke, G. Nakhaeizadeh, and I. Renz, editors,\n+ * Text Mining, pages 79\u201396. Physica/Springer (2003)\n+ * [3] F. Radlinski, M. Kurup, and T. Joachims. How does clickthrough data reflect re-\n+ * trieval quality? In CIKM, pages 43\u201352. ACM Press (2008)\n+ * [4] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+ * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+ */\n+public class TeamDraftInterleaving implements Interleaving{\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");\n+    if (seed == null) {\n+      RANDOM = new Random();\n+    } else {\n+      RANDOM = new Random(seed.hashCode());\n+    }\n+  }\n+\n+  /**\n+   * Team Draft Interleaving considers two ranking models: modelA and modelB.\n+   * For a given query, each model returns its ranked list of documents La = (a1,a2,...) and Lb = (b1, b2, ...).\n+   * The algorithm creates a unique ranked list I = (i1, i2, ...).\n+   * This list is created by interleaving elements from the two lists la and lb as described by Chapelle et al.[1].\n+   * Each element Ij is labelled TeamA if it is selected from La and TeamB if it is selected from Lb.\n+   * <p>\n+   * [1] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+   * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+   * <p>\n+   * Assumptions:\n+   * - rerankedA and rerankedB has the same length.\n+   * They contains the same search results, ranked differently by two ranking models\n+   * - each reranked list can not contain the same search result more than once.\n+   *\n+   * @param rerankedA a ranked list of search results produced by a ranking model A\n+   * @param rerankedB a ranked list of search results produced by a ranking model B\n+   * @return the interleaved ranking list\n+   */\n+  public InterleavingResult interleave(ScoreDoc[] rerankedA, ScoreDoc[] rerankedB) {\n+    LinkedHashSet<ScoreDoc> interleavedResults = new LinkedHashSet<>();\n+    ScoreDoc[] interleavedResultArray = new ScoreDoc[rerankedA.length];\n+    ArrayList<Set<Integer>> interleavingPicks = new ArrayList<>(2);\n+    Set<Integer> teamA = new HashSet<>();\n+    Set<Integer> teamB = new HashSet<>();\n+    int topN = rerankedA.length;\n+    int indexA = 0, indexB = 0;\n+\n+    while (interleavedResults.size() < topN && indexA < rerankedA.length && indexB < rerankedB.length) {\n+      if(teamA.size()<teamB.size() || (teamA.size()==teamB.size() && !RANDOM.nextBoolean())){\n+        indexA = updateIndex(interleavedResults,indexA,rerankedA);\n+        interleavedResults.add(rerankedA[indexA]);\n+        teamA.add(rerankedA[indexA].doc);\n+        indexA++;\n+      } else{\n+        indexB = updateIndex(interleavedResults,indexB,rerankedB);\n+        interleavedResults.add(rerankedB[indexB]);\n+        teamB.add(rerankedB[indexB].doc);\n+        indexB++;\n+      }\n+    }\n+    interleavingPicks.add(teamA);\n+    interleavingPicks.add(teamB);\n+    interleavedResultArray = interleavedResults.toArray(interleavedResultArray);\n+\n+    return new InterleavingResult(interleavedResultArray,interleavingPicks);\n+  }\n+\n+  private int updateIndex(LinkedHashSet<ScoreDoc> interleaved, int index, ScoreDoc[] reranked) {\n+    boolean foundElementToAdd = false;\n+    while (index < reranked.length && !foundElementToAdd) {\n+      ScoreDoc elementToCheck = reranked[index];\n+      if (interleaved.contains(elementToCheck)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MzkxNA=="}, "originalCommit": {"oid": "c4f87f7030218df9d7a2af0fdc3e089e68a6db07"}, "originalPosition": 109}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2MzU1MTUwOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/algorithms/TeamDraftInterleaving.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMzo1NDoyN1rOHwdmGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMzo1NDoyN1rOHwdmGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU3ODU4Ng==", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r520578586", "createdAt": "2020-11-10T13:54:27Z", "author": {"login": "sonatype-lift"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/interleaving/algorithms/TeamDraftInterleaving.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.ltr.interleaving.algorithms;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.LinkedHashSet;\n+import java.util.Random;\n+import java.util.Set;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.solr.ltr.interleaving.Interleaving;\n+import org.apache.solr.ltr.interleaving.InterleavingResult;\n+\n+/**\n+ * Interleaving was introduced the first time by Joachims in [1, 2].\n+ * Team Draft Interleaving is among the most successful and used interleaving approaches[3].\n+ * Team Draft Interleaving implements a method similar to the way in which captains select their players in team-matches.\n+ * Team Draft Interleaving produces a fair distribution of ranking models\u2019 elements in the final interleaved list.\n+ * \"Team draft interleaving\" has also proved to overcome an issue of the \"Balanced interleaving\" approach, in determining the winning model[4].\n+ * <p>\n+ * [1] T. Joachims. Optimizing search engines using clickthrough data. KDD (2002)\n+ * [2] T.Joachims.Evaluatingretrievalperformanceusingclickthroughdata.InJ.Franke, G. Nakhaeizadeh, and I. Renz, editors,\n+ * Text Mining, pages 79\u201396. Physica/Springer (2003)\n+ * [3] F. Radlinski, M. Kurup, and T. Joachims. How does clickthrough data reflect re-\n+ * trieval quality? In CIKM, pages 43\u201352. ACM Press (2008)\n+ * [4] O. Chapelle, T. Joachims, F. Radlinski, and Y. Yue.\n+ * Large-scale validation and analysis of interleaved search evaluation. ACM TOIS, 30(1):1\u201341, Feb. (2012)\n+ */\n+public class TeamDraftInterleaving implements Interleaving {\n+  public static Random RANDOM;\n+\n+  static {\n+    // We try to make things reproducible in the context of our tests by initializing the random instance\n+    // based on the current seed\n+    String seed = System.getProperty(\"tests.seed\");\n+    if (seed == null) {\n+      RANDOM = new Random();\n+    } else {\n+      RANDOM = new Random(seed.hashCode());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4189b9dd115bfc9a29c2f00d4c057716135c207b"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTYyNzIyOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMjo1MDozMlrOHyR0GA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMjo1MDozMlrOHyR0GA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ4MjcxMg==", "bodyText": "LTRFeatureLoggerTransformerFactory.1 - loggingModel is a member of of the transformer factory here.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522482712", "createdAt": "2020-11-12T22:50:32Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -79,6 +81,7 @@\n   private char csvFeatureSeparator = CSVFeatureLogger.DEFAULT_FEATURE_SEPARATOR;\n \n   private LTRThreadModule threadManager = null;\n+  private LoggingModel loggingModel = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTY1MjIxOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMjo1NjoxMFrOHySENg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMjo1NjoxMFrOHySENg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ4NjgzOA==", "bodyText": "LTRFeatureLoggerTransformerFactory.2 - loggingModel being a member of the transformer factory gives it SolrCore lifetime/scope but here it's initialised based on per-request parameters. If multiple threads use the same transformer factory object concurrently then they might trampled upon each other. cpoerschke@4912dac proposes to not have the logging model as a member of the transformer factory.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522486838", "createdAt": "2020-11-12T22:56:10Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTY2OTI1OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzowMDoyMlrOHySOsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzowMDoyMlrOHySOsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ4OTUyMw==", "bodyText": "LTRFeatureLoggerTransformerFactory.3 - I noted that threadManager here is an existing member of the transformer factory and it is initialised as part of request processing. Since there's no locking or anything there could be a chance that multiple threads concurrently call threadManager.setExecutor() but the argument to the set call is not specific to the request i.e. all requests would set the same thing (whereas for the logging model different requests could supply a different feature store name via the fl=[feature store=...] parameter).", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522489523", "createdAt": "2020-11-12T23:00:22Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTY3Njk5OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzowMzoyM1rOHySTSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxNzoyMDoxNVrOHy3piA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MDY5OQ==", "bodyText": "LTRFeatureLoggerTransformerFactory.4 - Very nice overview of the different code paths here. cpoerschke@3a61287 suggests some tweaks to the implementation, I will annotate comments re: my thinking behind those suggestions. Let me know what you think?", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522490699", "createdAt": "2020-11-12T23:03:23Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEwMjYwMA==", "bodyText": "Liked them! Will push them soon", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r523102600", "createdAt": "2020-11-13T17:20:15Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MDY5OQ=="}, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTY4ODM5OnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzowNzo0N1rOHySZ9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzowNzo0N1rOHySZ9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MjQwNA==", "bodyText": "LTRFeatureLoggerTransformerFactory.5 - the rerankingQuery here could be an OriginalRankingLTRScoringQuery object which inherently has no feature store. The implementation here works because it relies on rerankingQuery.getScoringModel() returning null for OriginalRankingLTRScoringQuery objects and because isModelMatchingFeatureStore checks model null-ness. This is very subtle and it could be made more explicit for code clarity.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522492404", "createdAt": "2020-11-12T23:07:47Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */\n+    private void setupRerankingQueriesForLogging(LTRScoringQuery[] rerankingQueriesFromContext, String transformerFeatureStore, Map<String, String[]> transformerExternalFeatureInfo) {\n+      if (docsWereNotReranked) { //no reranking query\n+        LTRScoringQuery loggingQuery = new LTRScoringQuery(loggingModel,\n+            transformerExternalFeatureInfo,\n+            true,\n+            threadManager);\n+        rerankingQueries = new LTRScoringQuery[]{loggingQuery};\n+      } else {\n+        rerankingQueries = new LTRScoringQuery[rerankingQueriesFromContext.length];\n+        System.arraycopy(rerankingQueriesFromContext, 0, rerankingQueries, 0, rerankingQueriesFromContext.length);\n+\n+        if (transformerFeatureStore != null) {// explicit feature store for the transformer\n+          LTRScoringModel matchingRerankingModel = null;\n+          for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+            if (isModelMatchingFeatureStore(transformerFeatureStore, rerankingQuery.getScoringModel())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTY5NTAxOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoxMDoyNVrOHySd6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxNzoyMDo0NlrOHy3qiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MzQxNw==", "bodyText": "LTRFeatureLoggerTransformerFactory.6 - the reranking queries from the context were copied and now they are being modified. The \"why copy-and-modify instead construct-a-new-one?\" question may arise for code readers.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522493417", "createdAt": "2020-11-12T23:10:25Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */\n+    private void setupRerankingQueriesForLogging(LTRScoringQuery[] rerankingQueriesFromContext, String transformerFeatureStore, Map<String, String[]> transformerExternalFeatureInfo) {\n+      if (docsWereNotReranked) { //no reranking query\n+        LTRScoringQuery loggingQuery = new LTRScoringQuery(loggingModel,\n+            transformerExternalFeatureInfo,\n+            true,\n+            threadManager);\n+        rerankingQueries = new LTRScoringQuery[]{loggingQuery};\n+      } else {\n+        rerankingQueries = new LTRScoringQuery[rerankingQueriesFromContext.length];\n+        System.arraycopy(rerankingQueriesFromContext, 0, rerankingQueries, 0, rerankingQueriesFromContext.length);\n+\n+        if (transformerFeatureStore != null) {// explicit feature store for the transformer\n+          LTRScoringModel matchingRerankingModel = null;\n+          for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+            if (isModelMatchingFeatureStore(transformerFeatureStore, rerankingQuery.getScoringModel())) {\n+              matchingRerankingModel = rerankingQuery.getScoringModel();\n+            }\n+          }\n+          if (matchingRerankingModel != null) {//one of the LTR query model can be re-used\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(matchingRerankingModel);\n+            }\n+          } else {\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(loggingModel);\n+              rerankingQuery.setExtractAllFeatures(true);\n+              rerankingQuery.setEfi(transformerExternalFeatureInfo);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3NDY2Mg==", "bodyText": "LTRScoringQuery queries may be LTRInterleavingScoringQuery, containing the picked document Ids we don't want to lose", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r523074662", "createdAt": "2020-11-13T16:48:42Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */\n+    private void setupRerankingQueriesForLogging(LTRScoringQuery[] rerankingQueriesFromContext, String transformerFeatureStore, Map<String, String[]> transformerExternalFeatureInfo) {\n+      if (docsWereNotReranked) { //no reranking query\n+        LTRScoringQuery loggingQuery = new LTRScoringQuery(loggingModel,\n+            transformerExternalFeatureInfo,\n+            true,\n+            threadManager);\n+        rerankingQueries = new LTRScoringQuery[]{loggingQuery};\n+      } else {\n+        rerankingQueries = new LTRScoringQuery[rerankingQueriesFromContext.length];\n+        System.arraycopy(rerankingQueriesFromContext, 0, rerankingQueries, 0, rerankingQueriesFromContext.length);\n+\n+        if (transformerFeatureStore != null) {// explicit feature store for the transformer\n+          LTRScoringModel matchingRerankingModel = null;\n+          for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+            if (isModelMatchingFeatureStore(transformerFeatureStore, rerankingQuery.getScoringModel())) {\n+              matchingRerankingModel = rerankingQuery.getScoringModel();\n+            }\n+          }\n+          if (matchingRerankingModel != null) {//one of the LTR query model can be re-used\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(matchingRerankingModel);\n+            }\n+          } else {\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(loggingModel);\n+              rerankingQuery.setExtractAllFeatures(true);\n+              rerankingQuery.setEfi(transformerExternalFeatureInfo);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MzQxNw=="}, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEwMjg1Nw==", "bodyText": "but this is solved with the queries from context :)", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r523102857", "createdAt": "2020-11-13T17:20:46Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -208,55 +216,116 @@ public void setContext(ResultContext context) {\n       if (threadManager != null) {\n         threadManager.setExecutor(context.getRequest().getCore().getCoreContainer().getUpdateShardHandler().getUpdateExecutor());\n       }\n-      \n-      // Setup LTRScoringQuery\n-      scoringQuery = SolrQueryRequestContextUtils.getScoringQuery(req);\n-      docsWereNotReranked = (scoringQuery == null);\n-      String featureStoreName = SolrQueryRequestContextUtils.getFvStoreName(req);\n-      if (docsWereNotReranked || (featureStoreName != null && (!featureStoreName.equals(scoringQuery.getScoringModel().getFeatureStoreName())))) {\n-        // if store is set in the transformer we should overwrite the logger\n \n-        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n+      LTRScoringQuery[] rerankingQueriesFromContext = SolrQueryRequestContextUtils.getScoringQueries(req);\n+      docsWereNotReranked = (rerankingQueriesFromContext == null || rerankingQueriesFromContext.length == 0);\n+      String transformerFeatureStore = SolrQueryRequestContextUtils.getFvStoreName(req);\n+      Map<String, String[]> transformerExternalFeatureInfo = LTRQParserPlugin.extractEFIParams(localparams);\n \n-        final FeatureStore store = fr.getFeatureStore(featureStoreName);\n-        featureStoreName = store.getName(); // if featureStoreName was null before this gets actual name\n-\n-        try {\n-          final LoggingModel lm = new LoggingModel(loggingModelName,\n-              featureStoreName, store.getFeatures());\n+      initLoggingModel(transformerFeatureStore);\n+      setupRerankingQueriesForLogging(rerankingQueriesFromContext, transformerFeatureStore, transformerExternalFeatureInfo);\n+      setupRerankingWeightsForLogging(context);\n+    }\n+    \n+    private boolean isModelMatchingFeatureStore(String featureStoreName, LTRScoringModel model) {\n+      return model != null && featureStoreName.equals(model.getFeatureStoreName());\n+    }\n \n-          scoringQuery = new LTRScoringQuery(lm,\n-              LTRQParserPlugin.extractEFIParams(localparams),\n-              true,\n-              threadManager); // request feature weights to be created for all features\n+    /**\n+     * The loggingModel is an empty model that is just used to extract the features\n+     * and log them\n+     * @param transformerFeatureStore the explicit transformer feature store\n+     */\n+    private void initLoggingModel(String transformerFeatureStore) {\n+      if (transformerFeatureStore == null || !isModelMatchingFeatureStore(transformerFeatureStore, loggingModel)) {\n+        // if store is set in the transformer we should overwrite the logger\n+        final ManagedFeatureStore fr = ManagedFeatureStore.getManagedFeatureStore(req.getCore());\n \n-        }catch (final Exception e) {\n-          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n-              \"retrieving the feature store \"+featureStoreName, e);\n-        }\n-      }\n+        final FeatureStore store = fr.getFeatureStore(transformerFeatureStore);\n+        transformerFeatureStore = store.getName(); // if featureStoreName was null before this gets actual name\n \n-      if (scoringQuery.getOriginalQuery() == null) {\n-        scoringQuery.setOriginalQuery(context.getQuery());\n+        loggingModel = new LoggingModel(loggingModelName,\n+            transformerFeatureStore, store.getFeatures());\n       }\n-      if (scoringQuery.getFeatureLogger() == null){\n-        scoringQuery.setFeatureLogger( SolrQueryRequestContextUtils.getFeatureLogger(req) );\n-      }\n-      scoringQuery.setRequest(req);\n-\n-      featureLogger = scoringQuery.getFeatureLogger();\n+    }\n \n-      try {\n-        modelWeight = scoringQuery.createWeight(searcher, ScoreMode.COMPLETE, 1f);\n-      } catch (final IOException e) {\n-        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e.getMessage(), e);\n+    /**\n+     * When preparing the reranking queries for logging features various scenarios apply:\n+     * \n+     * No Reranking \n+     * There is the need of a logger model from the default feature store/ the explicit feature store passed\n+     * to extract the feature vector\n+     * \n+     * Re Ranking\n+     * 1) If no explicit feature store is passed, the models for each reranking query can be safely re-used\n+     * the feature vector can be fetched from the feature vector cache.\n+     * 2) If an explicit feature store is passed, and no reranking query uses a model from that featureStore,\n+     * There is the need of a logger model to extract the feature vector\n+     * 3) If an explicit feature store is passed, and there is a reranking query that uses a model from that featureStore,\n+     * It can be re-used\n+     * \n+     * @param rerankingQueriesFromContext reranking queries\n+     * @param transformerFeatureStore explicit feature store for the transformer\n+     * @param transformerExternalFeatureInfo explicit efi for the transformer\n+     */\n+    private void setupRerankingQueriesForLogging(LTRScoringQuery[] rerankingQueriesFromContext, String transformerFeatureStore, Map<String, String[]> transformerExternalFeatureInfo) {\n+      if (docsWereNotReranked) { //no reranking query\n+        LTRScoringQuery loggingQuery = new LTRScoringQuery(loggingModel,\n+            transformerExternalFeatureInfo,\n+            true,\n+            threadManager);\n+        rerankingQueries = new LTRScoringQuery[]{loggingQuery};\n+      } else {\n+        rerankingQueries = new LTRScoringQuery[rerankingQueriesFromContext.length];\n+        System.arraycopy(rerankingQueriesFromContext, 0, rerankingQueries, 0, rerankingQueriesFromContext.length);\n+\n+        if (transformerFeatureStore != null) {// explicit feature store for the transformer\n+          LTRScoringModel matchingRerankingModel = null;\n+          for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+            if (isModelMatchingFeatureStore(transformerFeatureStore, rerankingQuery.getScoringModel())) {\n+              matchingRerankingModel = rerankingQuery.getScoringModel();\n+            }\n+          }\n+          if (matchingRerankingModel != null) {//one of the LTR query model can be re-used\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(matchingRerankingModel);\n+            }\n+          } else {\n+            for (LTRScoringQuery rerankingQuery : rerankingQueries) {\n+              rerankingQuery.setLtrScoringModel(loggingModel);\n+              rerankingQuery.setExtractAllFeatures(true);\n+              rerankingQuery.setEfi(transformerExternalFeatureInfo);\n+            }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5MzQxNw=="}, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTcxMjYxOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoxNzoxM1rOHySn7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxNzoyMToxM1rOHy3rrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5NTk4MA==", "bodyText": "LTRFeatureLoggerTransformerFactory.7 - here now the reranking queries that were copied from the context (and modified) are being used. It's very subtle but questions that may arise for code readers are (a) whether or not the copy happened before or after the picked interleaving doc ids were set, and/or (b) if the copy is shallow so that the query from the context and the query in the transformer share the same underlying picked ids object, and/or (c) if any shared underlying picked ids object remains shared when 'set' is called on it. cpoerschke@3a61287 proposes to introduce (alongside the rerankingQueries array) a rerankingQueriesFromContext array which is used only for the \"picked doc id\" check which would avoid the \"was it copied before or after the picked ids were set\" questions. An extra implementation subtlety is as follows: get-picked-interleaving-doc-ids applies only to interleaving queries and because of that the \"copy-and-modify\" approach was required for rerankingQueries before but if the already existing queries from the context can be used for the picked-or-not check then the rerankingQueries can follow a \"construct-a-new-one\" approach instead with the constructed queries all being of the same LTRScoringQuery base class type.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522495980", "createdAt": "2020-11-12T23:17:13Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -271,17 +340,24 @@ public void transform(SolrDocument doc, int docid)\n \n     private void implTransform(SolrDocument doc, int docid, Float score)\n         throws IOException {\n-      Object fv = featureLogger.getFeatureVector(docid, scoringQuery, searcher);\n-      if (fv == null) { // FV for this document was not in the cache\n-        fv = featureLogger.makeFeatureVector(\n-            LTRRescorer.extractFeaturesInfo(\n-                modelWeight,\n-                docid,\n-                (docsWereNotReranked ? score : null),\n-                leafContexts));\n+      LTRScoringQuery rerankingQuery = rerankingQueries[0];\n+      LTRScoringQuery.ModelWeight rerankingModelWeight = modelWeights[0];\n+      if (rerankingQueries.length > 1 && ((LTRInterleavingScoringQuery)rerankingQueries[1]).getPickedInterleavingDocIds().contains(docid)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 205}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEwMzE1MA==", "bodyText": "Perfectly splendid! I agree!", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r523103150", "createdAt": "2020-11-13T17:21:13Z", "author": {"login": "alessandrobenedetti"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/response/transform/LTRFeatureLoggerTransformerFactory.java", "diffHunk": "@@ -271,17 +340,24 @@ public void transform(SolrDocument doc, int docid)\n \n     private void implTransform(SolrDocument doc, int docid, Float score)\n         throws IOException {\n-      Object fv = featureLogger.getFeatureVector(docid, scoringQuery, searcher);\n-      if (fv == null) { // FV for this document was not in the cache\n-        fv = featureLogger.makeFeatureVector(\n-            LTRRescorer.extractFeaturesInfo(\n-                modelWeight,\n-                docid,\n-                (docsWereNotReranked ? score : null),\n-                leafContexts));\n+      LTRScoringQuery rerankingQuery = rerankingQueries[0];\n+      LTRScoringQuery.ModelWeight rerankingModelWeight = modelWeights[0];\n+      if (rerankingQueries.length > 1 && ((LTRInterleavingScoringQuery)rerankingQueries[1]).getPickedInterleavingDocIds().contains(docid)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5NTk4MA=="}, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 205}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTcyMzIzOnYy", "diffSide": "RIGHT", "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRScoringQuery.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyMToyOVrOHySuEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzoyMToyOVrOHySuEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ5NzU1Mw==", "bodyText": "LTRFeatureLoggerTransformerFactory.8 - with a rerankedQueriesFromContext + rerankedQueries approach in the feature logger transformer the setters here would not be needed.", "url": "https://github.com/apache/lucene-solr/pull/1571#discussion_r522497553", "createdAt": "2020-11-12T23:21:29Z", "author": {"login": "cpoerschke"}, "path": "solr/contrib/ltr/src/java/org/apache/solr/ltr/LTRScoringQuery.java", "diffHunk": "@@ -102,6 +102,26 @@ public LTRScoringModel getScoringModel() {\n     return ltrScoringModel;\n   }\n \n+  public void setLtrScoringModel(LTRScoringModel ltrScoringModel) {\n+    this.ltrScoringModel = ltrScoringModel;\n+  }\n+\n+  public void setLtrThreadMgr(LTRThreadModule ltrThreadMgr) {\n+    this.ltrThreadMgr = ltrThreadMgr;\n+  }\n+\n+  public void setExtractAllFeatures(boolean extractAllFeatures) {\n+    this.extractAllFeatures = extractAllFeatures;\n+  }\n+\n+  public void setEfi(Map<String, String[]> efi) {\n+    this.efi = efi;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7521f728079ff2980a0d78980448680f08bf911f"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1472, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}