{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY1NTI5MjM4", "number": 1195, "title": "SOLR-13101: Log accurate file counts for Push and Pull in CorePushPull", "bodyText": "Description\nNumber of files and bytes pushed/pulled are logged when pushing to or pulling from blobstore, but values are only accurate when operation is successful. Log expected and actual file count, actual byte count, and add back boolean for whether operation was successful.\nSolution\nCount number of files/bytes actually transferred\nTests\nRan ant test, and working on adding additional unit tests.\nLogline for successful push:\nPushPullData=[collectionName=gettingstarted shardName=shard1 sharedStoreName=gettingstarted_shard1 coreName=gettingstarted_shard1_replica_s1] action=PUSH storageProvider=LOCAL_FILE_SYSTEM bucketRegion=N/A bucketName=N/A runTime=44325264 startLatency=44325264 bytesTransferred=2076 attempt=0 expectedFilesAffected=10 actualFilesAffected=10 isSuccessful=true localGeneration=2 blobGeneration=-1 \nLogline for successful pull:\nPushPullData=[collectionName=pulltest2 shardName=shard2 sharedStoreName=pulltest2_shard2 coreName=pulltest2_shard2_replica_s6] action=PULL storageProvider=LOCAL_FILE_SYSTEM bucketRegion=N/A bucketName=N/A runTime=70088178 startLatency=70090032 bytesTransferred=9828 attempt=0 expectedFilesAffected=46 actualFilesAffected=46 isSuccessful=true localGeneration=1 blobGeneration=6\nLogline for exception thrown partway through push:\nPushPullData=[collectionName=gettingstarted shardName=shard1 sharedStoreName=gettingstarted_shard1 coreName=gettingstarted_shard1_replica_s1] action=PUSH storageProvider=LOCAL_FILE_SYSTEM bucketRegion=N/A bucketName=N/A runTime=6363713 startLatency=6363713 bytesTransferred=1132 attempt=0 expectedFilesAffected=10 actualFilesAffected=6 isSuccessful=false localGeneration=2 blobGeneration=-1\nLogline for exception thrown partway through pull:\nPushPullData=[collectionName=pulltest2 shardName=shard1 sharedStoreName=pulltest2_shard1 coreName=pulltest2_shard1_replica_s1] action=PULL storageProvider=LOCAL_FILE_SYSTEM bucketRegion=N/A bucketName=N/A runTime=9548098 startLatency=9548350 bytesTransferred=1404 attempt=0 expectedFilesAffected=19 actualFilesAffected=6 isSuccessful=false localGeneration=1 blobGeneration=3", "createdAt": "2020-01-21T21:43:03Z", "url": "https://github.com/apache/lucene-solr/pull/1195", "merged": true, "mergeCommit": {"oid": "5c797bfa31063a6532e223a18db16c0a2dc8effe"}, "closed": true, "closedAt": "2020-01-25T19:02:57Z", "author": {"login": "ebehrendt"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb8n-HoAH2gAyMzY1NTI5MjM4OjAwNTY2MTc1M2Y3YzVmYzBiOTc0ZGY5N2NmMmI0YzM3MDI2OTVkY2M=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9RyLNAFqTM0NzY0MDU1NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "author": {"user": {"login": "ebehrendt", "name": null}}, "url": "https://github.com/apache/lucene-solr/commit/005661753f7c5fc0b974df97cf2b4c3702695dcc", "committedDate": "2020-01-21T21:24:32Z", "message": "CorePushPull blob interaction log line inaccurate in case of failures. Fix logged file and bytes count to be accurate in both success and failure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjEzNTk2", "url": "https://github.com/apache/lucene-solr/pull/1195#pullrequestreview-346213596", "createdAt": "2020-01-21T21:45:30Z", "commit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0NTozMVrOFgJ0og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0NTozMVrOFgJ0og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1OTY4Mg==", "bodyText": "I considered creating an inner wrapper class for the return values but it seemed like overkill, so I went with returning a pair", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369259682", "createdAt": "2020-01-21T21:45:31Z", "author": {"login": "ebehrendt"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 150}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjE0MTc0", "url": "https://github.com/apache/lucene-solr/pull/1195#pullrequestreview-346214174", "createdAt": "2020-01-21T21:46:34Z", "commit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0NjozNFrOFgJ2aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0NjozNFrOFgJ2aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDEzNw==", "bodyText": "Moved IndexOutput initialization into the try with resources since it can throw an exception and it also implements Closable", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369260137", "createdAt": "2020-01-21T21:46:34Z", "author": {"login": "ebehrendt"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjE1MTA2", "url": "https://github.com/apache/lucene-solr/pull/1195#pullrequestreview-346215106", "createdAt": "2020-01-21T21:48:14Z", "commit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0ODoxNFrOFgJ5VA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0ODoxNFrOFgJ5VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDg4NA==", "bodyText": "Anyone have a recommendation on how to do this more gracefully than return the same values in and outside of the catch? I want to return these values whether exception is thrown or not, but cannot return from a finally.", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369260884", "createdAt": "2020-01-21T21:48:14Z", "author": {"login": "ebehrendt"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n+              OutputStream outStream = new IndexOutputStream(io);\n+            InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n+            IOUtils.copy(bis, outStream);\n+            \n+            filesDownloaded++;\n+            bytesTransferred += bf.getFileSize();\n+          } catch (Exception e) {\n+            return new Pair<>(filesDownloaded, bytesTransferred);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 172}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2NzY5MjI1", "url": "https://github.com/apache/lucene-solr/pull/1195#pullrequestreview-346769225", "createdAt": "2020-01-22T17:28:24Z", "commit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNzoyODoyNFrOFgkpFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNzozNjo1M1rOFgk5pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY5OTA5Mw==", "bodyText": "This comment is also out of date (soblb doesn't exist) so we can remove it.", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369699093", "createdAt": "2020-01-22T17:28:24Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMzMzNQ==", "bodyText": "This will swallow exceptions from requests failing with the blob store. I'd prefer to keep the same behavior and let those errors propagate up.", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369703335", "createdAt": "2020-01-22T17:36:53Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n+              OutputStream outStream = new IndexOutputStream(io);\n+            InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n+            IOUtils.copy(bis, outStream);\n+            \n+            filesDownloaded++;\n+            bytesTransferred += bf.getFileSize();\n+          } catch (Exception e) {\n+            return new Pair<>(filesDownloaded, bytesTransferred);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 172}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dddb6bdbfe45978583fb9ceb61f814e9c4f0e4e9", "author": {"user": {"login": "ebehrendt", "name": null}}, "url": "https://github.com/apache/lucene-solr/commit/dddb6bdbfe45978583fb9ceb61f814e9c4f0e4e9", "committedDate": "2020-01-23T21:38:32Z", "message": "Move file transfer count data into inner class to preserve incremented values when exception is thrown"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NjQwNTU0", "url": "https://github.com/apache/lucene-solr/pull/1195#pullrequestreview-347640554", "createdAt": "2020-01-23T22:06:22Z", "commit": {"oid": "dddb6bdbfe45978583fb9ceb61f814e9c4f0e4e9"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMjowNjoyMlrOFhONfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMjowNjoyMlrOFhONfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4MDE1OA==", "bodyText": "Looked at the code and OutputStream outStream = new IndexOutputStream(io) was already in the try-with block and will end up closing the IndexOutput you moved. But the change has no affect if close is called twice so no change needed here, just wanted to note that.", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r370380158", "createdAt": "2020-01-23T22:06:22Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDEzNw=="}, "originalCommit": {"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc"}, "originalPosition": 164}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2252, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}