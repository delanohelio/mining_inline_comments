{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEyMDI1NTI4", "number": 1473, "title": "LUCENE-9353: Move terms metadata to its own file.", "bodyText": "See https://issues.apache.org/jira/browse/LUCENE-9353.", "createdAt": "2020-05-01T07:44:52Z", "url": "https://github.com/apache/lucene-solr/pull/1473", "merged": true, "mergeCommit": {"oid": "87a3bef50f8c08404ee8bd66ca868caf5dd072cb"}, "closed": true, "closedAt": "2020-06-16T13:05:29Z", "author": {"login": "jpountz"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcc8vDyAH2gAyNDEyMDI1NTI4OjZlZGZjZmFkMGRlZDE0MmZiY2UxNTg3MDRiMTdmYzliMDIxMzliNzc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcr0g-BAH2gAyNDEyMDI1NTI4OjhiODQxN2VlM2FmZjdkZDcyNmE1MThjODE2MTAwNDUyZmI3ZDYxOGM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6edfcfad0ded142fbce158704b17fc9b02139b77", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/6edfcfad0ded142fbce158704b17fc9b02139b77", "committedDate": "2020-05-01T07:41:40Z", "message": "LUCENE-9353: Move terms metadata to its own file.\n\nSee https://issues.apache.org/jira/browse/LUCENE-9353."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/9a4df99cc3f2611315aa016192b921985ea94e42", "committedDate": "2020-05-01T07:45:30Z", "message": "Merge branch 'master' into separate_terms_meta_file"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0MTgwNDgx", "url": "https://github.com/apache/lucene-solr/pull/1473#pullrequestreview-404180481", "createdAt": "2020-05-01T14:13:17Z", "commit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNDoxMzoxN1rOGPKywA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNDoxMzoxN1rOGPKywA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODU1ODY1Ng==", "bodyText": "do we have a test that tickles these cases?", "url": "https://github.com/apache/lucene-solr/pull/1473#discussion_r418558656", "createdAt": "2020-05-01T14:13:17Z", "author": {"login": "msokolov"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java", "diffHunk": "@@ -148,56 +155,80 @@ public BlockTreeTermsReader(PostingsReaderBase postingsReader, SegmentReadState\n       CodecUtil.retrieveChecksum(termsIn);\n \n       // Read per-field details\n-      seekDir(termsIn);\n-      seekDir(indexIn);\n+      String metaName = IndexFileNames.segmentFileName(segment, state.segmentSuffix, TERMS_META_EXTENSION);\n+      Map<String, FieldReader> fieldMap = null;\n+      Throwable priorE = null;\n+      try (ChecksumIndexInput metaIn = version >= VERSION_META_FILE ? state.directory.openChecksumInput(metaName, state.context) : null) {\n+        try {\n+          final IndexInput indexMetaIn, termsMetaIn;\n+          if (version >= VERSION_META_FILE) {\n+            CodecUtil.checkIndexHeader(metaIn, TERMS_META_CODEC_NAME, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n+            indexMetaIn = termsMetaIn = metaIn;\n+          } else {\n+            seekDir(termsIn);\n+            seekDir(indexIn);\n+            indexMetaIn = indexIn;\n+            termsMetaIn = termsIn;\n+          }\n \n-      final int numFields = termsIn.readVInt();\n-      if (numFields < 0) {\n-        throw new CorruptIndexException(\"invalid numFields: \" + numFields, termsIn);\n-      }\n-      fieldMap = new HashMap<>((int) (numFields / 0.75f) + 1);\n-      for (int i = 0; i < numFields; ++i) {\n-        final int field = termsIn.readVInt();\n-        final long numTerms = termsIn.readVLong();\n-        if (numTerms <= 0) {\n-          throw new CorruptIndexException(\"Illegal numTerms for field number: \" + field, termsIn);\n-        }\n-        final BytesRef rootCode = readBytesRef(termsIn);\n-        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n-        if (fieldInfo == null) {\n-          throw new CorruptIndexException(\"invalid field number: \" + field, termsIn);\n-        }\n-        final long sumTotalTermFreq = termsIn.readVLong();\n-        // when frequencies are omitted, sumDocFreq=sumTotalTermFreq and only one value is written.\n-        final long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : termsIn.readVLong();\n-        final int docCount = termsIn.readVInt();\n-        if (version < VERSION_META_LONGS_REMOVED) {\n-          final int longsSize = termsIn.readVInt();\n-          if (longsSize < 0) {\n-            throw new CorruptIndexException(\"invalid longsSize for field: \" + fieldInfo.name + \", longsSize=\" + longsSize, termsIn);\n+          final int numFields = termsMetaIn.readVInt();\n+          if (numFields < 0) {\n+            throw new CorruptIndexException(\"invalid numFields: \" + numFields, termsMetaIn);\n+          }\n+          fieldMap = new HashMap<>((int) (numFields / 0.75f) + 1);\n+          for (int i = 0; i < numFields; ++i) {\n+            final int field = termsMetaIn.readVInt();\n+            final long numTerms = termsMetaIn.readVLong();\n+            if (numTerms <= 0) {\n+              throw new CorruptIndexException(\"Illegal numTerms for field number: \" + field, termsMetaIn);\n+            }\n+            final BytesRef rootCode = readBytesRef(termsMetaIn);\n+            final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n+            if (fieldInfo == null) {\n+              throw new CorruptIndexException(\"invalid field number: \" + field, termsMetaIn);\n+            }\n+            final long sumTotalTermFreq = termsMetaIn.readVLong();\n+            // when frequencies are omitted, sumDocFreq=sumTotalTermFreq and only one value is written.\n+            final long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : termsMetaIn.readVLong();\n+            final int docCount = termsMetaIn.readVInt();\n+            if (version < VERSION_META_LONGS_REMOVED) {\n+              final int longsSize = termsMetaIn.readVInt();\n+              if (longsSize < 0) {\n+                throw new CorruptIndexException(\"invalid longsSize for field: \" + fieldInfo.name + \", longsSize=\" + longsSize, termsMetaIn);\n+              }\n+            }\n+            BytesRef minTerm = readBytesRef(termsMetaIn);\n+            BytesRef maxTerm = readBytesRef(termsMetaIn);\n+            if (docCount < 0 || docCount > state.segmentInfo.maxDoc()) { // #docs with field must be <= #docs\n+              throw new CorruptIndexException(\"invalid docCount: \" + docCount + \" maxDoc: \" + state.segmentInfo.maxDoc(), termsMetaIn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "originalPosition": 125}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0MTgxMzU2", "url": "https://github.com/apache/lucene-solr/pull/1473#pullrequestreview-404181356", "createdAt": "2020-05-01T14:14:49Z", "commit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNDoxNDo0OVrOGPK1xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNDoxNDo0OVrOGPK1xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODU1OTQzMA==", "bodyText": "again, I don't know if we have test coverage for the corrputed metadata?", "url": "https://github.com/apache/lucene-solr/pull/1473#discussion_r418559430", "createdAt": "2020-05-01T14:14:49Z", "author": {"login": "msokolov"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsReader.java", "diffHunk": "@@ -148,56 +155,80 @@ public BlockTreeTermsReader(PostingsReaderBase postingsReader, SegmentReadState\n       CodecUtil.retrieveChecksum(termsIn);\n \n       // Read per-field details\n-      seekDir(termsIn);\n-      seekDir(indexIn);\n+      String metaName = IndexFileNames.segmentFileName(segment, state.segmentSuffix, TERMS_META_EXTENSION);\n+      Map<String, FieldReader> fieldMap = null;\n+      Throwable priorE = null;\n+      try (ChecksumIndexInput metaIn = version >= VERSION_META_FILE ? state.directory.openChecksumInput(metaName, state.context) : null) {\n+        try {\n+          final IndexInput indexMetaIn, termsMetaIn;\n+          if (version >= VERSION_META_FILE) {\n+            CodecUtil.checkIndexHeader(metaIn, TERMS_META_CODEC_NAME, version, version, state.segmentInfo.getId(), state.segmentSuffix);\n+            indexMetaIn = termsMetaIn = metaIn;\n+          } else {\n+            seekDir(termsIn);\n+            seekDir(indexIn);\n+            indexMetaIn = indexIn;\n+            termsMetaIn = termsIn;\n+          }\n \n-      final int numFields = termsIn.readVInt();\n-      if (numFields < 0) {\n-        throw new CorruptIndexException(\"invalid numFields: \" + numFields, termsIn);\n-      }\n-      fieldMap = new HashMap<>((int) (numFields / 0.75f) + 1);\n-      for (int i = 0; i < numFields; ++i) {\n-        final int field = termsIn.readVInt();\n-        final long numTerms = termsIn.readVLong();\n-        if (numTerms <= 0) {\n-          throw new CorruptIndexException(\"Illegal numTerms for field number: \" + field, termsIn);\n-        }\n-        final BytesRef rootCode = readBytesRef(termsIn);\n-        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n-        if (fieldInfo == null) {\n-          throw new CorruptIndexException(\"invalid field number: \" + field, termsIn);\n-        }\n-        final long sumTotalTermFreq = termsIn.readVLong();\n-        // when frequencies are omitted, sumDocFreq=sumTotalTermFreq and only one value is written.\n-        final long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : termsIn.readVLong();\n-        final int docCount = termsIn.readVInt();\n-        if (version < VERSION_META_LONGS_REMOVED) {\n-          final int longsSize = termsIn.readVInt();\n-          if (longsSize < 0) {\n-            throw new CorruptIndexException(\"invalid longsSize for field: \" + fieldInfo.name + \", longsSize=\" + longsSize, termsIn);\n+          final int numFields = termsMetaIn.readVInt();\n+          if (numFields < 0) {\n+            throw new CorruptIndexException(\"invalid numFields: \" + numFields, termsMetaIn);\n+          }\n+          fieldMap = new HashMap<>((int) (numFields / 0.75f) + 1);\n+          for (int i = 0; i < numFields; ++i) {\n+            final int field = termsMetaIn.readVInt();\n+            final long numTerms = termsMetaIn.readVLong();\n+            if (numTerms <= 0) {\n+              throw new CorruptIndexException(\"Illegal numTerms for field number: \" + field, termsMetaIn);\n+            }\n+            final BytesRef rootCode = readBytesRef(termsMetaIn);\n+            final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n+            if (fieldInfo == null) {\n+              throw new CorruptIndexException(\"invalid field number: \" + field, termsMetaIn);\n+            }\n+            final long sumTotalTermFreq = termsMetaIn.readVLong();\n+            // when frequencies are omitted, sumDocFreq=sumTotalTermFreq and only one value is written.\n+            final long sumDocFreq = fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : termsMetaIn.readVLong();\n+            final int docCount = termsMetaIn.readVInt();\n+            if (version < VERSION_META_LONGS_REMOVED) {\n+              final int longsSize = termsMetaIn.readVInt();\n+              if (longsSize < 0) {\n+                throw new CorruptIndexException(\"invalid longsSize for field: \" + fieldInfo.name + \", longsSize=\" + longsSize, termsMetaIn);\n+              }\n+            }\n+            BytesRef minTerm = readBytesRef(termsMetaIn);\n+            BytesRef maxTerm = readBytesRef(termsMetaIn);\n+            if (docCount < 0 || docCount > state.segmentInfo.maxDoc()) { // #docs with field must be <= #docs\n+              throw new CorruptIndexException(\"invalid docCount: \" + docCount + \" maxDoc: \" + state.segmentInfo.maxDoc(), termsMetaIn);\n+            }\n+            if (sumDocFreq < docCount) {  // #postings must be >= #docs with field\n+              throw new CorruptIndexException(\"invalid sumDocFreq: \" + sumDocFreq + \" docCount: \" + docCount, termsMetaIn);\n+            }\n+            if (sumTotalTermFreq < sumDocFreq) { // #positions must be >= #postings\n+              throw new CorruptIndexException(\"invalid sumTotalTermFreq: \" + sumTotalTermFreq + \" sumDocFreq: \" + sumDocFreq, termsMetaIn);\n+            }\n+            final long indexStartFP = indexMetaIn.readVLong();\n+            FieldReader previous = fieldMap.put(fieldInfo.name,\n+                new FieldReader(this, fieldInfo, numTerms, rootCode, sumTotalTermFreq, sumDocFreq, docCount,\n+                    indexStartFP, indexIn, minTerm, maxTerm));\n+            if (previous != null) {\n+              throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, termsMetaIn);\n+            }\n+          }\n+        } catch (Throwable exception) {\n+          priorE = exception;\n+        } finally {\n+          if (metaIn != null) {\n+            CodecUtil.checkFooter(metaIn, priorE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "originalPosition": 145}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0ODYyNDE0", "url": "https://github.com/apache/lucene-solr/pull/1473#pullrequestreview-404862414", "createdAt": "2020-05-04T10:17:39Z", "commit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDoxNzo0MFrOGP6WWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMDoxNzo0MFrOGP6WWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTMzNzgxOQ==", "bodyText": "@jpountz here I see the same lack of serializer write/read code, could it be possible to have such thing, It would improve readability and unit testing by only mocking fieldMetadatas and check serialization is correctly applied.", "url": "https://github.com/apache/lucene-solr/pull/1473#discussion_r419337819", "createdAt": "2020-05-04T10:17:40Z", "author": {"login": "juanka588"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java", "diffHunk": "@@ -1060,36 +1052,35 @@ public void close() throws IOException {\n       return;\n     }\n     closed = true;\n-    \n+\n+    final String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockTreeTermsReader.TERMS_META_EXTENSION);\n     boolean success = false;\n-    try {\n-      \n-      final long dirStart = termsOut.getFilePointer();\n-      final long indexDirStart = indexOut.getFilePointer();\n+    try (IndexOutput metaOut = state.directory.createOutput(metaName, state.context)) {\n+      CodecUtil.writeIndexHeader(metaOut, BlockTreeTermsReader.TERMS_META_CODEC_NAME, BlockTreeTermsReader.VERSION_CURRENT,\n+          state.segmentInfo.getId(), state.segmentSuffix);\n \n-      termsOut.writeVInt(fields.size());\n+      metaOut.writeVInt(fields.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1MDAyMDc1", "url": "https://github.com/apache/lucene-solr/pull/1473#pullrequestreview-405002075", "createdAt": "2020-05-04T13:46:38Z", "commit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NjozOFrOGQBF1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQxMzo0NjozOFrOGQBF1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ0ODI3Nw==", "bodyText": "why this file is not created at the same time with the indexOut, termOut?", "url": "https://github.com/apache/lucene-solr/pull/1473#discussion_r419448277", "createdAt": "2020-05-04T13:46:38Z", "author": {"login": "juanka588"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.java", "diffHunk": "@@ -1060,36 +1052,35 @@ public void close() throws IOException {\n       return;\n     }\n     closed = true;\n-    \n+\n+    final String metaName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, BlockTreeTermsReader.TERMS_META_EXTENSION);\n     boolean success = false;\n-    try {\n-      \n-      final long dirStart = termsOut.getFilePointer();\n-      final long indexDirStart = indexOut.getFilePointer();\n+    try (IndexOutput metaOut = state.directory.createOutput(metaName, state.context)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a4df99cc3f2611315aa016192b921985ea94e42"}, "originalPosition": 45}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9faa6304a4c1655bfce2497eb243d51669c2cf48", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/9faa6304a4c1655bfce2497eb243d51669c2cf48", "committedDate": "2020-06-08T14:43:03Z", "message": "Merge remote-tracking branch 'origin/master' into separate_terms_meta_file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "10b8c13161098494ba1492aa6bb9e9527c43343f", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/10b8c13161098494ba1492aa6bb9e9527c43343f", "committedDate": "2020-06-10T06:29:46Z", "message": "Merge branch 'master' into separate_terms_meta_file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7587f1c8835a4b47d5a1759438a9c5d27d8bce85", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/7587f1c8835a4b47d5a1759438a9c5d27d8bce85", "committedDate": "2020-06-10T07:47:36Z", "message": "Use separate file for FST metadata"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06e381af374146772c8268dd4e591f2f360b97e6", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/06e381af374146772c8268dd4e591f2f360b97e6", "committedDate": "2020-06-10T08:07:27Z", "message": "Improve CHANGES entry"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84208aa9a68900fd30a6513e9b0528db7fe2278f", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/84208aa9a68900fd30a6513e9b0528db7fe2278f", "committedDate": "2020-06-10T08:13:49Z", "message": "iter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db5a8f2052ea424938693f2ac8522b2d5f162f24", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/db5a8f2052ea424938693f2ac8522b2d5f162f24", "committedDate": "2020-06-16T10:19:36Z", "message": "Merge branch 'master' into separate_terms_meta_file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e225d8215d3f8caab74fdb370b59b9e6e66f95f", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/3e225d8215d3f8caab74fdb370b59b9e6e66f95f", "committedDate": "2020-06-16T12:35:07Z", "message": "Improve truncation detection."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b8417ee3aff7dd726a518c816100452fb7d618c", "author": {"user": {"login": "jpountz", "name": "Adrien Grand"}}, "url": "https://github.com/apache/lucene-solr/commit/8b8417ee3aff7dd726a518c816100452fb7d618c", "committedDate": "2020-06-16T12:35:54Z", "message": "iter"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2665, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}