{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA5MjQ1MzE3", "number": 2022, "title": "LUCENE-9004: KNN vector search using NSW graphs", "bodyText": "Phew this has been a long time coming, but I think it is in good shape now. We started with a scratchy prototype about a year ago, then @mocobeta got it on a better footing by adding a new codec and also implemented the full hierarchical algorithm, making the graph search faithful to the published literature. Then we took a step back to add underlying vector format as a separate patch, now landed. This patch builds on the new vector format, providing KNN search with NSW graphs. It's the simplest implementation I could tease out (single layer graph, simple neighbor selection, no max fanout control), but I think it will be a good foundation. I've done some pretty extensive performance testing and hyperparameter exploration using the (included) KnnGraphTester with some proprietary data, and get good results. I will follow up later with specifics, but single-threaded latencies in a few ms on my i7 laptop over a 1M x 256-dim dataset seems pretty good. Followups will include repeatable benchmarks on public datasets.", "createdAt": "2020-10-23T22:31:19Z", "url": "https://github.com/apache/lucene-solr/pull/2022", "merged": true, "mergeCommit": {"oid": "b36b4af22bb76dc42b466b818b417bcbc0deb006"}, "closed": true, "closedAt": "2020-11-13T13:53:51Z", "author": {"login": "msokolov"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdVdoUkAH2gAyNTA5MjQ1MzE3OjljNTRmZDc4NzQxM2M0NzYzMzMwZDJlNDJjYTg5ZDM0OWNjNTEzYmM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdcHWnQgH2gAyNTA5MjQ1MzE3OmNiNjRhNWJlYzIxYzlkMGNjZWEyZDI0OGM1ZGM1YzA0ZTNmYTFmZjE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9c54fd787413c4763330d2e42ca89d349cc513bc", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/9c54fd787413c4763330d2e42ca89d349cc513bc", "committedDate": "2020-10-23T21:40:56Z", "message": "WIP not complete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "350443acbf4d73d76001d947fe66f32d015b864c", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/350443acbf4d73d76001d947fe66f32d015b864c", "committedDate": "2020-10-23T21:45:08Z", "message": "restore some changes that got lost when merging commits"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c70d3ba1bf0102bc5dc0436911a8ad70978d30d", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/0c70d3ba1bf0102bc5dc0436911a8ad70978d30d", "committedDate": "2020-10-23T22:02:42Z", "message": "rename ScoreFunction to SearchStrategy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e5f2539786c5cfe9cd937f93d7705965833ced4", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/3e5f2539786c5cfe9cd937f93d7705965833ced4", "committedDate": "2020-10-23T22:04:44Z", "message": "LUCENE-9582: rename VectorValues.ScoreFunction to SearchStrategy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7704f41c3e6eb30bc44d00432f640a0ea0437a4", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/b7704f41c3e6eb30bc44d00432f640a0ea0437a4", "committedDate": "2020-10-23T22:05:52Z", "message": "refactor knn graph codec support for better extensibility"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0802b9e6e424a31f66be4bfb3d874456c323d491", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/0802b9e6e424a31f66be4bfb3d874456c323d491", "committedDate": "2020-10-23T22:05:52Z", "message": "improve naming and docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a4a744e6adebb5313b9e6d681a795a6540081b7", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/5a4a744e6adebb5313b9e6d681a795a6540081b7", "committedDate": "2020-10-23T22:05:52Z", "message": "cleaning up BoundsChecker and added a test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d23e48f7ae7352761081fd19eba5f110fd7d011", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/1d23e48f7ae7352761081fd19eba5f110fd7d011", "committedDate": "2020-10-23T22:05:52Z", "message": "removed annealing after test showed it is redundant"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/c10b88a38b25ca52e87be009ed8011ccc1b94683", "committedDate": "2020-10-23T22:08:37Z", "message": "move KNN search our of VectorValues.RandomAccess interface"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MTMyNzY5", "url": "https://github.com/apache/lucene-solr/pull/2022#pullrequestreview-516132769", "createdAt": "2020-10-24T00:01:15Z", "commit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNFQwMDowMToxNVrOHnhTsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNFQwMDowMToxNVrOHnhTsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTIwMjIyNQ==", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r511202225", "createdAt": "2020-10-24T00:01:15Z", "author": {"login": "sonatype-lift"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -165,42 +191,88 @@ public VectorValues getVectorValues(String field) throws IOException {\n     return new OffHeapVectorValues(fieldEntry, bytesSlice);\n   }\n \n+  // exposed for testing\n+  public KnnGraphValues getGraphValues(String field) throws IOException {\n+    FieldInfo info = fieldInfos.fieldInfo(field);\n+    if (info == null) {\n+      throw new IllegalArgumentException(\"No such field '\" + field + \"'\");\n+    }\n+    FieldEntry entry = fields.get(field);\n+    if (entry != null && entry.indexDataLength > 0) {\n+      return getGraphValues(entry);\n+    } else {\n+      return KnnGraphValues.EMPTY;\n+    }\n+  }\n+\n+  private KnnGraphValues getGraphValues(FieldEntry entry) throws IOException {\n+    if (isHnswStrategy(entry.searchStrategy)) {\n+      HnswGraphFieldEntry graphEntry = (HnswGraphFieldEntry) entry;\n+      IndexInput bytesSlice = vectorIndex.slice(\"graph-data\", entry.indexDataOffset, entry.indexDataLength);\n+      return new IndexedKnnGraphReader(graphEntry, bytesSlice);\n+    } else {\n+      return KnnGraphValues.EMPTY;\n+    }\n+  }\n+\n   @Override\n   public void close() throws IOException {\n-    vectorData.close();\n+    IOUtils.close(vectorData, vectorIndex);\n   }\n \n   private static class FieldEntry {\n \n     final int dimension;\n     final VectorValues.SearchStrategy searchStrategy;\n-    final int maxDoc;\n \n     final long vectorDataOffset;\n     final long vectorDataLength;\n+    final long indexDataOffset;\n+    final long indexDataLength;\n     final int[] ordToDoc;\n \n-    FieldEntry(int dimension, VectorValues.SearchStrategy searchStrategy, int maxDoc,\n-               long vectorDataOffset, long vectorDataLength, int[] ordToDoc) {\n-      this.dimension = dimension;\n+    FieldEntry(DataInput input, VectorValues.SearchStrategy searchStrategy) throws IOException {\n       this.searchStrategy = searchStrategy;\n-      this.maxDoc = maxDoc;\n-      this.vectorDataOffset = vectorDataOffset;\n-      this.vectorDataLength = vectorDataLength;\n-      this.ordToDoc = ordToDoc;\n+      vectorDataOffset = input.readVLong();\n+      vectorDataLength = input.readVLong();\n+      indexDataOffset = input.readVLong();\n+      indexDataLength = input.readVLong();\n+      dimension = input.readInt();\n+      int size = input.readInt();\n+      ordToDoc = new int[size];\n+      for (int i = 0; i < size; i++) {\n+        int doc = input.readVInt();\n+        ordToDoc[i] = doc;\n+      }\n     }\n \n     int size() {\n       return ordToDoc.length;\n     }\n   }\n \n+  private static class HnswGraphFieldEntry extends FieldEntry {\n+\n+    final long[] ordOffsets;\n+\n+    HnswGraphFieldEntry(DataInput input, VectorValues.SearchStrategy searchStrategy) throws IOException {\n+      super(input, searchStrategy);\n+      ordOffsets = new long[size()];\n+      long offset = 0;\n+      for (int i = 0; i < ordOffsets.length; i++) {\n+        offset += input.readVLong();\n+        ordOffsets[i] = offset;\n+      }\n+    }\n+  }\n+\n   /** Read the vector values from the index input. This supports both iterated and random access. */\n-  private final static class OffHeapVectorValues extends VectorValues {\n+  private final class OffHeapVectorValues extends VectorValues {\n \n     final FieldEntry fieldEntry;\n     final IndexInput dataIn;\n \n+    final Random random = new Random();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 249}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MTMyNzgw", "url": "https://github.com/apache/lucene-solr/pull/2022#pullrequestreview-516132780", "createdAt": "2020-10-24T00:01:16Z", "commit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNFQwMDowMToxNlrOHnhTvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yNFQwMDowMToxNlrOHnhTvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTIwMjIzNg==", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r511202236", "createdAt": "2020-10-24T00:01:16Z", "author": {"login": "sonatype-lift"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;\n+\n+  // These \"default\" hyperparameter settings are exposed (and nonfinal) to enable performance testing\n+  // since the indexing API doesn't provide any control over them.\n+\n+  // default max connections per node\n+  static int DEFAULT_MAX_CONN = 16;\n+\n+  // default candidate list size\n+  static int DEFAULT_BEAM_WIDTH = 16;\n+\n+  private final int maxConn;\n+  private final int beamWidth;\n+  private final BoundedVectorValues boundedVectors;\n+  private final VectorValues.SearchStrategy searchStrategy;\n+  private final HnswGraph hnsw;\n+  private final Random random;\n+\n+  /**\n+   * Reads all the vectors from a VectorValues, builds a graph connecting them by their dense ordinals, using default\n+   * hyperparameter settings, and returns the resulting graph.\n+   * @param vectorValues the vectors whose relations are represented by the graph\n+   */\n+  public static HnswGraph build(VectorValues vectorValues) throws IOException {\n+    HnswGraphBuilder builder = new HnswGraphBuilder(vectorValues.randomAccess());\n+    return builder.build(vectorValues.randomAccess());\n+  }\n+\n+  /**\n+   * Reads all the vectors from a VectorValues, builds a graph connecting them by their dense ordinals, using the given\n+   * hyperparameter settings, and returns the resulting graph.\n+   * @param vectorValues the vectors whose relations are represented by the graph\n+   * @param maxConn the number of connections to make when adding a new graph node; roughly speaking the graph fanout.\n+   * @param beamWidth the size of the beam search to use when finding nearest neighbors.\n+   * @param seed the seed for a random number generator used during graph construction. Provide this to ensure repeatable construction.\n+   */\n+  public static HnswGraph build(VectorValues vectorValues, int maxConn, int beamWidth, long seed) throws IOException {\n+    HnswGraphBuilder builder = new HnswGraphBuilder(vectorValues.randomAccess(), maxConn, beamWidth, seed);\n+    return builder.build(vectorValues.randomAccess());\n+  }\n+\n+  /**\n+   * Reads all the vectors from two copies of a random access VectorValues. Providing two copies enables efficient retrieval\n+   * without extra data copying, while avoiding collision of the returned values.\n+   * @param vectors the vectors for which to build a nearest neighbors graph. Must be an independet accessor for the vectors\n+   */\n+  private HnswGraph build(VectorValues.RandomAccess vectors) throws IOException {\n+    for (int node = 1; node < vectors.size(); node++) {\n+      insert(vectors.vectorValue(node));\n+    }\n+    return hnsw;\n+  }\n+\n+  /** Construct the builder with default configurations */\n+  private HnswGraphBuilder(VectorValues.RandomAccess vectors) {\n+    this(vectors, DEFAULT_MAX_CONN, DEFAULT_BEAM_WIDTH, randSeed);\n+  }\n+\n+  /** Full constructor */\n+  private HnswGraphBuilder(VectorValues.RandomAccess vectors, int maxConn, int beamWidth, long seed) {\n+    searchStrategy = vectors.searchStrategy();\n+    if (searchStrategy == VectorValues.SearchStrategy.NONE) {\n+      throw new IllegalStateException(\"No distance function\");\n+    }\n+    this.maxConn = maxConn;\n+    this.beamWidth = beamWidth;\n+    boundedVectors = new BoundedVectorValues(vectors);\n+    this.hnsw = new HnswGraph();\n+    random = new Random(seed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 107}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d17a2dd676dd9f3babc6ed3b3df307364db32606", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/d17a2dd676dd9f3babc6ed3b3df307364db32606", "committedDate": "2020-10-26T16:32:48Z", "message": "extract separate RandomAccessVectorValues interface"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c33757ab28b540b2f028fb826a51b50772101700", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/c33757ab28b540b2f028fb826a51b50772101700", "committedDate": "2020-10-26T23:14:32Z", "message": "use index checksum as seed for reproducible Random so we get consistent query response"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIwNjM3MDA5", "url": "https://github.com/apache/lucene-solr/pull/2022#pullrequestreview-520637009", "createdAt": "2020-10-30T12:52:24Z", "commit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "state": "COMMENTED", "comments": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxMjo1MjoyNFrOHrNr3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxMzo0MTozMFrOHrPhng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTAzOA==", "bodyText": "Does this mean Lucene users are free to chose to simply store / retrieve vectors, even after we push this change?  I.e. the ANN is optional?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515075038", "createdAt": "2020-10-30T12:52:24Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -102,23 +122,28 @@ private void readFields(ChecksumIndexInput meta, FieldInfos infos) throws IOExce\n       if (info == null) {\n         throw new CorruptIndexException(\"Invalid field number: \" + fieldNumber, meta);\n       }\n-      int searchStrategyId = meta.readInt();\n-      if (searchStrategyId < 0 || searchStrategyId >= VectorValues.SearchStrategy.values().length) {\n-        throw new CorruptIndexException(\"Invalid search strategy id: \" + searchStrategyId, meta);\n-      }\n-      VectorValues.SearchStrategy searchStrategy = VectorValues.SearchStrategy.values()[searchStrategyId];\n-      long vectorDataOffset = meta.readVLong();\n-      long vectorDataLength = meta.readVLong();\n-      int dimension = meta.readInt();\n-      int size = meta.readInt();\n-      int[] ordToDoc = new int[size];\n-      for (int i = 0; i < size; i++) {\n-        int doc = meta.readVInt();\n-        ordToDoc[i] = doc;\n-      }\n-      FieldEntry fieldEntry = new FieldEntry(dimension, searchStrategy, maxDoc, vectorDataOffset, vectorDataLength,\n-                                              ordToDoc);\n-      fields.put(info.name, fieldEntry);\n+      fields.put(info.name, readField(meta));\n+    }\n+  }\n+\n+  private VectorValues.SearchStrategy readSearchStrategy(DataInput input) throws IOException {\n+    int searchStrategyId = input.readInt();\n+    if (searchStrategyId < 0 || searchStrategyId >= VectorValues.SearchStrategy.values().length) {\n+      throw new CorruptIndexException(\"Invalid search strategy id: \" + searchStrategyId, input);\n+    }\n+    return VectorValues.SearchStrategy.values()[searchStrategyId];\n+  }\n+\n+  private FieldEntry readField(DataInput input) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = readSearchStrategy(input);\n+    switch(searchStrategy) {\n+      case NONE:\n+        return new FieldEntry(input, searchStrategy);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTk1MA==", "bodyText": "Why only testing?  It looks like it would be a useful API for users!", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515075950", "createdAt": "2020-10-30T12:54:21Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -165,42 +191,88 @@ public VectorValues getVectorValues(String field) throws IOException {\n     return new OffHeapVectorValues(fieldEntry, bytesSlice);\n   }\n \n+  // exposed for testing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ==", "bodyText": "Isn't there also an index-time fanout control?  Do we allow users to tune that (where?)?  If so, maybe link to that from this search-time fanout javadoc too?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515077829", "createdAt": "2020-10-30T12:57:52Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/VectorValues.java", "diffHunk": "@@ -74,6 +74,18 @@ public BytesRef binaryValue() throws IOException {\n     throw new UnsupportedOperationException();\n   }\n \n+  /**\n+   * Return the k nearest neighbor documents as determined by comparison of their vector values\n+   * for this field, to the given vector, by the field's search strategy. If the search strategy is\n+   * reversed, lower values indicate nearer vectors, otherwise higher scores indicate nearer\n+   * vectors. Unlike relevance scores, vector scores may be negative.\n+   * @param target the vector-valued query\n+   * @param k      the number of docs to return\n+   * @param fanout control the accuracy/speed tradeoff - larger values give better recall at higher cost", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MDA0Mg==", "bodyText": "A node corresponds to an indexed vector, right?  And it is represented using its compact vector ordinal?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515080042", "createdAt": "2020-10-30T13:01:52Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MjAxOQ==", "bodyText": "Maybe we could add this as a method on the enum constants instead?  So then caller could just call SearchStrategy.isReversed?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515082019", "createdAt": "2020-10-30T13:05:44Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return squareDistance(v1, v2);\n+      case DOT_PRODUCT_HNSW:\n+        return dotProduct(v1, v2);\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  /**\n+   * Return whether the given strategy returns lower values for nearer vectors\n+   * @param searchStrategy the strategy\n+   */\n+  public static boolean isReversed(VectorValues.SearchStrategy searchStrategy) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MjM3OA==", "bodyText": "Maybe this could also be a method on SearchStrategy enum?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515082378", "createdAt": "2020-10-30T13:06:21Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4NTk2MQ==", "bodyText": "Does our test-framework -Dtests.seed=XXX fix the seed here too?  So that (hopefully!) test failures are reproducible.", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515085961", "createdAt": "2020-10-30T13:12:55Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4NjU1Mg==", "bodyText": "Oh I see -- users cannot (easily) change these defaults while indexing?  I would think we could provide these arguments to the Codec at write time and route them down to this HNSW building process...", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515086552", "createdAt": "2020-10-30T13:13:43Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;\n+\n+  // These \"default\" hyperparameter settings are exposed (and nonfinal) to enable performance testing\n+  // since the indexing API doesn't provide any control over them.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4ODUyOA==", "bodyText": "Hmm did we decide not to impose the maxConnections?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515088528", "createdAt": "2020-10-30T13:17:07Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MDkxMQ==", "bodyText": "Maybe also make this a method on SearchStrategy enum?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515090911", "createdAt": "2020-10-30T13:20:54Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -54,4 +56,10 @@ public VectorReader fieldsReader(SegmentReadState state) throws IOException {\n     return new Lucene90VectorReader(state);\n   }\n \n+  static boolean isHnswStrategy(VectorValues.SearchStrategy searchStrategy) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MjEwNw==", "bodyText": "Is this class only used at segment-write time?  Or, is this also used to represent the HNSWGraph at search time?\nOK I think we do not use this at search time -- instead we .seek to a node, and then iterate through its int neighbors.  I guess we do not store the scores for each arc in the index.\nFrom your benchmarks, do you have a sense of how much heap is required (as a function of number of vectors) by this class to construct the ANN neighbors?\nAfter the one vector field for one segment is written, this class is GC'able?  So if I have three vector fields, the heap will only have one HnswGraph living at a time?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515092107", "createdAt": "2020-10-30T13:22:20Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MzY4Nw==", "bodyText": "An arc is the node id (compact ordinal) for the destination of the arc, right?  I.e. the neighbor nodes.\nMaybe rename arcs to neighborNodes?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515093687", "createdAt": "2020-10-30T13:24:48Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return squareDistance(v1, v2);\n+      case DOT_PRODUCT_HNSW:\n+        return dotProduct(v1, v2);\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  /**\n+   * Return whether the given strategy returns lower values for nearer vectors\n+   * @param searchStrategy the strategy\n+   */\n+  public static boolean isReversed(VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return true;\n+      case DOT_PRODUCT_HNSW:\n+        return false;\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  KnnGraphValues getGraphValues() {\n+    return new HnswGraphValues();\n+  }\n+\n+  /**\n+   * Present this graph as KnnGraphValues, used for searching while inserting new nodes.\n+   */\n+  private class HnswGraphValues extends KnnGraphValues {\n+\n+    private int arcUpTo;\n+    private int[] arcs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5NzM2MQ==", "bodyText": "At first I thought we should use Float.MIN_VALUE here, but that is not right, since it is the smallest positive float.\nBut then I worried whether negating Float.MAX_VALUE produces a valid float (e.g. you cannot safely negate Integer.MIN_VALUE).\nMaybe just use Float.NEGATIVE_INFINITY here and Float.POSITIVE_INFINITY for Min?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515097361", "createdAt": "2020-10-30T13:30:19Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/BoundsChecker.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+abstract class BoundsChecker {\n+\n+    float bound;\n+\n+    /**\n+     * Update the bound if sample is better\n+     */\n+    abstract void update(float sample);\n+\n+    /**\n+     * Return whether the sample exceeds (is worse than) the bound\n+     */\n+    abstract boolean check(float sample);\n+\n+    static BoundsChecker create(boolean reversed) {\n+        if (reversed) {\n+            return new Min();\n+        } else {\n+            return new Max();\n+        }\n+    }\n+\n+    static class Max extends BoundsChecker {\n+        Max() {\n+            bound = -Float.MAX_VALUE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5OTEyMw==", "bodyText": "Remove extra blank line?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515099123", "createdAt": "2020-10-30T13:33:11Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -54,4 +56,10 @@ public VectorReader fieldsReader(SegmentReadState state) throws IOException {\n     return new Lucene90VectorReader(state);\n   }\n \n+  static boolean isHnswStrategy(VectorValues.SearchStrategy searchStrategy) {\n+    return searchStrategy == VectorValues.SearchStrategy.DOT_PRODUCT_HNSW ||\n+        searchStrategy == VectorValues.SearchStrategy.EUCLIDEAN_HNSW;\n+  }\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5OTg5OQ==", "bodyText": "Hmm, why no longer public?  Users making their own Codec might want to use this constructor I think?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515099899", "createdAt": "2020-10-30T13:34:14Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -33,15 +34,16 @@\n \n   static final String META_CODEC_NAME = \"Lucene90VectorFormatMeta\";\n   static final String VECTOR_DATA_CODEC_NAME = \"Lucene90VectorFormatData\";\n-\n+  static final String VECTOR_INDEX_CODEC_NAME = \"Lucene90VectorFormatIndex\";\n   static final String META_EXTENSION = \"vem\";\n   static final String VECTOR_DATA_EXTENSION = \"vec\";\n+  static final String VECTOR_INDEX_EXTENSION = \"vex\";\n \n   static final int VERSION_START = 0;\n   static final int VERSION_CURRENT = VERSION_START;\n \n   /** Sole constructor */\n-  public Lucene90VectorFormat() {\n+  Lucene90VectorFormat() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMDkzMw==", "bodyText": "Hmm, remove the TODO in here?\nAdd @lucene.experimental?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515100933", "createdAt": "2020-10-30T13:35:11Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -24,6 +24,7 @@\n import org.apache.lucene.codecs.VectorWriter;\n import org.apache.lucene.index.SegmentReadState;\n import org.apache.lucene.index.SegmentWriteState;\n+import org.apache.lucene.index.VectorValues;\n \n /**\n  * Lucene 9.0 vector format, which encodes dense numeric vector values.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMzU3NA==", "bodyText": "s/friends/neighbors?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515103574", "createdAt": "2020-10-30T13:39:17Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMzk2OQ==", "bodyText": "Remove extra space before ;?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515103969", "createdAt": "2020-10-30T13:39:51Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.\n+ * TODO: replace with SortedNumericDocValues??\n+ */\n+public abstract class KnnGraphValues {\n+\n+  /** Sole constructor */\n+  protected KnnGraphValues() {}\n+\n+  /** Move the pointer to exactly {@code target}, the id of a node in the graph.\n+   *  After this method returns, call {@link #nextArc()} to return successive (ordered) connected node ordinals.\n+   * @param target must be a valid node in the graph, ie. &ge; 0 and &lt; {@link VectorValues#size()}.\n+   */\n+  public abstract void seek(int target) throws IOException;\n+\n+  /**\n+   * Iterates over the neighbor list. It is illegal to call this method after it returns\n+   * NO_MORE_DOCS without calling {@link #seek(int)}, which resets the iterator.\n+   * @return a node ordinal in the graph, or NO_MORE_DOCS if the iteration is complete.\n+   */\n+  public abstract int nextArc() throws IOException ;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwNDMxOA==", "bodyText": "Add @lucene.experimental?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515104318", "createdAt": "2020-10-30T13:40:18Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.\n+ * TODO: replace with SortedNumericDocValues??\n+ */\n+public abstract class KnnGraphValues {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwNTE4Mg==", "bodyText": "This is expected to normally be used just during indexing?  Maybe explain that in the javadoc?  I.e. at search time, users should use the other search method that pulls neighbors from the index and recurses.", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515105182", "createdAt": "2020-10-30T13:41:30Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683"}, "originalPosition": 75}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d4928bc6fc89b8e44ebba4b294ea5f761279db9", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/3d4928bc6fc89b8e44ebba4b294ea5f761279db9", "committedDate": "2020-11-01T19:21:53Z", "message": "Restrict fanout by maxConn"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b74d5b176f876ef7eb5ca7d2aebb234e01f54309", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/b74d5b176f876ef7eb5ca7d2aebb234e01f54309", "committedDate": "2020-11-06T14:38:05Z", "message": "remove unneeded sort of graph arcs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83cf18f9bd3bb6214c500d23e7acf63178109bbe", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/83cf18f9bd3bb6214c500d23e7acf63178109bbe", "committedDate": "2020-11-06T21:23:53Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2MzY1ODk3", "url": "https://github.com/apache/lucene-solr/pull/2022#pullrequestreview-526365897", "createdAt": "2020-11-09T15:24:29Z", "commit": {"oid": "83cf18f9bd3bb6214c500d23e7acf63178109bbe"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNToyNDoyOVrOHvz7iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxNToyNjo0OVrOHv0CtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg5NTk0Nw==", "bodyText": "Hmm is this unused?", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519895947", "createdAt": "2020-11-09T15:24:29Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -22,39 +22,60 @@\n import java.nio.FloatBuffer;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.Random;\n \n import org.apache.lucene.codecs.CodecUtil;\n import org.apache.lucene.codecs.VectorReader;\n import org.apache.lucene.index.CorruptIndexException;\n import org.apache.lucene.index.FieldInfo;\n import org.apache.lucene.index.FieldInfos;\n import org.apache.lucene.index.IndexFileNames;\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.RandomAccessVectorValues;\n+import org.apache.lucene.index.RandomAccessVectorValuesProducer;\n import org.apache.lucene.index.SegmentReadState;\n import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.search.ScoreDoc;\n import org.apache.lucene.search.TopDocs;\n+import org.apache.lucene.search.TotalHits;\n import org.apache.lucene.store.ChecksumIndexInput;\n+import org.apache.lucene.store.DataInput;\n import org.apache.lucene.store.IndexInput;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.RamUsageEstimator;\n+import org.apache.lucene.util.hnsw.HnswGraph;\n+import org.apache.lucene.util.hnsw.Neighbor;\n+import org.apache.lucene.util.hnsw.Neighbors;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n \n /**\n- * Reads vectors from the index segments.\n+ * Reads vectors from the index segments along with index data structures supporting KNN search.\n  * @lucene.experimental\n  */\n public final class Lucene90VectorReader extends VectorReader {\n \n   private final FieldInfos fieldInfos;\n   private final Map<String, FieldEntry> fields = new HashMap<>();\n   private final IndexInput vectorData;\n-  private final int maxDoc;\n+  private final IndexInput vectorIndex;\n+  private final long checksumSeed;\n \n   Lucene90VectorReader(SegmentReadState state) throws IOException {\n     this.fieldInfos = state.fieldInfos;\n-    this.maxDoc = state.segmentInfo.maxDoc();\n \n-    String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene90VectorFormat.META_EXTENSION);\n+    int versionMeta = readMetadata(state, Lucene90VectorFormat.META_EXTENSION);\n+    long[] checksumRef = new long[1];\n+    vectorData = openDataInput(state, versionMeta, Lucene90VectorFormat.VECTOR_DATA_EXTENSION, Lucene90VectorFormat.VECTOR_DATA_CODEC_NAME, checksumRef);\n+    vectorIndex = openDataInput(state, versionMeta, Lucene90VectorFormat.VECTOR_INDEX_EXTENSION, Lucene90VectorFormat.VECTOR_INDEX_CODEC_NAME, checksumRef);\n+    checksumSeed = checksumRef[0];\n+  }\n+\n+  private int readMetadata(SegmentReadState state, String fileExtension) throws IOException {\n+    String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, fileExtension);\n     int versionMeta = -1;\n+    long checksum = -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83cf18f9bd3bb6214c500d23e7acf63178109bbe"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg5Nzc4MQ==", "bodyText": "Clever seed!", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519897781", "createdAt": "2020-11-09T15:26:49Z", "author": {"login": "mikemccand"}, "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -277,24 +351,46 @@ public long cost() {\n     }\n \n     @Override\n-    public RandomAccess randomAccess() {\n+    public RandomAccessVectorValues randomAccess() {\n       return new OffHeapRandomAccess(dataIn.clone());\n     }\n \n+    @Override\n+    public TopDocs search(float[] vector, int topK, int fanout) throws IOException {\n+      // use a seed that is fixed for the index so we get reproducible results for the same query\n+      final Random random = new Random(checksumSeed);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83cf18f9bd3bb6214c500d23e7acf63178109bbe"}, "originalPosition": 265}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c25c7b2da6ad845491545298565f666a8d9c4713", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/c25c7b2da6ad845491545298565f666a8d9c4713", "committedDate": "2020-11-09T17:11:25Z", "message": "Merge remote-tracking branch 'apache/master' into LUCENE-9004"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f30bd409684ffe2283997e2ce504b96b262d6364", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/f30bd409684ffe2283997e2ce504b96b262d6364", "committedDate": "2020-11-09T22:09:29Z", "message": "Make VectorValuesWriter.SortingVectorValues.randomAccess create its own non-shared vector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb64a5bec21c9d0ccea2d248c5dc5c04e3fa1ff1", "author": {"user": null}, "url": "https://github.com/apache/lucene-solr/commit/cb64a5bec21c9d0ccea2d248c5dc5c04e3fa1ff1", "committedDate": "2020-11-13T13:41:09Z", "message": "last minute tidying"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2512, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}