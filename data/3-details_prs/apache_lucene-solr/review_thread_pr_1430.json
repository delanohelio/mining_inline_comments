{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyOTY3NDYx", "number": 1430, "reviewThreads": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNzowMjozM1rOD1IGsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMDo0NDowOFrOD70ZIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MDMzOTA2OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNzowMjozM1rOGKZ0NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNzowMjozM1rOGKZ0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2MTkwOQ==", "bodyText": "\"core.metadata file is missing from shared storage\" might be more clear on why the error", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r413561909", "createdAt": "2020-04-23T07:02:33Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.blob.process;\n+\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.solr.cloud.CloudDescriptor;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.client.BlobCoreMetadata;\n+import org.apache.solr.store.blob.client.BlobCoreMetadataBuilder;\n+import org.apache.solr.store.blob.client.CoreStorageClient;\n+import org.apache.solr.store.blob.metadata.CorePushPull;\n+import org.apache.solr.store.blob.metadata.PushPullData;\n+import org.apache.solr.store.blob.metadata.ServerSideMetadata;\n+import org.apache.solr.store.blob.metadata.SharedStoreResolutionUtil;\n+import org.apache.solr.store.blob.util.BlobStoreUtils;\n+import org.apache.solr.store.shared.SharedCoreConcurrencyController;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class executes synchronous pulls of cores from the shared store.\n+ */\n+public class CorePuller {\n+\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  /**\n+   * Brings a local core up to date with the shard's index in the shared store.\n+   * \n+   * @param core core to be pulled\n+   * @param sharedShardName identifier for the shard index data located on a shared store\n+   * @param shardVersionMetadata metadata pointing to the version of shard's index in the shared store to be pulled\n+   * @param isLeaderPulling whether pull is requested by a leader replica or not\n+   */\n+  public void pullCoreFromSharedStore(SolrCore core, String sharedShardName,\n+                                      SharedShardMetadataController.SharedShardVersionMetadata shardVersionMetadata,\n+                                      boolean isLeaderPulling) {\n+    CloudDescriptor cloudDescriptor = core.getCoreDescriptor().getCloudDescriptor();\n+    String collectionName = cloudDescriptor.getCollectionName();\n+    String shardName = cloudDescriptor.getShardId();\n+    String coreName = core.getName();\n+    try {\n+      log.info(\"Initiating pull for collection=\" + collectionName + \" shard=\" + shardName + \" coreName=\" + coreName);\n+      CoreContainer coreContainer = core.getCoreContainer();\n+      SharedCoreConcurrencyController concurrencyController = coreContainer.getSharedStoreManager().getSharedCoreConcurrencyController();\n+      if (SharedShardMetadataController.METADATA_NODE_DEFAULT_VALUE.equals(shardVersionMetadata.getMetadataSuffix())) {\n+        //no-op pull\n+        BlobCoreMetadata emptyBlobCoreMetadata = BlobCoreMetadataBuilder.buildEmptyCoreMetadata(sharedShardName);\n+        concurrencyController.updateCoreVersionMetadata(collectionName, shardName, coreName, shardVersionMetadata, emptyBlobCoreMetadata, isLeaderPulling);\n+        log.info(\"Pull successful, nothing to pull, collection=\" + collectionName + \" shard=\" + shardName + \" coreName=\" + coreName);\n+        return;\n+      }\n+      concurrencyController.recordState(collectionName, shardName, coreName, SharedCoreConcurrencyController.SharedCoreStage.BLOB_PULL_STARTED);\n+      try {\n+        // Get blob metadata\n+        String blobCoreMetadataName = BlobStoreUtils.buildBlobStoreMetadataName(shardVersionMetadata.getMetadataSuffix());\n+        CoreStorageClient blobClient = coreContainer.getSharedStoreManager().getBlobStorageProvider().getClient();\n+        BlobCoreMetadata blobCoreMetadata = blobClient.pullCoreMetadata(sharedShardName, blobCoreMetadataName);\n+        if (null == blobCoreMetadata) {\n+          // Zookepeer and blob are out of sync, could be due to eventual consistency model in blob or something else went wrong.\n+          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+              \"cannot get core.metadata file from shared store, blobCoreMetadataName=\" + blobCoreMetadataName +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MDM0NzQ1OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNzowNDo1OVrOGKZ5Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QwNzowNDo1OVrOGKZ5Cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2MzE0Nw==", "bodyText": "\"core.metadata\"", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r413563147", "createdAt": "2020-04-23T07:04:59Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.blob.process;\n+\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.solr.cloud.CloudDescriptor;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.client.BlobCoreMetadata;\n+import org.apache.solr.store.blob.client.BlobCoreMetadataBuilder;\n+import org.apache.solr.store.blob.client.CoreStorageClient;\n+import org.apache.solr.store.blob.metadata.CorePushPull;\n+import org.apache.solr.store.blob.metadata.PushPullData;\n+import org.apache.solr.store.blob.metadata.ServerSideMetadata;\n+import org.apache.solr.store.blob.metadata.SharedStoreResolutionUtil;\n+import org.apache.solr.store.blob.util.BlobStoreUtils;\n+import org.apache.solr.store.shared.SharedCoreConcurrencyController;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class executes synchronous pulls of cores from the shared store.\n+ */\n+public class CorePuller {\n+\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  /**\n+   * Brings a local core up to date with the shard's index in the shared store.\n+   * \n+   * @param core core to be pulled\n+   * @param sharedShardName identifier for the shard index data located on a shared store\n+   * @param shardVersionMetadata metadata pointing to the version of shard's index in the shared store to be pulled\n+   * @param isLeaderPulling whether pull is requested by a leader replica or not\n+   */\n+  public void pullCoreFromSharedStore(SolrCore core, String sharedShardName,\n+                                      SharedShardMetadataController.SharedShardVersionMetadata shardVersionMetadata,\n+                                      boolean isLeaderPulling) {\n+    CloudDescriptor cloudDescriptor = core.getCoreDescriptor().getCloudDescriptor();\n+    String collectionName = cloudDescriptor.getCollectionName();\n+    String shardName = cloudDescriptor.getShardId();\n+    String coreName = core.getName();\n+    try {\n+      log.info(\"Initiating pull for collection=\" + collectionName + \" shard=\" + shardName + \" coreName=\" + coreName);\n+      CoreContainer coreContainer = core.getCoreContainer();\n+      SharedCoreConcurrencyController concurrencyController = coreContainer.getSharedStoreManager().getSharedCoreConcurrencyController();\n+      if (SharedShardMetadataController.METADATA_NODE_DEFAULT_VALUE.equals(shardVersionMetadata.getMetadataSuffix())) {\n+        //no-op pull\n+        BlobCoreMetadata emptyBlobCoreMetadata = BlobCoreMetadataBuilder.buildEmptyCoreMetadata(sharedShardName);\n+        concurrencyController.updateCoreVersionMetadata(collectionName, shardName, coreName, shardVersionMetadata, emptyBlobCoreMetadata, isLeaderPulling);\n+        log.info(\"Pull successful, nothing to pull, collection=\" + collectionName + \" shard=\" + shardName + \" coreName=\" + coreName);\n+        return;\n+      }\n+      concurrencyController.recordState(collectionName, shardName, coreName, SharedCoreConcurrencyController.SharedCoreStage.BLOB_PULL_STARTED);\n+      try {\n+        // Get blob metadata\n+        String blobCoreMetadataName = BlobStoreUtils.buildBlobStoreMetadataName(shardVersionMetadata.getMetadataSuffix());\n+        CoreStorageClient blobClient = coreContainer.getSharedStoreManager().getBlobStorageProvider().getClient();\n+        BlobCoreMetadata blobCoreMetadata = blobClient.pullCoreMetadata(sharedShardName, blobCoreMetadataName);\n+        if (null == blobCoreMetadata) {\n+          // Zookepeer and blob are out of sync, could be due to eventual consistency model in blob or something else went wrong.\n+          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+              \"cannot get core.metadata file from shared store, blobCoreMetadataName=\" + blobCoreMetadataName +\n+                  \" shard=\" + shardName +\n+                  \" collectionName=\" + collectionName +\n+                  \" sharedShardName=\" + sharedShardName);\n+        } else if (blobCoreMetadata.getIsDeleted()) {\n+          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+              \"core.metadata file is marked deleted in shared store, blobCoreMetadataName=\" + blobCoreMetadataName +\n+                  \" shard=\" + shardName +\n+                  \" collectionName=\" + collectionName +\n+                  \" sharedShardName=\" + sharedShardName);\n+        } else if (blobCoreMetadata.getIsCorrupt()) {\n+          log.warn(\"core.Metadata file is marked corrupt, skipping sync, collection=\" + collectionName +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDEyMzc0OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxODo1MTowNFrOGUUZDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxODo1MTowNFrOGUUZDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk1ODc5OQ==", "bodyText": "isLeaderPulling -> isLeaderInitiated?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423958799", "createdAt": "2020-05-12T18:51:04Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/blob/process/CorePuller.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.blob.process;\n+\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.solr.cloud.CloudDescriptor;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.client.BlobCoreMetadata;\n+import org.apache.solr.store.blob.client.BlobCoreMetadataBuilder;\n+import org.apache.solr.store.blob.client.CoreStorageClient;\n+import org.apache.solr.store.blob.metadata.CorePushPull;\n+import org.apache.solr.store.blob.metadata.PushPullData;\n+import org.apache.solr.store.blob.metadata.ServerSideMetadata;\n+import org.apache.solr.store.blob.metadata.SharedStoreResolutionUtil;\n+import org.apache.solr.store.blob.util.BlobStoreUtils;\n+import org.apache.solr.store.shared.SharedCoreConcurrencyController;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class executes synchronous pulls of cores from the shared store.\n+ */\n+public class CorePuller {\n+\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  /**\n+   * Brings a local core up to date with the shard's index in the shared store.\n+   * \n+   * @param core core to be pulled\n+   * @param sharedShardName identifier for the shard index data located on a shared store\n+   * @param shardVersionMetadata metadata pointing to the version of shard's index in the shared store to be pulled\n+   * @param isLeaderPulling whether pull is requested by a leader replica or not", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDIwMDc3OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToxMjo1MVrOGUVKXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMToxODozNVrOGVzVKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3MTQyMw==", "bodyText": "Thinking about this more, does this (our pull logic) play nicely with update processors pre-distributed? Our usecase has DistributedUpdateProcessor first in the chain but I'd imagine there could be issues if anything processing before this point requires an up-to-date index. We may want to revisit this later.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423971423", "createdAt": "2020-05-12T19:12:51Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -114,16 +104,29 @@\n   private RollupRequestReplicationTracker rollupReplicationTracker;\n   private LeaderRequestReplicationTracker leaderReplicationTracker;\n \n+  /**\n+   * For {@link Replica.Type#SHARED} replica, it is necessary that we pull from the shared store at the start of\n+   * an indexing batch (if the core is stale). And we push to the shared store at the end of a successfully committed\n+   * indexing batch (we ensure that each batch has a hard commit). Details can be found in \n+   * {@link org.apache.solr.store.shared.SharedCoreConcurrencyController}.\n+   * In other words, we would like to call {@link SharedCoreIndexingBatchProcessor#startIndexingBatch()} at the start of", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDAxMTYxMw==", "bodyText": "Also startIndexingBatch and finishIndexingBatch are wrapped around more public methods addOrDeleteGoingToBeIndexedLocally or hardCommitCompletedLocally that are actually used in this class. Should we reference those methods in the doc instead?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r424011613", "createdAt": "2020-05-12T20:24:57Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -114,16 +104,29 @@\n   private RollupRequestReplicationTracker rollupReplicationTracker;\n   private LeaderRequestReplicationTracker leaderReplicationTracker;\n \n+  /**\n+   * For {@link Replica.Type#SHARED} replica, it is necessary that we pull from the shared store at the start of\n+   * an indexing batch (if the core is stale). And we push to the shared store at the end of a successfully committed\n+   * indexing batch (we ensure that each batch has a hard commit). Details can be found in \n+   * {@link org.apache.solr.store.shared.SharedCoreConcurrencyController}.\n+   * In other words, we would like to call {@link SharedCoreIndexingBatchProcessor#startIndexingBatch()} at the start of", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3MTQyMw=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNDI4Mw==", "bodyText": "I never liked this place to run batch start/finish logic. I have added a TODO.\nThe doc also refers addOrDeleteGoingToBeIndexedLocally and hardCommitCompletedLocally few lines later.\nstartIndexingBatch and finishIndexingBatch are mentioned first because they are the real reason for whole logic. They are not public because they don't need to be. But if/when we find another better place to start/finish a batch we will likely make them public and directly call them.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425514283", "createdAt": "2020-05-15T01:18:35Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -114,16 +104,29 @@\n   private RollupRequestReplicationTracker rollupReplicationTracker;\n   private LeaderRequestReplicationTracker leaderReplicationTracker;\n \n+  /**\n+   * For {@link Replica.Type#SHARED} replica, it is necessary that we pull from the shared store at the start of\n+   * an indexing batch (if the core is stale). And we push to the shared store at the end of a successfully committed\n+   * indexing batch (we ensure that each batch has a hard commit). Details can be found in \n+   * {@link org.apache.solr.store.shared.SharedCoreConcurrencyController}.\n+   * In other words, we would like to call {@link SharedCoreIndexingBatchProcessor#startIndexingBatch()} at the start of", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3MTQyMw=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDIwMjMwOnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToxMzoxNVrOGUVLUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMToyMDozMFrOGVzW3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3MTY2NQ==", "bodyText": "processDelete in this comment too?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423971665", "createdAt": "2020-05-12T19:13:15Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -114,16 +104,29 @@\n   private RollupRequestReplicationTracker rollupReplicationTracker;\n   private LeaderRequestReplicationTracker leaderReplicationTracker;\n \n+  /**\n+   * For {@link Replica.Type#SHARED} replica, it is necessary that we pull from the shared store at the start of\n+   * an indexing batch (if the core is stale). And we push to the shared store at the end of a successfully committed\n+   * indexing batch (we ensure that each batch has a hard commit). Details can be found in \n+   * {@link org.apache.solr.store.shared.SharedCoreConcurrencyController}.\n+   * In other words, we would like to call {@link SharedCoreIndexingBatchProcessor#startIndexingBatch()} at the start of\n+   * an indexing batch and {@link SharedCoreIndexingBatchProcessor#finishIndexingBatch()} at the end of a successfully\n+   * committed indexing batch.\n+   * For that, we rely on first {@link #processAdd(AddUpdateCommand)} or {@link #processCommit(CommitUpdateCommand)}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNDcxNg==", "bodyText": "Thanks for catching. Actually processCommit was incorrectly mentioned in place of processDelete.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425514716", "createdAt": "2020-05-15T01:20:30Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -114,16 +104,29 @@\n   private RollupRequestReplicationTracker rollupReplicationTracker;\n   private LeaderRequestReplicationTracker leaderReplicationTracker;\n \n+  /**\n+   * For {@link Replica.Type#SHARED} replica, it is necessary that we pull from the shared store at the start of\n+   * an indexing batch (if the core is stale). And we push to the shared store at the end of a successfully committed\n+   * indexing batch (we ensure that each batch has a hard commit). Details can be found in \n+   * {@link org.apache.solr.store.shared.SharedCoreConcurrencyController}.\n+   * In other words, we would like to call {@link SharedCoreIndexingBatchProcessor#startIndexingBatch()} at the start of\n+   * an indexing batch and {@link SharedCoreIndexingBatchProcessor#finishIndexingBatch()} at the end of a successfully\n+   * committed indexing batch.\n+   * For that, we rely on first {@link #processAdd(AddUpdateCommand)} or {@link #processCommit(CommitUpdateCommand)}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3MTY2NQ=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDIxODI5OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToxODoxM1rOGUVWDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMTozMDo1MVrOGVzg-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3NDQxMg==", "bodyText": "Doesn't this break the contract that only the leader may correctly write to shared storage? If we lose leadership before we can push the commit, shouldn't the batch considered failed instead so its retried on the new leader by the client?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423974412", "createdAt": "2020-05-12T19:18:13Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -184,6 +186,30 @@ public void processCommit(CommitUpdateCommand cmd) throws IOException {\n \n     updateCommand = cmd;\n \n+    // 1. SHARED replica has a hard requirement of processing each indexing batch with a hard commit(either explicit or\n+    // implicit, HttpSolrCall#addCommitIfAbsent) because that is how, at the end of an indexing batch, synchronous push\n+    // to shared store gets hold of the segment files on local disk. SHARED replica also does not support the notion of soft commit.\n+    // Therefore unlike NRT replica type we do not need to broadcast commit to the leaders of all the shards of a collection.\n+    //\n+    // 2. <code>isLeader</code> is computed fresh each time an AddUpdateCommand/DeleteUpdateCommand belonging to the indexing\n+    // batch is processed. And finally it is recomputed in this method. It is possible that at the beginning of a batch\n+    // this replica was a leader and did process some AddUpdateCommand/DeleteUpdateCommand. But before reaching this \n+    // method lost the leadership. In that case we will still like to process the commit otherwise the indexing batch can\n+    // succeed without pushing the changes to the shared store (data loss). Therefore, we are not restricting the ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNzMwNg==", "bodyText": "SHARED replica does not need leadership as such because it relies on the optimistic concurrency when writing to metadataSuffix znode. As long as a replica can match the metadataSuffix version it started indexing with, it will be correct. If the new leader has started indexing and have pushed before this replica then this replica will fail. But if it pushes before the new leader can push then the batch on new leader will fail. In both cases indexing will be correct.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425517306", "createdAt": "2020-05-15T01:30:51Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -184,6 +186,30 @@ public void processCommit(CommitUpdateCommand cmd) throws IOException {\n \n     updateCommand = cmd;\n \n+    // 1. SHARED replica has a hard requirement of processing each indexing batch with a hard commit(either explicit or\n+    // implicit, HttpSolrCall#addCommitIfAbsent) because that is how, at the end of an indexing batch, synchronous push\n+    // to shared store gets hold of the segment files on local disk. SHARED replica also does not support the notion of soft commit.\n+    // Therefore unlike NRT replica type we do not need to broadcast commit to the leaders of all the shards of a collection.\n+    //\n+    // 2. <code>isLeader</code> is computed fresh each time an AddUpdateCommand/DeleteUpdateCommand belonging to the indexing\n+    // batch is processed. And finally it is recomputed in this method. It is possible that at the beginning of a batch\n+    // this replica was a leader and did process some AddUpdateCommand/DeleteUpdateCommand. But before reaching this \n+    // method lost the leadership. In that case we will still like to process the commit otherwise the indexing batch can\n+    // succeed without pushing the changes to the shared store (data loss). Therefore, we are not restricting the ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3NDQxMg=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI0NDgzOnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyNTo1OFrOGUVnAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMTo1MjoxNVrOGVz2Bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3ODc1Mg==", "bodyText": "This means we won't support a client explicitly sending commit=true to a replica of a shard and having it route to the leader for SHARED replicas or clients sending commit=true for the purpose of refreshing all of the searchers in their collection (though most won't be stale if indexing is progressing in the presence of leadership change).", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423978752", "createdAt": "2020-05-12T19:25:58Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -184,6 +186,30 @@ public void processCommit(CommitUpdateCommand cmd) throws IOException {\n \n     updateCommand = cmd;\n \n+    // 1. SHARED replica has a hard requirement of processing each indexing batch with a hard commit(either explicit or\n+    // implicit, HttpSolrCall#addCommitIfAbsent) because that is how, at the end of an indexing batch, synchronous push\n+    // to shared store gets hold of the segment files on local disk. SHARED replica also does not support the notion of soft commit.\n+    // Therefore unlike NRT replica type we do not need to broadcast commit to the leaders of all the shards of a collection.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyMjY5NA==", "bodyText": "Correct. Former is not needed because isolated commit is a no-op for SHARED replica and later is not supported because SHARED replica has a different plan around opening of searchers https://issues.apache.org/jira/browse/SOLR-14339\nI have updated the comments.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425522694", "createdAt": "2020-05-15T01:52:15Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -184,6 +186,30 @@ public void processCommit(CommitUpdateCommand cmd) throws IOException {\n \n     updateCommand = cmd;\n \n+    // 1. SHARED replica has a hard requirement of processing each indexing batch with a hard commit(either explicit or\n+    // implicit, HttpSolrCall#addCommitIfAbsent) because that is how, at the end of an indexing batch, synchronous push\n+    // to shared store gets hold of the segment files on local disk. SHARED replica also does not support the notion of soft commit.\n+    // Therefore unlike NRT replica type we do not need to broadcast commit to the leaders of all the shards of a collection.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3ODc1Mg=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI0ODc1OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyNzoxNlrOGUVpxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyNzoxNlrOGUVpxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3OTQ2Mw==", "bodyText": "Can we add to this comment to explain why after setupRequest for future ref", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423979463", "createdAt": "2020-05-12T19:27:16Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -275,9 +293,10 @@ public void processAdd(AddUpdateCommand cmd) throws IOException {\n     // check if client has requested minimum replication factor information. will set replicationTracker to null if\n     // we aren't the leader or subShardLeader\n     checkReplicationTracker(cmd);\n-    // Update the local cores if needed.\n-    if (replicaType.equals(Replica.Type.SHARED)) {\n-      readFromSharedStoreIfNecessary();\n+\n+    // this should be called after setupRequest(UpdateCommand) and before the doc is indexed locally", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI1MDc2OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyNzo0NlrOGUVrEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyNzo0NlrOGUVrEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk3OTc5Mg==", "bodyText": "Same as L297", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423979792", "createdAt": "2020-05-12T19:27:46Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -363,6 +377,11 @@ protected void doDeleteById(DeleteUpdateCommand cmd) throws IOException {\n     // we aren't the leader or subShardLeader\n     checkReplicationTracker(cmd);\n \n+    // this should be called after setupRequest(UpdateCommand) and before the doc is indexed locally", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI1MjUzOnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyODoxOFrOGUVsPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyODoxOFrOGUVsPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4MDA5Mw==", "bodyText": "Same as L297", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423980093", "createdAt": "2020-05-12T19:28:18Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -497,6 +516,12 @@ protected void doDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {\n     // check if client has requested minimum replication factor information. will set replicationTracker to null if\n     // we aren't the leader or subShardLeader\n     checkReplicationTracker(cmd);\n+\n+    // this should be called after setupRequest(UpdateCommand) and before the doc is indexed locally ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 192}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI1NTQwOnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyOTowOFrOGUVt9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOToyOTowOFrOGUVt9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4MDUzMw==", "bodyText": "belongs -> belong", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423980533", "createdAt": "2020-05-12T19:29:08Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -1465,4 +1318,30 @@ private void zkCheck() {\n \n     throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Cannot talk to ZooKeeper - Updates are disabled.\");\n   }\n+\n+  private boolean isSharedCoreAddOrDeleteGoingToBeIndexedLocally() {\n+    // forwardToLeader: if true, then the update is going to be forwarded to its rightful leader.\n+    //                  The doc being added or deleted might not even belongs to the current core's (req.getCore()) shard.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 408}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI1OTI1OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTozMDoyN1rOGUVwwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjowMDoxMFrOGVz9yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4MTI0OA==", "bodyText": "there -> their\nand\n\"forward the add/delete updates since we don't forward commit-only updates\"?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423981248", "createdAt": "2020-05-12T19:30:27Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -1465,4 +1318,30 @@ private void zkCheck() {\n \n     throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Cannot talk to ZooKeeper - Updates are disabled.\");\n   }\n+\n+  private boolean isSharedCoreAddOrDeleteGoingToBeIndexedLocally() {\n+    // forwardToLeader: if true, then the update is going to be forwarded to its rightful leader.\n+    //                  The doc being added or deleted might not even belongs to the current core's (req.getCore()) shard.\n+    // isLeader: if true, then the current core (req.getCore()) is the leader of the shard to which the doc being added or deleted belongs to.\n+    //           For SHARED replicas only leader replicas do local indexing. Follower SHARED replicas do not do any local \n+    //           indexing and there only job is to forward the updates to the leader replica.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 411}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyNDY4Mg==", "bodyText": "correct.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425524682", "createdAt": "2020-05-15T02:00:10Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -1465,4 +1318,30 @@ private void zkCheck() {\n \n     throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Cannot talk to ZooKeeper - Updates are disabled.\");\n   }\n+\n+  private boolean isSharedCoreAddOrDeleteGoingToBeIndexedLocally() {\n+    // forwardToLeader: if true, then the update is going to be forwarded to its rightful leader.\n+    //                  The doc being added or deleted might not even belongs to the current core's (req.getCore()) shard.\n+    // isLeader: if true, then the current core (req.getCore()) is the leader of the shard to which the doc being added or deleted belongs to.\n+    //           For SHARED replicas only leader replicas do local indexing. Follower SHARED replicas do not do any local \n+    //           indexing and there only job is to forward the updates to the leader replica.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4MTI0OA=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 411}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI4MDE1OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTozNTo0NVrOGUV-kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjowMDoyNlrOGVz-Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4NDc4Nw==", "bodyText": "We'll likely have to update this comment when we revisit the split/buffering process for SHARED replica", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423984787", "createdAt": "2020-05-12T19:35:45Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -1465,4 +1318,30 @@ private void zkCheck() {\n \n     throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Cannot talk to ZooKeeper - Updates are disabled.\");\n   }\n+\n+  private boolean isSharedCoreAddOrDeleteGoingToBeIndexedLocally() {\n+    // forwardToLeader: if true, then the update is going to be forwarded to its rightful leader.\n+    //                  The doc being added or deleted might not even belongs to the current core's (req.getCore()) shard.\n+    // isLeader: if true, then the current core (req.getCore()) is the leader of the shard to which the doc being added or deleted belongs to.\n+    //           For SHARED replicas only leader replicas do local indexing. Follower SHARED replicas do not do any local \n+    //           indexing and there only job is to forward the updates to the leader replica.\n+    // isSubShardLeader: if true, then the current core (req.getCore()) is the leader of a sub shard being built.\n+    //                   Sub shard leaders only buffer the updates locally and apply them towards the end of a successful", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 413}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyNDc1MA==", "bodyText": "yes.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425524750", "createdAt": "2020-05-15T02:00:26Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/java/org/apache/solr/update/processor/DistributedZkUpdateProcessor.java", "diffHunk": "@@ -1465,4 +1318,30 @@ private void zkCheck() {\n \n     throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Cannot talk to ZooKeeper - Updates are disabled.\");\n   }\n+\n+  private boolean isSharedCoreAddOrDeleteGoingToBeIndexedLocally() {\n+    // forwardToLeader: if true, then the update is going to be forwarded to its rightful leader.\n+    //                  The doc being added or deleted might not even belongs to the current core's (req.getCore()) shard.\n+    // isLeader: if true, then the current core (req.getCore()) is the leader of the shard to which the doc being added or deleted belongs to.\n+    //           For SHARED replicas only leader replicas do local indexing. Follower SHARED replicas do not do any local \n+    //           indexing and there only job is to forward the updates to the leader replica.\n+    // isSubShardLeader: if true, then the current core (req.getCore()) is the leader of a sub shard being built.\n+    //                   Sub shard leaders only buffer the updates locally and apply them towards the end of a successful", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4NDc4Nw=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 413}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDI5NDA3OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTozOTo1NlrOGUWHkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTozOTo1NlrOGUWHkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4NzA4OA==", "bodyText": "We now know this can happen for applied buffered updates", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423987088", "createdAt": "2020-05-12T19:39:56Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessor.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.shared;\n+\n+import java.io.Closeable;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.solr.cloud.CloudDescriptor;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n+import org.apache.solr.common.cloud.Slice;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.process.CorePuller;\n+import org.apache.solr.store.blob.process.CorePusher;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class is responsible for bringing a stale SHARED core upto date by pulling from the shared store at the start \n+ * of an indexing batch and pushing the updated core at the end of a successfully committed indexing batch. \n+ */\n+public class SharedCoreIndexingBatchProcessor implements Closeable {\n+\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+  /**\n+   * Time indexing thread needs to wait to try acquiring pull write lock before checking if someone else has already done the pull.\n+   */\n+  public static int SECONDS_TO_WAIT_INDEXING_PULL_WRITE_LOCK = 5;\n+  /**\n+   * Max attempts by indexing thread to try acquiring pull write lock before bailing out. Ideally bail out scenario should never happen.\n+   * If it does then either we are too slow in pulling and can tune this value or something else is wrong.\n+   */\n+  public static int MAX_ATTEMPTS_INDEXING_PULL_WRITE_LOCK = 10;\n+\n+  private final SolrCore core;\n+  private final String collectionName;\n+  private final String shardName;\n+  private final String sharedShardName;\n+  private final CorePusher corePusher;\n+  private final CorePuller corePuller;\n+  private IndexingBatchState state;\n+  private ReentrantReadWriteLock corePullLock;\n+\n+  public SharedCoreIndexingBatchProcessor(SolrCore core, ClusterState clusterState) {\n+    this.core = core;\n+    CloudDescriptor cloudDescriptor = core.getCoreDescriptor().getCloudDescriptor();\n+    collectionName = cloudDescriptor.getCollectionName();\n+    shardName = cloudDescriptor.getShardId();\n+\n+    DocCollection collection = clusterState.getCollection(collectionName);\n+    if (!collection.getSharedIndex()) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, collectionName + \" is not a shared collection.\");\n+    }\n+\n+    Slice shard = collection.getSlicesMap().get(shardName);\n+    if (shard == null) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Indexing batch received for an unknown shard,\" +\n+          \" collection=\" + collectionName + \" shard=\" + shardName + \" core=\" + core.getName());\n+    }\n+\n+    if (!Slice.State.ACTIVE.equals(shard.getState())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDMwMzA2OnYy", "diffSide": "RIGHT", "path": "solr/core/src/java/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTo0Mjo0NFrOGUWNhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxOTo0Mjo0NFrOGUWNhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk4ODYxMg==", "bodyText": "on wards -> onward", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r423988612", "createdAt": "2020-05-12T19:42:44Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/java/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessor.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.shared;\n+\n+import java.io.Closeable;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.solr.cloud.CloudDescriptor;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n+import org.apache.solr.common.cloud.Slice;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.process.CorePuller;\n+import org.apache.solr.store.blob.process.CorePusher;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class is responsible for bringing a stale SHARED core upto date by pulling from the shared store at the start \n+ * of an indexing batch and pushing the updated core at the end of a successfully committed indexing batch. \n+ */\n+public class SharedCoreIndexingBatchProcessor implements Closeable {\n+\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+  /**\n+   * Time indexing thread needs to wait to try acquiring pull write lock before checking if someone else has already done the pull.\n+   */\n+  public static int SECONDS_TO_WAIT_INDEXING_PULL_WRITE_LOCK = 5;\n+  /**\n+   * Max attempts by indexing thread to try acquiring pull write lock before bailing out. Ideally bail out scenario should never happen.\n+   * If it does then either we are too slow in pulling and can tune this value or something else is wrong.\n+   */\n+  public static int MAX_ATTEMPTS_INDEXING_PULL_WRITE_LOCK = 10;\n+\n+  private final SolrCore core;\n+  private final String collectionName;\n+  private final String shardName;\n+  private final String sharedShardName;\n+  private final CorePusher corePusher;\n+  private final CorePuller corePuller;\n+  private IndexingBatchState state;\n+  private ReentrantReadWriteLock corePullLock;\n+\n+  public SharedCoreIndexingBatchProcessor(SolrCore core, ClusterState clusterState) {\n+    this.core = core;\n+    CloudDescriptor cloudDescriptor = core.getCoreDescriptor().getCloudDescriptor();\n+    collectionName = cloudDescriptor.getCollectionName();\n+    shardName = cloudDescriptor.getShardId();\n+\n+    DocCollection collection = clusterState.getCollection(collectionName);\n+    if (!collection.getSharedIndex()) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, collectionName + \" is not a shared collection.\");\n+    }\n+\n+    Slice shard = collection.getSlicesMap().get(shardName);\n+    if (shard == null) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Indexing batch received for an unknown shard,\" +\n+          \" collection=\" + collectionName + \" shard=\" + shardName + \" core=\" + core.getName());\n+    }\n+\n+    if (!Slice.State.ACTIVE.equals(shard.getState())) {\n+      // unclear what this means, but logging a warning for now\n+      log.warn(\"Processing an indexing batch for a non-active shard,\" +\n+          \" collection=\" + collectionName + \" shard=\" + shardName + \" core=\" + core.getName());\n+    }\n+\n+    sharedShardName = (String) shard.get(ZkStateReader.SHARED_SHARD_NAME);\n+    corePuller = new CorePuller();\n+    corePusher = new CorePusher();\n+    state = IndexingBatchState.NOT_STARTED;\n+  }\n+\n+  /**\n+   * Should be called whenever a document is about to be added/deleted from the SHARED core. If it is the first doc\n+   * of the core, this method will mark  the start of an indexing batch and bring a stale SHARED core upto date by\n+   * pulling from the shared store.\n+   */\n+  public void addOrDeleteGoingToBeIndexedLocally() {\n+    // Following logic is built on the assumption that one particular instance of this processor\n+    // will solely be consumed by a single thread. And all the documents of indexing batch will be processed by this one instance. \n+    String coreName = core.getName();\n+    if (IndexingBatchState.NOT_STARTED.equals(state)) {\n+      startIndexingBatch();\n+    } else if (IndexingBatchState.STARTED.equals(state)) {\n+      // do nothing, we only use this method to start an indexing batch once\n+    } else if (IndexingBatchState.COMMITTED.equals(state)) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n+          \"Why are we adding/deleting a doc through an already committed indexing batch?\" +\n+              \" collection=\" + collectionName + \" shard=\" + shardName + \" core=\" + coreName);\n+    } else {\n+      throwUnknownStateError();\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  protected void startIndexingBatch() {\n+    // Following pull logic should only run once before the first add/delete of an indexing batch is processed by this processor\n+\n+    assert IndexingBatchState.NOT_STARTED.equals(state);\n+\n+    if (corePullLock != null) {\n+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"How come we already have a pull read lock?\" +\n+          \" collection=\" + collectionName + \" shard=\" + shardName + \" core=\" + core.getName());\n+    }\n+\n+    String coreName = core.getName();\n+    CoreContainer coreContainer = core.getCoreContainer();\n+    SharedCoreConcurrencyController concurrencyController = coreContainer.getSharedStoreManager().getSharedCoreConcurrencyController();\n+    corePullLock = concurrencyController.getCorePullLock(collectionName, shardName, coreName);\n+    // from this point on wards we should always exit this method with read lock (no matter failure or what)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDQ2OTcxOnYy", "diffSide": "RIGHT", "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreConcurrencyTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMDozMTozMlrOGUX0_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjowNzozNFrOGV0Etw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDAxNTEwMg==", "bodyText": "what was the reason for this change?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r424015102", "createdAt": "2020-05-12T20:31:32Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreConcurrencyTest.java", "diffHunk": "@@ -595,7 +595,7 @@ private void configureTestSharedConcurrencyControllerForProcess(\n       public void recordState(String collectionName, String shardName, String coreName, SharedCoreStage stage) {\n         super.recordState(collectionName, shardName, coreName, stage);\n         ConcurrentLinkedQueue<String> coreConcurrencyStages = coreConcurrencyStagesMap.computeIfAbsent(coreName, k -> new ConcurrentLinkedQueue<>());\n-        coreConcurrencyStages.add(Thread.currentThread().getId() + \".\" + stage.name());\n+        coreConcurrencyStages.add(Thread.currentThread().getName() + \".\" + stage.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyNjQ1NQ==", "bodyText": "Sorry this is some what irrelevant. Looking through one of test run logs I realized in logging if thread has a name then that is logged e.g. puller threads. This change is only to help make debugging of this test easier.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425526455", "createdAt": "2020-05-15T02:07:34Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreConcurrencyTest.java", "diffHunk": "@@ -595,7 +595,7 @@ private void configureTestSharedConcurrencyControllerForProcess(\n       public void recordState(String collectionName, String shardName, String coreName, SharedCoreStage stage) {\n         super.recordState(collectionName, shardName, coreName, stage);\n         ConcurrentLinkedQueue<String> coreConcurrencyStages = coreConcurrencyStagesMap.computeIfAbsent(coreName, k -> new ConcurrentLinkedQueue<>());\n-        coreConcurrencyStages.add(Thread.currentThread().getId() + \".\" + stage.name());\n+        coreConcurrencyStages.add(Thread.currentThread().getName() + \".\" + stage.name());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDAxNTEwMg=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY0MDUwOTc3OnYy", "diffSide": "RIGHT", "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMDo0NDowOFrOGUYO2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMjoyOTowOFrOGV0aFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDAyMTcyMw==", "bodyText": "is this supposed to be its own test from L219?", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r424021723", "createdAt": "2020-05-12T20:44:08Z", "author": {"login": "andyvuong"}, "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.shared;\n+\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.process.CorePuller;\n+import org.apache.solr.store.blob.process.CorePusher;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Unit tests for {@link SharedCoreIndexingBatchProcessor}\n+ */\n+public class SharedCoreIndexingBatchProcessorTest extends  SolrCloudSharedStoreTestCase {\n+\n+  private static final String COLLECTION_NAME = \"sharedCollection\";\n+  private static final String SHARD_NAME = \"shard1\";\n+\n+  private SolrCore core;\n+  private CorePuller corePuller;\n+  private CorePusher corePusher;\n+  private ReentrantReadWriteLock corePullLock;\n+  private SharedCoreIndexingBatchProcessor processor;\n+\n+  @BeforeClass\n+  public static void setupCluster() throws Exception {\n+    assumeWorkingMockito();\n+    setupCluster(1);\n+  }\n+\n+  @Before\n+  public void setupTest() throws Exception {\n+    assertEquals(\"wrong number of nodes\", 1, cluster.getJettySolrRunners().size());\n+    CoreContainer cc = cluster.getJettySolrRunner(0).getCoreContainer();\n+\n+    int maxShardsPerNode = 1;\n+    int numReplicas = 1;\n+    setupSharedCollectionWithShardNames(COLLECTION_NAME, maxShardsPerNode, numReplicas, SHARD_NAME);\n+    DocCollection collection = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);\n+\n+    assertEquals(\"wrong number of replicas\", 1, collection.getReplicas().size());\n+    core = cc.getCore(collection.getReplicas().get(0).getCoreName());\n+\n+    assertNotNull(\"core is null\", core);\n+\n+    corePuller = Mockito.spy(new CorePuller());\n+    corePusher = Mockito.spy(new CorePusher());\n+    processor = new SharedCoreIndexingBatchProcessor(core, core.getCoreContainer().getZkController().getClusterState()) {\n+      @Override\n+      protected CorePuller getCorePuller() {\n+        return corePuller;\n+      }\n+\n+      @Override\n+      protected CorePusher getCorePusher() {\n+        return corePusher;\n+      }\n+    };\n+    processor = Mockito.spy(processor);\n+    corePullLock = core.getCoreContainer().getSharedStoreManager().getSharedCoreConcurrencyController().getCorePullLock(\n+        COLLECTION_NAME, SHARD_NAME, core.getName());\n+  }\n+\n+  @After\n+  public void teardownTest() throws Exception {\n+    if (core != null) {\n+      core.close();\n+    }\n+    if (processor != null) {\n+      processor.close();\n+      assertEquals(\"read lock count is wrong\", 0, corePullLock.getReadLockCount());\n+    }\n+    if (cluster != null) {\n+      cluster.deleteAllCollections();\n+    }\n+  }\n+\n+  /**\n+   * Tests that first add/delete starts an indexing batch.\n+   */\n+  @Test\n+  public void testAddOrDeleteStart() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that two adds/deletes only start an indexing batch once.\n+   */\n+  @Test\n+  public void testTwoAddOrDeleteOnlyStartOnce() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that commit does finish an indexing batch.\n+   */\n+  @Test\n+  public void testCommitDoesFinish() throws Exception {\n+    verify(processor, never()).finishIndexingBatch();\n+    processCommit();\n+    verify(processor).finishIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that a stale core is pulled at the start of an indexing batch.\n+   */\n+  @Test\n+  public void testStaleCoreIsPulledAtStart() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    verify(corePuller, never()).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that an up-to-date core is not pulled at the start of an indexing batch.\n+   */\n+  @Test\n+  public void testUpToDateCoreIsNotPulledAtStart() throws Exception {\n+    SharedShardMetadataController.SharedShardVersionMetadata shardVersionMetadata = core.getCoreContainer()\n+        .getSharedStoreManager().getSharedShardMetadataController().readMetadataValue(COLLECTION_NAME, SHARD_NAME);\n+    ClusterState clusterState = core.getCoreContainer().getZkController().getClusterState();\n+    DocCollection collection = clusterState.getCollection(COLLECTION_NAME);\n+    String sharedShardName = (String) collection.getSlicesMap().get(SHARD_NAME).get(ZkStateReader.SHARED_SHARD_NAME);\n+    corePuller.pullCoreFromSharedStore(core, sharedShardName, shardVersionMetadata, true);\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that a read lock is acquired even when the start encounters an error.\n+   */\n+  @Test\n+  public void testReadLockIsAcquiredEvenStartEncountersError() throws Exception {\n+    doThrow(new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"pull failed\"))\n+        .when(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    verify(processor, never()).startIndexingBatch();\n+    verify(corePuller, never()).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    assertEquals(\"wrong pull read lock count\", 0, corePullLock.getReadLockCount());\n+    boolean errorOccurred = false;\n+    try {\n+      processor.startIndexingBatch();\n+      fail(\"No exception thrown\");\n+    } catch (Exception ex) {\n+      assertTrue(\"Wrong exception thrown\", ex.getMessage().contains(\"pull failed\"));\n+    }\n+    assertEquals(\"wrong pull read lock count\", 1, corePullLock.getReadLockCount());\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that an indexing batch with some work does push to the shared store.\n+   */\n+  @Test\n+  public void testCommitAfterAddOrDeleteDoesPush() throws Exception {\n+    processAddOrDelete();\n+    processCommit();\n+    verify(corePusher).pushCoreToSharedStore(any(), any());\n+  }\n+\n+  /**\n+   * Tests that an indexing batch with no work does not push to the shared store.\n+   */\n+  @Test\n+  public void testIsolatedCommitDoesNotPush() throws Exception {\n+    processCommit();\n+    verify(corePusher, never()).pushCoreToSharedStore(any(), any());\n+  }\n+\n+  /**\n+   * Tests that an already committed indexing batch throws if a doc/deleted again.\n+   */\n+  @Test\n+  public void testAddOrDeleteAfterCommitThrows() throws Exception {\n+    processAddOrDelete();\n+    testAddOrDeleteAfterIsolatedCommitThrows();\n+  }\n+\n+  /**\n+   * Tests that an already isolated committed indexing batch throws if a doc/deleted again.\n+   */\n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUzMTkyNA==", "bodyText": "Two different flavors of tests. One with commit after some add/delete and the other one just isolated commit. I also got confused re-reading this. I believe confusion was coming from the re-use of test method. To make it more readable I have extracted the common code in separate method.", "url": "https://github.com/apache/lucene-solr/pull/1430#discussion_r425531924", "createdAt": "2020-05-15T02:29:08Z", "author": {"login": "mbwaheed"}, "path": "solr/core/src/test/org/apache/solr/store/shared/SharedCoreIndexingBatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.store.shared;\n+\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.common.cloud.ClusterState;\n+import org.apache.solr.common.cloud.DocCollection;\n+import org.apache.solr.common.cloud.ZkStateReader;\n+import org.apache.solr.core.CoreContainer;\n+import org.apache.solr.core.SolrCore;\n+import org.apache.solr.store.blob.process.CorePuller;\n+import org.apache.solr.store.blob.process.CorePusher;\n+import org.apache.solr.store.shared.metadata.SharedShardMetadataController;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Unit tests for {@link SharedCoreIndexingBatchProcessor}\n+ */\n+public class SharedCoreIndexingBatchProcessorTest extends  SolrCloudSharedStoreTestCase {\n+\n+  private static final String COLLECTION_NAME = \"sharedCollection\";\n+  private static final String SHARD_NAME = \"shard1\";\n+\n+  private SolrCore core;\n+  private CorePuller corePuller;\n+  private CorePusher corePusher;\n+  private ReentrantReadWriteLock corePullLock;\n+  private SharedCoreIndexingBatchProcessor processor;\n+\n+  @BeforeClass\n+  public static void setupCluster() throws Exception {\n+    assumeWorkingMockito();\n+    setupCluster(1);\n+  }\n+\n+  @Before\n+  public void setupTest() throws Exception {\n+    assertEquals(\"wrong number of nodes\", 1, cluster.getJettySolrRunners().size());\n+    CoreContainer cc = cluster.getJettySolrRunner(0).getCoreContainer();\n+\n+    int maxShardsPerNode = 1;\n+    int numReplicas = 1;\n+    setupSharedCollectionWithShardNames(COLLECTION_NAME, maxShardsPerNode, numReplicas, SHARD_NAME);\n+    DocCollection collection = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);\n+\n+    assertEquals(\"wrong number of replicas\", 1, collection.getReplicas().size());\n+    core = cc.getCore(collection.getReplicas().get(0).getCoreName());\n+\n+    assertNotNull(\"core is null\", core);\n+\n+    corePuller = Mockito.spy(new CorePuller());\n+    corePusher = Mockito.spy(new CorePusher());\n+    processor = new SharedCoreIndexingBatchProcessor(core, core.getCoreContainer().getZkController().getClusterState()) {\n+      @Override\n+      protected CorePuller getCorePuller() {\n+        return corePuller;\n+      }\n+\n+      @Override\n+      protected CorePusher getCorePusher() {\n+        return corePusher;\n+      }\n+    };\n+    processor = Mockito.spy(processor);\n+    corePullLock = core.getCoreContainer().getSharedStoreManager().getSharedCoreConcurrencyController().getCorePullLock(\n+        COLLECTION_NAME, SHARD_NAME, core.getName());\n+  }\n+\n+  @After\n+  public void teardownTest() throws Exception {\n+    if (core != null) {\n+      core.close();\n+    }\n+    if (processor != null) {\n+      processor.close();\n+      assertEquals(\"read lock count is wrong\", 0, corePullLock.getReadLockCount());\n+    }\n+    if (cluster != null) {\n+      cluster.deleteAllCollections();\n+    }\n+  }\n+\n+  /**\n+   * Tests that first add/delete starts an indexing batch.\n+   */\n+  @Test\n+  public void testAddOrDeleteStart() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that two adds/deletes only start an indexing batch once.\n+   */\n+  @Test\n+  public void testTwoAddOrDeleteOnlyStartOnce() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that commit does finish an indexing batch.\n+   */\n+  @Test\n+  public void testCommitDoesFinish() throws Exception {\n+    verify(processor, never()).finishIndexingBatch();\n+    processCommit();\n+    verify(processor).finishIndexingBatch();\n+  }\n+\n+  /**\n+   * Tests that a stale core is pulled at the start of an indexing batch.\n+   */\n+  @Test\n+  public void testStaleCoreIsPulledAtStart() throws Exception {\n+    verify(processor, never()).startIndexingBatch();\n+    verify(corePuller, never()).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that an up-to-date core is not pulled at the start of an indexing batch.\n+   */\n+  @Test\n+  public void testUpToDateCoreIsNotPulledAtStart() throws Exception {\n+    SharedShardMetadataController.SharedShardVersionMetadata shardVersionMetadata = core.getCoreContainer()\n+        .getSharedStoreManager().getSharedShardMetadataController().readMetadataValue(COLLECTION_NAME, SHARD_NAME);\n+    ClusterState clusterState = core.getCoreContainer().getZkController().getClusterState();\n+    DocCollection collection = clusterState.getCollection(COLLECTION_NAME);\n+    String sharedShardName = (String) collection.getSlicesMap().get(SHARD_NAME).get(ZkStateReader.SHARED_SHARD_NAME);\n+    corePuller.pullCoreFromSharedStore(core, sharedShardName, shardVersionMetadata, true);\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    verify(processor, never()).startIndexingBatch();\n+    processAddOrDelete();\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that a read lock is acquired even when the start encounters an error.\n+   */\n+  @Test\n+  public void testReadLockIsAcquiredEvenStartEncountersError() throws Exception {\n+    doThrow(new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"pull failed\"))\n+        .when(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    verify(processor, never()).startIndexingBatch();\n+    verify(corePuller, never()).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+    assertEquals(\"wrong pull read lock count\", 0, corePullLock.getReadLockCount());\n+    boolean errorOccurred = false;\n+    try {\n+      processor.startIndexingBatch();\n+      fail(\"No exception thrown\");\n+    } catch (Exception ex) {\n+      assertTrue(\"Wrong exception thrown\", ex.getMessage().contains(\"pull failed\"));\n+    }\n+    assertEquals(\"wrong pull read lock count\", 1, corePullLock.getReadLockCount());\n+    verify(processor).startIndexingBatch();\n+    verify(corePuller).pullCoreFromSharedStore(any(), any(), any(), anyBoolean());\n+  }\n+\n+  /**\n+   * Tests that an indexing batch with some work does push to the shared store.\n+   */\n+  @Test\n+  public void testCommitAfterAddOrDeleteDoesPush() throws Exception {\n+    processAddOrDelete();\n+    processCommit();\n+    verify(corePusher).pushCoreToSharedStore(any(), any());\n+  }\n+\n+  /**\n+   * Tests that an indexing batch with no work does not push to the shared store.\n+   */\n+  @Test\n+  public void testIsolatedCommitDoesNotPush() throws Exception {\n+    processCommit();\n+    verify(corePusher, never()).pushCoreToSharedStore(any(), any());\n+  }\n+\n+  /**\n+   * Tests that an already committed indexing batch throws if a doc/deleted again.\n+   */\n+  @Test\n+  public void testAddOrDeleteAfterCommitThrows() throws Exception {\n+    processAddOrDelete();\n+    testAddOrDeleteAfterIsolatedCommitThrows();\n+  }\n+\n+  /**\n+   * Tests that an already isolated committed indexing batch throws if a doc/deleted again.\n+   */\n+  @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDAyMTcyMw=="}, "originalCommit": {"oid": "1d7eaf579769f76886fa5273879c0b6c09faeeea"}, "originalPosition": 225}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 766, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}