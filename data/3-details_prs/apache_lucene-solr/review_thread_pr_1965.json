{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAwMDM3OTY3", "number": 1965, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzozNzo0OFrOEtl1rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjo1MToyMFrOEuFfWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MjQxMzI3OnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzozNzo0OFrOHhd9TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzozNzo0OFrOHhd9TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg1NTg4NA==", "bodyText": "This should not call getAttribute and instead use the instance flagsAtt above (instance field). In the next line it's correct.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504855884", "createdAt": "2020-10-14T17:37:48Z", "author": {"login": "uschindler"}, "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "diffHunk": "@@ -64,9 +82,15 @@ public boolean incrementToken() throws IOException {\n       }\n       termAtt.append(typeAtt.type());\n       posIncrAtt.setPositionIncrement(0);\n+      // control what flags transfer to synonym\n+      int flags = getAttribute(FlagsAttribute.class).getFlags();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MjQxOTg0OnYy", "diffSide": "RIGHT", "path": "lucene/CHANGES.txt", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzozOTo0MFrOHheBig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1NDoyNFrOHhekGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg1Njk3MA==", "bodyText": "same issue like in previous PR!", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504856970", "createdAt": "2020-10-14T17:39:40Z", "author": {"login": "uschindler"}, "path": "lucene/CHANGES.txt", "diffHunk": "@@ -15,7 +15,7 @@ API Changes\n * LUCENE-8474: RAMDirectory and associated deprecated classes have been\n   removed. (Dawid Weiss)\n \n-* LUCENE-3041: The deprecated Weight#extractTerms() method has been \n+* LUCENE-3041: The deprecated Weight#extractTerms() method has been", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NTgxNw==", "bodyText": "Well actually this PR predates other :), but yes same issue.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504865817", "createdAt": "2020-10-14T17:54:24Z", "author": {"login": "gus-asf"}, "path": "lucene/CHANGES.txt", "diffHunk": "@@ -15,7 +15,7 @@ API Changes\n * LUCENE-8474: RAMDirectory and associated deprecated classes have been\n   removed. (Dawid Weiss)\n \n-* LUCENE-3041: The deprecated Weight#extractTerms() method has been \n+* LUCENE-3041: The deprecated Weight#extractTerms() method has been", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg1Njk3MA=="}, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MjQ2MDU1OnYy", "diffSide": "RIGHT", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1MDozOFrOHhebCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1Nzo1NFrOHhesXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzQ5OA==", "bodyText": "that's all bits except the first 1 (01111111111111111...). To invert all bits use -1 or better ~0", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504863498", "createdAt": "2020-10-14T17:50:38Z", "author": {"login": "uschindler"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -190,7 +196,8 @@ public static void assertTokenStreamContents(TokenStream ts, String[] output, in\n       if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n       if (keywordAtt != null) keywordAtt.setKeyword((i&1) == 0);\n       if (payloadAtt != null) payloadAtt.setPayload(new BytesRef(new byte[] { 0x00, -0x21, 0x12, -0x43, 0x24 }));\n-      \n+      if (flagsAtt != null) flagsAtt.setFlags(Integer.MAX_VALUE); // all 1's", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NzkzNA==", "bodyText": "oops yeah realized that partway through (when I switched to ~0 for the other file), didn't come back and fix it here.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504867934", "createdAt": "2020-10-14T17:57:54Z", "author": {"login": "gus-asf"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -190,7 +196,8 @@ public static void assertTokenStreamContents(TokenStream ts, String[] output, in\n       if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n       if (keywordAtt != null) keywordAtt.setKeyword((i&1) == 0);\n       if (payloadAtt != null) payloadAtt.setPayload(new BytesRef(new byte[] { 0x00, -0x21, 0x12, -0x43, 0x24 }));\n-      \n+      if (flagsAtt != null) flagsAtt.setFlags(Integer.MAX_VALUE); // all 1's", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzQ5OA=="}, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MjQ2MTM4OnYy", "diffSide": "RIGHT", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1MDo1NFrOHhebmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1MDo1NFrOHhebmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzY0Mg==", "bodyText": "same here", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504863642", "createdAt": "2020-10-14T17:50:54Z", "author": {"login": "uschindler"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -294,6 +304,7 @@ public static void assertTokenStreamContents(TokenStream ts, String[] output, in\n     if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n     if (keywordAtt != null) keywordAtt.setKeyword(true);\n     if (payloadAtt != null) payloadAtt.setPayload(new BytesRef(new byte[] { 0x00, -0x21, 0x12, -0x43, 0x24 }));\n+    if (flagsAtt != null) flagsAtt.setFlags(Integer.MAX_VALUE); // all 1's", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MjQ2Mzk1OnYy", "diffSide": "RIGHT", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNzo1MTozNVrOHhedPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQyMTo1Mjo0NFrOHhmhLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NDA2MQ==", "bodyText": "maybe we should not change this method signature and just add another one, so we do not need to change unrelated files like MinHashFilter?", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504864061", "createdAt": "2020-10-14T17:51:35Z", "author": {"login": "uschindler"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -125,7 +125,7 @@ public void reflectWith(AttributeReflector reflector) {\n   //     arriving to pos Y have the same endOffset)\n   public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDk5NjE0MQ==", "bodyText": "Done, I think what was originally submitted was a bit easier than sorting out all the parameters at the time, but yes nicer to minimize.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504996141", "createdAt": "2020-10-14T21:52:44Z", "author": {"login": "gus-asf"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -125,7 +125,7 @@ public void reflectWith(AttributeReflector reflector) {\n   //     arriving to pos Y have the same endOffset)\n   public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NDA2MQ=="}, "originalCommit": {"oid": "9a25d7eefe877d5cfde76de065ad26da6d799ad4"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MzU3MjIyOnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQyMjo1MzoyMFrOHhpTRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQwODo1MjoxMFrOHh8_Tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw==", "bodyText": "Why not use Set.of() (since Java 11)?", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505041733", "createdAt": "2020-10-14T22:53:20Z", "author": {"login": "uschindler"}, "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.\n+ * This typically applies when the analysis would remove characters that should remain in the synonym.\n+ */\n+public class TestTypeAsSynonymFilter extends BaseTokenStreamTestCase {\n+\n+  /**\n+   * Test the straight forward case with the simplest constructor. Simply converts every\n+   * type to a synonym. Typically one wants to also set an ignore list containing \"word\" unless\n+   * that default value is removed by prior analysis.\n+   */\n+  public void testSimple() throws Exception {\n+\n+    Token token = new Token(\"foo\", 0, 2);\n+    token.setType(\"bar\");\n+    Token token2 = new Token(\"foo\", 4, 6);\n+    TokenStream ts = new CannedTokenStream(token, token2);\n+    ts = new TypeAsSynonymFilter(ts);\n+\n+    // \"word\" is the default type!\n+    assertTokenStreamContents(ts, new String[] {\n+        \"foo\", \"bar\",\"foo\",\"word\"},new int[] {0,0,4,4}, new int[]{2,2,6,6}, new int[] {1,0,1,0});\n+  }\n+\n+  /**\n+   * Tests that we can add a prefix to the synonym (for example, to keep it from ever matching user input directly),\n+   * and test that we can ignore a list of type values we don't wish to turn into synonyms.\n+   */\n+  public void testWithPrefixAndIgnore() throws Exception {\n+    Token[] tokens = new Token[] {\n+        new Token(\"foo\", 1, 3),\n+        new Token(\"foo\", 5, 7),\n+        new Token(\"foo\", 9, 11),\n+    } ;\n+    tokens[0].setType(\"bar\");\n+    tokens[2].setType(\"ignoreme\");\n+    TokenStream ts = new CannedTokenStream(tokens);\n+    ts = new TypeAsSynonymFilter(ts,\"pfx_\", Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()), 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfadcc750f3e47b587af6aa04a0b554ec748a34a"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MjQ5Mw==", "bodyText": "Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()) => Set.of(\"word\",\"ignoreme\")", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505042493", "createdAt": "2020-10-14T22:54:32Z", "author": {"login": "uschindler"}, "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.\n+ * This typically applies when the analysis would remove characters that should remain in the synonym.\n+ */\n+public class TestTypeAsSynonymFilter extends BaseTokenStreamTestCase {\n+\n+  /**\n+   * Test the straight forward case with the simplest constructor. Simply converts every\n+   * type to a synonym. Typically one wants to also set an ignore list containing \"word\" unless\n+   * that default value is removed by prior analysis.\n+   */\n+  public void testSimple() throws Exception {\n+\n+    Token token = new Token(\"foo\", 0, 2);\n+    token.setType(\"bar\");\n+    Token token2 = new Token(\"foo\", 4, 6);\n+    TokenStream ts = new CannedTokenStream(token, token2);\n+    ts = new TypeAsSynonymFilter(ts);\n+\n+    // \"word\" is the default type!\n+    assertTokenStreamContents(ts, new String[] {\n+        \"foo\", \"bar\",\"foo\",\"word\"},new int[] {0,0,4,4}, new int[]{2,2,6,6}, new int[] {1,0,1,0});\n+  }\n+\n+  /**\n+   * Tests that we can add a prefix to the synonym (for example, to keep it from ever matching user input directly),\n+   * and test that we can ignore a list of type values we don't wish to turn into synonyms.\n+   */\n+  public void testWithPrefixAndIgnore() throws Exception {\n+    Token[] tokens = new Token[] {\n+        new Token(\"foo\", 1, 3),\n+        new Token(\"foo\", 5, 7),\n+        new Token(\"foo\", 9, 11),\n+    } ;\n+    tokens[0].setType(\"bar\");\n+    tokens[2].setType(\"ignoreme\");\n+    TokenStream ts = new CannedTokenStream(tokens);\n+    ts = new TypeAsSynonymFilter(ts,\"pfx_\", Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()), 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}, "originalCommit": {"oid": "bfadcc750f3e47b587af6aa04a0b554ec748a34a"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTExOTk3NQ==", "bodyText": "Ah yeah sure. Originally developed vs 8.4 but now I can use it :)", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505119975", "createdAt": "2020-10-15T02:01:13Z", "author": {"login": "gus-asf"}, "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.\n+ * This typically applies when the analysis would remove characters that should remain in the synonym.\n+ */\n+public class TestTypeAsSynonymFilter extends BaseTokenStreamTestCase {\n+\n+  /**\n+   * Test the straight forward case with the simplest constructor. Simply converts every\n+   * type to a synonym. Typically one wants to also set an ignore list containing \"word\" unless\n+   * that default value is removed by prior analysis.\n+   */\n+  public void testSimple() throws Exception {\n+\n+    Token token = new Token(\"foo\", 0, 2);\n+    token.setType(\"bar\");\n+    Token token2 = new Token(\"foo\", 4, 6);\n+    TokenStream ts = new CannedTokenStream(token, token2);\n+    ts = new TypeAsSynonymFilter(ts);\n+\n+    // \"word\" is the default type!\n+    assertTokenStreamContents(ts, new String[] {\n+        \"foo\", \"bar\",\"foo\",\"word\"},new int[] {0,0,4,4}, new int[]{2,2,6,6}, new int[] {1,0,1,0});\n+  }\n+\n+  /**\n+   * Tests that we can add a prefix to the synonym (for example, to keep it from ever matching user input directly),\n+   * and test that we can ignore a list of type values we don't wish to turn into synonyms.\n+   */\n+  public void testWithPrefixAndIgnore() throws Exception {\n+    Token[] tokens = new Token[] {\n+        new Token(\"foo\", 1, 3),\n+        new Token(\"foo\", 5, 7),\n+        new Token(\"foo\", 9, 11),\n+    } ;\n+    tokens[0].setType(\"bar\");\n+    tokens[2].setType(\"ignoreme\");\n+    TokenStream ts = new CannedTokenStream(tokens);\n+    ts = new TypeAsSynonymFilter(ts,\"pfx_\", Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()), 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}, "originalCommit": {"oid": "bfadcc750f3e47b587af6aa04a0b554ec748a34a"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM2NDMwMg==", "bodyText": "In 8.x I'd use: new HashSet(Arrays.asList(\"word\",\"ignoreme\")), but that's a matter of preference. I tend to not use streams if there's no transformations/mappings going on.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505364302", "createdAt": "2020-10-15T08:52:10Z", "author": {"login": "uschindler"}, "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.\n+ * This typically applies when the analysis would remove characters that should remain in the synonym.\n+ */\n+public class TestTypeAsSynonymFilter extends BaseTokenStreamTestCase {\n+\n+  /**\n+   * Test the straight forward case with the simplest constructor. Simply converts every\n+   * type to a synonym. Typically one wants to also set an ignore list containing \"word\" unless\n+   * that default value is removed by prior analysis.\n+   */\n+  public void testSimple() throws Exception {\n+\n+    Token token = new Token(\"foo\", 0, 2);\n+    token.setType(\"bar\");\n+    Token token2 = new Token(\"foo\", 4, 6);\n+    TokenStream ts = new CannedTokenStream(token, token2);\n+    ts = new TypeAsSynonymFilter(ts);\n+\n+    // \"word\" is the default type!\n+    assertTokenStreamContents(ts, new String[] {\n+        \"foo\", \"bar\",\"foo\",\"word\"},new int[] {0,0,4,4}, new int[]{2,2,6,6}, new int[] {1,0,1,0});\n+  }\n+\n+  /**\n+   * Tests that we can add a prefix to the synonym (for example, to keep it from ever matching user input directly),\n+   * and test that we can ignore a list of type values we don't wish to turn into synonyms.\n+   */\n+  public void testWithPrefixAndIgnore() throws Exception {\n+    Token[] tokens = new Token[] {\n+        new Token(\"foo\", 1, 3),\n+        new Token(\"foo\", 5, 7),\n+        new Token(\"foo\", 9, 11),\n+    } ;\n+    tokens[0].setType(\"bar\");\n+    tokens[2].setType(\"ignoreme\");\n+    TokenStream ts = new CannedTokenStream(tokens);\n+    ts = new TypeAsSynonymFilter(ts,\"pfx_\", Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()), 0);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}, "originalCommit": {"oid": "bfadcc750f3e47b587af6aa04a0b554ec748a34a"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2NzUyOTkzOnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozMzozNlrOHiQaHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozMzozNlrOHiQaHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4MjQ2MQ==", "bodyText": "Consider adding the new features to the class comment", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505682461", "createdAt": "2020-10-15T16:33:36Z", "author": {"login": "sarowe"}, "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "diffHunk": "@@ -34,23 +36,39 @@\n   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2NzUzODcyOnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozNTo0N1rOHiQfew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozNTo0N1rOHiQfew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4MzgzNQ==", "bodyText": "Consider adding configuration for the new features to the example Solr configuration.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505683835", "createdAt": "2020-10-15T16:35:47Z", "author": {"login": "sarowe"}, "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "diffHunk": "@@ -18,12 +18,15 @@\n package org.apache.lucene.analysis.miscellaneous;\n \n import java.util.Map;\n+import java.util.Set;\n \n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.TokenFilterFactory;\n \n /**\n  * Factory for {@link TypeAsSynonymFilter}.\n+ *\n+ * <p>In Solr this might be used as such", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2NzU0NjgzOnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozNzo0OVrOHiQkpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNzowNzoyMlrOHiRs0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTE1OQ==", "bodyText": "There is a method getSet() which you could use instead of get() for the ignoreList; it does the splitting for you, and also supports mixed space/comma separators.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505685159", "createdAt": "2020-10-15T16:37:49Z", "author": {"login": "sarowe"}, "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "diffHunk": "@@ -46,10 +49,17 @@\n   public static final String NAME = \"typeAsSynonym\";\n \n   private final String prefix;\n+  private Set<String> ignore = null;\n+  private final int synFlagMask;\n \n   public TypeAsSynonymFilterFactory(Map<String,String> args) {\n     super(args);\n     prefix = get(args, \"prefix\");  // default value is null\n+    String ignoreList = get(args, \"ignore\");\n+    synFlagMask = getInt(args,\"synFlagsMask\", ~0);\n+    if (ignoreList != null) {\n+      ignore = Set.of(ignoreList.split(\",\"));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcwMzYzNQ==", "bodyText": "Ah cool.", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505703635", "createdAt": "2020-10-15T17:07:22Z", "author": {"login": "gus-asf"}, "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "diffHunk": "@@ -46,10 +49,17 @@\n   public static final String NAME = \"typeAsSynonym\";\n \n   private final String prefix;\n+  private Set<String> ignore = null;\n+  private final int synFlagMask;\n \n   public TypeAsSynonymFilterFactory(Map<String,String> args) {\n     super(args);\n     prefix = get(args, \"prefix\");  // default value is null\n+    String ignoreList = get(args, \"ignore\");\n+    synFlagMask = getInt(args,\"synFlagsMask\", ~0);\n+    if (ignoreList != null) {\n+      ignore = Set.of(ignoreList.split(\",\"));\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTE1OQ=="}, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2NzU1MDQ3OnYy", "diffSide": "RIGHT", "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozODo0OFrOHiQnBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjozODo0OFrOHiQnBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTc2NA==", "bodyText": "typo: ben", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505685764", "createdAt": "2020-10-15T16:38:48Z", "author": {"login": "sarowe"}, "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2NzU5ODk3OnYy", "diffSide": "RIGHT", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNjo1MToyMFrOHiRFcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNVQxNzowODoyNVrOHiRv8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY5MzU1Mw==", "bodyText": "Since you put back the original method, I think you can also revert this change?", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505693553", "createdAt": "2020-10-15T16:51:20Z", "author": {"login": "sarowe"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -390,19 +406,19 @@ public static void assertAnalyzesTo(Analyzer a, String input, String[] output, i\n   }\n \n   public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n-    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n+    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcwNDQzMg==", "bodyText": "ok", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505704432", "createdAt": "2020-10-15T17:08:25Z", "author": {"login": "gus-asf"}, "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -390,19 +406,19 @@ public static void assertAnalyzesTo(Analyzer a, String input, String[] output, i\n   }\n \n   public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n-    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n+    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads, null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY5MzU1Mw=="}, "originalCommit": {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd"}, "originalPosition": 211}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1139, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}