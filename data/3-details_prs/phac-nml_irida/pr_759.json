{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUzNzk2ODEw", "number": 759, "title": "Object store/ azure", "bodyText": "Description of changes\nWhat did you change in this pull request?  Provide a description of files changed, user interactions changed, etc.  Include how to test your changes.\nAdded support for AZURE object store\nRelated issue\nLink to the GitHub issue this pull request addresses using the #issuenum format.  If it completes an issue, use Fixes #issuenum to automatically close the issue.\nRelated to #228\nChecklist\nThings for the developer to confirm they've done before the PR should be accepted:\n* [ ] CHANGELOG.md (and UPGRADING.md if necessary) updated with information for new change.\n* [ ] Tests added (or description of how to test) for any new features.\n* [ ] User documentation updated for UI or technical changes.", "createdAt": "2020-07-20T20:13:08Z", "url": "https://github.com/phac-nml/irida/pull/759", "merged": true, "mergeCommit": {"oid": "c81f2284a6fc502621286a7d63e644ad2696a01c"}, "closed": true, "closedAt": "2020-11-04T21:00:42Z", "author": {"login": "deepsidhu85"}, "timelineItems": {"totalCount": 63, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcZl35kAH2gAyNDUzNzk2ODEwOjA0NDVjODk1Nzg3NDdhYWMxMTQyY2UyM2U1MzJjNWVkY2M0MDEwNTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZUOeLgFqTUyMzczMDUwNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0445c89578747aac1142ce23e532c5edcc401053", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/0445c89578747aac1142ce23e532c5edcc401053", "committedDate": "2020-04-20T21:21:44Z", "message": "Added azure file storage implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74a8321c54e160dd9e90d0e8334bd71a1592618e", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/74a8321c54e160dd9e90d0e8334bd71a1592618e", "committedDate": "2020-04-20T21:32:33Z", "message": "Removed aws dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d551c2fe591feb148ff467010f70e6b792bb12a0", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/d551c2fe591feb148ff467010f70e6b792bb12a0", "committedDate": "2020-04-22T19:36:30Z", "message": "Merged base branch and fixed merge conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3429d99afc7a0bd179ae7ecbaeb31ffbc33610e", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/f3429d99afc7a0bd179ae7ecbaeb31ffbc33610e", "committedDate": "2020-04-22T19:50:39Z", "message": "Removed unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ce1be7b8f077b7854d2e2acde4a1f34b9e1ef74", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/9ce1be7b8f077b7854d2e2acde4a1f34b9e1ef74", "committedDate": "2020-04-23T15:52:33Z", "message": "Upped the version of azure to fix race condition when opening blob stream. Updated comments and refactored code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "101099a6b1ef2f7159e70927e5c062f3030bf7d9", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/101099a6b1ef2f7159e70927e5c062f3030bf7d9", "committedDate": "2020-04-27T19:35:11Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce85c264c2101c58af82305b22c3e0834d6f2aa3", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/ce85c264c2101c58af82305b22c3e0834d6f2aa3", "committedDate": "2020-04-27T21:50:26Z", "message": "Updated tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed8865f30d2231b6e77c329ff02e65cc8a936d72", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/ed8865f30d2231b6e77c329ff02e65cc8a936d72", "committedDate": "2020-04-29T00:27:05Z", "message": "Updated code to work with newer version of jackson-core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c217c4d0ac3fe00dadc281ed632faf9e2e040437", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/c217c4d0ac3fe00dadc281ed632faf9e2e040437", "committedDate": "2020-04-29T15:58:20Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4e3f7f0b661a09eb16bcfa91cc1eed46a6bb7f5", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/b4e3f7f0b661a09eb16bcfa91cc1eed46a6bb7f5", "committedDate": "2020-04-30T18:55:09Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f8c98839535c513553bf2e631a0931f485b1215", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/4f8c98839535c513553bf2e631a0931f485b1215", "committedDate": "2020-05-06T13:57:51Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e973db16d219e031e22491940f1474092f08563a", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/e973db16d219e031e22491940f1474092f08563a", "committedDate": "2020-05-20T19:40:32Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90cfe53775e71c23153b9fde660abf5751052bee", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/90cfe53775e71c23153b9fde660abf5751052bee", "committedDate": "2020-05-20T21:00:46Z", "message": "Updated controller to fix failing tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91f6ab21233ed70229d975769fe2d9fe73514134", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/91f6ab21233ed70229d975769fe2d9fe73514134", "committedDate": "2020-05-22T23:33:20Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cd96c3493b5c8149955db9d28e046b6ddc5ebdbe", "author": {"user": null}, "url": "https://github.com/phac-nml/irida/commit/cd96c3493b5c8149955db9d28e046b6ddc5ebdbe", "committedDate": "2020-05-26T19:23:47Z", "message": "Merge branch 'object_store/_base' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94589440146b32ec5321a9b836aaa76cf2a613dc", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/94589440146b32ec5321a9b836aaa76cf2a613dc", "committedDate": "2020-06-16T20:09:08Z", "message": "Merged base branch and fixed merge conflict"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "089e266b987e1cdb2a2d57b48400709b09237416", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/089e266b987e1cdb2a2d57b48400709b09237416", "committedDate": "2020-06-17T18:36:06Z", "message": "Merged base branch, fixed merge conflict. Updated name to IridaFileStorageAzureUtilityImpl for azure implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7efb45d0e13a4d517edc3e626811a1cf1f5ebdb0", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/7efb45d0e13a4d517edc3e626811a1cf1f5ebdb0", "committedDate": "2020-07-15T15:45:56Z", "message": "Merged base branch and fixed merge conflict"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34cd883c2658a9e931632d050caf94477797af03", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/34cd883c2658a9e931632d050caf94477797af03", "committedDate": "2020-07-17T15:52:06Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e01fe6b246dd047f1f56f039c7f4554b555eed2", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/4e01fe6b246dd047f1f56f039c7f4554b555eed2", "committedDate": "2020-07-20T20:09:48Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b92448777d5c6315b6bcf15cba595ade32246d2", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/8b92448777d5c6315b6bcf15cba595ade32246d2", "committedDate": "2020-07-20T20:32:54Z", "message": "Changed concateexception to ioexception. Updated getFileSize method in azure implementation of iridafilestorageutility to return a string"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95e89d3e27aec6c6e87ee4d679ceeb40362f91c1", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/95e89d3e27aec6c6e87ee4d679ceeb40362f91c1", "committedDate": "2020-07-20T20:35:16Z", "message": "Renamed method parameter to be generic. Updated text displayed when an IOException is thrown"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8583556018d5858fe0a79335181d1877154c442", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/c8583556018d5858fe0a79335181d1877154c442", "committedDate": "2020-07-20T21:19:42Z", "message": "Removed unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/e91bafbbf743a246c50ac4f4acac398217beafd4", "committedDate": "2020-07-20T21:52:59Z", "message": "Updated test variable"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1OTk5MTg3", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-455999187", "createdAt": "2020-07-27T17:42:21Z", "commit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNzo0MjoyMVrOG3s3nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTowMToxNVrOG4RCqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1OTk5Nw==", "bodyText": "We already import lots of jackson stuff already, why do we need the new import?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461059997", "createdAt": "2020-07-27T17:42:21Z", "author": {"login": "tom114"}, "path": "pom.xml", "diffHunk": "@@ -344,6 +344,11 @@\n \t\t\t<artifactId>jackson-databind</artifactId>\n \t\t\t<version>${jackson.version}</version>\n \t\t</dependency>\n+\t\t<dependency>\n+\t\t\t<groupId>com.fasterxml.jackson.core</groupId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA==", "bodyText": "Why do we need the @ResponseBody stuff here?  The REST API should automatically be returning JSON without it.  What happens without these?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461060634", "createdAt": "2020-07-27T17:43:25Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg==", "bodyText": "This section looks like duplicate imports to me.  Aren't these already imported somewhere else?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461100752", "createdAt": "2020-07-27T18:54:58Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "diffHunk": "@@ -35,6 +35,16 @@\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleMetadataController;\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleSequenceFilesController;\n \n+import com.google.common.net.HttpHeaders;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.hateoas.Link;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Controller;\n+import org.springframework.ui.ModelMap;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.servlet.ModelAndView;\n+import org.springframework.web.servlet.view.RedirectView;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw==", "bodyText": "Rather than directly creating a file in /tmp use the Files.createTempDirectory method.  This will automatically create a unique directory in the appropriate location.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461599693", "createdAt": "2020-07-28T13:56:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMTE3Nw==", "bodyText": "Should this be a global?  It looks like it's initialized in every method.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461601177", "createdAt": "2020-07-28T13:58:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA==", "bodyText": "What's this for?  If it's just some random requirement for this code can you write a long comment about why it's here?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461651304", "createdAt": "2020-07-28T14:59:30Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA==", "bodyText": "The VALID_EXTENSIONS thing is for concatenating right?  Can you rename that variable and the comments around it with that info please?  It confuses me every time.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461652648", "createdAt": "2020-07-28T15:01:15Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {\n+\t\tString absolutePath = file.toAbsolutePath().toString();\n+\t\tif(absolutePath.charAt(0) == '/') {\n+\t\t\tabsolutePath = file.toAbsolutePath()\n+\t\t\t\t\t.toString()\n+\t\t\t\t\t.substring(1);\n+\t\t}\n+\t\treturn absolutePath;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void appendToFile(Path target, SequenceFile file) throws IOException{\n+\t\ttry (FileChannel out = FileChannel.open(target, StandardOpenOption.CREATE, StandardOpenOption.APPEND,\n+\t\t\t\tStandardOpenOption.WRITE)) {\n+\t\t\ttry (FileChannel in = new FileInputStream(getTemporaryFile(file.getFile())).getChannel()) {\n+\t\t\t\tfor (long p = 0, l = in.size(); p < l; ) {\n+\t\t\t\t\tp += in.transferTo(p, l - p, out);\n+\t\t\t\t}\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new IOException(\"Could not open input file for reading\", e);\n+\t\t\t}\n+\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new IOException(\"Could not open target file for writing\", e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException {\n+\t\tString selectedExtension = null;\n+\t\tfor (SequencingObject object : sequencingObjects) {\n+\n+\t\t\tfor (SequenceFile file : object.getFiles()) {\n+\t\t\t\tString fileName = getFileName(file.getFile());\n+\n+\t\t\t\tOptional<String> currentExtensionOpt = VALID_EXTENSIONS.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 221}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23c0b6d48cdf222b4c5674c280f79ed361766082", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/23c0b6d48cdf222b4c5674c280f79ed361766082", "committedDate": "2020-08-04T16:16:10Z", "message": "Removed @ResponseBody from rest controllers. Updated azure storage utility getTemporaryFile method. Removed duplicate imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2fbdcba5960698104c64d60d0dc1e65ac704d670", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/2fbdcba5960698104c64d60d0dc1e65ac704d670", "committedDate": "2020-08-04T16:28:10Z", "message": "Removed unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fdd25e1d2dc4f0342951f50e259cf2ec0657dfb2", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/fdd25e1d2dc4f0342951f50e259cf2ec0657dfb2", "committedDate": "2020-08-04T16:46:47Z", "message": "Updated variable name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51d1b298f6f6d0e5746810c1742022ea2c4a1d9e", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/51d1b298f6f6d0e5746810c1742022ea2c4a1d9e", "committedDate": "2020-08-04T17:54:09Z", "message": "Updated variable name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed912d41e3c61a6f49f0641acb0a16d93790af26", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/ed912d41e3c61a6f49f0641acb0a16d93790af26", "committedDate": "2020-08-12T15:00:52Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eea5f064c73e6ad6b63c67e60d129480dcb974a3", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/eea5f064c73e6ad6b63c67e60d129480dcb974a3", "committedDate": "2020-08-12T15:04:46Z", "message": "Removed dependency not required. Updated comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/1d77db91ce07dee1b577890082d13ee5360a0717", "committedDate": "2020-08-12T15:08:29Z", "message": "Removed @ResponseBody annotation not required"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d7418652545636565ceb4389f8db1cc6166e90b", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/4d7418652545636565ceb4389f8db1cc6166e90b", "committedDate": "2020-08-13T16:37:47Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2Mjc4OTM3", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-466278937", "createdAt": "2020-08-12T21:08:35Z", "commit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMTowODozNVrOG_y77Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxODozMTo0NFrOHAYb_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw==", "bodyText": "These exceptions should be logger.error level at least.  Honestly I'm not even sure these should be caught.  Should they maybe just be let go so that an appropriate error gets thrown up?  Just swallowing them here and logging could cause issues.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r469548013", "createdAt": "2020-08-12T21:08:35Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MTkwNg==", "bodyText": "As we discussed I think it would be good to wrap these exceptions in a StorageException.  We're already using that in the local storage utility so it would be good to use the same thing.\nPlease add that to any of the places in this file where we're just wrapping the BlobStorageException and logging.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470161906", "createdAt": "2020-08-13T18:30:56Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw=="}, "originalCommit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MjQzMA==", "bodyText": "As discussed lets try switching this to use Files.createTempFile instead of downloading to this specified location.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470162430", "createdAt": "2020-08-13T18:31:44Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d7418652545636565ceb4389f8db1cc6166e90b"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdee3fd5ecbe7c0e5096d3f5889a51af59eac4f2", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/bdee3fd5ecbe7c0e5096d3f5889a51af59eac4f2", "committedDate": "2020-08-18T21:22:16Z", "message": "Updated to use temporary files which are cleaned up after they have been used"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b16c81a35cbfe72080cf3818046d989db28fcad", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/4b16c81a35cbfe72080cf3818046d989db28fcad", "committedDate": "2020-08-18T21:36:51Z", "message": "Updated to throw a storageexception if file is not found on azure rather than just logging a message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/d1684d340301b0ee6445ac72a903ac6019342a4c", "committedDate": "2020-08-20T20:12:16Z", "message": "Updated FastQCFileProcessor to clean up temp files in a finally block. Updated cleanupLocalFiles method to removed temp directories"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNTQ5MjM0", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-473549234", "createdAt": "2020-08-24T14:34:24Z", "commit": {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNDozNDoyNFrOHFn1yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNDozNDoyNFrOHFn1yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY1NzY3NA==", "bodyText": "This class should be throwing a StorageException in all of these catch cases.  This method and all of the below.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r475657674", "createdAt": "2020-08-24T14:34:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c"}, "originalPosition": 70}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5988e06b794923529c3dd6889ff54b983970516a", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/5988e06b794923529c3dd6889ff54b983970516a", "committedDate": "2020-08-25T16:32:55Z", "message": "Changed from throwing ioexception to storageexception in azure file storage utility class"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc2ODcxMjc0", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-476871274", "createdAt": "2020-08-27T16:06:10Z", "commit": {"oid": "5988e06b794923529c3dd6889ff54b983970516a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNjowNjoxMFrOHIXRsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNjowNjoxMFrOHIXRsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUzMjAxNg==", "bodyText": "I don't think we should walk up to delete a parent directory.  While this shouldn't be an issue with our temp directories, it has the possibility of being accidentally misused and deleting a required directory.  if we're deleting a directory, I think it should be explicitly called to be deleted.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r478532016", "createdAt": "2020-08-27T16:06:10Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,281 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());\n+\t\t\tthrow new StorageException(e.getMessage());\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void cleanupLocalFiles(Path path) {\n+\t\tlogger.trace(\"Cleaning up temporary file downloaded from azure [\" + path.toString() + \"]\");\n+\n+\t\tPath origPath = path;\n+\t\tif(Files.isRegularFile(path)) {\n+\t\t\torigPath = path;\n+\t\t\tpath = path.getParent();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5988e06b794923529c3dd6889ff54b983970516a"}, "originalPosition": 87}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46fe13d1c605f4f904ff4b5ec6f433dc322d8737", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/46fe13d1c605f4f904ff4b5ec6f433dc322d8737", "committedDate": "2020-08-31T22:29:11Z", "message": "Updated getTemporaryFile method to return an IridaTemporaryFile object which has the path to the file and temporary directory. Updating directory removal"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cf54992305acf71bf222471ec4fc5d0e5d4d5fe", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/4cf54992305acf71bf222471ec4fc5d0e5d4d5fe", "committedDate": "2020-08-31T22:59:58Z", "message": "Fixed nullpointer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64984255444dfcf7490e7e32af61ca717a135937", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/64984255444dfcf7490e7e32af61ca717a135937", "committedDate": "2020-08-31T23:47:27Z", "message": "Removed unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05feefc11ed7c0e21deb78ad450036145ace7e5f", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/05feefc11ed7c0e21deb78ad450036145ace7e5f", "committedDate": "2020-09-01T18:07:05Z", "message": "Added a new method to cleanup local temporary files/directories and renamed previous method named cleanupLocalFiles. Updated logic in SamplesAjaxController to cleanup temp files/directories that are created."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8978508ddb1c7efcf74bea343516ea5fdb24b867", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/8978508ddb1c7efcf74bea343516ea5fdb24b867", "committedDate": "2020-09-01T18:46:02Z", "message": "Fixed logic so if the instance is using local storage it will clean up the file in a diretory if it exists"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7275c81aec8be26d33a80a302ad2a5a2484fd91a", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/7275c81aec8be26d33a80a302ad2a5a2484fd91a", "committedDate": "2020-09-01T20:33:06Z", "message": "Updated concatenator classes to return an iridaconcatenatortemporyfile pojo which contains the sequencing object and temporary file directory path which can be cleaned up in the sequencingobjectservice. Updated tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa0aca42498ea6647309db43637647e544db2b81", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/fa0aca42498ea6647309db43637647e544db2b81", "committedDate": "2020-09-02T15:13:30Z", "message": "Updated gzipfileprocessor to cleanup temporary local files and directories if the removeTemporaryFiles variable is set to true (defaults to true for autowired constructor but second constructor has an extra variable which is used by the gzipfileprocessortest to not delete the temporary files as the files are cleaned up once the test has finished running). Updated logger text."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bd9018d94882d33a9f10ab0a3007f64ec632e0b", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/8bd9018d94882d33a9f10ab0a3007f64ec632e0b", "committedDate": "2020-09-02T15:21:17Z", "message": "Updated method comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/a3254d00f733d0780c7d91896177e6f5da2b883c", "committedDate": "2020-09-02T15:27:39Z", "message": "Removed @Responsebody annotation for test methods as it is a restcontroller and the contentnegotiator returns the data as json"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyODk3MzQ5", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-482897349", "createdAt": "2020-09-04T19:29:58Z", "commit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxOToyOTo1OFrOHNZbdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMDozODoxMVrOHOtL_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgxMDE2NA==", "bodyText": "Something feels wrong with needing this file.  Particularily seeing where you use it the filePath portion is often null.  Is there a way to do this just returning either the SequencingObject or just an IridaTemporaryFile?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483810164", "createdAt": "2020-09-04T19:29:58Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaConcatenatorTemporaryFile.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory\n+ * for a concatenator object\n+ */\n+\n+public class IridaConcatenatorTemporaryFile {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw==", "bodyText": "If we're having this IridaTemporaryFile class we should likely have it be the responsibility of IridaFiles to create those files.  Not creating them in places like this.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483825713", "createdAt": "2020-09-04T20:11:52Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE3OTc3NQ==", "bodyText": "As discussed lets revert these changes back to the deleteIfExists stuff for now.  We can refactor this in a later branch when needed.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485179775", "createdAt": "2020-09-08T20:32:42Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/samples/RESTSampleAssemblyController.java", "diffHunk": "@@ -182,8 +183,7 @@ public ModelMap addNewAssemblyToSample(@PathVariable Long sampleId, @RequestPart\n \t\t} finally {\n \t\t\t// clean up the temporary files.\n \t\t\tlogger.trace(\"Deleted temp files\");\n-\t\t\tFiles.deleteIfExists(target);\n-\t\t\tFiles.deleteIfExists(temp);\n+\t\t\tIridaFiles.cleanupLocalTemporaryFiles(target, temp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDEzNA==", "bodyText": "Yeah I think we should revert this to returning the SequenceFile for now.  It's back to the same issue of dealing with those temp directories.  We can address that in the future.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180134", "createdAt": "2020-09-08T20:33:26Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDcwNw==", "bodyText": "If it makes sense can we just leave this method accessable form the IridaFileStorageUtility class and not in IridaFiles?  That way it's only responsible for dealing with those temporarily downloaded files.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180707", "createdAt": "2020-09-08T20:34:42Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "diffHunk": "@@ -65,4 +66,34 @@ public static String getFileExtension(List<? extends SequencingObject> files) th\n \t\treturn iridaFileStorageUtility.getFileExtension(files);\n \t}\n \n+\t/**\n+\t * Cleans up temporary downloaded files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath) {\n+\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(filePath, directoryPath);\n+\t}\n+\n+\t/**\n+\t * Cleans up temporary files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MTcwNw==", "bodyText": "For this method please accept an IridaTemporaryFile instead of the 2 Paths.  That will help ensure we only use this in the appropriate cases.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485181707", "createdAt": "2020-09-08T20:36:43Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -16,15 +21,25 @@\n  */\n \n public interface IridaFileStorageUtility {\n-\t//Valid extensions to try to concatenate with this tool\n-\tpublic static final List<String> VALID_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n+\tLogger logger = LoggerFactory.getLogger(IridaFileStorageUtility.class);\n+\n+\t//Valid file extensions for sample file concatenation\n+\tpublic static final List<String> VALID_CONCATENATION_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n \t/**\n \t * Get a temporarry file from storage\n \t *\n \t * @param file The {@link Path} to the file\n-\t * @return {@link File} which was retrieved from path\n+\t * @return {@link IridaTemporaryFile} which includes the file and optional temporary directory\n+\t */\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file);\n+\n+\t/**\n+\t * Delete temporary downloaded file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n \t */\n-\tpublic File getTemporaryFile(Path file);\n+\tpublic void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MjQ2Mg==", "bodyText": "After reverting back to Files.deleteIfExists in those places we discussed, you should be able to remove this static method.  I think it should likely go away.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485182462", "createdAt": "2020-09-08T20:38:11Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -106,4 +121,26 @@\n \t * @throws IOException if the files have different or invalid extensions\n \t */\n \tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException;\n+\n+\t/**\n+\t * Delete local temporary file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1dbdb47af3eedeee57410916380b562e92a85c41", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/1dbdb47af3eedeee57410916380b562e92a85c41", "committedDate": "2020-09-09T13:03:25Z", "message": "Reverted changes to clean up local temporary files. Updated cleanup downloaded local files method to accept an IridaTemporaryFile object instead of paths."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d3af6f73a93c490f5c649ca2b6124130711e4af", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/4d3af6f73a93c490f5c649ca2b6124130711e4af", "committedDate": "2020-09-09T13:11:09Z", "message": "Removed unused import and removed newlines"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/852f5b9327fe79f60ef841cdec400c1466061dd7", "committedDate": "2020-09-09T14:59:23Z", "message": "Removed unused imports"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA4NDc5NjEz", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-508479613", "createdAt": "2020-10-14T15:37:49Z", "commit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTozNzo0OVrOHhZPrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTo0NToyMFrOHhZkbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ==", "bodyText": "Can we update this comment to say something about how this is a temporarily downloaded file from an online service and should be cleaned up after it's done being used?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504778669", "createdAt": "2020-10-14T15:37:49Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3OTg1OA==", "bodyText": "Got 2 parts of this if resulting in the same thing ZIPPED.  Should the extension checking be added as an || to the top condition?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504779858", "createdAt": "2020-10-14T15:39:30Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/sequenceFile/Fast5Object.java", "diffHunk": "@@ -103,7 +105,10 @@ private Fast5Type setType(SequenceFile file) {\n \t\ttry {\r\n \t\t\tString extension = FilenameUtils.getExtension(getFile().getFileName());\r\n \r\n-\t\t\tif (file.isGzipped()) {\r\n+\t\t\t// Checks if file is where it should be before it checks if it is gzipped\r\n+\t\t\tif (IridaFiles.fileExists(file.getFile()) && file.isGzipped()) {\r\n+\t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r\n+\t\t\t} else if (extension.equals(\"gz\")) {\r\n \t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTIyNw==", "bodyText": "This processor gets a bit complicated.  Can you add comments through this file please about what's going on.  So up here something saying \"we're getting a local copy of the files\", down below \"we're creating a temp directory\", \"we're running the fastqc modules\", etc.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504781227", "createdAt": "2020-10-14T15:41:28Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjE2NA==", "bodyText": "Should this exception be wrapped and re-thrown as a StorageException or FileProcessorException rather than just logging?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504782164", "createdAt": "2020-10-14T15:42:47Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);\n+\t\tFile fastQCSequenceFileToProcess = iridaTemporaryFile.getFile().toFile();\n+\t\tPath outputDirectory = null;\n+\n \t\ttry {\n-\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n-\t\t\t\t\tiridaFileStorageUtility.getTemporaryFile(fileToProcess));\n-\t\t\tBasicStats basicStats = new BasicStats();\n-\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n-\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n-\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n-\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n-\n-\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n-\t\t\twhile (fastQCSequenceFile.hasNext()) {\n-\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n-\t\t\t\tfor (QCModule module : moduleList) {\n-\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\toutputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\n+\t\t\ttry {\n+\t\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n+\t\t\t\t\t\tfastQCSequenceFileToProcess);\n+\t\t\t\tBasicStats basicStats = new BasicStats();\n+\t\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n+\t\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n+\t\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n+\t\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n+\n+\t\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n+\t\t\t\twhile (fastQCSequenceFile.hasNext()) {\n+\t\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n+\t\t\t\t\tfor (QCModule module : moduleList) {\n+\t\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n \n-\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n+\t\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n \n-\t\t\tPath outputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\t\t\t\thandleBasicStats(basicStats, analysis);\n+\t\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n+\t\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n+\t\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n+\t\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n \n-\t\t\thandleBasicStats(basicStats, analysis);\n-\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n-\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n-\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n-\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n+\t\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n+\t\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n \n-\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n-\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n+\t\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n \n-\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n+\t\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n \n-\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n-\n-\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n-\t\t} catch (Exception e) {\n-\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n-\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n+\t\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t}\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(\"Unable to create temporary directory \", e);\n+\t\t\tthrow new StorageException(\"Unable to create temporary directory\", e);\n+\t\t} finally {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t\t\ttry {\n+\t\t\t\t\t// Delete the analysis-output* temp directory\n+\t\t\t\t\tFiles.deleteIfExists(outputDirectory);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tlogger.error(\"Unable to remove directory\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4Mzk4MQ==", "bodyText": "Can we add a prefix here instead of null?  That will make things easier to debug if something is going wrong leaving temp directories around.  Maybe something like \"azure-tmp-\".  We could add similar for the S3 stuff in its PR.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504783981", "createdAt": "2020-10-14T15:45:20Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.ria.web.dto.IridaTemporaryFile;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 58}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "117eedc7f06e586f08eed0fca9d520de62ca3c6f", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/117eedc7f06e586f08eed0fca9d520de62ca3c6f", "committedDate": "2020-10-14T19:33:45Z", "message": "Added comments. Updated exception thrown instead of a logging statement when trying to clean up the analysis outputs directory. Added prefix to temporary directory for azure files."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1dd0672eb3b8f066928f5efd3862d9c5eab3be50", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/1dd0672eb3b8f066928f5efd3862d9c5eab3be50", "committedDate": "2020-10-14T23:35:58Z", "message": "Changed package to delete temp analysis outputs directory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c5f601869cd0ec4090be803a7df2167c3b06fbb", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/8c5f601869cd0ec4090be803a7df2167c3b06fbb", "committedDate": "2020-10-15T13:17:40Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d15b2a07ea240feaf6f39b90428d985fca96efa8", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/d15b2a07ea240feaf6f39b90428d985fca96efa8", "committedDate": "2020-10-21T21:20:42Z", "message": "Moved into filesystem directory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2dc172a7c93d54c819c83356ed1270526877b050", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/2dc172a7c93d54c819c83356ed1270526877b050", "committedDate": "2020-10-22T21:49:58Z", "message": "Updated authentication for azure storage utility class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3f19b3a9265e51837347ea39913dd8e5dad9293", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/c3f19b3a9265e51837347ea39913dd8e5dad9293", "committedDate": "2020-11-02T15:19:23Z", "message": "Merge branch 'object-store' into object_store/_azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74049bc35efe3096cf568b220f513eeb6ba1a0ea", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/74049bc35efe3096cf568b220f513eeb6ba1a0ea", "committedDate": "2020-11-04T01:07:08Z", "message": "Updated getFileSize and getFileName methods to not error out if an exception is thrown."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c43265bd650f0a96e09d9dc086e9775f7dd660c6", "author": {"user": {"login": "deepsidhu85", "name": null}}, "url": "https://github.com/phac-nml/irida/commit/c43265bd650f0a96e09d9dc086e9775f7dd660c6", "committedDate": "2020-11-04T17:00:19Z", "message": "Removed finally blocks and storageexceptions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzNzMwNTA0", "url": "https://github.com/phac-nml/irida/pull/759#pullrequestreview-523730504", "createdAt": "2020-11-04T20:59:15Z", "commit": {"oid": "c43265bd650f0a96e09d9dc086e9775f7dd660c6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 49, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}