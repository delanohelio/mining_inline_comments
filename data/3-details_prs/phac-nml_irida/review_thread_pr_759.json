{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUzNzk2ODEw", "number": 759, "reviewThreads": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNzo0MjoyMVrOESfa5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTo0NToyMFrOEtjGdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODI0NjEzOnYy", "diffSide": "RIGHT", "path": "pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNzo0MjoyMVrOG3s3nQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMToxMjo1MFrOG5KZnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1OTk5Nw==", "bodyText": "We already import lots of jackson stuff already, why do we need the new import?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461059997", "createdAt": "2020-07-27T17:42:21Z", "author": {"login": "tom114"}, "path": "pom.xml", "diffHunk": "@@ -344,6 +344,11 @@\n \t\t\t<artifactId>jackson-databind</artifactId>\n \t\t\t<version>${jackson.version}</version>\n \t\t</dependency>\n+\t\t<dependency>\n+\t\t\t<groupId>com.fasterxml.jackson.core</groupId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MjQxNQ==", "bodyText": "The azure sdk requires a package which is a part of the core jackson (>=2.10) and is not available as a separate maven package", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462592415", "createdAt": "2020-07-29T21:12:50Z", "author": {"login": "deepsidhu85"}, "path": "pom.xml", "diffHunk": "@@ -344,6 +344,11 @@\n \t\t\t<artifactId>jackson-databind</artifactId>\n \t\t\t<version>${jackson.version}</version>\n \t\t</dependency>\n+\t\t<dependency>\n+\t\t\t<groupId>com.fasterxml.jackson.core</groupId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1OTk5Nw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODI1MDE3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNzo0MzoyNVrOG3s6Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNToxNDoxNFrOG_l9WQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA==", "bodyText": "Why do we need the @ResponseBody stuff here?  The REST API should automatically be returning JSON without it.  What happens without these?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461060634", "createdAt": "2020-07-27T17:43:25Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjU5Mw==", "bodyText": "Since the Azure sdk required jackson >2.10 the tests for this as well as the AnalysisAjaxTableController tests broke. My guess is the response is not being serialized properly", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596593", "createdAt": "2020-07-29T21:21:14Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg0MTY5Ng==", "bodyText": "Ok.  So I think something is going funny that made this necessary.  Our REST config in https://github.com/phac-nml/irida/blob/development/src/main/java/ca/corefacility/bioinformatics/irida/config/web/IridaRestApiWebConfig.java should serialize any resource to JSON automatically without the @ResponseBody annotation.  When I'm going through the rest api with curl I'm noticing some controllers being pretty-printed and some that aren't.  Pretty print is set up in https://github.com/phac-nml/irida/blob/development/src/main/java/ca/corefacility/bioinformatics/irida/config/web/IridaRestApiWebConfig.java#L73 and I think should be universal through the REST API.\nSo long story short, something funny is going on to need this.  I think we'll have to dig because there's something going wrong with configuration somehow.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463841696", "createdAt": "2020-07-31T21:06:11Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTExMTM4OQ==", "bodyText": "Sure I will take a look into it and see if I can figure out what's going on", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465111389", "createdAt": "2020-08-04T14:53:00Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMzNTM4NQ==", "bodyText": "Updated with PR #769", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r469335385", "createdAt": "2020-08-12T15:14:14Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3ODUwMjkxOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxODo1NDo1OFrOG3vW0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNjoxNjo1MlrOG7nuGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg==", "bodyText": "This section looks like duplicate imports to me.  Aren't these already imported somewhere else?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461100752", "createdAt": "2020-07-27T18:54:58Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "diffHunk": "@@ -35,6 +35,16 @@\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleMetadataController;\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleSequenceFilesController;\n \n+import com.google.common.net.HttpHeaders;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.hateoas.Link;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Controller;\n+import org.springframework.ui.ModelMap;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.servlet.ModelAndView;\n+import org.springframework.web.servlet.view.RedirectView;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MzY1NQ==", "bodyText": "Looks like they were missed. I will remove these", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462593655", "createdAt": "2020-07-29T21:15:20Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "diffHunk": "@@ -35,6 +35,16 @@\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleMetadataController;\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleSequenceFilesController;\n \n+import com.google.common.net.HttpHeaders;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.hateoas.Link;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Controller;\n+import org.springframework.ui.ModelMap;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.servlet.ModelAndView;\n+import org.springframework.web.servlet.view.RedirectView;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE2OTk0Ng==", "bodyText": "Removed in 23c0b6d", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465169946", "createdAt": "2020-08-04T16:16:52Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "diffHunk": "@@ -35,6 +35,16 @@\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleMetadataController;\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleSequenceFilesController;\n \n+import com.google.common.net.HttpHeaders;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.hateoas.Link;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Controller;\n+import org.springframework.ui.ModelMap;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.servlet.ModelAndView;\n+import org.springframework.web.servlet.view.RedirectView;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MTczNTUyOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzo1NjoyNFrOG4NzzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNjoxNjo1OVrOG7nuXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw==", "bodyText": "Rather than directly creating a file in /tmp use the Files.createTempDirectory method.  This will automatically create a unique directory in the appropriate location.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461599693", "createdAt": "2020-07-28T13:56:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NDAwMQ==", "bodyText": "This has been completely changed. If you take a look at the object_store/_analysis_submissions PR, I've made use of the existing folders", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462594001", "createdAt": "2020-07-29T21:16:02Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg0ODI1OQ==", "bodyText": "I see the getFile method in that branch, but it looks like it might have a slightly different use?  I understand the change later in the chain, but can it get pulled down to this PR since it was found here?  Its too easy for temporary stuff like this to accidentally slip by when getting reviewed later.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463848259", "createdAt": "2020-07-31T21:15:34Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTExMTg1Mg==", "bodyText": "Sure I can pull it down into here. The use is the same just renamed the method in a later branch", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465111852", "createdAt": "2020-08-04T14:53:38Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE3MDAxNA==", "bodyText": "Updated in 23c0b6d", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465170014", "createdAt": "2020-08-04T16:16:59Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MTc0NDg3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMzo1ODoyNFrOG4N5mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNjoyMjoyNVrOG7n7lA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMTE3Nw==", "bodyText": "Should this be a global?  It looks like it's initialized in every method.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461601177", "createdAt": "2020-07-28T13:58:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE3MzM5Ng==", "bodyText": "Removed global in 23c0b6d", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465173396", "createdAt": "2020-08-04T16:22:25Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMTE3Nw=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MjA2NjcxOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNDo1OTozMFrOG4Q9aA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQyMToyMjo0OVrOG6XV1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA==", "bodyText": "What's this for?  If it's just some random requirement for this code can you write a long comment about why it's here?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461651304", "createdAt": "2020-07-28T14:59:30Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjExMQ==", "bodyText": "Azure and AWS use a virtual filesystem. For example /opt/irida/data/sequence/1/filename.fastq would be the object. The file paths stored in the db have a leading slash which if we attempt to locate in the object store it tries to find containerName//object instead of containerName/object resulting in the bucket object (s3) or the blob(azure) not being found.\nI will update the comment to make this clear", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596111", "createdAt": "2020-07-29T21:20:13Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg1MzAxMw==", "bodyText": "Ok.  Is there maybe a different implementation of Path that should be used for these cloud types?  Or maybe the Path class isn't the appropriate thing to store for this anymore?  I think Path is something that is assumed to be a file system reference.  Here since it's no longer a file on a file system we need to keep converting it.  Maybe we should be storing these paths in another way.  Lets talk about it next week.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463853013", "createdAt": "2020-07-31T21:22:49Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MjA3NTQzOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNTowMToxNVrOG4RCqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNjo0NzoyN1rOG7o3aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA==", "bodyText": "The VALID_EXTENSIONS thing is for concatenating right?  Can you rename that variable and the comments around it with that info please?  It confuses me every time.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461652648", "createdAt": "2020-07-28T15:01:15Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {\n+\t\tString absolutePath = file.toAbsolutePath().toString();\n+\t\tif(absolutePath.charAt(0) == '/') {\n+\t\t\tabsolutePath = file.toAbsolutePath()\n+\t\t\t\t\t.toString()\n+\t\t\t\t\t.substring(1);\n+\t\t}\n+\t\treturn absolutePath;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void appendToFile(Path target, SequenceFile file) throws IOException{\n+\t\ttry (FileChannel out = FileChannel.open(target, StandardOpenOption.CREATE, StandardOpenOption.APPEND,\n+\t\t\t\tStandardOpenOption.WRITE)) {\n+\t\t\ttry (FileChannel in = new FileInputStream(getTemporaryFile(file.getFile())).getChannel()) {\n+\t\t\t\tfor (long p = 0, l = in.size(); p < l; ) {\n+\t\t\t\t\tp += in.transferTo(p, l - p, out);\n+\t\t\t\t}\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new IOException(\"Could not open input file for reading\", e);\n+\t\t\t}\n+\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new IOException(\"Could not open target file for writing\", e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException {\n+\t\tString selectedExtension = null;\n+\t\tfor (SequencingObject object : sequencingObjects) {\n+\n+\t\t\tfor (SequenceFile file : object.getFiles()) {\n+\t\t\t\tString fileName = getFileName(file.getFile());\n+\n+\t\t\t\tOptional<String> currentExtensionOpt = VALID_EXTENSIONS.stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjI1NQ==", "bodyText": "Sure I will get that updated", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596255", "createdAt": "2020-07-29T21:20:31Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {\n+\t\tString absolutePath = file.toAbsolutePath().toString();\n+\t\tif(absolutePath.charAt(0) == '/') {\n+\t\t\tabsolutePath = file.toAbsolutePath()\n+\t\t\t\t\t.toString()\n+\t\t\t\t\t.substring(1);\n+\t\t}\n+\t\treturn absolutePath;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void appendToFile(Path target, SequenceFile file) throws IOException{\n+\t\ttry (FileChannel out = FileChannel.open(target, StandardOpenOption.CREATE, StandardOpenOption.APPEND,\n+\t\t\t\tStandardOpenOption.WRITE)) {\n+\t\t\ttry (FileChannel in = new FileInputStream(getTemporaryFile(file.getFile())).getChannel()) {\n+\t\t\t\tfor (long p = 0, l = in.size(); p < l; ) {\n+\t\t\t\t\tp += in.transferTo(p, l - p, out);\n+\t\t\t\t}\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new IOException(\"Could not open input file for reading\", e);\n+\t\t\t}\n+\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new IOException(\"Could not open target file for writing\", e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException {\n+\t\tString selectedExtension = null;\n+\t\tfor (SequencingObject object : sequencingObjects) {\n+\n+\t\t\tfor (SequenceFile file : object.getFiles()) {\n+\t\t\t\tString fileName = getFileName(file.getFile());\n+\n+\t\t\t\tOptional<String> currentExtensionOpt = VALID_EXTENSIONS.stream()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE4ODcxNQ==", "bodyText": "Updated in fdd25e1", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465188715", "createdAt": "2020-08-04T16:47:27Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {\n+\t\tString absolutePath = file.toAbsolutePath().toString();\n+\t\tif(absolutePath.charAt(0) == '/') {\n+\t\t\tabsolutePath = file.toAbsolutePath()\n+\t\t\t\t\t.toString()\n+\t\t\t\t\t.substring(1);\n+\t\t}\n+\t\treturn absolutePath;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void appendToFile(Path target, SequenceFile file) throws IOException{\n+\t\ttry (FileChannel out = FileChannel.open(target, StandardOpenOption.CREATE, StandardOpenOption.APPEND,\n+\t\t\t\tStandardOpenOption.WRITE)) {\n+\t\t\ttry (FileChannel in = new FileInputStream(getTemporaryFile(file.getFile())).getChannel()) {\n+\t\t\t\tfor (long p = 0, l = in.size(); p < l; ) {\n+\t\t\t\t\tp += in.transferTo(p, l - p, out);\n+\t\t\t\t}\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new IOException(\"Could not open input file for reading\", e);\n+\t\t\t}\n+\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new IOException(\"Could not open target file for writing\", e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException {\n+\t\tString selectedExtension = null;\n+\t\tfor (SequencingObject object : sequencingObjects) {\n+\n+\t\t\tfor (SequenceFile file : object.getFiles()) {\n+\t\t\t\tString fileName = getFileName(file.getFile());\n+\n+\t\t\t\tOptional<String> currentExtensionOpt = VALID_EXTENSIONS.stream()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA=="}, "originalCommit": {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4"}, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMzkxNTY5OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMTowODozNVrOG_y77Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMTozNzoyMlrOHCnktQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw==", "bodyText": "These exceptions should be logger.error level at least.  Honestly I'm not even sure these should be caught.  Should they maybe just be let go so that an appropriate error gets thrown up?  Just swallowing them here and logging could cause issues.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r469548013", "createdAt": "2020-08-12T21:08:35Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MTkwNg==", "bodyText": "As we discussed I think it would be good to wrap these exceptions in a StorageException.  We're already using that in the local storage utility so it would be good to use the same thing.\nPlease add that to any of the places in this file where we're just wrapping the BlobStorageException and logging.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470161906", "createdAt": "2020-08-13T18:30:56Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw=="}, "originalCommit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzU3Mw==", "bodyText": "Updated in 4b16c81", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r472507573", "createdAt": "2020-08-18T21:37:22Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw=="}, "originalCommit": {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzNzkyMjUxOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxODozMTo0NFrOHAYb_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMTozNzo0NlrOHCnlcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MjQzMA==", "bodyText": "As discussed lets try switching this to use Files.createTempFile instead of downloading to this specified location.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470162430", "createdAt": "2020-08-13T18:31:44Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d7418652545636565ceb4389f8db1cc6166e90b"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzc2MQ==", "bodyText": "Updated in bdee3fd", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r472507761", "createdAt": "2020-08-18T21:37:46Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MjQzMA=="}, "originalCommit": {"oid": "4d7418652545636565ceb4389f8db1cc6166e90b"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3Mzc1NzAxOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNDozNDoyNFrOHFn1yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxNjozMzoyNFrOHGgTnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY1NzY3NA==", "bodyText": "This class should be throwing a StorageException in all of these catch cases.  This method and all of the below.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r475657674", "createdAt": "2020-08-24T14:34:24Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU4MjgxMw==", "bodyText": "Updated in 5988e06", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r476582813", "createdAt": "2020-08-25T16:33:24Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY1NzY3NA=="}, "originalCommit": {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5MTQ4MTY5OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yN1QxNjowNjoxMFrOHIXRsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxNTozNDowOVrOHL1IPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUzMjAxNg==", "bodyText": "I don't think we should walk up to delete a parent directory.  While this shouldn't be an issue with our temp directories, it has the possibility of being accidentally misused and deleting a required directory.  if we're deleting a directory, I think it should be explicitly called to be deleted.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r478532016", "createdAt": "2020-08-27T16:06:10Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,281 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());\n+\t\t\tthrow new StorageException(e.getMessage());\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void cleanupLocalFiles(Path path) {\n+\t\tlogger.trace(\"Cleaning up temporary file downloaded from azure [\" + path.toString() + \"]\");\n+\n+\t\tPath origPath = path;\n+\t\tif(Files.isRegularFile(path)) {\n+\t\t\torigPath = path;\n+\t\t\tpath = path.getParent();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5988e06b794923529c3dd6889ff54b983970516a"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjE2Njg0Ng==", "bodyText": "Updated in 05feefc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r482166846", "createdAt": "2020-09-02T15:34:09Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,281 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());\n+\t\t\tthrow new StorageException(e.getMessage());\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void cleanupLocalFiles(Path path) {\n+\t\tlogger.trace(\"Cleaning up temporary file downloaded from azure [\" + path.toString() + \"]\");\n+\n+\t\tPath origPath = path;\n+\t\tif(Files.isRegularFile(path)) {\n+\t\t\torigPath = path;\n+\t\t\tpath = path.getParent();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUzMjAxNg=="}, "originalCommit": {"oid": "5988e06b794923529c3dd6889ff54b983970516a"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTE1NDcyOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaConcatenatorTemporaryFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQxOToyOTo1OFrOHNZbdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNDozOVrOHPGUgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgxMDE2NA==", "bodyText": "Something feels wrong with needing this file.  Particularily seeing where you use it the filePath portion is often null.  Is there a way to do this just returning either the SequencingObject or just an IridaTemporaryFile?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483810164", "createdAt": "2020-09-04T19:29:58Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaConcatenatorTemporaryFile.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory\n+ * for a concatenator object\n+ */\n+\n+public class IridaConcatenatorTemporaryFile {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDI0MQ==", "bodyText": "Removed this in 1dbdb47 as we will deal with cleaning up local temporary files in a future branch if needed", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594241", "createdAt": "2020-09-09T13:04:39Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaConcatenatorTemporaryFile.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory\n+ * for a concatenator object\n+ */\n+\n+public class IridaConcatenatorTemporaryFile {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgxMDE2NA=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTI1NzE3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMDoxMTo1MlrOHNaYMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNDo0OVrOHPGU-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw==", "bodyText": "If we're having this IridaTemporaryFile class we should likely have it be the responsibility of IridaFiles to create those files.  Not creating them in places like this.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483825713", "createdAt": "2020-09-04T20:11:52Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDEzNA==", "bodyText": "Yeah I think we should revert this to returning the SequenceFile for now.  It's back to the same issue of dealing with those temp directories.  We can address that in the future.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180134", "createdAt": "2020-09-08T20:33:26Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDM2MQ==", "bodyText": "Reverted in 1dbdb47", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594361", "createdAt": "2020-09-09T13:04:49Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDYzNDI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/samples/RESTSampleAssemblyController.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMDozMjo0MlrOHOtBfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNDo1NlrOHPGVUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE3OTc3NQ==", "bodyText": "As discussed lets revert these changes back to the deleteIfExists stuff for now.  We can refactor this in a later branch when needed.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485179775", "createdAt": "2020-09-08T20:32:42Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/samples/RESTSampleAssemblyController.java", "diffHunk": "@@ -182,8 +183,7 @@ public ModelMap addNewAssemblyToSample(@PathVariable Long sampleId, @RequestPart\n \t\t} finally {\n \t\t\t// clean up the temporary files.\n \t\t\tlogger.trace(\"Deleted temp files\");\n-\t\t\tFiles.deleteIfExists(target);\n-\t\t\tFiles.deleteIfExists(temp);\n+\t\t\tIridaFiles.cleanupLocalTemporaryFiles(target, temp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDQ0OA==", "bodyText": "Reverted in 1dbdb47", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594448", "createdAt": "2020-09-09T13:04:56Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/samples/RESTSampleAssemblyController.java", "diffHunk": "@@ -182,8 +183,7 @@ public ModelMap addNewAssemblyToSample(@PathVariable Long sampleId, @RequestPart\n \t\t} finally {\n \t\t\t// clean up the temporary files.\n \t\t\tlogger.trace(\"Deleted temp files\");\n-\t\t\tFiles.deleteIfExists(target);\n-\t\t\tFiles.deleteIfExists(temp);\n+\t\t\tIridaFiles.cleanupLocalTemporaryFiles(target, temp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE3OTc3NQ=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDY0MDA3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMDozNDo0MlrOHOtFIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNjoyM1rOHPGZeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDcwNw==", "bodyText": "If it makes sense can we just leave this method accessable form the IridaFileStorageUtility class and not in IridaFiles?  That way it's only responsible for dealing with those temporarily downloaded files.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180707", "createdAt": "2020-09-08T20:34:42Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "diffHunk": "@@ -65,4 +66,34 @@ public static String getFileExtension(List<? extends SequencingObject> files) th\n \t\treturn iridaFileStorageUtility.getFileExtension(files);\n \t}\n \n+\t/**\n+\t * Cleans up temporary downloaded files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath) {\n+\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(filePath, directoryPath);\n+\t}\n+\n+\t/**\n+\t * Cleans up temporary files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTUxMg==", "bodyText": "Removed this method in 1dbdb47 as it is not required. We have the cleanupDownloadedTemporaryFiles method in the irida files storage utility classes to clean up any files downloaded from an object store", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595512", "createdAt": "2020-09-09T13:06:23Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "diffHunk": "@@ -65,4 +66,34 @@ public static String getFileExtension(List<? extends SequencingObject> files) th\n \t\treturn iridaFileStorageUtility.getFileExtension(files);\n \t}\n \n+\t/**\n+\t * Cleans up temporary downloaded files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath) {\n+\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(filePath, directoryPath);\n+\t}\n+\n+\t/**\n+\t * Cleans up temporary files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDcwNw=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDY0NjcwOnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMDozNjo0M1rOHOtJCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNjozMFrOHPGZ2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MTcwNw==", "bodyText": "For this method please accept an IridaTemporaryFile instead of the 2 Paths.  That will help ensure we only use this in the appropriate cases.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485181707", "createdAt": "2020-09-08T20:36:43Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -16,15 +21,25 @@\n  */\n \n public interface IridaFileStorageUtility {\n-\t//Valid extensions to try to concatenate with this tool\n-\tpublic static final List<String> VALID_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n+\tLogger logger = LoggerFactory.getLogger(IridaFileStorageUtility.class);\n+\n+\t//Valid file extensions for sample file concatenation\n+\tpublic static final List<String> VALID_CONCATENATION_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n \t/**\n \t * Get a temporarry file from storage\n \t *\n \t * @param file The {@link Path} to the file\n-\t * @return {@link File} which was retrieved from path\n+\t * @return {@link IridaTemporaryFile} which includes the file and optional temporary directory\n+\t */\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file);\n+\n+\t/**\n+\t * Delete temporary downloaded file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n \t */\n-\tpublic File getTemporaryFile(Path file);\n+\tpublic void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTYwOA==", "bodyText": "Updated in 1dbdb47", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595608", "createdAt": "2020-09-09T13:06:30Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -16,15 +21,25 @@\n  */\n \n public interface IridaFileStorageUtility {\n-\t//Valid extensions to try to concatenate with this tool\n-\tpublic static final List<String> VALID_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n+\tLogger logger = LoggerFactory.getLogger(IridaFileStorageUtility.class);\n+\n+\t//Valid file extensions for sample file concatenation\n+\tpublic static final List<String> VALID_CONCATENATION_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n \t/**\n \t * Get a temporarry file from storage\n \t *\n \t * @param file The {@link Path} to the file\n-\t * @return {@link File} which was retrieved from path\n+\t * @return {@link IridaTemporaryFile} which includes the file and optional temporary directory\n+\t */\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file);\n+\n+\t/**\n+\t * Delete temporary downloaded file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n \t */\n-\tpublic File getTemporaryFile(Path file);\n+\tpublic void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MTcwNw=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDY1MTY3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMDozODoxMVrOHOtL_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxMzowNjozOFrOHPGaLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MjQ2Mg==", "bodyText": "After reverting back to Files.deleteIfExists in those places we discussed, you should be able to remove this static method.  I think it should likely go away.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485182462", "createdAt": "2020-09-08T20:38:11Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -106,4 +121,26 @@\n \t * @throws IOException if the files have different or invalid extensions\n \t */\n \tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException;\n+\n+\t/**\n+\t * Delete local temporary file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTY5Mw==", "bodyText": "Removed in 1dbdb47", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595693", "createdAt": "2020-09-09T13:06:38Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -106,4 +121,26 @@\n \t * @throws IOException if the files have different or invalid extensions\n \t */\n \tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException;\n+\n+\t/**\n+\t * Delete local temporary file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MjQ2Mg=="}, "originalCommit": {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MTkzMTY3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTozNzo0OVrOHhZPrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMVQyMToyMToyN1rOHmGKKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ==", "bodyText": "Can we update this comment to say something about how this is a temporarily downloaded file from an online service and should be cleaned up after it's done being used?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504778669", "createdAt": "2020-10-14T15:37:49Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyNDA3OQ==", "bodyText": "Updated in 117eedc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504924079", "createdAt": "2020-10-14T19:35:15Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5MTMxMA==", "bodyText": "Just noticed the package of this file.  Definitely shouldn't be in dto.  Probably more in something like ca/corefacility/bioinformatics/irida/repositories/filesystem", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r509391310", "createdAt": "2020-10-21T15:35:11Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTcwODg0Mw==", "bodyText": "My bad. Been putting all dtos in that directory. Updated in d15b2a0", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r509708843", "createdAt": "2020-10-21T21:21:27Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MTkzOTE1OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/sequenceFile/Fast5Object.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTozOTozMFrOHhZUUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxOTozNTowOVrOHhiHdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3OTg1OA==", "bodyText": "Got 2 parts of this if resulting in the same thing ZIPPED.  Should the extension checking be added as an || to the top condition?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504779858", "createdAt": "2020-10-14T15:39:30Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/sequenceFile/Fast5Object.java", "diffHunk": "@@ -103,7 +105,10 @@ private Fast5Type setType(SequenceFile file) {\n \t\ttry {\r\n \t\t\tString extension = FilenameUtils.getExtension(getFile().getFileName());\r\n \r\n-\t\t\tif (file.isGzipped()) {\r\n+\t\t\t// Checks if file is where it should be before it checks if it is gzipped\r\n+\t\t\tif (IridaFiles.fileExists(file.getFile()) && file.isGzipped()) {\r\n+\t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r\n+\t\t\t} else if (extension.equals(\"gz\")) {\r\n \t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyNDAyMg==", "bodyText": "Yup I can't believe I did that. Updated in 117eedc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504924022", "createdAt": "2020-10-14T19:35:09Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/sequenceFile/Fast5Object.java", "diffHunk": "@@ -103,7 +105,10 @@ private Fast5Type setType(SequenceFile file) {\n \t\ttry {\r\n \t\t\tString extension = FilenameUtils.getExtension(getFile().getFileName());\r\n \r\n-\t\t\tif (file.isGzipped()) {\r\n+\t\t\t// Checks if file is where it should be before it checks if it is gzipped\r\n+\t\t\tif (IridaFiles.fileExists(file.getFile()) && file.isGzipped()) {\r\n+\t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r\n+\t\t\t} else if (extension.equals(\"gz\")) {\r\n \t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3OTg1OA=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MTk0NzU3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTo0MToyOFrOHhZZqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxOTozNDo0MlrOHhiGWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTIyNw==", "bodyText": "This processor gets a bit complicated.  Can you add comments through this file please about what's going on.  So up here something saying \"we're getting a local copy of the files\", down below \"we're creating a temp directory\", \"we're running the fastqc modules\", etc.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504781227", "createdAt": "2020-10-14T15:41:28Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzczNw==", "bodyText": "Added in 117eedc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923737", "createdAt": "2020-10-14T19:34:42Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTIyNw=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MTk1MzE3OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTo0Mjo0N1rOHhZdVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxOTozNDozN1rOHhiGIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjE2NA==", "bodyText": "Should this exception be wrapped and re-thrown as a StorageException or FileProcessorException rather than just logging?", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504782164", "createdAt": "2020-10-14T15:42:47Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);\n+\t\tFile fastQCSequenceFileToProcess = iridaTemporaryFile.getFile().toFile();\n+\t\tPath outputDirectory = null;\n+\n \t\ttry {\n-\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n-\t\t\t\t\tiridaFileStorageUtility.getTemporaryFile(fileToProcess));\n-\t\t\tBasicStats basicStats = new BasicStats();\n-\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n-\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n-\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n-\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n-\n-\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n-\t\t\twhile (fastQCSequenceFile.hasNext()) {\n-\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n-\t\t\t\tfor (QCModule module : moduleList) {\n-\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\toutputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\n+\t\t\ttry {\n+\t\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n+\t\t\t\t\t\tfastQCSequenceFileToProcess);\n+\t\t\t\tBasicStats basicStats = new BasicStats();\n+\t\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n+\t\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n+\t\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n+\t\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n+\n+\t\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n+\t\t\t\twhile (fastQCSequenceFile.hasNext()) {\n+\t\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n+\t\t\t\t\tfor (QCModule module : moduleList) {\n+\t\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n \n-\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n+\t\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n \n-\t\t\tPath outputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\t\t\t\thandleBasicStats(basicStats, analysis);\n+\t\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n+\t\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n+\t\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n+\t\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n \n-\t\t\thandleBasicStats(basicStats, analysis);\n-\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n-\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n-\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n-\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n+\t\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n+\t\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n \n-\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n-\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n+\t\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n \n-\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n+\t\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n \n-\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n-\n-\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n-\t\t} catch (Exception e) {\n-\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n-\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n+\t\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t}\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(\"Unable to create temporary directory \", e);\n+\t\t\tthrow new StorageException(\"Unable to create temporary directory\", e);\n+\t\t} finally {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t\t\ttry {\n+\t\t\t\t\t// Delete the analysis-output* temp directory\n+\t\t\t\t\tFiles.deleteIfExists(outputDirectory);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tlogger.error(\"Unable to remove directory\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzY4MA==", "bodyText": "Updated in 117eedc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923680", "createdAt": "2020-10-14T19:34:37Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);\n+\t\tFile fastQCSequenceFileToProcess = iridaTemporaryFile.getFile().toFile();\n+\t\tPath outputDirectory = null;\n+\n \t\ttry {\n-\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n-\t\t\t\t\tiridaFileStorageUtility.getTemporaryFile(fileToProcess));\n-\t\t\tBasicStats basicStats = new BasicStats();\n-\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n-\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n-\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n-\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n-\n-\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n-\t\t\twhile (fastQCSequenceFile.hasNext()) {\n-\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n-\t\t\t\tfor (QCModule module : moduleList) {\n-\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\toutputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\n+\t\t\ttry {\n+\t\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n+\t\t\t\t\t\tfastQCSequenceFileToProcess);\n+\t\t\t\tBasicStats basicStats = new BasicStats();\n+\t\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n+\t\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n+\t\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n+\t\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n+\n+\t\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n+\t\t\t\twhile (fastQCSequenceFile.hasNext()) {\n+\t\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n+\t\t\t\t\tfor (QCModule module : moduleList) {\n+\t\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n \n-\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n+\t\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n \n-\t\t\tPath outputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\t\t\t\thandleBasicStats(basicStats, analysis);\n+\t\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n+\t\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n+\t\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n+\t\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n \n-\t\t\thandleBasicStats(basicStats, analysis);\n-\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n-\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n-\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n-\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n+\t\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n+\t\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n \n-\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n-\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n+\t\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n \n-\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n+\t\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n \n-\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n-\n-\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n-\t\t} catch (Exception e) {\n-\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n-\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n+\t\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t}\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(\"Unable to create temporary directory \", e);\n+\t\t\tthrow new StorageException(\"Unable to create temporary directory\", e);\n+\t\t} finally {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t\t\ttry {\n+\t\t\t\t\t// Delete the analysis-output* temp directory\n+\t\t\t\t\tFiles.deleteIfExists(outputDirectory);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tlogger.error(\"Unable to remove directory\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjE2NA=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE2MTk2NDY5OnYy", "diffSide": "RIGHT", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxNTo0NToyMFrOHhZkbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQxOTozNDozMVrOHhiF6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4Mzk4MQ==", "bodyText": "Can we add a prefix here instead of null?  That will make things easier to debug if something is going wrong leaving temp directories around.  Maybe something like \"azure-tmp-\".  We could add similar for the S3 stuff in its PR.", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504783981", "createdAt": "2020-10-14T15:45:20Z", "author": {"login": "tom114"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.ria.web.dto.IridaTemporaryFile;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzYyNg==", "bodyText": "Sure good idea! Added in 117eedc", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923626", "createdAt": "2020-10-14T19:34:31Z", "author": {"login": "deepsidhu85"}, "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.ria.web.dto.IridaTemporaryFile;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4Mzk4MQ=="}, "originalCommit": {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7"}, "originalPosition": 58}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 678, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}