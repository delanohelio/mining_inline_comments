{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzNDcxNjUz", "number": 1746, "title": "VideoGrid WOH", "bodyText": "WOH that takes all the videos from a flavour, as well as a SMIL describing their start and duration times, and creates a single video from them.\nThe final video arranges simultaneous videos on a grid, dynamically resizing based on the number of currently active videos.\nYour pull request should\u2026\n\n have a concise title\n close an accompanying issue if one exists\n be against the correct branch (features can only go into develop)\n include migration scripts and documentation, if appropriate\n pass automated testing\n have a clean commit history\n have proper commit messages (title and body) for all commits\n have appropriate tags applied", "createdAt": "2020-08-05T15:46:37Z", "url": "https://github.com/opencast/opencast/pull/1746", "merged": true, "mergeCommit": {"oid": "f09ed598531e033fdc2d6541e3676b330ab8d861"}, "closed": true, "closedAt": "2020-10-05T14:24:11Z", "author": {"login": "Arnei"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTqN1ZAH2gAyNDYzNDcxNjUzOmFiNzA3ZTJlYjQ3ZGIxZWI5YTc1M2FkNzdmYjY2OWJjNmQ5YTYzYzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdPkj2DAFqTUwMjEwNzM2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ab707e2eb47db1eb9a753ad77fb669bc6d9a63c1", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/ab707e2eb47db1eb9a753ad77fb669bc6d9a63c1", "committedDate": "2020-04-02T11:01:46Z", "message": "Merge branch 'r/8.x' of https://github.com/Arnei/opencast into develop"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a38cd860e8f7d05398d5e676a8d3c2c1b6cf522", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/4a38cd860e8f7d05398d5e676a8d3c2c1b6cf522", "committedDate": "2020-08-05T15:35:28Z", "message": "VideoGrid WOH\n\nWOH that takes all the videos from a flavour, as well as a SMIL describing their start and duration times, and creates a single video from them.\nThe final video arranges simultaneous videos on a grid, dynamically resizing based on the number of currently active videos."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7098ad95a7d4d92d04d7930a0551186a093f73d1", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/7098ad95a7d4d92d04d7930a0551186a093f73d1", "committedDate": "2020-08-05T15:54:42Z", "message": "Added documentation to mkdocs.yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7325c7f68e959281977da628de2b89c2db128ff1", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/7325c7f68e959281977da628de2b89c2db128ff1", "committedDate": "2020-08-06T08:22:29Z", "message": "Fixed a video scaling bug\n\nFixed a bug where all videos in a portion would be uniformly scaled based on the resolution of the video that just became active/inactive."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6aa204ebfb703ad16c82e9c48960dcc4a118ccd4", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/6aa204ebfb703ad16c82e9c48960dcc4a118ccd4", "committedDate": "2020-08-07T12:43:46Z", "message": "Added Unit Tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c73819a52e5d012917b3a7109365eaa30be33aea", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/c73819a52e5d012917b3a7109365eaa30be33aea", "committedDate": "2020-08-11T12:05:18Z", "message": "Removed workflow that was previously added by accident"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "355498dbc5043986e5a55ef80746bcaf3e7a0620", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/355498dbc5043986e5a55ef80746bcaf3e7a0620", "committedDate": "2020-08-11T12:39:51Z", "message": "Fixed checkstyle error that prevented build."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a222502841d0acecbe674534e0c950e4f86b2692", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/a222502841d0acecbe674534e0c950e4f86b2692", "committedDate": "2020-08-12T08:06:55Z", "message": "Minor code refactoring\n\n- Removed unused code\n- Removed useless argument from VideoGridService\n- Added workspace cleanup\n- Replaced \"portion\" with \"section\"\n- Added comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95664fc2df83099f6d4965b62e4076b959673db4", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/95664fc2df83099f6d4965b62e4076b959673db4", "committedDate": "2020-08-12T09:31:51Z", "message": "Added optional target-tags configuration key"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c71fb27da06c68621addd78319591063856431b7", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/c71fb27da06c68621addd78319591063856431b7", "committedDate": "2020-08-12T13:29:24Z", "message": "Added basic unit testing to the service"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/cc2b196019bf5971ca3902a66158390d4cfa9aca", "committedDate": "2020-09-25T07:58:21Z", "message": "Extended the check to avoid sections with small durations from 0ms to 50ms.\n\nSuch an extremely short duration can happen when multiple either start or stop at very similar times. The ffmpeg filter command \"trim\" will then apparently generate an empty or non-readable video file, which causes concat operation to throw an exception."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9df92a5a23f481cd2445afb51c56f67286f0fab", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/f9df92a5a23f481cd2445afb51c56f67286f0fab", "committedDate": "2020-09-28T14:12:59Z", "message": "Merge remote-tracking branch 'upstream/develop' into develop"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMDAzNjky", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-501003692", "createdAt": "2020-10-02T09:53:28Z", "commit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwOTo1MzoyOFrOHbn0tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxMDowMDo1NVrOHboCQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNjA3MA==", "bodyText": "SHTUFF???", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498726070", "createdAt": "2020-10-02T09:53:28Z", "author": {"login": "mliradelc"}, "path": "etc/workflows/bbb-upload.xml", "diffHunk": "@@ -0,0 +1,299 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<definition xmlns=\"http://workflow.opencastproject.org\">\n+\n+  <id>bbb-upload</id>\n+  <title>BigBlueButton Upload</title>\n+  <tags>\n+  </tags>\n+  <displayOrder>1000</displayOrder>\n+  <description>\n+    Knock! Knock! Who's there? Candice. Candice who? Candice door open, or am I stuck out here?\n+  </description>\n+\n+  <configuration_panel>\n+    <![CDATA[\n+      <div id=\"workflow-configuration\">\n+        <input id=\"publish\" name=\"publish\" type=\"checkbox\" class=\"configField\" value=\"true\" checked=checked />\n+        <label for=\"publish\">Publish media directly</label>\n+      </div>\n+    ]]>\n+  </configuration_panel>\n+\n+  <operations>\n+\n+    <operation\n+        id=\"defaults\"\n+        description=\"Applying default configuration values\">\n+      <configurations>\n+        <configuration key=\"publish\">true</configuration>\n+      </configurations>\n+    </operation>\n+\n+    <!-- Set publication variables for compatibility with the publish workflow -->\n+\n+    <operation\n+        id=\"defaults\"\n+        if=\"${publish}\"\n+        description=\"Applying configuration values for publish workflow\">\n+      <configurations>\n+        <configuration key=\"publishToMediaModule\">true</configuration>\n+        <configuration key=\"publishToOaiPmh\">true</configuration>\n+      </configurations>\n+    </operation>\n+\n+    <!-- Apply ACL from series to the mediapackage -->\n+\n+    <operation\n+        id=\"series\"\n+        fail-on-error=\"true\"\n+        exception-handler-workflow=\"partial-error\"\n+        description=\"Applying access control entries from series\">\n+      <configurations>\n+        <configuration key=\"apply-acl\">true</configuration>\n+      </configurations>\n+    </operation>\n+\n+    <!-- Stitch together BBB SHTUFF -->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNjgzOQ==", "bodyText": "No video grid WOH, What is the purpose of this workflow?", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498726839", "createdAt": "2020-10-02T09:55:10Z", "author": {"login": "mliradelc"}, "path": "etc/workflows/bbb-upload.xml", "diffHunk": "@@ -0,0 +1,299 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNjkxMA==", "bodyText": "Nice reference, but I think we need a more concise description\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Knock! Knock! Who's there? Candice. Candice who? Candice door open, or am I stuck out here?\n          \n          \n            \n                Workflow to mix several presenter videos from BBB in only one video", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498726910", "createdAt": "2020-10-02T09:55:18Z", "author": {"login": "mliradelc"}, "path": "etc/workflows/bbb-upload.xml", "diffHunk": "@@ -0,0 +1,299 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<definition xmlns=\"http://workflow.opencastproject.org\">\n+\n+  <id>bbb-upload</id>\n+  <title>BigBlueButton Upload</title>\n+  <tags>\n+  </tags>\n+  <displayOrder>1000</displayOrder>\n+  <description>\n+    Knock! Knock! Who's there? Candice. Candice who? Candice door open, or am I stuck out here?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNzg1Mw==", "bodyText": "Allows more than one flavor?", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498727853", "createdAt": "2020-10-02T09:57:16Z", "author": {"login": "mliradelc"}, "path": "docs/guides/admin/docs/workflowoperationhandlers/video-grid-woh.md", "diffHunk": "@@ -0,0 +1,64 @@\n+# VideoGridWorkflowOperationHandler\n+\n+## Description\n+\n+The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously\n+playing videos into a single video file. For example, the webcam feeds during a video conference\n+can be combined by this WOH. The resulting video puts each input video on a grid that dynamically\n+resizes based on the number of inputs videos currently active. Which input video is active when\n+is defined by through a SMIL catalogue from e.g. a partial ingest.\n+\n+If the SMIL defines a section where there are no videos active, the background color will be shown\n+instead for the duration of the section. This also holds true for potentially empty beginning and end \n+sections, ensuring that a final single video is as long as the overall duration defined in the SMIL \n+(e.g. if the first input video becomes active at 30 seconds, the first generated output is a 30 second\n+long video of the background color). The background color is also shown whenever the input videos cannot\n+fully fill up the available space.\n+\n+This WOH relies on the inspect service for enriching generated, temporary video files with metadata.\n+Furthermore, it relies on the composers concat service to combine temporary video files into\n+a single output file.\n+\n+## Parameter Table\n+\n+|configuration keys | example                     | description                                                         |\n+|-------------------|-----------------------------|---------------------------------------------------------------------|\n+|source-flavor      | presenter/source            | Flavor containing all the video tracks to be combined.                              |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyODQ1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                <version>8-SNAPSHOT</version>\n          \n          \n            \n                <version>9-SNAPSHOT</version>\n          \n      \n    \n    \n  \n\nSeems that you develop over 8.x, check if works with 9.x", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498728459", "createdAt": "2020-10-02T09:58:34Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-remote/pom.xml", "diffHunk": "@@ -0,0 +1,69 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <artifactId>opencast-videogrid-remote</artifactId>\n+  <name>Opencast :: videogrid-remote</name>\n+  <packaging>bundle</packaging>\n+  <parent>\n+    <groupId>org.opencastproject</groupId>\n+    <artifactId>base</artifactId>\n+    <version>8-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyOTM1NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                <version>8-SNAPSHOT</version>\n          \n          \n            \n                <version>9-SNAPSHOT</version>", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498729355", "createdAt": "2020-10-02T10:00:29Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-service-api/pom.xml", "diffHunk": "@@ -0,0 +1,45 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <artifactId>opencast-videogrid-service-api</artifactId>\n+  <name>Opencast :: videogrid-service-api</name>\n+  <packaging>bundle</packaging>\n+  <parent>\n+    <groupId>org.opencastproject</groupId>\n+    <artifactId>base</artifactId>\n+    <version>8-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyOTUzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                <version>8-SNAPSHOT</version>\n          \n          \n            \n                <version>9-SNAPSHOT</version>", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498729538", "createdAt": "2020-10-02T10:00:55Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-service-impl/pom.xml", "diffHunk": "@@ -0,0 +1,111 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+  <artifactId>opencast-videogrid-service-impl</artifactId>\n+  <name>Opencast :: videogrid-service-impl</name>\n+  <packaging>bundle</packaging>\n+  <parent>\n+    <groupId>org.opencastproject</groupId>\n+    <artifactId>base</artifactId>\n+    <version>8-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 10}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca0975f376b9ee099308b94ffc40ab1fdf95deb8", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/ca0975f376b9ee099308b94ffc40ab1fdf95deb8", "committedDate": "2020-10-02T10:16:50Z", "message": "Merge remote-tracking branch 'upstream/develop' into develop"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08b3f4dab69c2305ede52f4097f23762ed7d0437", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/08b3f4dab69c2305ede52f4097f23762ed7d0437", "committedDate": "2020-10-02T12:17:18Z", "message": "Removed workflow which was added by accident"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e371f619d2c911b494ddac442a438d50b446c30", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/9e371f619d2c911b494ddac442a438d50b446c30", "committedDate": "2020-10-02T12:17:46Z", "message": "Merge branch 'develop' into MultipleWebcamWHO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7", "committedDate": "2020-10-02T13:30:12Z", "message": "Updated to 9, added support for multiple source flavors"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwOTM5NDQx", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-500939441", "createdAt": "2020-10-02T08:14:08Z", "commit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQwODoxNDowOFrOHbk2PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNDozODo0NVrOHbwLxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY3NzMwOQ==", "bodyText": "-by", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498677309", "createdAt": "2020-10-02T08:14:08Z", "author": {"login": "pascalseeland"}, "path": "docs/guides/admin/docs/workflowoperationhandlers/video-grid-woh.md", "diffHunk": "@@ -0,0 +1,64 @@\n+# VideoGridWorkflowOperationHandler\n+\n+## Description\n+\n+The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously\n+playing videos into a single video file. For example, the webcam feeds during a video conference\n+can be combined by this WOH. The resulting video puts each input video on a grid that dynamically\n+resizes based on the number of inputs videos currently active. Which input video is active when\n+is defined by through a SMIL catalogue from e.g. a partial ingest.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODY4MTI5MA==", "bodyText": "Should be videogrid.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498681290", "createdAt": "2020-10-02T08:22:23Z", "author": {"login": "pascalseeland"}, "path": "docs/guides/admin/mkdocs.yml", "diffHunk": "@@ -212,5 +212,6 @@ nav:\n    - Timelinepreviews: 'workflowoperationhandlers/timelinepreviews-woh.md'\n    - Transfer Metadata: 'workflowoperationhandlers/transfer-metadata-woh.md'\n    - Theme: 'workflowoperationhandlers/theme-woh.md'\n+   - Waveform: 'workflowoperationhandlers/video-grid-woh.md'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcwODk1NA==", "bodyText": "Please use OSGI Compendium and the @component Annotation in the RemoteImpl class instead of this extra file", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498708954", "createdAt": "2020-10-02T09:17:14Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-remote/src/main/resources/OSGI-INF/videogrid-remote.xml", "diffHunk": "@@ -0,0 +1,14 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMjgzMA==", "bodyText": "The sudden naming things webcam is confusing. Use something related to videogrid", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498722830", "createdAt": "2020-10-02T09:46:41Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-service-impl/src/main/java/org/opencastproject/videogrid/impl/VideoGridServiceImpl.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+\n+package org.opencastproject.videogrid.impl;\n+\n+import org.opencastproject.job.api.AbstractJobProducer;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.security.api.OrganizationDirectoryService;\n+import org.opencastproject.security.api.SecurityService;\n+import org.opencastproject.security.api.UserDirectoryService;\n+import org.opencastproject.serviceregistry.api.ServiceRegistry;\n+import org.opencastproject.serviceregistry.api.ServiceRegistryException;\n+import org.opencastproject.util.ConfigurationException;\n+import org.opencastproject.util.IoSupport;\n+import org.opencastproject.util.LoadUtil;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.FilenameUtils;\n+import org.osgi.service.cm.ManagedService;\n+import org.osgi.service.component.ComponentContext;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.lang.reflect.Type;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Dictionary;\n+import java.util.List;\n+\n+/** Create video grids */\n+public class VideoGridServiceImpl extends AbstractJobProducer implements VideoGridService, ManagedService {\n+\n+  /** Configuration key for this operation's job load */\n+  private static final String JOB_LOAD_CONFIG = \"job.load.videogrid\";\n+\n+  /** The load introduced on the system by creating a job */\n+  private static final float JOB_LOAD_DEFAULT = 1.5f;\n+\n+  /** The load introduced on the system by creating a job */\n+  private float jobLoad = JOB_LOAD_DEFAULT;\n+\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridServiceImpl.class);\n+\n+  /** List of available operations on jobs */\n+  private static final String OPERATION = \"createPartialTracks\";\n+\n+  /** Services */\n+  private Workspace workspace;\n+  private ServiceRegistry serviceRegistry;\n+  private SecurityService securityService;\n+  private UserDirectoryService userDirectoryService;\n+  private OrganizationDirectoryService organizationDirectoryService;\n+\n+  /** For JSON serialization */\n+  private static final Gson gson = new Gson();\n+  private static final Type stringListOfListType = new TypeToken<List<List<String>>>() { }.getType();\n+\n+  /** Creates a new videogrid service instance. */\n+  public VideoGridServiceImpl() {\n+    super(JOB_TYPE);\n+  }\n+\n+  @Override\n+  public void activate(ComponentContext cc) {\n+    super.activate(cc);\n+    logger.debug(\"Activated videogrid service\");\n+  }\n+\n+  @Override\n+  public void updated(Dictionary properties) throws ConfigurationException {\n+    if (properties == null)\n+      return;\n+    logger.debug(\"Start updating videogrid service\");\n+\n+    jobLoad = LoadUtil.getConfiguredLoadValue(properties, JOB_LOAD_CONFIG, JOB_LOAD_DEFAULT, serviceRegistry);\n+    logger.debug(\"Set videogrid job load to {}\", jobLoad);\n+\n+    logger.debug(\"Finished updating videogrid service\");\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.job.api.AbstractJobProducer#process(org.opencastproject.job.api.Job)\n+   */\n+  @Override\n+  protected String process(Job job) throws Exception {\n+    logger.debug(\"Started processing job {}\", job.getId());\n+    if (!OPERATION.equals(job.getOperation())) {\n+      throw new ServiceRegistryException(String.format(\"This service can't handle operations of type '%s'\",\n+              job.getOperation()));\n+    }\n+\n+    // Parse arguments\n+    List<String> arguments = job.getArguments();\n+    List<List<String>> commands = gson.fromJson(arguments.get(0), stringListOfListType);\n+\n+    String outputDirPath = String.format(\"%s/videogrid/%d/\", workspace.rootDirectory(), job.getId());\n+    FileUtils.forceMkdir(new File(outputDirPath));\n+\n+    // Execute all commands\n+    List<String> outputPaths = new ArrayList<>();\n+    int index = 0;\n+    for (List<String> command : commands) {\n+      // Add output path to command\n+      String outputFile = outputDirPath + \"videogrid_part_\" + index + \".mp4\";\n+      outputPaths.add(outputFile);\n+      command.add(outputFile);\n+      index++;\n+\n+      logger.info(\"Running command: {}\", command);\n+\n+      // Run ffmpeg\n+      ProcessBuilder pb = new ProcessBuilder(command);\n+      pb.redirectErrorStream(true);\n+      Process ffmpegProcess = null;\n+      int exitCode = 1;\n+      BufferedReader errStream = null;\n+      try {\n+        ffmpegProcess = pb.start();\n+\n+        errStream = new BufferedReader(new InputStreamReader(ffmpegProcess.getInputStream()));\n+        String line = errStream.readLine();\n+        while (line != null) {\n+          logger.info(line);\n+          line = errStream.readLine();\n+        }\n+\n+        exitCode = ffmpegProcess.waitFor();\n+      } catch (IOException ex) {\n+        throw new VideoGridServiceException(\"Start ffmpeg process failed\", ex);\n+      } catch (InterruptedException ex) {\n+        throw new VideoGridServiceException(\"Waiting for encoder process exited was interrupted unexpectedly\", ex);\n+      } finally {\n+        IoSupport.closeQuietly(ffmpegProcess);\n+        IoSupport.closeQuietly(errStream);\n+        if (exitCode != 0) {\n+          try {\n+            logger.warn(\"FFMPEG process exited with errorcode: \" + exitCode);\n+            FileUtils.forceDelete(new File(outputDirPath));\n+          } catch (IOException e) {\n+            // it is ok, no output file was generated by ffmpeg\n+          }\n+        }\n+      }\n+\n+      if (exitCode != 0)\n+        throw new Exception(String.format(\"The encoder process exited abnormally with exit code %s \"\n+                + \"using command\\n%s\", exitCode, String.join(\" \", command)));\n+    }\n+\n+    // Put each generated video into workspace\n+    List<URI> uris = new ArrayList<>();\n+    for (String outputPath : outputPaths) {\n+\n+      FileInputStream outputFileInputStream = null;\n+      URI webcamFileUri;\n+      try {\n+        outputFileInputStream = new FileInputStream(outputPath);\n+        webcamFileUri = workspace.putInCollection(\"videogrid\",\n+                FilenameUtils.getName(outputPath), outputFileInputStream);\n+        uris.add(webcamFileUri);\n+        logger.info(\"Copied the created webcam video to the workspace {}\", webcamFileUri);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMzg3NA==", "bodyText": "Please use Annotations", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498723874", "createdAt": "2020-10-02T09:48:50Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-service-impl/src/main/resources/OSGI-INF/videogrid-endpoint.xml", "diffHunk": "@@ -0,0 +1,18 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNDIwNw==", "bodyText": "Please use Annotations. You can take a look at the annimate-impl", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498724207", "createdAt": "2020-10-02T09:49:30Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-service-impl/src/main/resources/OSGI-INF/videogrid.xml", "diffHunk": "@@ -0,0 +1,22 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNzI4Ng==", "bodyText": "Please rename this class to reflect its usecase. It is not clear that Edl stands for Edit descion lis without searching the the rest of the code.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498727286", "createdAt": "2020-10-02T09:56:07Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1000 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVOR = \"source-flavor\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 291}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyODc2Mw==", "bodyText": "Please add a comment what those are used for.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498728763", "createdAt": "2020-10-02T09:59:12Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1000 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVOR = \"source-flavor\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyOTY1MQ==", "bodyText": "webcam -> videogrid", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498729651", "createdAt": "2020-10-02T10:01:10Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1000 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVOR = \"source-flavor\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 377}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc4ODAwMg==", "bodyText": "I do understand the wish to have the resolution as a pair, but in this case, I find it rather confusing to have getLeft and getRight for a resolution. I would suggest to encapsulate it into its own class instead of the ImmutablePair.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498788002", "createdAt": "2020-10-02T12:24:09Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1000 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVOR = \"source-flavor\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());\n+\n+    final MediaPackage mediaPackage = (MediaPackage) workflowInstance.getMediaPackage().clone();\n+\n+    // Read config options\n+    WorkflowOperationInstance operation = workflowInstance.getCurrentOperation();\n+    final String sourceFlavor = StringUtils.trimToNull(operation.getConfiguration(SOURCE_FLAVOR));\n+    final MediaPackageElementFlavor smilFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, SOURCE_SMIL_FLAVOR));\n+    final MediaPackageElementFlavor targetPresenterFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, TARGET_FLAVOR));\n+    String concatEncodingProfile = StringUtils.trimToNull(operation.getConfiguration(CONCAT_ENCODING_PROFILE));\n+\n+    // Get tracks from flavor\n+    TrackSelector trackSelector = new TrackSelector();\n+    trackSelector.addFlavor(sourceFlavor);\n+    final List<Track> sourceTracks = new ArrayList<>(\n+            trackSelector.select(mediaPackage, false)\n+    );\n+\n+    // No tracks? Skip\n+    if (sourceTracks.isEmpty()) {\n+      logger.warn(\"No tracks in source flavor, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // No concat encoding profile? Fail\n+    if (concatEncodingProfile == null)\n+      throw new WorkflowOperationException(\"Encoding profile must be set!\");\n+    EncodingProfile profile = composerService.getProfile(concatEncodingProfile);\n+    if (profile == null)\n+      throw new WorkflowOperationException(\"Encoding profile '\" + concatEncodingProfile + \"' was not found\");\n+\n+\n+    // Define a general Layout for the final video\n+    ImmutablePair<Integer, Integer> resolution;\n+    try {\n+      resolution = getResolution(getConfig(workflowInstance, OPT_RESOLUTION, \"1280x720\"));\n+    } catch (IllegalArgumentException e) {\n+      logger.warn(\"Given resolution was not well formatted!\");\n+      throw new WorkflowOperationException(e);\n+    }\n+    logger.info(\"The resolution of the final video: {}/{}\", resolution.getLeft(), resolution.getRight());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 419}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODgzNzgxNw==", "bodyText": "Please remove the opt-prefix and mark those mandatory which would be required to be provided. A lot of woh have optional parameters and they are usually not prefix with opt", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498837817", "createdAt": "2020-10-02T13:56:41Z", "author": {"login": "pascalseeland"}, "path": "docs/guides/admin/docs/workflowoperationhandlers/video-grid-woh.md", "diffHunk": "@@ -0,0 +1,64 @@\n+# VideoGridWorkflowOperationHandler\n+\n+## Description\n+\n+The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously\n+playing videos into a single video file. For example, the webcam feeds during a video conference\n+can be combined by this WOH. The resulting video puts each input video on a grid that dynamically\n+resizes based on the number of inputs videos currently active. Which input video is active when\n+is defined by through a SMIL catalogue from e.g. a partial ingest.\n+\n+If the SMIL defines a section where there are no videos active, the background color will be shown\n+instead for the duration of the section. This also holds true for potentially empty beginning and end \n+sections, ensuring that a final single video is as long as the overall duration defined in the SMIL \n+(e.g. if the first input video becomes active at 30 seconds, the first generated output is a 30 second\n+long video of the background color). The background color is also shown whenever the input videos cannot\n+fully fill up the available space.\n+\n+This WOH relies on the inspect service for enriching generated, temporary video files with metadata.\n+Furthermore, it relies on the composers concat service to combine temporary video files into\n+a single output file.\n+\n+## Parameter Table\n+\n+|configuration keys | example                     | description                                                         |\n+|-------------------|-----------------------------|---------------------------------------------------------------------|\n+|source-flavors     | presenter/source            | Flavors containing all the video tracks to be combined.                              |\n+|source-smil-flavor | smil/source+partial         | Flavor containing the SMIL specifying when each video track is active. The example shows the flavor used by partial ingest.                               |\n+|concat-encoding-profile | concat-samecodec.work  | Encoding profile used for the final concatenation.\n+|opt-resolution     | 1280x720                    | (Optional) Resolution of the output. Example value is the default.\n+|opt-background-color| 0xFFFFFF                   | (Optional) The color used to fill space not occupied by input videos in the output. Example value is the default.\n+|target-flavor      | presenter/partial           | Flavor containing the output video tracks.                              |\n+|opt-target-tags    | archive                     | (Optional) Tag(s) to add to the output track. Default is `null`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg0NTM4OQ==", "bodyText": "It would be nice if this minlen parameter could be set as a workflow parameter. I could even imagine setting it to something like 1 sec, so the video does not change that often in case a lot of people join or leave", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498845389", "createdAt": "2020-10-02T14:09:22Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1007 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVORS = \"source-flavors\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());\n+\n+    final MediaPackage mediaPackage = (MediaPackage) workflowInstance.getMediaPackage().clone();\n+\n+    // Read config options\n+    WorkflowOperationInstance operation = workflowInstance.getCurrentOperation();\n+    final MediaPackageElementFlavor smilFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, SOURCE_SMIL_FLAVOR));\n+    final MediaPackageElementFlavor targetPresenterFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, TARGET_FLAVOR));\n+    String concatEncodingProfile = StringUtils.trimToNull(operation.getConfiguration(CONCAT_ENCODING_PROFILE));\n+\n+    // Get source flavors\n+    String sourceFlavorNames = operation.getConfiguration(SOURCE_FLAVORS);\n+    final List<MediaPackageElementFlavor> sourceFlavors = new ArrayList<>();\n+    for (String flavorName : asList(sourceFlavorNames)) {\n+      sourceFlavors.add(MediaPackageElementFlavor.parseFlavor(flavorName));\n+    }\n+\n+    // Get tracks from flavor\n+    final List<Track> sourceTracks = new ArrayList<>();\n+    for (MediaPackageElementFlavor sourceFlavor: sourceFlavors) {\n+      TrackSelector trackSelector = new TrackSelector();\n+      trackSelector.addFlavor(sourceFlavor);\n+      sourceTracks.addAll(trackSelector.select(mediaPackage, false));\n+    }\n+\n+    // No tracks? Skip\n+    if (sourceTracks.isEmpty()) {\n+      logger.warn(\"No tracks in source flavors, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // No concat encoding profile? Fail\n+    if (concatEncodingProfile == null)\n+      throw new WorkflowOperationException(\"Encoding profile must be set!\");\n+    EncodingProfile profile = composerService.getProfile(concatEncodingProfile);\n+    if (profile == null)\n+      throw new WorkflowOperationException(\"Encoding profile '\" + concatEncodingProfile + \"' was not found\");\n+\n+\n+    // Define a general Layout for the final video\n+    ImmutablePair<Integer, Integer> resolution;\n+    try {\n+      resolution = getResolution(getConfig(workflowInstance, OPT_RESOLUTION, \"1280x720\"));\n+    } catch (IllegalArgumentException e) {\n+      logger.warn(\"Given resolution was not well formatted!\");\n+      throw new WorkflowOperationException(e);\n+    }\n+    logger.info(\"The resolution of the final video: {}/{}\", resolution.getLeft(), resolution.getRight());\n+\n+    // Define a bg color for the final video\n+    String bgColor = getConfig(workflowInstance, OPT_BACKGROUND_COLOR, \"0xFFFFFF\");\n+    final Pattern pattern = Pattern.compile(\"0x[A-Fa-f0-9]{6}\");\n+    if (!pattern.matcher(bgColor).matches()) {\n+      logger.warn(\"Given color {} was not well formatted!\", bgColor);\n+      throw new WorkflowOperationException(\"Given color was not well formatted!\");\n+    }\n+    logger.info(\"The background color of the final video: {}\", bgColor);\n+\n+    // Target tags\n+    String targetTagsOption = StringUtils.trimToNull(operation.getConfiguration(OPT_TARGET_TAGS));\n+    List<String> targetTags = asList(targetTagsOption);\n+\n+    // Define general layout for the final video\n+    LayoutArea layoutArea = new LayoutArea(\"webcam\", 0, 0, resolution.getLeft(), resolution.getRight(),\n+                                            bgColor);\n+\n+    // Get SMIL catalog\n+    final SMILDocument smilDocument;\n+    try {\n+      smilDocument = SmilUtil.getSmilDocumentFromMediaPackage(mediaPackage, smilFlavor, workspace);\n+    } catch (SAXException e) {\n+      throw new WorkflowOperationException(\"SMIL is not well formatted\", e);\n+    } catch (IOException | NotFoundException e) {\n+      throw new WorkflowOperationException(\"SMIL could not be found\", e);\n+    }\n+\n+    final SMILParElement parallel = (SMILParElement) smilDocument.getBody().getChildNodes().item(0);\n+    final NodeList sequences = parallel.getTimeChildren();\n+    final float trackDurationInSeconds = parallel.getDur();\n+    final long trackDurationInMs = Math.round(trackDurationInSeconds * 1000f);\n+\n+    // Get Start- and endtime of the final video from SMIL\n+    long finalStartTime = 0;\n+    long finalEndTime = trackDurationInMs;\n+\n+    // Create a list of start and stop events, i.e. every time a new video begins or an old one ends\n+    // Create list from SMIL from partial ingests\n+    List<StartStopEvent> events = new ArrayList<>();\n+\n+    for (int i = 0; i < sequences.getLength(); i++) {\n+      final SMILElement item = (SMILElement) sequences.item(i);\n+      NodeList children = item.getChildNodes();\n+\n+      for (int j = 0; j < children.getLength(); j++) {\n+        Node node = children.item(j);\n+        SMILMediaElement e = (SMILMediaElement) node;\n+\n+        // Avoid any element that is not a video or of the source type\n+        if (NODE_TYPE_VIDEO.equals(e.getNodeName())) {\n+          Track track;\n+          try {\n+            track = getTrackByID(e.getId(), sourceTracks);\n+          } catch (IllegalStateException ex) {\n+            logger.info(\"No track corresponding to SMIL ID found, skipping SMIL ID {}\", e.getId());\n+            continue;\n+          }\n+          double beginInSeconds = e.getBegin().item(0).getResolvedOffset();\n+          long beginInMs = Math.round(beginInSeconds * 1000d);\n+          double durationInSeconds = e.getDur();\n+          long durationInMs = Math.round(durationInSeconds * 1000d);\n+\n+          // Gather video information\n+          VideoInfo videoInfo = new VideoInfo();\n+          // Aspect Ratio, e.g. 16:9\n+          List<Track> tmpList = new ArrayList<Track>();\n+          tmpList.add(track);\n+          LayoutArea trackDimension = determineDimension(tmpList, true);\n+          if (trackDimension == null) {\n+            throw new WorkflowOperationException(\"One of the source video tracks did not contain a valid video stream or dimension\");\n+          }\n+          videoInfo.aspectRatioHeight = trackDimension.getHeight();\n+          videoInfo.aspectRatioWidth = trackDimension.getWidth();\n+          // \"StartTime\" is calculated later. It describes how far into the video the next section starts.\n+          // (E.g. If webcam2 is started 10 seconds after webcam1, the startTime for webcam1 in the next section is 10)\n+          videoInfo.startTime = 0;\n+\n+          logger.info(\"Video information: Width: {}, Height {}, StartTime: {}\", videoInfo.aspectRatioWidth,\n+                  videoInfo.aspectRatioHeight, videoInfo.startTime);\n+\n+          events.add(new StartStopEvent(true, getTrackPath(track), beginInMs, videoInfo));\n+          events.add(new StartStopEvent(false, getTrackPath(track), beginInMs + durationInMs, videoInfo));\n+\n+        }\n+      }\n+    }\n+\n+    // No events? Skip\n+    if (events.isEmpty()) {\n+      logger.warn(\"Could not generate sections from given SMIL catalogue for tracks in given flavor, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // Sort by timestamps ascending\n+    Collections.sort(events);\n+\n+    // Create an edit decision list\n+    List<VideoEdlPart> videoEdl = new ArrayList<VideoEdlPart>();\n+    HashMap<String, StartStopEvent> activeVideos = new HashMap<>();   // Currently running videos\n+\n+    // Define starting point\n+    VideoEdlPart start = new VideoEdlPart();\n+    start.timeStamp = finalStartTime;\n+    videoEdl.add(start);\n+\n+    // Define mid-points\n+    for (StartStopEvent event : events) {\n+      if (event.start) {\n+        logger.info(\"Add start event at {}\", event.timeStamp);\n+        activeVideos.put(event.filename, event);\n+      } else {\n+        logger.info(\"Add stop event at {}\", event);\n+        activeVideos.remove(event.filename);\n+      }\n+      videoEdl.add(createVideoEdl(event, activeVideos));\n+    }\n+\n+    // Define ending point\n+    VideoEdlPart endVideo = new VideoEdlPart();\n+    endVideo.timeStamp = finalEndTime;\n+    endVideo.nextTimeStamp = finalEndTime;\n+    videoEdl.add(endVideo);\n+\n+    // Pre processing EDL\n+    for (int i = 0; i < videoEdl.size() - 1; i++) {\n+      // For calculating cut lengths\n+      videoEdl.get(i).nextTimeStamp = videoEdl.get(i + 1).timeStamp;\n+    }\n+\n+    // Create ffmpeg command for each section\n+    List<List<String>> commands = new ArrayList<>();\n+    for (VideoEdlPart edl : videoEdl) {\n+      // A too small duration will result in ffmpeg producing a faulty video, so avoid any section smaller than 50ms\n+      if (edl.nextTimeStamp - edl.timeStamp < 50) {\n+        logger.info(\"Skipping {}-length edl entry\", edl.nextTimeStamp - edl.timeStamp);\n+        continue;\n+      }\n+      // Create command for section\n+      commands.add(compositeSection(layoutArea, edl));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 567}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg1OTk5Mw==", "bodyText": "It would be nice if you could add some kind of documentation how this algorithm works.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498859993", "createdAt": "2020-10-02T14:33:33Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1007 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVORS = \"source-flavors\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());\n+\n+    final MediaPackage mediaPackage = (MediaPackage) workflowInstance.getMediaPackage().clone();\n+\n+    // Read config options\n+    WorkflowOperationInstance operation = workflowInstance.getCurrentOperation();\n+    final MediaPackageElementFlavor smilFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, SOURCE_SMIL_FLAVOR));\n+    final MediaPackageElementFlavor targetPresenterFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, TARGET_FLAVOR));\n+    String concatEncodingProfile = StringUtils.trimToNull(operation.getConfiguration(CONCAT_ENCODING_PROFILE));\n+\n+    // Get source flavors\n+    String sourceFlavorNames = operation.getConfiguration(SOURCE_FLAVORS);\n+    final List<MediaPackageElementFlavor> sourceFlavors = new ArrayList<>();\n+    for (String flavorName : asList(sourceFlavorNames)) {\n+      sourceFlavors.add(MediaPackageElementFlavor.parseFlavor(flavorName));\n+    }\n+\n+    // Get tracks from flavor\n+    final List<Track> sourceTracks = new ArrayList<>();\n+    for (MediaPackageElementFlavor sourceFlavor: sourceFlavors) {\n+      TrackSelector trackSelector = new TrackSelector();\n+      trackSelector.addFlavor(sourceFlavor);\n+      sourceTracks.addAll(trackSelector.select(mediaPackage, false));\n+    }\n+\n+    // No tracks? Skip\n+    if (sourceTracks.isEmpty()) {\n+      logger.warn(\"No tracks in source flavors, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // No concat encoding profile? Fail\n+    if (concatEncodingProfile == null)\n+      throw new WorkflowOperationException(\"Encoding profile must be set!\");\n+    EncodingProfile profile = composerService.getProfile(concatEncodingProfile);\n+    if (profile == null)\n+      throw new WorkflowOperationException(\"Encoding profile '\" + concatEncodingProfile + \"' was not found\");\n+\n+\n+    // Define a general Layout for the final video\n+    ImmutablePair<Integer, Integer> resolution;\n+    try {\n+      resolution = getResolution(getConfig(workflowInstance, OPT_RESOLUTION, \"1280x720\"));\n+    } catch (IllegalArgumentException e) {\n+      logger.warn(\"Given resolution was not well formatted!\");\n+      throw new WorkflowOperationException(e);\n+    }\n+    logger.info(\"The resolution of the final video: {}/{}\", resolution.getLeft(), resolution.getRight());\n+\n+    // Define a bg color for the final video\n+    String bgColor = getConfig(workflowInstance, OPT_BACKGROUND_COLOR, \"0xFFFFFF\");\n+    final Pattern pattern = Pattern.compile(\"0x[A-Fa-f0-9]{6}\");\n+    if (!pattern.matcher(bgColor).matches()) {\n+      logger.warn(\"Given color {} was not well formatted!\", bgColor);\n+      throw new WorkflowOperationException(\"Given color was not well formatted!\");\n+    }\n+    logger.info(\"The background color of the final video: {}\", bgColor);\n+\n+    // Target tags\n+    String targetTagsOption = StringUtils.trimToNull(operation.getConfiguration(OPT_TARGET_TAGS));\n+    List<String> targetTags = asList(targetTagsOption);\n+\n+    // Define general layout for the final video\n+    LayoutArea layoutArea = new LayoutArea(\"webcam\", 0, 0, resolution.getLeft(), resolution.getRight(),\n+                                            bgColor);\n+\n+    // Get SMIL catalog\n+    final SMILDocument smilDocument;\n+    try {\n+      smilDocument = SmilUtil.getSmilDocumentFromMediaPackage(mediaPackage, smilFlavor, workspace);\n+    } catch (SAXException e) {\n+      throw new WorkflowOperationException(\"SMIL is not well formatted\", e);\n+    } catch (IOException | NotFoundException e) {\n+      throw new WorkflowOperationException(\"SMIL could not be found\", e);\n+    }\n+\n+    final SMILParElement parallel = (SMILParElement) smilDocument.getBody().getChildNodes().item(0);\n+    final NodeList sequences = parallel.getTimeChildren();\n+    final float trackDurationInSeconds = parallel.getDur();\n+    final long trackDurationInMs = Math.round(trackDurationInSeconds * 1000f);\n+\n+    // Get Start- and endtime of the final video from SMIL\n+    long finalStartTime = 0;\n+    long finalEndTime = trackDurationInMs;\n+\n+    // Create a list of start and stop events, i.e. every time a new video begins or an old one ends\n+    // Create list from SMIL from partial ingests\n+    List<StartStopEvent> events = new ArrayList<>();\n+\n+    for (int i = 0; i < sequences.getLength(); i++) {\n+      final SMILElement item = (SMILElement) sequences.item(i);\n+      NodeList children = item.getChildNodes();\n+\n+      for (int j = 0; j < children.getLength(); j++) {\n+        Node node = children.item(j);\n+        SMILMediaElement e = (SMILMediaElement) node;\n+\n+        // Avoid any element that is not a video or of the source type\n+        if (NODE_TYPE_VIDEO.equals(e.getNodeName())) {\n+          Track track;\n+          try {\n+            track = getTrackByID(e.getId(), sourceTracks);\n+          } catch (IllegalStateException ex) {\n+            logger.info(\"No track corresponding to SMIL ID found, skipping SMIL ID {}\", e.getId());\n+            continue;\n+          }\n+          double beginInSeconds = e.getBegin().item(0).getResolvedOffset();\n+          long beginInMs = Math.round(beginInSeconds * 1000d);\n+          double durationInSeconds = e.getDur();\n+          long durationInMs = Math.round(durationInSeconds * 1000d);\n+\n+          // Gather video information\n+          VideoInfo videoInfo = new VideoInfo();\n+          // Aspect Ratio, e.g. 16:9\n+          List<Track> tmpList = new ArrayList<Track>();\n+          tmpList.add(track);\n+          LayoutArea trackDimension = determineDimension(tmpList, true);\n+          if (trackDimension == null) {\n+            throw new WorkflowOperationException(\"One of the source video tracks did not contain a valid video stream or dimension\");\n+          }\n+          videoInfo.aspectRatioHeight = trackDimension.getHeight();\n+          videoInfo.aspectRatioWidth = trackDimension.getWidth();\n+          // \"StartTime\" is calculated later. It describes how far into the video the next section starts.\n+          // (E.g. If webcam2 is started 10 seconds after webcam1, the startTime for webcam1 in the next section is 10)\n+          videoInfo.startTime = 0;\n+\n+          logger.info(\"Video information: Width: {}, Height {}, StartTime: {}\", videoInfo.aspectRatioWidth,\n+                  videoInfo.aspectRatioHeight, videoInfo.startTime);\n+\n+          events.add(new StartStopEvent(true, getTrackPath(track), beginInMs, videoInfo));\n+          events.add(new StartStopEvent(false, getTrackPath(track), beginInMs + durationInMs, videoInfo));\n+\n+        }\n+      }\n+    }\n+\n+    // No events? Skip\n+    if (events.isEmpty()) {\n+      logger.warn(\"Could not generate sections from given SMIL catalogue for tracks in given flavor, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // Sort by timestamps ascending\n+    Collections.sort(events);\n+\n+    // Create an edit decision list\n+    List<VideoEdlPart> videoEdl = new ArrayList<VideoEdlPart>();\n+    HashMap<String, StartStopEvent> activeVideos = new HashMap<>();   // Currently running videos\n+\n+    // Define starting point\n+    VideoEdlPart start = new VideoEdlPart();\n+    start.timeStamp = finalStartTime;\n+    videoEdl.add(start);\n+\n+    // Define mid-points\n+    for (StartStopEvent event : events) {\n+      if (event.start) {\n+        logger.info(\"Add start event at {}\", event.timeStamp);\n+        activeVideos.put(event.filename, event);\n+      } else {\n+        logger.info(\"Add stop event at {}\", event);\n+        activeVideos.remove(event.filename);\n+      }\n+      videoEdl.add(createVideoEdl(event, activeVideos));\n+    }\n+\n+    // Define ending point\n+    VideoEdlPart endVideo = new VideoEdlPart();\n+    endVideo.timeStamp = finalEndTime;\n+    endVideo.nextTimeStamp = finalEndTime;\n+    videoEdl.add(endVideo);\n+\n+    // Pre processing EDL\n+    for (int i = 0; i < videoEdl.size() - 1; i++) {\n+      // For calculating cut lengths\n+      videoEdl.get(i).nextTimeStamp = videoEdl.get(i + 1).timeStamp;\n+    }\n+\n+    // Create ffmpeg command for each section\n+    List<List<String>> commands = new ArrayList<>();\n+    for (VideoEdlPart edl : videoEdl) {\n+      // A too small duration will result in ffmpeg producing a faulty video, so avoid any section smaller than 50ms\n+      if (edl.nextTimeStamp - edl.timeStamp < 50) {\n+        logger.info(\"Skipping {}-length edl entry\", edl.nextTimeStamp - edl.timeStamp);\n+        continue;\n+      }\n+      // Create command for section\n+      commands.add(compositeSection(layoutArea, edl));\n+    }\n+\n+    // Create video tracks for each section\n+    Job job;\n+    try {\n+      job = videoGridService.createPartialTracks(commands);\n+    } catch (VideoGridServiceException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    if (!waitForStatus(job).isSuccess()) {\n+      throw new WorkflowOperationException(String.format(\"VideoGrid job for media package '%s' failed\", mediaPackage));\n+    }\n+\n+    Gson gson = new Gson();\n+    List<URI> uris = gson.fromJson(job.getPayload(), new TypeToken<List<URI>>() { }.getType());\n+\n+    // Parse uris into tracks and enrich them with metadata\n+    List<Track> tracks = new ArrayList<>();\n+    for (URI uri : uris) {\n+      TrackImpl track = new TrackImpl();\n+      track.setFlavor(targetPresenterFlavor);\n+      track.setURI(uri);\n+\n+      Job inspection = null;\n+      try {\n+        inspection = inspectionService.enrich(track, true);\n+      } catch (MediaInspectionException | MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Inspection service could not enrich track\", e);\n+      }\n+      if (!waitForStatus(inspection).isSuccess()) {\n+        throw new WorkflowOperationException(String.format(\"Failed to add metadata to track.\"));\n+      }\n+\n+      try {\n+        tracks.add((TrackImpl) MediaPackageElementParser.getFromXml(inspection.getPayload()));\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by inspection service\", e);\n+      }\n+    }\n+\n+    // Concatenate sections\n+    Job concatJob = null;\n+    try {\n+      concatJob = composerService.concat(composerService.getProfile(concatEncodingProfile).getIdentifier(),\n+              new Dimension(layoutArea.width,layoutArea.height) , true, tracks.toArray(new Track[tracks.size()]));\n+    } catch (EncoderException | MediaPackageException e) {\n+      throw new WorkflowOperationException(\"The concat job failed\", e);\n+    }\n+    if (!waitForStatus(concatJob).isSuccess()) {\n+      throw new WorkflowOperationException(\"The concat job did not complete successfully.\");\n+    }\n+\n+    // Add to mediapackage\n+    if (concatJob.getPayload().length() > 0) {\n+      Track concatTrack;\n+      try {\n+        concatTrack = (Track) MediaPackageElementParser.getFromXml(concatJob.getPayload());\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by concat service\", e);\n+      }\n+      concatTrack.setFlavor(targetPresenterFlavor);\n+      concatTrack.setURI(concatTrack.getURI());\n+      for (String tag : targetTags) {\n+        concatTrack.addTag(tag);\n+      }\n+\n+      mediaPackage.add(concatTrack);\n+    } else {\n+      throw new WorkflowOperationException(\"Concat operation unsuccessful, no payload returned.\");\n+    }\n+\n+    try {\n+      workspace.cleanup(mediaPackage.getIdentifier());\n+    } catch (IOException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    final WorkflowOperationResult result = createResult(mediaPackage, WorkflowOperationResult.Action.CONTINUE);\n+    logger.debug(\"Video Grid operation completed\");\n+    return result;\n+  }\n+\n+  /**\n+   * Create a ffmpeg command that generate a videos for the given cutting marks\n+   * @param layoutArea\n+   *          General layout information for the video\n+   *          (Originally it was possible to have multiple layout areas)\n+   * @param videoEdl\n+   *          The edit decision list for the current cut\n+   * @return A command line ready ffmpeg command\n+   */\n+  private List<String> compositeSection(LayoutArea layoutArea, VideoEdlPart videoEdl)\n+  {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 660}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg2MTAxOA==", "bodyText": "This might fail if the tracks have very strange dimensions, like very narrow, etc", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498861018", "createdAt": "2020-10-02T14:35:20Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1007 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVORS = \"source-flavors\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());\n+\n+    final MediaPackage mediaPackage = (MediaPackage) workflowInstance.getMediaPackage().clone();\n+\n+    // Read config options\n+    WorkflowOperationInstance operation = workflowInstance.getCurrentOperation();\n+    final MediaPackageElementFlavor smilFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, SOURCE_SMIL_FLAVOR));\n+    final MediaPackageElementFlavor targetPresenterFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, TARGET_FLAVOR));\n+    String concatEncodingProfile = StringUtils.trimToNull(operation.getConfiguration(CONCAT_ENCODING_PROFILE));\n+\n+    // Get source flavors\n+    String sourceFlavorNames = operation.getConfiguration(SOURCE_FLAVORS);\n+    final List<MediaPackageElementFlavor> sourceFlavors = new ArrayList<>();\n+    for (String flavorName : asList(sourceFlavorNames)) {\n+      sourceFlavors.add(MediaPackageElementFlavor.parseFlavor(flavorName));\n+    }\n+\n+    // Get tracks from flavor\n+    final List<Track> sourceTracks = new ArrayList<>();\n+    for (MediaPackageElementFlavor sourceFlavor: sourceFlavors) {\n+      TrackSelector trackSelector = new TrackSelector();\n+      trackSelector.addFlavor(sourceFlavor);\n+      sourceTracks.addAll(trackSelector.select(mediaPackage, false));\n+    }\n+\n+    // No tracks? Skip\n+    if (sourceTracks.isEmpty()) {\n+      logger.warn(\"No tracks in source flavors, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // No concat encoding profile? Fail\n+    if (concatEncodingProfile == null)\n+      throw new WorkflowOperationException(\"Encoding profile must be set!\");\n+    EncodingProfile profile = composerService.getProfile(concatEncodingProfile);\n+    if (profile == null)\n+      throw new WorkflowOperationException(\"Encoding profile '\" + concatEncodingProfile + \"' was not found\");\n+\n+\n+    // Define a general Layout for the final video\n+    ImmutablePair<Integer, Integer> resolution;\n+    try {\n+      resolution = getResolution(getConfig(workflowInstance, OPT_RESOLUTION, \"1280x720\"));\n+    } catch (IllegalArgumentException e) {\n+      logger.warn(\"Given resolution was not well formatted!\");\n+      throw new WorkflowOperationException(e);\n+    }\n+    logger.info(\"The resolution of the final video: {}/{}\", resolution.getLeft(), resolution.getRight());\n+\n+    // Define a bg color for the final video\n+    String bgColor = getConfig(workflowInstance, OPT_BACKGROUND_COLOR, \"0xFFFFFF\");\n+    final Pattern pattern = Pattern.compile(\"0x[A-Fa-f0-9]{6}\");\n+    if (!pattern.matcher(bgColor).matches()) {\n+      logger.warn(\"Given color {} was not well formatted!\", bgColor);\n+      throw new WorkflowOperationException(\"Given color was not well formatted!\");\n+    }\n+    logger.info(\"The background color of the final video: {}\", bgColor);\n+\n+    // Target tags\n+    String targetTagsOption = StringUtils.trimToNull(operation.getConfiguration(OPT_TARGET_TAGS));\n+    List<String> targetTags = asList(targetTagsOption);\n+\n+    // Define general layout for the final video\n+    LayoutArea layoutArea = new LayoutArea(\"webcam\", 0, 0, resolution.getLeft(), resolution.getRight(),\n+                                            bgColor);\n+\n+    // Get SMIL catalog\n+    final SMILDocument smilDocument;\n+    try {\n+      smilDocument = SmilUtil.getSmilDocumentFromMediaPackage(mediaPackage, smilFlavor, workspace);\n+    } catch (SAXException e) {\n+      throw new WorkflowOperationException(\"SMIL is not well formatted\", e);\n+    } catch (IOException | NotFoundException e) {\n+      throw new WorkflowOperationException(\"SMIL could not be found\", e);\n+    }\n+\n+    final SMILParElement parallel = (SMILParElement) smilDocument.getBody().getChildNodes().item(0);\n+    final NodeList sequences = parallel.getTimeChildren();\n+    final float trackDurationInSeconds = parallel.getDur();\n+    final long trackDurationInMs = Math.round(trackDurationInSeconds * 1000f);\n+\n+    // Get Start- and endtime of the final video from SMIL\n+    long finalStartTime = 0;\n+    long finalEndTime = trackDurationInMs;\n+\n+    // Create a list of start and stop events, i.e. every time a new video begins or an old one ends\n+    // Create list from SMIL from partial ingests\n+    List<StartStopEvent> events = new ArrayList<>();\n+\n+    for (int i = 0; i < sequences.getLength(); i++) {\n+      final SMILElement item = (SMILElement) sequences.item(i);\n+      NodeList children = item.getChildNodes();\n+\n+      for (int j = 0; j < children.getLength(); j++) {\n+        Node node = children.item(j);\n+        SMILMediaElement e = (SMILMediaElement) node;\n+\n+        // Avoid any element that is not a video or of the source type\n+        if (NODE_TYPE_VIDEO.equals(e.getNodeName())) {\n+          Track track;\n+          try {\n+            track = getTrackByID(e.getId(), sourceTracks);\n+          } catch (IllegalStateException ex) {\n+            logger.info(\"No track corresponding to SMIL ID found, skipping SMIL ID {}\", e.getId());\n+            continue;\n+          }\n+          double beginInSeconds = e.getBegin().item(0).getResolvedOffset();\n+          long beginInMs = Math.round(beginInSeconds * 1000d);\n+          double durationInSeconds = e.getDur();\n+          long durationInMs = Math.round(durationInSeconds * 1000d);\n+\n+          // Gather video information\n+          VideoInfo videoInfo = new VideoInfo();\n+          // Aspect Ratio, e.g. 16:9\n+          List<Track> tmpList = new ArrayList<Track>();\n+          tmpList.add(track);\n+          LayoutArea trackDimension = determineDimension(tmpList, true);\n+          if (trackDimension == null) {\n+            throw new WorkflowOperationException(\"One of the source video tracks did not contain a valid video stream or dimension\");\n+          }\n+          videoInfo.aspectRatioHeight = trackDimension.getHeight();\n+          videoInfo.aspectRatioWidth = trackDimension.getWidth();\n+          // \"StartTime\" is calculated later. It describes how far into the video the next section starts.\n+          // (E.g. If webcam2 is started 10 seconds after webcam1, the startTime for webcam1 in the next section is 10)\n+          videoInfo.startTime = 0;\n+\n+          logger.info(\"Video information: Width: {}, Height {}, StartTime: {}\", videoInfo.aspectRatioWidth,\n+                  videoInfo.aspectRatioHeight, videoInfo.startTime);\n+\n+          events.add(new StartStopEvent(true, getTrackPath(track), beginInMs, videoInfo));\n+          events.add(new StartStopEvent(false, getTrackPath(track), beginInMs + durationInMs, videoInfo));\n+\n+        }\n+      }\n+    }\n+\n+    // No events? Skip\n+    if (events.isEmpty()) {\n+      logger.warn(\"Could not generate sections from given SMIL catalogue for tracks in given flavor, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // Sort by timestamps ascending\n+    Collections.sort(events);\n+\n+    // Create an edit decision list\n+    List<VideoEdlPart> videoEdl = new ArrayList<VideoEdlPart>();\n+    HashMap<String, StartStopEvent> activeVideos = new HashMap<>();   // Currently running videos\n+\n+    // Define starting point\n+    VideoEdlPart start = new VideoEdlPart();\n+    start.timeStamp = finalStartTime;\n+    videoEdl.add(start);\n+\n+    // Define mid-points\n+    for (StartStopEvent event : events) {\n+      if (event.start) {\n+        logger.info(\"Add start event at {}\", event.timeStamp);\n+        activeVideos.put(event.filename, event);\n+      } else {\n+        logger.info(\"Add stop event at {}\", event);\n+        activeVideos.remove(event.filename);\n+      }\n+      videoEdl.add(createVideoEdl(event, activeVideos));\n+    }\n+\n+    // Define ending point\n+    VideoEdlPart endVideo = new VideoEdlPart();\n+    endVideo.timeStamp = finalEndTime;\n+    endVideo.nextTimeStamp = finalEndTime;\n+    videoEdl.add(endVideo);\n+\n+    // Pre processing EDL\n+    for (int i = 0; i < videoEdl.size() - 1; i++) {\n+      // For calculating cut lengths\n+      videoEdl.get(i).nextTimeStamp = videoEdl.get(i + 1).timeStamp;\n+    }\n+\n+    // Create ffmpeg command for each section\n+    List<List<String>> commands = new ArrayList<>();\n+    for (VideoEdlPart edl : videoEdl) {\n+      // A too small duration will result in ffmpeg producing a faulty video, so avoid any section smaller than 50ms\n+      if (edl.nextTimeStamp - edl.timeStamp < 50) {\n+        logger.info(\"Skipping {}-length edl entry\", edl.nextTimeStamp - edl.timeStamp);\n+        continue;\n+      }\n+      // Create command for section\n+      commands.add(compositeSection(layoutArea, edl));\n+    }\n+\n+    // Create video tracks for each section\n+    Job job;\n+    try {\n+      job = videoGridService.createPartialTracks(commands);\n+    } catch (VideoGridServiceException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    if (!waitForStatus(job).isSuccess()) {\n+      throw new WorkflowOperationException(String.format(\"VideoGrid job for media package '%s' failed\", mediaPackage));\n+    }\n+\n+    Gson gson = new Gson();\n+    List<URI> uris = gson.fromJson(job.getPayload(), new TypeToken<List<URI>>() { }.getType());\n+\n+    // Parse uris into tracks and enrich them with metadata\n+    List<Track> tracks = new ArrayList<>();\n+    for (URI uri : uris) {\n+      TrackImpl track = new TrackImpl();\n+      track.setFlavor(targetPresenterFlavor);\n+      track.setURI(uri);\n+\n+      Job inspection = null;\n+      try {\n+        inspection = inspectionService.enrich(track, true);\n+      } catch (MediaInspectionException | MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Inspection service could not enrich track\", e);\n+      }\n+      if (!waitForStatus(inspection).isSuccess()) {\n+        throw new WorkflowOperationException(String.format(\"Failed to add metadata to track.\"));\n+      }\n+\n+      try {\n+        tracks.add((TrackImpl) MediaPackageElementParser.getFromXml(inspection.getPayload()));\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by inspection service\", e);\n+      }\n+    }\n+\n+    // Concatenate sections\n+    Job concatJob = null;\n+    try {\n+      concatJob = composerService.concat(composerService.getProfile(concatEncodingProfile).getIdentifier(),\n+              new Dimension(layoutArea.width,layoutArea.height) , true, tracks.toArray(new Track[tracks.size()]));\n+    } catch (EncoderException | MediaPackageException e) {\n+      throw new WorkflowOperationException(\"The concat job failed\", e);\n+    }\n+    if (!waitForStatus(concatJob).isSuccess()) {\n+      throw new WorkflowOperationException(\"The concat job did not complete successfully.\");\n+    }\n+\n+    // Add to mediapackage\n+    if (concatJob.getPayload().length() > 0) {\n+      Track concatTrack;\n+      try {\n+        concatTrack = (Track) MediaPackageElementParser.getFromXml(concatJob.getPayload());\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by concat service\", e);\n+      }\n+      concatTrack.setFlavor(targetPresenterFlavor);\n+      concatTrack.setURI(concatTrack.getURI());\n+      for (String tag : targetTags) {\n+        concatTrack.addTag(tag);\n+      }\n+\n+      mediaPackage.add(concatTrack);\n+    } else {\n+      throw new WorkflowOperationException(\"Concat operation unsuccessful, no payload returned.\");\n+    }\n+\n+    try {\n+      workspace.cleanup(mediaPackage.getIdentifier());\n+    } catch (IOException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    final WorkflowOperationResult result = createResult(mediaPackage, WorkflowOperationResult.Action.CONTINUE);\n+    logger.debug(\"Video Grid operation completed\");\n+    return result;\n+  }\n+\n+  /**\n+   * Create a ffmpeg command that generate a videos for the given cutting marks\n+   * @param layoutArea\n+   *          General layout information for the video\n+   *          (Originally it was possible to have multiple layout areas)\n+   * @param videoEdl\n+   *          The edit decision list for the current cut\n+   * @return A command line ready ffmpeg command\n+   */\n+  private List<String> compositeSection(LayoutArea layoutArea, VideoEdlPart videoEdl)\n+  {\n+    // Duration for this cut\n+    long duration = videoEdl.nextTimeStamp - videoEdl.timeStamp;\n+    logger.info(\"Cut timeStamp {}, duration {}\", videoEdl.timeStamp, duration);\n+\n+    // Declare ffmpeg command\n+    String ffmpegFilter = String.format(\"color=c=%s:s=%dx%d:r=24\", layoutArea.bgColor, layoutArea.width, layoutArea.height);\n+\n+    List<VideoInfo> videos = videoEdl.areas;\n+    int videoCount = videoEdl.areas.size();\n+\n+    logger.info(\"Laying out {} videos in {}\", videoCount, layoutArea.name);\n+\n+\n+    if (videoCount > 0) {\n+      int tilesH = 0;\n+      int tilesV = 0;\n+      int tileWidth = 0;\n+      int tileHeight = 0;\n+      int totalArea = 0;\n+\n+      // Do and exhaustive search to maximize video areas\n+      for (int tmpTilesV = 1; tmpTilesV < videoCount + 1; tmpTilesV++) {\n+        int tmpTilesH = (int) Math.ceil((videoCount / (float)tmpTilesV));\n+        int tmpTileWidth = (int) (2 * Math.floor((float)layoutArea.width / tmpTilesH / 2));\n+        int tmpTileHeight = (int) (2 * Math.floor((float)layoutArea.height / tmpTilesV / 2));\n+\n+        if (tmpTileWidth <= 0 || tmpTileHeight <= 0) {\n+          continue;\n+        }\n+\n+        int tmpTotalArea = 0;\n+        for (VideoInfo video: videos) {\n+          int videoWidth = video.aspectRatioWidth;\n+          int videoHeight = video.aspectRatioHeight;\n+          VideoInfo videoScaled = aspectScale(videoWidth, videoHeight, tmpTileWidth, tmpTileHeight);\n+          tmpTotalArea += videoScaled.aspectRatioWidth * videoScaled.aspectRatioHeight;\n+        }\n+\n+        if (tmpTotalArea > totalArea) {\n+          tilesH = tmpTilesH;\n+          tilesV = tmpTilesV;\n+          tileWidth = tmpTileWidth;\n+          tileHeight = tmpTileHeight;\n+          totalArea = tmpTotalArea;\n+        }\n+      }\n+\n+\n+      int tileX = 0;\n+      int tileY = 0;\n+\n+      logger.info(\"Tiling in a {}x{} grid\", tilesH, tilesV);\n+\n+      ffmpegFilter += String.format(\"[%s_in];\", layoutArea.name);\n+\n+      for (VideoInfo video : videos) {\n+        //Get videoinfo\n+        logger.info(\"tile location ({}, {})\", tileX, tileY);\n+        int videoWidth = video.aspectRatioWidth;\n+        int videoHeight = video.aspectRatioHeight;\n+        logger.info(\"original aspect: {}x{}\", videoWidth, videoHeight);\n+\n+        VideoInfo videoScaled = aspectScale(videoWidth, videoHeight, tileWidth, tileHeight);\n+        logger.info(\"scaled size: {}x{}\", videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight);\n+\n+        Offset offset = padOffset(videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight, tileWidth, tileHeight);\n+        logger.info(\"offset: left: {}, top: {}\", offset.x, offset.y);\n+\n+        // TODO: Get a proper value instead of the badly hardcoded 0\n+        // Offset in case the pts is greater than 0\n+        long seekOffset = 0;\n+        logger.info(\"seek offset: {}\", seekOffset);\n+\n+        // Webcam videos are variable, low fps; it might be that there's\n+        // no frame until some time after the seek point. Start decoding\n+        // 10s before the desired point to avoid this issue.\n+        long seek = video.startTime - 10000;\n+        if (seek < 0) {\n+          seek = 0;\n+        }\n+\n+        String padName = String.format(\"%s_x%d_y%d\", layoutArea.name, tileX, tileY);\n+\n+        // Apply the video start time offset to seek to the correct point.\n+        // Only actually apply the offset if we're already seeking so we\n+        // don't start seeking in a file where we've overridden the seek\n+        // behaviour.\n+        if (seek > 0) {\n+          seek = seek + seekOffset;\n+        }\n+        ffmpegFilter += String.format(\"movie=%s:sp=%s\", video.filename, msToS(seek));\n+        // Subtract away the offset from the timestamps, so the trimming\n+        // in the fps filter is accurate\n+        ffmpegFilter += String.format(\",setpts=PTS-%s/TB\", msToS(seekOffset));\n+        // fps filter fills in frames up to the desired start point, and\n+        // cuts the video there\n+        ffmpegFilter += String.format(\",fps=%d:start_time=%s\", FFMPEG_WF_FRAMERATE, msToS(video.startTime));\n+        // Reset the timestamps to start at 0 so that everything is synced\n+        // for the video tiling, and scale to the desired size.\n+        ffmpegFilter += String.format(\",setpts=PTS-STARTPTS,scale=%d:%d,setsar=1\", videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight);\n+        // And finally, pad the video to the desired aspect ratio\n+        ffmpegFilter += String.format(\",pad=w=%d:h=%d:x=%d:y=%d:color=%s\", tileWidth, tileHeight, offset.x, offset.y, layoutArea.bgColor);\n+        ffmpegFilter += String.format(\"[%s_movie];\", padName);\n+\n+        // In case the video was shorter than expected, we might have to pad\n+        // it to length. do that by concatenating a video generated by the\n+        // color filter. (It would be nice to repeat the last frame instead,\n+        // but there's no easy way to do that.)\n+        ffmpegFilter += String.format(\"color=c=%s:s=%dx%d:r=%d\", layoutArea.bgColor, tileWidth, tileHeight, FFMPEG_WF_FRAMERATE);\n+        ffmpegFilter += String.format(\"[%s_pad];\", padName);\n+        ffmpegFilter += String.format(\"[%s_movie][%s_pad]concat=n=2:v=1:a=0[%s];\", padName, padName, padName);\n+\n+        tileX += 1;\n+        if (tileX >= tilesH) {\n+          tileX = 0;\n+          tileY += 1;\n+        }\n+      }\n+\n+      // Create the video rows\n+      int remaining = videoCount;\n+      for (tileY = 0; tileY < tilesV; tileY++) {\n+        int thisTilesH = Math.min(tilesH, remaining);\n+        remaining -= thisTilesH;\n+\n+        for (tileX = 0; tileX < thisTilesH; tileX++) {\n+          ffmpegFilter += String.format(\"[%s_x%d_y%d]\", layoutArea.name, tileX, tileY);\n+        }\n+        if (thisTilesH > 1) {\n+          ffmpegFilter += String.format(\"hstack=inputs=%d,\", thisTilesH);\n+        }\n+        ffmpegFilter += String.format(\"pad=w=%d:h=%d:color=%s\", layoutArea.width, tileHeight, layoutArea.bgColor);\n+        ffmpegFilter += String.format(\"[%s_y%d];\", layoutArea.name, tileY);\n+      }\n+\n+      // Stack the video rows\n+      for (tileY = 0; tileY < tilesV; tileY++) {\n+        ffmpegFilter += String.format(\"[%s_y%d]\", layoutArea.name, tileY);\n+      }\n+      if (tilesV > 1) {\n+        ffmpegFilter += String.format(\"vstack=inputs=%d,\", tilesV);\n+      }\n+      ffmpegFilter += String.format(\"pad=w=%d:h=%d:color=%s\", layoutArea.width, layoutArea.height, layoutArea.bgColor);\n+      ffmpegFilter += String.format(\"[%s];\", layoutArea.name);\n+      ffmpegFilter += String.format(\"[%s_in][%s]overlay=x=%d:y=%d\", layoutArea.name, layoutArea.name, layoutArea.x, layoutArea.y);\n+\n+      // Here would be the end of the layoutArea Loop\n+    }\n+\n+    ffmpegFilter += String.format(\",trim=end=%s\", msToS(duration));\n+\n+    List<String> ffmpegCmd = new ArrayList<String>(Arrays.asList(FFMPEG));\n+    ffmpegCmd.add(\"-filter_complex\");\n+    ffmpegCmd.add(ffmpegFilter);\n+    ffmpegCmd.addAll(Arrays.asList(FFMPEG_WF_ARGS));\n+\n+    logger.info(\"Final command:\");\n+    logger.info(String.join(\" \", ffmpegCmd));\n+\n+    return ffmpegCmd;\n+  }\n+\n+  /**\n+   * Scale the video resolution to fit the new resolution while maintaining aspect ratio\n+   * @param oldWidth\n+   *          Width of the video\n+   * @param oldHeight\n+   *          Height of the video\n+   * @param newWidth\n+   *          Intended new width of the video\n+   * @param newHeight\n+   *          Intended new height of the video\n+   * @return\n+   *          Actual new width and height of the video, guaranteed to be the same or smaller as the intended values\n+   */\n+  private VideoInfo aspectScale(int oldWidth, int oldHeight, int newWidth, int newHeight) {\n+    if ((float)oldWidth / oldHeight > (float)newWidth / newHeight) {\n+      newHeight = (int) (2 * Math.round((float)oldHeight * newWidth / oldWidth / 2));\n+    } else {\n+      newWidth = (int) (2 * Math.round((float)oldWidth * newHeight / oldHeight / 2));\n+    }\n+    return new VideoInfo(newHeight, newWidth);\n+  }\n+\n+  /**\n+   * Calculate video offset from borders for ffmpeg pad operation\n+   * @param videoWidth\n+   *          Width of the video\n+   * @param videoHeight\n+   *          Height of the video\n+   * @param areaWidth\n+   *          Width of the area\n+   * @param areaHeight\n+   *          Width of the area\n+   * @return\n+   *          The position of the video within the padded area\n+   */\n+  private Offset padOffset(int videoWidth, int videoHeight, int areaWidth, int areaHeight) {\n+    int padX = (int) (2 * Math.round((float)(areaWidth - videoWidth) / 4));\n+    int padY = (int) (2 * Math.round((float)(areaHeight - videoHeight) / 4));\n+    return new Offset(padX, padY);\n+  }\n+\n+  /**\n+   * Converts milliseconds to seconds and to string\n+   * @param timestamp\n+   *          Time in milliseconds, e.g. 12567\n+   * @return\n+   *          Time in seconds, e.g. \"12.567\"\n+   */\n+  private String msToS(long timestamp)\n+  {\n+    double s = (double)timestamp / 1000;\n+    return String.format(Locale.US, \"%.3f\", s);   // Locale.US to get a . instead of a ,\n+  }\n+\n+  /**\n+   * Finds and returns the first track matching the given id in a list of tracks\n+   * @param trackId\n+   *          The id of the track we're looking for\n+   * @param tracks\n+   *          The collection of tracks we're looking in\n+   * @return\n+   *          The first track with the given trackId\n+   */\n+  private Track getTrackByID(String trackId, List<Track> tracks) {\n+    for (Track t : tracks) {\n+      if (t.getIdentifier().contains(trackId)) {\n+        logger.debug(\"Track-Id from smil found in Mediapackage ID: \" + t.getIdentifier());\n+        return t;\n+      }\n+    }\n+    throw new IllegalStateException(\"No track matching smil Track-id: \" + trackId);\n+  }\n+\n+  /**\n+   * Determine the largest dimension of the given list of tracks\n+   *\n+   * @param tracks\n+   *          the list of tracks\n+   * @param forceDivisible\n+   *          Whether to enforce the track's dimension to be divisible by two\n+   * @return the largest dimension from the list of track\n+   */\n+  private LayoutArea determineDimension(List<Track> tracks, boolean forceDivisible) {\n+    Tuple<Track, LayoutArea> trackDimension = getLargestTrack(tracks);\n+    if (trackDimension == null)\n+      return null;\n+\n+    if (forceDivisible && (trackDimension.getB().getHeight() % 2 != 0 || trackDimension.getB().getWidth() % 2 != 0)) {\n+      LayoutArea scaledDimension = new LayoutArea((trackDimension.getB().getWidth() / 2) * 2, (trackDimension\n+              .getB().getHeight() / 2) * 2);\n+      logger.info(\"Determined output dimension {} scaled down from {} for track {}\", scaledDimension,\n+              trackDimension.getB(), trackDimension.getA());\n+      return scaledDimension;\n+    } else {\n+      logger.info(\"Determined output dimension {} for track {}\", trackDimension.getB(), trackDimension.getA());\n+      return trackDimension.getB();\n+    }\n+  }\n+\n+  /**\n+   * Returns the track with the largest resolution from the list of tracks\n+   *\n+   * @param tracks\n+   *          the list of tracks\n+   * @return a {@link Tuple} with the largest track and it's dimension\n+   */\n+  private Tuple<Track, LayoutArea> getLargestTrack(List<Track> tracks) {\n+    Track track = null;\n+    LayoutArea dimension = null;\n+    for (Track t : tracks) {\n+      if (!t.hasVideo())\n+        continue;\n+\n+      VideoStream[] videoStreams = TrackSupport.byType(t.getStreams(), VideoStream.class);\n+      int frameWidth = videoStreams[0].getFrameWidth();\n+      int frameHeight = videoStreams[0].getFrameHeight();\n+      if (dimension == null || (frameWidth * frameHeight) > (dimension.getWidth() * dimension.getHeight())) {\n+        dimension = new LayoutArea(frameWidth, frameHeight);\n+        track = t;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 941}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg2MzA0NA==", "bodyText": "Please format this file.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498863044", "createdAt": "2020-10-02T14:38:45Z", "author": {"login": "pascalseeland"}, "path": "modules/videogrid-workflowoperation/src/test/resources/smil_ingest.unknown", "diffHunk": "@@ -0,0 +1 @@\n+<?xml version=\"1.1\" encoding=\"UTF-8\"?><smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"><head/><body><par dur=\"47187ms\"><seq><video begin=\"23046ms\" dur=\"14772ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/d79699b2-d683-4f0d-95ff-2dc4da3c9c40/medium_w_g7vtgxrzp24d_1596617796429.webm\" xml:id=\"d79699b2-d683-4f0d-95ff-2dc4da3c9c40\"/><video begin=\"24734ms\" dur=\"22453ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/76badf4a-3ab6-45f1-aba3-87deee80516e/medium_w_3ghiyg8tmlhk_1596617798147.webm\" xml:id=\"76badf4a-3ab6-45f1-aba3-87deee80516e\"/></seq><seq><video begin=\"5340ms\" dur=\"34ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/4394631c-71a9-41dc-a8b8-7c0d70d110ec/slide1.mp4\" xml:id=\"4394631c-71a9-41dc-a8b8-7c0d70d110ec\"/><audio begin=\"10330ms\" dur=\"34000ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/696bc7dc-caca-468c-9f8d-5f8fc57f0b83/0a62baa687baef56c59d74061eb85f04fa19a6eb_1596617773457_24877875.opus\" xml:id=\"696bc7dc-caca-468c-9f8d-5f8fc57f0b83\"/><video begin=\"32471ms\" dur=\"34ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/452324b2-87d4-4833-a3db-32e54fc2798c/slide2.mp4\" xml:id=\"452324b2-87d4-4833-a3db-32e54fc2798c\"/></seq></par></body></smil>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMzEzMTM0", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-501313134", "createdAt": "2020-10-02T17:19:28Z", "commit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxMzIzOTQw", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-501323940", "createdAt": "2020-10-02T17:36:24Z", "commit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNzozNjoyNFrOHb1_bA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQxNzozODozNlrOHb2DhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk1ODE4OA==", "bodyText": "I second @pascalseeland the webcam name doesn't not belong here. Please change it to another broader name", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498958188", "createdAt": "2020-10-02T17:36:24Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-service-impl/src/main/java/org/opencastproject/videogrid/impl/VideoGridServiceImpl.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+\n+package org.opencastproject.videogrid.impl;\n+\n+import org.opencastproject.job.api.AbstractJobProducer;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.security.api.OrganizationDirectoryService;\n+import org.opencastproject.security.api.SecurityService;\n+import org.opencastproject.security.api.UserDirectoryService;\n+import org.opencastproject.serviceregistry.api.ServiceRegistry;\n+import org.opencastproject.serviceregistry.api.ServiceRegistryException;\n+import org.opencastproject.util.ConfigurationException;\n+import org.opencastproject.util.IoSupport;\n+import org.opencastproject.util.LoadUtil;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.FilenameUtils;\n+import org.osgi.service.cm.ManagedService;\n+import org.osgi.service.component.ComponentContext;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.lang.reflect.Type;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Dictionary;\n+import java.util.List;\n+\n+/** Create video grids */\n+public class VideoGridServiceImpl extends AbstractJobProducer implements VideoGridService, ManagedService {\n+\n+  /** Configuration key for this operation's job load */\n+  private static final String JOB_LOAD_CONFIG = \"job.load.videogrid\";\n+\n+  /** The load introduced on the system by creating a job */\n+  private static final float JOB_LOAD_DEFAULT = 1.5f;\n+\n+  /** The load introduced on the system by creating a job */\n+  private float jobLoad = JOB_LOAD_DEFAULT;\n+\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridServiceImpl.class);\n+\n+  /** List of available operations on jobs */\n+  private static final String OPERATION = \"createPartialTracks\";\n+\n+  /** Services */\n+  private Workspace workspace;\n+  private ServiceRegistry serviceRegistry;\n+  private SecurityService securityService;\n+  private UserDirectoryService userDirectoryService;\n+  private OrganizationDirectoryService organizationDirectoryService;\n+\n+  /** For JSON serialization */\n+  private static final Gson gson = new Gson();\n+  private static final Type stringListOfListType = new TypeToken<List<List<String>>>() { }.getType();\n+\n+  /** Creates a new videogrid service instance. */\n+  public VideoGridServiceImpl() {\n+    super(JOB_TYPE);\n+  }\n+\n+  @Override\n+  public void activate(ComponentContext cc) {\n+    super.activate(cc);\n+    logger.debug(\"Activated videogrid service\");\n+  }\n+\n+  @Override\n+  public void updated(Dictionary properties) throws ConfigurationException {\n+    if (properties == null)\n+      return;\n+    logger.debug(\"Start updating videogrid service\");\n+\n+    jobLoad = LoadUtil.getConfiguredLoadValue(properties, JOB_LOAD_CONFIG, JOB_LOAD_DEFAULT, serviceRegistry);\n+    logger.debug(\"Set videogrid job load to {}\", jobLoad);\n+\n+    logger.debug(\"Finished updating videogrid service\");\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.job.api.AbstractJobProducer#process(org.opencastproject.job.api.Job)\n+   */\n+  @Override\n+  protected String process(Job job) throws Exception {\n+    logger.debug(\"Started processing job {}\", job.getId());\n+    if (!OPERATION.equals(job.getOperation())) {\n+      throw new ServiceRegistryException(String.format(\"This service can't handle operations of type '%s'\",\n+              job.getOperation()));\n+    }\n+\n+    // Parse arguments\n+    List<String> arguments = job.getArguments();\n+    List<List<String>> commands = gson.fromJson(arguments.get(0), stringListOfListType);\n+\n+    String outputDirPath = String.format(\"%s/videogrid/%d/\", workspace.rootDirectory(), job.getId());\n+    FileUtils.forceMkdir(new File(outputDirPath));\n+\n+    // Execute all commands\n+    List<String> outputPaths = new ArrayList<>();\n+    int index = 0;\n+    for (List<String> command : commands) {\n+      // Add output path to command\n+      String outputFile = outputDirPath + \"videogrid_part_\" + index + \".mp4\";\n+      outputPaths.add(outputFile);\n+      command.add(outputFile);\n+      index++;\n+\n+      logger.info(\"Running command: {}\", command);\n+\n+      // Run ffmpeg\n+      ProcessBuilder pb = new ProcessBuilder(command);\n+      pb.redirectErrorStream(true);\n+      Process ffmpegProcess = null;\n+      int exitCode = 1;\n+      BufferedReader errStream = null;\n+      try {\n+        ffmpegProcess = pb.start();\n+\n+        errStream = new BufferedReader(new InputStreamReader(ffmpegProcess.getInputStream()));\n+        String line = errStream.readLine();\n+        while (line != null) {\n+          logger.info(line);\n+          line = errStream.readLine();\n+        }\n+\n+        exitCode = ffmpegProcess.waitFor();\n+      } catch (IOException ex) {\n+        throw new VideoGridServiceException(\"Start ffmpeg process failed\", ex);\n+      } catch (InterruptedException ex) {\n+        throw new VideoGridServiceException(\"Waiting for encoder process exited was interrupted unexpectedly\", ex);\n+      } finally {\n+        IoSupport.closeQuietly(ffmpegProcess);\n+        IoSupport.closeQuietly(errStream);\n+        if (exitCode != 0) {\n+          try {\n+            logger.warn(\"FFMPEG process exited with errorcode: \" + exitCode);\n+            FileUtils.forceDelete(new File(outputDirPath));\n+          } catch (IOException e) {\n+            // it is ok, no output file was generated by ffmpeg\n+          }\n+        }\n+      }\n+\n+      if (exitCode != 0)\n+        throw new Exception(String.format(\"The encoder process exited abnormally with exit code %s \"\n+                + \"using command\\n%s\", exitCode, String.join(\" \", command)));\n+    }\n+\n+    // Put each generated video into workspace\n+    List<URI> uris = new ArrayList<>();\n+    for (String outputPath : outputPaths) {\n+\n+      FileInputStream outputFileInputStream = null;\n+      URI webcamFileUri;\n+      try {\n+        outputFileInputStream = new FileInputStream(outputPath);\n+        webcamFileUri = workspace.putInCollection(\"videogrid\",\n+                FilenameUtils.getName(outputPath), outputFileInputStream);\n+        uris.add(webcamFileUri);\n+        logger.info(\"Copied the created webcam video to the workspace {}\", webcamFileUri);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMjgzMA=="}, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk1ODc2MA==", "bodyText": "Needs to add that can be more than one flavor and mark what of them are required.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498958760", "createdAt": "2020-10-02T17:37:40Z", "author": {"login": "mliradelc"}, "path": "docs/guides/admin/docs/workflowoperationhandlers/video-grid-woh.md", "diffHunk": "@@ -0,0 +1,64 @@\n+# VideoGridWorkflowOperationHandler\n+\n+## Description\n+\n+The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously\n+playing videos into a single video file. For example, the webcam feeds during a video conference\n+can be combined by this WOH. The resulting video puts each input video on a grid that dynamically\n+resizes based on the number of inputs videos currently active. Which input video is active when\n+is defined by through a SMIL catalogue from e.g. a partial ingest.\n+\n+If the SMIL defines a section where there are no videos active, the background color will be shown\n+instead for the duration of the section. This also holds true for potentially empty beginning and end \n+sections, ensuring that a final single video is as long as the overall duration defined in the SMIL \n+(e.g. if the first input video becomes active at 30 seconds, the first generated output is a 30 second\n+long video of the background color). The background color is also shown whenever the input videos cannot\n+fully fill up the available space.\n+\n+This WOH relies on the inspect service for enriching generated, temporary video files with metadata.\n+Furthermore, it relies on the composers concat service to combine temporary video files into\n+a single output file.\n+\n+## Parameter Table\n+\n+|configuration keys | example                     | description                                                         |\n+|-------------------|-----------------------------|---------------------------------------------------------------------|\n+|source-flavors     | presenter/source            | Flavors containing all the video tracks to be combined.                              |\n+|source-smil-flavor | smil/source+partial         | Flavor containing the SMIL specifying when each video track is active. The example shows the flavor used by partial ingest.                               |\n+|concat-encoding-profile | concat-samecodec.work  | Encoding profile used for the final concatenation.\n+|opt-resolution     | 1280x720                    | (Optional) Resolution of the output. Example value is the default.\n+|opt-background-color| 0xFFFFFF                   | (Optional) The color used to fill space not occupied by input videos in the output. Example value is the default.\n+|target-flavor      | presenter/partial           | Flavor containing the output video tracks.                              |\n+|opt-target-tags    | archive                     | (Optional) Tag(s) to add to the output track. Default is `null`.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODgzNzgxNw=="}, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk1OTIzNg==", "bodyText": "Needs formating", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r498959236", "createdAt": "2020-10-02T17:38:36Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-workflowoperation/src/test/resources/smil_ingest.unknown", "diffHunk": "@@ -0,0 +1 @@\n+<?xml version=\"1.1\" encoding=\"UTF-8\"?><smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"><head/><body><par dur=\"47187ms\"><seq><video begin=\"23046ms\" dur=\"14772ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/d79699b2-d683-4f0d-95ff-2dc4da3c9c40/medium_w_g7vtgxrzp24d_1596617796429.webm\" xml:id=\"d79699b2-d683-4f0d-95ff-2dc4da3c9c40\"/><video begin=\"24734ms\" dur=\"22453ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/76badf4a-3ab6-45f1-aba3-87deee80516e/medium_w_3ghiyg8tmlhk_1596617798147.webm\" xml:id=\"76badf4a-3ab6-45f1-aba3-87deee80516e\"/></seq><seq><video begin=\"5340ms\" dur=\"34ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/4394631c-71a9-41dc-a8b8-7c0d70d110ec/slide1.mp4\" xml:id=\"4394631c-71a9-41dc-a8b8-7c0d70d110ec\"/><audio begin=\"10330ms\" dur=\"34000ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/696bc7dc-caca-468c-9f8d-5f8fc57f0b83/0a62baa687baef56c59d74061eb85f04fa19a6eb_1596617773457_24877875.opus\" xml:id=\"696bc7dc-caca-468c-9f8d-5f8fc57f0b83\"/><video begin=\"32471ms\" dur=\"34ms\" src=\"/files/mediapackage/b4f06863-bf53-4eb7-abb6-4433b9699081/452324b2-87d4-4833-a3db-32e54fc2798c/slide2.mp4\" xml:id=\"452324b2-87d4-4833-a3db-32e54fc2798c\"/></seq></par></body></smil>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg2MzA0NA=="}, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 1}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c90c6f34bea6c4bbe675db907a7b0210c2261008", "author": {"user": null}, "url": "https://github.com/opencast/opencast/commit/c90c6f34bea6c4bbe675db907a7b0210c2261008", "committedDate": "2020-10-05T09:28:38Z", "message": "Reformatting"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMDMzMjAw", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-502033200", "createdAt": "2020-10-05T13:04:21Z", "commit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzowNDoyMVrOHccFXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQxMzoyMDo0NFrOHccutQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU4MjMwMQ==", "bodyText": "@Arnei Can you put a comment like for example\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n            // Class Video decision list...", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r499582301", "createdAt": "2020-10-05T13:04:21Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1007 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVORS = \"source-flavors\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU4NjA4Ng==", "bodyText": "Change this, if not the users will be confused talking about a webcam WoH", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r499586086", "createdAt": "2020-10-05T13:10:37Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1000 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVOR = \"source-flavor\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyOTY1MQ=="}, "originalCommit": {"oid": "cc2b196019bf5971ca3902a66158390d4cfa9aca"}, "originalPosition": 377}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTU5Mjg4NQ==", "bodyText": "I understand @pascalseeland concerns, we found that some people have 21:9 monitors and if they record their screens you will have a very wide video, plus others.  H264 in their latest level could achieve more than 4096x2304 (that is the limit for h264) pixels while making a grid of videos. (This error can also occur for example when you try to scale Tears of steel in their original aspect ratio to 4K).\nIt will be nice to handle such edge cases, but FFmpeg will fail and tell you about this issue.", "url": "https://github.com/opencast/opencast/pull/1746#discussion_r499592885", "createdAt": "2020-10-05T13:20:44Z", "author": {"login": "mliradelc"}, "path": "modules/videogrid-workflowoperation/src/main/java/org/opencastproject/workflow/handler/videogrid/VideoGridWorkflowOperationHandler.java", "diffHunk": "@@ -0,0 +1,1007 @@\n+/**\n+ * Licensed to The Apereo Foundation under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ *\n+ * The Apereo Foundation licenses this file to you under the Educational\n+ * Community License, Version 2.0 (the \"License\"); you may not use this file\n+ * except in compliance with the License. You may obtain a copy of the License\n+ * at:\n+ *\n+ *   http://opensource.org/licenses/ecl2.txt\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ *\n+ */\n+package org.opencastproject.workflow.handler.videogrid;\n+\n+import static java.lang.String.format;\n+\n+import org.opencastproject.composer.api.ComposerService;\n+import org.opencastproject.composer.api.EncoderException;\n+import org.opencastproject.composer.api.EncodingProfile;\n+import org.opencastproject.composer.layout.Dimension;\n+import org.opencastproject.inspection.api.MediaInspectionException;\n+import org.opencastproject.inspection.api.MediaInspectionService;\n+import org.opencastproject.job.api.Job;\n+import org.opencastproject.job.api.JobContext;\n+import org.opencastproject.mediapackage.MediaPackage;\n+import org.opencastproject.mediapackage.MediaPackageElementFlavor;\n+import org.opencastproject.mediapackage.MediaPackageElementParser;\n+import org.opencastproject.mediapackage.MediaPackageException;\n+import org.opencastproject.mediapackage.Track;\n+import org.opencastproject.mediapackage.TrackSupport;\n+import org.opencastproject.mediapackage.VideoStream;\n+import org.opencastproject.mediapackage.selector.TrackSelector;\n+import org.opencastproject.mediapackage.track.TrackImpl;\n+import org.opencastproject.smil.api.util.SmilUtil;\n+import org.opencastproject.util.NotFoundException;\n+import org.opencastproject.util.data.Tuple;\n+import org.opencastproject.videogrid.api.VideoGridService;\n+import org.opencastproject.videogrid.api.VideoGridServiceException;\n+import org.opencastproject.workflow.api.AbstractWorkflowOperationHandler;\n+import org.opencastproject.workflow.api.WorkflowInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationException;\n+import org.opencastproject.workflow.api.WorkflowOperationInstance;\n+import org.opencastproject.workflow.api.WorkflowOperationResult;\n+import org.opencastproject.workspace.api.Workspace;\n+\n+import com.google.gson.Gson;\n+import com.google.gson.reflect.TypeToken;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.w3c.dom.Node;\n+import org.w3c.dom.NodeList;\n+import org.w3c.dom.smil.SMILDocument;\n+import org.w3c.dom.smil.SMILElement;\n+import org.w3c.dom.smil.SMILMediaElement;\n+import org.w3c.dom.smil.SMILParElement;\n+import org.xml.sax.SAXException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * The workflow definition for handling multiple webcam videos that have overlapping playtime\n+ * Checks which videos of those webcam videos are currently playing and dynamically scales them to fit in a single video\n+ *\n+ * Relies on a smil with videoBegin and duration times, as is created by ingest through addPartialTrack\n+ * Will pad sections where no video is playing with a background color. This includes beginning and end.\n+ *\n+ * Returns the final video to the target flavor\n+ */\n+public class VideoGridWorkflowOperationHandler extends AbstractWorkflowOperationHandler {\n+\n+  /** Workflow configuration keys */\n+  private static final String SOURCE_FLAVORS = \"source-flavors\";\n+  private static final String SOURCE_SMIL_FLAVOR = \"source-smil-flavor\";\n+  private static final String CONCAT_ENCODING_PROFILE = \"concat-encoding-profile\";\n+\n+  private static final String OPT_RESOLUTION = \"opt-resolution\";\n+  private static final String OPT_BACKGROUND_COLOR = \"opt-background-color\";\n+\n+  private static final String TARGET_FLAVOR = \"target-flavor\";\n+  private static final String OPT_TARGET_TAGS = \"opt-target-tags\";\n+\n+  /** The logging facility */\n+  private static final Logger logger = LoggerFactory.getLogger(VideoGridWorkflowOperationHandler.class);\n+\n+  /** Constants */\n+  private static final String NODE_TYPE_VIDEO = \"video\";\n+\n+  // TODO: Make ffmpeg commands more \"opencasty\"\n+  private static final String[] FFMPEG = {\"ffmpeg\", \"-y\", \"-v\", \"warning\", \"-nostats\", \"-max_error_rate\", \"1.0\"};\n+  private static final String FFMPEG_WF_CODEC = \"h264\"; //\"mpeg2video\";\n+  private static final int FFMPEG_WF_FRAMERATE = 24;\n+  private static final String[] FFMPEG_WF_ARGS = {\"-an\", \"-codec\", FFMPEG_WF_CODEC, \"-q:v\", \"2\", \"-g\", Integer.toString(FFMPEG_WF_FRAMERATE * 10), \"-pix_fmt\", \"yuv420p\", \"-r\", Integer.toString(FFMPEG_WF_FRAMERATE)};\n+\n+  /** Services */\n+  private Workspace workspace = null;\n+  private VideoGridService videoGridService = null;\n+  private MediaInspectionService inspectionService = null;\n+  private ComposerService composerService = null;\n+\n+  /** Service Callbacks **/\n+  public void setWorkspace(Workspace workspace) {\n+    this.workspace = workspace;\n+  }\n+  public void setVideoGridService(VideoGridService videoGridService) {\n+    this.videoGridService = videoGridService;\n+  }\n+  protected void setMediaInspectionService(MediaInspectionService inspectionService) {\n+    this.inspectionService = inspectionService;\n+  }\n+  public void setComposerService(ComposerService composerService) {\n+    this.composerService = composerService;\n+  }\n+\n+  /** Structs to store data and make code more readable **/\n+  class LayoutArea\n+  {\n+    private int x = 0;\n+    private int y = 0;\n+    private int width = 1920;\n+    private int height = 1080;\n+    private String name = \"webcam\";\n+    private String bgColor = \"0xFFFFFF\";\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+    public int getWidth() {\n+      return width;\n+    }\n+    public void setWidth(int width) {\n+      this.width = width;\n+    }\n+    public int getHeight() {\n+      return height;\n+    }\n+    public void setHeight(int height) {\n+      this.height = height;\n+    }\n+    public String getName() {\n+      return name;\n+    }\n+    public void setName(String name) {\n+      this.name = name;\n+    }\n+    public String getBgColor() {\n+      return bgColor;\n+    }\n+    public void setBgColor(String bgColor) {\n+      this.bgColor = bgColor;\n+    }\n+\n+    LayoutArea(int width, int height) {\n+      this.width = width;\n+      this.height = height;\n+    }\n+\n+    LayoutArea(String name, int x, int y, int width, int height, String bgColor) {\n+      this(width, height);\n+      this.name = name;\n+      this.x = x;\n+      this.y = y;\n+      this.bgColor = bgColor;\n+    }\n+  }\n+\n+  class VideoInfo\n+  {\n+    private int aspectRatioWidth = 16;\n+    private int aspectRatioHeight = 9;\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private long startTime = 0;\n+    private long duration = 0;\n+    private String filename = \"filename.mp4\";\n+\n+    public int getAspectRatioWidth() {\n+      return aspectRatioWidth;\n+    }\n+    public void setAspectRatioWidth(int aspectRatioWidth) {\n+      this.aspectRatioWidth = aspectRatioWidth;\n+    }\n+    public int getAspectRatioHeight() {\n+      return aspectRatioHeight;\n+    }\n+    public void setAspectRatioHeight(int aspectRatioHeight) {\n+      this.aspectRatioHeight = aspectRatioHeight;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public long getStartTime() {\n+      return startTime;\n+    }\n+    public void setStartTime(long startTime) {\n+      this.startTime = startTime;\n+    }\n+    public long getDuration() {\n+      return duration;\n+    }\n+    public void setDuration(long duration) {\n+      this.duration = duration;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+\n+    VideoInfo() {\n+\n+    }\n+\n+    VideoInfo(int height, int width) {\n+      aspectRatioWidth = width;\n+      aspectRatioHeight = height;\n+    }\n+\n+    VideoInfo(String filename, long timeStamp, int aspectRatioHeight, int aspectRatioWidth, long startTime)\n+    {\n+      this(aspectRatioHeight, aspectRatioWidth);\n+      this.filename = filename;\n+      this.timeStamp = timeStamp;\n+      this.startTime = startTime;\n+    }\n+  }\n+\n+  class Offset\n+  {\n+    private int x = 16;\n+    private int y = 9;\n+\n+    public int getX() {\n+      return x;\n+    }\n+    public void setX(int x) {\n+      this.x = x;\n+    }\n+    public int getY() {\n+      return y;\n+    }\n+    public void setY(int y) {\n+      this.y = y;\n+    }\n+\n+    Offset(int x, int y) {\n+      this.x = x;\n+      this.y = y;\n+    }\n+  }\n+\n+  class VideoEdlPart\n+  {\n+    private long timeStamp = 0;\n+    private long nextTimeStamp = 0;\n+    private List<VideoInfo> areas;\n+\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public long getNextTimeStamp() {\n+      return nextTimeStamp;\n+    }\n+    public void setNextTimeStamp(long nextTimeStamp) {\n+      this.nextTimeStamp = nextTimeStamp;\n+    }\n+    public List<VideoInfo> getAreas() {\n+      return areas;\n+    }\n+    public void setAreas(List<VideoInfo> areas) {\n+      this.areas = areas;\n+    }\n+\n+    VideoEdlPart()\n+    {\n+      areas = new ArrayList<VideoInfo>();\n+    }\n+  }\n+\n+  class StartStopEvent implements Comparable<StartStopEvent>\n+  {\n+    private boolean start;\n+    private long timeStamp;\n+    private String filename;\n+    private VideoInfo videoInfo;\n+\n+    public boolean isStart() {\n+      return start;\n+    }\n+    public void setStart(boolean start) {\n+      this.start = start;\n+    }\n+    public long getTimeStamp() {\n+      return timeStamp;\n+    }\n+    public void setTimeStamp(long timeStamp) {\n+      this.timeStamp = timeStamp;\n+    }\n+    public String getFilename() {\n+      return filename;\n+    }\n+    public void setFilename(String filename) {\n+      this.filename = filename;\n+    }\n+    public VideoInfo getVideoInfo() {\n+      return videoInfo;\n+    }\n+    public void setVideoInfo(VideoInfo videoInfo) {\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    StartStopEvent(boolean start, String filename, long timeStamp, VideoInfo videoInfo)\n+    {\n+      this.start = start;\n+      this.timeStamp = timeStamp;\n+      this.filename = filename;\n+      this.videoInfo = videoInfo;\n+    }\n+\n+    @Override\n+    public int compareTo(StartStopEvent o) {\n+      return Long.compare(this.timeStamp, o.timeStamp);\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * @see org.opencastproject.workflow.api.WorkflowOperationHandler#start(org.opencastproject.workflow.api.WorkflowInstance,\n+   *      JobContext)\n+   */\n+  @Override\n+  public WorkflowOperationResult start(final WorkflowInstance workflowInstance, JobContext context)\n+          throws WorkflowOperationException {\n+    logger.debug(\"Running multiple webcam workflow operation on workflow {}\", workflowInstance.getId());\n+\n+    final MediaPackage mediaPackage = (MediaPackage) workflowInstance.getMediaPackage().clone();\n+\n+    // Read config options\n+    WorkflowOperationInstance operation = workflowInstance.getCurrentOperation();\n+    final MediaPackageElementFlavor smilFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, SOURCE_SMIL_FLAVOR));\n+    final MediaPackageElementFlavor targetPresenterFlavor = MediaPackageElementFlavor.parseFlavor(\n+            getConfig(operation, TARGET_FLAVOR));\n+    String concatEncodingProfile = StringUtils.trimToNull(operation.getConfiguration(CONCAT_ENCODING_PROFILE));\n+\n+    // Get source flavors\n+    String sourceFlavorNames = operation.getConfiguration(SOURCE_FLAVORS);\n+    final List<MediaPackageElementFlavor> sourceFlavors = new ArrayList<>();\n+    for (String flavorName : asList(sourceFlavorNames)) {\n+      sourceFlavors.add(MediaPackageElementFlavor.parseFlavor(flavorName));\n+    }\n+\n+    // Get tracks from flavor\n+    final List<Track> sourceTracks = new ArrayList<>();\n+    for (MediaPackageElementFlavor sourceFlavor: sourceFlavors) {\n+      TrackSelector trackSelector = new TrackSelector();\n+      trackSelector.addFlavor(sourceFlavor);\n+      sourceTracks.addAll(trackSelector.select(mediaPackage, false));\n+    }\n+\n+    // No tracks? Skip\n+    if (sourceTracks.isEmpty()) {\n+      logger.warn(\"No tracks in source flavors, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // No concat encoding profile? Fail\n+    if (concatEncodingProfile == null)\n+      throw new WorkflowOperationException(\"Encoding profile must be set!\");\n+    EncodingProfile profile = composerService.getProfile(concatEncodingProfile);\n+    if (profile == null)\n+      throw new WorkflowOperationException(\"Encoding profile '\" + concatEncodingProfile + \"' was not found\");\n+\n+\n+    // Define a general Layout for the final video\n+    ImmutablePair<Integer, Integer> resolution;\n+    try {\n+      resolution = getResolution(getConfig(workflowInstance, OPT_RESOLUTION, \"1280x720\"));\n+    } catch (IllegalArgumentException e) {\n+      logger.warn(\"Given resolution was not well formatted!\");\n+      throw new WorkflowOperationException(e);\n+    }\n+    logger.info(\"The resolution of the final video: {}/{}\", resolution.getLeft(), resolution.getRight());\n+\n+    // Define a bg color for the final video\n+    String bgColor = getConfig(workflowInstance, OPT_BACKGROUND_COLOR, \"0xFFFFFF\");\n+    final Pattern pattern = Pattern.compile(\"0x[A-Fa-f0-9]{6}\");\n+    if (!pattern.matcher(bgColor).matches()) {\n+      logger.warn(\"Given color {} was not well formatted!\", bgColor);\n+      throw new WorkflowOperationException(\"Given color was not well formatted!\");\n+    }\n+    logger.info(\"The background color of the final video: {}\", bgColor);\n+\n+    // Target tags\n+    String targetTagsOption = StringUtils.trimToNull(operation.getConfiguration(OPT_TARGET_TAGS));\n+    List<String> targetTags = asList(targetTagsOption);\n+\n+    // Define general layout for the final video\n+    LayoutArea layoutArea = new LayoutArea(\"webcam\", 0, 0, resolution.getLeft(), resolution.getRight(),\n+                                            bgColor);\n+\n+    // Get SMIL catalog\n+    final SMILDocument smilDocument;\n+    try {\n+      smilDocument = SmilUtil.getSmilDocumentFromMediaPackage(mediaPackage, smilFlavor, workspace);\n+    } catch (SAXException e) {\n+      throw new WorkflowOperationException(\"SMIL is not well formatted\", e);\n+    } catch (IOException | NotFoundException e) {\n+      throw new WorkflowOperationException(\"SMIL could not be found\", e);\n+    }\n+\n+    final SMILParElement parallel = (SMILParElement) smilDocument.getBody().getChildNodes().item(0);\n+    final NodeList sequences = parallel.getTimeChildren();\n+    final float trackDurationInSeconds = parallel.getDur();\n+    final long trackDurationInMs = Math.round(trackDurationInSeconds * 1000f);\n+\n+    // Get Start- and endtime of the final video from SMIL\n+    long finalStartTime = 0;\n+    long finalEndTime = trackDurationInMs;\n+\n+    // Create a list of start and stop events, i.e. every time a new video begins or an old one ends\n+    // Create list from SMIL from partial ingests\n+    List<StartStopEvent> events = new ArrayList<>();\n+\n+    for (int i = 0; i < sequences.getLength(); i++) {\n+      final SMILElement item = (SMILElement) sequences.item(i);\n+      NodeList children = item.getChildNodes();\n+\n+      for (int j = 0; j < children.getLength(); j++) {\n+        Node node = children.item(j);\n+        SMILMediaElement e = (SMILMediaElement) node;\n+\n+        // Avoid any element that is not a video or of the source type\n+        if (NODE_TYPE_VIDEO.equals(e.getNodeName())) {\n+          Track track;\n+          try {\n+            track = getTrackByID(e.getId(), sourceTracks);\n+          } catch (IllegalStateException ex) {\n+            logger.info(\"No track corresponding to SMIL ID found, skipping SMIL ID {}\", e.getId());\n+            continue;\n+          }\n+          double beginInSeconds = e.getBegin().item(0).getResolvedOffset();\n+          long beginInMs = Math.round(beginInSeconds * 1000d);\n+          double durationInSeconds = e.getDur();\n+          long durationInMs = Math.round(durationInSeconds * 1000d);\n+\n+          // Gather video information\n+          VideoInfo videoInfo = new VideoInfo();\n+          // Aspect Ratio, e.g. 16:9\n+          List<Track> tmpList = new ArrayList<Track>();\n+          tmpList.add(track);\n+          LayoutArea trackDimension = determineDimension(tmpList, true);\n+          if (trackDimension == null) {\n+            throw new WorkflowOperationException(\"One of the source video tracks did not contain a valid video stream or dimension\");\n+          }\n+          videoInfo.aspectRatioHeight = trackDimension.getHeight();\n+          videoInfo.aspectRatioWidth = trackDimension.getWidth();\n+          // \"StartTime\" is calculated later. It describes how far into the video the next section starts.\n+          // (E.g. If webcam2 is started 10 seconds after webcam1, the startTime for webcam1 in the next section is 10)\n+          videoInfo.startTime = 0;\n+\n+          logger.info(\"Video information: Width: {}, Height {}, StartTime: {}\", videoInfo.aspectRatioWidth,\n+                  videoInfo.aspectRatioHeight, videoInfo.startTime);\n+\n+          events.add(new StartStopEvent(true, getTrackPath(track), beginInMs, videoInfo));\n+          events.add(new StartStopEvent(false, getTrackPath(track), beginInMs + durationInMs, videoInfo));\n+\n+        }\n+      }\n+    }\n+\n+    // No events? Skip\n+    if (events.isEmpty()) {\n+      logger.warn(\"Could not generate sections from given SMIL catalogue for tracks in given flavor, skipping ...\");\n+      return createResult(mediaPackage, WorkflowOperationResult.Action.SKIP);\n+    }\n+\n+    // Sort by timestamps ascending\n+    Collections.sort(events);\n+\n+    // Create an edit decision list\n+    List<VideoEdlPart> videoEdl = new ArrayList<VideoEdlPart>();\n+    HashMap<String, StartStopEvent> activeVideos = new HashMap<>();   // Currently running videos\n+\n+    // Define starting point\n+    VideoEdlPart start = new VideoEdlPart();\n+    start.timeStamp = finalStartTime;\n+    videoEdl.add(start);\n+\n+    // Define mid-points\n+    for (StartStopEvent event : events) {\n+      if (event.start) {\n+        logger.info(\"Add start event at {}\", event.timeStamp);\n+        activeVideos.put(event.filename, event);\n+      } else {\n+        logger.info(\"Add stop event at {}\", event);\n+        activeVideos.remove(event.filename);\n+      }\n+      videoEdl.add(createVideoEdl(event, activeVideos));\n+    }\n+\n+    // Define ending point\n+    VideoEdlPart endVideo = new VideoEdlPart();\n+    endVideo.timeStamp = finalEndTime;\n+    endVideo.nextTimeStamp = finalEndTime;\n+    videoEdl.add(endVideo);\n+\n+    // Pre processing EDL\n+    for (int i = 0; i < videoEdl.size() - 1; i++) {\n+      // For calculating cut lengths\n+      videoEdl.get(i).nextTimeStamp = videoEdl.get(i + 1).timeStamp;\n+    }\n+\n+    // Create ffmpeg command for each section\n+    List<List<String>> commands = new ArrayList<>();\n+    for (VideoEdlPart edl : videoEdl) {\n+      // A too small duration will result in ffmpeg producing a faulty video, so avoid any section smaller than 50ms\n+      if (edl.nextTimeStamp - edl.timeStamp < 50) {\n+        logger.info(\"Skipping {}-length edl entry\", edl.nextTimeStamp - edl.timeStamp);\n+        continue;\n+      }\n+      // Create command for section\n+      commands.add(compositeSection(layoutArea, edl));\n+    }\n+\n+    // Create video tracks for each section\n+    Job job;\n+    try {\n+      job = videoGridService.createPartialTracks(commands);\n+    } catch (VideoGridServiceException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    if (!waitForStatus(job).isSuccess()) {\n+      throw new WorkflowOperationException(String.format(\"VideoGrid job for media package '%s' failed\", mediaPackage));\n+    }\n+\n+    Gson gson = new Gson();\n+    List<URI> uris = gson.fromJson(job.getPayload(), new TypeToken<List<URI>>() { }.getType());\n+\n+    // Parse uris into tracks and enrich them with metadata\n+    List<Track> tracks = new ArrayList<>();\n+    for (URI uri : uris) {\n+      TrackImpl track = new TrackImpl();\n+      track.setFlavor(targetPresenterFlavor);\n+      track.setURI(uri);\n+\n+      Job inspection = null;\n+      try {\n+        inspection = inspectionService.enrich(track, true);\n+      } catch (MediaInspectionException | MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Inspection service could not enrich track\", e);\n+      }\n+      if (!waitForStatus(inspection).isSuccess()) {\n+        throw new WorkflowOperationException(String.format(\"Failed to add metadata to track.\"));\n+      }\n+\n+      try {\n+        tracks.add((TrackImpl) MediaPackageElementParser.getFromXml(inspection.getPayload()));\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by inspection service\", e);\n+      }\n+    }\n+\n+    // Concatenate sections\n+    Job concatJob = null;\n+    try {\n+      concatJob = composerService.concat(composerService.getProfile(concatEncodingProfile).getIdentifier(),\n+              new Dimension(layoutArea.width,layoutArea.height) , true, tracks.toArray(new Track[tracks.size()]));\n+    } catch (EncoderException | MediaPackageException e) {\n+      throw new WorkflowOperationException(\"The concat job failed\", e);\n+    }\n+    if (!waitForStatus(concatJob).isSuccess()) {\n+      throw new WorkflowOperationException(\"The concat job did not complete successfully.\");\n+    }\n+\n+    // Add to mediapackage\n+    if (concatJob.getPayload().length() > 0) {\n+      Track concatTrack;\n+      try {\n+        concatTrack = (Track) MediaPackageElementParser.getFromXml(concatJob.getPayload());\n+      } catch (MediaPackageException e) {\n+        throw new WorkflowOperationException(\"Could not parse track returned by concat service\", e);\n+      }\n+      concatTrack.setFlavor(targetPresenterFlavor);\n+      concatTrack.setURI(concatTrack.getURI());\n+      for (String tag : targetTags) {\n+        concatTrack.addTag(tag);\n+      }\n+\n+      mediaPackage.add(concatTrack);\n+    } else {\n+      throw new WorkflowOperationException(\"Concat operation unsuccessful, no payload returned.\");\n+    }\n+\n+    try {\n+      workspace.cleanup(mediaPackage.getIdentifier());\n+    } catch (IOException e) {\n+      throw new WorkflowOperationException(e);\n+    }\n+\n+    final WorkflowOperationResult result = createResult(mediaPackage, WorkflowOperationResult.Action.CONTINUE);\n+    logger.debug(\"Video Grid operation completed\");\n+    return result;\n+  }\n+\n+  /**\n+   * Create a ffmpeg command that generate a videos for the given cutting marks\n+   * @param layoutArea\n+   *          General layout information for the video\n+   *          (Originally it was possible to have multiple layout areas)\n+   * @param videoEdl\n+   *          The edit decision list for the current cut\n+   * @return A command line ready ffmpeg command\n+   */\n+  private List<String> compositeSection(LayoutArea layoutArea, VideoEdlPart videoEdl)\n+  {\n+    // Duration for this cut\n+    long duration = videoEdl.nextTimeStamp - videoEdl.timeStamp;\n+    logger.info(\"Cut timeStamp {}, duration {}\", videoEdl.timeStamp, duration);\n+\n+    // Declare ffmpeg command\n+    String ffmpegFilter = String.format(\"color=c=%s:s=%dx%d:r=24\", layoutArea.bgColor, layoutArea.width, layoutArea.height);\n+\n+    List<VideoInfo> videos = videoEdl.areas;\n+    int videoCount = videoEdl.areas.size();\n+\n+    logger.info(\"Laying out {} videos in {}\", videoCount, layoutArea.name);\n+\n+\n+    if (videoCount > 0) {\n+      int tilesH = 0;\n+      int tilesV = 0;\n+      int tileWidth = 0;\n+      int tileHeight = 0;\n+      int totalArea = 0;\n+\n+      // Do and exhaustive search to maximize video areas\n+      for (int tmpTilesV = 1; tmpTilesV < videoCount + 1; tmpTilesV++) {\n+        int tmpTilesH = (int) Math.ceil((videoCount / (float)tmpTilesV));\n+        int tmpTileWidth = (int) (2 * Math.floor((float)layoutArea.width / tmpTilesH / 2));\n+        int tmpTileHeight = (int) (2 * Math.floor((float)layoutArea.height / tmpTilesV / 2));\n+\n+        if (tmpTileWidth <= 0 || tmpTileHeight <= 0) {\n+          continue;\n+        }\n+\n+        int tmpTotalArea = 0;\n+        for (VideoInfo video: videos) {\n+          int videoWidth = video.aspectRatioWidth;\n+          int videoHeight = video.aspectRatioHeight;\n+          VideoInfo videoScaled = aspectScale(videoWidth, videoHeight, tmpTileWidth, tmpTileHeight);\n+          tmpTotalArea += videoScaled.aspectRatioWidth * videoScaled.aspectRatioHeight;\n+        }\n+\n+        if (tmpTotalArea > totalArea) {\n+          tilesH = tmpTilesH;\n+          tilesV = tmpTilesV;\n+          tileWidth = tmpTileWidth;\n+          tileHeight = tmpTileHeight;\n+          totalArea = tmpTotalArea;\n+        }\n+      }\n+\n+\n+      int tileX = 0;\n+      int tileY = 0;\n+\n+      logger.info(\"Tiling in a {}x{} grid\", tilesH, tilesV);\n+\n+      ffmpegFilter += String.format(\"[%s_in];\", layoutArea.name);\n+\n+      for (VideoInfo video : videos) {\n+        //Get videoinfo\n+        logger.info(\"tile location ({}, {})\", tileX, tileY);\n+        int videoWidth = video.aspectRatioWidth;\n+        int videoHeight = video.aspectRatioHeight;\n+        logger.info(\"original aspect: {}x{}\", videoWidth, videoHeight);\n+\n+        VideoInfo videoScaled = aspectScale(videoWidth, videoHeight, tileWidth, tileHeight);\n+        logger.info(\"scaled size: {}x{}\", videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight);\n+\n+        Offset offset = padOffset(videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight, tileWidth, tileHeight);\n+        logger.info(\"offset: left: {}, top: {}\", offset.x, offset.y);\n+\n+        // TODO: Get a proper value instead of the badly hardcoded 0\n+        // Offset in case the pts is greater than 0\n+        long seekOffset = 0;\n+        logger.info(\"seek offset: {}\", seekOffset);\n+\n+        // Webcam videos are variable, low fps; it might be that there's\n+        // no frame until some time after the seek point. Start decoding\n+        // 10s before the desired point to avoid this issue.\n+        long seek = video.startTime - 10000;\n+        if (seek < 0) {\n+          seek = 0;\n+        }\n+\n+        String padName = String.format(\"%s_x%d_y%d\", layoutArea.name, tileX, tileY);\n+\n+        // Apply the video start time offset to seek to the correct point.\n+        // Only actually apply the offset if we're already seeking so we\n+        // don't start seeking in a file where we've overridden the seek\n+        // behaviour.\n+        if (seek > 0) {\n+          seek = seek + seekOffset;\n+        }\n+        ffmpegFilter += String.format(\"movie=%s:sp=%s\", video.filename, msToS(seek));\n+        // Subtract away the offset from the timestamps, so the trimming\n+        // in the fps filter is accurate\n+        ffmpegFilter += String.format(\",setpts=PTS-%s/TB\", msToS(seekOffset));\n+        // fps filter fills in frames up to the desired start point, and\n+        // cuts the video there\n+        ffmpegFilter += String.format(\",fps=%d:start_time=%s\", FFMPEG_WF_FRAMERATE, msToS(video.startTime));\n+        // Reset the timestamps to start at 0 so that everything is synced\n+        // for the video tiling, and scale to the desired size.\n+        ffmpegFilter += String.format(\",setpts=PTS-STARTPTS,scale=%d:%d,setsar=1\", videoScaled.aspectRatioWidth, videoScaled.aspectRatioHeight);\n+        // And finally, pad the video to the desired aspect ratio\n+        ffmpegFilter += String.format(\",pad=w=%d:h=%d:x=%d:y=%d:color=%s\", tileWidth, tileHeight, offset.x, offset.y, layoutArea.bgColor);\n+        ffmpegFilter += String.format(\"[%s_movie];\", padName);\n+\n+        // In case the video was shorter than expected, we might have to pad\n+        // it to length. do that by concatenating a video generated by the\n+        // color filter. (It would be nice to repeat the last frame instead,\n+        // but there's no easy way to do that.)\n+        ffmpegFilter += String.format(\"color=c=%s:s=%dx%d:r=%d\", layoutArea.bgColor, tileWidth, tileHeight, FFMPEG_WF_FRAMERATE);\n+        ffmpegFilter += String.format(\"[%s_pad];\", padName);\n+        ffmpegFilter += String.format(\"[%s_movie][%s_pad]concat=n=2:v=1:a=0[%s];\", padName, padName, padName);\n+\n+        tileX += 1;\n+        if (tileX >= tilesH) {\n+          tileX = 0;\n+          tileY += 1;\n+        }\n+      }\n+\n+      // Create the video rows\n+      int remaining = videoCount;\n+      for (tileY = 0; tileY < tilesV; tileY++) {\n+        int thisTilesH = Math.min(tilesH, remaining);\n+        remaining -= thisTilesH;\n+\n+        for (tileX = 0; tileX < thisTilesH; tileX++) {\n+          ffmpegFilter += String.format(\"[%s_x%d_y%d]\", layoutArea.name, tileX, tileY);\n+        }\n+        if (thisTilesH > 1) {\n+          ffmpegFilter += String.format(\"hstack=inputs=%d,\", thisTilesH);\n+        }\n+        ffmpegFilter += String.format(\"pad=w=%d:h=%d:color=%s\", layoutArea.width, tileHeight, layoutArea.bgColor);\n+        ffmpegFilter += String.format(\"[%s_y%d];\", layoutArea.name, tileY);\n+      }\n+\n+      // Stack the video rows\n+      for (tileY = 0; tileY < tilesV; tileY++) {\n+        ffmpegFilter += String.format(\"[%s_y%d]\", layoutArea.name, tileY);\n+      }\n+      if (tilesV > 1) {\n+        ffmpegFilter += String.format(\"vstack=inputs=%d,\", tilesV);\n+      }\n+      ffmpegFilter += String.format(\"pad=w=%d:h=%d:color=%s\", layoutArea.width, layoutArea.height, layoutArea.bgColor);\n+      ffmpegFilter += String.format(\"[%s];\", layoutArea.name);\n+      ffmpegFilter += String.format(\"[%s_in][%s]overlay=x=%d:y=%d\", layoutArea.name, layoutArea.name, layoutArea.x, layoutArea.y);\n+\n+      // Here would be the end of the layoutArea Loop\n+    }\n+\n+    ffmpegFilter += String.format(\",trim=end=%s\", msToS(duration));\n+\n+    List<String> ffmpegCmd = new ArrayList<String>(Arrays.asList(FFMPEG));\n+    ffmpegCmd.add(\"-filter_complex\");\n+    ffmpegCmd.add(ffmpegFilter);\n+    ffmpegCmd.addAll(Arrays.asList(FFMPEG_WF_ARGS));\n+\n+    logger.info(\"Final command:\");\n+    logger.info(String.join(\" \", ffmpegCmd));\n+\n+    return ffmpegCmd;\n+  }\n+\n+  /**\n+   * Scale the video resolution to fit the new resolution while maintaining aspect ratio\n+   * @param oldWidth\n+   *          Width of the video\n+   * @param oldHeight\n+   *          Height of the video\n+   * @param newWidth\n+   *          Intended new width of the video\n+   * @param newHeight\n+   *          Intended new height of the video\n+   * @return\n+   *          Actual new width and height of the video, guaranteed to be the same or smaller as the intended values\n+   */\n+  private VideoInfo aspectScale(int oldWidth, int oldHeight, int newWidth, int newHeight) {\n+    if ((float)oldWidth / oldHeight > (float)newWidth / newHeight) {\n+      newHeight = (int) (2 * Math.round((float)oldHeight * newWidth / oldWidth / 2));\n+    } else {\n+      newWidth = (int) (2 * Math.round((float)oldWidth * newHeight / oldHeight / 2));\n+    }\n+    return new VideoInfo(newHeight, newWidth);\n+  }\n+\n+  /**\n+   * Calculate video offset from borders for ffmpeg pad operation\n+   * @param videoWidth\n+   *          Width of the video\n+   * @param videoHeight\n+   *          Height of the video\n+   * @param areaWidth\n+   *          Width of the area\n+   * @param areaHeight\n+   *          Width of the area\n+   * @return\n+   *          The position of the video within the padded area\n+   */\n+  private Offset padOffset(int videoWidth, int videoHeight, int areaWidth, int areaHeight) {\n+    int padX = (int) (2 * Math.round((float)(areaWidth - videoWidth) / 4));\n+    int padY = (int) (2 * Math.round((float)(areaHeight - videoHeight) / 4));\n+    return new Offset(padX, padY);\n+  }\n+\n+  /**\n+   * Converts milliseconds to seconds and to string\n+   * @param timestamp\n+   *          Time in milliseconds, e.g. 12567\n+   * @return\n+   *          Time in seconds, e.g. \"12.567\"\n+   */\n+  private String msToS(long timestamp)\n+  {\n+    double s = (double)timestamp / 1000;\n+    return String.format(Locale.US, \"%.3f\", s);   // Locale.US to get a . instead of a ,\n+  }\n+\n+  /**\n+   * Finds and returns the first track matching the given id in a list of tracks\n+   * @param trackId\n+   *          The id of the track we're looking for\n+   * @param tracks\n+   *          The collection of tracks we're looking in\n+   * @return\n+   *          The first track with the given trackId\n+   */\n+  private Track getTrackByID(String trackId, List<Track> tracks) {\n+    for (Track t : tracks) {\n+      if (t.getIdentifier().contains(trackId)) {\n+        logger.debug(\"Track-Id from smil found in Mediapackage ID: \" + t.getIdentifier());\n+        return t;\n+      }\n+    }\n+    throw new IllegalStateException(\"No track matching smil Track-id: \" + trackId);\n+  }\n+\n+  /**\n+   * Determine the largest dimension of the given list of tracks\n+   *\n+   * @param tracks\n+   *          the list of tracks\n+   * @param forceDivisible\n+   *          Whether to enforce the track's dimension to be divisible by two\n+   * @return the largest dimension from the list of track\n+   */\n+  private LayoutArea determineDimension(List<Track> tracks, boolean forceDivisible) {\n+    Tuple<Track, LayoutArea> trackDimension = getLargestTrack(tracks);\n+    if (trackDimension == null)\n+      return null;\n+\n+    if (forceDivisible && (trackDimension.getB().getHeight() % 2 != 0 || trackDimension.getB().getWidth() % 2 != 0)) {\n+      LayoutArea scaledDimension = new LayoutArea((trackDimension.getB().getWidth() / 2) * 2, (trackDimension\n+              .getB().getHeight() / 2) * 2);\n+      logger.info(\"Determined output dimension {} scaled down from {} for track {}\", scaledDimension,\n+              trackDimension.getB(), trackDimension.getA());\n+      return scaledDimension;\n+    } else {\n+      logger.info(\"Determined output dimension {} for track {}\", trackDimension.getB(), trackDimension.getA());\n+      return trackDimension.getB();\n+    }\n+  }\n+\n+  /**\n+   * Returns the track with the largest resolution from the list of tracks\n+   *\n+   * @param tracks\n+   *          the list of tracks\n+   * @return a {@link Tuple} with the largest track and it's dimension\n+   */\n+  private Tuple<Track, LayoutArea> getLargestTrack(List<Track> tracks) {\n+    Track track = null;\n+    LayoutArea dimension = null;\n+    for (Track t : tracks) {\n+      if (!t.hasVideo())\n+        continue;\n+\n+      VideoStream[] videoStreams = TrackSupport.byType(t.getStreams(), VideoStream.class);\n+      int frameWidth = videoStreams[0].getFrameWidth();\n+      int frameHeight = videoStreams[0].getFrameHeight();\n+      if (dimension == null || (frameWidth * frameHeight) > (dimension.getWidth() * dimension.getHeight())) {\n+        dimension = new LayoutArea(frameWidth, frameHeight);\n+        track = t;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg2MTAxOA=="}, "originalCommit": {"oid": "a95ac94d6c02bbf201005fdd15ad87e1c5ad4ab7"}, "originalPosition": 941}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAyMTA3MzYw", "url": "https://github.com/opencast/opencast/pull/1746#pullrequestreview-502107360", "createdAt": "2020-10-05T14:21:50Z", "commit": {"oid": "c90c6f34bea6c4bbe675db907a7b0210c2261008"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1796, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}