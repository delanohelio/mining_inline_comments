{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3MzUxMjM2", "number": 995, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowMDozMVrOD_QX8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzozMDoxMlrOD_jdsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjU1MTU0OnYy", "diffSide": "RIGHT", "path": "hugegraph-api/src/main/java/com/baidu/hugegraph/api/traversers/RingsAPI.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowMDozMVrOGZ0LDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowMDozMVrOGZ0LDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMjM4MA==", "bodyText": "reset these changes", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r429722380", "createdAt": "2020-05-25T04:00:31Z", "author": {"login": "javeme"}, "path": "hugegraph-api/src/main/java/com/baidu/hugegraph/api/traversers/RingsAPI.java", "diffHunk": "@@ -86,6 +89,10 @@ public String get(@Context GraphManager manager,\n         HugeTraverser.PathSet paths = traverser.rings(source, dir, edgeLabel,\n                                                       depth, sourceInRing,\n                                                       degree, capacity, limit);\n+        if (countOnly) {\n+            return manager.serializer(g).writeMap(ImmutableMap.of(\n+                                                  \"count\", paths.size()));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4408568fbad7c62796138d19c2ac39431b5a4109"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjU1Mjk2OnYy", "diffSide": "RIGHT", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowMjowOFrOGZ0L3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowMjowOFrOGZ0L3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMjU4OA==", "bodyText": "add properties for filtering sortkey:\n       private Map<String, Object> properties;", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r429722588", "createdAt": "2020-05-25T04:02:08Z", "author": {"login": "javeme"}, "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.traversal.algorithm;\n+\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.tinkerpop.gremlin.structure.Edge;\n+\n+import com.baidu.hugegraph.HugeGraph;\n+import com.baidu.hugegraph.backend.id.Id;\n+import com.baidu.hugegraph.backend.query.Aggregate;\n+import com.baidu.hugegraph.backend.query.Query;\n+import com.baidu.hugegraph.backend.query.QueryResults;\n+import com.baidu.hugegraph.backend.tx.GraphTransaction;\n+import com.baidu.hugegraph.iterator.FilterIterator;\n+import com.baidu.hugegraph.iterator.FlatMapperIterator;\n+import com.baidu.hugegraph.structure.HugeEdge;\n+import com.baidu.hugegraph.type.define.Directions;\n+import com.baidu.hugegraph.util.E;\n+\n+public class CountTraverser extends HugeTraverser {\n+\n+    private boolean containsTraversed = false;\n+    private long dedup = 1000000L;\n+    private final Set<Id> dedupSet = new HashSet<>();\n+    private final long[] count = {0L};\n+\n+    public CountTraverser(HugeGraph graph) {\n+        super(graph);\n+    }\n+\n+    public long count(Id source, List<Step> steps,\n+                      boolean containsTraversed, long dedup) {\n+        E.checkArgumentNotNull(source, \"The source can't be null\");\n+        E.checkArgument(steps != null && !steps.isEmpty(),\n+                        \"The steps can't be empty\");\n+        checkDedup(dedup);\n+\n+        this.containsTraversed = containsTraversed;\n+        this.dedup = dedup;\n+        if (this.containsTraversed) {\n+            count[0]++;\n+        }\n+\n+        int stepNum = steps.size();\n+        Step firstStep = steps.get(0);\n+        if (stepNum == 1) {\n+            // Just one step, query count and return\n+            count[0] += this.edgesCount(source, firstStep.direction,\n+                                        firstStep.labels);\n+            return count[0];\n+        }\n+\n+        // Multiple steps, construct first step to iterator\n+        Iterator<Edge> edges = this.edgesOfVertex(source, firstStep);\n+        for (int i = 1; i < stepNum; i++) {\n+            Step currentStep = steps.get(i);\n+            if (i != stepNum - 1) {\n+                edges = new FlatMapperIterator<>(edges, (edge) -> {\n+                    Id target = ((HugeEdge) edge).id().otherVertexId();\n+                    return this.edgesOfVertex(target, currentStep);\n+                });\n+            } else {\n+                // The last step, just query count\n+                while (edges.hasNext()) {\n+                    HugeEdge edge = (HugeEdge) edges.next();\n+                    Id target = edge.id().otherVertexId();\n+                    if (this.dedup(target)) {\n+                        continue;\n+                    }\n+                    // Count last layer vertices(without dedup)\n+                    this.count[0] += this.edgesCount(target,\n+                                                     currentStep.direction,\n+                                                     currentStep.labels);\n+                }\n+            }\n+        }\n+\n+        return this.count[0];\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Step step) {\n+        if (this.dedup(source)) {\n+            return QueryResults.emptyIterator();\n+        }\n+        Iterator<Edge> flatten = this.edgesOfVertex(source, step.direction,\n+                                                    step.labels, step.degree,\n+                                                    step.skipDegree);\n+        return new FilterIterator<>(flatten, e -> {\n+            if (this.containsTraversed) {\n+                // Count intermediate vertices\n+                this.count[0]++;\n+            }\n+            return true;\n+        });\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Directions dir,\n+                                         Map<Id, String> labels,\n+                                         long degree, long skipDegree) {\n+        checkSkipDegree(skipDegree, degree, NO_LIMIT);\n+        long queryLimit = skipDegree > 0 ? skipDegree : degree;\n+        Iterator<Edge> edges = this.edgesOfVertex(source, dir, labels,\n+                                                  queryLimit);\n+        return ShortestPathTraverser.skipSuperNodeIfNeeded(edges, degree,\n+                                                           skipDegree);\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Directions dir,\n+                                         Map<Id, String> labels, long limit) {\n+        Id[] els = labels.keySet().toArray(new Id[labels.size()]);\n+        Query query = GraphTransaction.constructEdgesQuery(source, dir, els);\n+        query.capacity(Query.NO_CAPACITY);\n+        if (limit != NO_LIMIT) {\n+            query.limit(limit);\n+        }\n+        return this.graph().edges(query);\n+    }\n+\n+    private long edgesCount(Id source, Directions dir, Map<Id, String> labels) {\n+        Id[] els = labels.keySet().toArray(new Id[labels.size()]);\n+        Query query = GraphTransaction.constructEdgesQuery(source, dir, els);\n+        query.aggregate(Aggregate.AggregateFunc.COUNT, null);\n+        query.capacity(Query.NO_CAPACITY);\n+        query.limit(Query.NO_LIMIT);\n+        return graph().queryNumber(query).longValue();\n+    }\n+\n+    private void checkDedup(long dedup) {\n+        checkNonNegativeOrNoLimit(dedup, \"dedup\");\n+    }\n+\n+    private boolean dedup(Id vertex) {\n+        if (!this.needDedup()) {\n+            return false;\n+        }\n+\n+        if (this.dedupSet.contains(vertex)) {\n+            // Skip vertex already traversed\n+            return true;\n+        } else if (!this.reachDedup()) {\n+            // Record vertex not traversed before if not reach dedup\n+            this.dedupSet.add(vertex);\n+        }\n+        return false;\n+    }\n+\n+    private boolean needDedup() {\n+        return this.dedup != 0L;\n+    }\n+\n+    private boolean reachDedup() {\n+        return this.dedup != NO_LIMIT && this.dedupSet.size() >= this.dedup;\n+    }\n+\n+    public static class Step {\n+\n+        private Directions direction;\n+        private Map<Id, String> labels;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4408568fbad7c62796138d19c2ac39431b5a4109"}, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjU1NTQxOnYy", "diffSide": "RIGHT", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowNTowOVrOGZ0NUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowNTowOVrOGZ0NUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMjk2Mg==", "bodyText": "move out from for-loop", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r429722962", "createdAt": "2020-05-25T04:05:09Z", "author": {"login": "javeme"}, "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.traversal.algorithm;\n+\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.tinkerpop.gremlin.structure.Edge;\n+\n+import com.baidu.hugegraph.HugeGraph;\n+import com.baidu.hugegraph.backend.id.Id;\n+import com.baidu.hugegraph.backend.query.Aggregate;\n+import com.baidu.hugegraph.backend.query.Query;\n+import com.baidu.hugegraph.backend.query.QueryResults;\n+import com.baidu.hugegraph.backend.tx.GraphTransaction;\n+import com.baidu.hugegraph.iterator.FilterIterator;\n+import com.baidu.hugegraph.iterator.FlatMapperIterator;\n+import com.baidu.hugegraph.structure.HugeEdge;\n+import com.baidu.hugegraph.type.define.Directions;\n+import com.baidu.hugegraph.util.E;\n+\n+public class CountTraverser extends HugeTraverser {\n+\n+    private boolean containsTraversed = false;\n+    private long dedup = 1000000L;\n+    private final Set<Id> dedupSet = new HashSet<>();\n+    private final long[] count = {0L};\n+\n+    public CountTraverser(HugeGraph graph) {\n+        super(graph);\n+    }\n+\n+    public long count(Id source, List<Step> steps,\n+                      boolean containsTraversed, long dedup) {\n+        E.checkArgumentNotNull(source, \"The source can't be null\");\n+        E.checkArgument(steps != null && !steps.isEmpty(),\n+                        \"The steps can't be empty\");\n+        checkDedup(dedup);\n+\n+        this.containsTraversed = containsTraversed;\n+        this.dedup = dedup;\n+        if (this.containsTraversed) {\n+            count[0]++;\n+        }\n+\n+        int stepNum = steps.size();\n+        Step firstStep = steps.get(0);\n+        if (stepNum == 1) {\n+            // Just one step, query count and return\n+            count[0] += this.edgesCount(source, firstStep.direction,\n+                                        firstStep.labels);\n+            return count[0];\n+        }\n+\n+        // Multiple steps, construct first step to iterator\n+        Iterator<Edge> edges = this.edgesOfVertex(source, firstStep);\n+        for (int i = 1; i < stepNum; i++) {\n+            Step currentStep = steps.get(i);\n+            if (i != stepNum - 1) {\n+                edges = new FlatMapperIterator<>(edges, (edge) -> {\n+                    Id target = ((HugeEdge) edge).id().otherVertexId();\n+                    return this.edgesOfVertex(target, currentStep);\n+                });\n+            } else {\n+                // The last step, just query count", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4408568fbad7c62796138d19c2ac39431b5a4109"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3NjU1NzE1OnYy", "diffSide": "RIGHT", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowNjo1NFrOGZ0OTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNVQwNDowNjo1NFrOGZ0OTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzIxNA==", "bodyText": "change count[0] to MutateLong", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r429723214", "createdAt": "2020-05-25T04:06:54Z", "author": {"login": "javeme"}, "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.traversal.algorithm;\n+\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.tinkerpop.gremlin.structure.Edge;\n+\n+import com.baidu.hugegraph.HugeGraph;\n+import com.baidu.hugegraph.backend.id.Id;\n+import com.baidu.hugegraph.backend.query.Aggregate;\n+import com.baidu.hugegraph.backend.query.Query;\n+import com.baidu.hugegraph.backend.query.QueryResults;\n+import com.baidu.hugegraph.backend.tx.GraphTransaction;\n+import com.baidu.hugegraph.iterator.FilterIterator;\n+import com.baidu.hugegraph.iterator.FlatMapperIterator;\n+import com.baidu.hugegraph.structure.HugeEdge;\n+import com.baidu.hugegraph.type.define.Directions;\n+import com.baidu.hugegraph.util.E;\n+\n+public class CountTraverser extends HugeTraverser {\n+\n+    private boolean containsTraversed = false;\n+    private long dedup = 1000000L;\n+    private final Set<Id> dedupSet = new HashSet<>();\n+    private final long[] count = {0L};\n+\n+    public CountTraverser(HugeGraph graph) {\n+        super(graph);\n+    }\n+\n+    public long count(Id source, List<Step> steps,\n+                      boolean containsTraversed, long dedup) {\n+        E.checkArgumentNotNull(source, \"The source can't be null\");\n+        E.checkArgument(steps != null && !steps.isEmpty(),\n+                        \"The steps can't be empty\");\n+        checkDedup(dedup);\n+\n+        this.containsTraversed = containsTraversed;\n+        this.dedup = dedup;\n+        if (this.containsTraversed) {\n+            count[0]++;\n+        }\n+\n+        int stepNum = steps.size();\n+        Step firstStep = steps.get(0);\n+        if (stepNum == 1) {\n+            // Just one step, query count and return\n+            count[0] += this.edgesCount(source, firstStep.direction,\n+                                        firstStep.labels);\n+            return count[0];\n+        }\n+\n+        // Multiple steps, construct first step to iterator\n+        Iterator<Edge> edges = this.edgesOfVertex(source, firstStep);\n+        for (int i = 1; i < stepNum; i++) {\n+            Step currentStep = steps.get(i);\n+            if (i != stepNum - 1) {\n+                edges = new FlatMapperIterator<>(edges, (edge) -> {\n+                    Id target = ((HugeEdge) edge).id().otherVertexId();\n+                    return this.edgesOfVertex(target, currentStep);\n+                });\n+            } else {\n+                // The last step, just query count\n+                while (edges.hasNext()) {\n+                    HugeEdge edge = (HugeEdge) edges.next();\n+                    Id target = edge.id().otherVertexId();\n+                    if (this.dedup(target)) {\n+                        continue;\n+                    }\n+                    // Count last layer vertices(without dedup)\n+                    this.count[0] += this.edgesCount(target,\n+                                                     currentStep.direction,\n+                                                     currentStep.labels);\n+                }\n+            }\n+        }\n+\n+        return this.count[0];\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Step step) {\n+        if (this.dedup(source)) {\n+            return QueryResults.emptyIterator();\n+        }\n+        Iterator<Edge> flatten = this.edgesOfVertex(source, step.direction,\n+                                                    step.labels, step.degree,\n+                                                    step.skipDegree);\n+        return new FilterIterator<>(flatten, e -> {\n+            if (this.containsTraversed) {\n+                // Count intermediate vertices\n+                this.count[0]++;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4408568fbad7c62796138d19c2ac39431b5a4109"}, "originalPosition": 113}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTY3MDc5OnYy", "diffSide": "RIGHT", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzoyNzozN1rOGaR0_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzoyNzozN1rOGaR0_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDIwODI1NA==", "bodyText": "remove it", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r430208254", "createdAt": "2020-05-26T07:27:37Z", "author": {"login": "javeme"}, "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.traversal.algorithm;\n+\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.mutable.MutableLong;\n+import org.apache.tinkerpop.gremlin.structure.Edge;\n+\n+import com.baidu.hugegraph.HugeGraph;\n+import com.baidu.hugegraph.backend.id.Id;\n+import com.baidu.hugegraph.backend.query.Aggregate;\n+import com.baidu.hugegraph.backend.query.Condition;\n+import com.baidu.hugegraph.backend.query.ConditionQuery;\n+import com.baidu.hugegraph.backend.query.Query;\n+import com.baidu.hugegraph.backend.query.QueryResults;\n+import com.baidu.hugegraph.backend.tx.GraphTransaction;\n+import com.baidu.hugegraph.iterator.FilterIterator;\n+import com.baidu.hugegraph.iterator.FlatMapperIterator;\n+import com.baidu.hugegraph.structure.HugeEdge;\n+import com.baidu.hugegraph.traversal.optimize.TraversalUtil;\n+import com.baidu.hugegraph.type.define.Directions;\n+import com.baidu.hugegraph.util.E;\n+\n+public class CountTraverser extends HugeTraverser {\n+\n+    private boolean containsTraversed = false;\n+    private long dedupSize = 1000000L;\n+    private final Set<Id> dedupSet = new HashSet<>();\n+    private final MutableLong count = new MutableLong(0L);\n+\n+    public CountTraverser(HugeGraph graph) {\n+        super(graph);\n+    }\n+\n+    public long count(Id source, List<Step> steps,\n+                      boolean containsTraversed, long dedupSize) {\n+        E.checkArgumentNotNull(source, \"The source can't be null\");\n+        E.checkArgument(steps != null && !steps.isEmpty(),\n+                        \"The steps can't be empty\");\n+        checkDedupSize(dedupSize);\n+\n+        this.containsTraversed = containsTraversed;\n+        this.dedupSize = dedupSize;\n+        if (this.containsTraversed) {\n+            count.increment();\n+        }\n+\n+        int stepNum = steps.size();\n+        Step firstStep = steps.get(0);\n+        if (stepNum == 1) {\n+            // Just one step, query count and return\n+            count.add(this.edgesCount(source, firstStep.direction,\n+                                      firstStep.labels, firstStep.properties));\n+            return count.longValue();\n+        }\n+\n+        // Multiple steps, construct first step to iterator\n+        Iterator<Edge> edges = this.edgesOfVertex(source, firstStep);\n+        // Wrap steps to Iterator except last step\n+        for (int i = 1; i < stepNum - 1; i++) {\n+            Step currentStep = steps.get(i);\n+            if (i != stepNum - 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52336a40465721da2cd38ec8c30e0cb9e099f6be"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTY3OTIyOnYy", "diffSide": "RIGHT", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzozMDoxMlrOGaR6MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzozMDoxMlrOGaR6MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDIwOTU4NA==", "bodyText": "move to super class", "url": "https://github.com/hugegraph/hugegraph/pull/995#discussion_r430209584", "createdAt": "2020-05-26T07:30:12Z", "author": {"login": "javeme"}, "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/traversal/algorithm/CountTraverser.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.traversal.algorithm;\n+\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.mutable.MutableLong;\n+import org.apache.tinkerpop.gremlin.structure.Edge;\n+\n+import com.baidu.hugegraph.HugeGraph;\n+import com.baidu.hugegraph.backend.id.Id;\n+import com.baidu.hugegraph.backend.query.Aggregate;\n+import com.baidu.hugegraph.backend.query.Condition;\n+import com.baidu.hugegraph.backend.query.ConditionQuery;\n+import com.baidu.hugegraph.backend.query.Query;\n+import com.baidu.hugegraph.backend.query.QueryResults;\n+import com.baidu.hugegraph.backend.tx.GraphTransaction;\n+import com.baidu.hugegraph.iterator.FilterIterator;\n+import com.baidu.hugegraph.iterator.FlatMapperIterator;\n+import com.baidu.hugegraph.structure.HugeEdge;\n+import com.baidu.hugegraph.traversal.optimize.TraversalUtil;\n+import com.baidu.hugegraph.type.define.Directions;\n+import com.baidu.hugegraph.util.E;\n+\n+public class CountTraverser extends HugeTraverser {\n+\n+    private boolean containsTraversed = false;\n+    private long dedupSize = 1000000L;\n+    private final Set<Id> dedupSet = new HashSet<>();\n+    private final MutableLong count = new MutableLong(0L);\n+\n+    public CountTraverser(HugeGraph graph) {\n+        super(graph);\n+    }\n+\n+    public long count(Id source, List<Step> steps,\n+                      boolean containsTraversed, long dedupSize) {\n+        E.checkArgumentNotNull(source, \"The source can't be null\");\n+        E.checkArgument(steps != null && !steps.isEmpty(),\n+                        \"The steps can't be empty\");\n+        checkDedupSize(dedupSize);\n+\n+        this.containsTraversed = containsTraversed;\n+        this.dedupSize = dedupSize;\n+        if (this.containsTraversed) {\n+            count.increment();\n+        }\n+\n+        int stepNum = steps.size();\n+        Step firstStep = steps.get(0);\n+        if (stepNum == 1) {\n+            // Just one step, query count and return\n+            count.add(this.edgesCount(source, firstStep.direction,\n+                                      firstStep.labels, firstStep.properties));\n+            return count.longValue();\n+        }\n+\n+        // Multiple steps, construct first step to iterator\n+        Iterator<Edge> edges = this.edgesOfVertex(source, firstStep);\n+        // Wrap steps to Iterator except last step\n+        for (int i = 1; i < stepNum - 1; i++) {\n+            Step currentStep = steps.get(i);\n+            if (i != stepNum - 1) {\n+                edges = new FlatMapperIterator<>(edges, (edge) -> {\n+                    Id target = ((HugeEdge) edge).id().otherVertexId();\n+                    return this.edgesOfVertex(target, currentStep);\n+                });\n+            }\n+        }\n+\n+        // The last step, just query count\n+        Step lastStep = steps.get(stepNum - 1);\n+        while (edges.hasNext()) {\n+            HugeEdge edge = (HugeEdge) edges.next();\n+            Id target = edge.id().otherVertexId();\n+            if (this.dedup(target)) {\n+                continue;\n+            }\n+            // Count last layer vertices(without dedupSize)\n+            this.count.add(this.edgesCount(target, lastStep.direction,\n+                                           lastStep.labels,\n+                                           lastStep.properties));\n+        }\n+\n+        return this.count.longValue();\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Step step) {\n+        if (this.dedup(source)) {\n+            return QueryResults.emptyIterator();\n+        }\n+        Iterator<Edge> flatten = this.edgesOfVertex(source, step.direction,\n+                                                    step.labels,\n+                                                    step.properties,\n+                                                    step.degree,\n+                                                    step.skipDegree);\n+        return new FilterIterator<>(flatten, e -> {\n+            if (this.containsTraversed) {\n+                // Count intermediate vertices\n+                this.count.increment();\n+            }\n+            return true;\n+        });\n+    }\n+\n+    private Iterator<Edge> edgesOfVertex(Id source, Directions dir,\n+                                         Map<Id, String> labels,\n+                                         Map<Id, Object> properties,\n+                                         long degree, long skipDegree) {\n+        checkSkipDegree(skipDegree, degree, NO_LIMIT);\n+        long queryLimit = skipDegree > 0 ? skipDegree : degree;\n+        Iterator<Edge> edges = this.edgesOfVertexWithSK(source, dir, labels,\n+                                                        properties, queryLimit);\n+        return ShortestPathTraverser.skipSuperNodeIfNeeded(edges, degree,\n+                                                           skipDegree);\n+    }\n+\n+    protected Iterator<Edge> edgesOfVertexWithSK(Id source, Directions dir,\n+                                                 Map<Id, String> labels,\n+                                                 Map<Id, Object> properties,\n+                                                 long limit) {\n+        Id[] els = labels.keySet().toArray(new Id[labels.size()]);\n+        Query query = GraphTransaction.constructEdgesQuery(source, dir, els);\n+        this.filterBySortKeys(query, labels, properties);\n+        query.capacity(Query.NO_CAPACITY);\n+        if (limit != NO_LIMIT) {\n+            query.limit(limit);\n+        }\n+        return this.graph().edges(query);\n+    }\n+\n+    private long edgesCount(Id source, Directions dir, Map<Id, String> labels,\n+                            Map<Id, Object> properties) {\n+        Id[] els = labels.keySet().toArray(new Id[labels.size()]);\n+        Query query = GraphTransaction.constructEdgesQuery(source, dir, els);\n+        this.filterBySortKeys(query, labels, properties);\n+        query.aggregate(Aggregate.AggregateFunc.COUNT, null);\n+        query.capacity(Query.NO_CAPACITY);\n+        query.limit(Query.NO_LIMIT);\n+        return graph().queryNumber(query).longValue();\n+    }\n+\n+    private void filterBySortKeys(Query query, Map<Id, String> labels,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "52336a40465721da2cd38ec8c30e0cb9e099f6be"}, "originalPosition": 164}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1618, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}