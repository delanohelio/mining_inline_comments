{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzNzQxODg3", "number": 112, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMzo1Nzo1M1rODY922w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MTozNlrODZ5khw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTA1ODgzOnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMzo1Nzo1M1rOFfIFmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjozMjozMlrOFgiuuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjY4MQ==", "bodyText": "nit: Probably InvalidStateException would make more sense?\nRuntimeException is unchecked, making it a bad choice to suggest to users.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r368182681", "createdAt": "2020-01-17T23:57:53Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0NTQ5MQ==", "bodyText": "InvalidStateException is not available so I will print out the error message instead", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r368245491", "createdAt": "2020-01-18T19:58:44Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjY4MQ=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTM2MjQ2NA==", "bodyText": "I think there's a miscommunication on error handling here.\nIf something goes wrong, we definitely want to throw an exception - but we want a checked exception vs unchecked.\nCheck out this article for a breakdown of checked v unchecked.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369362464", "createdAt": "2020-01-22T04:09:57Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjY4MQ=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY2Nzc2OQ==", "bodyText": "Throwing Exception so that it's checked.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369667769", "createdAt": "2020-01-22T16:32:32Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjY4MQ=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NTA1OTg1OnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMzo1ODo0NFrOFfIGNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwNDoxMToxMFrOFgQGuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjgzOA==", "bodyText": "nit: It there error throwable? e.g. throw loadJob.getStatus().getError().toString()? Else use a checked error.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r368182838", "createdAt": "2020-01-17T23:58:44Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");\n+      } else if (completedJob.getStatus().getError() != null) {\n+        // You can also look at queryJob.getStatus().getExecutionErrors() for all\n+        // errors, not just the latest one.\n+        throw new RuntimeException(loadJob.getStatus().getError().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0NTU1MA==", "bodyText": "yes - in fact, it helped me debug when I wasn't able to figure out what was wrong with the job.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r368245550", "createdAt": "2020-01-18T19:59:40Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");\n+      } else if (completedJob.getStatus().getError() != null) {\n+        // You can also look at queryJob.getStatus().getExecutionErrors() for all\n+        // errors, not just the latest one.\n+        throw new RuntimeException(loadJob.getStatus().getError().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjgzOA=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyNTE1MQ==", "bodyText": "What I meant was can you throw the Error directly - using throw loadJob.getStatus().getError()?\nOtherwise you really shouldn't throw a unchecked exceptions like this - checked exceptions are preferred. (A regular Exception is considered checked, while RuntimeExceptions are unchecked.)", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369125151", "createdAt": "2020-01-21T16:59:47Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");\n+      } else if (completedJob.getStatus().getError() != null) {\n+        // You can also look at queryJob.getStatus().getExecutionErrors() for all\n+        // errors, not just the latest one.\n+        throw new RuntimeException(loadJob.getStatus().getError().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjgzOA=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2NTgxNg==", "bodyText": "Oh I see... I'm updating this to be print it out since loadJob.getStatus().getError() is a String instead of Throwable.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369165816", "createdAt": "2020-01-21T18:22:34Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");\n+      } else if (completedJob.getStatus().getError() != null) {\n+        // You can also look at queryJob.getStatus().getExecutionErrors() for all\n+        // errors, not just the latest one.\n+        throw new RuntimeException(loadJob.getStatus().getError().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjgzOA=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTM2MjYxNw==", "bodyText": "We want to throw - it should just be a checked exception.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369362617", "createdAt": "2020-01-22T04:11:10Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        throw new RuntimeException(\"Job no longer exists\");\n+      } else if (completedJob.getStatus().getError() != null) {\n+        // You can also look at queryJob.getStatus().getExecutionErrors() for all\n+        // errors, not just the latest one.\n+        throw new RuntimeException(loadJob.getStatus().getError().toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE4MjgzOA=="}, "originalCommit": {"oid": "fa6459ec25d93f874ef739b01ecd23fcb2bf0324"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4NDg0MjMxOnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MTozNlrOFgjDuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjo0MTozNlrOFgjDuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MzE0Nw==", "bodyText": "nit: This should probably throw an Exception as well.", "url": "https://github.com/googleapis/java-bigquery/pull/112#discussion_r369673147", "createdAt": "2020-01-22T16:41:36Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/AddColumnLoadAppend.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_relax_column_load_append]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.Field;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobInfo;\n+import com.google.cloud.bigquery.JobInfo.SchemaUpdateOption;\n+import com.google.cloud.bigquery.JobInfo.WriteDisposition;\n+import com.google.cloud.bigquery.LegacySQLTypeName;\n+import com.google.cloud.bigquery.LoadJobConfiguration;\n+import com.google.cloud.bigquery.Schema;\n+import com.google.cloud.bigquery.Table;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.common.collect.ImmutableList;\n+import java.util.UUID;\n+\n+public class AddColumnLoadAppend {\n+\n+  public static void runAddColumnLoadAppend() throws Exception {\n+    // TODO(developer): Replace these variables before running the sample.\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    String sourceUri = \"/path/to/file.csv\";\n+    addColumnLoadAppend(datasetName, tableName, sourceUri);\n+  }\n+\n+  public static void addColumnLoadAppend(String datasetName, String tableName, String sourceUri)\n+      throws Exception {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+\n+      TableId tableId = TableId.of(datasetName, tableName);\n+      Table table = bigquery.getTable(tableId);\n+\n+      // Add a new column to a BigQuery table while appending rows via a load job.\n+      // 'REQUIRED' fields cannot  be added to an existing schema, so the additional column must be\n+      // 'NULLABLE'.\n+      Schema newSchema =\n+          Schema.of(\n+              Field.newBuilder(\"name\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.REQUIRED)\n+                  .build(),\n+              // Adding below additional column during the load job\n+              Field.newBuilder(\"post_abbr\", LegacySQLTypeName.STRING)\n+                  .setMode(Field.Mode.NULLABLE)\n+                  .build());\n+\n+      LoadJobConfiguration loadJobConfig =\n+          LoadJobConfiguration.builder(tableId, sourceUri)\n+              .setFormatOptions(FormatOptions.csv())\n+              .setWriteDisposition(WriteDisposition.WRITE_APPEND)\n+              .setSchema(newSchema)\n+              .setSchemaUpdateOptions(ImmutableList.of(SchemaUpdateOption.ALLOW_FIELD_ADDITION))\n+              .build();\n+\n+      // Create a job ID so that we can safely retry.\n+      JobId jobId = JobId.of(UUID.randomUUID().toString());\n+      Job loadJob = bigquery.create(JobInfo.newBuilder(loadJobConfig).setJobId(jobId).build());\n+      System.out.println(loadJob.getJobId());\n+\n+      // Load data from a GCS parquet file into the table\n+      // Blocks until this load table job completes its execution, either failing or succeeding.\n+      Job completedJob = loadJob.waitFor();\n+\n+      // Check for errors\n+      if (completedJob == null) {\n+        System.out.println(\"Job not executed since it no longer exists.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3dc47cb2c7c331401c39cdbe59e00d0978746eb"}, "originalPosition": 90}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3544, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}