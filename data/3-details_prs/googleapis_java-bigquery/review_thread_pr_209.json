{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMjYxNzAx", "number": 209, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyNDo0NFrODk4ajw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjowNjo0NFrODlmtOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM5OTk5NjMxOnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyNDo0NFrOFxc-iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjowMDozM1rOFylzHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTMwNA==", "bodyText": "You can try-with multiple resources:\ntry (TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n         OutputStream stream = Channels.newOutputStream(writer)) {\n     Files.copy(csvPath, stream);\n}\nAlternatively, you could nest try-with-resource statements as well.", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r387399304", "createdAt": "2020-03-04T01:24:44Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_load_from_file]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobStatistics.LoadStatistics;\n+import com.google.cloud.bigquery.TableDataWriteChannel;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.cloud.bigquery.WriteChannelConfiguration;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.nio.file.FileSystems;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+\n+public class LoadLocalFile {\n+\n+  public static void runLoadLocalFile() {\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    Path csvPath = FileSystems.getDefault().getPath(\".\", \"my-data.csv\");\n+    loadLocalFile(datasetName, tableName, csvPath);\n+  }\n+\n+  public static void loadLocalFile(String datasetName, String tableName, Path csvPath) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+      TableId tableId = TableId.of(datasetName, tableName);\n+\n+      WriteChannelConfiguration writeChannelConfiguration =\n+          WriteChannelConfiguration.newBuilder(tableId)\n+              .setFormatOptions(FormatOptions.csv())\n+              .build();\n+\n+      // The location must be specified; other fields can be auto-detected.\n+      JobId jobId = JobId.newBuilder().setLocation(\"us\").build();\n+\n+      TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n+\n+      // Imports a local file into a table.\n+      try (OutputStream stream = Channels.newOutputStream(writer)) {\n+        Files.copy(csvPath, stream);\n+      } finally {\n+        writer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MjQxNQ==", "bodyText": "okay - will use try with multiple resources", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388592415", "createdAt": "2020-03-05T22:00:33Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_load_from_file]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobStatistics.LoadStatistics;\n+import com.google.cloud.bigquery.TableDataWriteChannel;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.cloud.bigquery.WriteChannelConfiguration;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.nio.file.FileSystems;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+\n+public class LoadLocalFile {\n+\n+  public static void runLoadLocalFile() {\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    Path csvPath = FileSystems.getDefault().getPath(\".\", \"my-data.csv\");\n+    loadLocalFile(datasetName, tableName, csvPath);\n+  }\n+\n+  public static void loadLocalFile(String datasetName, String tableName, Path csvPath) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+      TableId tableId = TableId.of(datasetName, tableName);\n+\n+      WriteChannelConfiguration writeChannelConfiguration =\n+          WriteChannelConfiguration.newBuilder(tableId)\n+              .setFormatOptions(FormatOptions.csv())\n+              .build();\n+\n+      // The location must be specified; other fields can be auto-detected.\n+      JobId jobId = JobId.newBuilder().setLocation(\"us\").build();\n+\n+      TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n+\n+      // Imports a local file into a table.\n+      try (OutputStream stream = Channels.newOutputStream(writer)) {\n+        Files.copy(csvPath, stream);\n+      } finally {\n+        writer.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTMwNA=="}, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMDAwMTUzOnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQwMToyNzo0MVrOFxdBsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjowMjo0NlrOFyl3Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMDExMg==", "bodyText": "IOExceptions and InterruptedException should probably bubble up", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r387400112", "createdAt": "2020-03-04T01:27:41Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_load_from_file]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobStatistics.LoadStatistics;\n+import com.google.cloud.bigquery.TableDataWriteChannel;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.cloud.bigquery.WriteChannelConfiguration;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.nio.file.FileSystems;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+\n+public class LoadLocalFile {\n+\n+  public static void runLoadLocalFile() {\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    Path csvPath = FileSystems.getDefault().getPath(\".\", \"my-data.csv\");\n+    loadLocalFile(datasetName, tableName, csvPath);\n+  }\n+\n+  public static void loadLocalFile(String datasetName, String tableName, Path csvPath) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+      TableId tableId = TableId.of(datasetName, tableName);\n+\n+      WriteChannelConfiguration writeChannelConfiguration =\n+          WriteChannelConfiguration.newBuilder(tableId)\n+              .setFormatOptions(FormatOptions.csv())\n+              .build();\n+\n+      // The location must be specified; other fields can be auto-detected.\n+      JobId jobId = JobId.newBuilder().setLocation(\"us\").build();\n+\n+      TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n+\n+      // Imports a local file into a table.\n+      try (OutputStream stream = Channels.newOutputStream(writer)) {\n+        Files.copy(csvPath, stream);\n+      } finally {\n+        writer.close();\n+      }\n+\n+      Job job = writer.getJob();\n+      Job completedJob = job.waitFor();\n+      if (completedJob == null) {\n+        System.out.println(\"Job not executed since it no longer exists.\");\n+        return;\n+      } else if (completedJob.getStatus().getError() != null) {\n+        System.out.println(\n+            \"BigQuery was unable to load local file to the table due to an error: \\n\"\n+                + job.getStatus().getError());\n+        return;\n+      }\n+\n+      // Get output status\n+      LoadStatistics stats = job.getStatistics();\n+      System.out.printf(\"Successfully loaded %d rows. \\n\", stats.getOutputRows());\n+    } catch (BigQueryException | IOException | InterruptedException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MzUxMQ==", "bodyText": "okay will do", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388593511", "createdAt": "2020-03-05T22:02:46Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_load_from_file]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobStatistics.LoadStatistics;\n+import com.google.cloud.bigquery.TableDataWriteChannel;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.cloud.bigquery.WriteChannelConfiguration;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.nio.file.FileSystems;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+\n+public class LoadLocalFile {\n+\n+  public static void runLoadLocalFile() {\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    Path csvPath = FileSystems.getDefault().getPath(\".\", \"my-data.csv\");\n+    loadLocalFile(datasetName, tableName, csvPath);\n+  }\n+\n+  public static void loadLocalFile(String datasetName, String tableName, Path csvPath) {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+      TableId tableId = TableId.of(datasetName, tableName);\n+\n+      WriteChannelConfiguration writeChannelConfiguration =\n+          WriteChannelConfiguration.newBuilder(tableId)\n+              .setFormatOptions(FormatOptions.csv())\n+              .build();\n+\n+      // The location must be specified; other fields can be auto-detected.\n+      JobId jobId = JobId.newBuilder().setLocation(\"us\").build();\n+\n+      TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n+\n+      // Imports a local file into a table.\n+      try (OutputStream stream = Channels.newOutputStream(writer)) {\n+        Files.copy(csvPath, stream);\n+      } finally {\n+        writer.close();\n+      }\n+\n+      Job job = writer.getJob();\n+      Job completedJob = job.waitFor();\n+      if (completedJob == null) {\n+        System.out.println(\"Job not executed since it no longer exists.\");\n+        return;\n+      } else if (completedJob.getStatus().getError() != null) {\n+        System.out.println(\n+            \"BigQuery was unable to load local file to the table due to an error: \\n\"\n+                + job.getStatus().getError());\n+        return;\n+      }\n+\n+      // Get output status\n+      LoadStatistics stats = job.getStatistics();\n+      System.out.printf(\"Successfully loaded %d rows. \\n\", stats.getOutputRows());\n+    } catch (BigQueryException | IOException | InterruptedException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMDExMg=="}, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjc3NDAxOnYy", "diffSide": "RIGHT", "path": "samples/src/test/java/com/example/bigquery/LoadPartitionedTableIT.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODowMTo1M1rOFx3wvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjoxODoxNVrOFymR2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzgzODE0Mg==", "bodyText": "This looks like a typo", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r387838142", "createdAt": "2020-03-04T18:01:53Z", "author": {"login": "kurtisvg"}, "path": "samples/src/test/java/com/example/bigquery/LoadPartitionedTableIT.java", "diffHunk": "@@ -59,7 +60,9 @@ public void tearDown() {\n   public void loadPartitionedTable() throws Exception {\n     String sourceUri = \"gs://cloud-samples-data/bigquery/us-states/us-states-by-date-no-header.csv\";\n \n-    String tableName = \"LOAD_PARTITIONED_TABLE_TEST\";\n+    String tableName =\n+        \"LOAD_PARTITIONED_TABLE_TEST_\" + UUID.randomUUID().toString().replace('-', '_');\n+    ;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MjgzNQ==", "bodyText": "this is in a different test actually -- I just wanted to update the table name have a random string part.", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388592835", "createdAt": "2020-03-05T22:01:22Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/test/java/com/example/bigquery/LoadPartitionedTableIT.java", "diffHunk": "@@ -59,7 +60,9 @@ public void tearDown() {\n   public void loadPartitionedTable() throws Exception {\n     String sourceUri = \"gs://cloud-samples-data/bigquery/us-states/us-states-by-date-no-header.csv\";\n \n-    String tableName = \"LOAD_PARTITIONED_TABLE_TEST\";\n+    String tableName =\n+        \"LOAD_PARTITIONED_TABLE_TEST_\" + UUID.randomUUID().toString().replace('-', '_');\n+    ;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzgzODE0Mg=="}, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NTc3Nw==", "bodyText": "I think the semicolon on L65 is still extra (and looks like it was added in this PR).", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388595777", "createdAt": "2020-03-05T22:08:02Z", "author": {"login": "kurtisvg"}, "path": "samples/src/test/java/com/example/bigquery/LoadPartitionedTableIT.java", "diffHunk": "@@ -59,7 +60,9 @@ public void tearDown() {\n   public void loadPartitionedTable() throws Exception {\n     String sourceUri = \"gs://cloud-samples-data/bigquery/us-states/us-states-by-date-no-header.csv\";\n \n-    String tableName = \"LOAD_PARTITIONED_TABLE_TEST\";\n+    String tableName =\n+        \"LOAD_PARTITIONED_TABLE_TEST_\" + UUID.randomUUID().toString().replace('-', '_');\n+    ;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzgzODE0Mg=="}, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwMDI4Mg==", "bodyText": "you're right! thanks!", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388600282", "createdAt": "2020-03-05T22:18:15Z", "author": {"login": "stephaniewang526"}, "path": "samples/src/test/java/com/example/bigquery/LoadPartitionedTableIT.java", "diffHunk": "@@ -59,7 +60,9 @@ public void tearDown() {\n   public void loadPartitionedTable() throws Exception {\n     String sourceUri = \"gs://cloud-samples-data/bigquery/us-states/us-states-by-date-no-header.csv\";\n \n-    String tableName = \"LOAD_PARTITIONED_TABLE_TEST\";\n+    String tableName =\n+        \"LOAD_PARTITIONED_TABLE_TEST_\" + UUID.randomUUID().toString().replace('-', '_');\n+    ;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzgzODE0Mg=="}, "originalCommit": {"oid": "a996d4b3610fdc708e5ea5c8125107e8cd1132e1"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwNzU4MDc0OnYy", "diffSide": "RIGHT", "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjowNjo0NFrOFyl-PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNVQyMjowNjo0NFrOFyl-PA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NTI2MA==", "bodyText": "nit: Add a comment\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  Job job = bigquery.getJob(jobId);\n          \n          \n            \n                  // Get the Job created by the TableDataWriteChannel and wait for it to complete.\n          \n          \n            \n                  Job job = bigquery.getJob(jobId);", "url": "https://github.com/googleapis/java-bigquery/pull/209#discussion_r388595260", "createdAt": "2020-03-05T22:06:44Z", "author": {"login": "kurtisvg"}, "path": "samples/src/main/java/com/example/bigquery/LoadLocalFile.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.example.bigquery;\n+\n+// [START bigquery_load_from_file]\n+import com.google.cloud.bigquery.BigQuery;\n+import com.google.cloud.bigquery.BigQueryException;\n+import com.google.cloud.bigquery.BigQueryOptions;\n+import com.google.cloud.bigquery.FormatOptions;\n+import com.google.cloud.bigquery.Job;\n+import com.google.cloud.bigquery.JobId;\n+import com.google.cloud.bigquery.JobStatistics.LoadStatistics;\n+import com.google.cloud.bigquery.TableDataWriteChannel;\n+import com.google.cloud.bigquery.TableId;\n+import com.google.cloud.bigquery.WriteChannelConfiguration;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.nio.file.FileSystems;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.UUID;\n+\n+public class LoadLocalFile {\n+\n+  public static void runLoadLocalFile() throws IOException, InterruptedException {\n+    String datasetName = \"MY_DATASET_NAME\";\n+    String tableName = \"MY_TABLE_NAME\";\n+    Path csvPath = FileSystems.getDefault().getPath(\".\", \"my-data.csv\");\n+    loadLocalFile(datasetName, tableName, csvPath);\n+  }\n+\n+  public static void loadLocalFile(String datasetName, String tableName, Path csvPath)\n+      throws IOException, InterruptedException {\n+    try {\n+      // Initialize client that will be used to send requests. This client only needs to be created\n+      // once, and can be reused for multiple requests.\n+      BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\n+      TableId tableId = TableId.of(datasetName, tableName);\n+\n+      WriteChannelConfiguration writeChannelConfiguration =\n+          WriteChannelConfiguration.newBuilder(tableId)\n+              .setFormatOptions(FormatOptions.csv())\n+              .build();\n+\n+      // The location and JobName must be specified; other fields can be auto-detected.\n+      String jobName = \"jobId_\" + UUID.randomUUID().toString();\n+      JobId jobId = JobId.newBuilder().setLocation(\"us\").setJob(jobName).build();\n+\n+      // Imports a local file into a table.\n+      try (TableDataWriteChannel writer = bigquery.writer(jobId, writeChannelConfiguration);\n+          OutputStream stream = Channels.newOutputStream(writer)) {\n+        Files.copy(csvPath, stream);\n+      }\n+\n+      Job job = bigquery.getJob(jobId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9538681eefb07615a159e3f223020083d62770b"}, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3503, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}