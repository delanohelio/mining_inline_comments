{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyNzY0OTAw", "number": 2868, "title": "NMS-10586: Sink API: Persistent Off-Heap Storage", "bodyText": "This PR updates the off-heap functionality of the Sink process on Minion. The H2 db implementation that was using off-heap memory is now removed. It is replaced by a file based fifo queue to avoid using memory and allowing us to store much larger amounts of messages off-heap.\nThe new implementation is installed and active by default. It can optionally be disabled by setting the max file size to 0.\nAdditionally, fixed a memory leak where we were storing futures on-heap for off-heap messages.\nTested on Minion using udpgen. I was seeing a throughput of 10-15MB/s to the disk, limited mostly by the time to serialize SNMP trap objects.\nAll Contributors\n\n Have you read and followed our Contribution Guidelines?\n Have you made an issue in the OpenNMS issue tracker?If so, you should:\n\nupdate the title of this PR to be of the format: ${JIRA-ISSUE-NUMBER}: subject of pull request\nupdate the JIRA link at the bottom of this comment to refer to the real issue number\nprefix your commit messages with the issue number, if possible\n\n\n Have you made a comment in that issue which points back to this PR?\n Have you updated the JIRA link at the bottom of this comment to link to your issue?\n If this is a new or updated feature, is there documentation for the new behavior?\n If this is new code, are there unit and/or integration tests?\n If this PR targets a foundation-* branch, does it avoid changing files in $OPENNMS_HOME/etc/?\n\nPull Request Process\nOne or more reviewers should be assigned to each PR.\nIf you know that a particular person is subject matter expert in the area your PR affects, feel free to assign one or more reviewers when you create this PR, otherwise reviewers will be assigned for you.\nOnce the reviewer(s) accept the PR and the branch passes continuous integration in Bamboo, the PR is eligible for merge.\nAt that time, if you have commit access (are an OpenNMS Group employee or a member of the Order of the Green Polo) you are welcome to merge the PR.\nOtherwise, a reviewer can merge it for you.\nThanks for taking time to contribute!\nExternal References\n\nJIRA (Issue Tracker): http://issues.opennms.org/browse/NMS-10586\nBamboo (Continuous Integration): https://bamboo.opennms.org/", "createdAt": "2020-01-14T17:56:32Z", "url": "https://github.com/OpenNMS/opennms/pull/2868", "merged": true, "mergeCommit": {"oid": "c3eaf75bee1a90f9f33c3a1cee9f4fd3a459cdb5"}, "closed": true, "closedAt": "2020-01-24T13:51:51Z", "author": {"login": "mattixtech"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6V-EGAFqTM0Mjc3MzAxNA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9R10mgBqjI5NzU0NjU1MDk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyNzczMDE0", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-342773014", "createdAt": "2020-01-14T19:12:24Z", "commit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOToxMjoyNVrOFdiuhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOToxNjo0N1rOFdi2UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMTk5MA==", "bodyText": "We can use the standard logger for these instead of the RATE_LIMITED_LOGGER. The RATE_LIMITED_LOGGER is intended to be used to avoid flooding the log with error messages.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366521990", "createdAt": "2020-01-14T19:12:25Z", "author": {"login": "j-white"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/common/AsyncDispatcherImpl.java", "diffHunk": "@@ -67,226 +65,162 @@\n \n     private static final Logger LOG = LoggerFactory.getLogger(AsyncDispatcherImpl.class);\n     private final SyncDispatcher<S> syncDispatcher;\n-    private OffHeapAdapter offHeapAdapter;\n-    private ExecutorService offHeapAdapterExecutor = Executors.newSingleThreadExecutor();\n     private final AsyncPolicy asyncPolicy;\n-    private OffHeapQueue offHeapQueue;\n-    private SinkModule<S,T> sinkModule;\n-    private DispatcherState<W,S,T> state;\n-    private boolean useOffHeap = false;\n+    private final Counter droppedCounter;\n     \n-    final RateLimitedLog rateLimittedLogger = RateLimitedLog\n+    private final DispatchQueue<S> dispatchQueue;\n+    private final Map<String, CompletableFuture<DispatchStatus>> futureMap = new ConcurrentHashMap<>();\n+    private final AtomicInteger activeDispatchers = new AtomicInteger(0);\n+    \n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n             .withRateLimit(LOG)\n-            .maxRate(5).every(Duration.standardSeconds(30))\n+            .maxRate(5).every(Duration.standardSeconds(5))\n             .build();\n \n-    final LinkedBlockingQueue<Runnable> queue;\n-    final ExecutorService executor;\n+    private final ExecutorService executor;\n \n     public AsyncDispatcherImpl(DispatcherState<W, S, T> state, AsyncPolicy asyncPolicy,\n-            SyncDispatcher<S> syncDispatcher) {\n+                               SyncDispatcher<S> syncDispatcher) {\n         Objects.requireNonNull(state);\n         Objects.requireNonNull(asyncPolicy);\n-        this.syncDispatcher = Objects.requireNonNull(syncDispatcher);\n+        Objects.requireNonNull(syncDispatcher);\n+        this.syncDispatcher = syncDispatcher;\n         this.asyncPolicy = asyncPolicy;\n-        this.state = state;\n-        sinkModule = state.getModule();\n-        if (OffHeapServiceLoader.isOffHeapEnabled()) {\n-            offHeapQueue = OffHeapServiceLoader.getOffHeapQueue();\n-            if (offHeapQueue != null) {\n-                useOffHeap = true;\n-                LOG.info(\"Offheap storage enabled for sink module, {}\", sinkModule.getId());\n-            }\n-        }\n-        \n-        final RejectedExecutionHandler rejectedExecutionHandler;\n-        if (asyncPolicy.isBlockWhenFull()) {\n-            // This queue ensures that calling thread is blocked when the queue is full\n-            // See the implementation of OfferBlockingQueue for details\n-            queue = new OfferBlockingQueue<>(asyncPolicy.getQueueSize());\n-            rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();\n+        SinkModule<S, T> sinkModule = state.getModule();\n+        Optional<DispatchQueueFactory> factory = DispatchQueueServiceLoader.getDispatchQueueFactory();\n+\n+        if (factory.isPresent()) {\n+            LOG.debug(\"Using queue from factory\");\n+            dispatchQueue = factory.get().getQueue(asyncPolicy, sinkModule.getId(),\n+                    sinkModule::marshalSingleMessage, sinkModule::unmarshalSingleMessage);\n         } else {\n-            queue = new LinkedBlockingQueue<Runnable>(asyncPolicy.getQueueSize());\n-            // Reject and increase the dropped counter when the queue is full\n-            final Counter droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n-            rejectedExecutionHandler = new RejectedExecutionHandler() {\n-                @Override\n-                public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n-                    droppedCounter.inc();\n-                    throw new RejectedExecutionException(\"Task \" + r.toString() +\n-                            \" rejected from \" +\n-                            e.toString());\n-                }\n-            };\n+            int size = asyncPolicy.getQueueSize();\n+            LOG.debug(\"Using default in memory queue of size {}\", size);\n+            dispatchQueue = new DefaultQueue<>(size);\n         }\n \n-        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"), new Gauge<Integer>() {\n-            @Override\n-            public Integer getValue() {\n-                return queue.size();\n-            }\n-        });\n+        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"),\n+                (Gauge<Integer>) activeDispatchers::get);\n+\n+        droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n \n-        executor = new ThreadPoolExecutor(\n-                asyncPolicy.getNumThreads(),\n-                asyncPolicy.getNumThreads(),\n-                1000L,\n-                TimeUnit.MILLISECONDS,\n-                queue,\n-                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" + state.getModule().getId(), Integer.MAX_VALUE),\n-                rejectedExecutionHandler\n-            );\n+        executor = Executors.newFixedThreadPool(asyncPolicy.getNumThreads(),\n+                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" +\n+                        state.getModule().getId(), Integer.MAX_VALUE));\n+        startDrainingQueue();\n     }\n \n-    /**\n-     * When used in a ThreadPoolExecutor, this queue will block calls to\n-     * {@link ThreadPoolExecutor#execute(Runnable)} when the queue is full.\n-     * This is done by overriding calls to {@link LinkedBlockingQueue#offer(Object)}\n-     * with calls to {@link LinkedBlockingQueue#put(Object)}, but comes with the caveat\n-     * that executor must be built with <code>corePoolSize == maxPoolSize</code>.\n-     * In the context of the {@link AsyncDispatcherImpl}, this is an acceptable caveat,\n-     * since we enforce the matching pool sizes.\n-     *\n-     * There are alternative ways of solving this problem, for example we could use a\n-     * {@link RejectedExecutionHandler} to achieve similar behavior, and allow\n-     * for <code>corePoolSize < maxPoolSize</code>, but not for <code>corePoolSize==0</code>.\n-     *\n-     * For further discussions on this topic see:\n-     *   http://stackoverflow.com/a/3518588\n-     *   http://stackoverflow.com/a/32123535\n-     *\n-     * If the implementation is changed, make sure that that executor is built accordingly.\n-     */\n-    \n-    private static class OfferBlockingQueue<E> extends LinkedBlockingQueue<E> {\n-        private static final long serialVersionUID = 1L;\n+    private void dispatchFromQueue() {\n+        while (true) {\n+            try {\n+                RATE_LIMITED_LOGGER.trace(\"Asking dispatch queue for the next entry...\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMzIzMg==", "bodyText": "TODO", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366523232", "createdAt": "2020-01-14T19:15:07Z", "author": {"login": "j-white"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueFactory.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+\n+import org.opennms.core.ipc.sink.api.AsyncPolicy;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.DispatchQueueFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class QueueFileOffHeapDispatchQueueFactory implements DispatchQueueFactory {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueueFactory.class);\n+\n+    private final int inMemoryEntrySize;\n+    private final long offHeapSize;\n+    private final int batchSize;\n+    private final Path baseFilePath;\n+\n+    private final Map<String, DispatchQueue<?>> queues = new ConcurrentHashMap<>();\n+\n+    public QueueFileOffHeapDispatchQueueFactory(int inMemoryEntrySize, int batchSize, String offHeapSize,\n+                                                String baseFilePath) {\n+        this.inMemoryEntrySize = inMemoryEntrySize;\n+        this.batchSize = batchSize;\n+        this.offHeapSize = convertToBytes(offHeapSize);\n+\n+        if (baseFilePath == null || baseFilePath.length() == 0) {\n+            this.baseFilePath = Paths.get(System.getProperty(\"karaf.data\"));\n+        } else {\n+            this.baseFilePath = Paths.get(baseFilePath);\n+        }\n+\n+        LOG.info(\"DispatchQueue factory initialized with on-heap size: {}, batch size: {}, off-heap size: {}, \" +\n+                        \"and file path: {}\", this.inMemoryEntrySize, this.batchSize, this.offHeapSize,\n+                this.baseFilePath);\n+    }\n+\n+    @Override\n+    public <T> DispatchQueue<T> getQueue(AsyncPolicy asyncPolicy, String moduleName, Function<T, byte[]> serializer,\n+                                         Function<byte[], T> deserializer) {\n+        if (asyncPolicy.getNumThreads() > inMemoryEntrySize) {\n+            throw new IllegalArgumentException(\"The in memory queue size must be greater than or equal to the number\" +\n+                    \" of consuming threads\");\n+        }\n+\n+        return (DispatchQueue<T>) queues.computeIfAbsent(moduleName, (k) -> {\n+            try {\n+                // TODO: Configurable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMzU0NQ==", "bodyText": "What's the expect behavior for unknown suffixes?", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366523545", "createdAt": "2020-01-14T19:15:48Z", "author": {"login": "j-white"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueFactory.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+\n+import org.opennms.core.ipc.sink.api.AsyncPolicy;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.DispatchQueueFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class QueueFileOffHeapDispatchQueueFactory implements DispatchQueueFactory {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueueFactory.class);\n+\n+    private final int inMemoryEntrySize;\n+    private final long offHeapSize;\n+    private final int batchSize;\n+    private final Path baseFilePath;\n+\n+    private final Map<String, DispatchQueue<?>> queues = new ConcurrentHashMap<>();\n+\n+    public QueueFileOffHeapDispatchQueueFactory(int inMemoryEntrySize, int batchSize, String offHeapSize,\n+                                                String baseFilePath) {\n+        this.inMemoryEntrySize = inMemoryEntrySize;\n+        this.batchSize = batchSize;\n+        this.offHeapSize = convertToBytes(offHeapSize);\n+\n+        if (baseFilePath == null || baseFilePath.length() == 0) {\n+            this.baseFilePath = Paths.get(System.getProperty(\"karaf.data\"));\n+        } else {\n+            this.baseFilePath = Paths.get(baseFilePath);\n+        }\n+\n+        LOG.info(\"DispatchQueue factory initialized with on-heap size: {}, batch size: {}, off-heap size: {}, \" +\n+                        \"and file path: {}\", this.inMemoryEntrySize, this.batchSize, this.offHeapSize,\n+                this.baseFilePath);\n+    }\n+\n+    @Override\n+    public <T> DispatchQueue<T> getQueue(AsyncPolicy asyncPolicy, String moduleName, Function<T, byte[]> serializer,\n+                                         Function<byte[], T> deserializer) {\n+        if (asyncPolicy.getNumThreads() > inMemoryEntrySize) {\n+            throw new IllegalArgumentException(\"The in memory queue size must be greater than or equal to the number\" +\n+                    \" of consuming threads\");\n+        }\n+\n+        return (DispatchQueue<T>) queues.computeIfAbsent(moduleName, (k) -> {\n+            try {\n+                // TODO: Configurable\n+                return new QueueFileOffHeapDispatchQueue<>(serializer, deserializer, k, baseFilePath,\n+                        inMemoryEntrySize, batchSize,\n+                        offHeapSize);\n+            } catch (IOException e) {\n+                throw new RuntimeException(e);\n+            }\n+        });\n+    }\n+\n+    private static long convertToBytes(String sizeWithSuffix) {\n+        if (sizeWithSuffix == null || sizeWithSuffix.length() == 0) {\n+            return 0;\n+        }\n+\n+        String suffix = sizeWithSuffix.substring(sizeWithSuffix.length() - 2).toLowerCase();\n+        String sizeValue = sizeWithSuffix.substring(0, sizeWithSuffix.length() - 2);\n+\n+        double value = Long.parseLong(sizeValue);\n+        long bytes = 0;\n+\n+        switch (suffix) {\n+            case \"kb\":\n+                bytes = (long) value * 1024;\n+                break;\n+            case \"mb\":\n+                bytes = (long) value * 1024 * 1024;\n+                break;\n+            case \"gb\":\n+                bytes = (long) value * 1024 * 1024 * 1024;\n+                break;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMzc3Ng==", "bodyText": "Will cause error if length is 1", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366523776", "createdAt": "2020-01-14T19:16:18Z", "author": {"login": "j-white"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueFactory.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+\n+import org.opennms.core.ipc.sink.api.AsyncPolicy;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.DispatchQueueFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class QueueFileOffHeapDispatchQueueFactory implements DispatchQueueFactory {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueueFactory.class);\n+\n+    private final int inMemoryEntrySize;\n+    private final long offHeapSize;\n+    private final int batchSize;\n+    private final Path baseFilePath;\n+\n+    private final Map<String, DispatchQueue<?>> queues = new ConcurrentHashMap<>();\n+\n+    public QueueFileOffHeapDispatchQueueFactory(int inMemoryEntrySize, int batchSize, String offHeapSize,\n+                                                String baseFilePath) {\n+        this.inMemoryEntrySize = inMemoryEntrySize;\n+        this.batchSize = batchSize;\n+        this.offHeapSize = convertToBytes(offHeapSize);\n+\n+        if (baseFilePath == null || baseFilePath.length() == 0) {\n+            this.baseFilePath = Paths.get(System.getProperty(\"karaf.data\"));\n+        } else {\n+            this.baseFilePath = Paths.get(baseFilePath);\n+        }\n+\n+        LOG.info(\"DispatchQueue factory initialized with on-heap size: {}, batch size: {}, off-heap size: {}, \" +\n+                        \"and file path: {}\", this.inMemoryEntrySize, this.batchSize, this.offHeapSize,\n+                this.baseFilePath);\n+    }\n+\n+    @Override\n+    public <T> DispatchQueue<T> getQueue(AsyncPolicy asyncPolicy, String moduleName, Function<T, byte[]> serializer,\n+                                         Function<byte[], T> deserializer) {\n+        if (asyncPolicy.getNumThreads() > inMemoryEntrySize) {\n+            throw new IllegalArgumentException(\"The in memory queue size must be greater than or equal to the number\" +\n+                    \" of consuming threads\");\n+        }\n+\n+        return (DispatchQueue<T>) queues.computeIfAbsent(moduleName, (k) -> {\n+            try {\n+                // TODO: Configurable\n+                return new QueueFileOffHeapDispatchQueue<>(serializer, deserializer, k, baseFilePath,\n+                        inMemoryEntrySize, batchSize,\n+                        offHeapSize);\n+            } catch (IOException e) {\n+                throw new RuntimeException(e);\n+            }\n+        });\n+    }\n+\n+    private static long convertToBytes(String sizeWithSuffix) {\n+        if (sizeWithSuffix == null || sizeWithSuffix.length() == 0) {\n+            return 0;\n+        }\n+\n+        String suffix = sizeWithSuffix.substring(sizeWithSuffix.length() - 2).toLowerCase();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMzk4NA==", "bodyText": "Might be a good idea to trim trailing white-space off of this too", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366523984", "createdAt": "2020-01-14T19:16:47Z", "author": {"login": "j-white"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueFactory.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+\n+import org.opennms.core.ipc.sink.api.AsyncPolicy;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.DispatchQueueFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class QueueFileOffHeapDispatchQueueFactory implements DispatchQueueFactory {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueueFactory.class);\n+\n+    private final int inMemoryEntrySize;\n+    private final long offHeapSize;\n+    private final int batchSize;\n+    private final Path baseFilePath;\n+\n+    private final Map<String, DispatchQueue<?>> queues = new ConcurrentHashMap<>();\n+\n+    public QueueFileOffHeapDispatchQueueFactory(int inMemoryEntrySize, int batchSize, String offHeapSize,\n+                                                String baseFilePath) {\n+        this.inMemoryEntrySize = inMemoryEntrySize;\n+        this.batchSize = batchSize;\n+        this.offHeapSize = convertToBytes(offHeapSize);\n+\n+        if (baseFilePath == null || baseFilePath.length() == 0) {\n+            this.baseFilePath = Paths.get(System.getProperty(\"karaf.data\"));\n+        } else {\n+            this.baseFilePath = Paths.get(baseFilePath);\n+        }\n+\n+        LOG.info(\"DispatchQueue factory initialized with on-heap size: {}, batch size: {}, off-heap size: {}, \" +\n+                        \"and file path: {}\", this.inMemoryEntrySize, this.batchSize, this.offHeapSize,\n+                this.baseFilePath);\n+    }\n+\n+    @Override\n+    public <T> DispatchQueue<T> getQueue(AsyncPolicy asyncPolicy, String moduleName, Function<T, byte[]> serializer,\n+                                         Function<byte[], T> deserializer) {\n+        if (asyncPolicy.getNumThreads() > inMemoryEntrySize) {\n+            throw new IllegalArgumentException(\"The in memory queue size must be greater than or equal to the number\" +\n+                    \" of consuming threads\");\n+        }\n+\n+        return (DispatchQueue<T>) queues.computeIfAbsent(moduleName, (k) -> {\n+            try {\n+                // TODO: Configurable\n+                return new QueueFileOffHeapDispatchQueue<>(serializer, deserializer, k, baseFilePath,\n+                        inMemoryEntrySize, batchSize,\n+                        offHeapSize);\n+            } catch (IOException e) {\n+                throw new RuntimeException(e);\n+            }\n+        });\n+    }\n+\n+    private static long convertToBytes(String sizeWithSuffix) {\n+        if (sizeWithSuffix == null || sizeWithSuffix.length() == 0) {\n+            return 0;\n+        }\n+\n+        String suffix = sizeWithSuffix.substring(sizeWithSuffix.length() - 2).toLowerCase();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyMzc3Ng=="}, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyNzc4MTQw", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-342778140", "createdAt": "2020-01-14T19:20:54Z", "commit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOToyMDo1NFrOFdi-Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOToyMDo1NFrOFdi-Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUyNjAxMQ==", "bodyText": "Update copyright year.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366526011", "createdAt": "2020-01-14T19:20:54Z", "author": {"login": "bouff"}, "path": "core/ipc/sink/api/src/main/java/org/opennms/core/ipc/sink/api/AsyncDispatcher.java", "diffHunk": "@@ -40,13 +40,12 @@\n public interface AsyncDispatcher<S extends Message> extends AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyNzg0NjA4", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-342784608", "createdAt": "2020-01-14T19:31:19Z", "commit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOTozMToyMFrOFdjR_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOTozMToyMFrOFdjR_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUzMTA2OQ==", "bodyText": "Copyright year for this one as well.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366531069", "createdAt": "2020-01-14T19:31:20Z", "author": {"login": "bouff"}, "path": "core/ipc/sink/api/src/main/java/org/opennms/core/ipc/sink/api/WriteFailedException.java", "diffHunk": "@@ -35,4 +35,9 @@\n     public WriteFailedException(String message) {\n         super(message);\n     }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQyNzg4NzU0", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-342788754", "createdAt": "2020-01-14T19:38:13Z", "commit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQxOTozODoxM1rOFdjepg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNFQyMDozOTozM1rOFdlGSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjUzNDMxMA==", "bodyText": "additional messages can be persisted directly to...", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366534310", "createdAt": "2020-01-14T19:38:13Z", "author": {"login": "bouff"}, "path": "opennms-doc/guide-admin/src/asciidoc/text/minion/offheap.adoc", "diffHunk": "@@ -3,35 +3,31 @@\n \n === Using Off-heap Storage for Sink Messages\n \n-If a _Minion_ loses connectivity with the broker (i.e. _Kafka_ or _ActiveMQ_), then any received messages (i.e. syslog, flows, SNMP traps) are queued in the JVM heap until connectivity is restored.\n-This queue is limited by a fixed (and configurable) number of messages.\n+If a _Minion_ loses connectivity with the broker (i.e. _Kafka_ or _ActiveMQ_), then any received messages (i.e. syslog, flows, SNMP traps) are queued until connectivity is restored.\n+This queue is limited by a fixed (and configurable) number of messages queued in the JVM heap and can optionally queue\n+additional messages directly to the filesystem to avoid using heap memory.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU2MDg0MQ==", "bodyText": "Perhaps add a test case to check return value of the future (dispatch, queued).  No biggie though.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366560841", "createdAt": "2020-01-14T20:39:33Z", "author": {"login": "bouff"}, "path": "core/ipc/sink/off-heap/src/test/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import static com.jayway.awaitility.Awaitility.await;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.nullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Objects;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+\n+import com.jayway.awaitility.core.ConditionTimeoutException;\n+\n+public class QueueFileOffHeapDispatchQueueTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4ca6d5c20d6504263741240580fd45a07215616a"}, "originalPosition": 57}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "51c4adfd3cd946fa25b033b9c63b4729039afbfb", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/51c4adfd3cd946fa25b033b9c63b4729039afbfb", "committedDate": "2020-01-14T23:03:03Z", "message": "Review feedback 2"}, "afterCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c", "committedDate": "2020-01-15T15:36:47Z", "message": "Review feedback 2"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzMzY4NDA3", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-343368407", "createdAt": "2020-01-15T16:52:00Z", "commit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQxNjo1MjowMFrOFd_OnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMDoxNzo1NVrOFeFK6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4ODk1Ng==", "bodyText": "This should be either LOG.trace or remove message from the log if you want to keep it in debug.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366988956", "createdAt": "2020-01-15T16:52:00Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueue.java", "diffHunk": "@@ -0,0 +1,537 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ForkJoinPool;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.joda.time.Duration;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.squareup.tape2.QueueFile;\n+import com.swrve.ratelimitedlogger.RateLimitedLog;\n+\n+/**\n+ * A {@link DispatchQueue} that first attempts to queue items in memory and upon overflowing the allocated in-memory\n+ * queue writes items \"off heap\" directly to disk via a file. The in-memory queue is volatile and if the process\n+ * crashes its contents are lost. The contents written to disk are durable and in the event of a crash will be reloaded.\n+ * <p>\n+ * This queue can be configured to only queue to memory by specifying the maximum off-heap size of 0. Using this\n+ * configuration causes {@link #enqueue} to block when the in-memory queue fills up rather than writing to the off-heap\n+ * queue.\n+ * <p>\n+ * Before queued items are written to disk they are first accumulated in a batch to limit the number of discrete writes\n+ * we make to disk. The batched items are considered part of the in-memory portion of the queue and are also volatile.\n+ *\n+ * @param <T> the type being queued\n+ */\n+public class QueueFileOffHeapDispatchQueue<T> implements DispatchQueue<T> {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueue.class);\n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n+            .withRateLimit(LOG)\n+            .maxRate(5)\n+            .every(Duration.standardSeconds(30))\n+            .build();\n+\n+    // This must match the size of the HEADER_LENGTH in QueueFile's Element class\n+    //\n+    // We could pull this out of that class reflectively but it seemed easier to just hard code it here\n+    private static final int SERIALIZED_OBJECT_HEADER_SIZE_IN_BYTES = 4;\n+    private static final String FILE_EXTENSION = \".fifo\";\n+\n+    private final Function<T, byte[]> serializer;\n+    private final Function<byte[], T> deserializer;\n+    private final String moduleName;\n+    private final BlockingQueue<Map.Entry<String, T>> inMemoryQueue;\n+\n+    // Note the queue is not thread safe so access should be synchronized\n+    private final QueueFile offHeapQueue;\n+    private final long maxFileSizeInBytes;\n+    private final int batchSize;\n+    private final Batch batch;\n+\n+    private final ForkJoinPool serdesPool = new ForkJoinPool(\n+            Math.max(Runtime.getRuntime().availableProcessors() - 1, 1));\n+\n+    // Used to guard access to the offHeapQueue and batch data structures\n+    private final Object offHeapMutex = new Object();\n+    private final FileCapacityLatch fileCapacityLatch = new FileCapacityLatch();\n+\n+    private final Method usedBytesMethod;\n+\n+    public QueueFileOffHeapDispatchQueue(Function<T, byte[]> serializer, Function<byte[], T> deserializer,\n+                                         String moduleName, Path filePath, int inMemoryQueueSize, int batchSize,\n+                                         long maxFileSizeInBytes) throws IOException {\n+        Objects.requireNonNull(serializer);\n+        Objects.requireNonNull(deserializer);\n+        Objects.requireNonNull(moduleName);\n+\n+        if (inMemoryQueueSize < 1) {\n+            throw new IllegalArgumentException(\"In memory queue size must be greater than 0\");\n+        }\n+\n+        if (inMemoryQueueSize % batchSize != 0) {\n+            throw new IllegalArgumentException(\"In memory queue size must be a multiple of batch size\");\n+        }\n+\n+        if (maxFileSizeInBytes < 0) {\n+            throw new IllegalArgumentException(\"Max file size must be either 0 or a positive integer\");\n+        }\n+\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+        this.moduleName = moduleName;\n+        this.batchSize = batchSize;\n+        this.maxFileSizeInBytes = maxFileSizeInBytes;\n+        batch = new Batch(batchSize);\n+\n+        inMemoryQueue = new ArrayBlockingQueue<>(inMemoryQueueSize, true);\n+\n+        // Setting the max file size to 0 or less will disable the off-heap portion of this queue\n+        if (maxFileSizeInBytes > 0) {\n+            Objects.requireNonNull(filePath);\n+            File file = Paths.get(filePath.toString(), moduleName + FILE_EXTENSION).toFile();\n+\n+            QueueFile qf;\n+            try {\n+                qf = new QueueFile.Builder(file).build();\n+            } catch (Exception e) {\n+                LOG.warn(\"Exception while loading queue file\", e);\n+\n+                if (file.delete()) {\n+                    qf = new QueueFile.Builder(file).build();\n+                } else {\n+                    throw new IOException(\"Could delete corrupted queue file \" + file.getAbsolutePath());\n+                }\n+            }\n+            offHeapQueue = qf;\n+\n+            // QueueFile unfortunately does not expose its file size usage publicly so we need to access it reflectively\n+            try {\n+                usedBytesMethod = offHeapQueue.getClass().getDeclaredMethod(\"usedBytes\");\n+                usedBytesMethod.setAccessible(true);\n+            } catch (NoSuchMethodException e) {\n+                LOG.warn(\"Could not instantiate queue\", e);\n+                throw new RuntimeException(e);\n+            }\n+\n+            checkFileSize();\n+        } else {\n+            offHeapQueue = null;\n+            usedBytesMethod = null;\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public long checkFileSize() {\n+        try {\n+            long fileSize = (long) usedBytesMethod.invoke(offHeapQueue);\n+            fileCapacityLatch.setCurrentCapacityBytes(maxFileSizeInBytes - fileSize);\n+            LOG.trace(\"Checked file size for module {} and got result {} bytes\", moduleName,\n+                    fileSize);\n+\n+            return fileSize;\n+        } catch (IllegalAccessException | InvocationTargetException e) {\n+            RATE_LIMITED_LOGGER.warn(\"Failed to check file size for module {}\", moduleName, e);\n+            return 0;\n+        }\n+    }\n+\n+    /**\n+     * When enqueueing we prefer the in-memory queue unless the file based queue is already utilized. If that fails\n+     * (because it is full) we then enqueue via the file based queue provided it is not currently full and has been\n+     * configured. If the file based queue is full or not configured we block and wait for capacity.\n+     * <p>\n+     * We only write to the file based queue when we have a full batch ready. The batch container is then emptied after\n+     * being written to disk.\n+     */\n+    @Override\n+    public synchronized EnqueueResult enqueue(T message, String key) throws WriteFailedException {\n+        Map.Entry<String, T> msgEntry = new AbstractMap.SimpleImmutableEntry<>(key, message);\n+        \n+        LOG.debug(\"Attempting to enqueue {} with key {} into queue with current size {}\", message, key, getSize());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk5NzAzNQ==", "bodyText": "This method is also used in source code.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r366997035", "createdAt": "2020-01-15T17:06:57Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueue.java", "diffHunk": "@@ -0,0 +1,537 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ForkJoinPool;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.joda.time.Duration;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.squareup.tape2.QueueFile;\n+import com.swrve.ratelimitedlogger.RateLimitedLog;\n+\n+/**\n+ * A {@link DispatchQueue} that first attempts to queue items in memory and upon overflowing the allocated in-memory\n+ * queue writes items \"off heap\" directly to disk via a file. The in-memory queue is volatile and if the process\n+ * crashes its contents are lost. The contents written to disk are durable and in the event of a crash will be reloaded.\n+ * <p>\n+ * This queue can be configured to only queue to memory by specifying the maximum off-heap size of 0. Using this\n+ * configuration causes {@link #enqueue} to block when the in-memory queue fills up rather than writing to the off-heap\n+ * queue.\n+ * <p>\n+ * Before queued items are written to disk they are first accumulated in a batch to limit the number of discrete writes\n+ * we make to disk. The batched items are considered part of the in-memory portion of the queue and are also volatile.\n+ *\n+ * @param <T> the type being queued\n+ */\n+public class QueueFileOffHeapDispatchQueue<T> implements DispatchQueue<T> {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueue.class);\n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n+            .withRateLimit(LOG)\n+            .maxRate(5)\n+            .every(Duration.standardSeconds(30))\n+            .build();\n+\n+    // This must match the size of the HEADER_LENGTH in QueueFile's Element class\n+    //\n+    // We could pull this out of that class reflectively but it seemed easier to just hard code it here\n+    private static final int SERIALIZED_OBJECT_HEADER_SIZE_IN_BYTES = 4;\n+    private static final String FILE_EXTENSION = \".fifo\";\n+\n+    private final Function<T, byte[]> serializer;\n+    private final Function<byte[], T> deserializer;\n+    private final String moduleName;\n+    private final BlockingQueue<Map.Entry<String, T>> inMemoryQueue;\n+\n+    // Note the queue is not thread safe so access should be synchronized\n+    private final QueueFile offHeapQueue;\n+    private final long maxFileSizeInBytes;\n+    private final int batchSize;\n+    private final Batch batch;\n+\n+    private final ForkJoinPool serdesPool = new ForkJoinPool(\n+            Math.max(Runtime.getRuntime().availableProcessors() - 1, 1));\n+\n+    // Used to guard access to the offHeapQueue and batch data structures\n+    private final Object offHeapMutex = new Object();\n+    private final FileCapacityLatch fileCapacityLatch = new FileCapacityLatch();\n+\n+    private final Method usedBytesMethod;\n+\n+    public QueueFileOffHeapDispatchQueue(Function<T, byte[]> serializer, Function<byte[], T> deserializer,\n+                                         String moduleName, Path filePath, int inMemoryQueueSize, int batchSize,\n+                                         long maxFileSizeInBytes) throws IOException {\n+        Objects.requireNonNull(serializer);\n+        Objects.requireNonNull(deserializer);\n+        Objects.requireNonNull(moduleName);\n+\n+        if (inMemoryQueueSize < 1) {\n+            throw new IllegalArgumentException(\"In memory queue size must be greater than 0\");\n+        }\n+\n+        if (inMemoryQueueSize % batchSize != 0) {\n+            throw new IllegalArgumentException(\"In memory queue size must be a multiple of batch size\");\n+        }\n+\n+        if (maxFileSizeInBytes < 0) {\n+            throw new IllegalArgumentException(\"Max file size must be either 0 or a positive integer\");\n+        }\n+\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+        this.moduleName = moduleName;\n+        this.batchSize = batchSize;\n+        this.maxFileSizeInBytes = maxFileSizeInBytes;\n+        batch = new Batch(batchSize);\n+\n+        inMemoryQueue = new ArrayBlockingQueue<>(inMemoryQueueSize, true);\n+\n+        // Setting the max file size to 0 or less will disable the off-heap portion of this queue\n+        if (maxFileSizeInBytes > 0) {\n+            Objects.requireNonNull(filePath);\n+            File file = Paths.get(filePath.toString(), moduleName + FILE_EXTENSION).toFile();\n+\n+            QueueFile qf;\n+            try {\n+                qf = new QueueFile.Builder(file).build();\n+            } catch (Exception e) {\n+                LOG.warn(\"Exception while loading queue file\", e);\n+\n+                if (file.delete()) {\n+                    qf = new QueueFile.Builder(file).build();\n+                } else {\n+                    throw new IOException(\"Could delete corrupted queue file \" + file.getAbsolutePath());\n+                }\n+            }\n+            offHeapQueue = qf;\n+\n+            // QueueFile unfortunately does not expose its file size usage publicly so we need to access it reflectively\n+            try {\n+                usedBytesMethod = offHeapQueue.getClass().getDeclaredMethod(\"usedBytes\");\n+                usedBytesMethod.setAccessible(true);\n+            } catch (NoSuchMethodException e) {\n+                LOG.warn(\"Could not instantiate queue\", e);\n+                throw new RuntimeException(e);\n+            }\n+\n+            checkFileSize();\n+        } else {\n+            offHeapQueue = null;\n+            usedBytesMethod = null;\n+        }\n+    }\n+\n+    @VisibleForTesting", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA1NDUyNw==", "bodyText": "It is also good to have a test case that shows that order is maintained while in the batch. With batch having 100 different messages and getting them back in order.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367054527", "createdAt": "2020-01-15T19:08:17Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/off-heap/src/test/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueueTest.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import static com.jayway.awaitility.Awaitility.await;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.nullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Objects;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+\n+import com.jayway.awaitility.core.ConditionTimeoutException;\n+\n+public class QueueFileOffHeapDispatchQueueTest {\n+\n+    @Rule\n+    public TemporaryFolder folder = new TemporaryFolder();\n+\n+    @Test\n+    public void canQueueAndDequeue() throws IOException, WriteFailedException, InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA2MDA3Nw==", "bodyText": "This should never happen I guess, may be a warning if happens.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367060077", "createdAt": "2020-01-15T19:20:25Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/common/AsyncDispatcherImpl.java", "diffHunk": "@@ -67,226 +65,162 @@\n \n     private static final Logger LOG = LoggerFactory.getLogger(AsyncDispatcherImpl.class);\n     private final SyncDispatcher<S> syncDispatcher;\n-    private OffHeapAdapter offHeapAdapter;\n-    private ExecutorService offHeapAdapterExecutor = Executors.newSingleThreadExecutor();\n     private final AsyncPolicy asyncPolicy;\n-    private OffHeapQueue offHeapQueue;\n-    private SinkModule<S,T> sinkModule;\n-    private DispatcherState<W,S,T> state;\n-    private boolean useOffHeap = false;\n+    private final Counter droppedCounter;\n     \n-    final RateLimitedLog rateLimittedLogger = RateLimitedLog\n+    private final DispatchQueue<S> dispatchQueue;\n+    private final Map<String, CompletableFuture<DispatchStatus>> futureMap = new ConcurrentHashMap<>();\n+    private final AtomicInteger activeDispatchers = new AtomicInteger(0);\n+    \n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n             .withRateLimit(LOG)\n             .maxRate(5).every(Duration.standardSeconds(30))\n             .build();\n \n-    final LinkedBlockingQueue<Runnable> queue;\n-    final ExecutorService executor;\n+    private final ExecutorService executor;\n \n     public AsyncDispatcherImpl(DispatcherState<W, S, T> state, AsyncPolicy asyncPolicy,\n-            SyncDispatcher<S> syncDispatcher) {\n+                               SyncDispatcher<S> syncDispatcher) {\n         Objects.requireNonNull(state);\n         Objects.requireNonNull(asyncPolicy);\n-        this.syncDispatcher = Objects.requireNonNull(syncDispatcher);\n+        Objects.requireNonNull(syncDispatcher);\n+        this.syncDispatcher = syncDispatcher;\n         this.asyncPolicy = asyncPolicy;\n-        this.state = state;\n-        sinkModule = state.getModule();\n-        if (OffHeapServiceLoader.isOffHeapEnabled()) {\n-            offHeapQueue = OffHeapServiceLoader.getOffHeapQueue();\n-            if (offHeapQueue != null) {\n-                useOffHeap = true;\n-                LOG.info(\"Offheap storage enabled for sink module, {}\", sinkModule.getId());\n-            }\n-        }\n-        \n-        final RejectedExecutionHandler rejectedExecutionHandler;\n-        if (asyncPolicy.isBlockWhenFull()) {\n-            // This queue ensures that calling thread is blocked when the queue is full\n-            // See the implementation of OfferBlockingQueue for details\n-            queue = new OfferBlockingQueue<>(asyncPolicy.getQueueSize());\n-            rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();\n+        SinkModule<S, T> sinkModule = state.getModule();\n+        Optional<DispatchQueueFactory> factory = DispatchQueueServiceLoader.getDispatchQueueFactory();\n+\n+        if (factory.isPresent()) {\n+            LOG.debug(\"Using queue from factory\");\n+            dispatchQueue = factory.get().getQueue(asyncPolicy, sinkModule.getId(),\n+                    sinkModule::marshalSingleMessage, sinkModule::unmarshalSingleMessage);\n         } else {\n-            queue = new LinkedBlockingQueue<Runnable>(asyncPolicy.getQueueSize());\n-            // Reject and increase the dropped counter when the queue is full\n-            final Counter droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n-            rejectedExecutionHandler = new RejectedExecutionHandler() {\n-                @Override\n-                public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n-                    droppedCounter.inc();\n-                    throw new RejectedExecutionException(\"Task \" + r.toString() +\n-                            \" rejected from \" +\n-                            e.toString());\n-                }\n-            };\n+            int size = asyncPolicy.getQueueSize();\n+            LOG.debug(\"Using default in memory queue of size {}\", size);\n+            dispatchQueue = new DefaultQueue<>(size);\n         }\n \n-        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"), new Gauge<Integer>() {\n-            @Override\n-            public Integer getValue() {\n-                return queue.size();\n-            }\n-        });\n+        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"),\n+                (Gauge<Integer>) activeDispatchers::get);\n+\n+        droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n \n-        executor = new ThreadPoolExecutor(\n-                asyncPolicy.getNumThreads(),\n-                asyncPolicy.getNumThreads(),\n-                1000L,\n-                TimeUnit.MILLISECONDS,\n-                queue,\n-                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" + state.getModule().getId(), Integer.MAX_VALUE),\n-                rejectedExecutionHandler\n-            );\n+        executor = Executors.newFixedThreadPool(asyncPolicy.getNumThreads(),\n+                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" +\n+                        state.getModule().getId(), Integer.MAX_VALUE));\n+        startDrainingQueue();\n     }\n \n-    /**\n-     * When used in a ThreadPoolExecutor, this queue will block calls to\n-     * {@link ThreadPoolExecutor#execute(Runnable)} when the queue is full.\n-     * This is done by overriding calls to {@link LinkedBlockingQueue#offer(Object)}\n-     * with calls to {@link LinkedBlockingQueue#put(Object)}, but comes with the caveat\n-     * that executor must be built with <code>corePoolSize == maxPoolSize</code>.\n-     * In the context of the {@link AsyncDispatcherImpl}, this is an acceptable caveat,\n-     * since we enforce the matching pool sizes.\n-     *\n-     * There are alternative ways of solving this problem, for example we could use a\n-     * {@link RejectedExecutionHandler} to achieve similar behavior, and allow\n-     * for <code>corePoolSize < maxPoolSize</code>, but not for <code>corePoolSize==0</code>.\n-     *\n-     * For further discussions on this topic see:\n-     *   http://stackoverflow.com/a/3518588\n-     *   http://stackoverflow.com/a/32123535\n-     *\n-     * If the implementation is changed, make sure that that executor is built accordingly.\n-     */\n-    \n-    private static class OfferBlockingQueue<E> extends LinkedBlockingQueue<E> {\n-        private static final long serialVersionUID = 1L;\n+    private void dispatchFromQueue() {\n+        while (true) {\n+            try {\n+                LOG.trace(\"Asking dispatch queue for the next entry...\");\n+                Map.Entry<String, S> messageEntry = dispatchQueue.dequeue();\n+                LOG.trace(\"Received message entry from dispatch queue {}\", messageEntry);\n+                activeDispatchers.incrementAndGet();\n+                LOG.trace(\"Sending message {} via sync dispatcher\", messageEntry);\n+                syncDispatcher.send(messageEntry.getValue());\n+                LOG.trace(\"Successfully sent message {}\", messageEntry);\n+\n+                if (messageEntry.getKey() != null) {\n+                    LOG.trace(\"Attempting to complete future for message {}\", messageEntry);\n+                    CompletableFuture<DispatchStatus> messageFuture = futureMap.remove(messageEntry.getKey());\n+\n+                    if (messageFuture != null) {\n+                        messageFuture.complete(DispatchStatus.DISPATCHED);\n+                        LOG.trace(\"Completed future for message {}\", messageEntry);\n+                    } else {\n+                        RATE_LIMITED_LOGGER.warn(\"No future found for message {}\", messageEntry);\n+                    }\n+                } else {\n+                    LOG.trace(\"Dequeued an entry with a null key\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA3NTc4NA==", "bodyText": "may be add newId here in the message or put it in RATE_LIMITED_LOGGER", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367075784", "createdAt": "2020-01-15T19:54:13Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/common/AsyncDispatcherImpl.java", "diffHunk": "@@ -67,226 +65,162 @@\n \n     private static final Logger LOG = LoggerFactory.getLogger(AsyncDispatcherImpl.class);\n     private final SyncDispatcher<S> syncDispatcher;\n-    private OffHeapAdapter offHeapAdapter;\n-    private ExecutorService offHeapAdapterExecutor = Executors.newSingleThreadExecutor();\n     private final AsyncPolicy asyncPolicy;\n-    private OffHeapQueue offHeapQueue;\n-    private SinkModule<S,T> sinkModule;\n-    private DispatcherState<W,S,T> state;\n-    private boolean useOffHeap = false;\n+    private final Counter droppedCounter;\n     \n-    final RateLimitedLog rateLimittedLogger = RateLimitedLog\n+    private final DispatchQueue<S> dispatchQueue;\n+    private final Map<String, CompletableFuture<DispatchStatus>> futureMap = new ConcurrentHashMap<>();\n+    private final AtomicInteger activeDispatchers = new AtomicInteger(0);\n+    \n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n             .withRateLimit(LOG)\n             .maxRate(5).every(Duration.standardSeconds(30))\n             .build();\n \n-    final LinkedBlockingQueue<Runnable> queue;\n-    final ExecutorService executor;\n+    private final ExecutorService executor;\n \n     public AsyncDispatcherImpl(DispatcherState<W, S, T> state, AsyncPolicy asyncPolicy,\n-            SyncDispatcher<S> syncDispatcher) {\n+                               SyncDispatcher<S> syncDispatcher) {\n         Objects.requireNonNull(state);\n         Objects.requireNonNull(asyncPolicy);\n-        this.syncDispatcher = Objects.requireNonNull(syncDispatcher);\n+        Objects.requireNonNull(syncDispatcher);\n+        this.syncDispatcher = syncDispatcher;\n         this.asyncPolicy = asyncPolicy;\n-        this.state = state;\n-        sinkModule = state.getModule();\n-        if (OffHeapServiceLoader.isOffHeapEnabled()) {\n-            offHeapQueue = OffHeapServiceLoader.getOffHeapQueue();\n-            if (offHeapQueue != null) {\n-                useOffHeap = true;\n-                LOG.info(\"Offheap storage enabled for sink module, {}\", sinkModule.getId());\n-            }\n-        }\n-        \n-        final RejectedExecutionHandler rejectedExecutionHandler;\n-        if (asyncPolicy.isBlockWhenFull()) {\n-            // This queue ensures that calling thread is blocked when the queue is full\n-            // See the implementation of OfferBlockingQueue for details\n-            queue = new OfferBlockingQueue<>(asyncPolicy.getQueueSize());\n-            rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();\n+        SinkModule<S, T> sinkModule = state.getModule();\n+        Optional<DispatchQueueFactory> factory = DispatchQueueServiceLoader.getDispatchQueueFactory();\n+\n+        if (factory.isPresent()) {\n+            LOG.debug(\"Using queue from factory\");\n+            dispatchQueue = factory.get().getQueue(asyncPolicy, sinkModule.getId(),\n+                    sinkModule::marshalSingleMessage, sinkModule::unmarshalSingleMessage);\n         } else {\n-            queue = new LinkedBlockingQueue<Runnable>(asyncPolicy.getQueueSize());\n-            // Reject and increase the dropped counter when the queue is full\n-            final Counter droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n-            rejectedExecutionHandler = new RejectedExecutionHandler() {\n-                @Override\n-                public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n-                    droppedCounter.inc();\n-                    throw new RejectedExecutionException(\"Task \" + r.toString() +\n-                            \" rejected from \" +\n-                            e.toString());\n-                }\n-            };\n+            int size = asyncPolicy.getQueueSize();\n+            LOG.debug(\"Using default in memory queue of size {}\", size);\n+            dispatchQueue = new DefaultQueue<>(size);\n         }\n \n-        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"), new Gauge<Integer>() {\n-            @Override\n-            public Integer getValue() {\n-                return queue.size();\n-            }\n-        });\n+        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"),\n+                (Gauge<Integer>) activeDispatchers::get);\n+\n+        droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n \n-        executor = new ThreadPoolExecutor(\n-                asyncPolicy.getNumThreads(),\n-                asyncPolicy.getNumThreads(),\n-                1000L,\n-                TimeUnit.MILLISECONDS,\n-                queue,\n-                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" + state.getModule().getId(), Integer.MAX_VALUE),\n-                rejectedExecutionHandler\n-            );\n+        executor = Executors.newFixedThreadPool(asyncPolicy.getNumThreads(),\n+                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" +\n+                        state.getModule().getId(), Integer.MAX_VALUE));\n+        startDrainingQueue();\n     }\n \n-    /**\n-     * When used in a ThreadPoolExecutor, this queue will block calls to\n-     * {@link ThreadPoolExecutor#execute(Runnable)} when the queue is full.\n-     * This is done by overriding calls to {@link LinkedBlockingQueue#offer(Object)}\n-     * with calls to {@link LinkedBlockingQueue#put(Object)}, but comes with the caveat\n-     * that executor must be built with <code>corePoolSize == maxPoolSize</code>.\n-     * In the context of the {@link AsyncDispatcherImpl}, this is an acceptable caveat,\n-     * since we enforce the matching pool sizes.\n-     *\n-     * There are alternative ways of solving this problem, for example we could use a\n-     * {@link RejectedExecutionHandler} to achieve similar behavior, and allow\n-     * for <code>corePoolSize < maxPoolSize</code>, but not for <code>corePoolSize==0</code>.\n-     *\n-     * For further discussions on this topic see:\n-     *   http://stackoverflow.com/a/3518588\n-     *   http://stackoverflow.com/a/32123535\n-     *\n-     * If the implementation is changed, make sure that that executor is built accordingly.\n-     */\n-    \n-    private static class OfferBlockingQueue<E> extends LinkedBlockingQueue<E> {\n-        private static final long serialVersionUID = 1L;\n+    private void dispatchFromQueue() {\n+        while (true) {\n+            try {\n+                LOG.trace(\"Asking dispatch queue for the next entry...\");\n+                Map.Entry<String, S> messageEntry = dispatchQueue.dequeue();\n+                LOG.trace(\"Received message entry from dispatch queue {}\", messageEntry);\n+                activeDispatchers.incrementAndGet();\n+                LOG.trace(\"Sending message {} via sync dispatcher\", messageEntry);\n+                syncDispatcher.send(messageEntry.getValue());\n+                LOG.trace(\"Successfully sent message {}\", messageEntry);\n+\n+                if (messageEntry.getKey() != null) {\n+                    LOG.trace(\"Attempting to complete future for message {}\", messageEntry);\n+                    CompletableFuture<DispatchStatus> messageFuture = futureMap.remove(messageEntry.getKey());\n+\n+                    if (messageFuture != null) {\n+                        messageFuture.complete(DispatchStatus.DISPATCHED);\n+                        LOG.trace(\"Completed future for message {}\", messageEntry);\n+                    } else {\n+                        RATE_LIMITED_LOGGER.warn(\"No future found for message {}\", messageEntry);\n+                    }\n+                } else {\n+                    LOG.trace(\"Dequeued an entry with a null key\");\n+                }\n \n-        public OfferBlockingQueue(int capacity) {\n-            super(capacity);\n+                activeDispatchers.decrementAndGet();\n+            } catch (InterruptedException e) {\n+                break;\n+            } catch (Exception e) {\n+                RATE_LIMITED_LOGGER.warn(\"Encountered exception while taking from dispatch queue\", e);\n+            }\n         }\n+    }\n \n-        @Override\n-        public boolean offer(E e) {\n-            try {\n-                put(e);\n-                return true;\n-            } catch (InterruptedException ie) {\n-                Thread.currentThread().interrupt();\n-            }\n-            return false;\n+    private void startDrainingQueue() {\n+        for (int i = 0; i < asyncPolicy.getNumThreads(); i++) {\n+            executor.execute(this::dispatchFromQueue);\n         }\n     }\n \n     @Override\n-    public CompletableFuture<S> send(S message) {\n-         \n-        // Check if OffHeap is enabled and if local queue is full or if OffHeap not Empty then write message to OffHeap.\n-        if (useOffHeap && (asyncPolicy.getQueueSize() == getQueueSize() ||\n-                ((offHeapAdapter != null) && !offHeapAdapter.isOffHeapEmpty()))) {\n-            // Start drain thread before the first write to OffHeapQueue.\n-            if (offHeapAdapter == null) {\n-                this.offHeapAdapter = new OffHeapAdapter();\n-                offHeapAdapterExecutor.execute(offHeapAdapter);\n-                LOG.info(\"started drain thread for {}\", sinkModule.getId());\n-            }\n-            try {\n-                return offHeapAdapter.writeMessage(message);\n-            } catch (WriteFailedException e) {\n-                rateLimittedLogger.error(\"OffHeap write failed \", e);\n-            }\n+    public CompletableFuture<DispatchStatus> send(S message) {\n+        CompletableFuture<DispatchStatus> sendFuture = new CompletableFuture<>();\n+\n+        if (!asyncPolicy.isBlockWhenFull() && dispatchQueue.isFull()) {\n+            droppedCounter.inc();\n+            sendFuture.completeExceptionally(new RuntimeException(\"Dispatch queue full\"));\n+            return sendFuture;\n         }\n+\n         try {\n-            return CompletableFuture.supplyAsync(() -> {\n-                syncDispatcher.send(message);\n-                return message;\n-            }, executor);\n-        } catch (RejectedExecutionException ree) {\n-            final CompletableFuture<S> future = new CompletableFuture<>();\n-            future.completeExceptionally(ree);\n-            return future;\n+            String newId = UUID.randomUUID().toString();\n+            DispatchQueue.EnqueueResult result = dispatchQueue.enqueue(message, newId);\n+            \n+            LOG.trace(\"Result of enqueueing was {}\", result);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA3NjgxOA==", "bodyText": "since the message could be large, put these traces  under if(LOG.isTraceEnabled) or remove the message from the log.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367076818", "createdAt": "2020-01-15T19:56:25Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/common/AsyncDispatcherImpl.java", "diffHunk": "@@ -67,226 +65,162 @@\n \n     private static final Logger LOG = LoggerFactory.getLogger(AsyncDispatcherImpl.class);\n     private final SyncDispatcher<S> syncDispatcher;\n-    private OffHeapAdapter offHeapAdapter;\n-    private ExecutorService offHeapAdapterExecutor = Executors.newSingleThreadExecutor();\n     private final AsyncPolicy asyncPolicy;\n-    private OffHeapQueue offHeapQueue;\n-    private SinkModule<S,T> sinkModule;\n-    private DispatcherState<W,S,T> state;\n-    private boolean useOffHeap = false;\n+    private final Counter droppedCounter;\n     \n-    final RateLimitedLog rateLimittedLogger = RateLimitedLog\n+    private final DispatchQueue<S> dispatchQueue;\n+    private final Map<String, CompletableFuture<DispatchStatus>> futureMap = new ConcurrentHashMap<>();\n+    private final AtomicInteger activeDispatchers = new AtomicInteger(0);\n+    \n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n             .withRateLimit(LOG)\n             .maxRate(5).every(Duration.standardSeconds(30))\n             .build();\n \n-    final LinkedBlockingQueue<Runnable> queue;\n-    final ExecutorService executor;\n+    private final ExecutorService executor;\n \n     public AsyncDispatcherImpl(DispatcherState<W, S, T> state, AsyncPolicy asyncPolicy,\n-            SyncDispatcher<S> syncDispatcher) {\n+                               SyncDispatcher<S> syncDispatcher) {\n         Objects.requireNonNull(state);\n         Objects.requireNonNull(asyncPolicy);\n-        this.syncDispatcher = Objects.requireNonNull(syncDispatcher);\n+        Objects.requireNonNull(syncDispatcher);\n+        this.syncDispatcher = syncDispatcher;\n         this.asyncPolicy = asyncPolicy;\n-        this.state = state;\n-        sinkModule = state.getModule();\n-        if (OffHeapServiceLoader.isOffHeapEnabled()) {\n-            offHeapQueue = OffHeapServiceLoader.getOffHeapQueue();\n-            if (offHeapQueue != null) {\n-                useOffHeap = true;\n-                LOG.info(\"Offheap storage enabled for sink module, {}\", sinkModule.getId());\n-            }\n-        }\n-        \n-        final RejectedExecutionHandler rejectedExecutionHandler;\n-        if (asyncPolicy.isBlockWhenFull()) {\n-            // This queue ensures that calling thread is blocked when the queue is full\n-            // See the implementation of OfferBlockingQueue for details\n-            queue = new OfferBlockingQueue<>(asyncPolicy.getQueueSize());\n-            rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();\n+        SinkModule<S, T> sinkModule = state.getModule();\n+        Optional<DispatchQueueFactory> factory = DispatchQueueServiceLoader.getDispatchQueueFactory();\n+\n+        if (factory.isPresent()) {\n+            LOG.debug(\"Using queue from factory\");\n+            dispatchQueue = factory.get().getQueue(asyncPolicy, sinkModule.getId(),\n+                    sinkModule::marshalSingleMessage, sinkModule::unmarshalSingleMessage);\n         } else {\n-            queue = new LinkedBlockingQueue<Runnable>(asyncPolicy.getQueueSize());\n-            // Reject and increase the dropped counter when the queue is full\n-            final Counter droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n-            rejectedExecutionHandler = new RejectedExecutionHandler() {\n-                @Override\n-                public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n-                    droppedCounter.inc();\n-                    throw new RejectedExecutionException(\"Task \" + r.toString() +\n-                            \" rejected from \" +\n-                            e.toString());\n-                }\n-            };\n+            int size = asyncPolicy.getQueueSize();\n+            LOG.debug(\"Using default in memory queue of size {}\", size);\n+            dispatchQueue = new DefaultQueue<>(size);\n         }\n \n-        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"), new Gauge<Integer>() {\n-            @Override\n-            public Integer getValue() {\n-                return queue.size();\n-            }\n-        });\n+        state.getMetrics().register(MetricRegistry.name(state.getModule().getId(), \"queue-size\"),\n+                (Gauge<Integer>) activeDispatchers::get);\n+\n+        droppedCounter = state.getMetrics().counter(MetricRegistry.name(state.getModule().getId(), \"dropped\"));\n \n-        executor = new ThreadPoolExecutor(\n-                asyncPolicy.getNumThreads(),\n-                asyncPolicy.getNumThreads(),\n-                1000L,\n-                TimeUnit.MILLISECONDS,\n-                queue,\n-                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" + state.getModule().getId(), Integer.MAX_VALUE),\n-                rejectedExecutionHandler\n-            );\n+        executor = Executors.newFixedThreadPool(asyncPolicy.getNumThreads(),\n+                new LogPreservingThreadFactory(SystemInfoUtils.DEFAULT_INSTANCE_ID + \".Sink.AsyncDispatcher.\" +\n+                        state.getModule().getId(), Integer.MAX_VALUE));\n+        startDrainingQueue();\n     }\n \n-    /**\n-     * When used in a ThreadPoolExecutor, this queue will block calls to\n-     * {@link ThreadPoolExecutor#execute(Runnable)} when the queue is full.\n-     * This is done by overriding calls to {@link LinkedBlockingQueue#offer(Object)}\n-     * with calls to {@link LinkedBlockingQueue#put(Object)}, but comes with the caveat\n-     * that executor must be built with <code>corePoolSize == maxPoolSize</code>.\n-     * In the context of the {@link AsyncDispatcherImpl}, this is an acceptable caveat,\n-     * since we enforce the matching pool sizes.\n-     *\n-     * There are alternative ways of solving this problem, for example we could use a\n-     * {@link RejectedExecutionHandler} to achieve similar behavior, and allow\n-     * for <code>corePoolSize < maxPoolSize</code>, but not for <code>corePoolSize==0</code>.\n-     *\n-     * For further discussions on this topic see:\n-     *   http://stackoverflow.com/a/3518588\n-     *   http://stackoverflow.com/a/32123535\n-     *\n-     * If the implementation is changed, make sure that that executor is built accordingly.\n-     */\n-    \n-    private static class OfferBlockingQueue<E> extends LinkedBlockingQueue<E> {\n-        private static final long serialVersionUID = 1L;\n+    private void dispatchFromQueue() {\n+        while (true) {\n+            try {\n+                LOG.trace(\"Asking dispatch queue for the next entry...\");\n+                Map.Entry<String, S> messageEntry = dispatchQueue.dequeue();\n+                LOG.trace(\"Received message entry from dispatch queue {}\", messageEntry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA4NjMxNA==", "bodyText": "We should probably add a note saying that this file size is per module.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367086314", "createdAt": "2020-01-15T20:17:55Z", "author": {"login": "cgorantla"}, "path": "opennms-doc/guide-admin/src/asciidoc/text/minion/offheap.adoc", "diffHunk": "@@ -3,35 +3,31 @@\n \n === Using Off-heap Storage for Sink Messages\n \n-If a _Minion_ loses connectivity with the broker (i.e. _Kafka_ or _ActiveMQ_), then any received messages (i.e. syslog, flows, SNMP traps) are queued in the JVM heap until connectivity is restored.\n-This queue is limited by a fixed (and configurable) number of messages.\n+If a _Minion_ loses connectivity with the broker (i.e. _Kafka_ or _ActiveMQ_), then any received messages (i.e. syslog, flows, SNMP traps) are queued until connectivity is restored.\n+This queue is limited by a fixed (and configurable) number of messages queued in the JVM heap and can optionally queue\n+additional messages by persisting directly to the filesystem avoiding heap memory usage.\n Once the queue is full, additional messages will be dropped.\n \n The off-heap storage feature allows us to extend the storage capacity by queuing messages outside of the JVM heap.\n \n-NOTE: The current implementation of the off-heap storage supports storing messages in the system memory outside of the heap.\n-      No file-system based storage is currently support.\n-\n ==== Configuring Off-heap Storage\n \n-Install off-heap feature on _Minion_:\n+Configure storage limits:\n \n [source, sh]\n ----\n-echo 'opennms-core-ipc-sink-offheap' >> \"$MINION_HOME/etc/featuresBoot.d/features.boot\"\n+echo 'offHeapSize = 1GB\n+entriesAllowedOnHeap = 100000\n+offHeapFilePath =' > \"$MINION_HOME/etc/org.opennms.core.ipc.sink.offheap.cfg\"\n ----", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTMzODA1", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-343533805", "createdAt": "2020-01-15T21:29:27Z", "commit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMToyOToyN1rOFeHCAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMToyOToyN1rOFeHCAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExNjgwMw==", "bodyText": "I'm not sure if I understand this code completely.   If there is only one thread that does dequeue the order should be maintained. Would like to see a test case.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r367116803", "createdAt": "2020-01-15T21:29:27Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueue.java", "diffHunk": "@@ -0,0 +1,537 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ForkJoinPool;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.joda.time.Duration;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.squareup.tape2.QueueFile;\n+import com.swrve.ratelimitedlogger.RateLimitedLog;\n+\n+/**\n+ * A {@link DispatchQueue} that first attempts to queue items in memory and upon overflowing the allocated in-memory\n+ * queue writes items \"off heap\" directly to disk via a file. The in-memory queue is volatile and if the process\n+ * crashes its contents are lost. The contents written to disk are durable and in the event of a crash will be reloaded.\n+ * <p>\n+ * This queue can be configured to only queue to memory by specifying the maximum off-heap size of 0. Using this\n+ * configuration causes {@link #enqueue} to block when the in-memory queue fills up rather than writing to the off-heap\n+ * queue.\n+ * <p>\n+ * Before queued items are written to disk they are first accumulated in a batch to limit the number of discrete writes\n+ * we make to disk. The batched items are considered part of the in-memory portion of the queue and are also volatile.\n+ *\n+ * @param <T> the type being queued\n+ */\n+public class QueueFileOffHeapDispatchQueue<T> implements DispatchQueue<T> {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueue.class);\n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n+            .withRateLimit(LOG)\n+            .maxRate(5)\n+            .every(Duration.standardSeconds(30))\n+            .build();\n+\n+    // This must match the size of the HEADER_LENGTH in QueueFile's Element class\n+    //\n+    // We could pull this out of that class reflectively but it seemed easier to just hard code it here\n+    private static final int SERIALIZED_OBJECT_HEADER_SIZE_IN_BYTES = 4;\n+    private static final String FILE_EXTENSION = \".fifo\";\n+\n+    private final Function<T, byte[]> serializer;\n+    private final Function<byte[], T> deserializer;\n+    private final String moduleName;\n+    private final BlockingQueue<Map.Entry<String, T>> inMemoryQueue;\n+\n+    // Note the queue is not thread safe so access should be synchronized\n+    private final QueueFile offHeapQueue;\n+    private final long maxFileSizeInBytes;\n+    private final int batchSize;\n+    private final Batch batch;\n+\n+    private final ForkJoinPool serdesPool = new ForkJoinPool(\n+            Math.max(Runtime.getRuntime().availableProcessors() - 1, 1));\n+\n+    // Used to guard access to the offHeapQueue and batch data structures\n+    private final Object offHeapMutex = new Object();\n+    private final FileCapacityLatch fileCapacityLatch = new FileCapacityLatch();\n+\n+    private final Method usedBytesMethod;\n+\n+    public QueueFileOffHeapDispatchQueue(Function<T, byte[]> serializer, Function<byte[], T> deserializer,\n+                                         String moduleName, Path filePath, int inMemoryQueueSize, int batchSize,\n+                                         long maxFileSizeInBytes) throws IOException {\n+        Objects.requireNonNull(serializer);\n+        Objects.requireNonNull(deserializer);\n+        Objects.requireNonNull(moduleName);\n+\n+        if (inMemoryQueueSize < 1) {\n+            throw new IllegalArgumentException(\"In memory queue size must be greater than 0\");\n+        }\n+\n+        if (inMemoryQueueSize % batchSize != 0) {\n+            throw new IllegalArgumentException(\"In memory queue size must be a multiple of batch size\");\n+        }\n+\n+        if (maxFileSizeInBytes < 0) {\n+            throw new IllegalArgumentException(\"Max file size must be either 0 or a positive integer\");\n+        }\n+\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+        this.moduleName = moduleName;\n+        this.batchSize = batchSize;\n+        this.maxFileSizeInBytes = maxFileSizeInBytes;\n+        batch = new Batch(batchSize);\n+\n+        inMemoryQueue = new ArrayBlockingQueue<>(inMemoryQueueSize, true);\n+\n+        // Setting the max file size to 0 or less will disable the off-heap portion of this queue\n+        if (maxFileSizeInBytes > 0) {\n+            Objects.requireNonNull(filePath);\n+            File file = Paths.get(filePath.toString(), moduleName + FILE_EXTENSION).toFile();\n+\n+            QueueFile qf;\n+            try {\n+                qf = new QueueFile.Builder(file).build();\n+            } catch (Exception e) {\n+                LOG.warn(\"Exception while loading queue file\", e);\n+\n+                if (file.delete()) {\n+                    qf = new QueueFile.Builder(file).build();\n+                } else {\n+                    throw new IOException(\"Could delete corrupted queue file \" + file.getAbsolutePath());\n+                }\n+            }\n+            offHeapQueue = qf;\n+\n+            // QueueFile unfortunately does not expose its file size usage publicly so we need to access it reflectively\n+            try {\n+                usedBytesMethod = offHeapQueue.getClass().getDeclaredMethod(\"usedBytes\");\n+                usedBytesMethod.setAccessible(true);\n+            } catch (NoSuchMethodException e) {\n+                LOG.warn(\"Could not instantiate queue\", e);\n+                throw new RuntimeException(e);\n+            }\n+\n+            checkFileSize();\n+        } else {\n+            offHeapQueue = null;\n+            usedBytesMethod = null;\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public long checkFileSize() {\n+        try {\n+            long fileSize = (long) usedBytesMethod.invoke(offHeapQueue);\n+            fileCapacityLatch.setCurrentCapacityBytes(maxFileSizeInBytes - fileSize);\n+            LOG.trace(\"Checked file size for module {} and got result {} bytes\", moduleName,\n+                    fileSize);\n+\n+            return fileSize;\n+        } catch (IllegalAccessException | InvocationTargetException e) {\n+            RATE_LIMITED_LOGGER.warn(\"Failed to check file size for module {}\", moduleName, e);\n+            return 0;\n+        }\n+    }\n+\n+    /**\n+     * When enqueueing we prefer the in-memory queue unless the file based queue is already utilized. If that fails\n+     * (because it is full) we then enqueue via the file based queue provided it is not currently full and has been\n+     * configured. If the file based queue is full or not configured we block and wait for capacity.\n+     * <p>\n+     * We only write to the file based queue when we have a full batch ready. The batch container is then emptied after\n+     * being written to disk.\n+     */\n+    @Override\n+    public synchronized EnqueueResult enqueue(T message, String key) throws WriteFailedException {\n+        Map.Entry<String, T> msgEntry = new AbstractMap.SimpleImmutableEntry<>(key, message);\n+        \n+        LOG.debug(\"Attempting to enqueue {} with key {} into queue with current size {}\", message, key, getSize());\n+\n+        // Off-heap queueing is not enabled so queue directly to memory\n+        if (offHeapQueue == null) {\n+            LOG.trace(\"Enqueueing {} with key {} in-memory since there is no off-heap queue \" +\n+                    \"configured\", message, key);\n+\n+            try {\n+                inMemoryQueue.put(msgEntry);\n+            } catch (InterruptedException e) {\n+                throw new WriteFailedException(e);\n+            }\n+\n+            return EnqueueResult.IMMEDIATE;\n+        }\n+\n+        // Off-heap queueing is enabled but we haven't started using it yet so continue trying to fill the in-memory\n+        // queue\n+        int size = 0;\n+        byte[] serializedBatch = null;\n+        synchronized (offHeapMutex) {\n+            if (offHeapQueue.size() <= 0 && batch.isEmpty()) {\n+                // If the in-memory queue is full, this offer will fail and we will fall through below to the off-heap\n+                // queueing logic\n+                boolean inMemoryQueueHadSpace = inMemoryQueue.offer(msgEntry);\n+\n+                if (inMemoryQueueHadSpace) {\n+                    LOG.trace(\"Enqueueing {} with key {} in-memory\", message, key);\n+\n+                    return EnqueueResult.IMMEDIATE;\n+                }\n+            }\n+\n+            // The in-memory queue is either full or there is already message in the batch or off-heap so we continue to\n+            // batch\n+            LOG.trace(\"Batching message {} with key {} for off-heap queue\", message, key);\n+            batch.add(message);\n+\n+            if (batch.isFull()) {\n+                LOG.trace(\"Flushing batch off-heap\");\n+\n+                try {\n+                    serializedBatch = batch.toSerializedBatchAndClear();\n+                } catch (Exception e) {\n+                    RATE_LIMITED_LOGGER.warn(\"Failed to flush to off-heap\", e);\n+                    throw new WriteFailedException(e);\n+                }\n+\n+                size = serializedBatch.length + SERIALIZED_OBJECT_HEADER_SIZE_IN_BYTES;\n+                fileCapacityLatch.markFlushNeeded();\n+            }\n+        }\n+\n+        if (serializedBatch != null) {\n+            try {\n+                // This is a critical blocking call and it has to be done outside the context of any shared lock with\n+                // dequeue() otherwise it will cause a deadlock\n+                //\n+                // After unblocking we will pick up the lock again and double check that we still need to flush and then\n+                // perform that while holding the lock\n+                fileCapacityLatch.waitForCapacity(size);\n+\n+                synchronized (offHeapMutex) {\n+                    if (!fileCapacityLatch.isFlushNeeded()) {\n+                        return EnqueueResult.DEFERRED;\n+                    }\n+\n+                    try {\n+                        offHeapQueue.add(serializedBatch);\n+\n+                        // Since we just wrote to disk, we need to check the file again to record the current capacity\n+                        checkFileSize();\n+                    } catch (IOException e) {\n+                        throw new WriteFailedException(e);\n+                    }\n+                }\n+            } catch (InterruptedException e) {\n+                throw new WriteFailedException(e);\n+            }\n+        }\n+\n+        return EnqueueResult.DEFERRED;\n+    }\n+\n+    /**\n+     * On every call to dequeue, if the off-heap queue is configured, we check the file for an entry and drain it to the\n+     * in-memory queue provided there is room. We then take exclusively from the head of the in-memory queue which\n+     * ensures ordering with respect to the two discrete queues.\n+     * <p>\n+     * After completely draining the queue on disk we check the existing batch for entries and drain them next.\n+     */\n+    @Override\n+    public Map.Entry<String, T> dequeue() throws InterruptedException {\n+        LOG.debug(\"Dequeueing an entry from queue with current size {}\", getSize());\n+\n+        // If off-heap queueing is enabled we need to first check if there is anything to read off-heap\n+        if (offHeapQueue != null) {\n+            synchronized (offHeapMutex) {\n+                // Try to move a batch from the off-heap queue to the in-memory queue\n+                if (offHeapQueue.size() > 0 && inMemoryQueue.remainingCapacity() >= batchSize) {\n+                    LOG.trace(\"Found an entry off-heap and there was room in-memory, moving it\");\n+\n+                    try {\n+                        byte[] entry = offHeapQueue.peek();\n+                        if (entry != null) {\n+                            offHeapQueue.remove();\n+\n+                            try {\n+                                inMemoryQueue.addAll(unbatchSerializedBatch(new SerializedBatch(entry)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825b2d49ad85ad7a650161eafa1b2a5bb1fbd5c"}, "originalPosition": 312}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b424e9d8cf5a5f7382156af82ec97d506d292340", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/b424e9d8cf5a5f7382156af82ec97d506d292340", "committedDate": "2020-01-16T01:19:59Z", "message": "More review feedback"}, "afterCommit": {"oid": "3d612385a83e66958c518f69cb1e2f98af480271", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/3d612385a83e66958c518f69cb1e2f98af480271", "committedDate": "2020-01-17T18:50:25Z", "message": "Initial version of testms generated by JHipster-6.6.0 with blueprints: kotlin-1.4.0"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3d612385a83e66958c518f69cb1e2f98af480271", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/3d612385a83e66958c518f69cb1e2f98af480271", "committedDate": "2020-01-17T18:50:25Z", "message": "Initial version of testms generated by JHipster-6.6.0 with blueprints: kotlin-1.4.0"}, "afterCommit": {"oid": "d13a046b32568f268530975b096936ee35afe84d", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/d13a046b32568f268530975b096936ee35afe84d", "committedDate": "2020-01-17T20:39:22Z", "message": "Additional test case to test production/consumption in parallel on separate threads"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0ODg2MjY5", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-344886269", "createdAt": "2020-01-17T23:01:53Z", "commit": {"oid": "d13a046b32568f268530975b096936ee35afe84d"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMzowMTo1M1rOFfHZJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMzowMzoyOFrOFfHakA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3MTMwMw==", "bodyText": "Consider using asyncPolicy.getQueueSize() as the default inMemoryQueueSize for the specific module. We can extend AsyncPolicy to set offHeapSize then everything is associated with module", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r368171303", "createdAt": "2020-01-17T23:01:53Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/common/AsyncDispatcherImpl.java", "diffHunk": "@@ -67,226 +65,162 @@\n \n     private static final Logger LOG = LoggerFactory.getLogger(AsyncDispatcherImpl.class);\n     private final SyncDispatcher<S> syncDispatcher;\n-    private OffHeapAdapter offHeapAdapter;\n-    private ExecutorService offHeapAdapterExecutor = Executors.newSingleThreadExecutor();\n     private final AsyncPolicy asyncPolicy;\n-    private OffHeapQueue offHeapQueue;\n-    private SinkModule<S,T> sinkModule;\n-    private DispatcherState<W,S,T> state;\n-    private boolean useOffHeap = false;\n+    private final Counter droppedCounter;\n     \n-    final RateLimitedLog rateLimittedLogger = RateLimitedLog\n+    private final DispatchQueue<S> dispatchQueue;\n+    private final Map<String, CompletableFuture<DispatchStatus>> futureMap = new ConcurrentHashMap<>();\n+    private final AtomicInteger activeDispatchers = new AtomicInteger(0);\n+    \n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n             .withRateLimit(LOG)\n             .maxRate(5).every(Duration.standardSeconds(30))\n             .build();\n \n-    final LinkedBlockingQueue<Runnable> queue;\n-    final ExecutorService executor;\n+    private final ExecutorService executor;\n \n     public AsyncDispatcherImpl(DispatcherState<W, S, T> state, AsyncPolicy asyncPolicy,\n-            SyncDispatcher<S> syncDispatcher) {\n+                               SyncDispatcher<S> syncDispatcher) {\n         Objects.requireNonNull(state);\n         Objects.requireNonNull(asyncPolicy);\n-        this.syncDispatcher = Objects.requireNonNull(syncDispatcher);\n+        Objects.requireNonNull(syncDispatcher);\n+        this.syncDispatcher = syncDispatcher;\n         this.asyncPolicy = asyncPolicy;\n-        this.state = state;\n-        sinkModule = state.getModule();\n-        if (OffHeapServiceLoader.isOffHeapEnabled()) {\n-            offHeapQueue = OffHeapServiceLoader.getOffHeapQueue();\n-            if (offHeapQueue != null) {\n-                useOffHeap = true;\n-                LOG.info(\"Offheap storage enabled for sink module, {}\", sinkModule.getId());\n-            }\n-        }\n-        \n-        final RejectedExecutionHandler rejectedExecutionHandler;\n-        if (asyncPolicy.isBlockWhenFull()) {\n-            // This queue ensures that calling thread is blocked when the queue is full\n-            // See the implementation of OfferBlockingQueue for details\n-            queue = new OfferBlockingQueue<>(asyncPolicy.getQueueSize());\n-            rejectedExecutionHandler = new ThreadPoolExecutor.AbortPolicy();\n+        SinkModule<S, T> sinkModule = state.getModule();\n+        Optional<DispatchQueueFactory> factory = DispatchQueueServiceLoader.getDispatchQueueFactory();\n+\n+        if (factory.isPresent()) {\n+            LOG.debug(\"Using queue from factory\");\n+            dispatchQueue = factory.get().getQueue(asyncPolicy, sinkModule.getId(),\n+                    sinkModule::marshalSingleMessage, sinkModule::unmarshalSingleMessage);\n         } else {\n-            queue = new LinkedBlockingQueue<Runnable>(asyncPolicy.getQueueSize());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d13a046b32568f268530975b096936ee35afe84d"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3MTY2NA==", "bodyText": "I think the exception should be  Could not delete", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r368171664", "createdAt": "2020-01-17T23:03:28Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/off-heap/src/main/java/org/opennms/core/ipc/sink/offheap/QueueFileOffHeapDispatchQueue.java", "diffHunk": "@@ -0,0 +1,560 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2020 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2020 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ForkJoinPool;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.joda.time.Duration;\n+import org.opennms.core.ipc.sink.api.DispatchQueue;\n+import org.opennms.core.ipc.sink.api.WriteFailedException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.squareup.tape2.QueueFile;\n+import com.swrve.ratelimitedlogger.RateLimitedLog;\n+\n+/**\n+ * A {@link DispatchQueue} that first attempts to queue items in memory and upon overflowing the allocated in-memory\n+ * queue writes items \"off heap\" directly to disk via a file. The in-memory queue is volatile and if the process\n+ * crashes its contents are lost. The contents written to disk are durable and in the event of a crash will be reloaded.\n+ * <p>\n+ * This queue can be configured to only queue to memory by specifying the maximum off-heap size of 0. Using this\n+ * configuration causes {@link #enqueue} to block when the in-memory queue fills up rather than writing to the off-heap\n+ * queue.\n+ * <p>\n+ * Before queued items are written to disk they are first accumulated in a batch to limit the number of discrete writes\n+ * we make to disk. The batched items are considered part of the in-memory portion of the queue and are also volatile.\n+ *\n+ * @param <T> the type being queued\n+ */\n+public class QueueFileOffHeapDispatchQueue<T> implements DispatchQueue<T> {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(QueueFileOffHeapDispatchQueue.class);\n+    private final RateLimitedLog RATE_LIMITED_LOGGER = RateLimitedLog\n+            .withRateLimit(LOG)\n+            .maxRate(5)\n+            .every(Duration.standardSeconds(30))\n+            .build();\n+\n+    // This must match the size of the HEADER_LENGTH in QueueFile's Element class\n+    //\n+    // We could pull this out of that class reflectively but it seemed easier to just hard code it here\n+    private static final int SERIALIZED_OBJECT_HEADER_SIZE_IN_BYTES = 4;\n+    private static final String FILE_EXTENSION = \".fifo\";\n+\n+    private final Function<T, byte[]> serializer;\n+    private final Function<byte[], T> deserializer;\n+    private final String moduleName;\n+    private final BlockingQueue<Map.Entry<String, T>> inMemoryQueue;\n+\n+    // Note the queue is not thread safe so access should be synchronized\n+    private final QueueFile offHeapQueue;\n+    private final long maxFileSizeInBytes;\n+    private final int batchSize;\n+    private final Batch batch;\n+\n+    private final ForkJoinPool serdesPool = new ForkJoinPool(\n+            Math.max(Runtime.getRuntime().availableProcessors() - 1, 1));\n+\n+    // Used to guard access to the offHeapQueue and batch data structures\n+    private final Lock offHeapLock = new ReentrantLock(true);\n+    // Used to ensure only one thread can be enqueing at a time\n+    private final Lock enqueueLock = new ReentrantLock(true);\n+    private final FileCapacityLatch fileCapacityLatch = new FileCapacityLatch();\n+\n+    private final Method usedBytesMethod;\n+\n+    public QueueFileOffHeapDispatchQueue(Function<T, byte[]> serializer, Function<byte[], T> deserializer,\n+                                         String moduleName, Path filePath, int inMemoryQueueSize, int batchSize,\n+                                         long maxFileSizeInBytes) throws IOException {\n+        Objects.requireNonNull(serializer);\n+        Objects.requireNonNull(deserializer);\n+        Objects.requireNonNull(moduleName);\n+\n+        if (inMemoryQueueSize < 1) {\n+            throw new IllegalArgumentException(\"In memory queue size must be greater than 0\");\n+        }\n+\n+        if (inMemoryQueueSize % batchSize != 0) {\n+            throw new IllegalArgumentException(\"In memory queue size must be a multiple of batch size\");\n+        }\n+\n+        if (maxFileSizeInBytes < 0) {\n+            throw new IllegalArgumentException(\"Max file size must be either 0 or a positive integer\");\n+        }\n+\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+        this.moduleName = moduleName;\n+        this.batchSize = batchSize;\n+        this.maxFileSizeInBytes = maxFileSizeInBytes;\n+        batch = new Batch(batchSize);\n+\n+        inMemoryQueue = new ArrayBlockingQueue<>(inMemoryQueueSize, true);\n+\n+        // Setting the max file size to 0 or less will disable the off-heap portion of this queue\n+        if (maxFileSizeInBytes > 0) {\n+            Objects.requireNonNull(filePath);\n+            File file = Paths.get(filePath.toString(), moduleName + FILE_EXTENSION).toFile();\n+\n+            QueueFile qf;\n+            try {\n+                qf = new QueueFile.Builder(file).build();\n+            } catch (Exception e) {\n+                LOG.warn(\"Exception while loading queue file\", e);\n+\n+                if (file.delete()) {\n+                    qf = new QueueFile.Builder(file).build();\n+                } else {\n+                    throw new IOException(\"Could delete corrupted queue file \" + file.getAbsolutePath());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d13a046b32568f268530975b096936ee35afe84d"}, "originalPosition": 160}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MTQyMjA1", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-346142205", "createdAt": "2020-01-21T19:42:57Z", "commit": {"oid": "7e31fbf64c0f4e1b0ce4fa2ce8b67b6e933c0695"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MTcxMTg4", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-346171188", "createdAt": "2020-01-21T20:31:36Z", "commit": {"oid": "7e31fbf64c0f4e1b0ce4fa2ce8b67b6e933c0695"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NTg0NTU1", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-347584555", "createdAt": "2020-01-23T20:26:11Z", "commit": {"oid": "0a582a9767ba891d972843347f45d4c9ef7863ae"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NjI3MDQ5", "url": "https://github.com/OpenNMS/opennms/pull/2868#pullrequestreview-347627049", "createdAt": "2020-01-23T21:41:20Z", "commit": {"oid": "0a582a9767ba891d972843347f45d4c9ef7863ae"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMTo0MToyMFrOFhNlBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QyMTo0MToyMFrOFhNlBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM2OTc5OA==", "bodyText": "I think you have to do null check on the reference before passing it to  context.getService.  In the previous case, it used to check this only when off-heap feature is enabled config is present.", "url": "https://github.com/OpenNMS/opennms/pull/2868#discussion_r370369798", "createdAt": "2020-01-23T21:41:20Z", "author": {"login": "cgorantla"}, "path": "core/ipc/sink/common/src/main/java/org/opennms/core/ipc/sink/offheap/DispatchQueueServiceLoader.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*******************************************************************************\n+ * This file is part of OpenNMS(R).\n+ *\n+ * Copyright (C) 2018 The OpenNMS Group, Inc.\n+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.\n+ *\n+ * OpenNMS(R) is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published\n+ * by the Free Software Foundation, either version 3 of the License,\n+ * or (at your option) any later version.\n+ *\n+ * OpenNMS(R) is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with OpenNMS(R).  If not, see:\n+ *      http://www.gnu.org/licenses/\n+ *\n+ * For more information contact:\n+ *     OpenNMS(R) Licensing <license@opennms.org>\n+ *     http://www.opennms.org/\n+ *     http://www.opennms.com/\n+ *******************************************************************************/\n+\n+package org.opennms.core.ipc.sink.offheap;\n+\n+import java.util.Optional;\n+\n+import org.opennms.core.ipc.sink.api.DispatchQueueFactory;\n+import org.osgi.framework.BundleContext;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+public class DispatchQueueServiceLoader {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(DispatchQueueServiceLoader.class);\n+    private static BundleContext context;\n+    private static volatile DispatchQueueFactory dispatchQueueFactory;\n+\n+    public BundleContext getBundleContext() {\n+        return context;\n+    }\n+\n+    public static void setBundleContext(BundleContext bundleContext) {\n+        context = bundleContext;\n+    }\n+\n+    public static Optional<DispatchQueueFactory> getDispatchQueueFactory() {\n+        if (dispatchQueueFactory != null) {\n+            return Optional.of(dispatchQueueFactory);\n+        }\n+\n+        if (context != null) {\n+            try {\n+                dispatchQueueFactory = context.getService(context.getServiceReference(DispatchQueueFactory.class));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a582a9767ba891d972843347f45d4c9ef7863ae"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7bb6413c20dcccf7874c9cd480a2441c76953747", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/7bb6413c20dcccf7874c9cd480a2441c76953747", "committedDate": "2020-01-23T22:02:36Z", "message": "Sink API: Persistent Off-Heap Storage\n\nAdd off-heap storage implementation using a fifo file."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "960cacd1c9e9d8299b8c2bb40122fb928b826f3a", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/960cacd1c9e9d8299b8c2bb40122fb928b826f3a", "committedDate": "2020-01-23T22:02:43Z", "message": "Review feedback and update test to wait for threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4adfbca387f9b2889ea20567a85755183e5c8881", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/4adfbca387f9b2889ea20567a85755183e5c8881", "committedDate": "2020-01-23T22:02:43Z", "message": "Update more log messages"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adf1f7f145d8c701f616eb2c4e52e04e3d893ef0", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/adf1f7f145d8c701f616eb2c4e52e04e3d893ef0", "committedDate": "2020-01-23T22:02:45Z", "message": "Update copyrights"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f11e6a5edc0a6985518c30efbbdf241e5f7ee7d", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/7f11e6a5edc0a6985518c30efbbdf241e5f7ee7d", "committedDate": "2020-01-23T22:02:46Z", "message": "Review feedback 2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd34b2b11685926881be8563d95d181b62e35667", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/fd34b2b11685926881be8563d95d181b62e35667", "committedDate": "2020-01-23T22:02:47Z", "message": "More review feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b0e1bbd16a27062871af00bd7f30424ff7b16d2", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/8b0e1bbd16a27062871af00bd7f30424ff7b16d2", "committedDate": "2020-01-23T22:02:49Z", "message": "Additional test case to test production/consumption in parallel on separate threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b3dd20bc6fa2cc61682ee375228be42f5cacb7a", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/3b3dd20bc6fa2cc61682ee375228be42f5cacb7a", "committedDate": "2020-01-23T22:02:55Z", "message": "Fix exception message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dcc257c5e729334ea4f2ae661b8fce02ce202bd", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/9dcc257c5e729334ea4f2ae661b8fce02ce202bd", "committedDate": "2020-01-23T22:02:56Z", "message": "Install the feature on sentinel too..."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "029acc34322865fee996929e9239c1d8a3207161", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/029acc34322865fee996929e9239c1d8a3207161", "committedDate": "2020-01-23T22:02:58Z", "message": "Add null checking for service ref and fix fair locking in queue impl"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a582a9767ba891d972843347f45d4c9ef7863ae", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/0a582a9767ba891d972843347f45d4c9ef7863ae", "committedDate": "2020-01-23T20:18:00Z", "message": "Install the feature on sentinel too..."}, "afterCommit": {"oid": "029acc34322865fee996929e9239c1d8a3207161", "author": {"user": {"login": "mattixtech", "name": "Matthew Brooks"}}, "url": "https://github.com/OpenNMS/opennms/commit/029acc34322865fee996929e9239c1d8a3207161", "committedDate": "2020-01-23T22:02:58Z", "message": "Add null checking for service ref and fix fair locking in queue impl"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3713, "cost": 1, "resetAt": "2021-11-01T15:33:45Z"}}}