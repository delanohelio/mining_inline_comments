{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3MjAyNzYw", "number": 2519, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoxOTozMFrOEjnbEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNToxNVrOEkEmKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzgxNTIzOnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoxOTozMFrOHSEQFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoxOTozMFrOHSEQFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjA2OQ==", "bodyText": "Why the dash? This is not German :)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488706069", "createdAt": "2020-09-15T14:19:30Z", "author": {"login": "viliam-durina"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NzgyMTA0OnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoyMDozN1rOHSETqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMDowODoyMVrOHSp07g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjk4Ng==", "bodyText": "No comma", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488706986", "createdAt": "2020-09-15T14:20:37Z", "author": {"login": "viliam-durina"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyOTA3Nw==", "bodyText": "I don't think it's ok to remove the comma: https://owl.purdue.edu/owl/general_writing/punctuation/commas/commas_with_nonessential_elements.html", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489229077", "createdAt": "2020-09-16T07:41:17Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjk4Ng=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI1OTAyOQ==", "bodyText": "\"Create a sink to write to a remote map\" parses differently than \"Create a sink to write to, a remote map\". But you could say \"Create a sink to write to (a remote map)\".", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489259029", "createdAt": "2020-09-16T08:30:33Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjk4Ng=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTMyMTcxMA==", "bodyText": "Ahh, now I understand what Viliam was saying. Yes, I did actually intend to say Create a sink to write to, a remote map, but now I realise that Create a sink to write to a remote map makes much more sense, even though it is not what I initially intended. Will fix.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489321710", "createdAt": "2020-09-16T10:08:21Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjk4Ng=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Nzk2NjUyOnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MDowMFrOHSFu2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxMTo1MjowMVrOHStL7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA==", "bodyText": "Can you keep the line breaks? It renders the same (or so I hope), and is easier on the eyes for reading.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488730328", "createdAt": "2020-09-15T14:50:00Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxOTA1Ng==", "bodyText": "We don't use arbitrary line breaks, if it's the same paragraph, it should flow until the margin.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489219056", "createdAt": "2020-09-16T07:23:41Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzMDU3Nw==", "bodyText": "I can't really decide if it's easier on my eyes or if it annoys me greatly. I think I will just not touch it again.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489230577", "createdAt": "2020-09-16T07:43:48Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI5NjYxNQ==", "bodyText": "IIRC there were many instances of this in the document and it annoyed me: it looks like a new paragraph, but actually it's not.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489296615", "createdAt": "2020-09-16T09:27:39Z", "author": {"login": "viliam-durina"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTMxNDkzMg==", "bodyText": "Those LB are not arbitrary. I put them after each ., : or ;. It helps a lot while writing/reading a post.\nI don't see the point in removing them in the course of a PR that has nothing to do with it.\nIt's similar to changing tabs to spaces while fixing a bug.\nBut since you all agree, it's up to you now.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489314932", "createdAt": "2020-09-16T09:57:04Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTMyMzc4MA==", "bodyText": "I'm with Nicolas on this (can't believe I'm actually uttering these words... ;) ). I don't particularly like his formatting style either, but it's not harming anybody, so we shouldn't mess with it, especially not in a completely unrelated PR. I will revert my initial \"fixes\".", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489323780", "createdAt": "2020-09-16T10:12:13Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTM3Njc1MQ==", "bodyText": "I didn't realize this was a blog post, we can have some personal style in them, but for the docs that are team-maintained, we have some policies on formatting.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489376751", "createdAt": "2020-09-16T11:52:01Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Nzk3MzIzOnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MTozMFrOHSFzJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MTozMFrOHSFzJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMTQzMA==", "bodyText": "Provide a mapping function to extract the cache key from the ChangeRecord", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488731430", "createdAt": "2020-09-15T14:51:30Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map\n \n-3. Wrap `Person` objects into `Map.Entry`s keyed by ID\n+3. Name of the remote map\n \n-4. Create the sink to write to, a remote map\n+4. Client configuration so it can connect to the right host, cluster\n+and instance\n \n-5. Name of the remote map\n+5. Provide mapping from `ChangeRecord` to cache key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Nzk3NjA0OnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MjowNVrOHSF04A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MjowNVrOHSF04A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMTg3Mg==", "bodyText": "Provide a mapping function to extract the cache value (the Person POJO) from the ChangeRecord", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488731872", "createdAt": "2020-09-15T14:52:05Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map\n \n-3. Wrap `Person` objects into `Map.Entry`s keyed by ID\n+3. Name of the remote map\n \n-4. Create the sink to write to, a remote map\n+4. Client configuration so it can connect to the right host, cluster\n+and instance\n \n-5. Name of the remote map\n+5. Provide mapping from `ChangeRecord` to cache key\n \n-6. Client configuration so it can connect to the right host, cluster\n-  and instance\n+6. Provide mapping from `ChangeRecord` to cache value (`Person` POJO)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1Nzk4NDY3OnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1Mzo0NlrOHSF6Aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzo0NzozNlrOHSkZuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMzE4Nw==", "bodyText": "This API is more compact than the previous one, but it's more complex to get the hang on when you're unfamiliar with it.\nDo you intend to freeze the API at some point?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488733187", "createdAt": "2020-09-15T14:53:46Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzMjgyNw==", "bodyText": "It's not a matter of API. There was no API change, the pipeline simply wasn't using the right sink. This sink is the right one because it handles deletions too. The old one wasn't.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489232827", "createdAt": "2020-09-16T07:47:36Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMzE4Nw=="}, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MjU5NDk5OnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNToxNVrOHSyibQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwNzoxOTo0NFrOHTUtEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NDQyOQ==", "bodyText": "Is this some leftover change? It doesn't seem to improve anything.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489464429", "createdAt": "2020-09-16T14:05:15Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -206,9 +206,9 @@ data, depending on the underlying disk technology.\n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+It has sources and sinks to integrate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDAyNDIxMA==", "bodyText": "Yes, leftover, fixed it.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r490024210", "createdAt": "2020-09-17T07:19:44Z", "author": {"login": "jbartok"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -206,9 +206,9 @@ data, depending on the underlying disk technology.\n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+It has sources and sinks to integrate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NDQyOQ=="}, "originalCommit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4562, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}