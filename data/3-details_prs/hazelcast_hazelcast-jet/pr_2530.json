{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5MjA3NTgz", "number": 2530, "title": "CDC blog post", "bodyText": "Blog post on Debezium-Jet integration.", "createdAt": "2020-09-18T09:54:09Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530", "merged": true, "mergeCommit": {"oid": "20e60a484a307ba16c8580e67e46ed746d92ad6b"}, "closed": true, "closedAt": "2020-09-21T11:11:40Z", "author": {"login": "jbartok"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdKChQogH2gAyNDg5MjA3NTgzOmY0MDIyNjcxNWJlZDc1NThiYThkNDExZGMzODc5OTIwMzljYjM4MGY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdLA7XrgFqTQ5MjQ2NzM3MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f40226715bed7558ba8d411dc387992039cb380f", "committedDate": "2020-09-18T09:52:37Z", "message": "Add CDC blog post"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxMzgyOTAx", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#pullrequestreview-491382901", "createdAt": "2020-09-18T11:30:46Z", "commit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTozMDo0NlrOHUJPYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMTo0NDoxOVrOHUJvnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg4NDk2MA==", "bodyText": "Does not explain what functionality change data capture technologies provide.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490884960", "createdAt": "2020-09-18T11:30:46Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg4NzQ4Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              of- or even entire Debezium events can be interpreted\n          \n          \n            \n              of - or even entire Debezium events can be interpreted", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490887483", "createdAt": "2020-09-18T11:34:58Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg4ODYzNg==", "bodyText": "I would leave out this paragraph.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490888636", "createdAt": "2020-09-18T11:36:50Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5MDU0Mw==", "bodyText": "I can already tell you it was an unfortunate decision. It makes processing delete events difficult. I left out a delete operation from my elastic/cdc blog because of this.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490890543", "createdAt": "2020-09-18T11:39:43Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,\n+which in turn is able to resume the data flow from that offset.\n+\n+One other thing we did and might be worth mentioning is that the Jet\n+integration also makes use of Debezium\u2019s [new record state\n+extraction](https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html)\n+SMT (Simple Message Transformation), for the purpose of message\n+structure simplification. With this transformation in effect, only the\n+\"after\" structure of the Debezium event envelope is processed by Jet.\n+However, whether this is a good idea or not, only time will tell. I", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5MTU1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            When we will cover further connectors and if we will extend existing\n          \n          \n            \n            When we cover further connectors and if we extend existing", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490891551", "createdAt": "2020-09-18T11:41:13Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,\n+which in turn is able to resume the data flow from that offset.\n+\n+One other thing we did and might be worth mentioning is that the Jet\n+integration also makes use of Debezium\u2019s [new record state\n+extraction](https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html)\n+SMT (Simple Message Transformation), for the purpose of message\n+structure simplification. With this transformation in effect, only the\n+\"after\" structure of the Debezium event envelope is processed by Jet.\n+However, whether this is a good idea or not, only time will tell. I\n+personally think that if and when we will start covering schema changes\n+more, we might end up re-enabling the full Debezium event content.\n+\n+## Examples\n+\n+The simplest example of using the Jet-Debezium integration would be our\n+[CDC tutorial](https://jet-start.sh/docs/next/tutorials/cdc) that I\u2019ve\n+already mentioned above. A more involved one can be seen in my\n+colleague\u2019s, Nicolas Fr\u00e4nkel\u2019s [blog\n+post](https://jet-start.sh/blog/2020/07/16/designing-evergreen-cache-cdc).\n+\n+## License\n+\n+The Jet - Debezium integration is currently provided under the [Apache\n+License, Version 2](https://www.apache.org/licenses/LICENSE-2.0.txt),\n+just like most of Jet and Debezium, so making full usage of the\n+combination of the two should have no impediments in your own projects.\n+\n+## Looking ahead\n+\n+At the moment of writing the Jet-Debezium integration is fully finished\n+only for MySQL and Postgres databases and has been [released in version\n+4.2](https://jet-start.sh/blog/2020/07/14/jet-42-is-released) of Jet.\n+When we will cover further connectors and if we will extend existing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5Mjc3Nw==", "bodyText": "Doesn't merger imply some cooperation between us and Debezium?\nMaybe use something more abstract, like synergy or whatever fancy word you can think of.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490892777", "createdAt": "2020-09-18T11:43:27Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,\n+which in turn is able to resume the data flow from that offset.\n+\n+One other thing we did and might be worth mentioning is that the Jet\n+integration also makes use of Debezium\u2019s [new record state\n+extraction](https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html)\n+SMT (Simple Message Transformation), for the purpose of message\n+structure simplification. With this transformation in effect, only the\n+\"after\" structure of the Debezium event envelope is processed by Jet.\n+However, whether this is a good idea or not, only time will tell. I\n+personally think that if and when we will start covering schema changes\n+more, we might end up re-enabling the full Debezium event content.\n+\n+## Examples\n+\n+The simplest example of using the Jet-Debezium integration would be our\n+[CDC tutorial](https://jet-start.sh/docs/next/tutorials/cdc) that I\u2019ve\n+already mentioned above. A more involved one can be seen in my\n+colleague\u2019s, Nicolas Fr\u00e4nkel\u2019s [blog\n+post](https://jet-start.sh/blog/2020/07/16/designing-evergreen-cache-cdc).\n+\n+## License\n+\n+The Jet - Debezium integration is currently provided under the [Apache\n+License, Version 2](https://www.apache.org/licenses/LICENSE-2.0.txt),\n+just like most of Jet and Debezium, so making full usage of the\n+combination of the two should have no impediments in your own projects.\n+\n+## Looking ahead\n+\n+At the moment of writing the Jet-Debezium integration is fully finished\n+only for MySQL and Postgres databases and has been [released in version\n+4.2](https://jet-start.sh/blog/2020/07/14/jet-42-is-released) of Jet.\n+When we will cover further connectors and if we will extend existing\n+ones (for example by adding handling for database schema changes),\n+remains to be seen.\n+\n+The functionality provided by Debezium, the ability to allow modern\n+processing of legacy data is a great fit to Jet\u2019s ability to carry out\n+that processing efficiently. The combination of the two has the\n+potential to become much more than the sum of their parts. I\u2019m very much\n+looking forward to finding out what this merger can lead to. Stay tuned!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5MzIxMg==", "bodyText": "Yes after reading whole article I think you should briefly explain what CDC is.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490893212", "createdAt": "2020-09-18T11:44:19Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg4NDk2MA=="}, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/836ec41c4f0b60df0fa95c647d8e77786282aa44", "committedDate": "2020-09-18T12:05:13Z", "message": "Update site/website/blog/2020-09-18-cdc-meets-stream-processing.md\n\nCo-authored-by: Franti\u0161ek Hartman <frant.hartm@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNDIwMjY3", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#pullrequestreview-491420267", "createdAt": "2020-09-18T12:30:32Z", "commit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMjozMDozM1rOHULHRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMjo0NTo1NFrOHULm3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkxNTY1Mg==", "bodyText": "What's the diff here? Just curious :)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490915652", "createdAt": "2020-09-18T12:30:33Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-04-01-upgrading-to-jet-40.md", "diffHunk": "@@ -158,8 +158,8 @@ We made multiple breaking changes in Jet\u2019s own APIs too:\n   `withUnorderedAsyncResponses()` were removed from `ServiceFactory`.\n   These properties are relevant only in the context of asynchronous\n   operations and were used in conjunction with\n-  `GeneralStage.mapUsingServiceAsync(\u2026\u200b)`. In Jet 4.0 the\n-  `GeneralStage.mapUsingServiceAsync(\u2026\u200b)` method has a new variant with\n+  `GeneralStage.mapUsingServiceAsync(\u2026)`. In Jet 4.0 the\n+  `GeneralStage.mapUsingServiceAsync(\u2026)` method has a new variant with", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkxNzc2NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \u201cdumbed down\u201dversion (even as full-blown is light enough to be\n          \n          \n            \n            \u201cdumbed down\u201d version (even as full-blown is light enough to be", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490917765", "createdAt": "2020-09-18T12:34:51Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkxODA4NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n          \n          \n            \n            we used Debezium to build a Kafka Connect source for Jet. Well\u2026", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490918085", "createdAt": "2020-09-18T12:35:30Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkxOTU0OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n          \n          \n            \n              Jr](https://github.com/FasterXML/jackson-jr), to simplify how parts", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490919549", "createdAt": "2020-09-18T12:38:14Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkyMDA3OQ==", "bodyText": "Delete this line", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490920079", "createdAt": "2020-09-18T12:39:20Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of - or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkyMTc4OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            surprisingly simple. All that was really needed was to add Debezium\u2019s\n          \n          \n            \n            surprisingly simple. All we had to do was add Debezium\u2019s", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490921789", "createdAt": "2020-09-18T12:42:27Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of - or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkyMjQ0MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            execute a recovery, it can also pass the recovered offset to Debezium,\n          \n          \n            \n            execute a recovery, it passes the recovered offset to Debezium,", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490922441", "createdAt": "2020-09-18T12:43:36Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of - or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkyMjU3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            which in turn is able to resume the data flow from that offset.\n          \n          \n            \n            which in turn resumes the data flow from that offset.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490922571", "createdAt": "2020-09-18T12:43:52Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of - or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,\n+which in turn is able to resume the data flow from that offset.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "836ec41c4f0b60df0fa95c647d8e77786282aa44"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkyMzc0Mw==", "bodyText": "\"integration\" maybe", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r490923743", "createdAt": "2020-09-18T12:45:54Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title: Change Data Capture meets Stream Processing\n+description: Debezium based Change Data Capture sources for Hazelcast Jet\n+author: Bart\u00f3k J\u00f3zsef\n+authorURL: https://www.linkedin.com/in/bjozsef/\n+authorImageURL: https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg\n+---\n+\n+## Introduction\n+\n+Hazelcast Jet is a distributed, lightweight stream processing framework.\n+It allows you to write modern Java code that focuses purely on data\n+transformation while it does all the heavy lifting of getting the data\n+flowing and computation running across a cluster of nodes. Jet stores\n+computational state in [fault-tolerant, distributed in-memory\n+storage](https://jet-start.sh/docs/api/data-structures), allowing\n+thousands of concurrent users granular and fast access to your data\n+without breaking a sweat.\n+\n+While stream processing is a natural solution for providing insight into\n+many big-data workloads, it\u2019s a relatively new evolution over its\n+predecessor - offline batch processing. Utilizing stream processing\n+effectively requires re-architecting existing systems to event-driven\n+architectures and introducing several new components. This process is\n+not always straightforward and also requires a shift in mindset.\n+\n+In this context, the functionality provided by change data capture\n+technologies, for which Debezium is one of the, if not THE best\n+open-source alternative, is a godsend. To be able to ingest data from\n+relational databases, without affecting the applications that use them,\n+changes the game for streaming systems. It becomes possible to safely\n+extend old systems with all kinds of new functionality: real-time\n+analytics, complex event processing, anomaly & fraud detection and so\n+on.\n+\n+## Integration\n+\n+When we first considered integrating Debezium into Jet, the most\n+important decisions were centered around the fact that Debezium is\n+designed to be deployed via Apache [Kafka\n+Connect](https://kafka.apache.org/documentation/#connect), which then\n+takes care of *fault tolerance* and *scalability*. Fortunately, Jet is\n+fully capable of providing these crucial services. Also, Kafka Connect\n+is a good enough abstraction that we were able to mimic it for Debezium.\n+\n+We are aware that Debezium also offers an *embedded mode* for\n+applications not interested in fault-tolerance guarantees such as\n+exactly-once processing and resilience, but since Jet does not have a\n+\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+embedded), we quickly discarded this approach.\n+\n+So, first, we added generic support for Kafka Connect sources to Jet,\n+which should be a valuable feature even outside the scope of CDC. Then\n+we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n+\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n+source. We just had to make sure that Jet\u2019s specific fault-tolerance\n+mechanisms will interact with it properly, through the Kafka Connect\n+API.\n+\n+## Synergy\n+\n+One immediate benefit that Jet offers to Debezium users is eliminating\n+the need for *external services*. No Zookeeper, no Kafka needed. When\n+using Debezium through Jet, the latter takes care of the whole lifecycle\n+and fault tolerance of all the components involved. The setup is greatly\n+simplified.\n+\n+Then, obviously, there is the *stream processing capability*, because\n+that\u2019s what Jet does. Not only do you get access to the data, but you\n+also have the toolbox to process it, extract whatever insights you need\n+from it.\n+\n+In addition, Jet also aims to offer *further convenience* wrappers when\n+the Debezium source is being used. For example:\n+\n+* builders for the most common configuration properties to make setting\n+  up Debezium for some specific DB as simple as possible\n+* standard Java interfaces to give structure to the complex Debezium\n+  events\n+* JSON parsing, including mapping to Objects, based on [Jackson\n+  jr](https://github.com/FasterXML/jackson-jr), to simplify how parts\n+  of- or even entire Debezium events can be interpreted\n+\n+For an example look at this sample from our [CDC\n+tutorial](https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job). All\n+the code you would need to build an in-memory replica of your MySQL\n+database table would be something like:\n+\n+```java\n+StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+        .setDatabaseAddress(\"127.0.0.1\")\n+        .setDatabasePort(3306)\n+        .setDatabaseUser(\"debezium\")\n+        .setDatabasePassword(\"dbz\")\n+        .setClusterName(\"dbserver1\")\n+        .setDatabaseWhitelist(\"inventory\")\n+        .setTableWhitelist(\"inventory.customers\")\n+        .build();\n+\n+Pipeline pipeline = Pipeline.create();\n+pipeline.readFrom(source)\n+        .withoutTimestamps()\n+        .peek()\n+        .writeTo(CdcSinks.map(\"customers\",\n+                r -> r.key().toMap().get(\"id\"),\n+                r -> r.value().toObject(Customer.class).toString()));\n+\n+JobConfig cfg = new JobConfig().setName(\"mysql-monitor\");\n+Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+```\n+\n+One last service that Jet aims to add to Debezium\u2019s value is performance\n+benchmarks. We want to measure both the performance impact of enabling\n+CDC on specific databases and the event throughput. This work is still\n+ongoing, we still have to publish our exact testing methodology, but the\n+results obtained so far are available [here](https://jet-start.sh/docs/next/design-docs/005-cdc-sources#performance).\n+\n+## Architecture\n+\n+I have stated above that when Debezium is integrated into Jet, the\n+latter takes on the role of service-provider as far as fault tolerance\n+and scalability are concerned.\n+\n+Jet doesn't delegate its cluster management and fault tolerance concerns\n+to an outside system like ZooKeeper. It reuses the groundwork\n+implemented for Hazelcast IMDG: cluster management and the IMap, and\n+adds its own implementation of Chandy-Lamport distributed snapshots. If\n+a cluster member fails, Jet will restart the job on the remaining\n+members, restore the state of processing from the last snapshot, and\n+then seamlessly continue from that point. For further details, consult\n+our [documentation on the\n+topic](https://jet-start.sh/docs/next/architecture/fault-tolerance).\n+\n+Extending this functionality umbrella to cover Debezium has been\n+surprisingly simple. All that was really needed was to add Debezium\u2019s\n+source offset to Jet\u2019s snapshots. This way, whenever Jet needs to\n+execute a recovery, it can also pass the recovered offset to Debezium,\n+which in turn is able to resume the data flow from that offset.\n+\n+One other thing we did and might be worth mentioning is that the Jet\n+integration also makes use of Debezium\u2019s [new record state\n+extraction](https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html)\n+SMT (Simple Message Transformation), for the purpose of message\n+structure simplification. With this transformation in effect, only the\n+\"after\" structure of the Debezium event envelope is processed by Jet.\n+However, whether this is a good idea or not, only time will tell. I\n+personally think that if and when we will start covering schema changes\n+more, we might end up re-enabling the full Debezium event content.\n+\n+## Examples\n+\n+The simplest example of using the Jet-Debezium integration would be our\n+[CDC tutorial](https://jet-start.sh/docs/next/tutorials/cdc) that I\u2019ve\n+already mentioned above. A more involved one can be seen in my\n+colleague\u2019s, Nicolas Fr\u00e4nkel\u2019s [blog\n+post](https://jet-start.sh/blog/2020/07/16/designing-evergreen-cache-cdc).\n+\n+## License\n+\n+The Jet - Debezium integration is currently provided under the [Apache\n+License, Version 2](https://www.apache.org/licenses/LICENSE-2.0.txt),\n+just like most of Jet and Debezium, so making full usage of the\n+combination of the two should have no impediments in your own projects.\n+\n+## Looking ahead\n+\n+At the moment of writing the Jet-Debezium integration is fully finished\n+only for MySQL and Postgres databases and has been [released in version\n+4.2](https://jet-start.sh/blog/2020/07/14/jet-42-is-released) of Jet.\n+When we will cover further connectors and if we will extend existing\n+ones (for example by adding handling for database schema changes),\n+remains to be seen.\n+\n+The functionality provided by Debezium, the ability to allow modern\n+processing of legacy data is a great fit to Jet\u2019s ability to carry out\n+that processing efficiently. The combination of the two has the\n+potential to become much more than the sum of their parts. I\u2019m very much\n+looking forward to finding out what this merger can lead to. Stay tuned!", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5Mjc3Nw=="}, "originalCommit": {"oid": "f40226715bed7558ba8d411dc387992039cb380f"}, "originalPosition": 178}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e000d15754e3936826ead5b8fc0c2102e26651d7", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/e000d15754e3936826ead5b8fc0c2102e26651d7", "committedDate": "2020-09-21T07:57:23Z", "message": "Address review concerns"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyNDYzMzk4", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#pullrequestreview-492463398", "createdAt": "2020-09-21T10:28:45Z", "commit": {"oid": "e000d15754e3936826ead5b8fc0c2102e26651d7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxMDoyODo0NVrOHVJnUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxMDoyODo0NVrOHVJnUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTkzOTY2Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            we used Debezium to build a Kafka Connect source for Jet. Well\u2026\u201cbuild\u201d\n          \n          \n            \n            we used Debezium to build a Kafka Connect source for Jet. Well\u2026 \u201cbuild\u201d", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#discussion_r491939666", "createdAt": "2020-09-21T10:28:45Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-09-18-cdc-meets-stream-processing.md", "diffHunk": "@@ -46,16 +50,15 @@ is a good enough abstraction that we were able to mimic it for Debezium.\n We are aware that Debezium also offers an *embedded mode* for\n applications not interested in fault-tolerance guarantees such as\n exactly-once processing and resilience, but since Jet does not have a\n-\u201cdumbed down\u201dversion (even as full-blown is light enough to be\n+\u201cdumbed down\u201d version (even as full-blown is light enough to be\n embedded), we quickly discarded this approach.\n \n So, first, we added generic support for Kafka Connect sources to Jet,\n which should be a valuable feature even outside the scope of CDC. Then\n-we\u2019ve used Debezium to build a Kafka Connect source for Jet. Well\u2026\n-\u201cbuild\u201d might be overstating it. Debezium already is a Kafka Connect\n-source. We just had to make sure that Jet\u2019s specific fault-tolerance\n-mechanisms will interact with it properly, through the Kafka Connect\n-API.\n+we used Debezium to build a Kafka Connect source for Jet. Well\u2026\u201cbuild\u201d", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e000d15754e3936826ead5b8fc0c2102e26651d7"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0055fcdb1c66eb6693875c16cb7f3d123e5d2f87", "author": {"user": {"login": "mtopolnik", "name": "Marko Topolnik"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/0055fcdb1c66eb6693875c16cb7f3d123e5d2f87", "committedDate": "2020-09-21T10:30:57Z", "message": "Add missing space"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkyNDY3Mzcw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2530#pullrequestreview-492467370", "createdAt": "2020-09-21T10:35:15Z", "commit": {"oid": "0055fcdb1c66eb6693875c16cb7f3d123e5d2f87"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3614, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}