{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM3MDY1NTIx", "number": 2753, "title": "Improve CSV reading performance in SQL", "bodyText": "Instead of reading into memory-heavy LinkedHashMap, read CSVs internally into String[].", "createdAt": "2020-12-11T16:01:41Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753", "merged": true, "mergeCommit": {"oid": "035270bf2a3387623f47e2cd49730f80489a6483"}, "closed": true, "closedAt": "2021-01-14T15:29:53Z", "author": {"login": "viliam-durina"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdlKCdNAH2gAyNTM3MDY1NTIxOmE4NTI0NWFiYTJjYjU5ZTU3M2NmZGI3OTY5ZjA1MWU1MDg3M2JjMzY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdwFIUsgFqTU2ODI3OTQwMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a85245aba2cb59e573cfdb7969f051e50873bc36", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a85245aba2cb59e573cfdb7969f051e50873bc36", "committedDate": "2020-12-11T15:54:10Z", "message": "Improve CSV reading performance in SQL\n\nInstead of reading into memory-heavy LinkedHashMap, read CSVs internally\ninto String[]."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/bff559c8fc476db3d06c1dc150beef5b47208e34", "committedDate": "2020-12-11T16:03:44Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUxMDkxOTM4", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#pullrequestreview-551091938", "createdAt": "2020-12-14T07:11:48Z", "commit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzoxMTo0OFrOIFCpoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQwNzoyMDo1NlrOIFC4Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1NzIxNw==", "bodyText": "I think you could avoid projection if header == stringArrayFieldList.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542157217", "createdAt": "2020-12-14T07:11:48Z", "author": {"login": "gierlachg"}, "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -47,18 +53,49 @@\n )\n public class CsvReadFileFnProvider implements ReadFileFnProvider {\n \n+    @SuppressWarnings(\"unchecked\")\n     @Nonnull\n     @Override\n     public <T> FunctionEx<Path, Stream<T>> createReadFileFn(@Nonnull FileFormat<T> format) {\n         CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n         Class<?> formatClazz = csvFileFormat.clazz(); // Format is not Serializable\n \n         return path -> {\n-            ObjectReader reader = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n-                                                 .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                                 .with(CsvSchema.emptySchema().withHeader());\n             FileInputStream fis = new FileInputStream(path.toFile());\n-            return StreamSupport.<T>stream(Spliterators.spliteratorUnknownSize(reader.readValues(fis), ORDERED), false)\n+            MappingIterator<T> iterator;\n+            Function<T, T> projection = r -> r;\n+            if (formatClazz == String[].class) {\n+                ObjectReader reader = new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                                     .readerFor(String[].class)\n+                                                     .with(CsvSchema.emptySchema().withSkipFirstDataRow(false));\n+                iterator = reader.readValues(fis);\n+                if (!iterator.hasNext()) {\n+                    throw new JetException(\"Header row missing in \" + path);\n+                }\n+                String[] header = (String[]) iterator.next();\n+                List<String> fieldList = csvFileFormat.stringArrayFieldList();\n+                if (fieldList != null) {\n+                    int[] simpleFieldMap = createSimpleFieldMap(fieldList, header);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODE0Ng==", "bodyText": "Hadoop variant needs exactly same logic, I guess it could be somehow shared.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542158146", "createdAt": "2020-12-14T07:14:10Z", "author": {"login": "gierlachg"}, "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -47,18 +53,49 @@\n )\n public class CsvReadFileFnProvider implements ReadFileFnProvider {\n \n+    @SuppressWarnings(\"unchecked\")\n     @Nonnull\n     @Override\n     public <T> FunctionEx<Path, Stream<T>> createReadFileFn(@Nonnull FileFormat<T> format) {\n         CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n         Class<?> formatClazz = csvFileFormat.clazz(); // Format is not Serializable\n \n         return path -> {\n-            ObjectReader reader = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n-                                                 .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                                 .with(CsvSchema.emptySchema().withHeader());\n             FileInputStream fis = new FileInputStream(path.toFile());\n-            return StreamSupport.<T>stream(Spliterators.spliteratorUnknownSize(reader.readValues(fis), ORDERED), false)\n+            MappingIterator<T> iterator;\n+            Function<T, T> projection = r -> r;\n+            if (formatClazz == String[].class) {\n+                ObjectReader reader = new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                                     .readerFor(String[].class)\n+                                                     .with(CsvSchema.emptySchema().withSkipFirstDataRow(false));\n+                iterator = reader.readValues(fis);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODQ3NA==", "bodyText": "We could use a test, proving that projection works.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542158474", "createdAt": "2020-12-14T07:14:56Z", "author": {"login": "gierlachg"}, "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java", "diffHunk": "@@ -33,7 +33,6 @@\n \n     @Test\n     public void shouldReadCsvFile() {\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1OTMzNg==", "bodyText": "Does it make sense to have clazz & stringArrayFieldList at the same time? Maybe, both should be final and we should have 2 constructors setting clazz in one and stringArrayFieldList in the other?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542159336", "createdAt": "2020-12-14T07:16:56Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java", "diffHunk": "@@ -34,6 +35,7 @@\n     public static final String FORMAT_CSV = \"csv\";\n \n     private Class<T> clazz;\n+    private List<String> stringArrayFieldList;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDQwNQ==", "bodyText": "I'm not sure i like formatForSample & formatForData. Maybe just implement resolveMetadata in subclasses?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160405", "createdAt": "2020-12-14T07:19:32Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java", "diffHunk": "@@ -33,7 +33,7 @@\n     private static final FileFormat<Map<String, String>> FORMAT = FileFormat.avro();\n \n     @Override\n-    protected FileFormat<?> format() {\n+    protected FileFormat<?> formatForSample() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDcxOQ==", "bodyText": "Why distinct is needed here? Maybe it should be part of validation?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160719", "createdAt": "2020-12-14T07:20:14Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java", "diffHunk": "@@ -42,7 +50,16 @@\n     }\n \n     @Override\n-    protected SupplierEx<QueryTarget> queryTargetSupplier() {\n-        return CsvQueryTarget::new;\n+    protected SupplierEx<QueryTarget> queryTargetSupplier(List<MappingField> resolvedFields) {\n+        List<String> fieldMap = createFieldList(resolvedFields);\n+        return () -> new CsvQueryTarget(fieldMap);\n+    }\n+\n+    @Nonnull\n+    private static List<String> createFieldList(List<MappingField> resolvedFields) {\n+        return resolvedFields.stream()\n+                      .map(f -> f.externalName() != null ? f.externalName() : f.name())\n+                      .distinct()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDk5MA==", "bodyText": "Is res[index] == -1 condition needed?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160990", "createdAt": "2020-12-14T07:20:56Z", "author": {"login": "gierlachg"}, "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -68,4 +105,17 @@\n     public String format() {\n         return CsvFileFormat.FORMAT_CSV;\n     }\n+\n+    private static int[] createSimpleFieldMap(List<String> fieldList, String[] actualHeader) {\n+        int[] res = new int[fieldList.size()];\n+        Arrays.fill(res, -1);\n+        for (int i = 0; i < actualHeader.length; i++) {\n+            int index = fieldList.indexOf(actualHeader[i]);\n+            // if the header is present in the file and we didn't encounter it yet, store its index\n+            if (index >= 0 && res[index] == -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce994cc7afd6db9ba292a1663e1db21fd886c348", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/ce994cc7afd6db9ba292a1663e1db21fd886c348", "committedDate": "2020-12-14T19:42:07Z", "message": "Finish the change in Hadoop module"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3772e38e13cd59129667b4c7c85661e7e52ebacd", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3772e38e13cd59129667b4c7c85661e7e52ebacd", "committedDate": "2020-12-14T19:54:28Z", "message": "Move more logic to subclasses"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "201b483d5652e1fa925c4501b449e6cd6e5222cd", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/201b483d5652e1fa925c4501b449e6cd6e5222cd", "committedDate": "2020-12-14T20:02:52Z", "message": "Add test for duplicate external name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49357355c5163935190cb639ac2f0e96a20701f7", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/49357355c5163935190cb639ac2f0e96a20701f7", "committedDate": "2020-12-14T20:03:22Z", "message": "Revert pom.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cf8a9cbe0ca35ed39f8847148a1544428aa599f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1cf8a9cbe0ca35ed39f8847148a1544428aa599f", "committedDate": "2020-12-14T20:16:02Z", "message": "Add test for Util.createFieldProjection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3eab14a181beb56b4562f7cf3a2ef96c3d5f2e62", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3eab14a181beb56b4562f7cf3a2ef96c3d5f2e62", "committedDate": "2020-12-14T20:17:29Z", "message": "Fix style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e8eedec80108039af44871fc1ee9948e08de167", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/0e8eedec80108039af44871fc1ee9948e08de167", "committedDate": "2020-12-15T07:33:44Z", "message": "Add CsvFileFormatTest for remapping functionality"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "197fa3d8e1dc2e752fd373dfa23867752953a614", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/197fa3d8e1dc2e752fd373dfa23867752953a614", "committedDate": "2020-12-15T07:40:05Z", "message": "Format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "438654d10a8b987cdf57247b2d07d4ed72702469", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/438654d10a8b987cdf57247b2d07d4ed72702469", "committedDate": "2020-12-15T07:40:14Z", "message": "Merge remote-tracking branch 'viliam/csv-performance' into csv-performance"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyMTc0MDcy", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#pullrequestreview-552174072", "createdAt": "2020-12-15T07:38:17Z", "commit": {"oid": "0e8eedec80108039af44871fc1ee9948e08de167"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzozODoxN1rOIF88Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwNzo0NDozNlrOIF9Jmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMjI1OQ==", "bodyText": "Maybe use org.apache.hadoop.conf.Configuration#setStrings(String, String[])", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543112259", "createdAt": "2020-12-15T07:38:17Z", "author": {"login": "frant-hartm"}, "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java", "diffHunk": "@@ -197,7 +199,13 @@ public String format() {\n \n             Class<?> clazz = csvFileFormat.clazz();\n             if (clazz != null) {\n-                job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getCanonicalName());\n+                job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getName());\n+            }\n+            List<String> fieldList = csvFileFormat.stringArrayFieldList();\n+            if (fieldList != null) {\n+                for (int i = 0; i < fieldList.size(); i++) {\n+                    job.getConfiguration().set(CSV_INPUT_FORMAT_FIELD_LIST_PREFIX + i, fieldList.get(i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e8eedec80108039af44871fc1ee9948e08de167"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMzAyNA==", "bodyText": "I agree there should be some tests in the file connector for this. It is user facing API and there is non trivial amount of new code here. I pushed some.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543113024", "createdAt": "2020-12-15T07:39:43Z", "author": {"login": "frant-hartm"}, "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java", "diffHunk": "@@ -33,7 +33,6 @@\n \n     @Test\n     public void shouldReadCsvFile() {\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODQ3NA=="}, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMzM1Nw==", "bodyText": "The false condition here isn't covered by tests.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543113357", "createdAt": "2020-12-15T07:40:22Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java", "diffHunk": "@@ -548,4 +550,51 @@ public static String formatJobDuration(long durationMs) {\n         String textUpToHours = String.format(\"%02d:%02d:%02d.%03d\", hours, minutes, seconds, millis);\n         return sign + (durationMs > 0 ? durationMs + \"d \" : \"\") + textUpToHours;\n     }\n+\n+    /**\n+     * Given a list of input field names and a list of output field names\n+     * creates a projection to map between these.\n+     * <p>\n+     * For example, if input names are {@code [surname, name, address]} and\n+     * output names are {@code [name, surname, age]}, then the function,\n+     * applied to {@code [Smith, John, New York]} will return {@code [John,\n+     * Smith, (null)]}. That is, it will map the fields from the input order to\n+     * output order. The output field named {@code age} is missing in input, so\n+     * the value for it is {@code null} for any input.\n+     *\n+     * @param inputFields the input headers\n+     * @param outputFields the output headers\n+     * @return the indices to map input to output\n+     */\n+    @Nonnull\n+    public static Function<String[], String[]> createFieldProjection(\n+            @Nonnull String[] inputFields,\n+            @Nonnull List<String> outputFields\n+    ) {\n+        if (outputFields.equals(asList(inputFields))) {\n+            // shortcut - the mapping is an identity\n+            return i -> i;\n+        }\n+        int[] simpleFieldMap = new int[outputFields.size()];\n+        Arrays.fill(simpleFieldMap, -1);\n+        for (int i = 0; i < inputFields.length; i++) {\n+            int index = outputFields.indexOf(inputFields[i]);\n+            // if the inputFields is present in the file and we didn't encounter it yet, store its index\n+            if (index >= 0 && simpleFieldMap[index] == -1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e8eedec80108039af44871fc1ee9948e08de167"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExNDU1OA==", "bodyText": "We originaly had a final clazz, changed it with the SQL file connector. now looking at all the places maybe we could go back to final clazz and always provide a class (either Map, instead of null), TreeNode for json etc. This way we could avoid the cases if null then this class..", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543114558", "createdAt": "2020-12-15T07:42:27Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java", "diffHunk": "@@ -34,6 +35,7 @@\n     public static final String FORMAT_CSV = \"csv\";\n \n     private Class<T> clazz;\n+    private List<String> stringArrayFieldList;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1OTMzNg=="}, "originalCommit": {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExNTY3NA==", "bodyText": "I find the double negation less readable.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543115674", "createdAt": "2020-12-15T07:44:36Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -98,7 +98,7 @@\n      */\n     public FileSourceBuilder(@Nonnull String path) {\n         this.path = requireNonNull(path, \"path must not be null\");\n-        if (!(Paths.get(path).isAbsolute() || hasHadoopPrefix(path))) {\n+        if (!hasHadoopPrefix(path) && !Paths.get(path).isAbsolute()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e8eedec80108039af44871fc1ee9948e08de167"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84f4de3ad0f29bf241049d8fd92ea8e21d12452c", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/84f4de3ad0f29bf241049d8fd92ea8e21d12452c", "committedDate": "2020-12-15T19:45:55Z", "message": "Merge branch 'master' into csv-performance\n\n# Conflicts:\n#\thazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java\n#\thazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/MetadataResolver.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97cd5c683bb658a5dcf22cc6db26aa497a8c3b35", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/97cd5c683bb658a5dcf22cc6db26aa497a8c3b35", "committedDate": "2020-12-15T19:52:15Z", "message": "Fix linter errer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "785be0ca6e46a0dca7c3d5c329da32c8e018ee2e", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/785be0ca6e46a0dca7c3d5c329da32c8e018ee2e", "committedDate": "2020-12-15T19:52:32Z", "message": "Improve unit test coverage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e3a8033dac9bdf38f8aa57828722e6ae3942efa", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/5e3a8033dac9bdf38f8aa57828722e6ae3942efa", "committedDate": "2020-12-15T19:56:55Z", "message": "Use different condition style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30a16c804422c2549a5945b18498e5f725736842", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/30a16c804422c2549a5945b18498e5f725736842", "committedDate": "2020-12-15T20:59:42Z", "message": "Fix indentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0d32b2827ae82a07e164fc155c7fda74d07d5c4", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f0d32b2827ae82a07e164fc155c7fda74d07d5c4", "committedDate": "2021-01-13T16:06:33Z", "message": "Merge branch 'master' into csv-performance\n\n# Conflicts:\n#\textensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java\n#\thazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java\n#\thazelcast-jet-core/src/test/java/com/hazelcast/jet/impl/util/UtilTest.java\n#\thazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/JsonMetadataResolver.java\n#\thazelcast-jet-sql/src/test/java/com/hazelcast/jet/sql/impl/connector/file/SqlCsvTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "981e69db77acf85a5f77791d3300d0117bccf13e", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/981e69db77acf85a5f77791d3300d0117bccf13e", "committedDate": "2021-01-14T08:25:33Z", "message": "Formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f7265495ef3f81ecd7bc02e41a48110d5179698", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1f7265495ef3f81ecd7bc02e41a48110d5179698", "committedDate": "2021-01-14T12:20:34Z", "message": "Refactor CSV file format API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d0554f74a73f5499ae9256216e1537a42e0d974", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1d0554f74a73f5499ae9256216e1537a42e0d974", "committedDate": "2021-01-14T13:55:42Z", "message": "Merge pull request #2 from gierlachg/refactor\n\nRefactor CSV file format API"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4MjcxMTAz", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#pullrequestreview-568271103", "createdAt": "2021-01-14T14:15:04Z", "commit": {"oid": "1d0554f74a73f5499ae9256216e1537a42e0d974"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4Mjc5NDAz", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#pullrequestreview-568279403", "createdAt": "2021-01-14T14:24:13Z", "commit": {"oid": "1d0554f74a73f5499ae9256216e1537a42e0d974"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3430, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}