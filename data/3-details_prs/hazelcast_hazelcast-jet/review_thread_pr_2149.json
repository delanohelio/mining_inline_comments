{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwMjQ0ODYx", "number": 2149, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo0MzoyM1rODxmzCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwNjo0MzoyNlrOD3fr1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMzQyNDcyOnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/pipeline/SinksTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo0MzoyM1rOGFKtDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo0MzoyM1rOGFKtDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3MTQzNw==", "bodyText": "when_writeToMultipleStagesToSingleSink_then_allItemsShouldBeOnSink (to conform to convention)?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r408071437", "createdAt": "2020-04-14T11:43:23Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/pipeline/SinksTest.java", "diffHunk": "@@ -117,7 +117,7 @@ public void when_setLocalParallelism_then_sinkHasIt() {\n     }\n \n     @Test\n-    public void whenDrainToMultipleStagesToSingleSink_thenAllItemsShouldBeOnSink() {\n+    public void whenWriteToMultipleStagesToSingleSink_thenAllItemsShouldBeOnSink() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db7b55a622c89b1d74dc17c60ee83255231c5e74"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMzQ0MDc3OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/pipeline/RebalanceBatchStageTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo0ODowNlrOGFK21A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo0ODowNlrOGFK21A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3Mzk0MA==", "bodyText": "Does it make sense to add RebalanceStreamStageTest? If not, maybe rename to simply RebalanceStageTest?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r408073940", "createdAt": "2020-04-14T11:48:06Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/pipeline/RebalanceBatchStageTest.java", "diffHunk": "@@ -0,0 +1,334 @@\n+package com.hazelcast.jet.pipeline;\n+\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.accumulator.LongAccumulator;\n+import com.hazelcast.jet.aggregate.AggregateOperation1;\n+import com.hazelcast.jet.aggregate.AggregateOperations;\n+import com.hazelcast.jet.core.DAG;\n+import com.hazelcast.jet.core.Edge;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.datamodel.Tuple3;\n+import com.hazelcast.jet.pipeline.test.AssertionSinks;\n+import org.junit.Test;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.stream.IntStream;\n+import java.util.stream.Stream;\n+\n+import static com.hazelcast.jet.core.test.JetAssert.assertFalse;\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.datamodel.Tuple3.tuple3;\n+import static com.hazelcast.jet.pipeline.BatchAggregateTest.FORMAT_FN;\n+import static com.hazelcast.jet.pipeline.BatchAggregateTest.FORMAT_FN_2;\n+import static com.hazelcast.jet.pipeline.BatchAggregateTest.FORMAT_FN_3;\n+import static com.hazelcast.jet.pipeline.test.AssertionSinks.assertAnyOrder;\n+import static java.util.Collections.singletonList;\n+import static java.util.Spliterators.spliteratorUnknownSize;\n+import static java.util.function.Function.identity;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.summingLong;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.StreamSupport.stream;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class RebalanceBatchStageTest extends PipelineTestSupport {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db7b55a622c89b1d74dc17c60ee83255231c5e74"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMzQ3OTY4OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/pipeline/PipelineImpl.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo1OTowN1rOGFLN_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxMTo1OTowN1rOGFLN_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3OTg2OQ==", "bodyText": "Maybe computeIfAbsent would be better here as it leaves the map unmodified (so for instance one could print existing one for debugging purposes)?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r408079869", "createdAt": "2020-04-14T11:59:07Z", "author": {"login": "gierlachg"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/pipeline/PipelineImpl.java", "diffHunk": "@@ -160,12 +206,8 @@ void makeNamesUnique() {\n         }\n     }\n \n-    public void attachFiles(@Nonnull Map<String, File> filesToAttach) {\n-        this.attachedFiles.putAll(filesToAttach);\n-    }\n-\n-    @Nonnull\n-    public Map<String, File> attachedFiles() {\n-        return Collections.unmodifiableMap(attachedFiles);\n+    private void register(Transform stage) {\n+        List<Transform> prev = adjacencyMap.put(stage, new ArrayList<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db7b55a622c89b1d74dc17c60ee83255231c5e74"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNDI2MzI0OnYy", "diffSide": "RIGHT", "path": "site/docs/design-docs/007-stage-rebalance.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDo1ODoyOFrOGFS3aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDo1ODoyOFrOGFS3aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNTE2Mw==", "bodyText": "Should be readFrom?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r408205163", "createdAt": "2020-04-14T14:58:28Z", "author": {"login": "gierlachg"}, "path": "site/docs/design-docs/007-stage-rebalance.md", "diffHunk": "@@ -0,0 +1,225 @@\n+---\n+title: Rebalance Data on a Pipeline Stage\n+description: Adds a stage.rebalance() method that results in a\n+distributed DAG edge from this stage to the next one.\n+---\n+\n+By default, Jet uses local DAG edges, which means that the data that\n+originated on a given cluster member stays within it. This has the\n+advantage of avoiding the latency of network hops and congesting the\n+links between members. The disadvantage is that the data may be\n+imbalanced across members, especially when using a non-distributed data\n+source. We are therefore introducing a Pipeline API method,\n+`stage.rebalance()`, that allows the user to decide where the data\n+should be distributed across all members.\n+\n+There are two ways of balancing the data on an edge: using a\n+self-balancing round-robin scheme and using a partitioning key that\n+makes for each data item a fixed decision on its target processor. We\n+provide both methods.\n+\n+## Semantics\n+\n+```java\n+stage.rebalance().map(Person::getName)\n+```\n+\n+Jet uses a round-robin distributed edge from `stage` to `map`.\n+\n+```java\n+stage.rebalance(Person::getName).map(Person::getAge)\n+```\n+\n+Jet uses a distributed edge partitioned by `Person::getName`.\n+\n+```java\n+stage.map(Person::getName).rebalance().flatMap(s -> traverseArray(s.toCharArray()))\n+```\n+\n+Jet doesn't fuse `map` and `flatMap`, uses a distributed round-robin\n+edge between them.\n+\n+```java\n+stage0 = ...\n+stage1 = src.rebalance();\n+stage0.merge(stage1);\n+```\n+\n+For merging, Jet independently rebalances the stages as requested.\n+\n+```java\n+stage.rebalance().aggregate(...)\n+or\n+stage.rebalance(Person::getName).aggregate(...)\n+```\n+\n+Jet uses single-stage aggregation instead of the default two-stage,\n+but global aggregation still requires all computation to happen on one\n+processor. The actual effect is the opposite of rebalancing, maybe we\n+should just throw an error for this.\n+\n+```java\n+stage.rebalance().groupingKey(Person:getAge).aggregate(...)\n+```\n+\n+Jet uses single-stage aggregation, partitions the edge with the grouping\n+key.\n+\n+```java\n+stage.rebalance(Person::getName).groupingKey(Person:getAge)\n+```\n+\n+For all transforms except aggregation, rebalancing has no effect here\n+since `groupingKey()` by itself results in a distributed-partitioned\n+edge.\n+\n+Aggregation is by default two-stage and `rebalance()` makes it\n+single-stage, so it has some effect but still the rebalancing key is\n+ignored. The grouping key must be used for semantic correctness.\n+\n+Maybe we should throw an error for any `rebalance(fn1).groupingKey(fn2)`\n+call. The same applies to `rebalance(fn1).window(wDef).groupingKey(fn2)`\n+\n+```java\n+stage0 = stage.groupingKey(Person:getAge)\n+stage1 = stage.rebalance().groupingKey(Person:getAge)\n+\n+stage0.aggregate(stage1, ...)\n+```\n+\n+If any of the joined stages are rebalanced, Jet uses single-stage\n+aggregation.\n+\n+```java\n+stage0 = p.drawFrom(src0).rebalance();\n+enrichingStage1 = p.drawFrom(src1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf814120fc4c2374b72594a4c4f40d05503d9289"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNDI2NDg0OnYy", "diffSide": "RIGHT", "path": "site/docs/design-docs/007-stage-rebalance.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDo1ODo0NlrOGFS4Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDo1ODo0NlrOGFS4Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNTQxMA==", "bodyText": "Should be readFrom?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r408205410", "createdAt": "2020-04-14T14:58:46Z", "author": {"login": "gierlachg"}, "path": "site/docs/design-docs/007-stage-rebalance.md", "diffHunk": "@@ -0,0 +1,225 @@\n+---\n+title: Rebalance Data on a Pipeline Stage\n+description: Adds a stage.rebalance() method that results in a\n+distributed DAG edge from this stage to the next one.\n+---\n+\n+By default, Jet uses local DAG edges, which means that the data that\n+originated on a given cluster member stays within it. This has the\n+advantage of avoiding the latency of network hops and congesting the\n+links between members. The disadvantage is that the data may be\n+imbalanced across members, especially when using a non-distributed data\n+source. We are therefore introducing a Pipeline API method,\n+`stage.rebalance()`, that allows the user to decide where the data\n+should be distributed across all members.\n+\n+There are two ways of balancing the data on an edge: using a\n+self-balancing round-robin scheme and using a partitioning key that\n+makes for each data item a fixed decision on its target processor. We\n+provide both methods.\n+\n+## Semantics\n+\n+```java\n+stage.rebalance().map(Person::getName)\n+```\n+\n+Jet uses a round-robin distributed edge from `stage` to `map`.\n+\n+```java\n+stage.rebalance(Person::getName).map(Person::getAge)\n+```\n+\n+Jet uses a distributed edge partitioned by `Person::getName`.\n+\n+```java\n+stage.map(Person::getName).rebalance().flatMap(s -> traverseArray(s.toCharArray()))\n+```\n+\n+Jet doesn't fuse `map` and `flatMap`, uses a distributed round-robin\n+edge between them.\n+\n+```java\n+stage0 = ...\n+stage1 = src.rebalance();\n+stage0.merge(stage1);\n+```\n+\n+For merging, Jet independently rebalances the stages as requested.\n+\n+```java\n+stage.rebalance().aggregate(...)\n+or\n+stage.rebalance(Person::getName).aggregate(...)\n+```\n+\n+Jet uses single-stage aggregation instead of the default two-stage,\n+but global aggregation still requires all computation to happen on one\n+processor. The actual effect is the opposite of rebalancing, maybe we\n+should just throw an error for this.\n+\n+```java\n+stage.rebalance().groupingKey(Person:getAge).aggregate(...)\n+```\n+\n+Jet uses single-stage aggregation, partitions the edge with the grouping\n+key.\n+\n+```java\n+stage.rebalance(Person::getName).groupingKey(Person:getAge)\n+```\n+\n+For all transforms except aggregation, rebalancing has no effect here\n+since `groupingKey()` by itself results in a distributed-partitioned\n+edge.\n+\n+Aggregation is by default two-stage and `rebalance()` makes it\n+single-stage, so it has some effect but still the rebalancing key is\n+ignored. The grouping key must be used for semantic correctness.\n+\n+Maybe we should throw an error for any `rebalance(fn1).groupingKey(fn2)`\n+call. The same applies to `rebalance(fn1).window(wDef).groupingKey(fn2)`\n+\n+```java\n+stage0 = stage.groupingKey(Person:getAge)\n+stage1 = stage.rebalance().groupingKey(Person:getAge)\n+\n+stage0.aggregate(stage1, ...)\n+```\n+\n+If any of the joined stages are rebalanced, Jet uses single-stage\n+aggregation.\n+\n+```java\n+stage0 = p.drawFrom(src0).rebalance();\n+enrichingStage1 = p.drawFrom(src1);\n+joinedStage = stage0.hashJoin(enrichingStage1, joinMapEntries());\n+```\n+\n+Hash join is just a stateless mapping transform of `stage0`, so this\n+uses a round-robin distributed edge from `stage0` to `joinedStage`.\n+\n+```java\n+stage0 = p.drawFrom(src0);\n+enrichingStage1 = p.drawFrom(src1).rebalance();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf814120fc4c2374b72594a4c4f40d05503d9289"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTcwOTY2OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/core/DAG.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozMjoxMVrOGGabrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozMjoxMVrOGGabrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM3NzcxMA==", "bodyText": "shouldn't it be @Nullable then?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r409377710", "createdAt": "2020-04-16T08:32:11Z", "author": {"login": "cangencer"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/core/DAG.java", "diffHunk": "@@ -220,18 +220,17 @@ public DAG edge(@Nonnull Edge edge) {\n     }\n \n     /**\n-     * Returns the vertex with the given name.\n+     * Returns the vertex with the given name, or {@code null} if there is no\n+     * vertex with that name.\n      */\n-    @Nonnull\n     public Vertex getVertex(@Nonnull String vertexName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c77f2fc8cfe667f6077b5cf92b7627b3f36670"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTcxNTE2OnYy", "diffSide": "RIGHT", "path": "site/docs/design-docs/008-stage-rebalance.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozMzo0MFrOGGafWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozMzo0MFrOGGafWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM3ODY1MQ==", "bodyText": "should include the numerical id here", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r409378651", "createdAt": "2020-04-16T08:33:40Z", "author": {"login": "cangencer"}, "path": "site/docs/design-docs/008-stage-rebalance.md", "diffHunk": "@@ -0,0 +1,225 @@\n+---\n+title: Rebalance Data on a Pipeline Stage", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c77f2fc8cfe667f6077b5cf92b7627b3f36670"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTczNjA4OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozOTowMlrOGGasqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozOTowMlrOGGasqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM4MjA1Ng==", "bodyText": "missing @Nonnull and @since tags", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r409382056", "createdAt": "2020-04-16T08:39:02Z", "author": {"login": "cangencer"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -846,6 +850,12 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    @Nonnull\n+    <K> GeneralStage<T> rebalance(FunctionEx<? super T, ? extends K> keyFn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c77f2fc8cfe667f6077b5cf92b7627b3f36670"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTczNzYzOnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozOToyNlrOGGatqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwODozOToyNlrOGGatqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM4MjMxNQ==", "bodyText": "missing @since tag", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r409382315", "createdAt": "2020-04-16T08:39:26Z", "author": {"login": "cangencer"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -846,6 +850,12 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    @Nonnull\n+    <K> GeneralStage<T> rebalance(FunctionEx<? super T, ? extends K> keyFn);\n+\n+    @Nonnull\n+    GeneralStage<T> rebalance();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0c77f2fc8cfe667f6077b5cf92b7627b3f36670"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTEzNDQ1OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/pipeline/transform/AbstractTransform.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwNjoyNzozNFrOGNxQOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwNjoyNzozNFrOGNxQOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA5MTY0Mw==", "bodyText": "Rename to setPartitionKeyFnForInput to match public FunctionEx<?, ?> partitionKeyFnForInput(int ordinal)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r417091643", "createdAt": "2020-04-29T06:27:34Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/pipeline/transform/AbstractTransform.java", "diffHunk": "@@ -69,9 +77,24 @@ public int localParallelism() {\n         return localParallelism;\n     }\n \n-    @Nonnull\n-    Optimization getOptimization() {\n-        return optimization;\n+    @Override\n+    public void setRebalanceInput(int ordinal, boolean value) {\n+        upstreamRebalancingFlags[ordinal] = value;\n+    }\n+\n+    @Override\n+    public void setRebalanceKeyForInput(int ordinal, FunctionEx<?, ?> keyFn) {\n+        upstreamPartitionKeyFns[ordinal] = keyFn;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "754b2da4609fdd0ca6ce36270968789ded524881"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTE3MjM1OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwNjo0Mjo0OVrOGNxmAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwODowMDoyMlrOGNz08A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA5NzIxOA==", "bodyText": "Shouldn't these have @since tags because this is public API?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r417097218", "createdAt": "2020-04-29T06:42:49Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -941,6 +943,127 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    /**\n+     * Returns a new stage that applies data rebalancing to the output of this\n+     * stage. By default, Jet prefers to process the data locally, on the\n+     * cluster member where it was originally received. This is generally a\n+     * good option because it eliminates unneeded network traffic. However, if\n+     * the data volume is highly skewed across members, for example when using\n+     * a non-distributed data source, you can tell Jet to rebalance the data by\n+     * sending some to the other members.\n+     * <p>\n+     * To implement rebalancing, Jet uses a <em>distributed unicast</em> data\n+     * routing pattern on the DAG edge from this stage's vertex to the next one.\n+     * It routes the data in a round-robin fashion, sending each item to the\n+     * next member (member list includes the local one as well). If a given\n+     * member's queue is overloaded and applying backpressure, it skips it and\n+     * retries in the next round. With this scheme you get perfectly balanced\n+     * item counts on each member under light load, but under heavier load it\n+     * favors throughput: if the network becomes a bottleneck, most data may\n+     * stay local.\n+     * <p>\n+     * These are some basic invariants:\n+     * <ol><li>\n+     *     The rebalancing stage does not transform data, it just changes the\n+     *     physical layout of computation.\n+     * </li><li>\n+     *     If rebalancing is inapplicable due to the nature of the downstream\n+     *     stage (for example, a non-parallelizable operation like stateful\n+     *     mapping), the rebalancing stage is removed from the execution plan.\n+     * </li><li>\n+     *     If the downstream stage already does rebalancing for correctness (e.g.,\n+     *     grouping by key implies partitioning by that key), this rebalancing\n+     *     stage is optimized away.\n+     * </li></ol>\n+     * Aggregation is a special case because it is implemented with two\n+     * vertices at the Core DAG level. The first vertex accumulates local\n+     * partial results and the second one combines them globally. There are two\n+     * cases:\n+     * <ol><li>\n+     *     {@code stage.rebalance().groupingKey(keyFn).aggregate(...)}: here Jet\n+     *     removes the first (local) aggregation vertex and goes straight to\n+     *     distributed aggregation without combining. The data is rebalanced\n+     *     through partitioning.\n+     * </li><li>\n+     *     {@code stage.rebalance().aggregate(...)}: in this case the second vertex\n+     *     is non-parallelizable and must execute on a single member. Therefore Jet\n+     *     keeps both vertices and applies rebalancing before the first one.\n+     * </li></ol>\n+     *\n+     * @return a new stage using the same transform as this one, only with a\n+     *         rebalancing flag raised that will affect data routing into the next\n+     *         stage.\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    GeneralStage<T> rebalance();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "754b2da4609fdd0ca6ce36270968789ded524881"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzEzMzgwOA==", "bodyText": "I see a @since tag three lines above your comment :)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r417133808", "createdAt": "2020-04-29T08:00:22Z", "author": {"login": "mtopolnik"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -941,6 +943,127 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    /**\n+     * Returns a new stage that applies data rebalancing to the output of this\n+     * stage. By default, Jet prefers to process the data locally, on the\n+     * cluster member where it was originally received. This is generally a\n+     * good option because it eliminates unneeded network traffic. However, if\n+     * the data volume is highly skewed across members, for example when using\n+     * a non-distributed data source, you can tell Jet to rebalance the data by\n+     * sending some to the other members.\n+     * <p>\n+     * To implement rebalancing, Jet uses a <em>distributed unicast</em> data\n+     * routing pattern on the DAG edge from this stage's vertex to the next one.\n+     * It routes the data in a round-robin fashion, sending each item to the\n+     * next member (member list includes the local one as well). If a given\n+     * member's queue is overloaded and applying backpressure, it skips it and\n+     * retries in the next round. With this scheme you get perfectly balanced\n+     * item counts on each member under light load, but under heavier load it\n+     * favors throughput: if the network becomes a bottleneck, most data may\n+     * stay local.\n+     * <p>\n+     * These are some basic invariants:\n+     * <ol><li>\n+     *     The rebalancing stage does not transform data, it just changes the\n+     *     physical layout of computation.\n+     * </li><li>\n+     *     If rebalancing is inapplicable due to the nature of the downstream\n+     *     stage (for example, a non-parallelizable operation like stateful\n+     *     mapping), the rebalancing stage is removed from the execution plan.\n+     * </li><li>\n+     *     If the downstream stage already does rebalancing for correctness (e.g.,\n+     *     grouping by key implies partitioning by that key), this rebalancing\n+     *     stage is optimized away.\n+     * </li></ol>\n+     * Aggregation is a special case because it is implemented with two\n+     * vertices at the Core DAG level. The first vertex accumulates local\n+     * partial results and the second one combines them globally. There are two\n+     * cases:\n+     * <ol><li>\n+     *     {@code stage.rebalance().groupingKey(keyFn).aggregate(...)}: here Jet\n+     *     removes the first (local) aggregation vertex and goes straight to\n+     *     distributed aggregation without combining. The data is rebalanced\n+     *     through partitioning.\n+     * </li><li>\n+     *     {@code stage.rebalance().aggregate(...)}: in this case the second vertex\n+     *     is non-parallelizable and must execute on a single member. Therefore Jet\n+     *     keeps both vertices and applies rebalancing before the first one.\n+     * </li></ol>\n+     *\n+     * @return a new stage using the same transform as this one, only with a\n+     *         rebalancing flag raised that will affect data routing into the next\n+     *         stage.\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    GeneralStage<T> rebalance();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA5NzIxOA=="}, "originalCommit": {"oid": "754b2da4609fdd0ca6ce36270968789ded524881"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5NTE3Mzk3OnYy", "diffSide": "RIGHT", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwNjo0MzoyNlrOGNxm7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwODowMToyMVrOGNz3DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA5NzQ1NA==", "bodyText": "Is this visible on the DAG we print to the log?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r417097454", "createdAt": "2020-04-29T06:43:26Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -941,6 +943,127 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    /**\n+     * Returns a new stage that applies data rebalancing to the output of this\n+     * stage. By default, Jet prefers to process the data locally, on the\n+     * cluster member where it was originally received. This is generally a\n+     * good option because it eliminates unneeded network traffic. However, if\n+     * the data volume is highly skewed across members, for example when using\n+     * a non-distributed data source, you can tell Jet to rebalance the data by\n+     * sending some to the other members.\n+     * <p>\n+     * To implement rebalancing, Jet uses a <em>distributed unicast</em> data\n+     * routing pattern on the DAG edge from this stage's vertex to the next one.\n+     * It routes the data in a round-robin fashion, sending each item to the\n+     * next member (member list includes the local one as well). If a given\n+     * member's queue is overloaded and applying backpressure, it skips it and\n+     * retries in the next round. With this scheme you get perfectly balanced\n+     * item counts on each member under light load, but under heavier load it\n+     * favors throughput: if the network becomes a bottleneck, most data may\n+     * stay local.\n+     * <p>\n+     * These are some basic invariants:\n+     * <ol><li>\n+     *     The rebalancing stage does not transform data, it just changes the\n+     *     physical layout of computation.\n+     * </li><li>\n+     *     If rebalancing is inapplicable due to the nature of the downstream\n+     *     stage (for example, a non-parallelizable operation like stateful\n+     *     mapping), the rebalancing stage is removed from the execution plan.\n+     * </li><li>\n+     *     If the downstream stage already does rebalancing for correctness (e.g.,\n+     *     grouping by key implies partitioning by that key), this rebalancing\n+     *     stage is optimized away.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "754b2da4609fdd0ca6ce36270968789ded524881"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzEzNDM0OQ==", "bodyText": "The effects of rebalancing are visible in the DAG, but never as a \"rebalancing vertex\". It just changes the DAG", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2149#discussion_r417134349", "createdAt": "2020-04-29T08:01:21Z", "author": {"login": "mtopolnik"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/GeneralStage.java", "diffHunk": "@@ -941,6 +943,127 @@\n     @Nonnull\n     <K> GeneralStageWithKey<T, K> groupingKey(@Nonnull FunctionEx<? super T, ? extends K> keyFn);\n \n+    /**\n+     * Returns a new stage that applies data rebalancing to the output of this\n+     * stage. By default, Jet prefers to process the data locally, on the\n+     * cluster member where it was originally received. This is generally a\n+     * good option because it eliminates unneeded network traffic. However, if\n+     * the data volume is highly skewed across members, for example when using\n+     * a non-distributed data source, you can tell Jet to rebalance the data by\n+     * sending some to the other members.\n+     * <p>\n+     * To implement rebalancing, Jet uses a <em>distributed unicast</em> data\n+     * routing pattern on the DAG edge from this stage's vertex to the next one.\n+     * It routes the data in a round-robin fashion, sending each item to the\n+     * next member (member list includes the local one as well). If a given\n+     * member's queue is overloaded and applying backpressure, it skips it and\n+     * retries in the next round. With this scheme you get perfectly balanced\n+     * item counts on each member under light load, but under heavier load it\n+     * favors throughput: if the network becomes a bottleneck, most data may\n+     * stay local.\n+     * <p>\n+     * These are some basic invariants:\n+     * <ol><li>\n+     *     The rebalancing stage does not transform data, it just changes the\n+     *     physical layout of computation.\n+     * </li><li>\n+     *     If rebalancing is inapplicable due to the nature of the downstream\n+     *     stage (for example, a non-parallelizable operation like stateful\n+     *     mapping), the rebalancing stage is removed from the execution plan.\n+     * </li><li>\n+     *     If the downstream stage already does rebalancing for correctness (e.g.,\n+     *     grouping by key implies partitioning by that key), this rebalancing\n+     *     stage is optimized away.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA5NzQ1NA=="}, "originalCommit": {"oid": "754b2da4609fdd0ca6ce36270968789ded524881"}, "originalPosition": 162}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4791, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}