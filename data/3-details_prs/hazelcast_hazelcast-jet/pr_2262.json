{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5OTE2MjQ0", "number": 2262, "title": "[005] Improve CDC map sink", "bodyText": "Checklist\n\n Tags Set\n Milestone Set", "createdAt": "2020-05-19T06:55:04Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262", "merged": true, "mergeCommit": {"oid": "e779ae522359ab9eee05751433dace18abe9c86f"}, "closed": true, "closedAt": "2020-05-31T05:54:22Z", "author": {"login": "jbartok"}, "timelineItems": {"totalCount": 59, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABciu2GfAH2gAyNDE5OTE2MjQ0OjJjOWYwMjMyNTMyZTZmYWIyMmQxNWI1YzAwNjI0OTQ4ZDgzYjMwNDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcmkt3WgH2gAyNDE5OTE2MjQ0OjkyYjliZTI2NmRkZTYxNjFlZDYyZjFmNTE4YjQxNjM1NTc2MmQ3OGU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2c9f0232532e6fab22d15b5c00624948d83b3045", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/2c9f0232532e6fab22d15b5c00624948d83b3045", "committedDate": "2020-05-19T06:54:14Z", "message": "Improve CDC map sink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c34aefe42fbdf6cf1b477e6e2edf461b3e2ee482", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c34aefe42fbdf6cf1b477e6e2edf461b3e2ee482", "committedDate": "2020-05-19T07:01:11Z", "message": "Add CDCSink to website content"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b08735b1b88f2e38d996292e19d94d2ee329439", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1b08735b1b88f2e38d996292e19d94d2ee329439", "committedDate": "2020-05-19T08:02:25Z", "message": "Move partition service to base class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fe62a795be6c40ff6b1eb56e81128c114452c6d", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/4fe62a795be6c40ff6b1eb56e81128c114452c6d", "committedDate": "2020-05-19T10:25:33Z", "message": "Extract more commong code from processors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8826136b866ecea8ea4b08a58fad441f61fc1409", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/8826136b866ecea8ea4b08a58fad441f61fc1409", "committedDate": "2020-05-20T07:09:40Z", "message": "Merge branch 'master' into cdc-sink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43418d245369b41ef55fe233dd3d6c9fa8529bc2", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/43418d245369b41ef55fe233dd3d6c9fa8529bc2", "committedDate": "2020-05-20T11:07:47Z", "message": "Get rid of some Supplier classes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4730f2c19348965981e4395f954cb481564fb171", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/4730f2c19348965981e4395f954cb481564fb171", "committedDate": "2020-05-21T09:39:41Z", "message": "Add sequence tracking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7b50785fa19789780f919830d8823488d0690e5", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/e7b50785fa19789780f919830d8823488d0690e5", "committedDate": "2020-05-21T12:02:08Z", "message": "Fix checkstyle and javadoc stuff"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c12f76e4bd483c59bf398d73ac3e90bd6600868a", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c12f76e4bd483c59bf398d73ac3e90bd6600868a", "committedDate": "2020-05-21T12:49:04Z", "message": "Add integration test for CdcSinks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a40e5436e80f2e0c3ef439d532dcc587c4402348", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a40e5436e80f2e0c3ef439d532dcc587c4402348", "committedDate": "2020-05-21T12:53:32Z", "message": "Specify charset"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "476c1135e490e9996e2e1ee0404f2054a61a564c", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/476c1135e490e9996e2e1ee0404f2054a61a564c", "committedDate": "2020-05-25T08:29:47Z", "message": "Fix license in POM file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "758e8d18b042e658e8bc201db93f9828bf60df78", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/758e8d18b042e658e8bc201db93f9828bf60df78", "committedDate": "2020-05-25T08:30:28Z", "message": "Save CDC sink state to snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2ec156b69719c2727d00d6afc5582761b032658", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d2ec156b69719c2727d00d6afc5582761b032658", "committedDate": "2020-05-25T09:22:12Z", "message": "Fix checkstyle issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6ad8b72285cba56e0e99f68c61a46685c1e1c09", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a6ad8b72285cba56e0e99f68c61a46685c1e1c09", "committedDate": "2020-05-25T09:38:45Z", "message": "Make ordering detection non-optional"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20105303b889ca6d511aaf318bb4ac53a35af8f2", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/20105303b889ca6d511aaf318bb4ac53a35af8f2", "committedDate": "2020-05-25T10:03:26Z", "message": "Add test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "914b3a823b8e737500a38316fb5591964cbafec0", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/914b3a823b8e737500a38316fb5591964cbafec0", "committedDate": "2020-05-25T10:03:41Z", "message": "Remove saving state to snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e98ae555d4aecd0da275e13307df0cb1bfa76785", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/e98ae555d4aecd0da275e13307df0cb1bfa76785", "committedDate": "2020-05-25T10:55:30Z", "message": "Remove saving state to snapshot"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26e1c73403294432d216a0a38f5123a0219088ee", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/26e1c73403294432d216a0a38f5123a0219088ee", "committedDate": "2020-05-25T11:42:56Z", "message": "Merge branch 'master' into cdc-sink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/319d3abedf96708f1b2d4dc940a12b6934dfb246", "committedDate": "2020-05-25T12:09:55Z", "message": "Limit sequence cache size (LRU)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDAzNzcx", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418003771", "createdAt": "2020-05-26T06:31:58Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMTo1OVrOGaQUuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMTo1OVrOGaQUuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzYwOA==", "bodyText": "3.2?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183608", "createdAt": "2020-05-26T06:31:59Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDAzOTAx", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418003901", "createdAt": "2020-05-26T06:32:14Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjoxNFrOGaQVGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjoxNFrOGaQVGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzcwNQ==", "bodyText": "mirror/replica would be better", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183705", "createdAt": "2020-05-26T06:32:14Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA0MTU1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418004155", "createdAt": "2020-05-26T06:32:50Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1MFrOGaQV5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1MFrOGaQV5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzkxMQ==", "bodyText": "I think we should be more explicit here in the doc", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183911", "createdAt": "2020-05-26T06:32:50Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 143}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA0MjA5", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418004209", "createdAt": "2020-05-26T06:32:57Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1N1rOGaQWFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1N1rOGaQWFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4Mzk1OQ==", "bodyText": "this is wrong, it should be 4.0", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183959", "createdAt": "2020-05-26T06:32:57Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA1MjUw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418005250", "createdAt": "2020-05-26T06:35:08Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNTowOFrOGaQZpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNTowOFrOGaQZpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NDg3MQ==", "bodyText": "what is expiration?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430184871", "createdAt": "2020-05-26T06:35:08Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 238}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA1Mzc4", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418005378", "createdAt": "2020-05-26T06:35:25Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNToyNVrOGaQaDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNToyNVrOGaQaDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NDk3Mg==", "bodyText": "this is quite large", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430184972", "createdAt": "2020-05-26T06:35:25Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 233}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA1Njg4", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418005688", "createdAt": "2020-05-26T06:36:07Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjowN1rOGaQbDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjowN1rOGaQbDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NTIzMQ==", "bodyText": "can yo uwrite some javadoc explaining what this does, the name doesn't tell much", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430185231", "createdAt": "2020-05-26T06:36:07Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 231}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA1Nzk5", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418005799", "createdAt": "2020-05-26T06:36:21Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjoyMVrOGaQbYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjoyMVrOGaQbYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NTMxNQ==", "bodyText": "what's stored here?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430185315", "createdAt": "2020-05-26T06:36:21Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 236}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA2OTE5", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418006919", "createdAt": "2020-05-26T06:38:40Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo0MFrOGaQevw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo0MFrOGaQevw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjE3NQ==", "bodyText": "can this happen? if not, it should just be an assertion", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430186175", "createdAt": "2020-05-26T06:38:40Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[] {partition, value, timestamp});\n+                return true;\n+            } else {\n+                prevSequence[2] = timestamp;\n+                if (prevSequence[0] != partition) { //sequence partition changed for key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 255}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MDA3MDU1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418007055", "createdAt": "2020-05-26T06:38:56Z", "commit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo1NlrOGaQfFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo1NlrOGaQfFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjI2Mw==", "bodyText": "you can use compute instead of doing two separate put/gets (two hash lookups)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430186263", "createdAt": "2020-05-26T06:38:56Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 249}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "028cfb78525261340e28fbbb96182afafa34c286", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/028cfb78525261340e28fbbb96182afafa34c286", "committedDate": "2020-05-26T07:36:08Z", "message": "Fix versions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ddbfff4cc32bc456ab5c1dee235507e4d477a0ba", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/ddbfff4cc32bc456ab5c1dee235507e4d477a0ba", "committedDate": "2020-05-26T08:21:10Z", "message": "Address review concerns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3cc4969ad1d86b0eb24037c2cf95d1148d19d841", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3cc4969ad1d86b0eb24037c2cf95d1148d19d841", "committedDate": "2020-05-26T09:02:28Z", "message": "Move back to using system time for expiration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94", "committedDate": "2020-05-26T10:32:13Z", "message": "Fix minor issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MTg5OTA1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418189905", "createdAt": "2020-05-26T11:02:03Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjowNFrOGaZPZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjowNFrOGaZPZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMyOTcwMQ==", "bodyText": "you don't need the else here.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430329701", "createdAt": "2020-05-26T11:02:04Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 318}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MTkwMDcy", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418190072", "createdAt": "2020-05-26T11:02:20Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjoyMFrOGaZP7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjoyMFrOGaZP7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMyOTgzOQ==", "bodyText": "can be inlined", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430329839", "createdAt": "2020-05-26T11:02:20Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 249}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MTkwMzc3", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418190377", "createdAt": "2020-05-26T11:02:48Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjo0OVrOGaZQ6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjo0OVrOGaZQ6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMDA4OQ==", "bodyText": "no need for else", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430330089", "createdAt": "2020-05-26T11:02:49Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {\n+                prevSequence[2] = System.currentTimeMillis();\n+                if (prevSequence[0] != partition) { //sequence partition changed for key\n+                    prevSequence[0] = partition;\n+                    prevSequence[1] = sequence;\n+                    return true;\n+                } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 324}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MTkwNjU4", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418190658", "createdAt": "2020-05-26T11:03:15Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMzoxNVrOGaZRtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMzoxNVrOGaZRtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMDI5NQ==", "bodyText": "no need for else", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430330295", "createdAt": "2020-05-26T11:03:15Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {\n+                prevSequence[2] = System.currentTimeMillis();\n+                if (prevSequence[0] != partition) { //sequence partition changed for key\n+                    prevSequence[0] = partition;\n+                    prevSequence[1] = sequence;\n+                    return true;\n+                } else {\n+                    if (prevSequence[1] < sequence) { //sequence is newer than previous for key\n+                        prevSequence[1] = sequence;\n+                        return true;\n+                    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 328}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MTkxODUw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418191850", "createdAt": "2020-05-26T11:05:04Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowNTowNVrOGaZVWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowNTowNVrOGaZVWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMTIyNw==", "bodyText": "this is not true, it's a specific three element array and the role of each element is well defined. it's just not any array that's sorted", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430331227", "createdAt": "2020-05-26T11:05:05Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 261}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4MjY5Mzc0", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-418269374", "createdAt": "2020-05-26T12:57:08Z", "commit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo1NzowOFrOGac-pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMjowNFrOGadLMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5MDk1MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull IMap<? super K, V> map,\n          \n          \n            \n                        @Nonnull IMap<? super K, ? super V> map,", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430390951", "createdAt": "2020-05-26T12:57:08Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5MTk0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430391944", "createdAt": "2020-05-26T12:58:43Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5Mzk0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430393947", "createdAt": "2020-05-26T13:01:43Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5NDE2MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430394160", "createdAt": "2020-05-26T13:02:04Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 203}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cde32bec65bbf9d1bbb7209c0f68fee7bdf5241d", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/cde32bec65bbf9d1bbb7209c0f68fee7bdf5241d", "committedDate": "2020-05-27T06:12:52Z", "message": "Refactor sequence tracking to a cleaner form"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a16b7b1043de8fa67d43a188a552533eefccdaf4", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a16b7b1043de8fa67d43a188a552533eefccdaf4", "committedDate": "2020-05-27T07:39:09Z", "message": "Fix generic type extension"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d43ddafd9834ddbf1a6965d569919b999390fcec", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d43ddafd9834ddbf1a6965d569919b999390fcec", "committedDate": "2020-05-27T13:18:49Z", "message": "Fix naming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea923731bf03c1a6abaa0eb69afb17570a57bd6b", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/ea923731bf03c1a6abaa0eb69afb17570a57bd6b", "committedDate": "2020-05-27T14:04:10Z", "message": "some refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2658115378d61685ffabac9517762f06e16adec9", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/2658115378d61685ffabac9517762f06e16adec9", "committedDate": "2020-05-27T16:05:38Z", "message": "some improvements to update map"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f091a927674a01fbde98fa6e6af329ad3f1f6ca0", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f091a927674a01fbde98fa6e6af329ad3f1f6ca0", "committedDate": "2020-05-27T16:14:13Z", "message": "fix header"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ec8fd72c338356c88059c0fed63ee75d7b91aed", "author": {"user": {"login": "cangencer", "name": "Can Gencer"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1ec8fd72c338356c88059c0fed63ee75d7b91aed", "committedDate": "2020-05-28T06:42:09Z", "message": "fix serialization of EP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d4acc2dbe752b1089738b18d93265aa1e98066d", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/6d4acc2dbe752b1089738b18d93265aa1e98066d", "committedDate": "2020-05-28T09:10:11Z", "message": "Fix alphabetical order in source list"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fffb8198d828ebf8c4e336a16f25449e7ce26493", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/fffb8198d828ebf8c4e336a16f25449e7ce26493", "committedDate": "2020-05-28T09:17:15Z", "message": "Replace total parallelism of one with partitioned-distributed edges"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5e4e4b3e6c1da441e53d6da570e596d162c9e5d", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c5e4e4b3e6c1da441e53d6da570e596d162c9e5d", "committedDate": "2020-05-28T09:43:33Z", "message": "Remove copy-paste leftover"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c811aae1b79b6ae11f0fcb4f802572d8c597627", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/9c811aae1b79b6ae11f0fcb4f802572d8c597627", "committedDate": "2020-05-28T09:44:52Z", "message": "Rename constant to be consistent with previous changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3743f890d37c62d6de86543ac5125203a07e9e18", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3743f890d37c62d6de86543ac5125203a07e9e18", "committedDate": "2020-05-28T10:00:20Z", "message": "Shorten processor hierarchy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50f65a1f53519fd6ba44a0f893f6366a4d9f5284", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/50f65a1f53519fd6ba44a0f893f6366a4d9f5284", "committedDate": "2020-05-28T10:26:50Z", "message": "Rename package in MySQL module"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13c130d16347df89b05c34dea77372a33d38584e", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/13c130d16347df89b05c34dea77372a33d38584e", "committedDate": "2020-05-28T10:41:41Z", "message": "Rename sequence \"partition\" to \"source\""}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b41a763f9fd6dc423bb6e8e6d23a8380d57e3b4", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/8b41a763f9fd6dc423bb6e8e6d23a8380d57e3b4", "committedDate": "2020-05-28T10:44:05Z", "message": "Merge branch 'master' into cdc-sink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b4ac89904b302587a30b57ac551e3dacaf05daa", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/7b4ac89904b302587a30b57ac551e3dacaf05daa", "committedDate": "2020-05-29T07:16:11Z", "message": "Remove duplication of SerializerHook file"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwODI4NjU1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-420828655", "createdAt": "2020-05-29T10:18:45Z", "commit": {"oid": "7b4ac89904b302587a30b57ac551e3dacaf05daa"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2e0ce32410c994cbfd08eba23ae7f86ddcbf236", "author": {"user": {"login": "mtopolnik", "name": "Marko Topolnik"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/b2e0ce32410c994cbfd08eba23ae7f86ddcbf236", "committedDate": "2020-05-29T14:26:46Z", "message": "Marko's edits"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMDA3MDkw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#pullrequestreview-421007090", "createdAt": "2020-05-29T14:27:34Z", "commit": {"oid": "7b4ac89904b302587a30b57ac551e3dacaf05daa"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92b9be266dde6161ed62f1f518b416355762d78e", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/92b9be266dde6161ed62f1f518b416355762d78e", "committedDate": "2020-05-31T05:21:53Z", "message": "Merge branch 'master' into cdc-sink"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3801, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}