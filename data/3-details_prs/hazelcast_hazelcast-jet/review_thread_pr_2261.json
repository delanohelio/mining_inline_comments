{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5NDk3NTgx", "number": 2261, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0MzoxMlrOD9qGLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjoxOVrOD9qJXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1OTc5NDM4OnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-05-18-spark-jet.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0MzoxMlrOGXR9rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0MzoxMlrOGXR9rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA2NDc0OQ==", "bodyText": "4.2?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2261#discussion_r427064749", "createdAt": "2020-05-19T06:43:12Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-05-18-spark-jet.md", "diffHunk": "@@ -0,0 +1,267 @@\n+---\n+title: How Hazelcast Jet Compares to Apache Spark\n+author: Vladimir Schreiner\n+authorURL: https://twitter.com/voloda\n+authorImageURL: https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/speaker-vladimir-schreiner-e1551380845855-170x170.jpg\n+---\n+\n+\u201cHow Jet compares to Spark\u201d and \u201cwhy should I choose Jet over Spark\u201d are\n+arguably the most frequent questions I\u2019ve been asked during the talks\n+and workshops. While it is hard to assess the product fit without\n+focusing on a concrete use-case, I\u2019d still like to compare concepts and\n+architecture used under the hood of both frameworks.\n+\n+Versions considered: [Hazelcast Jet 4.2](https://jet-start.sh/download)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20f8012e638c444520cb8412ea28d43cfe69720"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1OTgwMjUzOnYy", "diffSide": "RIGHT", "path": "site/website/blog/2020-05-18-spark-jet.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjoxOVrOGXSC5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwNjo0NjoxOVrOGXSC5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA2NjA4NQ==", "bodyText": "Do you want full link in the text?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2261#discussion_r427066085", "createdAt": "2020-05-19T06:46:19Z", "author": {"login": "frant-hartm"}, "path": "site/website/blog/2020-05-18-spark-jet.md", "diffHunk": "@@ -0,0 +1,267 @@\n+---\n+title: How Hazelcast Jet Compares to Apache Spark\n+author: Vladimir Schreiner\n+authorURL: https://twitter.com/voloda\n+authorImageURL: https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/speaker-vladimir-schreiner-e1551380845855-170x170.jpg\n+---\n+\n+\u201cHow Jet compares to Spark\u201d and \u201cwhy should I choose Jet over Spark\u201d are\n+arguably the most frequent questions I\u2019ve been asked during the talks\n+and workshops. While it is hard to assess the product fit without\n+focusing on a concrete use-case, I\u2019d still like to compare concepts and\n+architecture used under the hood of both frameworks.\n+\n+Versions considered: [Hazelcast Jet 4.2](https://jet-start.sh/download)\n+and [Apache Spark 2.4.5](https://spark.apache.org/downloads.html).\n+\n+## Computations Modeled as Graphs\n+\n+Apache Spark and Hazelcast Jet (referred to as \u201cframeworks\u201d) are both\n+tools for clustered computing. They are applicable mostly for analytical\n+(OLAP) applications, including those that apply a series of processing\n+steps to many uniform data records (such as lines in a file, rows in a\n+table or records appended to a stream), as one example.\n+\n+Both frameworks build the on principles of dataflow programming: a user\n+builds an application by chaining high-level coarse-grained operators\n+such as map, join or aggregate. The operators form a network that can be\n+modeled as a graph ([directed acyclic\n+graphs](https://en.wikipedia.org/wiki/Directed_acyclic_graph) or DAG to\n+be specific) where nodes represent steps in the computation and edges\n+represent data exchange.\n+\n+The dataflow model has some important properties that both frameworks\n+use for scaling and fault-tolerance:\n+\n+- Pipeline Parallelism: operators can work independently, in parallel.\n+- Data Parallelism: a single operator can run in multiple instances,\n+  each instance processing a particular data partition\n+- No Shared State: each operator instance manages its state exclusively.\n+  There is no shared state to coordinate access to or to replicate.\n+  Moreover, the state is only determined by the input data. As a result,\n+  the operator can be recovered by replaying the input data.\n+\n+Spark and Jet differ in how they use and execute the DAG as explained in\n+the next section but fundamentally: no matter which API you use (RDDs,\n+Spark SQL or a Pipeline API of Jet), **the physical execution plan is a\n+DAG representing the dataflow**.\n+\n+## Staged x Continuous Execution Mode\n+\n+In Spark, the DAG nodes represent execution stages. A stage must be\n+fully completed before Spark starts the next one. In Jet, DAG represents\n+connected operators. Jet executes all DAG nodes concurrently.\n+\n+Let\u2019s use a textbook OLAP example to elaborate: the log analysis (a\n+real-world application of notorious word count). Data from the access\n+logs are aggregated over different grouping keys, such as counting the\n+web sessions over several web applications using shared session id.\n+\n+This is the Spark and Jet code to load the data, pre-process (parse) and\n+aggregate it:\n+\n+Spark RDD API (Java)\n+\n+```java\n+sc.textFile(\"/path/to/input/\")\n+    .flatMap(LineIterator::new)\n+    .mapToPair(s -> new Tuple2<>(s, 1L))\n+    .reduceByKey((Function2<Long, Long, Long>) (a, b) -> a + b)\n+    .saveAsTextFile(\"/path/to/output/\");\n+```\n+\n+Jet Pipeline API (Java)\n+\n+```java\n+p.readFrom(Sources.files(\"/path/to/input/\"))\n+    .map(LogLine::parse)\n+    .groupingKey(wholeItem())\n+    .aggregate(counting())\n+    .writeTo(Sinks.files(\"/path/to/output/\"));\n+```\n+\n+### Spark and Staged Execution\n+\n+Spark splits the computation to non-overlapping stages. A reading stage\n+and a group-and-aggregate stage, in our case. During the reading stage,\n+Spark workers fetch data from disk files, parse it and cache it in the\n+cluster memory. Spark schedules more tasks if the source can be read in\n+parallel (e.g. data is partitioned). All reading stage tasks must be\n+finished before the first aggregating task is started.\n+\n+This is the DAG representing execution stages (source:\n+[https://www.tutorialkart.com/apache-spark/dag-and-physical-execution-plan/](https://www.tutorialkart.com/apache-spark/dag-and-physical-execution-plan/)).\n+\n+![Spark Staged Execution](assets/2020-05-18-spark-dag-stages.svg)\n+\n+Staged execution was designed to support an iterative analytics use-case\n+where the results of one stage stay cached in a cluster memory to be\n+reused by a following step in the analysis. This makes Spark a popular\n+choice for ML research where a data scientist gradually evolves the\n+dataset with new experiments, evicting the data when their Spark session\n+is over. It is also a powerful debugging tool.\n+\n+On the other hand, staged execution doesn\u2019t perform well for\n+latency-sensitive use-cases, namely stream processing.\n+\n+Streaming data is continuously incrementing. Staged execution is however\n+designed for finite datasets. Whole input must be read before Spark\n+starts subsequent steps. Spark Streaming works around this by batching\n+the input data, e.g. creating finite chunks from an infinite stream.\n+Buffering adds to the job latency as the data are waiting for the batch\n+to fill, staying idle.\n+\n+The stages are planned and scheduled again and again for every batch.\n+The overhead of the planning process increases the latency further.\n+\n+Another latency penalty comes if the data partitions are not balanced\n+evenly. If a single partition of data takes longer to read or process,\n+it would block the whole job from progressing since the next stage can\u2019t\n+be started. Jet would be impacted by this scenario, too, but it can\n+still provide early results \u2013 in-complete, indicative results based on\n+already processed partitions.\n+\n+### Jet and Continuous Execution\n+\n+Jet executes all DAG nodes concurrently. The DAG is deployed to all\n+cluster nodes when the job is submitted and runs until a termination.\n+The instances of running DAG nodes, called Processors, then run in\n+parallel and continuously exchange data. For partitioned data sets, the\n+data partitions are evenly distributed among available processors (see\n+the\n+[docs](https://jet-start.sh/docs/architecture/distributed-computing)).\n+\n+This is the DAG representing the execution plan for the log aggregation.\n+Jet would create multiple instances of each and route data among it\n+following the routing strategy (source:\n+[https://jet-start.sh/docs/next/architecture/distributed-computing](https://jet-start.sh/docs/next/architecture/distributed-computing)):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b20f8012e638c444520cb8412ea28d43cfe69720"}, "originalPosition": 137}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4713, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}