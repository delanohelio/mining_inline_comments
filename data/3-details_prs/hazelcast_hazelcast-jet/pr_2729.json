{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyNDU2Njcy", "number": 2729, "title": "Add SQL file support", "bodyText": "Added support for files in SQL.\nIntroduced couple of changes to regular file connector to support non-java cases - overlaps with #2721 which might be closed if this one gets through.\nAdded also documentation @vladoschreiner.", "createdAt": "2020-12-04T10:58:38Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729", "merged": true, "mergeCommit": {"oid": "9cc913bdfa4f990c93755d9880beb843437e260a"}, "closed": true, "closedAt": "2020-12-11T12:17:12Z", "author": {"login": "gierlachg"}, "timelineItems": {"totalCount": 61, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdZjAxqAH2gAyNTMyNDU2NjcyOmYxMWMwNWM1N2M5YmIxNWMwYTI3ODA4NmUzNjNhYTFmZDRhODg2NDM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdlG66sgFqTU1MDA0ODEzNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f11c05c57c9bb15c0a278086e363aa1fd4a88643", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f11c05c57c9bb15c0a278086e363aa1fd4a88643", "committedDate": "2020-11-05T14:12:52Z", "message": "Add file connector (SQL)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57e63c8ccff9282db2fc2030d5916853c1acc3bd", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/57e63c8ccff9282db2fc2030d5916853c1acc3bd", "committedDate": "2020-11-06T15:28:59Z", "message": "Merge branch 'master' into sql-file\n\n# Conflicts:\n#\thazelcast-jet-sql/pom.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e6f1fd651728dfaf433af1fe26dd0b38bd8d5d3", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/0e6f1fd651728dfaf433af1fe26dd0b38bd8d5d3", "committedDate": "2020-11-16T14:49:54Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5d5da09c55535a9461920ab07dda014e29bbb57", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f5d5da09c55535a9461920ab07dda014e29bbb57", "committedDate": "2020-11-24T11:37:07Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8077b57f3a270926adccb030c6e4726a4c1513cc", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/8077b57f3a270926adccb030c6e4726a4c1513cc", "committedDate": "2020-11-24T13:12:46Z", "message": "Follow changes from master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b0ace95bfba981d6eed59c628023635330b7d43", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3b0ace95bfba981d6eed59c628023635330b7d43", "committedDate": "2020-11-26T08:54:08Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21c580558b81267ecac12e34a065cb158226ac1f", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/21c580558b81267ecac12e34a065cb158226ac1f", "committedDate": "2020-11-26T12:09:03Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "928151365ea2adec57a04b3e23ec045fba6e16c0", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/928151365ea2adec57a04b3e23ec045fba6e16c0", "committedDate": "2020-11-26T14:44:00Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf4fb6096b4415c18a0fae4554265ff0057a14ee", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/cf4fb6096b4415c18a0fae4554265ff0057a14ee", "committedDate": "2020-11-26T14:44:00Z", "message": "Fix dependency issue (Jetty conflict)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b5d3f70596398516f8fbdd5d41ed669740e80e5", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/7b5d3f70596398516f8fbdd5d41ed669740e80e5", "committedDate": "2020-11-26T14:44:00Z", "message": "Add buildMetaSupplier() to FileSourceBuilder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f39fe5cc5d4ab305678176041d12844ce6012ff4", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f39fe5cc5d4ab305678176041d12844ce6012ff4", "committedDate": "2020-11-26T15:26:01Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf2c4b5bb864f6c0dd0e86a7c5792f44681c47db", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/bf2c4b5bb864f6c0dd0e86a7c5792f44681c47db", "committedDate": "2020-12-02T10:23:12Z", "message": "Switch to new File API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b740f40158111eec2d7d1b78c8199d8ad596bee", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/6b740f40158111eec2d7d1b78c8199d8ad596bee", "committedDate": "2020-12-02T13:17:32Z", "message": "Use testcontainers based Kafka Schema Registry for Kafka tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a856cb91e710e94e30487324a46a8a6ea9ee659a", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a856cb91e710e94e30487324a46a8a6ea9ee659a", "committedDate": "2020-12-02T15:36:12Z", "message": "Support file table function options"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b89b89728f3e7e68060ebf84f1e5b1d791aed416", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/b89b89728f3e7e68060ebf84f1e5b1d791aed416", "committedDate": "2020-12-03T11:36:16Z", "message": "Validation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb002cba1cbd0f210efe2be3893d1ed2537a6297", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/eb002cba1cbd0f210efe2be3893d1ed2537a6297", "committedDate": "2020-12-03T14:01:09Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6104928346ca44c166940b2674d99dff01d378c", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a6104928346ca44c166940b2674d99dff01d378c", "committedDate": "2020-12-03T14:48:39Z", "message": "Cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86b092adb1ec3b17178d84215b9e6e88870de345", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/86b092adb1ec3b17178d84215b9e6e88870de345", "committedDate": "2020-12-04T09:41:23Z", "message": "Make glob optional"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9cb06cc31f711612bce1e00dbd9be81db4b1b91", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d9cb06cc31f711612bce1e00dbd9be81db4b1b91", "committedDate": "2020-12-04T10:50:17Z", "message": "Add Sql File connector docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a92d5e9881d8fc427803f7d8fa6e646bc14bcccc", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a92d5e9881d8fc427803f7d8fa6e646bc14bcccc", "committedDate": "2020-12-07T07:17:34Z", "message": "Fix Kafka docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a32108b9bb866ca2c25907e286231a4fcd93f30", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/8a32108b9bb866ca2c25907e286231a4fcd93f30", "committedDate": "2020-12-07T13:41:44Z", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be8d86842daac7e7586d541dffcdc6b2e68a934d", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/be8d86842daac7e7586d541dffcdc6b2e68a934d", "committedDate": "2020-12-07T14:14:24Z", "message": "Merge remote-tracking branch 'upstream/sql-file' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a3852360edff9267d54b6a320b68180f9360844", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/6a3852360edff9267d54b6a320b68180f9360844", "committedDate": "2020-12-07T15:04:22Z", "message": "Wording touchups, test for empty column list"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/13e762dc40402c9f054afc186814c7cdb7759694", "committedDate": "2020-12-07T16:28:10Z", "message": "Documentation updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "696347824cb00088fc9585049ee7129bfb530f81", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/696347824cb00088fc9585049ee7129bfb530f81", "committedDate": "2020-12-09T07:39:42Z", "message": "Merge remote-tracking branch 'upstream/master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89fde5bc970c9c0c5c560328bd6ab803891810bd", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/89fde5bc970c9c0c5c560328bd6ab803891810bd", "committedDate": "2020-12-09T07:49:21Z", "message": "Merge branch 'sql-file' into sql-file-upstream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ff2845ac238cda544c0c886429bacd344ff1235", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1ff2845ac238cda544c0c886429bacd344ff1235", "committedDate": "2020-12-09T08:11:13Z", "message": "Minor changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MTg4OTAy", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#pullrequestreview-546188902", "createdAt": "2020-12-07T14:16:02Z", "commit": {"oid": "8a32108b9bb866ca2c25907e286231a4fcd93f30"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNDoxNjowMlrOIAozqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQxMToyMjozNFrOIBUoLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzUzOTQ5OA==", "bodyText": "This probably has no effect.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r537539498", "createdAt": "2020-12-07T14:16:02Z", "author": {"login": "viliam-durina"}, "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -51,20 +52,31 @@\n     public <T> FunctionEx<Path, Stream<T>> createReadFileFn(@Nonnull FileFormat<T> format) {\n         CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n         Class<?> formatClazz = csvFileFormat.clazz(); // Format is not Serializable\n-        return path -> {\n-            CsvSchema schema = CsvSchema.emptySchema().withHeader();\n-            CsvMapper mapper = new CsvMapper();\n-            ObjectReader reader = mapper.readerFor(formatClazz)\n-                                        .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                        .with(schema);\n+        boolean includesHeader = csvFileFormat.includesHeader();\n \n+        return path -> {\n+            ObjectReader reader = reader(formatClazz, includesHeader);\n             FileInputStream fis = new FileInputStream(path.toFile());\n-\n             return StreamSupport.<T>stream(Spliterators.spliteratorUnknownSize(reader.readValues(fis), ORDERED), false)\n                     .onClose(() -> uncheckRun(fis::close));\n         };\n     }\n \n+    private static <T> ObjectReader reader(Class<T> clazz, boolean includesHeader) {\n+        if (clazz == null) {\n+            return new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                  .readerFor(String[].class)\n+                                  .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a32108b9bb866ca2c25907e286231a4fcd93f30"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzUzOTY4MA==", "bodyText": "This probably has no effect.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r537539680", "createdAt": "2020-12-07T14:16:17Z", "author": {"login": "viliam-durina"}, "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/CsvInputFormat.java", "diffHunk": "@@ -101,4 +97,19 @@ public void close() throws IOException {\n             }\n         };\n     }\n+\n+    private static <T> ObjectReader reader(Class<T> clazz, boolean includesHeader) {\n+        if (clazz == null) {\n+            return new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                  .readerFor(String[].class)\n+                                  .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a32108b9bb866ca2c25907e286231a4fcd93f30"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwNjE1MQ==", "bodyText": "We should add this dep everywhere where jackson-jr-objects i guess. For example, jackson-jr-objects is optional in hazelcast-jet-distribution", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r537606151", "createdAt": "2020-12-07T15:40:52Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-core/pom.xml", "diffHunk": "@@ -107,6 +107,11 @@\n             <artifactId>classgraph</artifactId>\n             <version>${classgraph.version}</version>\n         </dependency>\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.jr</groupId>\n+            <artifactId>jackson-jr-stree</artifactId>\n+            <version>${jackson.jr.version}</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6a3852360edff9267d54b6a320b68180f9360844"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyMDA4NQ==", "bodyText": "It's not great that we just ignore the logging. When one enables the logging to see which files are open, it's not good that files open through this traverser are not logged.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538220085", "createdAt": "2020-12-08T10:30:08Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/connector/ReadFilesP.java", "diffHunk": "@@ -160,24 +129,118 @@ public void close() throws IOException {\n     ) {\n         checkSerializable(readFileFn, \"readFileFn\");\n \n-        return ProcessorMetaSupplier.of(DEFAULT_LOCAL_PARALLELISM, () -> new ReadFilesP<>(\n-                directory, glob, sharedFileSystem, readFileFn)\n-        );\n+        return new MetaSupplier<>(DEFAULT_LOCAL_PARALLELISM, directory, glob, sharedFileSystem, readFileFn);\n     }\n \n-    /**\n-     * Private API.\n-     */\n-    public static <T> Processor processor(\n-            @Nonnull String directory,\n-            @Nonnull String glob,\n-            boolean sharedFileSystem,\n-            @Nonnull FunctionEx<? super Path, ? extends Stream<T>> readFileFn\n-    ) {\n-        checkSerializable(readFileFn, \"readFileFn\");\n+    private static final class MetaSupplier<T> implements FileProcessorMetaSupplier<T> {\n+\n+        private final int localParallelism;\n+        private final String directory;\n+        private final String glob;\n+        private final boolean sharedFileSystem;\n+        private final FunctionEx<? super Path, ? extends Stream<T>> readFileFn;\n+\n+        private MetaSupplier(\n+                int localParallelism,\n+                String directory,\n+                String glob,\n+                boolean sharedFileSystem,\n+                FunctionEx<? super Path, ? extends Stream<T>> readFileFn\n+        ) {\n+            this.localParallelism = localParallelism;\n+            this.directory = directory;\n+            this.glob = glob;\n+            this.sharedFileSystem = sharedFileSystem;\n+            this.readFileFn = readFileFn;\n+        }\n \n-        return new ReadFilesP<>(\n-                directory, glob, sharedFileSystem, readFileFn\n-        );\n+        @Nonnull\n+        @Override\n+        public Function<? super Address, ? extends ProcessorSupplier> get(@Nonnull List<Address> addresses) {\n+            return address -> ProcessorSupplier.of(() -> new ReadFilesP<>(directory, glob, sharedFileSystem, readFileFn));\n+        }\n+\n+        @Override\n+        public int preferredLocalParallelism() {\n+            return localParallelism;\n+        }\n+\n+        @Override\n+        public FileTraverser<T> traverser() {\n+            return new LocalFileTraverser<>(DisabledLogger.INSTANCE, directory, glob, path -> true, readFileFn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyMDk0NQ==", "bodyText": "Javadoc needs updating. Class javadoc too.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538220945", "createdAt": "2020-12-08T10:31:09Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/FileSourceFactory.java", "diffHunk": "@@ -36,5 +37,5 @@\n      * @param <T>           type of the item the source emits\n      */\n     @Nonnull\n-    <T> BatchSource<T> create(@Nonnull FileSourceConfiguration<T> configuration);\n+    <T> ProcessorMetaSupplier create(@Nonnull FileSourceConfiguration<T> configuration);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyMzg1Ng==", "bodyText": "Might be useful to actually assert this, not just ignore the rest. For example like this:\n            // Only one implementation is expected to be present on classpath\n            Iterator<FileSourceFactory> iterator = loader.iterator();\n            if (!iterator.hasNext()) {\n                throw new JetException(\"No suitable FileSourceFactory found. \" +\n                        \"Do you have Jet's Hadoop module on classpath?\");\n            }\n            try {\n                return iterator.next().create(fsc);\n            } finally {\n                if (iterator.hasNext()) {\n                    throw new JetException(\"Multiple FileSourceFactory implementations found\");\n                }\n            }", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538223856", "createdAt": "2020-12-08T10:34:16Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -201,7 +214,7 @@ public FileSourceBuilder(@Nonnull String path) {\n                 path, glob, format, sharedFileSystem, options\n         );\n \n-        if (useHadoop || hasHadoopPrefix(path)) {\n+        if (shouldUseHadoop()) {\n             ServiceLoader<FileSourceFactory> loader = ServiceLoader.load(FileSourceFactory.class);\n             // Only one implementation is expected to be present on classpath", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI0MTA5Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        List<Processor> processors = new ArrayList<>(count);\n          \n          \n            \n                        for (int i = 0; i < count; i++) {\n          \n          \n            \n                            ResettableSingletonTraverser<Object[]> traverser = new ResettableSingletonTraverser<>();\n          \n          \n            \n                            RowProjector projector = projectorSupplier.get();\n          \n          \n            \n                            Processor processor = new TransformP<>(object -> {\n          \n          \n            \n                                traverser.accept(projector.project(object));\n          \n          \n            \n                                return traverser;\n          \n          \n            \n                            });\n          \n          \n            \n                            processors.add(processor);\n          \n          \n            \n                        }\n          \n          \n            \n                        return processors;\n          \n          \n            \n                        return Stream.generate(projectorSupplier)\n          \n          \n            \n                                     .limit(count)\n          \n          \n            \n                                     .map(projector -> mapP(projector::project).get())\n          \n          \n            \n                                     .collect(Collectors.toList());\n          \n      \n    \n    \n  \n\nWe also need to make RowProjector.Supplier implement SupplierEx<RowProjector> for the above to compile.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538241096", "createdAt": "2020-12-08T10:56:39Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/Processors.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.function.SupplierEx;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.core.ResettableSingletonTraverser;\n+import com.hazelcast.jet.impl.processor.TransformP;\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.nio.serialization.DataSerializable;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.extract.QueryTarget;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+public final class Processors {\n+\n+    private Processors() {\n+    }\n+\n+    public static ProcessorSupplier rowProjector(\n+            String[] paths,\n+            QueryDataType[] types,\n+            SupplierEx<QueryTarget> targetSupplier,\n+            Expression<Boolean> predicate,\n+            List<Expression<?>> projection\n+    ) {\n+        return new Processors.RowProjectorProcessorSupplier(\n+                RowProjector.supplier(paths, types, targetSupplier, predicate, projection));\n+    }\n+\n+    @SuppressFBWarnings(\n+            value = {\"SE_BAD_FIELD\", \"SE_NO_SERIALVERSIONID\"},\n+            justification = \"the class is never java-serialized\"\n+    )\n+    private static final class RowProjectorProcessorSupplier implements ProcessorSupplier, DataSerializable {\n+\n+        private RowProjector.Supplier projectorSupplier;\n+\n+        @SuppressWarnings(\"unused\")\n+        private RowProjectorProcessorSupplier() {\n+        }\n+\n+        RowProjectorProcessorSupplier(RowProjector.Supplier projectorSupplier) {\n+            this.projectorSupplier = projectorSupplier;\n+        }\n+\n+        @Nonnull\n+        @Override\n+        public Collection<? extends Processor> get(int count) {\n+            List<Processor> processors = new ArrayList<>(count);\n+            for (int i = 0; i < count; i++) {\n+                ResettableSingletonTraverser<Object[]> traverser = new ResettableSingletonTraverser<>();\n+                RowProjector projector = projectorSupplier.get();\n+                Processor processor = new TransformP<>(object -> {\n+                    traverser.accept(projector.project(object));\n+                    return traverser;\n+                });\n+                processors.add(processor);\n+            }\n+            return processors;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI0MzE5MQ==", "bodyText": "You can use writeUtfArray.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538243191", "createdAt": "2020-12-08T10:59:33Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/RowProjector.java", "diffHunk": "@@ -90,4 +95,77 @@ public RowProjector(\n     public int getColumnCount() {\n         return extractors.length;\n     }\n+\n+    public static Supplier supplier(\n+            String[] paths,\n+            QueryDataType[] types,\n+            SupplierEx<QueryTarget> targetSupplier,\n+            Expression<Boolean> predicate,\n+            List<Expression<?>> projections\n+    ) {\n+        return new Supplier(paths, types, targetSupplier, predicate, projections);\n+    }\n+\n+    public static class Supplier implements DataSerializable {\n+\n+        private String[] paths;\n+        private QueryDataType[] types;\n+\n+        private SupplierEx<QueryTarget> targetSupplier;\n+\n+        private Expression<Boolean> predicate;\n+        private List<Expression<?>> projections;\n+\n+        @SuppressWarnings(\"unused\")\n+        private Supplier() {\n+        }\n+\n+        Supplier(\n+                String[] paths,\n+                QueryDataType[] types,\n+                SupplierEx<QueryTarget> targetSupplier,\n+                Expression<Boolean> predicate,\n+                List<Expression<?>> projections\n+        ) {\n+            this.paths = paths;\n+            this.types = types;\n+            this.targetSupplier = targetSupplier;\n+            this.predicate = predicate;\n+            this.projections = projections;\n+        }\n+\n+        public RowProjector get() {\n+            return new RowProjector(paths, types, targetSupplier.get(), predicate, projections);\n+        }\n+\n+        @Override\n+        public void writeData(ObjectDataOutput out) throws IOException {\n+            out.writeInt(paths.length);\n+            for (String path : paths) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI1MTI5Ng==", "bodyText": "Jet already has Processors class, it might confuse users which one to import. What about SqlProcessors?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538251296", "createdAt": "2020-12-08T11:12:04Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/Processors.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.function.SupplierEx;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.core.ResettableSingletonTraverser;\n+import com.hazelcast.jet.impl.processor.TransformP;\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.nio.serialization.DataSerializable;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.extract.QueryTarget;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+public final class Processors {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI1MjUwNg==", "bodyText": "As far as I understand, this whole class is needed to support DataSerializable. But I don't think it's a big issue if we use java serialization, we do it everywhere else. The below code will do that, and you can delete RowProjectorProcessorSupplier and the RowProjector.Supplier:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return new Processors.RowProjectorProcessorSupplier(\n          \n          \n            \n                            RowProjector.supplier(paths, types, targetSupplier, predicate, projection));\n          \n          \n            \n                    ServiceFactory<?, RowProjector> service =\n          \n          \n            \n                            nonSharedService(ctx -> new RowProjector(paths, types, targetSupplier.get(), predicate, projection));\n          \n          \n            \n                    return mapUsingServiceP(service, (projector, item) -> projector.project(item));", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538252506", "createdAt": "2020-12-08T11:14:13Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/Processors.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.function.SupplierEx;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.core.ResettableSingletonTraverser;\n+import com.hazelcast.jet.impl.processor.TransformP;\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.nio.serialization.DataSerializable;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.extract.QueryTarget;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+\n+public final class Processors {\n+\n+    private Processors() {\n+    }\n+\n+    public static ProcessorSupplier rowProjector(\n+            String[] paths,\n+            QueryDataType[] types,\n+            SupplierEx<QueryTarget> targetSupplier,\n+            Expression<Boolean> predicate,\n+            List<Expression<?>> projection\n+    ) {\n+        return new Processors.RowProjectorProcessorSupplier(\n+                RowProjector.supplier(paths, types, targetSupplier, predicate, projection));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI1NzQ1Mg==", "bodyText": "Is there a reason it's not supported?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r538257452", "createdAt": "2020-12-08T11:22:34Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.sql.impl.extract.CsvQueryTarget;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.sql.impl.QueryException;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+final class CsvMetadataResolver extends MetadataResolver {\n+\n+    static final CsvMetadataResolver INSTANCE = new CsvMetadataResolver();\n+\n+    private CsvMetadataResolver() {\n+    }\n+\n+    @Override\n+    public String supportedFormat() {\n+        return CsvFileFormat.FORMAT_CSV;\n+    }\n+\n+    @Override\n+    public List<MappingField> resolveAndValidateFields(List<MappingField> userFields, Map<String, ?> options) {\n+        return !userFields.isEmpty() ? validateFields(userFields) : resolveFieldsFromSample(options);\n+    }\n+\n+    private List<MappingField> validateFields(List<MappingField> userFields) {\n+        for (MappingField userField : userFields) {\n+            if (userField.externalName() != null) {\n+                throw QueryException.error(\"EXTERNAL NAME not supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e762dc40402c9f054afc186814c7cdb7759694"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86ba6f252acb2be279a5a9a2ce44f86fdbaff7db", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/86ba6f252acb2be279a5a9a2ce44f86fdbaff7db", "committedDate": "2020-12-09T08:31:59Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b47e8f4cb6a317c94cf76f40f51d80ae88c5554a", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/b47e8f4cb6a317c94cf76f40f51d80ae88c5554a", "committedDate": "2020-12-09T09:22:22Z", "message": "Address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c897b050513dbf55f516f5cf1b886ac6531c7b6", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/2c897b050513dbf55f516f5cf1b886ac6531c7b6", "committedDate": "2020-12-09T09:38:58Z", "message": "Address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "926fa8c31dc5dfa079d8e314f3d2f871d0d0d97a", "author": {"user": {"login": "frant-hartm", "name": "Franti\u0161ek Hartman"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/926fa8c31dc5dfa079d8e314f3d2f871d0d0d97a", "committedDate": "2020-12-09T11:59:03Z", "message": "Publish hadoop module without relocation\n\nWe need 3 different hadoop modules:\n- hazelcast-jet-hadoop-core - all our classes without relocation\nshould be used from other Jet modules, in combination with\nhazelcast-jet-core\n\n- hazelcast-jet-hadoop - for users, with relocated packages (Jackson),\nto be used together with hazelcast-jet\nusers provide own version of hadoop\n\n- hazelcast-jet-hadoop-all - same as previous, with all deps included"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1997ecc87503c134c2e364a7bdbe62b047a7e6e", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c1997ecc87503c134c2e364a7bdbe62b047a7e6e", "committedDate": "2020-12-09T12:23:52Z", "message": "Merge remote-tracking branch 'upstream/sql-file' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "989c35e515c3cc22fdb7a4a074e1c387f7a6946b", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/989c35e515c3cc22fdb7a4a074e1c387f7a6946b", "committedDate": "2020-12-09T13:14:28Z", "message": "Merge branch 'master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2136662e8d498e397d61973321a462e22b05aa42", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/2136662e8d498e397d61973321a462e22b05aa42", "committedDate": "2020-12-09T13:44:29Z", "message": "Shade sql module"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d9723eac7d14a0150f455bca7ec9c77caed6578", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3d9723eac7d14a0150f455bca7ec9c77caed6578", "committedDate": "2020-12-09T14:57:27Z", "message": "An attempt to fix Kafka Avro test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2bf7ffa2716e4c93f746ac665fd22a616c9e5da", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d2bf7ffa2716e4c93f746ac665fd22a616c9e5da", "committedDate": "2020-12-09T15:01:53Z", "message": "Fix imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cd6fac674c647f79a4460affd00ab733e7876c7", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/5cd6fac674c647f79a4460affd00ab733e7876c7", "committedDate": "2020-12-09T15:02:26Z", "message": "Remove unnecessary exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b4ac59ca00eab4b8a8b20a3390483fedbdf071a", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/4b4ac59ca00eab4b8a8b20a3390483fedbdf071a", "committedDate": "2020-12-09T15:06:05Z", "message": "More tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd99e7a5b41f8665b15e0e8961381ee0b0117c37", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/bd99e7a5b41f8665b15e0e8961381ee0b0117c37", "committedDate": "2020-12-09T15:08:04Z", "message": "Merge remote-tracking branch 'upstream/sql-file' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64681b5e39078b7de55bfa52ff3f7d2fdcd463af", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/64681b5e39078b7de55bfa52ff3f7d2fdcd463af", "committedDate": "2020-12-09T15:29:09Z", "message": "An attempt to fix Kafka Avro test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32888ae7d629841e7f3f90364f3cc2773842d426", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/32888ae7d629841e7f3f90364f3cc2773842d426", "committedDate": "2020-12-10T10:17:48Z", "message": "An attempt to fix Kafka Avro test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d418b43f270b94dbb5cef446df03f50c813249b8", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d418b43f270b94dbb5cef446df03f50c813249b8", "committedDate": "2020-12-10T10:44:44Z", "message": "Remove never thrown exceptions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "02d757ce8f3ede648eccddf5478d4018de0bd592", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/02d757ce8f3ede648eccddf5478d4018de0bd592", "committedDate": "2020-12-10T10:47:55Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72c825bb5a1da357589e626e5a20a230882f1bd6", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/72c825bb5a1da357589e626e5a20a230882f1bd6", "committedDate": "2020-12-10T11:35:23Z", "message": "An attempt to fix Kafka Avro test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2863f4d3d577f140c78a13b3c01caeb6cd629383", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/2863f4d3d577f140c78a13b3c01caeb6cd629383", "committedDate": "2020-12-10T11:57:03Z", "message": "An attempt to fix Kafka Avro test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c797f388177a2432ef74efdf41098e5682920d8d", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c797f388177a2432ef74efdf41098e5682920d8d", "committedDate": "2020-12-10T12:05:47Z", "message": "Use actual logger for ReadFilesP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06f2051f0cbfd9535d78afede89e7becb632b046", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/06f2051f0cbfd9535d78afede89e7becb632b046", "committedDate": "2020-12-10T14:11:11Z", "message": "Rework CSV file connector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15df73f7d5732514fb1082530d4490e8b059f53f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/15df73f7d5732514fb1082530d4490e8b059f53f", "committedDate": "2020-12-10T15:04:09Z", "message": "Remove duplicate tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/37e069c353bc9a771b0bce73ae75777665f93e6e", "committedDate": "2020-12-10T15:47:19Z", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into sql-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c65fb479402bba445e4d8e5cd3419d51865b5a4f", "committedDate": "2020-12-10T18:22:44Z", "message": "Minor changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5MzYwMjA2", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#pullrequestreview-549360206", "createdAt": "2020-12-10T16:12:58Z", "commit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNjoxMjo1OFrOIDRJdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxODoyNDo0OFrOIDXRYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI5NzU5MA==", "bodyText": "What about this more concise name?\nfilesHadoop(s3:///directory/*)\n\nfilesLocal(/directory/*.csv)\n\n\"files\" + (shouldUseHadoop() ? \"Hadoop\" : \"Local\") + '(' + path + '/' + glob + ')'", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540297590", "createdAt": "2020-12-10T16:12:58Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -190,6 +193,17 @@ public FileSourceBuilder(@Nonnull String path) {\n      */\n     @Nonnull\n     public BatchSource<T> build() {\n+        ProcessorMetaSupplier metaSupplier = buildMetaSupplier();\n+\n+        return Sources.batchFromProcessor(\"files(path=\" + path + \", glob=\" + glob + \", hadoop=\" + shouldUseHadoop(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM3OTAzNA==", "bodyText": "Shouldn't we return null?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540379034", "createdAt": "2020-12-10T17:56:23Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/schema/UnknownStatistic.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.schema;\n+\n+\n+import org.apache.calcite.rel.RelCollation;\n+import org.apache.calcite.rel.RelDistribution;\n+import org.apache.calcite.rel.RelReferentialConstraint;\n+import org.apache.calcite.schema.Statistic;\n+import org.apache.calcite.util.ImmutableBitSet;\n+\n+import java.util.List;\n+\n+public final class UnknownStatistic implements Statistic {\n+\n+    public static final UnknownStatistic INSTANCE = new UnknownStatistic();\n+\n+    private UnknownStatistic() {\n+    }\n+\n+    @Override\n+    public Double getRowCount() {\n+        return 0.0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM5NzkyMQ==", "bodyText": "Is the only purpose of this class to be able to somehow pass the HazelcastTable object to place where the function is used? An explanatory comment would be good.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540397921", "createdAt": "2020-12-10T18:24:48Z", "author": {"login": "viliam-durina"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/schema/JetTableFunction.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.schema;\n+\n+import com.hazelcast.sql.impl.calcite.schema.HazelcastTable;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeComparability;\n+import org.apache.calcite.rel.type.RelDataTypeFactory;\n+import org.apache.calcite.rel.type.RelDataTypeFamily;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.calcite.rel.type.RelDataTypePrecedenceList;\n+import org.apache.calcite.rel.type.StructKind;\n+import org.apache.calcite.schema.TableFunction;\n+import org.apache.calcite.sql.SqlCollation;\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlIntervalQualifier;\n+import org.apache.calcite.sql.type.SqlTypeName;\n+\n+import java.nio.charset.Charset;\n+import java.util.List;\n+\n+public abstract class JetTableFunction implements TableFunction {\n+\n+    @Override\n+    public final RelDataType getRowType(RelDataTypeFactory typeFactory, List<Object> arguments) {\n+        HazelcastTable table = toTable(arguments);\n+        RelDataType rowType = table.getRowType(typeFactory);\n+\n+        return new JetFunctionRelDataType(table, rowType);\n+    }\n+\n+    protected abstract HazelcastTable toTable(List<Object> arguments);\n+\n+    public HazelcastTable toTable(RelDataType rowType) {\n+        return ((JetFunctionRelDataType) rowType).table();\n+    }\n+\n+    private static final class JetFunctionRelDataType implements RelDataType {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5MzU1MzE1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#pullrequestreview-549355315", "createdAt": "2020-12-10T16:08:04Z", "commit": {"oid": "15df73f7d5732514fb1082530d4490e8b059f53f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQxNjowODo1MVrOIDQ9Aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMjoxMDo1MFrOIDflGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI5NDQwMw==", "bodyText": "Was there an issue with reading the csv as String[]? Reading each line as a Map seems memory heavy. I didn't do any benchmarks though so it might be just a feeling.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540294403", "createdAt": "2020-12-10T16:08:51Z", "author": {"login": "frant-hartm"}, "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/CsvInputFormat.java", "diffHunk": "@@ -50,20 +51,15 @@\n \n             @Override\n             public void initialize(InputSplit split, TaskAttemptContext context) throws IOException {\n-\n                 FileSplit fileSplit = (FileSplit) split;\n                 Configuration conf = context.getConfiguration();\n \n                 Configuration configuration = context.getConfiguration();\n                 String className = configuration.get(CSV_INPUT_FORMAT_BEAN_CLASS);\n-                Class<?> clazz = ReflectionUtils.loadClass(className);\n-\n-                CsvMapper mapper = new CsvMapper();\n-\n-                CsvSchema schema = CsvSchema.emptySchema().withHeader();\n-                ObjectReader reader = mapper.readerFor(clazz)\n-                                            .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                            .with(schema);\n+                Class<?> clazz = className == null ? null : ReflectionUtils.loadClass(className);\n+                ObjectReader reader = new CsvMapper().readerFor(clazz != null ? clazz : Map.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37e069c353bc9a771b0bce73ae75777665f93e6e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUwNzYyOQ==", "bodyText": "The FileFormat#json should also be able to read regular json files, not only jsonl. It doesn't work currently (bug reported by ondrej).\nIs the user expected to specify json or jsonl as format in SQL query? Maybe json would be more intuitive.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540507629", "createdAt": "2020-12-10T21:25:07Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/FileTableFunction.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.hazelcast.internal.util.UuidUtil;\n+import com.hazelcast.jet.sql.impl.schema.JetTableFunction;\n+import com.hazelcast.jet.sql.impl.schema.JetTableFunctionParameter;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.jet.sql.impl.schema.UnknownStatistic;\n+import com.hazelcast.sql.impl.calcite.schema.HazelcastTable;\n+import com.hazelcast.sql.impl.schema.Table;\n+import org.apache.calcite.schema.FunctionParameter;\n+import org.apache.calcite.sql.type.SqlTypeName;\n+\n+import java.lang.reflect.Type;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.AVRO_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.CSV_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.JSONL_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.OPTION_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.PARQUET_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_GLOB;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_OPTIONS;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_PATH;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_SHARED_FILE_SYSTEM;\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptyList;\n+\n+public final class FileTableFunction extends JetTableFunction {\n+\n+    public static final FileTableFunction CSV = new FileTableFunction(CSV_FORMAT, asList(\n+            new JetTableFunctionParameter(0, OPTION_PATH, SqlTypeName.VARCHAR, true),\n+            new JetTableFunctionParameter(1, OPTION_GLOB, SqlTypeName.VARCHAR, false),\n+            new JetTableFunctionParameter(2, OPTION_SHARED_FILE_SYSTEM, SqlTypeName.VARCHAR, false),\n+            new JetTableFunctionParameter(3, OPTION_OPTIONS, SqlTypeName.MAP, false)\n+    ));\n+\n+    public static final FileTableFunction JSONL = new FileTableFunction(JSONL_FORMAT, asList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUwOTEyMQ==", "bodyText": "What happens when the first record you get for schema resolution has a field null, but other records have a int/double/string/ there.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540509121", "createdAt": "2020-12-10T21:27:39Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/JsonResolver.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.fasterxml.jackson.jr.stree.JrsBoolean;\n+import com.fasterxml.jackson.jr.stree.JrsObject;\n+import com.fasterxml.jackson.jr.stree.JrsValue;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+\n+final class JsonResolver {\n+\n+    private JsonResolver() {\n+    }\n+\n+    static List<MappingField> resolveFields(JrsObject object) {\n+        Map<String, MappingField> fields = new LinkedHashMap<>();\n+        Iterator<Entry<String, JrsValue>> iterator = object.fields();\n+        while (iterator.hasNext()) {\n+            Entry<String, JrsValue> entry = iterator.next();\n+\n+            String name = entry.getKey();\n+            QueryDataType type = resolveType(entry.getValue());\n+\n+            MappingField field = new MappingField(name, type);\n+            fields.putIfAbsent(field.name(), field);\n+        }\n+        return new ArrayList<>(fields.values());\n+    }\n+\n+    private static QueryDataType resolveType(JrsValue value) {\n+        if (value == null || value.isNull()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUxMDYzMA==", "bodyText": "Does array fall under this? Are arrays supported by our SQL implementation?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540510630", "createdAt": "2020-12-10T21:30:22Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/JsonResolver.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.fasterxml.jackson.jr.stree.JrsBoolean;\n+import com.fasterxml.jackson.jr.stree.JrsObject;\n+import com.fasterxml.jackson.jr.stree.JrsValue;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+\n+final class JsonResolver {\n+\n+    private JsonResolver() {\n+    }\n+\n+    static List<MappingField> resolveFields(JrsObject object) {\n+        Map<String, MappingField> fields = new LinkedHashMap<>();\n+        Iterator<Entry<String, JrsValue>> iterator = object.fields();\n+        while (iterator.hasNext()) {\n+            Entry<String, JrsValue> entry = iterator.next();\n+\n+            String name = entry.getKey();\n+            QueryDataType type = resolveType(entry.getValue());\n+\n+            MappingField field = new MappingField(name, type);\n+            fields.putIfAbsent(field.name(), field);\n+        }\n+        return new ArrayList<>(fields.values());\n+    }\n+\n+    private static QueryDataType resolveType(JrsValue value) {\n+        if (value == null || value.isNull()) {\n+            return QueryDataType.OBJECT;\n+        } else if (value instanceof JrsBoolean) {\n+            return QueryDataType.BOOLEAN;\n+        } else if (value.isNumber()) {\n+            return QueryDataType.DOUBLE;\n+        } else if (value.isValueNode()) {\n+            return QueryDataType.VARCHAR;\n+        } else {\n+            return QueryDataType.OBJECT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUxNDEzNQ==", "bodyText": "Does this mean I can't query e.g. nested json fields?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540514135", "createdAt": "2020-12-10T21:36:04Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/MetadataResolver.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.hazelcast.function.SupplierEx;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.impl.FileProcessorMetaSupplier;\n+import com.hazelcast.jet.pipeline.file.impl.FileTraverser;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.sql.impl.QueryException;\n+import com.hazelcast.sql.impl.extract.QueryTarget;\n+import com.hazelcast.sql.impl.schema.TableField;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.sneakyThrow;\n+import static com.hazelcast.jet.impl.util.Util.toList;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_GLOB;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_PATH;\n+import static com.hazelcast.jet.sql.impl.connector.file.FileSqlConnector.OPTION_SHARED_FILE_SYSTEM;\n+import static java.util.Map.Entry;\n+\n+abstract class MetadataResolver<T> {\n+\n+    private final FileFormat<?> format;\n+    private final Function<T, List<MappingField>> fieldResolver;\n+    private final SupplierEx<QueryTarget> queryTargetSupplier;\n+\n+    protected MetadataResolver(\n+            FileFormat<?> format,\n+            Function<T, List<MappingField>> fieldResolver,\n+            SupplierEx<QueryTarget> queryTargetSupplier\n+    ) {\n+        this.format = format;\n+        this.fieldResolver = fieldResolver;\n+        this.queryTargetSupplier = queryTargetSupplier;\n+    }\n+\n+\n+    String supportedFormat() {\n+        return format.format();\n+    }\n+\n+    List<MappingField> resolveAndValidateFields(List<MappingField> userFields, Map<String, ?> options) {\n+        return !userFields.isEmpty() ? validateFields(userFields) : resolveFieldsFromSample(options);\n+    }\n+\n+    private List<MappingField> validateFields(List<MappingField> userFields) {\n+        for (MappingField userField : userFields) {\n+            String externalName = userField.externalName();\n+            if (externalName != null && externalName.indexOf('.') >= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUyNTYwNg==", "bodyText": "This is a binary file checked into the repo.\nIt would be easier to maintain to generate the file on the fly during the test - e.g. when someone needs to add a field to the file, create a similar file with a specific corner case etc. If the code is there it can be easily modified. Otherwise one would need to create the file from scratch or maybe somehow modify it.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540525606", "createdAt": "2020-12-10T21:56:14Z", "author": {"login": "frant-hartm"}, "path": "hazelcast-jet-sql/src/test/java/com/hazelcast/jet/sql/impl/connector/file/SqlAvroTest.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.file;\n+\n+import com.hazelcast.jet.sql.SqlTestSupport;\n+import com.hazelcast.sql.SqlService;\n+import org.apache.avro.SchemaBuilder;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.math.BigDecimal;\n+import java.nio.file.Paths;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.AVRO_FORMAT;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnector.OPTION_FORMAT;\n+import static java.time.ZoneOffset.UTC;\n+import static java.util.Collections.singletonList;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+public class SqlAvroTest extends SqlTestSupport {\n+\n+    private static final String RESOURCES_PATH = Paths.get(\"src/test/resources\").toFile().getAbsolutePath();\n+\n+    private static SqlService sqlService;\n+\n+    @BeforeClass\n+    public static void setUpClass() {\n+        initialize(1, null);\n+        sqlService = instance().getSql();\n+    }\n+\n+    @Test\n+    public void test_nulls() {\n+        String name = randomName();\n+        sqlService.execute(\"CREATE MAPPING \" + name + \" (\"\n+                + \"nonExistingField VARCHAR\"\n+                + \") TYPE \" + FileSqlConnector.TYPE_NAME + ' '\n+                + \"OPTIONS (\"\n+                + '\\'' + OPTION_FORMAT + \"'='\" + AVRO_FORMAT + '\\''\n+                + \", '\" + FileSqlConnector.OPTION_PATH + \"'='\" + RESOURCES_PATH + '\\''\n+                + \", '\" + FileSqlConnector.OPTION_GLOB + \"'='\" + \"file.avro\" + '\\''", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUzNDA0MQ==", "bodyText": "This should be hazelcast-jet-hadoop-all.\nCloud storages need their respective jars, maybe just link to the section in sources and sinks.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#discussion_r540534041", "createdAt": "2020-12-10T22:10:50Z", "author": {"login": "frant-hartm"}, "path": "site/docs/sql/file-connector.md", "diffHunk": "@@ -0,0 +1,247 @@\n+---\n+title: File Connector\n+description: Description of the SQL File connector\n+---\n+\n+The File connector supports reading from both local and remote files.\n+\n+To work with files you must specify location and serialization.\n+Any options not recognized by Jet are passed, in case of remote files,\n+directly to Hadoop client. For local files they are simply ignored.\n+\n+You can find detailed information for the options below.\n+\n+## Location options\n+\n+`path` is an absolute path to the directory containing your data. These\n+are the supported schemes:\n+\n+* `hdfs`: HDFS\n+* `s3a`: Amazon S3\n+* `wasbs`: Azure Cloud Storage\n+* `adl`: Azure Data Lake Generation 1\n+* `abfs`: Azure Data Lake Generation 2\n+* `gs`: Google Cloud Storage\n+\n+So for instance, path to data residing in a Hadoop cluster could look\n+like `hdfs://path/to/directory/`. Any path not starting with any of the\n+above is considered local (i.e. files residing on Jet members), e.g.\n+`/path/to/directory/`.\n+\n+`glob` is a pattern to filter the files in the specified directory.\n+The default value is '*', matching all files.\n+\n+## Serialization options\n+\n+`format` defines the serialization used to read the files. We assume all\n+records in files have the same format. These are the supported `format`\n+values:\n+\n+* `csv`\n+* `jsonl`\n+* `avro`\n+* `parquet`: remote files only\n+\n+If you omit a file list from the `CREATE MAPPING` command, Jet will read\n+a sample file and try to determine column names and types from it. In\n+some cases you can use a different type if you specify the columns\n+explicitly. For example, the CSV format uses `VARCHAR` for all fields -\n+if you specify `DATE` manually, the behavior would be as if `CAST(column\n+AS DATE)` was used, using the same rules for conversion from `VARCHAR`\n+to `DATE` as `CAST` uses.\n+\n+Also if you don't specify the columns, the directory needs to be\n+available at the time you execute the `CREATE MAPPING` and it must not\n+be empty. In case of local files, every cluster member must have some\n+file. If you specify the columns, an empty directory is OK.\n+\n+See the examples for individual serialization options below.\n+\n+### CSV Serialization\n+\n+The `csv` files are expected to be comma-separated and `UTF-8` encoded.\n+Each file must have a header on the first line. If you omit the column\n+list from the mapping declaration, Jet will try to infer the column\n+names from the file header. All columns will have `VARCHAR` type.\n+\n+```sql\n+CREATE MAPPING my_files\n+TYPE File\n+OPTIONS (\n+    'path' = '/path/to/directory',\n+    'format' = 'csv'\n+)\n+```\n+\n+### JSONL serialization\n+\n+The `jsonl` files are expected to contain one valid json document per\n+line and be `UTF-8` encoded. If you skip mapping columns from the\n+declaration, we infer names and types based on a sample.\n+\n+```sql\n+CREATE MAPPING my_files\n+TYPE File\n+OPTIONS (\n+    'path' = '/path/to/directory',\n+    'format' = 'jsonl'\n+)\n+```\n+\n+#### Mapping Between JSON and SQL Types\n+\n+| JSON type | SQL Type  |\n+| - | - |\n+| `BOOLEAN` | `BOOLEAN` |\n+| `NUMBER` | `DOUBLE` |\n+| `STRING` | `VARCHAR` |\n+| all other types | `OBJECT` |\n+\n+### Avro & Parquet Serialization\n+\n+The `avro` & `parquet` files are expected to contain Avro records.\n+\n+```sql\n+CREATE MAPPING my_files\n+TYPE File\n+OPTIONS (\n+    'path' = '/path/to/directory',\n+    'format' = 'avro'\n+)\n+```\n+\n+```sql\n+CREATE MAPPING my_files\n+TYPE File\n+OPTIONS (\n+    'path' = 'hdfs://path/to/directory',\n+    'format' = 'parquet'\n+    /* more Hadoop options ... */\n+)\n+```\n+\n+#### Mapping Between Avro and SQL Types\n+\n+| Avro Type | SQL Type |\n+| - | - |\n+| `BOOLEAN` | `BOOLEAN` |\n+| `INT` | `INT` |\n+| `LONG` | `BIGINT` |\n+| `FLOAT` | `REAL` |\n+| `DOUBLE` | `DOUBLE` |\n+| `STRING` | `VARCHAR` |\n+| all other types | `OBJECT` |\n+\n+## External Name\n+\n+You rarely need to specify the columns in DDL. If you do, you might want\n+to specify the external name. External names are supported for all\n+formats except for `csv`.\n+\n+We don't support nested fields, hence the external name should refer to\n+the top-level field - not containing any `.`.\n+\n+## File Table Functions\n+\n+To execute an ad hoc query against data in files you can use one of the\n+predefined table functions:\n+\n+* `csv_file`\n+* `jsonl_file`\n+* `avro_file`\n+* `parquet_file`\n+\n+Table functions will create a temporary mapping, valid for the duration\n+of the statement. They accept the same options as `CREATE MAPPING`\n+statements.\n+\n+You can use positional arguments:\n+\n+```sql\n+SELECT * FROM TABLE(\n+  CSV_FILE('/path/to/directory', '*.csv', MAP['key', 'value'])\n+)\n+```\n+\n+Or named arguments:\n+\n+```sql\n+SELECT * FROM TABLE(\n+  CSV_FILE(path => '/path/to/directory', options => MAP['key', 'value'])\n+)\n+```\n+\n+## Installation\n+\n+Depending on what formats you want to work with you need different\n+modules on the classpath.\n+\n+`csv` format requires the `hazelcast-jet-csv` module:\n+\n+<!--DOCUSAURUS_CODE_TABS-->\n+\n+<!--Gradle-->\n+\n+```groovy\n+compile 'com.hazelcast.jet:hazelcast-jet-csv:{jet-version}'\n+```\n+\n+<!--Maven-->\n+\n+```xml\n+<dependency>\n+    <groupId>com.hazelcast.jet</groupId>\n+    <artifactId>hazelcast-jet-csv</artifactId>\n+    <version>{jet-version}</version>\n+</dependency>\n+```\n+\n+<!--END_DOCUSAURUS_CODE_TABS-->\n+\n+`avro` format requires the `hazelcast-jet-avro` module:\n+\n+<!--DOCUSAURUS_CODE_TABS-->\n+\n+<!--Gradle-->\n+\n+```groovy\n+compile 'com.hazelcast.jet:hazelcast-jet-avro:{jet-version}'\n+```\n+\n+<!--Maven-->\n+\n+```xml\n+<dependency>\n+    <groupId>com.hazelcast.jet</groupId>\n+    <artifactId>hazelcast-jet-avro</artifactId>\n+    <version>{jet-version}</version>\n+</dependency>\n+```\n+\n+<!--END_DOCUSAURUS_CODE_TABS-->\n+\n+`parquet` format and all remote files require the `hazelcast-jet-hadoop`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c65fb479402bba445e4d8e5cd3419d51865b5a4f"}, "originalPosition": 223}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6963463d2e95c0bbabda7d970b0cdbda6d514a4", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/a6963463d2e95c0bbabda7d970b0cdbda6d514a4", "committedDate": "2020-12-11T07:20:24Z", "message": "Update docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4eaed37b7f6a59d5738e8748681ddac8ab0d1a37", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/4eaed37b7f6a59d5738e8748681ddac8ab0d1a37", "committedDate": "2020-12-11T07:42:31Z", "message": "Cleanups"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01fb2af1359f21f65981e8050e614cae9c12f708", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/01fb2af1359f21f65981e8050e614cae9c12f708", "committedDate": "2020-12-11T08:15:02Z", "message": "jsonl -> json"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc1f3f345e179a9db142d3ebea11f0c94ef22391", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/bc1f3f345e179a9db142d3ebea11f0c94ef22391", "committedDate": "2020-12-11T10:07:54Z", "message": "Generate avro & parquet data on the fly"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6337620e0769c67a2a0a9518546f578576619cc", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/e6337620e0769c67a2a0a9518546f578576619cc", "committedDate": "2020-12-11T10:27:01Z", "message": "Fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74eccd6b98d8b0fba59d7197e3a8abd9985440f4", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/74eccd6b98d8b0fba59d7197e3a8abd9985440f4", "committedDate": "2020-12-11T10:44:43Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d5ea1617253d174a0b3822ae5a1faaafd9698035", "author": {"user": {"login": "gierlachg", "name": "Grzegorz Gierlach"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/d5ea1617253d174a0b3822ae5a1faaafd9698035", "committedDate": "2020-12-11T11:11:43Z", "message": "Cleanup dependencies"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMDQ4MTM3", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2729#pullrequestreview-550048137", "createdAt": "2020-12-11T12:16:13Z", "commit": {"oid": "d5ea1617253d174a0b3822ae5a1faaafd9698035"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3411, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}