{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3MjAyNzYw", "number": 2519, "title": "Change Evergreen Cache tutorial to proper CDC sink", "bodyText": "There are other changes backing these on the Evergreen Cache repo's fix-sink branch, but I will keep those away from the master branch until merging this in, so the Blog and backing codebase remain in sync.", "createdAt": "2020-09-15T10:37:38Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519", "merged": true, "mergeCommit": {"oid": "d31148530ca5bf981c77b48ff7c3cd61cddcd658"}, "closed": true, "closedAt": "2020-09-18T06:19:12Z", "author": {"login": "jbartok"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdJFUNOgH2gAyNDg3MjAyNzYwOmY4Y2JhNzhlNGU5MWE0ZjVmNmQ1YTQ1ODFkZGM1YTc0Y2YyNjI3YWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdJruKzAH2gAyNDg3MjAyNzYwOjMxYTNjZjJiNDRjMTI5MjJlZDE5MjA2OTk1YTQ3MDg3MTI5ZDY2N2I=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad", "committedDate": "2020-09-15T10:34:09Z", "message": "Change tutorial to proper CDC sink"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4NzM1MTM2", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#pullrequestreview-488735136", "createdAt": "2020-09-15T14:19:30Z", "commit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoxOTozMFrOHSEQFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDoyMDozN1rOHSETqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjA2OQ==", "bodyText": "Why the dash? This is not German :)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488706069", "createdAt": "2020-09-15T14:19:30Z", "author": {"login": "viliam-durina"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODcwNjk4Ng==", "bodyText": "No comma", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488706986", "createdAt": "2020-09-15T14:20:37Z", "author": {"login": "viliam-durina"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4NzY3MjE1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#pullrequestreview-488767215", "createdAt": "2020-09-15T14:50:00Z", "commit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1MDowMFrOHSFu2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNDo1Mzo0NlrOHSF6Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMDMyOA==", "bodyText": "Can you keep the line breaks? It renders the same (or so I hope), and is easier on the eyes for reading.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488730328", "createdAt": "2020-09-15T14:50:00Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -205,16 +205,14 @@ data, depending on the underlying disk technology.\n \n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n-fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+fault-tolerant data processing. It has sources and sinks to integrate\n+with various file-, messaging- and database systems (such as Amazon S3,\n+Kafka, message brokers and relational databases).\n \n Jet also provides a Debezium module where it can process change events\n directly from the database and write them to its distributed key-value\n-store.\n-This avoids having to write the intermediate messages to Kafka and then\n-read again to be written to a separate cache.\n+store. This avoids having to write the intermediate messages to Kafka", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMTQzMA==", "bodyText": "Provide a mapping function to extract the cache key from the ChangeRecord", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488731430", "createdAt": "2020-09-15T14:51:30Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map\n \n-3. Wrap `Person` objects into `Map.Entry`s keyed by ID\n+3. Name of the remote map\n \n-4. Create the sink to write to, a remote map\n+4. Client configuration so it can connect to the right host, cluster\n+and instance\n \n-5. Name of the remote map\n+5. Provide mapping from `ChangeRecord` to cache key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMTg3Mg==", "bodyText": "Provide a mapping function to extract the cache value (the Person POJO) from the ChangeRecord", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488731872", "createdAt": "2020-09-15T14:52:05Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2\n+                \"entities\",                                     //3\n+                new CustomClientConfig(env.get(\"CACHE_HOST\")),  //4\n+                r -> r.key().toMap().get(\"id\"),                 //5\n+                r -> r.value().toObject(Person.class)           //6\n         ));\n ```\n \n-1. Get a stream of Jet `ChangeRecord`\n+1. Get a stream of Jet `ChangeRecord` items\n \n-2. Convert `ChangeRecord` to a regular `Person` POJO\n+2. Create the sink to write to, a remote map\n \n-3. Wrap `Person` objects into `Map.Entry`s keyed by ID\n+3. Name of the remote map\n \n-4. Create the sink to write to, a remote map\n+4. Client configuration so it can connect to the right host, cluster\n+and instance\n \n-5. Name of the remote map\n+5. Provide mapping from `ChangeRecord` to cache key\n \n-6. Client configuration so it can connect to the right host, cluster\n-  and instance\n+6. Provide mapping from `ChangeRecord` to cache value (`Person` POJO)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODczMzE4Nw==", "bodyText": "This API is more compact than the previous one, but it's more complex to get the hang on when you're unfamiliar with it.\nDo you intend to freeze the API at some point?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r488733187", "createdAt": "2020-09-15T14:53:46Z", "author": {"login": "nfrankel"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -270,28 +268,26 @@ The pipeline definition is quite straightforward:\n ```java\n pipeline.readFrom(source)                                       //1\n         .withoutTimestamps()\n-        .map(r -> {\n-            Person person = r.value().toObject(Person.class);   //2\n-            return Util.entry(person.id, person);               //3\n-        })\n-        .writeTo(Sinks.remoteMap(                               //4\n-                \"entities\",                                     //5\n-                new CustomClientConfig(env.get(\"CACHE_HOST\"))   //6\n+        .writeTo(CdcSinks.remoteMap(                            //2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f8cba78e4e91a4f5f6d5a4581ddc5a74cf2627ad"}, "originalPosition": 33}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1684f356d1beb483faae3d93075226457f455da5", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/1684f356d1beb483faae3d93075226457f455da5", "committedDate": "2020-09-16T07:49:02Z", "message": "Address review concerns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3037008538d7a5c87078f10450b473bc75d8d92e", "committedDate": "2020-09-16T10:14:43Z", "message": "Address review concerns"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5NTA4MjQ1", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#pullrequestreview-489508245", "createdAt": "2020-09-16T10:56:31Z", "commit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5NjYxNTAw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#pullrequestreview-489661500", "createdAt": "2020-09-16T14:05:15Z", "commit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNToxNVrOHSyibQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNDowNToxNVrOHSyibQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ2NDQyOQ==", "bodyText": "Is this some leftover change? It doesn't seem to improve anything.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2519#discussion_r489464429", "createdAt": "2020-09-16T14:05:15Z", "author": {"login": "mtopolnik"}, "path": "site/website/blog/2020-07-16-designing-evergreen-cache-cdc.md", "diffHunk": "@@ -206,9 +206,9 @@ data, depending on the underlying disk technology.\n [Hazelcast Jet](https://jet-start.sh/) is a distributed stream\n processing framework built on Hazelcast and combines a cache with\n fault-tolerant data processing.\n-It has sources and sinks to integrate with several file, messaging and\n-database systems (such as Amazon S3, Kafka, message brokers and\n-relational databases).\n+It has sources and sinks to integrate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3037008538d7a5c87078f10450b473bc75d8d92e"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31a3cf2b44c12922ed19206995a47087129d667b", "author": {"user": null}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/31a3cf2b44c12922ed19206995a47087129d667b", "committedDate": "2020-09-17T07:18:54Z", "message": "Fix formatting"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3604, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}