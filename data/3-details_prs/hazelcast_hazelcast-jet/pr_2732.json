{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyNTk3ODMy", "number": 2732, "title": "Reduce poll and init timeout in Kafka source", "bodyText": "We reduced the poll timeout from 50ms to 0ms. The consumer receives\nrecords on the background, there's no need to block for more records,\njust grab those that are immediately available. This reduces snapshot\nlatency.\nSecondly, it fixes the issue when the consumer.partitionsFor() can\nblock for up to 60 seconds waiting for the metadata in the init()\nmethod. We reduced the waiting to 1 second, which can easily not be\nenough. As as consequence, we had to adapt the processor to live without\npartition information and try to get it later (we already did that when\nchecking for partitions added at runtime). The major change was that\nnow, when restoring offsets from the snapshot, we can't rely on\ncurrentAssignment, but we'll simply assume the topic has at least as\nmany partitions as the number of offsets we restored for that topic.\nAs a side effect, this also fixes the issue when a partition was added\nwhile the job was down. Take this scenario:\n\ntopic T has 1 partition\nthe job is suspended\nwhile suspended, another partition is added\nthe job wakes up\n\nNow there's the change: Previously, the processor found out in the\ninit method that there are 2 partitions. These partitions would start\nat default positions. Then, offset for partition 1 was restored, but no\noffset for partition 2. If the auto.offset.reset parameter was\nlatest (the default), we could miss the messages in partition 2 before\nthe job restarted.\nWith current implementation we don't check partition counts in init.\nWhen the job restarts, it will restore offsets for partition 1, but not\nfor 2. The partition count for the topic will be inferred to 1. Later,\nafter the snapshot is restored, it will query the metadata for the topic\nand find out there are 2 partitions. The 2nd partition will be added and\nsought to the beginning and all items from it will be consumed.\nFixes #2724", "createdAt": "2020-12-04T15:16:25Z", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732", "merged": true, "mergeCommit": {"oid": "04fe8d304fa79f3f237f04de4e49baeaafd6dfb0"}, "closed": true, "closedAt": "2020-12-09T15:22:53Z", "author": {"login": "viliam-durina"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdi5SkiAH2gAyNTMyNTk3ODMyOmVmMzg5MzBlMWUzODkyYzdiMGQyMDU3MjhiNTFjYjQyY2JjNjc4NmY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkbqLegH2gAyNTMyNTk3ODMyOmYxNmU4YTNiNjZlNDdiMDJlZTk4M2U2OGU0NjgwMDk0OGJkNzZiNzE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ef38930e1e3892c7b0d205728b51cb42cbc6786f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/ef38930e1e3892c7b0d205728b51cb42cbc6786f", "committedDate": "2020-12-04T15:15:32Z", "message": "Reduce poll and init timeout in Kafka source\n\nWe reduced the `poll` timeout from 50ms to 0ms. The consumer receives\nrecords on the background, there's no need to block for more records,\njust grab those that are immediately available. This reduces snapshot\nlatency.\n\nSecondly, it fixes the issue when the `consumer.partitionsFor()` can\nblock for up to 60 seconds waiting for the metadata in the `init()`\nmethod. We reduced the waiting to 1 second, which can easily not be\nenough. As as consequence, we had to adapt the processor to live without\npartition information and try to get it later (we already did that when\nchecking for partitions added at runtime). The major change was that\nnow, when restoring offsets from the snapshot, we can't rely on\n`currentAssignment`, but we'll simply assume the topic has at least as\nmany partitions as the number of offsets we restored for that topic.\n\nAs a side effect, this also fixes the issue when a partition was added\nwhile the job was down. Take this scenario:\n- topic T has 1 partition\n- the job is suspended\n- while suspended, another partition is added\n- the job wakes up\n\nNow there's the change: Previously, the processor found out in the\n`init` method that there are 2 partitions. These partitions would start\nat default positions. Then, offset for partition 1 was restored, but no\noffset for partition 2. If the `auto.offset.reset` parameter was\n`latest` (the default), we could miss the messages in partition 2 before\nthe job restarted.\n\nWith current implementation we don't check partition counts in `init`.\nWhen the job restarts, it will restore offsets for partition 1, but not\nfor 2. The partition count for the topic will be inferred to 1. Later,\nafter the snapshot is restored, it will query the metadata for the topic\nand find out there are 2 partitions. The 2nd partition will be added and\nsought to the beginning and all items from it will be consumed.\n\nFixes #2724"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3264f3848301e6aa981c5881071e991be541028d", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/3264f3848301e6aa981c5881071e991be541028d", "committedDate": "2020-12-07T08:20:50Z", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into kafka-fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1521e199747448356f51f35eaedf60c7ffa7b5f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/c1521e199747448356f51f35eaedf60c7ffa7b5f", "committedDate": "2020-12-07T13:35:13Z", "message": "Add tests and final fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0d12238f53bc5ee9251cb76af167f90a3c98ef4", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/e0d12238f53bc5ee9251cb76af167f90a3c98ef4", "committedDate": "2020-12-07T13:38:16Z", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into kafka-fixes\n\n# Conflicts:\n#\thazelcast-jet-core/src/test/java/com/hazelcast/jet/pipeline/MockLoggingFactory.java"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MzM3OTEx", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732#pullrequestreview-546337911", "createdAt": "2020-12-07T16:50:05Z", "commit": {"oid": "e0d12238f53bc5ee9251cb76af167f90a3c98ef4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNjo1MDowNVrOIAwNiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxNjo1MDowNVrOIAwNiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY2MDgwOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    getLogger().info(\"New partition(s) handled: \" + newAssignments);\n          \n          \n            \n                    getLogger().info(\"New partition(s) assigned: \" + newAssignments);", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732#discussion_r537660809", "createdAt": "2020-12-07T16:50:05Z", "author": {"login": "gierlachg"}, "path": "extensions/kafka/src/main/java/com/hazelcast/jet/kafka/impl/StreamKafkaP.java", "diffHunk": "@@ -107,60 +106,63 @@ protected void init(@Nonnull Context context) {\n         processorIndex = context.globalProcessorIndex();\n         totalParallelism = context.totalParallelism();\n         consumer = new KafkaConsumer<>(properties);\n-        assignPartitions(false);\n     }\n \n-    private void assignPartitions(boolean seekToBeginning) {\n+    private void assignPartitions() {\n         if (System.nanoTime() < nextMetadataCheck) {\n             return;\n         }\n-        boolean allEqual = true;\n-        for (int i = 0; i < topics.size(); i++) {\n-            int newCount = consumer.partitionsFor(topics.get(i)).size();\n-            allEqual &= partitionCounts[i] == newCount;\n-            partitionCounts[i] = newCount;\n-        }\n-        if (allEqual) {\n-            return;\n-        }\n-\n-        KafkaPartitionAssigner assigner = new KafkaPartitionAssigner(topics, partitionCounts, totalParallelism);\n-        Set<TopicPartition> newAssignments = assigner.topicPartitionsFor(processorIndex);\n-        logFinest(getLogger(), \"Currently assigned partitions: %s\", newAssignments);\n-\n-        newAssignments.removeAll(currentAssignment.keySet());\n-        if (!newAssignments.isEmpty()) {\n-            getLogger().info(\"Partition assignments changed, added partitions: \" + newAssignments);\n-            for (TopicPartition tp : newAssignments) {\n-                currentAssignment.put(tp, currentAssignment.size());\n-            }\n-            eventTimeMapper.addPartitions(newAssignments.size());\n-            consumer.assign(currentAssignment.keySet());\n-            if (seekToBeginning) {\n-                // for newly detected partitions, we should always seek to the beginning\n-                consumer.seekToBeginning(newAssignments);\n+        for (int topicIndex = 0; topicIndex < topics.size(); topicIndex++) {\n+            int newPartitionCount;\n+            String topicName = topics.get(topicIndex);\n+            try {\n+                newPartitionCount = consumer.partitionsFor(topicName, Duration.ofSeconds(1)).size();\n+            } catch (TimeoutException e) {\n+                // If we fail to get the metadata, don't try other topics (they are likely to fail too)\n+                getLogger().warning(\"Unable to get partition metadata, ignoring: \" + e, e);\n+                return;\n             }\n+\n+            handleNewPartitions(topicIndex, newPartitionCount);\n         }\n \n-        createOrExtendOffsetsArrays();\n         nextMetadataCheck = System.nanoTime() + METADATA_CHECK_INTERVAL_NANOS;\n     }\n \n-    private void createOrExtendOffsetsArrays() {\n-        for (int topicIdx = 0; topicIdx < partitionCounts.length; topicIdx++) {\n-            int newPartitionCount = partitionCounts[topicIdx];\n-            String topicName = topics.get(topicIdx);\n-            long[] oldOffsets = offsets.get(topicName);\n-            if (oldOffsets != null && oldOffsets.length == newPartitionCount) {\n-                continue;\n-            }\n-            long[] newOffsets = new long[newPartitionCount];\n-            Arrays.fill(newOffsets, -1);\n-            if (oldOffsets != null) {\n-                arraycopy(oldOffsets, 0, newOffsets, 0, oldOffsets.length);\n+    private void handleNewPartitions(int topicIndex, int newPartitionCount) {\n+        String topicName = topics.get(topicIndex);\n+        long[] oldTopicOffsets = offsets.get(topicName);\n+        if (oldTopicOffsets.length >= newPartitionCount) {\n+            return;\n+        }\n+        // extend the offsets array for this topic\n+        long[] newOffsets = Arrays.copyOf(oldTopicOffsets, newPartitionCount);\n+        Arrays.fill(newOffsets, oldTopicOffsets.length, newOffsets.length, -1);\n+        offsets.put(topicName, newOffsets);\n+        Collection<TopicPartition> newAssignments = new ArrayList<>();\n+        for (int partition = oldTopicOffsets.length; partition < newPartitionCount; partition++) {\n+            if (handledByThisProcessor(topicIndex, partition)) {\n+                TopicPartition tp = new TopicPartition(topicName, partition);\n+                currentAssignment.put(tp, currentAssignment.size());\n+                newAssignments.add(tp);\n             }\n-            offsets.put(topicName, newOffsets);\n         }\n+        if (newAssignments.isEmpty()) {\n+            return;\n+        }\n+        getLogger().info(\"New partition(s) handled: \" + newAssignments);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0d12238f53bc5ee9251cb76af167f90a3c98ef4"}, "originalPosition": 160}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2ODIwNDQw", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732#pullrequestreview-546820440", "createdAt": "2020-12-08T07:40:17Z", "commit": {"oid": "e0d12238f53bc5ee9251cb76af167f90a3c98ef4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwNzo0MDoxN1rOIBLQfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwNzo0MDoxN1rOIBLQfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODEwMzkzMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertTrue(processor.   currentAssignment.isEmpty());\n          \n          \n            \n                    assertTrue(processor.currentAssignment.isEmpty());", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732#discussion_r538103933", "createdAt": "2020-12-08T07:40:17Z", "author": {"login": "gierlachg"}, "path": "extensions/kafka/src/test/java/com/hazelcast/jet/kafka/impl/StreamKafkaPTest.java", "diffHunk": "@@ -244,7 +246,7 @@ public void when_noAssignedPartitionAndAddedLater_then_resumesFromIdle() throws\n                 .setTotalParallelism(INITIAL_PARTITION_COUNT + 1)\n                 .setGlobalProcessorIndex(INITIAL_PARTITION_COUNT));\n \n-        assertTrue(processor.currentAssignment.isEmpty());\n+        assertTrue(processor.   currentAssignment.isEmpty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0d12238f53bc5ee9251cb76af167f90a3c98ef4"}, "originalPosition": 69}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aee8632dfbeec6e82af0358cf134dac7ed6cf27f", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/aee8632dfbeec6e82af0358cf134dac7ed6cf27f", "committedDate": "2020-12-08T07:51:44Z", "message": "Remove double seeking"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2ODI4MTE5", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2732#pullrequestreview-546828119", "createdAt": "2020-12-08T07:53:18Z", "commit": {"oid": "aee8632dfbeec6e82af0358cf134dac7ed6cf27f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "398f0b8f3f77cb144e6d13c96fbc77521b3582e6", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/398f0b8f3f77cb144e6d13c96fbc77521b3582e6", "committedDate": "2020-12-09T09:48:31Z", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into kafka-fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f16e8a3b66e47b02ee983e68e46800948bd76b71", "author": {"user": {"login": "viliam-durina", "name": "Viliam Durina"}}, "url": "https://github.com/hazelcast/hazelcast-jet/commit/f16e8a3b66e47b02ee983e68e46800948bd76b71", "committedDate": "2020-12-09T09:52:01Z", "message": "Address review comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3413, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}