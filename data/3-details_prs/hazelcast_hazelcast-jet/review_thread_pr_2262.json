{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5OTE2MjQ0", "number": 2262, "reviewThreads": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMTo1OVrOD_idtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMjowNFrOD_qbcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUxNTQxOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMTo1OVrOGaQUuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMTo1OVrOGaQUuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzYwOA==", "bodyText": "3.2?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183608", "createdAt": "2020-05-26T06:31:59Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUxNjA2OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjoxNFrOGaQVGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjoxNFrOGaQVGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzcwNQ==", "bodyText": "mirror/replica would be better", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183705", "createdAt": "2020-05-26T06:32:14Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUxNzQzOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1MFrOGaQV5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1MFrOGaQV5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4MzkxMQ==", "bodyText": "I think we should be more explicit here in the doc", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183911", "createdAt": "2020-05-26T06:32:50Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUxNzcyOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1N1rOGaQWFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozMjo1N1rOGaQWFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4Mzk1OQ==", "bodyText": "this is wrong, it should be 4.0", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430183959", "createdAt": "2020-05-26T06:32:57Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUyNDEyOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNTowOFrOGaQZpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNTowOFrOGaQZpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NDg3MQ==", "bodyText": "what is expiration?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430184871", "createdAt": "2020-05-26T06:35:08Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUyNDgwOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNToyNVrOGaQaDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjo0OToxM1rOGaQvjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NDk3Mg==", "bodyText": "this is quite large", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430184972", "createdAt": "2020-05-26T06:35:25Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 233}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE5MDQ3Nw==", "bodyText": "I've set a large value due to what's in the Javadoc, but I might have overdone it. I was thinking that it's possible to observe keys at a rate of 200,000/sec, so with a 10 second expiration you could potentially get a lot of them, so 64K initial capacity didn't seem a lot. But since it's only initial capacity and can increase on demand, yeah, a smaller value should do it.\n\nA linked hash map has two parameters that affect its performance: initial capacity and load factor. They are defined precisely as for HashMap. Note, however, that the penalty for choosing an excessively high value for initial capacity is less severe for this class than for HashMap, as iteration times for this class are unaffected by capacity.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430190477", "createdAt": "2020-05-26T06:49:13Z", "author": {"login": "jbartok"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NDk3Mg=="}, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 233}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUyNjQxOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjowN1rOGaQbDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjowN1rOGaQbDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NTIzMQ==", "bodyText": "can yo uwrite some javadoc explaining what this does, the name doesn't tell much", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430185231", "createdAt": "2020-05-26T06:36:07Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUyNjg5OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozNjoyMVrOGaQbYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMTo1NVrOGaZO_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NTMxNQ==", "bodyText": "what's stored here?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430185315", "createdAt": "2020-05-26T06:36:21Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 236}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMyOTU5Nw==", "bodyText": "what's in long[] should be documented, for example that the last element is timestamp etc", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430329597", "createdAt": "2020-05-26T11:01:55Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NTMxNQ=="}, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 236}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUzMjI2OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo0MFrOGaQevw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNzowOToyM1rOGaRR_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjE3NQ==", "bodyText": "can this happen? if not, it should just be an assertion", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430186175", "createdAt": "2020-05-26T06:38:40Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[] {partition, value, timestamp});\n+                return true;\n+            } else {\n+                prevSequence[2] = timestamp;\n+                if (prevSequence[0] != partition) { //sequence partition changed for key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 255}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE5OTI5NA==", "bodyText": "It should be possible, for example when you have a setup where the Debezium connector is able to switch from one DB to another. Is also the cause of simple numeric value not being enough as a sequence number.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430199294", "createdAt": "2020-05-26T07:09:23Z", "author": {"login": "jbartok"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[] {partition, value, timestamp});\n+                return true;\n+            } else {\n+                prevSequence[2] = timestamp;\n+                if (prevSequence[0] != partition) { //sequence partition changed for key", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjE3NQ=="}, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 255}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3OTUzMjc4OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjozODo1NlrOGaQfFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo0NDo0MFrOGacgLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjI2Mw==", "bodyText": "you can use compute instead of doing two separate put/gets (two hash lookups)", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430186263", "createdAt": "2020-05-26T06:38:56Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDIyMTA3NA==", "bodyText": "A put only happens once for a key during a 10s period (or whatever the expiration is). Wouldn't compute be a far worse solution due to all the garbage it would create (would be using a capturing-lamda)?", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430221074", "createdAt": "2020-05-26T07:51:36Z", "author": {"login": "jbartok"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjI2Mw=="}, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM4MzE1MA==", "bodyText": "Yes you are right. I thought we could pass in a constant lambda, but doesn't work in this case.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430383150", "createdAt": "2020-05-26T12:44:40Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 3.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date image of a change\n+     * data capture stream in the form of an {@code IMap}. By image we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Convenience for {@link #map(String, FunctionEx, FunctionEx)} with\n+     * actual {@code IMap} instance being passed in, instead of just\n+     * name.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least 3.11.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            int expiration = properties.getSeconds(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expiration);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            long timestamp = getTimestamp(item);\n+\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, timestamp, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+        private static long getTimestamp(ChangeRecord item) {\n+            try {\n+                return item.timestamp();\n+            } catch (ParsingException e) {\n+                //use current time, should be good enough for cache expiration purposes\n+                return System.currentTimeMillis();\n+            }\n+        }\n+\n+    }\n+\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 64 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        public Sequences(int expiration) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = eldest.getValue()[2];\n+                    return System.currentTimeMillis() - age > expiration;\n+                }\n+            };\n+        }\n+\n+        boolean update(K key, long timestamp, long partition, long value) {\n+            long[] prevSequence = sequences.get(key);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE4NjI2Mw=="}, "originalCommit": {"oid": "319d3abedf96708f1b2d4dc940a12b6934dfb246"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDQyMDI5OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjowNFrOGaZPZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjowNFrOGaZPZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMyOTcwMQ==", "bodyText": "you don't need the else here.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430329701", "createdAt": "2020-05-26T11:02:04Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 318}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDQyMTIxOnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjoyMFrOGaZP7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjoyMFrOGaZP7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMyOTgzOQ==", "bodyText": "can be inlined", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430329839", "createdAt": "2020-05-26T11:02:20Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDQyMjc1OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjo0OVrOGaZQ6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMjo0OVrOGaZQ6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMDA4OQ==", "bodyText": "no need for else", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430330089", "createdAt": "2020-05-26T11:02:49Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {\n+                prevSequence[2] = System.currentTimeMillis();\n+                if (prevSequence[0] != partition) { //sequence partition changed for key\n+                    prevSequence[0] = partition;\n+                    prevSequence[1] = sequence;\n+                    return true;\n+                } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 324}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDQyMzg3OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMzoxNVrOGaZRtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowMzoxNVrOGaZRtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMDI5NQ==", "bodyText": "no need for else", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430330295", "createdAt": "2020-05-26T11:03:15Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure\n+     * that {@code ChangeRecord}s produced by a source contain a monotonic\n+     * increasing sequence number, as long as the sequence number partition\n+     * doesn't change.\n+     * <p>\n+     * The <i>partition</i> part is a kind of context for the numeric\n+     * sequence, the \"source\" of it if you will. It is necessary for avoiding\n+     * the comparison of numeric sequences which come from different sources.\n+     * For example if the numeric sequence is in fact based on transaction\n+     * IDs, then it makes sense to compare them only if they are produced by\n+     * the same database instance. Or if the numeric ID is an offset in a\n+     * write-ahead log, then it makes sense to compare them only if they are\n+     * offsets from the same log file. Implementations need to make sure that\n+     * the partition is the same if and only if the source of the numeric\n+     * sequence is the same.\n+     * <p>\n+     * Tracking of the sequence numbers for various keys happens in a\n+     * LRU cache style, keys that haven't been updated nor read since a\n+     * certain time (see {@code expirationMs} parameter) will be evicted,\n+     * to keep the memory consumption limited. This is ok, because\n+     * reordering of events happens only in case of events spaced very\n+     * close to each other in time.\n+     */\n+    private static final class Sequences<K> {\n+\n+        private static final int INITIAL_CAPACITY = 4 * 1024;\n+        private static final float LOAD_FACTOR = 0.75f;\n+\n+        private final LinkedHashMap<K, long[]> sequences;\n+\n+        /**\n+         * @param expirationMs number of milliseconds for which a sequence\n+         *                     observed for a certain key is guaranteed\n+         *                     to be tracked; might be evicted afterwards\n+         */\n+        Sequences(long expirationMs) {\n+            sequences = new LinkedHashMap<K, long[]>(INITIAL_CAPACITY, LOAD_FACTOR, true) {\n+                @Override\n+                protected boolean removeEldestEntry(Map.Entry<K, long[]> eldest) {\n+                    long age = System.currentTimeMillis() - eldest.getValue()[2];\n+                    return age > expirationMs;\n+                }\n+            };\n+        }\n+\n+        /**\n+         * @param key       key of an event that has just been observed\n+         * @param partition partition of the source event sequence number\n+         * @param sequence  numeric value of the source event sequence number\n+         * @return true if the newly observed sequence number if more\n+         * recent than what we have observed before (if any)\n+         */\n+        boolean update(K key, long partition, long sequence) {\n+            long[] prevSequence = sequences.get(key);\n+            if (prevSequence == null) { //first observed sequence for key\n+                sequences.put(key, new long[]{partition, sequence, System.currentTimeMillis()});\n+                return true;\n+            } else {\n+                prevSequence[2] = System.currentTimeMillis();\n+                if (prevSequence[0] != partition) { //sequence partition changed for key\n+                    prevSequence[0] = partition;\n+                    prevSequence[1] = sequence;\n+                    return true;\n+                } else {\n+                    if (prevSequence[1] < sequence) { //sequence is newer than previous for key\n+                        prevSequence[1] = sequence;\n+                        return true;\n+                    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 328}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDQyOTI5OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMTowNTowNVrOGaZVWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo0NzoyNFrOGacmrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMTIyNw==", "bodyText": "this is not true, it's a specific three element array and the role of each element is well defined. it's just not any array that's sorted", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430331227", "createdAt": "2020-05-26T11:05:05Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 261}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM0ODcyMA==", "bodyText": "The comment talks about the conceptual sequence number, which consists of two parts, not the array we use, which also holds a timestamp used for expiration, but which is not part of the sequence number. Will find a clearer form.", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430348720", "createdAt": "2020-05-26T11:40:52Z", "author": {"login": "jbartok"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMTIyNw=="}, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 261}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM4NDgxMw==", "bodyText": "Yes that's kind of what I meant.. the description didn't quite match what was in the code (with the long[])", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430384813", "createdAt": "2020-05-26T12:47:24Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        ProcessorSupplier supplier = AbstractHazelcastConnectorSupplier.of(asXmlString(clientConfig),\n+                instance -> new CdcSinkProcessor<>(instance, map, keyFn, extend(valueFn)));\n+        ProcessorMetaSupplier metaSupplier = ProcessorMetaSupplier.forceTotalParallelismOne(supplier, name);\n+        return new SinkImpl<>(name, metaSupplier, true, null);\n+    }\n+\n+    @Nonnull\n+    private static <V> FunctionEx<ChangeRecord, V> extend(@Nonnull FunctionEx<ChangeRecord, V> valueFn) {\n+        return (record) -> {\n+            if (DELETE.equals(record.operation())) {\n+                return null;\n+            }\n+            return valueFn.apply(record);\n+        };\n+    }\n+\n+    private static class CdcSinkProcessor<K, V> extends UpdateMapWithMaterializedValuesP<ChangeRecord, K, V> {\n+\n+        private Sequences<K> sequences;\n+\n+        CdcSinkProcessor(\n+                @Nonnull HazelcastInstance instance,\n+                @Nonnull String map,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends K> keyFn,\n+                @Nonnull FunctionEx<? super ChangeRecord, ? extends V> valueFn\n+        ) {\n+            super(instance, map, keyFn, valueFn);\n+        }\n+\n+        @Override\n+        public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+            super.init(outbox, context);\n+\n+            HazelcastProperties properties = new HazelcastProperties(context.jetInstance().getConfig().getProperties());\n+            long expirationMs = properties.getMillis(SEQUENCE_CACHE_EXPIRATION_SECONDS);\n+            this.sequences = new Sequences<>(expirationMs);\n+        }\n+\n+        @Override\n+        protected boolean shouldBeDropped(K key, ChangeRecord item) {\n+            ChangeRecordImpl recordImpl = (ChangeRecordImpl) item;\n+            long sequencePartition = recordImpl.getSequencePartition();\n+            long sequenceValue = recordImpl.getSequenceValue();\n+\n+            boolean isNew = sequences.update(key, sequencePartition, sequenceValue);\n+            return !isNew;\n+        }\n+\n+    }\n+\n+    /**\n+     * Tracks the last seen sequence number for a set of keys. The\n+     * sequence numbers originate from Debezium event headers and consist\n+     * of two parts.\n+     * <p>\n+     * The <i>sequence</i> part is exactly what the name implies: a numeric\n+     * sequence which we base our ordering on. Implementations needs to ensure", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDMzMTIyNw=="}, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 261}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDgwMDI5OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo1NzowOFrOGac-pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo1NzowOFrOGac-pw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5MDk1MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull IMap<? super K, V> map,\n          \n          \n            \n                        @Nonnull IMap<? super K, ? super V> map,", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430390951", "createdAt": "2020-05-26T12:57:08Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDgwNjM5OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo1ODo0M1rOGadCiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMjo1ODo0M1rOGadCiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5MTk0NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430391944", "createdAt": "2020-05-26T12:58:43Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 191}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDgxOTA0OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMTo0M1rOGadKWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMTo0M1rOGadKWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5Mzk0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430393947", "createdAt": "2020-05-26T13:01:43Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4MDgyMDM0OnYy", "diffSide": "RIGHT", "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMjowNFrOGadLMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxMzowMjowNFrOGadLMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDM5NDE2MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, V> valueFn\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends K> keyFn,\n          \n          \n            \n                        @Nonnull FunctionEx<ChangeRecord, ? extends V> valueFn", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2262#discussion_r430394160", "createdAt": "2020-05-26T13:02:04Z", "author": {"login": "cangencer"}, "path": "extensions/cdc-debezium/src/main/java/com/hazelcast/jet/cdc/CdcSinks.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc;\n+\n+import com.hazelcast.client.config.ClientConfig;\n+import com.hazelcast.core.HazelcastInstance;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.impl.connector.AbstractHazelcastConnectorSupplier;\n+import com.hazelcast.jet.impl.connector.UpdateMapWithMaterializedValuesP;\n+import com.hazelcast.jet.impl.pipeline.SinkImpl;\n+import com.hazelcast.jet.pipeline.Sink;\n+import com.hazelcast.map.IMap;\n+import com.hazelcast.spi.properties.HazelcastProperties;\n+import com.hazelcast.spi.properties.HazelcastProperty;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.cdc.Operation.DELETE;\n+import static com.hazelcast.jet.impl.util.ImdgUtil.asXmlString;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Contains factory methods for change data capture specific pipeline\n+ * sinks. As a consequence these sinks take {@link ChangeRecord} items\n+ * as their input.\n+ * <p>\n+ * These sinks can detect any <i>reordering</i> that might have happened\n+ * in the stream of {@code ChangeRecord} items they ingest (Jet pipelines\n+ * benefit from massively parallel execution, so item reordering can and\n+ * does happen). The reordering is based on implementation specific\n+ * sequence numbers provided by CDC event sources. The sink reacts to\n+ * reordering by dropping obsolete input items. The exact behaviour\n+ * looks like this. For each input item the sink:\n+ * <ol>\n+ *  <li>applies the {@code keyFn} on the input item to extract its key</li>\n+ *  <li>extracts the input item's sequence number</li>\n+ *  <li>compares the extracted sequence number against the previously\n+ *          seen sequence number for the same key, if any</li>\n+ *  <li>if there is a previously seen sequence number and is more recent\n+ *          than the one observed in the input item, then drops (ignores)\n+ *          the input item</li>\n+ * </ol>\n+ *\n+ * @since 4.2\n+ */\n+public final class CdcSinks {\n+\n+    /**\n+     * Number of seconds for which the last seen sequence number for any\n+     * input key will be guarantied to be remembered (used for\n+     * reordering detection). After this time, the last seen sequence\n+     * number values will eventually be evicted, in order to save space.\n+     * <p>\n+     * Default value is 10 seconds.\n+     *\n+     * @since 4.2\n+     */\n+    public static final HazelcastProperty SEQUENCE_CACHE_EXPIRATION_SECONDS\n+            = new HazelcastProperty(\"jet.cdc.sink.sequence.cache.expiration.seconds\", 10, SECONDS);\n+\n+    private CdcSinks() {\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull String map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"localMapCdcSink(\" + map + ')';\n+        return sink(name, map, null, keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink which maintains an up-to-date mirror of a change\n+     * data capture stream in the form of an {@code IMap}. By mirror we\n+     * mean that the map should always describe the end result of merging\n+     * all the change events seen so far.\n+     * <p>\n+     * <b>NOTE</b>: in order for the sink behaviour to be predictable\n+     * the map should be non-existent or empty by the time the sink starts\n+     * using it.\n+     * <p>\n+     * For each item the sink receives it uses the {@code keyFn} to\n+     * determine which map key the change event applies to. Then, based\n+     * on the {@code ChangeRecord}'s {@code Operation} it decides to\n+     * either:\n+     * <ul>\n+     *   <li>delete the key from the map\n+     *          ({@link Operation#DELETE})</li>\n+     *   <li>insert a new value for the key\n+     *          ({@link Operation#SYNC} & {@link Operation#INSERT})</li>\n+     *   <li>update the current value for the key\n+     *          ({@link Operation#UPDATE})</li>\n+     * </ul>\n+     * For insert and update operations the new value to use is\n+     * determined from the input record by using the provided\n+     * {@code valueFn}. <strong>IMPORTANT</strong> to note that if the\n+     * {@code valueFn} returns {@code null}, then the key will be\n+     * deleted from the map no matter the operation (ie. even for update\n+     * and insert records).\n+     * <p>\n+     * For the functionality of this sink it is vital that the order of\n+     * the input items is preserved so we'll always create a single\n+     * instance of it in each pipeline.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> map(\n+            @Nonnull IMap<? super K, V> map,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        return map(map.getName(), keyFn, valueFn);\n+    }\n+\n+    /**\n+     * Returns a sink equivalent to {@link #map}, but for a map in a\n+     * remote Hazelcast cluster identified by the supplied {@code\n+     * ClientConfig}.\n+     * <p>\n+     * <b>NOTE</b>: same limitation as for {@link #map}, the map should\n+     * be non-existent or empty by the time the sink starts using it.\n+     * <p>\n+     * Due to the used API, the remote cluster must be at least version 4.0.\n+     *\n+     * @since 4.2\n+     */\n+    @Nonnull\n+    public static <K, V> Sink<ChangeRecord> remoteMap(\n+            @Nonnull String map,\n+            @Nonnull ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn\n+    ) {\n+        String name = \"remoteMapCdcSink(\" + map + ')';\n+        return sink(name, map, clientConfig, keyFn, valueFn);\n+    }\n+\n+    @Nonnull\n+    private static <K, V> Sink<ChangeRecord> sink(\n+            @Nonnull String name,\n+            @Nonnull String map,\n+            @Nullable ClientConfig clientConfig,\n+            @Nonnull FunctionEx<ChangeRecord, K> keyFn,\n+            @Nonnull FunctionEx<ChangeRecord, V> valueFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4ef9cd7e2488d2b3c84e28ccfb1e1b0809a5c94"}, "originalPosition": 203}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4718, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}