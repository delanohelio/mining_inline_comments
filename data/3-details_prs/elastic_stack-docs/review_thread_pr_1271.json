{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ4NTY2Mzg5", "number": 1271, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QxODoyMzo1MFrOGOFpig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QyMTowOToyNFrOGOJplg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDE3NDI1ODAyOnYy", "diffSide": "RIGHT", "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QxODoyMzo1MFrOJy6Ixg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QyMTowODoxMFrOJzAUTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzM2MTA5NA==", "bodyText": "It's worth adding that the cardinality estimates used by Kibana come from running aggregations against the source indices of the datafeed at the time Kibana is being used to create the job.  If these are not reflective of the cardinality the job will experience while running (for example because ingest hasn't yet started at the time the job is created) then the memory estimate will be wrong.\nIf you use the estimate anomaly detection jobs model memory API then you must provide your own cardinality estimates.", "url": "https://github.com/elastic/stack-docs/pull/1271#discussion_r657361094", "createdAt": "2021-06-23T18:23:50Z", "author": {"login": "droberts195"}, "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "diffHunk": "@@ -159,18 +159,29 @@ start the {dfeed} for the change to be applied.\n == 7. Set the model memory limit\n \n The `model_memory_limit` job configuration option sets the approximate maximum \n-amount of memory resources required for analytical processing. If this variable \n-is set too low for the job and the limit is approached, data pruning becomes \n-more aggressive. Upon exceeding this limit, new entities are not modeled.\n-\n-Use model memory estimation to have a better picture of the memory needs of the \n-model. Model memory estimation happens automatically when you create the job in \n-{kib} or you can call the \n-{ref}/ml-estimate-model-memory.html[Estimate {anomaly-jobs} model memory API] \n-manually. The estimation is based on the analysis configuration details for the \n-job and cardinality estimates for the fields it references. You can update the \n-memory settings of an existing job, but the job must be closed.\n-\n+amount of memory resources required for analytical processing. When you create\n+an {anomaly-job} in {kib}, it provides an estimate for this limit. The estimate \n+is based on the analysis configuration details for the job and cardinality \n+estimates for the fields it references. You can also obtain this information\n+from the\n+{ref}/ml-estimate-model-memory.html[estimate {anomaly-jobs} model memory API].  ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d97139edf5205cb9f147ef012f8838cf10740cc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzQ2MjM0OA==", "bodyText": "Thanks, I've interwoven those details in these paragraphs.", "url": "https://github.com/elastic/stack-docs/pull/1271#discussion_r657462348", "createdAt": "2021-06-23T21:08:10Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "diffHunk": "@@ -159,18 +159,29 @@ start the {dfeed} for the change to be applied.\n == 7. Set the model memory limit\n \n The `model_memory_limit` job configuration option sets the approximate maximum \n-amount of memory resources required for analytical processing. If this variable \n-is set too low for the job and the limit is approached, data pruning becomes \n-more aggressive. Upon exceeding this limit, new entities are not modeled.\n-\n-Use model memory estimation to have a better picture of the memory needs of the \n-model. Model memory estimation happens automatically when you create the job in \n-{kib} or you can call the \n-{ref}/ml-estimate-model-memory.html[Estimate {anomaly-jobs} model memory API] \n-manually. The estimation is based on the analysis configuration details for the \n-job and cardinality estimates for the fields it references. You can update the \n-memory settings of an existing job, but the job must be closed.\n-\n+amount of memory resources required for analytical processing. When you create\n+an {anomaly-job} in {kib}, it provides an estimate for this limit. The estimate \n+is based on the analysis configuration details for the job and cardinality \n+estimates for the fields it references. You can also obtain this information\n+from the\n+{ref}/ml-estimate-model-memory.html[estimate {anomaly-jobs} model memory API].  ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzM2MTA5NA=="}, "originalCommit": {"oid": "4d97139edf5205cb9f147ef012f8838cf10740cc"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDE3NDI3NjQyOnYy", "diffSide": "RIGHT", "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QxODoyODoxN1rOJy6UNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QyMDozNzoxMVrOJy_LFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzM2NDAyMA==", "bodyText": "You can also decrease the model memory limit while the job is closed, providing you do not reduce it below the size reported in the latest model size stats.  (The ability to reduce model memory limit was added in 6.3.)", "url": "https://github.com/elastic/stack-docs/pull/1271#discussion_r657364020", "createdAt": "2021-06-23T18:28:17Z", "author": {"login": "droberts195"}, "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "diffHunk": "@@ -159,18 +159,29 @@ start the {dfeed} for the change to be applied.\n == 7. Set the model memory limit\n \n The `model_memory_limit` job configuration option sets the approximate maximum \n-amount of memory resources required for analytical processing. If this variable \n-is set too low for the job and the limit is approached, data pruning becomes \n-more aggressive. Upon exceeding this limit, new entities are not modeled.\n-\n-Use model memory estimation to have a better picture of the memory needs of the \n-model. Model memory estimation happens automatically when you create the job in \n-{kib} or you can call the \n-{ref}/ml-estimate-model-memory.html[Estimate {anomaly-jobs} model memory API] \n-manually. The estimation is based on the analysis configuration details for the \n-job and cardinality estimates for the fields it references. You can update the \n-memory settings of an existing job, but the job must be closed.\n-\n+amount of memory resources required for analytical processing. When you create\n+an {anomaly-job} in {kib}, it provides an estimate for this limit. The estimate \n+is based on the analysis configuration details for the job and cardinality \n+estimates for the fields it references. You can also obtain this information\n+from the\n+{ref}/ml-estimate-model-memory.html[estimate {anomaly-jobs} model memory API].  \n+\n+If you change the resources available on your {ml} nodes or the characteristics \n+of your data, the memory requirements might also change. You can increase the \n+model memory limit for an existing job while it is closed. To decrease the limit, \n+you must clone and re-run the job.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d97139edf5205cb9f147ef012f8838cf10740cc"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzQ0MzYwNw==", "bodyText": "Thanks!  I've tried to make that clearer in the API too via elastic/elasticsearch#74517", "url": "https://github.com/elastic/stack-docs/pull/1271#discussion_r657443607", "createdAt": "2021-06-23T20:37:11Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "diffHunk": "@@ -159,18 +159,29 @@ start the {dfeed} for the change to be applied.\n == 7. Set the model memory limit\n \n The `model_memory_limit` job configuration option sets the approximate maximum \n-amount of memory resources required for analytical processing. If this variable \n-is set too low for the job and the limit is approached, data pruning becomes \n-more aggressive. Upon exceeding this limit, new entities are not modeled.\n-\n-Use model memory estimation to have a better picture of the memory needs of the \n-model. Model memory estimation happens automatically when you create the job in \n-{kib} or you can call the \n-{ref}/ml-estimate-model-memory.html[Estimate {anomaly-jobs} model memory API] \n-manually. The estimation is based on the analysis configuration details for the \n-job and cardinality estimates for the fields it references. You can update the \n-memory settings of an existing job, but the job must be closed.\n-\n+amount of memory resources required for analytical processing. When you create\n+an {anomaly-job} in {kib}, it provides an estimate for this limit. The estimate \n+is based on the analysis configuration details for the job and cardinality \n+estimates for the fields it references. You can also obtain this information\n+from the\n+{ref}/ml-estimate-model-memory.html[estimate {anomaly-jobs} model memory API].  \n+\n+If you change the resources available on your {ml} nodes or the characteristics \n+of your data, the memory requirements might also change. You can increase the \n+model memory limit for an existing job while it is closed. To decrease the limit, \n+you must clone and re-run the job.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzM2NDAyMA=="}, "originalCommit": {"oid": "4d97139edf5205cb9f147ef012f8838cf10740cc"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkNDE3NDkxMzUwOnYy", "diffSide": "RIGHT", "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QyMTowOToyNFrOJzAXDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wNi0yM1QyMTowOToyNFrOJzAXDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzQ2MzA1NA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you change the resources available on your {ml} nodes or the make significant \n          \n          \n            \n            If you change the resources available on your {ml} nodes or make significant", "url": "https://github.com/elastic/stack-docs/pull/1271#discussion_r657463054", "createdAt": "2021-06-23T21:09:24Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/anomaly-detection/anomaly-detection-scale.asciidoc", "diffHunk": "@@ -159,18 +159,33 @@ start the {dfeed} for the change to be applied.\n == 7. Set the model memory limit\n \n The `model_memory_limit` job configuration option sets the approximate maximum \n-amount of memory resources required for analytical processing. If this variable \n-is set too low for the job and the limit is approached, data pruning becomes \n-more aggressive. Upon exceeding this limit, new entities are not modeled.\n-\n-Use model memory estimation to have a better picture of the memory needs of the \n-model. Model memory estimation happens automatically when you create the job in \n-{kib} or you can call the \n-{ref}/ml-estimate-model-memory.html[Estimate {anomaly-jobs} model memory API] \n-manually. The estimation is based on the analysis configuration details for the \n-job and cardinality estimates for the fields it references. You can update the \n-memory settings of an existing job, but the job must be closed.\n-\n+amount of memory resources required for analytical processing. When you create\n+an {anomaly-job} in {kib}, it provides an estimate for this limit. The estimate \n+is based on the analysis configuration details for the job and cardinality \n+estimates, which are derived by running aggregations on the source indices as\n+they exist at that specific point in time. \n+\n+If you change the resources available on your {ml} nodes or the make significant ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ff588ab54dd4196b6415171e5a73a149cfe063e"}, "originalPosition": 22}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1422, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}