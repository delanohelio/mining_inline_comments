{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk2NzgxNDI2", "number": 1394, "title": "[DOCS] Adds data frame analytics at scale page to the ML DFA docs", "bodyText": "Overview\nThis PR adds a Data frame analytics at scale page to the ML DFA documentation as a sub-page of the Overview section.\nPreview\nWorking with data frame analytics at scale", "createdAt": "2020-10-02T09:06:00Z", "url": "https://github.com/elastic/stack-docs/pull/1394", "merged": true, "mergeCommit": {"oid": "0b9ad857921a58255f6f483a9434ae2442027816"}, "closed": true, "closedAt": "2020-10-05T07:57:04Z", "author": {"login": "szabosteve"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdOiMHjgH2gAyNDk2NzgxNDI2OjY3Zjc2ZmY3YzMzNGIyYmI5Zjg0YjBmYjFjZTMzYmExNWRhNDIwZmM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdPe1Z5gH2gAyNDk2NzgxNDI2OmYxZWJkZjc1YmFjOWU1ZWQ3NjAzNDk5Y2QzMjc0MTQyZWY0ZDFlZDM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc", "committedDate": "2020-10-02T09:02:11Z", "message": "[DOCS] Adds data frame analytics at scale page to the ML DFA docs."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDcxNzkz", "url": "https://github.com/elastic/stack-docs/pull/1394#pullrequestreview-501471793", "createdAt": "2020-10-02T22:05:16Z", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjowNToxN1rOHb8w9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjowNToxN1rOHb8w9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA2OTE3NA==", "bodyText": "Should this be a section title or bolded? It's merging with the subsequent phrase in the output.", "url": "https://github.com/elastic/stack-docs/pull/1394#discussion_r499069174", "createdAt": "2020-10-02T22:05:17Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc", "diffHunk": "@@ -0,0 +1,153 @@\n+[role=\"xpack\"]\n+[[ml-dfa-scale]]\n+= Working with {dfanalytics} at scale\n+\n+A {dfanalytics-job} has numerous configuration options. Some of them may have a \n+significant effect on the time taken to train a model. The training time depends \n+on various factors, like the statistical characteristics of your data, the \n+number of provided hyperparameters, the number of features included in the \n+analysis, the hardware you use, and so on. This guide contains a list of \n+considerations to help you plan for training {dfanalytics} models at scale and \n+optimizing training time.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the time taken to train \n+  models for {dfanalytics-jobs}.\n+\n+\n+Prerequisites:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDc0MDY3", "url": "https://github.com/elastic/stack-docs/pull/1394#pullrequestreview-501474067", "createdAt": "2020-10-02T22:12:05Z", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMjowNVrOHb84KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMjowNVrOHb84KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MTAxNw==", "bodyText": "Though I like politeness IRL we tend to omit it from docs :)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To learn more about the individual phases, please refer to <<ml-dfa-phases>>.\n          \n          \n            \n            To learn more about the individual phases, refer to <<ml-dfa-phases>>.", "url": "https://github.com/elastic/stack-docs/pull/1394#discussion_r499071017", "createdAt": "2020-10-02T22:12:05Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc", "diffHunk": "@@ -0,0 +1,153 @@\n+[role=\"xpack\"]\n+[[ml-dfa-scale]]\n+= Working with {dfanalytics} at scale\n+\n+A {dfanalytics-job} has numerous configuration options. Some of them may have a \n+significant effect on the time taken to train a model. The training time depends \n+on various factors, like the statistical characteristics of your data, the \n+number of provided hyperparameters, the number of features included in the \n+analysis, the hardware you use, and so on. This guide contains a list of \n+considerations to help you plan for training {dfanalytics} models at scale and \n+optimizing training time.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the time taken to train \n+  models for {dfanalytics-jobs}.\n+\n+\n+Prerequisites:\n+This guide assumes you\u2019re already familiar with: \n+\n+* How to create data frame analytics jobs. If not, refer to <<ml-dfa-overview>>.\n+\n+* How data frame analytics jobs work. If not, refer to <<ml-dfa-phases>>.\n+\n+It is important to note that there is a correlation between the training time, \n+the complexity of the model, the size of the data, and the quality of the \n+analysis results. Improvements in quality, however, are not linear with the \n+amount of training data; for very large source data, it might take hours to \n+train a model for very small gains in quality. When you work at scale with \n+{dfanalytics}, you need to decide what quality of results is acceptable for your \n+use case. When you have determined your acceptance criteria, you have a better \n+picture of the factors you can trade off while still achieving your goal.\n+\n+\n+The following recommendations are not sequential \u2013 the numbers just help to \n+navigate between the list items; you can take action on one or more of them in \n+any order.\n+\n+\n+[discrete]\n+[[rapid-iteration]]\n+== 0. Start small and iterate rapidly\n+\n+Training is an iterative process. Experiment with different settings and \n+configuration options (including but not limited to hyperparameters and feature \n+importance), then evaluate the results and decide whether they are good enough \n+or need further experimentation.\n+\n+Every iteration takes time, so it is useful to start with a small set of data so \n+you can iterate rapidly and then build up from here.\n+\n+\n+[discrete]\n+[[small-training-percent]]\n+== 1. Set a small training percent\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+The number of documents used for training a model has an effect on the training \n+time. A higher training percent means a longer training time.\n+\n+Consider starting with a small percentage of training data so you can complete \n+iterations more quickly. Once you are happy with your configuration, increase \n+the training percent.  As a rule of thumb, if you have a data set with more than \n+100,000 data points, start with a training percent of 5 or 10.\n+\n+\n+[discrete]\n+[[disable-feature-importance]]\n+== 2. Disable {feat-imp} calculation\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+<<ml-feature-importance>> indicates which fields had the biggest impact on each \n+prediction that is generated by the analysis. Depending on the size of the data \n+set, {feat-imp} can take a long time to compute.\n+\n+For a shorter runtime, consider disabling {feat-imp} for some or all iterations \n+if you do not require it.\n+\n+\n+[discrete]\n+[[optimize-included-fields]]\n+== 3. Optimize the number of included fields \n+\n+You can speed up runtime by only analyzing relevant fields.\n+\n+By default, all the fields that are supported by the analysis type are included \n+in the analysis. In general, more fields analyzed requires more resources and \n+longer training times, including the time taken for automatic feature selection. \n+To reduce training time, consider limiting the scope of the analysis to the \n+relevant fields that contribute to the prediction. You may do this by either \n+excluding non-relevant fields or by including relevant ones.\n+\n+NOTE: {feat-imp-cap} can help you determine the fields that contribute most to \n+the prediction. However, as calculating {feat-imp} increases training time, this \n+is a trade-off that can be evaluated during an iterative training process. \n+\n+\n+[discrete]\n+[[increase-threads]]\n+== 4. Increase the maximum number of threads\n+\n+You can set the maximum number of threads that are used during the analysis. The \n+default value of `max_num_threads` is 1. Depending on the characteristics of the \n+data, using more threads may decrease the training time at the cost of increased \n+CPU usage. Note that trying to use more threads than the number of CPU cores has \n+no advantage.\n+\n+Hyperparameter optimization and calculating {feat-imp} gain the most benefit \n+from the increased number of threads. This can be seen in phases \n+`coarse_parameter_search`, `fine_tuning_parameters`, and `writing_results`. The \n+rest of the phases are not affected by the increased number of threads.\n+\n+To learn more about the individual phases, please refer to <<ml-dfa-phases>>.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "originalPosition": 116}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDc0NDk2", "url": "https://github.com/elastic/stack-docs/pull/1394#pullrequestreview-501474496", "createdAt": "2020-10-02T22:13:25Z", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMzoyNVrOHb85sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMzoyNVrOHb85sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MTQxMQ==", "bodyText": "Not a big deal, but you can likely simplify as follows:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            NOTE: If your {ml} nodes are running concurrent jobs (either {anomaly-detect} or \n          \n          \n            \n            NOTE: If your {ml} nodes are running concurrent {anomaly-detect} or", "url": "https://github.com/elastic/stack-docs/pull/1394#discussion_r499071411", "createdAt": "2020-10-02T22:13:25Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc", "diffHunk": "@@ -0,0 +1,153 @@\n+[role=\"xpack\"]\n+[[ml-dfa-scale]]\n+= Working with {dfanalytics} at scale\n+\n+A {dfanalytics-job} has numerous configuration options. Some of them may have a \n+significant effect on the time taken to train a model. The training time depends \n+on various factors, like the statistical characteristics of your data, the \n+number of provided hyperparameters, the number of features included in the \n+analysis, the hardware you use, and so on. This guide contains a list of \n+considerations to help you plan for training {dfanalytics} models at scale and \n+optimizing training time.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the time taken to train \n+  models for {dfanalytics-jobs}.\n+\n+\n+Prerequisites:\n+This guide assumes you\u2019re already familiar with: \n+\n+* How to create data frame analytics jobs. If not, refer to <<ml-dfa-overview>>.\n+\n+* How data frame analytics jobs work. If not, refer to <<ml-dfa-phases>>.\n+\n+It is important to note that there is a correlation between the training time, \n+the complexity of the model, the size of the data, and the quality of the \n+analysis results. Improvements in quality, however, are not linear with the \n+amount of training data; for very large source data, it might take hours to \n+train a model for very small gains in quality. When you work at scale with \n+{dfanalytics}, you need to decide what quality of results is acceptable for your \n+use case. When you have determined your acceptance criteria, you have a better \n+picture of the factors you can trade off while still achieving your goal.\n+\n+\n+The following recommendations are not sequential \u2013 the numbers just help to \n+navigate between the list items; you can take action on one or more of them in \n+any order.\n+\n+\n+[discrete]\n+[[rapid-iteration]]\n+== 0. Start small and iterate rapidly\n+\n+Training is an iterative process. Experiment with different settings and \n+configuration options (including but not limited to hyperparameters and feature \n+importance), then evaluate the results and decide whether they are good enough \n+or need further experimentation.\n+\n+Every iteration takes time, so it is useful to start with a small set of data so \n+you can iterate rapidly and then build up from here.\n+\n+\n+[discrete]\n+[[small-training-percent]]\n+== 1. Set a small training percent\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+The number of documents used for training a model has an effect on the training \n+time. A higher training percent means a longer training time.\n+\n+Consider starting with a small percentage of training data so you can complete \n+iterations more quickly. Once you are happy with your configuration, increase \n+the training percent.  As a rule of thumb, if you have a data set with more than \n+100,000 data points, start with a training percent of 5 or 10.\n+\n+\n+[discrete]\n+[[disable-feature-importance]]\n+== 2. Disable {feat-imp} calculation\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+<<ml-feature-importance>> indicates which fields had the biggest impact on each \n+prediction that is generated by the analysis. Depending on the size of the data \n+set, {feat-imp} can take a long time to compute.\n+\n+For a shorter runtime, consider disabling {feat-imp} for some or all iterations \n+if you do not require it.\n+\n+\n+[discrete]\n+[[optimize-included-fields]]\n+== 3. Optimize the number of included fields \n+\n+You can speed up runtime by only analyzing relevant fields.\n+\n+By default, all the fields that are supported by the analysis type are included \n+in the analysis. In general, more fields analyzed requires more resources and \n+longer training times, including the time taken for automatic feature selection. \n+To reduce training time, consider limiting the scope of the analysis to the \n+relevant fields that contribute to the prediction. You may do this by either \n+excluding non-relevant fields or by including relevant ones.\n+\n+NOTE: {feat-imp-cap} can help you determine the fields that contribute most to \n+the prediction. However, as calculating {feat-imp} increases training time, this \n+is a trade-off that can be evaluated during an iterative training process. \n+\n+\n+[discrete]\n+[[increase-threads]]\n+== 4. Increase the maximum number of threads\n+\n+You can set the maximum number of threads that are used during the analysis. The \n+default value of `max_num_threads` is 1. Depending on the characteristics of the \n+data, using more threads may decrease the training time at the cost of increased \n+CPU usage. Note that trying to use more threads than the number of CPU cores has \n+no advantage.\n+\n+Hyperparameter optimization and calculating {feat-imp} gain the most benefit \n+from the increased number of threads. This can be seen in phases \n+`coarse_parameter_search`, `fine_tuning_parameters`, and `writing_results`. The \n+rest of the phases are not affected by the increased number of threads.\n+\n+To learn more about the individual phases, please refer to <<ml-dfa-phases>>.\n+\n+NOTE: If your {ml} nodes are running concurrent jobs (either {anomaly-detect} or ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "originalPosition": 118}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDc0NjE1", "url": "https://github.com/elastic/stack-docs/pull/1394#pullrequestreview-501474615", "createdAt": "2020-10-02T22:13:50Z", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMzo1MFrOHb86DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMjoxMzo1MFrOHb86DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MTUwMQ==", "bodyText": "Continued:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {dfanalytics}), then you may want to keep the maximum number of threads set to a \n          \n          \n            \n            {dfanalytics-jobs}, you may want to keep the maximum number of threads set to a", "url": "https://github.com/elastic/stack-docs/pull/1394#discussion_r499071501", "createdAt": "2020-10-02T22:13:50Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-dfa-scale.asciidoc", "diffHunk": "@@ -0,0 +1,153 @@\n+[role=\"xpack\"]\n+[[ml-dfa-scale]]\n+= Working with {dfanalytics} at scale\n+\n+A {dfanalytics-job} has numerous configuration options. Some of them may have a \n+significant effect on the time taken to train a model. The training time depends \n+on various factors, like the statistical characteristics of your data, the \n+number of provided hyperparameters, the number of features included in the \n+analysis, the hardware you use, and so on. This guide contains a list of \n+considerations to help you plan for training {dfanalytics} models at scale and \n+optimizing training time.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the time taken to train \n+  models for {dfanalytics-jobs}.\n+\n+\n+Prerequisites:\n+This guide assumes you\u2019re already familiar with: \n+\n+* How to create data frame analytics jobs. If not, refer to <<ml-dfa-overview>>.\n+\n+* How data frame analytics jobs work. If not, refer to <<ml-dfa-phases>>.\n+\n+It is important to note that there is a correlation between the training time, \n+the complexity of the model, the size of the data, and the quality of the \n+analysis results. Improvements in quality, however, are not linear with the \n+amount of training data; for very large source data, it might take hours to \n+train a model for very small gains in quality. When you work at scale with \n+{dfanalytics}, you need to decide what quality of results is acceptable for your \n+use case. When you have determined your acceptance criteria, you have a better \n+picture of the factors you can trade off while still achieving your goal.\n+\n+\n+The following recommendations are not sequential \u2013 the numbers just help to \n+navigate between the list items; you can take action on one or more of them in \n+any order.\n+\n+\n+[discrete]\n+[[rapid-iteration]]\n+== 0. Start small and iterate rapidly\n+\n+Training is an iterative process. Experiment with different settings and \n+configuration options (including but not limited to hyperparameters and feature \n+importance), then evaluate the results and decide whether they are good enough \n+or need further experimentation.\n+\n+Every iteration takes time, so it is useful to start with a small set of data so \n+you can iterate rapidly and then build up from here.\n+\n+\n+[discrete]\n+[[small-training-percent]]\n+== 1. Set a small training percent\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+The number of documents used for training a model has an effect on the training \n+time. A higher training percent means a longer training time.\n+\n+Consider starting with a small percentage of training data so you can complete \n+iterations more quickly. Once you are happy with your configuration, increase \n+the training percent.  As a rule of thumb, if you have a data set with more than \n+100,000 data points, start with a training percent of 5 or 10.\n+\n+\n+[discrete]\n+[[disable-feature-importance]]\n+== 2. Disable {feat-imp} calculation\n+\n+(This step only applies to {regression} and {classification} jobs.)\n+\n+<<ml-feature-importance>> indicates which fields had the biggest impact on each \n+prediction that is generated by the analysis. Depending on the size of the data \n+set, {feat-imp} can take a long time to compute.\n+\n+For a shorter runtime, consider disabling {feat-imp} for some or all iterations \n+if you do not require it.\n+\n+\n+[discrete]\n+[[optimize-included-fields]]\n+== 3. Optimize the number of included fields \n+\n+You can speed up runtime by only analyzing relevant fields.\n+\n+By default, all the fields that are supported by the analysis type are included \n+in the analysis. In general, more fields analyzed requires more resources and \n+longer training times, including the time taken for automatic feature selection. \n+To reduce training time, consider limiting the scope of the analysis to the \n+relevant fields that contribute to the prediction. You may do this by either \n+excluding non-relevant fields or by including relevant ones.\n+\n+NOTE: {feat-imp-cap} can help you determine the fields that contribute most to \n+the prediction. However, as calculating {feat-imp} increases training time, this \n+is a trade-off that can be evaluated during an iterative training process. \n+\n+\n+[discrete]\n+[[increase-threads]]\n+== 4. Increase the maximum number of threads\n+\n+You can set the maximum number of threads that are used during the analysis. The \n+default value of `max_num_threads` is 1. Depending on the characteristics of the \n+data, using more threads may decrease the training time at the cost of increased \n+CPU usage. Note that trying to use more threads than the number of CPU cores has \n+no advantage.\n+\n+Hyperparameter optimization and calculating {feat-imp} gain the most benefit \n+from the increased number of threads. This can be seen in phases \n+`coarse_parameter_search`, `fine_tuning_parameters`, and `writing_results`. The \n+rest of the phases are not affected by the increased number of threads.\n+\n+To learn more about the individual phases, please refer to <<ml-dfa-phases>>.\n+\n+NOTE: If your {ml} nodes are running concurrent jobs (either {anomaly-detect} or \n+{dfanalytics}), then you may want to keep the maximum number of threads set to a ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAxNDc1MDI4", "url": "https://github.com/elastic/stack-docs/pull/1394#pullrequestreview-501475028", "createdAt": "2020-10-02T22:15:17Z", "commit": {"oid": "67f76ff7c334b2bb9f84b0fb1ce33ba15da420fc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1ebdf75bac9e5ed7603499cd3274142ef4d1ed3", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/f1ebdf75bac9e5ed7603499cd3274142ef4d1ed3", "committedDate": "2020-10-05T07:41:35Z", "message": "[DOCS] Addresses feedback."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4655, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}