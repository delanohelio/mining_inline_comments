{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU3MTIyMzgy", "number": 1306, "title": "[DOCS] Adds supervised ML workflow description to DFA overview", "bodyText": "Overview\nThis PR adds a new page to the DFA documentation about the supervised machine learning workflow under Overview.\nPreview\nDFA overview\nSupervised machine learning workflow", "createdAt": "2020-07-27T12:11:17Z", "url": "https://github.com/elastic/stack-docs/pull/1306", "merged": true, "mergeCommit": {"oid": "965fcd97b9a760f5cf4e002e8024a0aa34072823"}, "closed": true, "closedAt": "2020-08-06T08:33:05Z", "author": {"login": "szabosteve"}, "timelineItems": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5Ap9oAH2gAyNDU3MTIyMzgyOjhhMjM5ZTA2MDAzOTVhNDJiMGRlOGZiMzNhOGU3ODhhOGExZGMwYzg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8LJAiAH2gAyNDU3MTIyMzgyOmRjMzIzNWI2ZmI0YzIwMzc3NTM3MGFhMDk5NDlhMzAzNmJmYTE2ZjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "8a239e0600395a42b0de8fb33a8e788a8a1dc0c8", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/8a239e0600395a42b0de8fb33a8e788a8a1dc0c8", "committedDate": "2020-07-27T12:05:36Z", "message": "[DOCS] Adds supervised ML workflow description to DFA overview."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd0672393762864271fc83e9238b62dc560b8417", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/bd0672393762864271fc83e9238b62dc560b8417", "committedDate": "2020-07-27T12:52:32Z", "message": "[DOCS] Adds better examples to regression and classification."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/464be52559693925bd1d16780c3f5116f5e46f8b", "committedDate": "2020-07-29T09:11:49Z", "message": "[DOCS] Adds next steps section."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDI1MjMw", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457425230", "createdAt": "2020-07-29T11:18:59Z", "commit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxODo1OVrOG4z7GQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxODo1OVrOG4z7GQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIyNDE1Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Consult the documentation to learn more about <<dfa-regression>> and \n          \n          \n            \n            * Consult the documentation to learn more about <<dfa-regression,regression>> and", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462224153", "createdAt": "2020-07-29T11:18:59Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+[DIAGRAM]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. \n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+Trained models are stored as {es} documents in an internal index. The Elastic \n+{ml} feature called {infer} enables you to use the model in a continuous fashion \n+either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression>> and ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "originalPosition": 143}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDI1NDE3", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457425417", "createdAt": "2020-07-29T11:19:18Z", "commit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxOToxOVrOG4z7rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxOToxOVrOG4z7rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIyNDMwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <<dfa-classification>>.\n          \n          \n            \n              <<dfa-classification,classification>>.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462224302", "createdAt": "2020-07-29T11:19:19Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+[DIAGRAM]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. \n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+Trained models are stored as {es} documents in an internal index. The Elastic \n+{ml} feature called {infer} enables you to use the model in a continuous fashion \n+either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression>> and \n+  <<dfa-classification>>.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "originalPosition": 144}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDI1NzUy", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457425752", "createdAt": "2020-07-29T11:19:51Z", "commit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxOTo1MVrOG4z80A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToxOTo1MVrOG4z80A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIyNDU5Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Learn how to evaluate <<ml-dfanalytics-classification,classification>> and \n          \n          \n            \n            * Learn how to evaluate <<ml-dfanalytics-regression-evaluation,regression>> and", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462224592", "createdAt": "2020-07-29T11:19:51Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+[DIAGRAM]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. \n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+Trained models are stored as {es} documents in an internal index. The Elastic \n+{ml} feature called {infer} enables you to use the model in a continuous fashion \n+either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression>> and \n+  <<dfa-classification>>.\n+* Learn how to evaluate <<ml-dfanalytics-classification,classification>> and ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "originalPosition": 145}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDI1OTM5", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457425939", "createdAt": "2020-07-29T11:20:06Z", "commit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToyMDowNlrOG4z9Zg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMToyMDowNlrOG4z9Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIyNDc0Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <<ml-dfanalytics-regression-evaluation,regression>> models.\n          \n          \n            \n              <<ml-dfanalytics-classification,classification>> models.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462224742", "createdAt": "2020-07-29T11:20:06Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+[DIAGRAM]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. \n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+Trained models are stored as {es} documents in an internal index. The Elastic \n+{ml} feature called {infer} enables you to use the model in a continuous fashion \n+either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression>> and \n+  <<dfa-classification>>.\n+* Learn how to evaluate <<ml-dfanalytics-classification,classification>> and \n+  <<ml-dfanalytics-regression-evaluation,regression>> models.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "464be52559693925bd1d16780c3f5116f5e46f8b"}, "originalPosition": 146}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a07afe5bbd02988694cbfce1c3e9517d77c65b37", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/a07afe5bbd02988694cbfce1c3e9517d77c65b37", "committedDate": "2020-07-29T11:20:15Z", "message": "Apply suggestions from code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDMzMTc3", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457433177", "createdAt": "2020-07-29T11:31:45Z", "commit": {"oid": "a07afe5bbd02988694cbfce1c3e9517d77c65b37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMTozMTo0NVrOG40UOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMTozMTo0NVrOG40UOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIzMDU4NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            [DIAGRAM]\n          \n          \n            \n            include::ml/lifecycle.adoc[lines=15..26]```", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462230585", "createdAt": "2020-07-29T11:31:45Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+[DIAGRAM]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a07afe5bbd02988694cbfce1c3e9517d77c65b37"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2752c64301fcf0bc4690e73779ea34f590e5351", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/d2752c64301fcf0bc4690e73779ea34f590e5351", "committedDate": "2020-07-29T11:31:54Z", "message": "Update docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NDMzNDQ5", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-457433449", "createdAt": "2020-07-29T11:32:11Z", "commit": {"oid": "d2752c64301fcf0bc4690e73779ea34f590e5351"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMTozMjoxMVrOG40VKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxMTozMjoxMVrOG40VKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIzMDgyNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            include::ml/lifecycle.adoc[lines=15..26]```\n          \n          \n            \n            include::ml/lifecycle.adoc[lines=15..26]", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r462230827", "createdAt": "2020-07-29T11:32:11Z", "author": {"login": "szabosteve"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,147 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Supervised {ml} workflow\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+* Define the problem\n+* Prepare and transform data\n+* Train and test the model\n+* Deploy the model\n+\n+include::ml/lifecycle.adoc[lines=15..26]```", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2752c64301fcf0bc4690e73779ea34f590e5351"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3c0af76d36649ce4a7064f25405440cc8ae8bd1", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/a3c0af76d36649ce4a7064f25405440cc8ae8bd1", "committedDate": "2020-07-29T11:32:15Z", "message": "Update docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab8218d43d998d1e8241010eee5ea1ff80904ada", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/ab8218d43d998d1e8241010eee5ea1ff80904ada", "committedDate": "2020-07-29T12:08:14Z", "message": "[DOCS] Adds lifecycle diagram adoc."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f67346de016b7ea4f1643cfe681bd6796d8284a3", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/f67346de016b7ea4f1643cfe681bd6796d8284a3", "committedDate": "2020-07-29T12:10:01Z", "message": "[DOCS] Removes incorrect reference."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3ba0e3f8c2ebcbbe01cbaa0b0336889242cfb21", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/e3ba0e3f8c2ebcbbe01cbaa0b0336889242cfb21", "committedDate": "2020-07-29T16:38:57Z", "message": "[DOCS] Further changes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/f9b55997d1442cdf0c1b7697797c8c03a6ccb334", "committedDate": "2020-07-31T08:25:25Z", "message": "[DOCS] Adds diagram to the text."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5MTE5NzAx", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-459119701", "createdAt": "2020-07-31T11:59:16Z", "commit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxMTo1OToxNlrOG6F_dA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxMjoyNzozMVrOG6Gt-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU2ODc1Ng==", "bodyText": "Perhaps more succinct to say\nThis page describes the end-to-end workflow to clarify how you can  train a model, evaluate it and deploy it. It gives a high-level overview of the steps  required to identify and implement a solution using supervised learning.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463568756", "createdAt": "2020-07-31T11:59:16Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU2OTU3NA==", "bodyText": "suggest remove or examples", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463569574", "createdAt": "2020-07-31T12:01:16Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU2OTk4Nw==", "bodyText": "this para feels a bit untidy.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463569987", "createdAt": "2020-07-31T12:02:13Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3MDM1MQ==", "bodyText": "suggest remove or you are not collecting all of the necessary information", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463570351", "createdAt": "2020-07-31T12:03:14Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3MTM5Ng==", "bodyText": "suggest remove as it consists of the observed examples on which you can train the model.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463571396", "createdAt": "2020-07-31T12:05:43Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3MjI3MA==", "bodyText": "typo? Doing so makes a large dataset more manageable, reducing the computing resources  and time required for training.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463572270", "createdAt": "2020-07-31T12:07:56Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3NjU4Mw==", "bodyText": "Suggest\nNow define how to split your data into a training set and a test set. The test set won\u2019t be used to train the model, but is used to evaluate how the model performs. There is no optimal percentage that fits all use cases, it depends on the amount of data and the time you have to train.\nPotentially include something to say for large data sets (e.g. >100k docs) then you may wish to start with a very low training percent - just to complete an end to end iteration in a short time.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463576583", "createdAt": "2020-07-31T12:18:29Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3ODE1Ng==", "bodyText": "Do we need a link to Evaluation here?\nI think we should close off this section with another mention that depending on the result of the evaluation, you may wish to iterate.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463578156", "createdAt": "2020-07-31T12:21:45Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU3OTg5Mg==", "bodyText": "It seems out of place to mention an implementation detail such as Trained models are stored as {es} documents in an internal index.\nPhase enables you to use the model in a continuous fashion doesn't feel quite right. Inference enables you to make predictions for new data. This could be done thru ingest, continuous transforms or an agg.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463579892", "createdAt": "2020-07-31T12:25:52Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can \n+train a model and deploy it to answer the right questions and solve your \n+problem. It gives a high-level overview of the steps required to identify and \n+implement a solution to a problem using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. What business problems do you want to solve by analyzing this data? The \n+better you know the data, the quicker you will be able to create {ml} models \n+that generate useful insights. It is crucial to think through the problem and \n+set clear objectives. Find the answer to questions like these: What kinds of \n+patterns do you want to discover in your data? What type of value do you want to \n+predict: a category, or a numerical value? The answers help you choose the type \n+of analysis that fits your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values or \n+examples that the model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es} or \n+you are not collecting all of the necessary information, this is the stage where \n+you develop your data pipeline. If you want to learn more about how to ingest \n+data into {es}, refer to the {ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must \n+supply a labelled data set for training. This is often called the \"ground truth\" \n+as it consists of the observed examples on which you can train the model. The \n+\"ground truth\" allows the training process to identify relationships among the \n+various characteristics of the data and the predicted value as well as takes a \n+critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable and by reducing the computing resources \n+and time required for training.\n+\n+Now define how to split your training data, using what's called the train-test \n+split. There is no optimal percentage that fits for all use cases, it depends on \n+the amount of data and the time you have to train. The test set won\u2019t be used to \n+train the model, but only for testing during the learning process.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on  how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further evaluation types for both \n+{classification} and {regression} analysis which provide metrics about training \n+performance. \n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+Trained models are stored as {es} documents in an internal index. The Elastic \n+{ml} feature called {infer} enables you to use the model in a continuous fashion \n+either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU4MDY2Ng==", "bodyText": "suggest You can then use your model to make predictions on new data.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r463580666", "createdAt": "2020-07-31T12:27:31Z", "author": {"login": "sophiec20"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,142 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+unseen data. This page describes the end-to-end workflow to clarify how you can ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9b55997d1442cdf0c1b7697797c8c03a6ccb334"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26e730ef82e066fdee24b415bb5f1987fba2926e", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/26e730ef82e066fdee24b415bb5f1987fba2926e", "committedDate": "2020-07-31T14:38:49Z", "message": "[DOCS] Addresses review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/acc2c6b793b0be405db363f577e64d96d91fa441", "committedDate": "2020-07-31T14:39:56Z", "message": "[DOCS] Fine-tunes wording."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMDAzNDE4", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-460003418", "createdAt": "2020-08-03T12:57:32Z", "commit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxMjo1NzozM1rOG64dvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxMjo1OTo1M1rOG64igA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM5NTcwOA==", "bodyText": "When we talk about \"classification and regression\", we sometimes switch the order. We might want to review copy to keep a consistent order when we use the two words together. Or not \ud83d\ude06", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r464395708", "createdAt": "2020-08-03T12:57:33Z", "author": {"login": "joshdevins"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM5NTg3Nw==", "bodyText": "See above comment about word order.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r464395877", "createdAt": "2020-08-03T12:57:51Z", "author": {"login": "joshdevins"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM5NjMxNA==", "bodyText": "\"every round of iteration is...\" should read \"every iteration is...\"", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r464396314", "createdAt": "2020-08-03T12:58:43Z", "author": {"login": "joshdevins"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM5NjkyOA==", "bodyText": "\"training set and test set\" should maybe rather be just \"training and test set\"", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r464396928", "createdAt": "2020-08-03T12:59:53Z", "author": {"login": "joshdevins"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{classification-cap} and {regression} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every round of iteration is \n+followed by an evaluation to see how the model performs. When you are satisfied \n+with the results, you are ready to deploy the model otherwise you may want to \n+adjust the training configuration or consider alternative ways to preprocess and \n+represent your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in classification and regression automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training set and a test set. The test ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc2c6b793b0be405db363f577e64d96d91fa441"}, "originalPosition": 97}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/1c30df500343227726f05f8919e447aab08f6bfb", "committedDate": "2020-08-03T15:09:14Z", "message": "[DOCS] Addresses feedback."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxOTgyMjQ0", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-461982244", "createdAt": "2020-08-05T20:02:18Z", "commit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMDowMjoxOFrOG8YneQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMDowMjoxOFrOG8YneQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3MTA2NQ==", "bodyText": "Very minor issue, but the first arrow looks different than the others, so I suggest making it the same:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |           |-->+           +-->+           +-->|           |\n          \n          \n            \n            |           +-->+           +-->+           +-->|           |", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465971065", "createdAt": "2020-08-05T20:02:18Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/supervised-lifecycle.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+[ditaa, target=\"ml-dfa-lifecycle-diagram\"]\n+....\n+                            \n++-----------+   +-----------+   +-----------+   +-----------+\n+|           |-->+           +-->+           +-->|           |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxOTgzOTQx", "url": "https://github.com/elastic/stack-docs/pull/1306#pullrequestreview-461983941", "createdAt": "2020-08-05T20:04:52Z", "commit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "state": "APPROVED", "comments": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMDowNDo1M1rOG8Ys-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMDo1OTozNFrOG8aZxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3MjQ3NA==", "bodyText": "I always prefer \"enable\" to \"allow\" since the former implies a sense of empowerment, whereas the latter makes me think of security/authority or permission to do something.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Elastic supervised learning allows you to train a {ml} model based on training \n          \n          \n            \n            Elastic supervised learning enables you to train a {ml} model based on training", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465972474", "createdAt": "2020-08-05T20:04:53Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3Mzk3NA==", "bodyText": "Not a mandatory change, but I think it's helpful to note this is a summary, not a walk-through/tutorial:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            new data. This page describes the end-to-end workflow to clarify how you can \n          \n          \n            \n            new data. This page summarizes the end-to-end workflow for", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465973974", "createdAt": "2020-08-05T20:07:53Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3NDg5Mw==", "bodyText": "Rewording to avoid a succession of \"it\":\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            train a model, evaluate it and deploy it. It gives a high-level overview of the \n          \n          \n            \n            training, evaluating and deploying a model. It gives a high-level overview of the", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465974893", "createdAt": "2020-08-05T20:09:35Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3NzU0OA==", "bodyText": "Unsupervised learning... can be trained on.\n\nThis feels like a long sentence. Perhaps it can be split into two like this?:\n\nSupervised learning requires a data set that contains known values that the model can be trained on. Unsupervised learning -- like {anomaly-detect} or {oldetection} does not have this requirement.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465977548", "createdAt": "2020-08-05T20:14:51Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3OTA2MQ==", "bodyText": "I like to use the target page's title if possible, so readers have a hint of where the link will take them.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {ref}/ingest.html[documentation].\n          \n          \n            \n            {ref}/ingest.html[Ingest node documentation].", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465979061", "createdAt": "2020-08-05T20:17:40Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4MTQ0Ng==", "bodyText": "It feels a little awkward to repeat this term in close succession. Perhaps reword like this?:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \"ground truth\". The \"ground truth\" allows the training process to identify \n          \n          \n            \n            \"ground truth\". The training process uses this information to identify", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465981446", "createdAt": "2020-08-05T20:22:13Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4MTk0MA==", "bodyText": "If you accept my suggestion for the first part of this sentence, I recommend this change too:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            value as well as takes a critical role in model evaluation.\n          \n          \n            \n            value. It also plays a critical role in model evaluation.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465981940", "createdAt": "2020-08-05T20:23:10Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4MjgxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {regression-cap} and {classification} requires specifically structured source \n          \n          \n            \n            {regression-cap} and {classification} require specifically structured source", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465982817", "createdAt": "2020-08-05T20:24:51Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4MzYyNQ==", "bodyText": "Since the paragraph started with \"regression and classification\", I think they're redundant here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            can be used as the source for {dfanalytics} like {regression} and \n          \n          \n            \n            can be used as the source for these types of {dfanalytics}.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465983625", "createdAt": "2020-08-05T20:26:23Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4MzkyNQ==", "bodyText": "If you accept the suggestion for the first part of this sentence, you must also remove this part:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {classification}.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465983925", "createdAt": "2020-08-05T20:26:57Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4NDU2Ng==", "bodyText": "I like shorter, digestible sentences, so I'd suggest splitting this in two:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            results, you are ready to deploy the model otherwise you may want to adjust the \n          \n          \n            \n            results, you are ready to deploy the model. Otherwise, you may want to adjust the", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465984566", "createdAt": "2020-08-05T20:28:20Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4NTg2NQ==", "bodyText": "When you are satisfied with the results...\n\nThis sentence (or two, if you split it) feel like they belong at the end of this section instead of the beginning.  They seem to be about transitioning from training to deploying, so I think they'd make more sense at the end.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465985865", "createdAt": "2020-08-05T20:30:43Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4NjQxMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            However, you can exclude irrelevant fields optionally from the process. Doing so \n          \n          \n            \n            However, you can optionally exclude irrelevant fields from the process. Doing so", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465986412", "createdAt": "2020-08-05T20:31:50Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4NjYxOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            makes a large dataset more manageable, reducing the computing resources and time \n          \n          \n            \n            makes a large data set more manageable, reducing the computing resources and time", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465986619", "createdAt": "2020-08-05T20:32:16Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4NzgyMw==", "bodyText": "\"Now\" feels odd to me since they're not actually doing any of this \"now\". They're thinking about the order they need to do things in the future when they actually tackle this workflow. I suggest something like \"next\":\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now define how to split your data into a training and a test set. The test set \n          \n          \n            \n            Next you must define how to split your data into a training and a test set. The test set", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465987823", "createdAt": "2020-08-05T20:34:48Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4ODQ3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            won\u2019t be used to train the model, but is used to evaluate how the model \n          \n          \n            \n            won\u2019t be used to train the model; it is used to evaluate how the model", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465988474", "createdAt": "2020-08-05T20:36:08Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4OTE3Nw==", "bodyText": "I think this extra info is unnecessary:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            During the training process, the training data that contains the ground truth \n          \n          \n            \n            During the training process, the training data", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465989177", "createdAt": "2020-08-05T20:37:31Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk4OTQ3MA==", "bodyText": "Likewise, I think readers understand what training data is by this point:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            you want to learn from is fed through the learning algorithm. The model predicts \n          \n          \n            \n            is fed through the learning algorithm. The model predicts", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465989470", "createdAt": "2020-08-05T20:38:05Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5MDc4Mg==", "bodyText": "This switch to \"will be\" is unexpected. I'd suggest sticking with the present:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Once the model has been trained, it will be tested on how well it predicts for \n          \n          \n            \n            Once the model is trained, you can evaluate how well it predicts", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465990782", "createdAt": "2020-08-05T20:40:44Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on how well it predicts for ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5ODMwOA==", "bodyText": "I found \"an estimate of a quantity\" confusing, so if possible it would be simpler to just omit that:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            previously unseen data. This test provides an estimate of a quantity known as \n          \n          \n            \n            previously unseen data with", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r465998308", "createdAt": "2020-08-05T20:55:36Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMDA2NQ==", "bodyText": "I thought these were the same links as the previous sentence, since they have the same name. I suggest linking the \"evaluate\" term instead:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Learn how to evaluate <<ml-dfanalytics-regression-evaluation,regression>> and \n          \n          \n            \n            * Learn how to <<ml-dfanalytics-evaluate,evaluate>> regression and", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r466000065", "createdAt": "2020-08-05T20:59:03Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further \n+<<ml-dfanalytics-evaluate,evaluation types>> for both {regression} and \n+{classification} analysis which provide metrics about training performance. \n+Depending on the evaluation results, you may wish to iterate.\n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+The Elastic {ml} feature called {infer} enables you to make predictions for new \n+data either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression,regression>> \n+  and <<dfa-classification,classification>>.\n+* Learn how to evaluate <<ml-dfanalytics-regression-evaluation,regression>> and ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMDMyNQ==", "bodyText": "If you accept the suggestion on the first part of this sentence, please make this one too:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              <<ml-dfanalytics-classification,classification>> models.\n          \n          \n            \n            classification models.", "url": "https://github.com/elastic/stack-docs/pull/1306#discussion_r466000325", "createdAt": "2020-08-05T20:59:34Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/df-analytics/ml-supervised-workflow.asciidoc", "diffHunk": "@@ -0,0 +1,139 @@\n+[role=\"xpack\"]\n+[[ml-supervised-workflow]]\n+= Introduction to supervised learning\n+\n+Elastic supervised learning allows you to train a {ml} model based on training \n+examples that you provide. You can then use your model to make predictions on \n+new data. This page describes the end-to-end workflow to clarify how you can \n+train a model, evaluate it and deploy it. It gives a high-level overview of the \n+steps required to identify and implement a solution using supervised learning.\n+\n+The workflow for supervised learning consists of the following stages:\n+\n+image::images/ml-dfa-lifecycle-diagram.png[\"Supervised learning workflow\"]\n+\n+These are iterative stages, meaning that after evaluating each step, you might \n+need to make adjustments before you move further.\n+\n+\n+[[define-problem]]\n+== Define the problem\n+\n+It\u2019s important to take a moment and think about where {ml} can be most \n+impactful. Consider what type of data you have available and what value it \n+holds. The better you know the data, the quicker you will be able to create {ml} \n+models that generate useful insights. What kinds of patterns do you want to \n+discover in your data? What type of value do you want to predict: a category, or \n+a numerical value? The answers help you choose the type of analysis that fits \n+your use case.\n+\n+After you identify the problem, consider which of the {ml-features} are most \n+likely to help you solve it. Unsupervised learning \u2013 like {anomaly-detect} or \n+{oldetection} \u2013 does not require a labelled data set to train the model on while \n+supervised learning requires a data set that contains the known values that the \n+model can be trained on.\n+\n+{stack} provides the following types of supervised learning: \n+\n+* {regression}: predicts **continuous, numerical values** like the response time \n+  of a web request. \n+* {classification}: predicts **discrete, categorical values** like whether a \n+  https://www.elastic.co/blog/machine-learning-in-cybersecurity-training-supervised-models-to-detect-dga-activity[DNS request originates from a malicious or benign domain]. \n+\n+\n+[[prepare-transform-data]]\n+== Prepare and transform data\n+\n+You have defined the problem and selected an appropriate type of analysis. The \n+next step is to produce a high-quality data set in {es} with a clear \n+relationship to your training objectives. If your data is not already in {es}, \n+this is the stage where you develop your data pipeline. If you want to learn \n+more about how to ingest data into {es}, refer to the \n+{ref}/ingest.html[documentation].\n+\n+{regression-cap} and {classification} are supervised {ml} techniques, therefore \n+you must supply a labelled data set for training. This is often called the \n+\"ground truth\". The \"ground truth\" allows the training process to identify \n+relationships among the various characteristics of the data and the predicted \n+value as well as takes a critical role in model evaluation.\n+\n+An important requirement is a data set that is large enough to train a model. \n+For example, if you would like to train a {classification} model that decides \n+whether an email is a spam or not, you need a labelled data set that contains \n+enough data points from each possible category to train the model. What counts \n+as \"enough\" depends on various factors like the complexity of the problem or \n+the {ml} solution you have chosen. There is no exact number that fits every \n+use case; deciding how much data is acceptable is rather a heuristic process \n+that might involve iterative trials.\n+\n+Before you train the model, consider preprocessing the data. In practice, the \n+type of preprocessing depends on the nature of the data set. Preprocessing can \n+include, but is not limited to, mitigating redundancy, reducing biases, applying \n+standards and/or conventions, data normalization, and so on.\n+\n+{regression-cap} and {classification} requires specifically structured source \n+data: a two dimensional tabular data structure. For this reason, you might need \n+to {ref}/transforms.html[{transform}] your data to create a {dataframe} which \n+can be used as the source for {dfanalytics} like {regression} and \n+{classification}.\n+\n+[[train-test-iterate]]\n+== Train, test, iterate\n+\n+After your data is prepared and transformed into the right format, it is time to \n+train the model. Training is an iterative process \u2014 every iteration is followed \n+by an evaluation to see how the model performs. When you are satisfied with the \n+results, you are ready to deploy the model otherwise you may want to adjust the \n+training configuration or consider alternative ways to preprocess and represent \n+your data.\n+\n+The first step is defining the features \u2013 the relevant fields in the data set \u2013 \n+that will be used for training the model. By default, all the fields with \n+supported types are included in {regression} and {classification} automatically. \n+However, you can exclude irrelevant fields optionally from the process. Doing so \n+makes a large dataset more manageable, reducing the computing resources and time \n+required for training.\n+\n+Now define how to split your data into a training and a test set. The test set \n+won\u2019t be used to train the model, but is used to evaluate how the model \n+performs. There is no optimal percentage that fits all use cases, it depends on \n+the amount of data and the time you have to train. For large data sets, you may \n+want to start with a low training percent to complete an end-to-end iteration in \n+a short time.\n+\n+During the training process, the training data that contains the ground truth \n+you want to learn from is fed through the learning algorithm. The model predicts \n+the value and compares it to the ground truth then the model is fine-tuned to \n+make the predictions more accurate.\n+\n+Once the model has been trained, it will be tested on how well it predicts for \n+previously unseen data. This test provides an estimate of a quantity known as \n+the model generalization error. There are further \n+<<ml-dfanalytics-evaluate,evaluation types>> for both {regression} and \n+{classification} analysis which provide metrics about training performance. \n+Depending on the evaluation results, you may wish to iterate.\n+\n+\n+[[deploy-model]]\n+== Deploy model\n+\n+You have trained the model and are satisfied with the performance. The last step \n+is to deploy your trained model and start using it on new data.\n+\n+The Elastic {ml} feature called {infer} enables you to make predictions for new \n+data either by using it as a processor in an ingest pipeline, in a continuous \n+{transform} or as an aggregation at search time. When new data comes into your \n+ingest pipeline or you run a search on your data with an {infer} aggregation, \n+the model is used to infer against the data and make predictions on it.\n+\n+\n+[[next-steps]]\n+== Next steps\n+\n+* Read more about how to {ref}/transforms.html[transform you data] into an \n+  entity-centric index.\n+* Consult the documentation to learn more about <<dfa-regression,regression>> \n+  and <<dfa-classification,classification>>.\n+* Learn how to evaluate <<ml-dfanalytics-regression-evaluation,regression>> and \n+  <<ml-dfanalytics-classification,classification>> models.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c30df500343227726f05f8919e447aab08f6bfb"}, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0714d02e332209af8ffb1868364b518f4f6aa3e5", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/0714d02e332209af8ffb1868364b518f4f6aa3e5", "committedDate": "2020-08-06T07:31:19Z", "message": "Apply suggestions from code review\n\nCo-authored-by: Lisa Cawley <lcawley@elastic.co>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc3235b6fb4c203775370aa09949a3036bfa16f5", "author": {"user": {"login": "szabosteve", "name": "Istv\u00e1n Zolt\u00e1n Szab\u00f3"}}, "url": "https://github.com/elastic/stack-docs/commit/dc3235b6fb4c203775370aa09949a3036bfa16f5", "committedDate": "2020-08-06T08:00:20Z", "message": "[DOCS] Addresses feedback and adds fixed diagram."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4686, "cost": 1, "resetAt": "2021-11-01T14:20:25Z"}}}