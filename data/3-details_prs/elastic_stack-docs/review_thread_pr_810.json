{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzNDMzOTMx", "number": 810, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDo1NzoyOVrODZylJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDo1NzoyOVrODZylJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MzY5NzAzOnYy", "diffSide": "RIGHT", "path": "docs/en/stack/ml/anomaly-detection/datafeeds.asciidoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDo1NzoyOVrOFgYF6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxNjowOTo1NVrOFgh5sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ5MzQ4MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            //TBD: Comment on interplay between date_histogram aggregation's interval and the\n          \n          \n            \n            Such aggregations must include a `histogram` or `date_histogram` using the\n          \n          \n            \n            {anomaly-job}'s `time_field`, and the `fixed_interval`/`calendar_interval` of\n          \n          \n            \n            this must divide exactly into both the {anomaly-job}'s `bucket_span` and the\n          \n          \n            \n            {dfeed}'s `frequency`.", "url": "https://github.com/elastic/stack-docs/pull/810#discussion_r369493480", "createdAt": "2020-01-22T10:57:29Z", "author": {"login": "droberts195"}, "path": "docs/en/stack/ml/anomaly-detection/datafeeds.asciidoc", "diffHunk": "@@ -6,11 +6,21 @@\n sent from some other source via an API. _{dfeeds-cap}_ retrieve data from {es}\n for analysis, which is the simpler and more common scenario.\n \n-If you create {anomaly-jobs} in {kib}, you must use {dfeeds}. When you create a\n-job, you select an index pattern and {kib} configures the {dfeed} for you under\n-the covers. If you use APIs instead, you can create a {dfeed} by using the\n-create {dfeeds} API after you create an {anomaly-job}. You can associate only\n-one {dfeed} with each job. For a description of all the {dfeed} properties, see\n+You can associate only one {dfeed} with each {anomaly-job}. The {dfeed} contains\n+a query that runs at a defined interval (`frequency`). By default, this interval\n+is calculated relative to the <<ml-buckets,bucket span>> of the {anomaly-job}.\n+If you are concerned about delayed data, you can add a delay before the query\n+runs at each interval. See <<ml-delayed-data-detection>>.\n+\n+{dfeeds-cap} can also aggregate data before sending it to the {anomaly-job}.\n+There are some limitations, however, and aggregations should generally be used\n+only for low cardinality data. See <<ml-configuring-aggregation>>.\n+//TBD: Comment on interplay between date_histogram aggregation's interval and the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82747527f535d2fc86d27c0ed27fa9babae8e67a"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY1NDE5NA==", "bodyText": "I forgot I still had that TBD in there.  I thought perhaps I'd omit it since the detailed information is now in the aggregations example and in the API reference pages per elastic/elasticsearch#51280", "url": "https://github.com/elastic/stack-docs/pull/810#discussion_r369654194", "createdAt": "2020-01-22T16:09:55Z", "author": {"login": "lcawl"}, "path": "docs/en/stack/ml/anomaly-detection/datafeeds.asciidoc", "diffHunk": "@@ -6,11 +6,21 @@\n sent from some other source via an API. _{dfeeds-cap}_ retrieve data from {es}\n for analysis, which is the simpler and more common scenario.\n \n-If you create {anomaly-jobs} in {kib}, you must use {dfeeds}. When you create a\n-job, you select an index pattern and {kib} configures the {dfeed} for you under\n-the covers. If you use APIs instead, you can create a {dfeed} by using the\n-create {dfeeds} API after you create an {anomaly-job}. You can associate only\n-one {dfeed} with each job. For a description of all the {dfeed} properties, see\n+You can associate only one {dfeed} with each {anomaly-job}. The {dfeed} contains\n+a query that runs at a defined interval (`frequency`). By default, this interval\n+is calculated relative to the <<ml-buckets,bucket span>> of the {anomaly-job}.\n+If you are concerned about delayed data, you can add a delay before the query\n+runs at each interval. See <<ml-delayed-data-detection>>.\n+\n+{dfeeds-cap} can also aggregate data before sending it to the {anomaly-job}.\n+There are some limitations, however, and aggregations should generally be used\n+only for low cardinality data. See <<ml-configuring-aggregation>>.\n+//TBD: Comment on interplay between date_histogram aggregation's interval and the", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ5MzQ4MA=="}, "originalCommit": {"oid": "82747527f535d2fc86d27c0ed27fa9babae8e67a"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1293, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}