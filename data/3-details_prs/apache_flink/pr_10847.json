{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYyMzc3NTE0", "number": 10847, "title": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink", "bodyText": "What is the purpose of the change\nImplement JDBC sink with exactly-once semantics.\nExistingTwoPhaseCommitFunction is not currently used.\nVerifying this change\nThis change added tests and can be verified as follows:\n\nAdded end-to-end test for happy flow (derby db)\nAdded integration tests for varous failure scenarios (derby, h2)\nAdded unit tests\n\nDoes this pull request potentially affect one of the following parts:\n\nDependencies: add h2, flink-core, javax.transaction, change scope of flink-streaming-java for flink-connector-jdbc\nThe public API: yes\nThe serializers: yes (XID)\nThe runtime per-record code paths (performance sensitive): yes (for records going through the sink)\nAnything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: no\nThe S3 file system connector: no\n\nDocumentation\n\nDoes this pull request introduce a new feature? yes\nIf yes, how is the feature documented? docs, JavaDocs", "createdAt": "2020-01-13T23:49:10Z", "url": "https://github.com/apache/flink/pull/10847", "merged": true, "mergeCommit": {"oid": "ced428ca9645a497365bfe940f315263e88d07dc"}, "closed": true, "closedAt": "2021-01-19T12:54:15Z", "author": {"login": "rkhachatryan"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6L5s1gBqjI5NDU5NjY2NTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdxmg1jgBqjQyMjExNTY1MjI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1f19ab63df12c2a0cbc75644a34bcab26c08d7f6", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/1f19ab63df12c2a0cbc75644a34bcab26c08d7f6", "committedDate": "2020-01-13T23:43:32Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "3e136166db3c3a2325a4014719ca011b4d162a4d", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/3e136166db3c3a2325a4014719ca011b4d162a4d", "committedDate": "2020-01-14T07:33:05Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3e136166db3c3a2325a4014719ca011b4d162a4d", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/3e136166db3c3a2325a4014719ca011b4d162a4d", "committedDate": "2020-01-14T07:33:05Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "3c3f7e4329383accb9b940c950321e0c65bdc0b9", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/3c3f7e4329383accb9b940c950321e0c65bdc0b9", "committedDate": "2020-01-14T15:00:02Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3c3f7e4329383accb9b940c950321e0c65bdc0b9", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/3c3f7e4329383accb9b940c950321e0c65bdc0b9", "committedDate": "2020-01-14T15:00:02Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "committedDate": "2020-01-21T13:17:14Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "committedDate": "2020-01-21T13:17:14Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "21f8b53a2b914b3cfc5f2b284682e168522fedb7", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/21f8b53a2b914b3cfc5f2b284682e168522fedb7", "committedDate": "2020-01-23T14:44:30Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "21f8b53a2b914b3cfc5f2b284682e168522fedb7", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/21f8b53a2b914b3cfc5f2b284682e168522fedb7", "committedDate": "2020-01-23T14:44:30Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "2a7d5e55530eb275ffb276cead3516f3da9623a8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/2a7d5e55530eb275ffb276cead3516f3da9623a8", "committedDate": "2020-01-23T17:30:17Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2a7d5e55530eb275ffb276cead3516f3da9623a8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/2a7d5e55530eb275ffb276cead3516f3da9623a8", "committedDate": "2020-01-23T17:30:17Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "committedDate": "2020-01-24T14:49:14Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "committedDate": "2020-01-24T14:49:14Z", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "62eee77afbff0cdabceffeab6e737633af15a4fc", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/62eee77afbff0cdabceffeab6e737633af15a4fc", "committedDate": "2020-01-24T20:10:30Z", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "62eee77afbff0cdabceffeab6e737633af15a4fc", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/62eee77afbff0cdabceffeab6e737633af15a4fc", "committedDate": "2020-01-24T20:10:30Z", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "b2d552291f80b750912f037fc2a64698aa1dc34f", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b2d552291f80b750912f037fc2a64698aa1dc34f", "committedDate": "2020-01-29T13:44:26Z", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b2d552291f80b750912f037fc2a64698aa1dc34f", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b2d552291f80b750912f037fc2a64698aa1dc34f", "committedDate": "2020-01-29T13:44:26Z", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC"}, "afterCommit": {"oid": "63956a5e617a61fe592dc6c5bb62e615392f9535", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/63956a5e617a61fe592dc6c5bb62e615392f9535", "committedDate": "2020-01-29T17:12:56Z", "message": "[FLINK-15578][docs][connectors/jdbc] document exactly once JDBC sink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "63956a5e617a61fe592dc6c5bb62e615392f9535", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/63956a5e617a61fe592dc6c5bb62e615392f9535", "committedDate": "2020-01-29T17:12:56Z", "message": "[FLINK-15578][docs][connectors/jdbc] document exactly once JDBC sink"}, "afterCommit": {"oid": "b55a17559f8bbd427788152fdc5a2e79e273ad7a", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b55a17559f8bbd427788152fdc5a2e79e273ad7a", "committedDate": "2020-11-29T20:39:44Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b55a17559f8bbd427788152fdc5a2e79e273ad7a", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b55a17559f8bbd427788152fdc5a2e79e273ad7a", "committedDate": "2020-11-29T20:39:44Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "committedDate": "2020-11-29T21:20:11Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "committedDate": "2020-11-29T21:20:11Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "committedDate": "2020-11-30T06:40:27Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "committedDate": "2020-11-30T06:40:27Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "committedDate": "2020-11-30T06:41:57Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "committedDate": "2020-11-30T06:41:57Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "1a5d68a1e74c02bb85534ffdde081fcb03d70917", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/1a5d68a1e74c02bb85534ffdde081fcb03d70917", "committedDate": "2020-11-30T07:30:54Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MTI5Mjgw", "url": "https://github.com/apache/flink/pull/10847#pullrequestreview-546129280", "createdAt": "2020-12-07T13:06:12Z", "commit": {"oid": "1a5d68a1e74c02bb85534ffdde081fcb03d70917"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxMzowNjoxMlrOIAl4EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QxMzowNjozOVrOIAl5aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ5MTQ3Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since 1.13, Flink JDBC sink supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).\n          \n          \n            \n            Flink also comes with a JDBC sink that supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).", "url": "https://github.com/apache/flink/pull/10847#discussion_r537491472", "createdAt": "2020-12-07T13:06:12Z", "author": {"login": "aljoscha"}, "path": "docs/dev/connectors/jdbc.md", "diffHunk": "@@ -65,3 +62,42 @@ env.execute();\n {% endhighlight %}\n \n Please refer to the [API documentation]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/connector/jdbc/JdbcSink.html) for more details.\n+\n+## Exactly-once\n+\n+Since 1.13, Flink JDBC sink supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a5d68a1e74c02bb85534ffdde081fcb03d70917"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ5MTgxNg==", "bodyText": "What does \"Semantic\" mean in this class?", "url": "https://github.com/apache/flink/pull/10847#discussion_r537491816", "createdAt": "2020-12-07T13:06:39Z", "author": {"login": "aljoscha"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/SemanticXidGenerator.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.security.SecureRandom;\n+\n+/**\n+ * Generates {@link Xid} from:\n+ * <ol>\n+ *     <li>checkpoint id</li>\n+ *     <li>subtask index</li>\n+ *     <li>4 random bytes to provide uniqueness across other jobs and apps (generated at startup using {@link SecureRandom})</li>\n+ * </ol>\n+ * Each {@link SemanticXidGenerator} instance MUST be used for only one Sink (otherwise Xids could collide).\n+ */\n+@Internal\n+class SemanticXidGenerator implements XidGenerator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a5d68a1e74c02bb85534ffdde081fcb03d70917"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "47d975bde036c81ba5b9c8b2300ba352b6f7d6d1", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/47d975bde036c81ba5b9c8b2300ba352b6f7d6d1", "committedDate": "2020-12-07T14:40:09Z", "message": "Update docs/dev/connectors/jdbc.md\r\n\r\nAccepting Suggested change\n\nCo-authored-by: Aljoscha Krettek <aljoscha@apache.org>"}, "afterCommit": {"oid": "44c02d892bb4e1393ad45ce69e9624b58278ded4", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/44c02d892bb4e1393ad45ce69e9624b58278ded4", "committedDate": "2020-12-28T10:07:51Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "44c02d892bb4e1393ad45ce69e9624b58278ded4", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/44c02d892bb4e1393ad45ce69e9624b58278ded4", "committedDate": "2020-12-28T10:07:51Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "ed4de0e7b5f268c387e0c15d205842936596d943", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/ed4de0e7b5f268c387e0c15d205842936596d943", "committedDate": "2020-12-28T14:07:26Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ed4de0e7b5f268c387e0c15d205842936596d943", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/ed4de0e7b5f268c387e0c15d205842936596d943", "committedDate": "2020-12-28T14:07:26Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "committedDate": "2020-12-30T17:38:17Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwMjg2NDQ1", "url": "https://github.com/apache/flink/pull/10847#pullrequestreview-560286445", "createdAt": "2020-12-31T07:56:41Z", "commit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "state": "COMMENTED", "comments": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMVQwNzo1Njo0MVrOIM7Gtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMVQxMDoyOTo1MlrOIM86_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjE5OA==", "bodyText": "I think we can use StringUtils.byteToHexString(bytes) here to avoid duplicate implementation.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422198", "createdAt": "2020-12-31T07:56:41Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.Nonnull;\n+import javax.transaction.xa.Xid;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * A simple {@link Xid} implementation that stores branch and global transaction identifiers as byte\n+ * arrays.\n+ */\n+@Internal\n+final class XidImpl implements Xid, Serializable {\n+\n+    private final int formatId;\n+    @Nonnull private final byte[] globalTransactionId;\n+    @Nonnull private final byte[] branchQualifier;\n+\n+    XidImpl(int formatId, byte[] globalTransactionId, byte[] branchQualifier) {\n+        Preconditions.checkArgument(globalTransactionId.length <= Xid.MAXGTRIDSIZE);\n+        Preconditions.checkArgument(branchQualifier.length <= Xid.MAXBQUALSIZE);\n+        this.formatId = formatId;\n+        this.globalTransactionId = Arrays.copyOf(globalTransactionId, globalTransactionId.length);\n+        this.branchQualifier = Arrays.copyOf(branchQualifier, branchQualifier.length);\n+    }\n+\n+    @Override\n+    public int getFormatId() {\n+        return formatId;\n+    }\n+\n+    @Override\n+    public byte[] getGlobalTransactionId() {\n+        return globalTransactionId;\n+    }\n+\n+    @Override\n+    public byte[] getBranchQualifier() {\n+        return branchQualifier;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) {\n+            return true;\n+        }\n+        if (!(o instanceof XidImpl)) {\n+            return false;\n+        }\n+        XidImpl xid = (XidImpl) o;\n+        return formatId == xid.formatId\n+                && Arrays.equals(globalTransactionId, xid.globalTransactionId)\n+                && Arrays.equals(branchQualifier, xid.branchQualifier);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        int result = Objects.hash(formatId);\n+        result = 31 * result + Arrays.hashCode(globalTransactionId);\n+        result = 31 * result + Arrays.hashCode(branchQualifier);\n+        return result;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return formatId + \":\" + bytesToHex(globalTransactionId) + \":\" + bytesToHex(branchQualifier);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjMxMQ==", "bodyText": "Add a serialVersionUID to the class?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422311", "createdAt": "2020-12-31T07:57:18Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.Nonnull;\n+import javax.transaction.xa.Xid;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * A simple {@link Xid} implementation that stores branch and global transaction identifiers as byte\n+ * arrays.\n+ */\n+@Internal\n+final class XidImpl implements Xid, Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjc0MA==", "bodyText": "Condition obj == this covered by subsequent condition obj instanceof XidSerializer, we can remove obj == this here.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422740", "createdAt": "2020-12-31T07:59:48Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidSerializer.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+\n+/** {@link Xid} serializer. */\n+@Internal\n+final class XidSerializer extends TypeSerializer<Xid> {\n+\n+    private static final TypeSerializerSnapshot<Xid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<Xid>(XidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return true;\n+    }\n+\n+    @Override\n+    public TypeSerializer<Xid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public Xid createInstance() {\n+        return new XidImpl(0, new byte[0], new byte[0]);\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from) {\n+        return from;\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from, Xid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(Xid xid, DataOutputView target) throws IOException {\n+        target.writeInt(xid.getFormatId());\n+        writeBytesWithSize(target, xid.getGlobalTransactionId());\n+        writeBytesWithSize(target, xid.getBranchQualifier());\n+    }\n+\n+    @Override\n+    public Xid deserialize(DataInputView source) throws IOException {\n+        return new XidImpl(source.readInt(), readBytesWithSize(source), readBytesWithSize(source));\n+    }\n+\n+    private void writeBytesWithSize(DataOutputView target, byte[] bytes) throws IOException {\n+        target.writeByte(bytes.length);\n+        target.write(bytes, 0, bytes.length);\n+    }\n+\n+    private byte[] readBytesWithSize(DataInputView source) throws IOException {\n+        byte len = source.readByte();\n+        byte[] bytes = new byte[len];\n+        source.read(bytes, 0, len);\n+        return bytes;\n+    }\n+\n+    @Override\n+    public Xid deserialize(Xid reuse, DataInputView source) throws IOException {\n+        return deserialize(source);\n+    }\n+\n+    @Override\n+    public void copy(DataInputView source, DataOutputView target) throws IOException {\n+        serialize(deserialize(source), target);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        return obj == this || obj instanceof XidSerializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjgzNA==", "bodyText": "Better to return this.getClass().hashCode();.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422834", "createdAt": "2020-12-31T08:00:32Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidSerializer.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+\n+/** {@link Xid} serializer. */\n+@Internal\n+final class XidSerializer extends TypeSerializer<Xid> {\n+\n+    private static final TypeSerializerSnapshot<Xid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<Xid>(XidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return true;\n+    }\n+\n+    @Override\n+    public TypeSerializer<Xid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public Xid createInstance() {\n+        return new XidImpl(0, new byte[0], new byte[0]);\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from) {\n+        return from;\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from, Xid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(Xid xid, DataOutputView target) throws IOException {\n+        target.writeInt(xid.getFormatId());\n+        writeBytesWithSize(target, xid.getGlobalTransactionId());\n+        writeBytesWithSize(target, xid.getBranchQualifier());\n+    }\n+\n+    @Override\n+    public Xid deserialize(DataInputView source) throws IOException {\n+        return new XidImpl(source.readInt(), readBytesWithSize(source), readBytesWithSize(source));\n+    }\n+\n+    private void writeBytesWithSize(DataOutputView target, byte[] bytes) throws IOException {\n+        target.writeByte(bytes.length);\n+        target.write(bytes, 0, bytes.length);\n+    }\n+\n+    private byte[] readBytesWithSize(DataInputView source) throws IOException {\n+        byte len = source.readByte();\n+        byte[] bytes = new byte[len];\n+        source.read(bytes, 0, len);\n+        return bytes;\n+    }\n+\n+    @Override\n+    public Xid deserialize(Xid reuse, DataInputView source) throws IOException {\n+        return deserialize(source);\n+    }\n+\n+    @Override\n+    public void copy(DataInputView source, DataOutputView target) throws IOException {\n+        serialize(deserialize(source), target);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        return obj == this || obj instanceof XidSerializer;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMzkwMg==", "bodyText": "Could we add a test scope to this? And move this one and the following one under the <!-- test dependencies -->.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550423902", "createdAt": "2020-12-31T08:06:49Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -55,7 +55,15 @@ under the License.\n \t\t\t<groupId>org.apache.flink</groupId>\n \t\t\t<artifactId>flink-streaming-java_${scala.binary.version}</artifactId>\n \t\t\t<version>${project.version}</version>\n-\t\t\t<scope>provided</scope>\n+\t\t\t<type>test-jar</type>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMzk3MA==", "bodyText": "I think this is only used for testing, could we change the scope to test?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550423970", "createdAt": "2020-12-31T08:07:12Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -92,6 +100,19 @@ under the License.\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>javax.transaction</groupId>\n+\t\t\t<artifactId>javax.transaction-api</artifactId>\n+\t\t\t<version>1.3</version>\n+\t\t</dependency>\n+\n+\t\t<dependency>\n+\t\t\t<groupId>com.h2database</groupId>\n+\t\t\t<artifactId>h2</artifactId>\n+\t\t\t<version>1.4.200</version>\n+\t\t\t<scope>compile</scope>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNDAxMQ==", "bodyText": "What classes do we depend on this dependency?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550424011", "createdAt": "2020-12-31T08:07:32Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -92,6 +100,19 @@ under the License.\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>javax.transaction</groupId>\n+\t\t\t<artifactId>javax.transaction-api</artifactId>\n+\t\t\t<version>1.3</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTMxNw==", "bodyText": "This loses the restored information?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550425317", "createdAt": "2020-12-31T08:15:28Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializer.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/** {@link CheckpointAndXid} serializer. */\n+@Internal\n+final class CheckpointAndXidSerializer extends TypeSerializer<CheckpointAndXid> {\n+\n+    private static final TypeSerializerSnapshot<CheckpointAndXid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<CheckpointAndXid>(CheckpointAndXidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    private final TypeSerializer<Xid> xidSerializer = new XidSerializer();\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return xidSerializer.isImmutableType();\n+    }\n+\n+    @Override\n+    public TypeSerializer<CheckpointAndXid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public CheckpointAndXid createInstance() {\n+        return CheckpointAndXid.createRestored(0L, 0, xidSerializer.createInstance());\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from) {\n+        return CheckpointAndXid.createRestored(\n+                from.checkpointId, from.attempts, xidSerializer.copy(from.xid));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTgzMg==", "bodyText": "Why don't we serialize the restored flag?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550425832", "createdAt": "2020-12-31T08:18:02Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializer.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/** {@link CheckpointAndXid} serializer. */\n+@Internal\n+final class CheckpointAndXidSerializer extends TypeSerializer<CheckpointAndXid> {\n+\n+    private static final TypeSerializerSnapshot<CheckpointAndXid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<CheckpointAndXid>(CheckpointAndXidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    private final TypeSerializer<Xid> xidSerializer = new XidSerializer();\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return xidSerializer.isImmutableType();\n+    }\n+\n+    @Override\n+    public TypeSerializer<CheckpointAndXid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public CheckpointAndXid createInstance() {\n+        return CheckpointAndXid.createRestored(0L, 0, xidSerializer.createInstance());\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from) {\n+        return CheckpointAndXid.createRestored(\n+                from.checkpointId, from.attempts, xidSerializer.copy(from.xid));\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from, CheckpointAndXid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(CheckpointAndXid record, DataOutputView target) throws IOException {\n+        target.writeLong(record.checkpointId);\n+        target.writeInt(record.attempts);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzMTc1Nw==", "bodyText": "I think this can be simply supported by calling close() and open() ?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550431757", "createdAt": "2020-12-31T08:49:44Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaFacadeImpl.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.FlinkRuntimeException;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingRunnable;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import javax.sql.XAConnection;\n+import javax.sql.XADataSource;\n+import javax.transaction.xa.XAException;\n+import javax.transaction.xa.XAResource;\n+import javax.transaction.xa.Xid;\n+\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+import static java.util.Optional.empty;\n+import static java.util.Optional.of;\n+import static javax.transaction.xa.XAException.XAER_NOTA;\n+import static javax.transaction.xa.XAException.XAER_RMFAIL;\n+import static javax.transaction.xa.XAException.XA_HEURCOM;\n+import static javax.transaction.xa.XAException.XA_HEURHAZ;\n+import static javax.transaction.xa.XAException.XA_HEURMIX;\n+import static javax.transaction.xa.XAException.XA_HEURRB;\n+import static javax.transaction.xa.XAException.XA_RBBASE;\n+import static javax.transaction.xa.XAException.XA_RBTIMEOUT;\n+import static javax.transaction.xa.XAException.XA_RBTRANSIENT;\n+import static javax.transaction.xa.XAResource.TMENDRSCAN;\n+import static javax.transaction.xa.XAResource.TMNOFLAGS;\n+import static javax.transaction.xa.XAResource.TMSTARTRSCAN;\n+\n+/** Default {@link XaFacade} implementation. */\n+@NotThreadSafe\n+@Internal\n+class XaFacadeImpl implements XaFacade {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(XaFacadeImpl.class);\n+    private static final Set<Integer> TRANSIENT_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_RBTRANSIENT, XAER_RMFAIL));\n+    private static final Set<Integer> HEUR_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_HEURRB, XA_HEURCOM, XA_HEURHAZ, XA_HEURMIX));\n+    private static final int MAX_RECOVER_CALLS = 100;\n+\n+    private final Supplier<XADataSource> dataSourceSupplier;\n+    private final Integer timeoutSec;\n+    private transient XAResource xaResource;\n+    private transient Connection connection;\n+    private transient XAConnection xaConnection;\n+\n+    /** @return a non-serializable instance. */\n+    static XaFacadeImpl fromXaDataSource(XADataSource ds) {\n+        return new XaFacadeImpl(() -> ds, empty());\n+    }\n+\n+    XaFacadeImpl(Supplier<XADataSource> dataSourceSupplier, Optional<Integer> timeoutSec) {\n+        this.dataSourceSupplier = Preconditions.checkNotNull(dataSourceSupplier);\n+        this.timeoutSec = timeoutSec.orElse(null);\n+    }\n+\n+    @Override\n+    public void open() throws SQLException, XAException {\n+        Preconditions.checkState(!isOpen(), \"already connected\");\n+        XADataSource ds = dataSourceSupplier.get();\n+        xaConnection = ds.getXAConnection();\n+        xaResource = xaConnection.getXAResource();\n+        if (timeoutSec != null) {\n+            xaResource.setTransactionTimeout(timeoutSec);\n+        }\n+        connection = xaConnection.getConnection();\n+        connection.setReadOnly(false);\n+        connection.setAutoCommit(false);\n+        Preconditions.checkState(!connection.getAutoCommit());\n+    }\n+\n+    @Override\n+    public void close() throws SQLException {\n+        if (connection != null) {\n+            connection.close();\n+            connection = null;\n+        }\n+        if (xaConnection != null) {\n+            xaConnection.close();\n+            xaConnection = null;\n+        }\n+        xaResource = null;\n+    }\n+\n+    @Override\n+    public Connection getConnection() {\n+        Preconditions.checkNotNull(connection);\n+        return connection;\n+    }\n+\n+    @Override\n+    public boolean isConnectionValid() {\n+        return isOpen();\n+    }\n+\n+    @Override\n+    public Connection getOrEstablishConnection() throws SQLException, ClassNotFoundException {\n+        if (!isOpen()) {\n+            try {\n+                open();\n+            } catch (XAException e) {\n+                throw new SQLException(e);\n+            }\n+        }\n+        return connection;\n+    }\n+\n+    @Override\n+    public void closeConnection() {\n+        try {\n+            close();\n+        } catch (SQLException e) {\n+            LOG.warn(\"Connection close failed.\", e);\n+        }\n+    }\n+\n+    @Override\n+    public Connection reestablishConnection() {\n+        throw new UnsupportedOperationException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzMzM5OQ==", "bodyText": "Should use connection.isValid to check the validation?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550433399", "createdAt": "2020-12-31T08:58:25Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaFacadeImpl.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.FlinkRuntimeException;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingRunnable;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import javax.sql.XAConnection;\n+import javax.sql.XADataSource;\n+import javax.transaction.xa.XAException;\n+import javax.transaction.xa.XAResource;\n+import javax.transaction.xa.Xid;\n+\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+import static java.util.Optional.empty;\n+import static java.util.Optional.of;\n+import static javax.transaction.xa.XAException.XAER_NOTA;\n+import static javax.transaction.xa.XAException.XAER_RMFAIL;\n+import static javax.transaction.xa.XAException.XA_HEURCOM;\n+import static javax.transaction.xa.XAException.XA_HEURHAZ;\n+import static javax.transaction.xa.XAException.XA_HEURMIX;\n+import static javax.transaction.xa.XAException.XA_HEURRB;\n+import static javax.transaction.xa.XAException.XA_RBBASE;\n+import static javax.transaction.xa.XAException.XA_RBTIMEOUT;\n+import static javax.transaction.xa.XAException.XA_RBTRANSIENT;\n+import static javax.transaction.xa.XAResource.TMENDRSCAN;\n+import static javax.transaction.xa.XAResource.TMNOFLAGS;\n+import static javax.transaction.xa.XAResource.TMSTARTRSCAN;\n+\n+/** Default {@link XaFacade} implementation. */\n+@NotThreadSafe\n+@Internal\n+class XaFacadeImpl implements XaFacade {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(XaFacadeImpl.class);\n+    private static final Set<Integer> TRANSIENT_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_RBTRANSIENT, XAER_RMFAIL));\n+    private static final Set<Integer> HEUR_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_HEURRB, XA_HEURCOM, XA_HEURHAZ, XA_HEURMIX));\n+    private static final int MAX_RECOVER_CALLS = 100;\n+\n+    private final Supplier<XADataSource> dataSourceSupplier;\n+    private final Integer timeoutSec;\n+    private transient XAResource xaResource;\n+    private transient Connection connection;\n+    private transient XAConnection xaConnection;\n+\n+    /** @return a non-serializable instance. */\n+    static XaFacadeImpl fromXaDataSource(XADataSource ds) {\n+        return new XaFacadeImpl(() -> ds, empty());\n+    }\n+\n+    XaFacadeImpl(Supplier<XADataSource> dataSourceSupplier, Optional<Integer> timeoutSec) {\n+        this.dataSourceSupplier = Preconditions.checkNotNull(dataSourceSupplier);\n+        this.timeoutSec = timeoutSec.orElse(null);\n+    }\n+\n+    @Override\n+    public void open() throws SQLException, XAException {\n+        Preconditions.checkState(!isOpen(), \"already connected\");\n+        XADataSource ds = dataSourceSupplier.get();\n+        xaConnection = ds.getXAConnection();\n+        xaResource = xaConnection.getXAResource();\n+        if (timeoutSec != null) {\n+            xaResource.setTransactionTimeout(timeoutSec);\n+        }\n+        connection = xaConnection.getConnection();\n+        connection.setReadOnly(false);\n+        connection.setAutoCommit(false);\n+        Preconditions.checkState(!connection.getAutoCommit());\n+    }\n+\n+    @Override\n+    public void close() throws SQLException {\n+        if (connection != null) {\n+            connection.close();\n+            connection = null;\n+        }\n+        if (xaConnection != null) {\n+            xaConnection.close();\n+            xaConnection = null;\n+        }\n+        xaResource = null;\n+    }\n+\n+    @Override\n+    public Connection getConnection() {\n+        Preconditions.checkNotNull(connection);\n+        return connection;\n+    }\n+\n+    @Override\n+    public boolean isConnectionValid() {\n+        return isOpen();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzNTkxNg==", "bodyText": "Add @PublicEvolving annotation?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550435916", "createdAt": "2020-12-31T09:11:21Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExactlyOnceOptions.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+\n+/**\n+ * JDBC exactly once sink options.\n+ *\n+ * <p><b>maxCommitAttempts</b> - maximum number of commit attempts to make per transaction; must be\n+ * > 0; state size is proportional to the product of max number of in-flight snapshots and this\n+ * number.\n+ *\n+ * <p><b>allowOutOfOrderCommits</b> - If true, all prepared transactions will be attempted to commit\n+ * regardless of any transient failures during this operation. This may lead to inconsistency.\n+ * Default: false.\n+ *\n+ * <p><b>recoveredAndRollback</b> - whether to rollback prepared transactions known to XA RM on\n+ * startup (after committing <b>known</b> transactions, i.e. restored from state).\n+ *\n+ * <p>NOTE that setting this parameter to true may:\n+ *\n+ * <ol>\n+ *   <li>interfere with other subtasks or applications (one subtask rolling back transactions\n+ *       prepared by the other one (and known to it))\n+ *   <li>block when using with some non-MVCC databases, if there are ended-not-prepared transactions\n+ * </ol>\n+ *\n+ * See also {@link org.apache.flink.connector.jdbc.xa.XaFacade#recover()}\n+ */\n+public class JdbcExactlyOnceOptions implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzOTU5Mg==", "bodyText": "Does the hangingXids have to be a Deque to keep the order? If yes, I'm wondering the state recovery doesn't retain the order.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550439592", "createdAt": "2020-12-31T09:29:23Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzOTcyNQ==", "bodyText": "nit: would be better to call this outputFormat to avoid confusing with formats, e.g. csv, json.", "url": "https://github.com/apache/flink/pull/10847#discussion_r550439725", "createdAt": "2020-12-31T09:30:07Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NTAzMA==", "bodyText": "Will this break the state consistent that hangingXids.peek() should equal to currentXid?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550445030", "createdAt": "2020-12-31T09:55:57Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());\n+        preparedXids = new ArrayList<>(state.getPrepared());\n+        LOG.info(\n+                \"initialized state: prepared xids: {}, hanging xids: {}\",\n+                preparedXids.size(),\n+                hangingXids.size());\n+    }\n+\n+    @Override\n+    public void open(Configuration configuration) throws Exception {\n+        super.open(configuration);\n+        xidGenerator.open();\n+        xaFacade.open();\n+        format.setRuntimeContext(getRuntimeContext());\n+        format.open(\n+                getRuntimeContext().getIndexOfThisSubtask(),\n+                getRuntimeContext().getNumberOfParallelSubtasks());\n+        hangingXids = new LinkedList<>(xaGroupOps.failOrRollback(hangingXids).getForRetry());\n+        commitUpToCheckpoint(Optional.empty());\n+        if (options.isDiscoverAndRollbackOnRecovery()) {\n+            // todo: consider doing recover-rollback later (e.g. after the 1st checkpoint)\n+            // when we are sure that all other subtasks started and committed any of their prepared\n+            // transactions\n+            // this would require to distinguish between this job Xids and other Xids\n+            xaGroupOps.recoverAndRollback();\n+        }\n+        beginTx(0L);\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        LOG.debug(\"snapshot state, checkpointId={}\", context.getCheckpointId());\n+        rollbackPreparedFromCheckpoint(context.getCheckpointId());\n+        prepareCurrentTx(context.getCheckpointId());\n+        beginTx(context.getCheckpointId() + 1);\n+        stateHandler.store(of(preparedXids, hangingXids));\n+    }\n+\n+    @Override\n+    public void notifyCheckpointComplete(long checkpointId) {\n+        commitUpToCheckpoint(Optional.of(checkpointId));\n+    }\n+\n+    @Override\n+    public void invoke(T value, Context context) throws IOException {\n+        Preconditions.checkState(currentXid != null, \"current xid must not be null\");\n+        if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"invoke, xid: {}, value: {}\", currentXid, value);\n+        }\n+        format.writeRecord(value);\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        super.close();\n+        if (currentXid != null && xaFacade.isOpen()) {\n+            try {\n+                LOG.debug(\"remove current transaction before closing, xid={}\", currentXid);\n+                xaFacade.failOrRollback(currentXid);\n+            } catch (Exception e) {\n+                LOG.warn(\"unable to fail/rollback current transaction, xid={}\", currentXid, e);\n+            }\n+        }\n+        xaFacade.close();\n+        xidGenerator.close();\n+        // don't format.close(); as we don't want neither to flush nor to close connection here\n+        currentXid = null;\n+        hangingXids = null;\n+        preparedXids = null;\n+    }\n+\n+    private void prepareCurrentTx(long checkpointId) throws IOException {\n+        Preconditions.checkState(currentXid != null, \"no current xid\");\n+        Preconditions.checkState(\n+                !hangingXids.isEmpty() && hangingXids.peek().equals(currentXid),\n+                \"inconsistent internal state\");\n+        hangingXids.poll();\n+        format.flush();\n+        try {\n+            xaFacade.endAndPrepare(currentXid);\n+            preparedXids.add(CheckpointAndXid.createNew(checkpointId, currentXid));\n+        } catch (EmptyXaTransactionException e) {\n+            LOG.info(\n+                    \"empty XA transaction (skip), xid: {}, checkpoint {}\",\n+                    currentXid,\n+                    checkpointId);\n+        }\n+        currentXid = null;\n+    }\n+\n+    /** @param checkpointId to associate with the new transaction. */\n+    private void beginTx(long checkpointId) {\n+        Preconditions.checkState(currentXid == null, \"currentXid not null\");\n+        currentXid = xidGenerator.generateXid(getRuntimeContext(), checkpointId);\n+        hangingXids.offer(currentXid);\n+        xaFacade.start(currentXid);\n+    }\n+\n+    private void commitUpToCheckpoint(Optional<Long> checkpointInclusive) {\n+        Tuple2<List<CheckpointAndXid>, List<CheckpointAndXid>> splittedXids =\n+                split(preparedXids, checkpointInclusive, true);\n+        if (splittedXids.f0.isEmpty()) {\n+            checkpointInclusive.ifPresent(\n+                    cp -> LOG.warn(\"nothing to commit up to checkpoint: {}\", cp));\n+        } else {\n+            preparedXids = splittedXids.f1;\n+            preparedXids.addAll(\n+                    xaGroupOps\n+                            .commit(\n+                                    splittedXids.f0,\n+                                    options.isAllowOutOfOrderCommits(),\n+                                    options.getMaxCommitAttempts())\n+                            .getForRetry());\n+        }\n+    }\n+\n+    private void rollbackPreparedFromCheckpoint(long fromCheckpointInclusive) {\n+        Tuple2<List<CheckpointAndXid>, List<CheckpointAndXid>> splittedXids =\n+                split(preparedXids, fromCheckpointInclusive, false);\n+        if (splittedXids.f1.isEmpty()) {\n+            return;\n+        }\n+        preparedXids = splittedXids.f0;\n+        LOG.warn(\n+                \"state snapshots have already been taken for checkpoint >= {}, rolling back {} transactions\",\n+                fromCheckpointInclusive,\n+                splittedXids.f1.size());\n+        xaGroupOps\n+                .failOrRollback(\n+                        splittedXids.f1.stream()\n+                                .map(CheckpointAndXid::getXid)\n+                                .collect(Collectors.toList()))\n+                .getForRetry()\n+                .forEach(hangingXids::offerFirst);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 340}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NzczMA==", "bodyText": "Could you add Javadocs on the configuration mehtods about what are the configs used for?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550447730", "createdAt": "2020-12-31T10:08:56Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExactlyOnceOptions.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+\n+/**\n+ * JDBC exactly once sink options.\n+ *\n+ * <p><b>maxCommitAttempts</b> - maximum number of commit attempts to make per transaction; must be\n+ * > 0; state size is proportional to the product of max number of in-flight snapshots and this\n+ * number.\n+ *\n+ * <p><b>allowOutOfOrderCommits</b> - If true, all prepared transactions will be attempted to commit\n+ * regardless of any transient failures during this operation. This may lead to inconsistency.\n+ * Default: false.\n+ *\n+ * <p><b>recoveredAndRollback</b> - whether to rollback prepared transactions known to XA RM on\n+ * startup (after committing <b>known</b> transactions, i.e. restored from state).\n+ *\n+ * <p>NOTE that setting this parameter to true may:\n+ *\n+ * <ol>\n+ *   <li>interfere with other subtasks or applications (one subtask rolling back transactions\n+ *       prepared by the other one (and known to it))\n+ *   <li>block when using with some non-MVCC databases, if there are ended-not-prepared transactions\n+ * </ol>\n+ *\n+ * See also {@link org.apache.flink.connector.jdbc.xa.XaFacade#recover()}\n+ */\n+public class JdbcExactlyOnceOptions implements Serializable {\n+\n+    private static final boolean DEFAULT_RECOVERED_AND_ROLLBACK = false;\n+    private static final int DEFAULT_MAX_COMMIT_ATTEMPTS = 3;\n+    private static final boolean DEFAULT_ALLOW_OUT_OF_ORDER_COMMITS = false;\n+\n+    private final boolean discoverAndRollbackOnRecovery;\n+    private final int maxCommitAttempts;\n+    private final boolean allowOutOfOrderCommits;\n+    private final Integer timeoutSec;\n+\n+    private JdbcExactlyOnceOptions(\n+            boolean discoverAndRollbackOnRecovery,\n+            int maxCommitAttempts,\n+            boolean allowOutOfOrderCommits,\n+            Optional<Integer> timeoutSec) {\n+        this.discoverAndRollbackOnRecovery = discoverAndRollbackOnRecovery;\n+        this.maxCommitAttempts = maxCommitAttempts;\n+        this.allowOutOfOrderCommits = allowOutOfOrderCommits;\n+        this.timeoutSec = timeoutSec.orElse(null);\n+        Preconditions.checkArgument(this.maxCommitAttempts > 0, \"maxCommitAttempts should be > 0\");\n+    }\n+\n+    public static JdbcExactlyOnceOptions defaults() {\n+        return builder().build();\n+    }\n+\n+    public boolean isDiscoverAndRollbackOnRecovery() {\n+        return discoverAndRollbackOnRecovery;\n+    }\n+\n+    public boolean isAllowOutOfOrderCommits() {\n+        return allowOutOfOrderCommits;\n+    }\n+\n+    public int getMaxCommitAttempts() {\n+        return maxCommitAttempts;\n+    }\n+\n+    public Integer getTimeoutSec() {\n+        return timeoutSec;\n+    }\n+\n+    public static JDBCExactlyOnceOptionsBuilder builder() {\n+        return new JDBCExactlyOnceOptionsBuilder();\n+    }\n+\n+    /** JDBCExactlyOnceOptionsBuilder. */\n+    public static class JDBCExactlyOnceOptionsBuilder {\n+        private boolean recoveredAndRollback = DEFAULT_RECOVERED_AND_ROLLBACK;\n+        private int maxCommitAttempts = DEFAULT_MAX_COMMIT_ATTEMPTS;\n+        private boolean allowOutOfOrderCommits = DEFAULT_ALLOW_OUT_OF_ORDER_COMMITS;\n+        private Optional<Integer> timeoutSec = Optional.empty();\n+\n+        public JDBCExactlyOnceOptionsBuilder withRecoveredAndRollback(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0ODg4NQ==", "bodyText": "I have some questions:\n\nWill this leave some retry Xids in the preparedXids?\nIf the job is failed, will the job restart the checkpoint from checkpoint: 0?\nIf yes, will the retry Xids in the preparedXids not be comitted for a long time?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550448885", "createdAt": "2020-12-31T10:15:01Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());\n+        preparedXids = new ArrayList<>(state.getPrepared());\n+        LOG.info(\n+                \"initialized state: prepared xids: {}, hanging xids: {}\",\n+                preparedXids.size(),\n+                hangingXids.size());\n+    }\n+\n+    @Override\n+    public void open(Configuration configuration) throws Exception {\n+        super.open(configuration);\n+        xidGenerator.open();\n+        xaFacade.open();\n+        format.setRuntimeContext(getRuntimeContext());\n+        format.open(\n+                getRuntimeContext().getIndexOfThisSubtask(),\n+                getRuntimeContext().getNumberOfParallelSubtasks());\n+        hangingXids = new LinkedList<>(xaGroupOps.failOrRollback(hangingXids).getForRetry());\n+        commitUpToCheckpoint(Optional.empty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ1MTk2Ng==", "bodyText": "I'm a little confused about this. Does this mean we can't provide exactly once guarantee across partititons?", "url": "https://github.com/apache/flink/pull/10847#discussion_r550451966", "createdAt": "2020-12-31T10:29:52Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwMDcwMjE1", "url": "https://github.com/apache/flink/pull/10847#pullrequestreview-570070215", "createdAt": "2021-01-17T15:58:54Z", "commit": {"oid": "0bc72013bb63f51c7de3909885709de5e56940dd"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QxNTo1ODo1NVrOIVS6dA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xN1QxNTo1OTowOVrOIVS6qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDg4NA==", "bodyText": "I think a better and easier way to test serializer is extending SerializerTestBase.", "url": "https://github.com/apache/flink/pull/10847#discussion_r559200884", "createdAt": "2021-01-17T15:58:55Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializersTest.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/** XaSerializersTest. */\n+public class CheckpointAndXidSerializersTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc72013bb63f51c7de3909885709de5e56940dd"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDkzOA==", "bodyText": "I think a better and easier way to test serializer is extending SerializerTestBase.", "url": "https://github.com/apache/flink/pull/10847#discussion_r559200938", "createdAt": "2021-01-17T15:59:09Z", "author": {"login": "wuchong"}, "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/XidSerializersTest.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+\n+import org.junit.Test;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+/** XaSerializersTest. */\n+public class XidSerializersTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0bc72013bb63f51c7de3909885709de5e56940dd"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwODc3NzQ0", "url": "https://github.com/apache/flink/pull/10847#pullrequestreview-570877744", "createdAt": "2021-01-19T03:13:47Z", "commit": {"oid": "51794ed8d24485bee01645ee15e7ecc1b8d13f8f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e28928f4abbbf2b380db720d6b1dc6d5eeae7b05", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/e28928f4abbbf2b380db720d6b1dc6d5eeae7b05", "committedDate": "2021-01-19T07:50:15Z", "message": "[hotfix][sink][test] Unignore JdbcITCase"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f27572110fbc02a1f0ad65260212b621b928dfe", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/6f27572110fbc02a1f0ad65260212b621b928dfe", "committedDate": "2021-01-19T07:50:57Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "51794ed8d24485bee01645ee15e7ecc1b8d13f8f", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/51794ed8d24485bee01645ee15e7ecc1b8d13f8f", "committedDate": "2021-01-18T21:27:11Z", "message": "fixup! fixup! [FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}, "afterCommit": {"oid": "6f27572110fbc02a1f0ad65260212b621b928dfe", "author": {"user": {"login": "rkhachatryan", "name": "Roman"}}, "url": "https://github.com/apache/flink/commit/6f27572110fbc02a1f0ad65260212b621b928dfe", "committedDate": "2021-01-19T07:50:57Z", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4704, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}